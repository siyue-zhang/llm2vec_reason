{"TheoremQA_elainewan/math_calculus_5_2.json": {"camel_6824": 0, "camel_7241": 0, "camel_7253": 0, "camel_6865": 0, "camel_6855": 0, "camel_6848": 0, "camel_6808": 0, "camel_6820": 0, "camel_6874": 0, "camel_6857": 0, "camel_6809": 0, "camel_6816": 0, "camel_6876": 0, "camel_6805": 0, "camel_6819": 0, "camel_6802": 0, "camel_6852": 0, "camel_6831": 0, "camel_6834": 0, "camel_6877": 0, "camel_6822": 0, "camel_6863": 0, "camel_6854": 0, "camel_6811": 0, "camel_6879": 0, "camel_6832": 0, "camel_6837": 0, "camel_6830": 0, "camel_6836": 0, "camel_6803": 0, "camel_6867": 0, "camel_6851": 0, "camel_6861": 0, "camel_6833": 0, "aqua_rat_48063": 0.7324509620666504, "gsm_rft_17167": 0.7325214743614197, "math_train_algebra_1735": 0.7325446009635925, "math_test_algebra_981": 0.7325935363769531, "camel_30697": 0.7326709032058716, "aqua_rat_28633": 0.7326927781105042, "camel_31258": 0.7330976128578186, "aqua_rat_2195": 0.7333664894104004, "aqua_rat_28645": 0.7334028482437134, "camel_31220": 0.7334890961647034, "aqua_rat_56227": 0.7335062623023987, "camel_969": 0.7335977554321289, "aqua_rat_4456": 0.7336224913597107, "aqua_rat_37001": 0.7336422801017761, "aqua_rat_34190": 0.7336732149124146, "aqua_rat_50390": 0.7338539958000183, "camel_39122": 0.7339667081832886, "gsm_rft_21414": 0.733979344367981, "aqua_rat_37157": 0.7340393662452698, "gsm_rft_18280": 0.7340395450592041, "aqua_rat_62310": 0.7341551184654236, "camel_3446": 0.7342535257339478, "aqua_rat_23008": 0.7343509197235107, "camel_31278": 0.7344385981559753, "aqua_rat_51555": 0.7345965504646301, "aqua_rat_14360": 0.7345983982086182, "aqua_rat_19771": 0.7346507906913757, "camel_2359": 0.7347397208213806, "camel_2372": 0.7347984313964844, "aqua_rat_65926": 0.7350023984909058, "aqua_rat_66672": 0.735148549079895, "aqua_rat_11054": 0.7353672385215759, "gsm_rft_30481": 0.7354790568351746, "gsm_train_17263": 0.7354790568351746, "aqua_rat_17258": 0.7356383800506592, "aqua_rat_59885": 0.7356517910957336, "aqua_rat_38060": 0.7357224225997925, "aqua_rat_74848": 0.7358177304267883, "aqua_rat_57204": 0.7360637784004211, "aqua_rat_28458": 0.7360805869102478, "math_test_algebra_2284": 0.7361518144607544, "camel_30690": 0.7362249493598938, "aqua_rat_22245": 0.7363201379776001, "camel_31273": 0.7364389896392822, "aqua_rat_1178": 0.7364858984947205, "aqua_rat_27804": 0.7366252541542053, "gsm_rft_18615": 0.7367135286331177, "aqua_rat_49581": 0.736736536026001, "camel_31101": 0.7367714047431946, "camel_30657": 0.7369102239608765, "aqua_rat_5416": 0.7369957566261292, "aqua_rat_35106": 0.7369993925094604, "aqua_rat_39676": 0.7372042536735535, "aqua_rat_45928": 0.7374463081359863, "aqua_rat_49970": 0.7377541661262512, "gsm_train_26371": 0.7377774715423584, "aqua_rat_63860": 0.737849771976471, "aqua_rat_60271": 0.7380310297012329, "camel_31286": 0.7380819916725159, "aqua_rat_86925": 0.7381691932678223, "camel_2370": 0.7382533550262451, "camel_30683": 0.7382586598396301, "aqua_rat_70726": 0.7382755279541016, "camel_31340": 0.7383384108543396, "aqua_rat_63153": 0.7383456230163574, "camel_5436": 0.7383712530136108, "camel_31078": 0.7384456396102905, "aqua_rat_11589": 0.7386072278022766, "gsm_rft_20403": 0.7389857769012451, "gsm_rft_20758": 0.7390764355659485, "aqua_rat_76127": 0.7395526170730591, "aqua_rat_28257": 0.7395866513252258, "aqua_rat_13947": 0.7399064898490906, "aqua_rat_52546": 0.7400788068771362, "aqua_rat_4051": 0.7407895922660828, "aqua_rat_38371": 0.741210401058197, "aqua_rat_70198": 0.7414394617080688, "aqua_rat_68920": 0.7415059208869934, "gsm_rft_7352": 0.7415397763252258, "gsm_train_32872": 0.7415499687194824, "math_test_algebra_1303": 0.7418949007987976, "aqua_rat_62650": 0.7423515319824219, "gsm_rft_469": 0.7424339652061462, "aqua_rat_33646": 0.7424483895301819, "gsm_train_15179": 0.7425166368484497, "gsm_rft_24752": 0.7425422668457031, "aqua_rat_15634": 0.7428072690963745, "aqua_rat_11633": 0.7435270547866821, "aqua_rat_47616": 0.7435811161994934, "gsm_rft_34686": 0.7436509132385254, "math_train_geometry_430": 0.7438338398933411, "aqua_rat_57461": 0.7441383004188538, "aqua_rat_17252": 0.7448408603668213, "aqua_rat_84494": 0.7450014352798462, "aqua_rat_32037": 0.7453079223632812, "aqua_rat_23330": 0.7454146146774292, "gsm_rft_24023": 0.7457095384597778, "aqua_rat_13807": 0.746100902557373, "gsm_rft_34916": 0.7461844086647034, "gsm_train_31543": 0.7461844086647034, "gsm_rft_4984": 0.7461844086647034, "aqua_rat_53348": 0.7463647723197937, "aqua_rat_47871": 0.7465402483940125, "aqua_rat_77082": 0.7467964291572571, "aqua_rat_13049": 0.7469044327735901, "gsm_rft_30558": 0.7472634315490723, "gsm_rft_19857": 0.7479742169380188, "aqua_rat_45358": 0.7481960654258728, "aqua_rat_11429": 0.7483106255531311, "math_test_algebra_2091": 0.7486976385116577, "camel_30703": 0.7489438056945801, "aqua_rat_18888": 0.7491316795349121, "aqua_rat_16428": 0.7494911551475525, "camel_37442": 0.7495872974395752, "gsm_rft_20038": 0.7497254014015198, "gsm_train_6685": 0.7499487996101379, "gsm_train_31200": 0.7505099177360535, "gsm_rft_5605": 0.7507920265197754, "aqua_rat_13982": 0.7508799433708191, "aqua_rat_34824": 0.7509060502052307, "aqua_rat_84797": 0.7510750889778137, "gsm_rft_13509": 0.7511386275291443, "aqua_rat_71177": 0.7514985799789429, "aqua_rat_27419": 0.7519270181655884, "aqua_rat_20021": 0.7527072429656982, "aqua_rat_42383": 0.7531501054763794, "gsm_rft_34403": 0.753278374671936, "gsm_train_31883": 0.753278374671936, "aqua_rat_51871": 0.7533236145973206, "gsm_rft_29300": 0.7535825371742249, "aqua_rat_34293": 0.7536588311195374, "aqua_rat_69903": 0.7538808584213257, "math_test_algebra_1377": 0.7546705603599548, "gsm_rft_960": 0.7548619508743286, "aqua_rat_74383": 0.7552139163017273, "aqua_rat_28038": 0.7552664279937744, "camel_5037": 0.755550742149353, "aqua_rat_19732": 0.7558329105377197, "aqua_rat_15784": 0.7559196949005127, "aqua_rat_42745": 0.7564349174499512, "aqua_rat_18977": 0.7566684484481812, "aqua_rat_16497": 0.7570719122886658, "math_train_algebra_52": 0.7572559118270874, "aqua_rat_67610": 0.7574516534805298, "aqua_rat_65312": 0.7591023445129395, "aqua_rat_23237": 0.7592254281044006, "aqua_rat_8703": 0.7593729496002197, "camel_30709": 0.7598230242729187, "aqua_rat_67451": 0.759926438331604, "aqua_rat_37668": 0.7611026167869568, "aqua_rat_35057": 0.7637948989868164, "aqua_rat_47365": 0.7658241987228394, "aqua_rat_59882": 0.7680322527885437, "gsm_rft_17947": 0.7725790739059448, "gsm_rft_17465": 0.7725790739059448, "gsm_train_29627": 0.7728521823883057, "gsm_rft_9752": 0.7790473699569702, "gsm_train_179": 0.7797008156776428, "aqua_rat_59630": 0.7810314893722534, "aqua_rat_56788": 0.7815194129943848, "gsm_rft_32594": 0.7817632555961609, "aqua_rat_17824": 0.7820999622344971, "aqua_rat_15563": 0.7821821570396423, "aqua_rat_42376": 0.7824240922927856, "aqua_rat_76659": 0.7866608500480652, "aqua_rat_24388": 0.7966723442077637}, "TheoremQA_jianyu_xu/pigeonhole_3.json": {"camel_20614": 0, "camel_20310": 0, "camel_21165": 0, "camel_21246": 0, "camel_21068": 0, "camel_21218": 0, "math_train_number_theory_717": 0, "camel_21798": 0, "math_test_number_theory_612": 0, "camel_21141": 0, "camel_21160": 0, "camel_21177": 0, "TheoremQA_jianyu_xu/pigeonhole_3.json": 0, "camel_21040": 0, "camel_21361": 0, "camel_21154": 0, "camel_21169": 0, "camel_21128": 0, "camel_21174": 0, "camel_21196": 0, "camel_21147": 0, "camel_21159": 0, "camel_21183": 0, "camel_21126": 0, "aqua_rat_44859": 0.7155603766441345, "aqua_rat_69238": 0.7156796455383301, "aqua_rat_73560": 0.7157609462738037, "aqua_rat_58655": 0.7158416509628296, "aqua_rat_7904": 0.7159944772720337, "aqua_rat_19703": 0.7160419225692749, "aqua_rat_70004": 0.7161797881126404, "aqua_rat_76846": 0.7161960601806641, "aqua_rat_31643": 0.7164416909217834, "math_test_counting_and_probability_294": 0.7165310382843018, "aqua_rat_69292": 0.7165927290916443, "aqua_rat_84115": 0.7171927094459534, "math_train_prealgebra_109": 0.7172176837921143, "gsm_rft_4734": 0.7177245616912842, "camel_24417": 0.7184311151504517, "aqua_rat_36961": 0.7186532616615295, "aqua_rat_39047": 0.7186611294746399, "aqua_rat_87748": 0.7186865210533142, "aqua_rat_82495": 0.7187002897262573, "aqua_rat_35873": 0.7187515497207642, "aqua_rat_52817": 0.7188593149185181, "math_train_counting_and_probability_83": 0.7189244627952576, "aqua_rat_47936": 0.7190824151039124, "aqua_rat_61626": 0.7191267013549805, "aqua_rat_73605": 0.7191384434700012, "aqua_rat_80653": 0.7193381786346436, "aqua_rat_81950": 0.7195200324058533, "aqua_rat_1237": 0.7196044921875, "camel_36341": 0.7196460366249084, "aqua_rat_11918": 0.7198408842086792, "math_test_prealgebra_1560": 0.719927966594696, "aqua_rat_59145": 0.7203910946846008, "gsm_rft_22082": 0.7206008434295654, "aqua_rat_60779": 0.7206530570983887, "aqua_rat_51045": 0.7207755446434021, "math_test_prealgebra_1034": 0.7208452820777893, "gsm_rft_19787": 0.7214322686195374, "gsm_rft_22335": 0.7214387059211731, "gsm_train_27893": 0.7214387059211731, "gsm_rft_19183": 0.7215123176574707, "gsm_rft_8826": 0.7216857671737671, "aqua_rat_48668": 0.721709668636322, "aqua_rat_66347": 0.7217757701873779, "camel_37666": 0.7219218611717224, "math_test_counting_and_probability_430": 0.722119152545929, "gsm_rft_33533": 0.7230374813079834, "aqua_rat_65264": 0.7238891124725342, "aqua_rat_149": 0.724144697189331, "aqua_rat_78805": 0.7243752479553223, "aqua_rat_5877": 0.7246493697166443, "aqua_rat_80224": 0.7246766686439514, "aqua_rat_15442": 0.7247466444969177, "aqua_rat_24803": 0.7247663140296936, "camel_11570": 0.7249871492385864, "aqua_rat_19096": 0.7250795364379883, "math_train_prealgebra_1573": 0.7256468534469604, "aqua_rat_6737": 0.7257508635520935, "aqua_rat_29842": 0.7258378863334656, "aqua_rat_64699": 0.725976288318634, "aqua_rat_37216": 0.7260151505470276, "aqua_rat_47084": 0.7267542481422424, "aqua_rat_69267": 0.7269097566604614, "aqua_rat_31932": 0.7269182205200195, "aqua_rat_60456": 0.7271272540092468, "aqua_rat_7483": 0.7275155186653137, "aqua_rat_67387": 0.727831244468689, "aqua_rat_17862": 0.7282319664955139, "aqua_rat_85357": 0.7283638715744019, "aqua_rat_34864": 0.7290114164352417, "aqua_rat_17359": 0.7293135523796082, "aqua_rat_12317": 0.729499340057373, "aqua_rat_51353": 0.7299216985702515, "aqua_rat_82662": 0.7304173707962036, "aqua_rat_14782": 0.7310442924499512, "aqua_rat_23573": 0.7319747805595398, "aqua_rat_40097": 0.7322893738746643, "math_train_counting_and_probability_1015": 0.7327374815940857, "aqua_rat_18128": 0.7331685423851013, "aqua_rat_70890": 0.7332295775413513, "aqua_rat_30710": 0.733298659324646, "aqua_rat_83796": 0.7334290146827698, "aqua_rat_56528": 0.7338511347770691, "aqua_rat_72179": 0.7339329719543457, "aqua_rat_37903": 0.7339594960212708, "math_test_prealgebra_1443": 0.7342649102210999, "aqua_rat_78018": 0.7343890070915222, "aqua_rat_50597": 0.734488844871521, "aqua_rat_32047": 0.7351044416427612, "aqua_rat_48028": 0.7353224754333496, "math_train_algebra_770": 0.7353282570838928, "aqua_rat_52525": 0.7353448271751404, "aqua_rat_15286": 0.7355202436447144, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0.7357735633850098, "math_train_algebra_2532": 0.7364283204078674, "aqua_rat_25753": 0.7364509105682373, "aqua_rat_36396": 0.7367219924926758, "aqua_rat_23494": 0.7368664741516113, "math_test_counting_and_probability_686": 0.7370764017105103, "aqua_rat_87077": 0.7371026873588562, "camel_11529": 0.737156093120575, "aqua_rat_46632": 0.7372176051139832, "aqua_rat_66892": 0.7381643056869507, "aqua_rat_81033": 0.7381675243377686, "aqua_rat_44416": 0.7383756041526794, "camel_38521": 0.7384141683578491, "aqua_rat_5242": 0.7385520339012146, "aqua_rat_59053": 0.7385636568069458, "aqua_rat_53475": 0.7386593222618103, "aqua_rat_20344": 0.739690899848938, "aqua_rat_22763": 0.739709734916687, "aqua_rat_26962": 0.7401515245437622, "aqua_rat_80759": 0.740408718585968, "aqua_rat_80435": 0.7407984137535095, "aqua_rat_51541": 0.7411561012268066, "aqua_rat_40065": 0.741405725479126, "aqua_rat_15511": 0.7416201829910278, "aqua_rat_65028": 0.7421275973320007, "aqua_rat_62094": 0.7426865100860596, "math_train_counting_and_probability_125": 0.7428877353668213, "aqua_rat_66794": 0.7435279488563538, "aqua_rat_65518": 0.7438798546791077, "aqua_rat_3903": 0.743921160697937, "aqua_rat_52776": 0.7440172433853149, "aqua_rat_82439": 0.7443094253540039, "aqua_rat_37634": 0.7444857954978943, "aqua_rat_20004": 0.7450193166732788, "aqua_rat_6686": 0.7457458972930908, "aqua_rat_22669": 0.746023416519165, "aqua_rat_7521": 0.7461325526237488, "aqua_rat_41017": 0.7462440729141235, "aqua_rat_41228": 0.7466130256652832, "aqua_rat_72312": 0.7479888200759888, "aqua_rat_58088": 0.7480186223983765, "aqua_rat_56383": 0.7484749555587769, "aqua_rat_8919": 0.7490307092666626, "aqua_rat_82478": 0.7494508624076843, "aqua_rat_32157": 0.7496362328529358, "aqua_rat_50073": 0.7497621774673462, "aqua_rat_56885": 0.7501353025436401, "aqua_rat_63725": 0.7502160668373108, "aqua_rat_42905": 0.7503474950790405, "aqua_rat_19152": 0.7510866522789001, "aqua_rat_26254": 0.7522128224372864, "aqua_rat_5662": 0.7530354857444763, "aqua_rat_74390": 0.7536428570747375, "aqua_rat_83986": 0.7540897130966187, "aqua_rat_65742": 0.7543433904647827, "aqua_rat_17717": 0.7551430463790894, "aqua_rat_53649": 0.7560233473777771, "aqua_rat_39271": 0.756172239780426, "aqua_rat_46009": 0.756335973739624, "aqua_rat_87746": 0.7569494247436523, "aqua_rat_45273": 0.757391095161438, "aqua_rat_31828": 0.7575326561927795, "aqua_rat_56614": 0.758109986782074, "math_train_counting_and_probability_5123": 0.7588449716567993, "aqua_rat_23636": 0.7594355940818787, "aqua_rat_11601": 0.7600472569465637, "aqua_rat_75262": 0.760232150554657, "aqua_rat_86710": 0.7611820101737976, "aqua_rat_27921": 0.7646414041519165, "aqua_rat_19090": 0.7661574482917786, "aqua_rat_34164": 0.7666540741920471, "aqua_rat_73303": 0.7670835256576538, "aqua_rat_40277": 0.7672398090362549, "aqua_rat_49569": 0.7683942914009094, "aqua_rat_24238": 0.769383430480957, "aqua_rat_76356": 0.7763511538505554, "aqua_rat_71213": 0.7773325443267822, "aqua_rat_37649": 0.7773596048355103, "aqua_rat_38285": 0.7775523662567139, "aqua_rat_29990": 0.7779722213745117, "aqua_rat_48010": 0.7827629446983337, "aqua_rat_48130": 0.7831767201423645, "aqua_rat_66391": 0.7845960259437561, "aqua_rat_57502": 0.7931535840034485}, "TheoremQA_jianyu_xu/pigeonhole_2.json": {"TheoremQA_jianyu_xu/pigeonhole_2.json": 0, "aqua_rat_3359": 0.6989787220954895, "camel_30739": 0.6990313529968262, "math_train_algebra_759": 0.6991153955459595, "math_train_geometry_441": 0.6991241574287415, "math_test_counting_and_probability_731": 0.6991331577301025, "math_train_geometry_583": 0.6991508603096008, "camel_9551": 0.699401319026947, "aqua_rat_42221": 0.6994685530662537, "math_train_geometry_6165": 0.6997038722038269, "camel_30194": 0.6998637914657593, "camel_30197": 0.6999356150627136, "aqua_rat_21756": 0.7000990509986877, "aqua_rat_28458": 0.7001094222068787, "aqua_rat_75437": 0.7001729607582092, "aqua_rat_46008": 0.7004961371421814, "aqua_rat_2381": 0.700598955154419, "math_train_geometry_6016": 0.7006627917289734, "aqua_rat_84517": 0.7017704844474792, "math_train_geometry_6086": 0.7017870545387268, "camel_30182": 0.7018443942070007, "camel_18069": 0.7021769881248474, "aqua_rat_68735": 0.7023797035217285, "math_train_prealgebra_280": 0.7027307152748108, "aqua_rat_84054": 0.702853798866272, "camel_28300": 0.7031502723693848, "math_test_geometry_99": 0.7038456201553345, "aqua_rat_13356": 0.7041933536529541, "aqua_rat_43563": 0.7055730819702148, "math_test_prealgebra_1736": 0.7059487700462341, "aqua_rat_84463": 0.7059718370437622, "camel_30290": 0.7061811685562134, "camel_28273": 0.706430196762085, "math_test_counting_and_probability_193": 0.7065051794052124, "aqua_rat_82465": 0.707275927066803, "camel_30767": 0.7074223160743713, "aqua_rat_13610": 0.7074804902076721, "camel_28302": 0.7075283527374268, "camel_30292": 0.7076178789138794, "aqua_rat_46758": 0.7079630494117737, "camel_30750": 0.7079851627349854, "camel_18333": 0.7080536484718323, "camel_30296": 0.7081114053726196, "camel_30183": 0.7082579135894775, "math_train_prealgebra_780": 0.7082948088645935, "math_train_prealgebra_777": 0.7083297967910767, "aqua_rat_417": 0.7083616256713867, "aqua_rat_65230": 0.7088450789451599, "aqua_rat_74503": 0.7088612914085388, "aqua_rat_36861": 0.7090911865234375, "camel_39223": 0.7091194987297058, "camel_30754": 0.7091308236122131, "math_test_counting_and_probability_969": 0.7091378569602966, "aqua_rat_60553": 0.7093929648399353, "math_test_prealgebra_1485": 0.7096365094184875, "aqua_rat_11272": 0.7097142934799194, "math_test_prealgebra_1534": 0.7101209163665771, "aqua_rat_86374": 0.7101596593856812, "math_train_prealgebra_161": 0.7103422284126282, "aqua_rat_22386": 0.7104196548461914, "aqua_rat_35842": 0.7107640504837036, "aqua_rat_54515": 0.7107747197151184, "camel_30318": 0.711148202419281, "camel_30217": 0.711239755153656, "camel_31985": 0.7113401889801025, "aqua_rat_24200": 0.7114426493644714, "aqua_rat_74936": 0.7114986181259155, "aqua_rat_26168": 0.7121289372444153, "camel_30260": 0.7125627994537354, "aqua_rat_19228": 0.7142294645309448, "aqua_rat_7563": 0.7144105434417725, "aqua_rat_35129": 0.7157530188560486, "aqua_rat_43659": 0.7158050537109375, "aqua_rat_84154": 0.7158353328704834, "aqua_rat_40381": 0.7160482406616211, "math_test_algebra_2": 0.7161262035369873, "math_test_geometry_507": 0.716312050819397, "aqua_rat_44300": 0.7163709998130798, "camel_30216": 0.7169517874717712, "aqua_rat_44987": 0.7171647548675537, "camel_28282": 0.7175465226173401, "aqua_rat_62436": 0.7183102965354919, "aqua_rat_38843": 0.7183862328529358, "aqua_rat_6164": 0.7183865904808044, "aqua_rat_86005": 0.7185032963752747, "aqua_rat_17762": 0.7188616991043091, "aqua_rat_37702": 0.7190245389938354, "aqua_rat_25895": 0.719049334526062, "math_test_counting_and_probability_1065": 0.7190560102462769, "camel_19751": 0.7196471691131592, "aqua_rat_5243": 0.7196972966194153, "aqua_rat_22251": 0.7197672724723816, "aqua_rat_84620": 0.7199535965919495, "camel_28249": 0.7200627326965332, "camel_28294": 0.7201697826385498, "aqua_rat_65765": 0.7201926708221436, "camel_28256": 0.7202244400978088, "aqua_rat_75829": 0.720278799533844, "camel_18377": 0.7212778329849243, "math_train_geometry_732": 0.7215943336486816, "math_test_counting_and_probability_339": 0.7222021818161011, "camel_18399": 0.7228965163230896, "math_train_algebra_2169": 0.7229533791542053, "camel_28260": 0.7231273055076599, "math_train_prealgebra_628": 0.7231994867324829, "aqua_rat_8991": 0.723397433757782, "aqua_rat_19011": 0.7236304879188538, "math_train_geometry_671": 0.7240650653839111, "aqua_rat_18244": 0.7240669131278992, "aqua_rat_67812": 0.7245009541511536, "aqua_rat_80509": 0.7249549031257629, "math_test_geometry_766": 0.7249594926834106, "aqua_rat_41800": 0.7252750396728516, "math_test_prealgebra_994": 0.7262744307518005, "aqua_rat_11574": 0.7263922095298767, "aqua_rat_10228": 0.7266495823860168, "aqua_rat_72434": 0.7273646593093872, "aqua_rat_55274": 0.7274069786071777, "camel_19722": 0.7274155616760254, "camel_30169": 0.7274754643440247, "camel_30304": 0.7274828553199768, "aqua_rat_10932": 0.7276170253753662, "math_train_geometry_215": 0.7276867032051086, "aqua_rat_60547": 0.7279655337333679, "aqua_rat_46063": 0.7281748652458191, "math_test_counting_and_probability_175": 0.7288633584976196, "math_test_geometry_90": 0.7289528250694275, "math_train_geometry_6173": 0.7290165424346924, "aqua_rat_78573": 0.7299754023551941, "aqua_rat_13829": 0.7307390570640564, "aqua_rat_55940": 0.7312602400779724, "aqua_rat_43043": 0.7314591407775879, "aqua_rat_83185": 0.7318637371063232, "math_test_prealgebra_1564": 0.7322275638580322, "aqua_rat_33903": 0.7326544523239136, "aqua_rat_68089": 0.7328614592552185, "camel_30259": 0.7329134941101074, "aqua_rat_24670": 0.7334885001182556, "aqua_rat_84046": 0.7340652942657471, "aqua_rat_85946": 0.7341222763061523, "aqua_rat_85048": 0.7345288991928101, "aqua_rat_75858": 0.7345708012580872, "aqua_rat_56566": 0.7345998287200928, "aqua_rat_21116": 0.7346466183662415, "math_train_prealgebra_1184": 0.735409140586853, "camel_19716": 0.7354791164398193, "aqua_rat_25415": 0.735644519329071, "aqua_rat_7497": 0.7360774874687195, "aqua_rat_17930": 0.7361095547676086, "aqua_rat_5254": 0.7362878322601318, "aqua_rat_36704": 0.7363088726997375, "aqua_rat_71780": 0.7363690137863159, "aqua_rat_11567": 0.7365166544914246, "aqua_rat_72603": 0.736608624458313, "camel_30242": 0.7376055121421814, "aqua_rat_32592": 0.7377741932868958, "math_test_prealgebra_957": 0.7378575205802917, "camel_19743": 0.7390770316123962, "aqua_rat_26062": 0.7395722270011902, "aqua_rat_9508": 0.7405990958213806, "aqua_rat_9335": 0.741714596748352, "aqua_rat_47046": 0.7435027956962585, "camel_30224": 0.743816077709198, "aqua_rat_17107": 0.74383544921875, "camel_28310": 0.7441033124923706, "aqua_rat_57399": 0.7442623376846313, "math_train_geometry_491": 0.7453362345695496, "math_train_prealgebra_676": 0.7453485727310181, "camel_19685": 0.7453678846359253, "camel_38190": 0.7460745573043823, "camel_42542": 0.7464560866355896, "aqua_rat_66974": 0.7480645775794983, "aqua_rat_25540": 0.7489179968833923, "math_train_geometry_355": 0.7489199042320251, "aqua_rat_16864": 0.7505621910095215, "aqua_rat_87175": 0.7522004246711731, "aqua_rat_12007": 0.7529362440109253, "math_train_counting_and_probability_787": 0.753229558467865, "aqua_rat_36627": 0.7540205121040344, "aqua_rat_14389": 0.7547829151153564, "aqua_rat_81227": 0.755677342414856, "aqua_rat_23501": 0.7557759284973145, "aqua_rat_59875": 0.7585236430168152, "aqua_rat_24561": 0.7590921521186829, "aqua_rat_888": 0.7592059373855591, "aqua_rat_38400": 0.7592527270317078, "aqua_rat_45720": 0.7596839666366577, "math_train_geometry_937": 0.7597336769104004, "aqua_rat_29707": 0.7599334716796875, "aqua_rat_69644": 0.7607560753822327, "camel_18380": 0.7614313364028931, "math_train_geometry_6226": 0.7616117596626282, "camel_28290": 0.7624738812446594, "aqua_rat_29007": 0.7666754722595215, "math_test_prealgebra_1899": 0.7675386667251587, "aqua_rat_16643": 0.7745980024337769, "aqua_rat_17380": 0.7746590375900269, "aqua_rat_64709": 0.777396559715271, "aqua_rat_10325": 0.7809953093528748, "aqua_rat_45831": 0.7927632927894592}, "TheoremQA_maxku/cv-imageprocessing6-histogram.json": {"TheoremQA_maxku/cv-imageprocessing6-histogram.json": 0, "gsm_rft_24072": 0.6786129474639893, "gsm_train_14570": 0.6786129474639893, "aqua_rat_39605": 0.6787441968917847, "gsm_train_21219": 0.6788251996040344, "gsm_rft_29448": 0.6789373755455017, "camel_8818": 0.6789484024047852, "gsm_rft_26894": 0.678998589515686, "gsm_rft_5639": 0.6790553331375122, "camel_25976": 0.679063081741333, "gsm_rft_7102": 0.6790695190429688, "aqua_rat_6979": 0.6790850758552551, "aqua_rat_84902": 0.6791850328445435, "gsm_rft_2892": 0.6792760491371155, "gsm_rft_13725": 0.679315447807312, "aqua_rat_51191": 0.6793296337127686, "gsm_rft_2599": 0.6793306469917297, "camel_37112": 0.6793349385261536, "aqua_rat_71099": 0.679462730884552, "aqua_rat_77962": 0.6794847249984741, "gsm_rft_1067": 0.6795148253440857, "aqua_rat_30525": 0.6795604228973389, "aqua_rat_16656": 0.6795623898506165, "camel_9274": 0.6795886754989624, "aqua_rat_1283": 0.6796292066574097, "camel_20866": 0.6796870827674866, "camel_9126": 0.6797521710395813, "aqua_rat_25201": 0.6797769665718079, "aqua_rat_88002": 0.6798266768455505, "aqua_rat_5269": 0.6798574328422546, "camel_36625": 0.6800117492675781, "aqua_rat_54784": 0.680190920829773, "gsm_rft_24906": 0.6802453398704529, "aqua_rat_51043": 0.6803404688835144, "aqua_rat_28407": 0.6804860234260559, "gsm_rft_35665": 0.6805959939956665, "aqua_rat_17717": 0.6806660294532776, "aqua_rat_75099": 0.6806790828704834, "aqua_rat_8423": 0.680698037147522, "aqua_rat_43002": 0.6810349822044373, "gsm_train_29739": 0.6811143755912781, "aqua_rat_60270": 0.6814298629760742, "aqua_rat_67407": 0.681443989276886, "aqua_rat_52229": 0.681570827960968, "gsm_rft_29559": 0.6816790103912354, "gsm_rft_9540": 0.6817445158958435, "camel_9915": 0.6817519068717957, "gsm_rft_9020": 0.6819567680358887, "aqua_rat_59957": 0.6820696592330933, "aqua_rat_62287": 0.6821562051773071, "gsm_rft_30102": 0.682176411151886, "aqua_rat_87757": 0.682453989982605, "aqua_rat_75297": 0.6825494170188904, "gsm_train_34957": 0.6826596856117249, "aqua_rat_59211": 0.6826834678649902, "aqua_rat_72973": 0.6827087998390198, "camel_25785": 0.682746946811676, "gsm_rft_11605": 0.6827694773674011, "gsm_rft_32658": 0.6827706694602966, "gsm_rft_29892": 0.6827706694602966, "camel_37817": 0.6831597089767456, "camel_8861": 0.6832984089851379, "aqua_rat_5931": 0.6833944320678711, "aqua_rat_70673": 0.6834256052970886, "camel_24166": 0.683722198009491, "aqua_rat_39463": 0.6838506460189819, "aqua_rat_54401": 0.683861494064331, "gsm_rft_32211": 0.6840399503707886, "camel_25578": 0.6841738820075989, "gsm_rft_20407": 0.6841893792152405, "aqua_rat_24368": 0.6842952370643616, "camel_25590": 0.684554398059845, "aqua_rat_40080": 0.6849250793457031, "gsm_rft_26802": 0.6850976347923279, "aqua_rat_8304": 0.6851117014884949, "aqua_rat_51362": 0.6853197813034058, "camel_38521": 0.6853492856025696, "aqua_rat_26476": 0.6853851675987244, "camel_9911": 0.6854596734046936, "aqua_rat_34523": 0.6855210661888123, "camel_9875": 0.6859224438667297, "aqua_rat_88079": 0.6860828995704651, "gsm_rft_12684": 0.6861300468444824, "aqua_rat_45780": 0.6863524913787842, "aqua_rat_84671": 0.686390221118927, "aqua_rat_79682": 0.6866507530212402, "gsm_rft_24342": 0.6867712140083313, "aqua_rat_47454": 0.686896026134491, "aqua_rat_2935": 0.6874085664749146, "camel_25559": 0.6874290704727173, "aqua_rat_20543": 0.6875489950180054, "camel_37822": 0.6875884532928467, "gsm_rft_16086": 0.6876503825187683, "gsm_rft_35439": 0.6877793073654175, "camel_25568": 0.6877833008766174, "aqua_rat_54301": 0.6878225803375244, "aqua_rat_40690": 0.6879091858863831, "camel_9162": 0.687985897064209, "camel_9894": 0.6880786418914795, "gsm_rft_29313": 0.6882909536361694, "gsm_rft_4204": 0.6883260607719421, "gsm_rft_35193": 0.6883888244628906, "aqua_rat_85376": 0.6886582374572754, "aqua_rat_69951": 0.6887544989585876, "camel_25581": 0.6888377666473389, "aqua_rat_5662": 0.6888403296470642, "aqua_rat_24892": 0.688850998878479, "aqua_rat_45111": 0.688930332660675, "aqua_rat_61417": 0.689004123210907, "aqua_rat_4547": 0.6890990138053894, "aqua_rat_63120": 0.6891509294509888, "aqua_rat_60798": 0.6891509890556335, "aqua_rat_87674": 0.6892545819282532, "camel_8855": 0.6892732977867126, "camel_9152": 0.6893113255500793, "aqua_rat_33139": 0.6896748542785645, "aqua_rat_76389": 0.6897932887077332, "aqua_rat_42432": 0.6900179386138916, "aqua_rat_82838": 0.6901305317878723, "aqua_rat_63590": 0.6902996897697449, "aqua_rat_80630": 0.6903460621833801, "aqua_rat_18682": 0.6904484033584595, "aqua_rat_50918": 0.6907634735107422, "aqua_rat_8518": 0.6909189224243164, "aqua_rat_62074": 0.6910064220428467, "aqua_rat_79065": 0.6910569667816162, "aqua_rat_10491": 0.6913403272628784, "gsm_train_35230": 0.6915097236633301, "gsm_rft_6011": 0.6915097236633301, "gsm_train_13639": 0.6915585994720459, "gsm_rft_15724": 0.6915585994720459, "gsm_rft_20547": 0.6922642588615417, "aqua_rat_46784": 0.692840576171875, "camel_9198": 0.6931828260421753, "aqua_rat_73720": 0.6932491064071655, "camel_20877": 0.6933310627937317, "gsm_rft_14522": 0.693378210067749, "aqua_rat_39124": 0.6935949325561523, "camel_25575": 0.6940550804138184, "gsm_rft_15553": 0.6941434144973755, "gsm_rft_21722": 0.6941462159156799, "camel_9186": 0.6941755414009094, "aqua_rat_19930": 0.6941801905632019, "aqua_rat_16321": 0.694196879863739, "aqua_rat_64013": 0.6944049000740051, "aqua_rat_7528": 0.6945299506187439, "camel_25549": 0.6946918368339539, "aqua_rat_73869": 0.6950742602348328, "aqua_rat_41252": 0.6951297521591187, "camel_9138": 0.6952025890350342, "aqua_rat_53198": 0.6954935193061829, "aqua_rat_6259": 0.6955235004425049, "aqua_rat_51046": 0.6956972479820251, "aqua_rat_86082": 0.6962614059448242, "aqua_rat_57690": 0.6966411471366882, "aqua_rat_38759": 0.6967107653617859, "gsm_rft_23057": 0.6969282031059265, "aqua_rat_4046": 0.697075605392456, "gsm_rft_23297": 0.6971392035484314, "camel_8873": 0.6977212429046631, "aqua_rat_27645": 0.6982712149620056, "aqua_rat_58938": 0.6983370184898376, "aqua_rat_54275": 0.6989025473594666, "aqua_rat_62272": 0.6989719867706299, "camel_9170": 0.6991205215454102, "aqua_rat_12478": 0.6991546750068665, "aqua_rat_20866": 0.6994118690490723, "aqua_rat_51590": 0.699630618095398, "aqua_rat_88299": 0.6997469663619995, "aqua_rat_4058": 0.7000030279159546, "aqua_rat_14601": 0.7003812789916992, "gsm_train_8850": 0.7004846334457397, "gsm_rft_248": 0.7004846334457397, "gsm_rft_9522": 0.701109766960144, "aqua_rat_42840": 0.7015655040740967, "aqua_rat_38732": 0.7017450928688049, "aqua_rat_56264": 0.7019487619400024, "camel_8830": 0.7022600173950195, "gsm_rft_14968": 0.7025445699691772, "gsm_train_13395": 0.7025445699691772, "gsm_rft_30865": 0.7025821208953857, "camel_8719": 0.7026448845863342, "aqua_rat_59580": 0.7031619548797607, "gsm_rft_19047": 0.7032505869865417, "gsm_train_29804": 0.7032505869865417, "aqua_rat_5139": 0.7035126090049744, "gsm_rft_30185": 0.70357745885849, "gsm_train_17713": 0.7036007642745972, "gsm_rft_34828": 0.7067025303840637, "camel_9163": 0.706906259059906, "gsm_rft_15172": 0.7081730365753174, "gsm_rft_32883": 0.7084493637084961, "gsm_rft_6826": 0.7098320126533508, "aqua_rat_72504": 0.7114949226379395, "camel_8837": 0.7120519280433655, "camel_9122": 0.7235057353973389, "camel_9140": 0.7274558544158936, "camel_9166": 0.7309741973876953, "camel_37839": 0.7478686571121216, "camel_9127": 0.7527485489845276}, "TheoremQA_elainewan/math_algebra_1.json": {"math_train_algebra_2247": 0, "math_train_algebra_25200": 0, "math_test_prealgebra_1910": 0, "math_train_algebra_768": 0, "math_train_algebra_1005": 0, "gsm_rft_31977": 0.7665594220161438, "aqua_rat_86183": 0.7667268514633179, "aqua_rat_40191": 0.7668246030807495, "aqua_rat_16375": 0.7668267488479614, "aqua_rat_37152": 0.766889214515686, "aqua_rat_74421": 0.7669060230255127, "camel_25795": 0.767057478427887, "aqua_rat_31031": 0.7671388983726501, "aqua_rat_12919": 0.7671558856964111, "aqua_rat_14288": 0.7671633362770081, "camel_40598": 0.7671657800674438, "aqua_rat_42593": 0.7672032117843628, "aqua_rat_12718": 0.7672191858291626, "aqua_rat_43011": 0.7673279047012329, "aqua_rat_75561": 0.7673497796058655, "aqua_rat_40084": 0.7673608660697937, "aqua_rat_20803": 0.767392098903656, "gsm_rft_7819": 0.7675012946128845, "camel_25800": 0.7675439119338989, "camel_25834": 0.7675676941871643, "aqua_rat_45016": 0.767586350440979, "aqua_rat_28481": 0.7676085233688354, "aqua_rat_47976": 0.7676897644996643, "aqua_rat_16147": 0.767726719379425, "aqua_rat_20897": 0.7677520513534546, "aqua_rat_47159": 0.7677643895149231, "aqua_rat_26133": 0.7679399847984314, "aqua_rat_63719": 0.7679605484008789, "aqua_rat_79214": 0.7679616808891296, "camel_25796": 0.7679747343063354, "aqua_rat_67913": 0.7680198550224304, "aqua_rat_27122": 0.7680482864379883, "aqua_rat_46375": 0.7681108117103577, "aqua_rat_40983": 0.7681965231895447, "aqua_rat_36193": 0.7682122588157654, "aqua_rat_11684": 0.7682346105575562, "aqua_rat_58718": 0.7684153914451599, "aqua_rat_59985": 0.7684702277183533, "aqua_rat_7381": 0.7685096859931946, "aqua_rat_65235": 0.768548309803009, "aqua_rat_86435": 0.7685657143592834, "aqua_rat_73871": 0.7686424851417542, "camel_25788": 0.7687170505523682, "gsm_rft_13918": 0.7689350843429565, "aqua_rat_20296": 0.7689570784568787, "aqua_rat_63304": 0.7689902782440186, "aqua_rat_16095": 0.7692073583602905, "aqua_rat_23497": 0.7692103981971741, "aqua_rat_73355": 0.7693194150924683, "aqua_rat_51240": 0.7694804668426514, "gsm_rft_25700": 0.7695974707603455, "gsm_rft_2632": 0.7696022391319275, "gsm_train_14640": 0.7696022391319275, "gsm_train_10158": 0.7696242928504944, "camel_25831": 0.7696488499641418, "aqua_rat_35767": 0.7696684002876282, "aqua_rat_11659": 0.7697744965553284, "aqua_rat_16633": 0.7698773741722107, "aqua_rat_23710": 0.7699455618858337, "camel_25791": 0.7700109481811523, "gsm_rft_6027": 0.7700920104980469, "gsm_train_35156": 0.7701796889305115, "aqua_rat_45805": 0.7703560590744019, "aqua_rat_14542": 0.7703595161437988, "aqua_rat_8458": 0.7704392075538635, "gsm_rft_24321": 0.770487904548645, "aqua_rat_63218": 0.7706577777862549, "aqua_rat_66352": 0.7708328366279602, "aqua_rat_33678": 0.7708448767662048, "gsm_rft_21054": 0.7708866596221924, "aqua_rat_34563": 0.7710336446762085, "camel_25827": 0.7710543870925903, "aqua_rat_32382": 0.7711073756217957, "aqua_rat_30065": 0.7713218331336975, "gsm_rft_27466": 0.7714549899101257, "aqua_rat_22933": 0.7717549800872803, "gsm_rft_10560": 0.7719284892082214, "aqua_rat_26263": 0.7719342708587646, "aqua_rat_33811": 0.7720974683761597, "camel_25790": 0.7721251249313354, "camel_25786": 0.7722848653793335, "camel_25794": 0.7723212838172913, "gsm_rft_22114": 0.7723830342292786, "aqua_rat_30292": 0.7724135518074036, "aqua_rat_30147": 0.7725164890289307, "aqua_rat_15840": 0.7728286981582642, "aqua_rat_83487": 0.772847056388855, "aqua_rat_70349": 0.7728819251060486, "gsm_rft_24163": 0.7729088664054871, "aqua_rat_43828": 0.7729688286781311, "aqua_rat_68355": 0.7730413675308228, "camel_25832": 0.7730841636657715, "aqua_rat_9524": 0.7732186913490295, "aqua_rat_21148": 0.7732440233230591, "camel_25775": 0.7732490301132202, "gsm_rft_9243": 0.7733177542686462, "aqua_rat_1214": 0.7735888361930847, "aqua_rat_45600": 0.7741038799285889, "gsm_rft_25042": 0.7742631435394287, "aqua_rat_45146": 0.774379312992096, "aqua_rat_46967": 0.7744247317314148, "gsm_rft_28081": 0.7744455337524414, "aqua_rat_39261": 0.7746396660804749, "aqua_rat_63142": 0.7747260332107544, "gsm_rft_24676": 0.7747679948806763, "aqua_rat_10477": 0.7748188972473145, "aqua_rat_30929": 0.775005578994751, "gsm_rft_23270": 0.7750298976898193, "aqua_rat_41110": 0.7753299474716187, "aqua_rat_46957": 0.775400698184967, "aqua_rat_15690": 0.7754279971122742, "camel_25828": 0.775520920753479, "camel_25979": 0.7755797505378723, "aqua_rat_35764": 0.7758290767669678, "camel_25818": 0.7758609652519226, "gsm_rft_8170": 0.7760698199272156, "aqua_rat_44570": 0.7761924862861633, "aqua_rat_13702": 0.7764109373092651, "gsm_rft_11348": 0.7764586210250854, "gsm_rft_23170": 0.776739776134491, "aqua_rat_78979": 0.7768034338951111, "aqua_rat_37040": 0.776846170425415, "gsm_rft_33714": 0.7768776416778564, "gsm_train_15065": 0.7769275307655334, "gsm_rft_35331": 0.776996910572052, "gsm_rft_11207": 0.7770481705665588, "aqua_rat_7271": 0.7771551609039307, "camel_25782": 0.7771944999694824, "aqua_rat_62896": 0.7772366404533386, "aqua_rat_50829": 0.7772641181945801, "aqua_rat_74163": 0.7774766087532043, "aqua_rat_71341": 0.7776851058006287, "aqua_rat_67253": 0.7777346968650818, "aqua_rat_39021": 0.7779713869094849, "aqua_rat_29692": 0.7780713438987732, "aqua_rat_42213": 0.7782313227653503, "gsm_rft_1804": 0.7786049842834473, "aqua_rat_4305": 0.7786898612976074, "aqua_rat_16730": 0.7787508964538574, "gsm_train_1401": 0.778919517993927, "gsm_rft_3198": 0.778919517993927, "gsm_rft_4688": 0.778919517993927, "camel_36747": 0.7789803147315979, "aqua_rat_64661": 0.7798523306846619, "aqua_rat_66629": 0.7801645398139954, "gsm_train_3338": 0.7802197933197021, "camel_25799": 0.780227541923523, "camel_25777": 0.7802907824516296, "aqua_rat_19094": 0.7804558277130127, "gsm_rft_33497": 0.7806932926177979, "aqua_rat_17648": 0.7807694673538208, "aqua_rat_13983": 0.7809146046638489, "aqua_rat_81928": 0.7810283303260803, "aqua_rat_1161": 0.7812849283218384, "aqua_rat_30263": 0.7813186645507812, "gsm_rft_13016": 0.7814056277275085, "gsm_train_17710": 0.7814056277275085, "camel_25820": 0.7816577553749084, "aqua_rat_6489": 0.781775176525116, "gsm_rft_20693": 0.7820733189582825, "aqua_rat_6033": 0.7821680307388306, "camel_25785": 0.7821780443191528, "aqua_rat_63175": 0.7825729250907898, "gsm_rft_15751": 0.7829452157020569, "aqua_rat_69430": 0.7829710841178894, "aqua_rat_25641": 0.7834761142730713, "aqua_rat_13276": 0.7835152745246887, "camel_25789": 0.7838459014892578, "aqua_rat_39160": 0.7838740348815918, "aqua_rat_21864": 0.7841702699661255, "camel_25766": 0.7849551439285278, "aqua_rat_848": 0.7854923605918884, "camel_25769": 0.7858500480651855, "camel_25802": 0.7859029769897461, "camel_25773": 0.7868772149085999, "aqua_rat_22606": 0.7881844639778137, "camel_25646": 0.7885156869888306, "aqua_rat_30602": 0.7887546420097351, "aqua_rat_84741": 0.7890035510063171, "aqua_rat_4406": 0.789889395236969, "aqua_rat_8086": 0.790080726146698, "aqua_rat_30576": 0.79045170545578, "aqua_rat_64307": 0.7905285954475403, "camel_37930": 0.7906278967857361, "camel_25764": 0.7931174039840698, "camel_25797": 0.7938422560691833, "camel_25771": 0.7944498658180237, "aqua_rat_43052": 0.7945153117179871, "camel_25829": 0.7965614199638367, "camel_25809": 0.7970024347305298, "camel_25792": 0.8067911863327026, "camel_25783": 0.80938321352005, "camel_25817": 0.8114235997200012, "camel_25821": 0.8179198503494263, "camel_25793": 0.8183879256248474}, "TheoremQA_xinyi/rotation.json": {"TheoremQA_xinyi/rotation.json": 0, "aqua_rat_83913": 0.7236790060997009, "aqua_rat_60136": 0.7238896489143372, "aqua_rat_40672": 0.7240682244300842, "aqua_rat_7620": 0.7243751287460327, "aqua_rat_28149": 0.7246282696723938, "aqua_rat_61955": 0.724632203578949, "aqua_rat_20126": 0.7246659994125366, "aqua_rat_79757": 0.7247351408004761, "aqua_rat_2726": 0.7247553467750549, "aqua_rat_65887": 0.7247746586799622, "aqua_rat_72097": 0.7251129746437073, "aqua_rat_70728": 0.7251975536346436, "aqua_rat_53176": 0.7252907752990723, "aqua_rat_42327": 0.7255522608757019, "aqua_rat_62762": 0.7256875038146973, "aqua_rat_50972": 0.7259929776191711, "aqua_rat_64279": 0.726123034954071, "aqua_rat_75694": 0.7263776063919067, "aqua_rat_53702": 0.7266702055931091, "aqua_rat_40964": 0.7266875505447388, "aqua_rat_29570": 0.7267383933067322, "aqua_rat_74287": 0.7275669574737549, "aqua_rat_8953": 0.7276026606559753, "aqua_rat_34470": 0.7276684641838074, "aqua_rat_37025": 0.7277881503105164, "aqua_rat_66742": 0.7278013229370117, "aqua_rat_59674": 0.7282907962799072, "aqua_rat_7066": 0.7284739017486572, "aqua_rat_40694": 0.72865891456604, "aqua_rat_80828": 0.728792667388916, "aqua_rat_50800": 0.7304425239562988, "aqua_rat_50937": 0.7308372259140015, "aqua_rat_43469": 0.7312263250350952, "aqua_rat_42233": 0.731489360332489, "aqua_rat_51549": 0.7316287159919739, "aqua_rat_1270": 0.7318047285079956, "aqua_rat_34100": 0.7320839762687683, "aqua_rat_38590": 0.7323054075241089, "camel_5358": 0.7326149940490723, "aqua_rat_28240": 0.7327680587768555, "aqua_rat_55212": 0.7330247163772583, "aqua_rat_55874": 0.7331368923187256, "aqua_rat_75907": 0.7331500053405762, "aqua_rat_72665": 0.7337442636489868, "aqua_rat_78529": 0.7341009378433228, "aqua_rat_87034": 0.7341628074645996, "aqua_rat_85655": 0.7349727153778076, "aqua_rat_76350": 0.7351753115653992, "aqua_rat_64811": 0.7353391647338867, "aqua_rat_43412": 0.7354937791824341, "aqua_rat_77772": 0.7356336712837219, "aqua_rat_51123": 0.7358794808387756, "aqua_rat_65249": 0.7358893752098083, "aqua_rat_33878": 0.7363558411598206, "aqua_rat_41201": 0.7363967895507812, "aqua_rat_44946": 0.7366307973861694, "aqua_rat_12166": 0.7367674112319946, "camel_5344": 0.737570583820343, "aqua_rat_8254": 0.7378383874893188, "aqua_rat_59830": 0.7390373945236206, "aqua_rat_72875": 0.7393301129341125, "aqua_rat_7567": 0.7398456931114197, "aqua_rat_56401": 0.7402310967445374, "aqua_rat_69804": 0.7405074238777161, "aqua_rat_3802": 0.7406826615333557, "aqua_rat_343": 0.7407419085502625, "aqua_rat_18920": 0.7410460710525513, "aqua_rat_47661": 0.7412188053131104, "aqua_rat_241": 0.7413492202758789, "aqua_rat_56518": 0.7415494322776794, "aqua_rat_32296": 0.7418124675750732, "aqua_rat_65833": 0.7420085668563843, "aqua_rat_46912": 0.7421368360519409, "aqua_rat_46923": 0.7431699633598328, "aqua_rat_44993": 0.744141161441803, "aqua_rat_72820": 0.7441723346710205, "aqua_rat_84016": 0.7452399134635925, "aqua_rat_56684": 0.7457985281944275, "aqua_rat_19837": 0.7459800839424133, "aqua_rat_19041": 0.7463005781173706, "aqua_rat_51535": 0.7465110421180725, "aqua_rat_74017": 0.7466274499893188, "aqua_rat_71238": 0.7468056082725525, "aqua_rat_43860": 0.7475007176399231, "aqua_rat_71550": 0.7478655576705933, "math_test_geometry_602": 0.7479778528213501, "aqua_rat_79843": 0.7481186389923096, "camel_19715": 0.7488304972648621, "aqua_rat_16963": 0.7490384578704834, "aqua_rat_77927": 0.7492877840995789, "aqua_rat_75920": 0.7496700286865234, "aqua_rat_25430": 0.7508705854415894, "aqua_rat_81253": 0.7512845396995544, "aqua_rat_77944": 0.7525913119316101, "aqua_rat_17586": 0.7531200051307678, "aqua_rat_73912": 0.7532646059989929, "aqua_rat_50378": 0.7540047764778137, "aqua_rat_10341": 0.7540386915206909, "aqua_rat_68269": 0.7541912198066711, "aqua_rat_62625": 0.7548844814300537, "aqua_rat_17232": 0.7549967169761658, "aqua_rat_1474": 0.7556765079498291, "aqua_rat_32921": 0.7557170391082764, "aqua_rat_31326": 0.7558505535125732, "aqua_rat_8248": 0.7562534213066101, "math_train_algebra_2034": 0.7563261985778809, "aqua_rat_67556": 0.7563756108283997, "aqua_rat_36048": 0.7565709352493286, "aqua_rat_71793": 0.756578803062439, "aqua_rat_14801": 0.7566059231758118, "TheoremQA_panlu/uniform_circular_motion2.json": 0.7566587328910828, "aqua_rat_43143": 0.7570427060127258, "aqua_rat_8986": 0.7572764754295349, "aqua_rat_73548": 0.7576135993003845, "aqua_rat_2048": 0.7576369643211365, "math_test_algebra_1169": 0.7576910853385925, "aqua_rat_61468": 0.7579972743988037, "aqua_rat_17161": 0.758046567440033, "aqua_rat_48820": 0.758061408996582, "aqua_rat_33605": 0.7583833336830139, "aqua_rat_47412": 0.7584665417671204, "aqua_rat_40488": 0.7585468292236328, "aqua_rat_26876": 0.7589154243469238, "aqua_rat_20229": 0.7592381238937378, "aqua_rat_60956": 0.7603565454483032, "aqua_rat_30978": 0.7611989378929138, "aqua_rat_64696": 0.7612573504447937, "aqua_rat_23236": 0.7614326477050781, "aqua_rat_2921": 0.7616701126098633, "aqua_rat_49190": 0.7618646025657654, "aqua_rat_30563": 0.7619541883468628, "aqua_rat_34381": 0.7621675133705139, "aqua_rat_33984": 0.7623319625854492, "aqua_rat_22863": 0.7633711695671082, "aqua_rat_61106": 0.7635868191719055, "aqua_rat_59863": 0.7639307379722595, "aqua_rat_59708": 0.7641100883483887, "aqua_rat_52791": 0.7647837996482849, "math_test_prealgebra_1007": 0.7652137279510498, "aqua_rat_85184": 0.7661958336830139, "aqua_rat_75769": 0.7670127153396606, "aqua_rat_58488": 0.7674133777618408, "aqua_rat_54163": 0.7678701877593994, "aqua_rat_7934": 0.7679840922355652, "aqua_rat_79046": 0.7691363096237183, "TheoremQA_xinyi/newtons_laws_1.json": 0.7693676352500916, "aqua_rat_85602": 0.7695207595825195, "aqua_rat_36499": 0.7699616551399231, "aqua_rat_28317": 0.7706297636032104, "math_train_geometry_613": 0.7708773612976074, "aqua_rat_18227": 0.771550714969635, "aqua_rat_43663": 0.7719306945800781, "aqua_rat_47721": 0.7722658514976501, "aqua_rat_67030": 0.7730006575584412, "camel_5284": 0.7731718420982361, "aqua_rat_53605": 0.7733674049377441, "aqua_rat_75408": 0.773887038230896, "aqua_rat_12137": 0.7740842700004578, "aqua_rat_63049": 0.774770200252533, "aqua_rat_71139": 0.7755478620529175, "aqua_rat_86326": 0.7758076190948486, "aqua_rat_87142": 0.7763408422470093, "aqua_rat_43369": 0.7766270637512207, "aqua_rat_79407": 0.7769849896430969, "aqua_rat_65204": 0.7778966426849365, "aqua_rat_84913": 0.7789238691329956, "aqua_rat_15993": 0.7789634466171265, "aqua_rat_18077": 0.7791488766670227, "aqua_rat_43997": 0.7806631326675415, "aqua_rat_52253": 0.780964732170105, "aqua_rat_57087": 0.781074583530426, "aqua_rat_55349": 0.7814760208129883, "aqua_rat_6798": 0.7815046906471252, "aqua_rat_16632": 0.7816877365112305, "aqua_rat_2038": 0.7819485664367676, "aqua_rat_25695": 0.7822978496551514, "aqua_rat_46742": 0.7823597192764282, "aqua_rat_70325": 0.7826949954032898, "aqua_rat_57227": 0.7832067012786865, "aqua_rat_69552": 0.7836272716522217, "aqua_rat_13503": 0.7843077182769775, "math_test_prealgebra_1423": 0.787138819694519, "aqua_rat_60106": 0.7950155138969421, "aqua_rat_5744": 0.8050748705863953, "aqua_rat_84659": 0.8051992654800415, "aqua_rat_11110": 0.8060232400894165, "camel_5004": 0.8068233728408813, "aqua_rat_83499": 0.8092291951179504, "aqua_rat_23015": 0.811675488948822, "aqua_rat_75022": 0.8124257922172546, "aqua_rat_81657": 0.8124534487724304, "aqua_rat_66318": 0.8128283619880676, "aqua_rat_54538": 0.8132598400115967, "aqua_rat_86618": 0.8137142658233643, "aqua_rat_6305": 0.8144358396530151, "aqua_rat_34465": 0.8150511384010315, "aqua_rat_8349": 0.8152427077293396, "aqua_rat_4364": 0.815740704536438, "aqua_rat_18441": 0.819460928440094}, "TheoremQA_wenhuchen/eigen_value1.json": {"camel_14535": 0, "camel_14517": 0, "camel_14524": 0, "camel_14522": 0, "camel_14485": 0, "camel_14484": 0, "camel_14557": 0, "camel_14526": 0, "camel_14550": 0, "camel_15329": 0, "camel_14519": 0, "camel_14506": 0, "camel_14518": 0, "camel_14501": 0, "camel_14558": 0, "camel_14545": 0, "camel_14551": 0, "camel_14498": 0, "camel_14416": 0, "camel_14499": 0, "camel_14513": 0, "camel_14492": 0, "camel_15307": 0, "camel_14505": 0, "camel_15748": 0, "camel_14490": 0, "camel_14553": 0, "camel_14512": 0, "camel_14531": 0, "camel_14554": 0, "camel_14509": 0, "camel_14421": 0, "camel_14537": 0, "camel_14420": 0, "camel_14542": 0, "camel_14415": 0, "camel_14507": 0, "camel_14552": 0, "camel_14486": 0, "camel_14427": 0, "camel_14476": 0, "camel_14525": 0, "camel_14448": 0, "camel_14539": 0, "camel_14534": 0, "camel_14462": 0, "camel_14489": 0, "camel_14540": 0, "camel_14463": 0, "camel_14521": 0, "camel_14516": 0, "camel_14477": 0, "camel_14494": 0, "camel_14527": 0, "camel_14547": 0, "camel_14543": 0, "camel_14488": 0, "camel_15679": 0, "camel_14468": 0, "camel_14453": 0, "TheoremQA_wenhuchen/eigen_value1.json": 0, "camel_14508": 0, "camel_14402": 0, "camel_14473": 0, "camel_14549": 0, "camel_14423": 0, "camel_14472": 0, "camel_14413": 0, "camel_14483": 0, "camel_14403": 0, "camel_14470": 0, "camel_14479": 0, "camel_14533": 0, "camel_14417": 0, "camel_14410": 0, "camel_14465": 0, "camel_14425": 0, "camel_14464": 0, "camel_14424": 0, "camel_14536": 0, "camel_14401": 0, "camel_14504": 0, "camel_14467": 0, "camel_14520": 0, "camel_14409": 0, "camel_14478": 0, "camel_14447": 0, "camel_14433": 0, "camel_14449": 0, "camel_14469": 0, "camel_14487": 0, "camel_14443": 0, "camel_14404": 0, "camel_14435": 0, "camel_14460": 0, "camel_14440": 0, "camel_14457": 0, "camel_14437": 0, "camel_14454": 0, "camel_14455": 0, "camel_14556": 0, "camel_14428": 0, "camel_14407": 0, "camel_14451": 0, "camel_14438": 0, "camel_14439": 0, "camel_14445": 0, "camel_14436": 0, "camel_14515": 0, "camel_14422": 0, "camel_14471": 0, "camel_14405": 0, "camel_14523": 0, "camel_14412": 0, "camel_14419": 0, "camel_14538": 0, "camel_14541": 0, "camel_14441": 0, "camel_14456": 0, "camel_14429": 0, "camel_14434": 0, "camel_14408": 0, "camel_14432": 0, "camel_14426": 0, "camel_14559": 0, "camel_14510": 0, "camel_14414": 0, "camel_14406": 0, "camel_14461": 0, "camel_14458": 0, "camel_14532": 0, "camel_14482": 0, "camel_14442": 0, "camel_14529": 0, "camel_14474": 0, "camel_14431": 0, "camel_14493": 0, "camel_14546": 0, "camel_14475": 0, "camel_14500": 0, "camel_14430": 0, "camel_14400": 0, "camel_14530": 0, "camel_14497": 0, "camel_14446": 0, "camel_14503": 0, "camel_14548": 0, "camel_14452": 0, "camel_14544": 0, "camel_14459": 0, "camel_14418": 0, "camel_14466": 0, "camel_14411": 0, "camel_14450": 0, "camel_14444": 0, "TheoremQA_elainewan/math_algebra_4.json": 0.783272922039032, "camel_40114": 0.7845654487609863, "camel_40110": 0.7845702171325684, "camel_40137": 0.7851756811141968, "camel_40100": 0.7852442264556885, "camel_40152": 0.7855231165885925, "camel_29615": 0.7855416536331177, "camel_9333": 0.7860699892044067, "TheoremQA_wenhuchen/definite_matrix2.json": 0.7872396111488342, "camel_40097": 0.7875140905380249, "camel_28412": 0.7877641916275024, "camel_29622": 0.7878099083900452, "camel_40081": 0.7893567681312561, "camel_40106": 0.7895576357841492, "camel_40128": 0.7901692986488342, "camel_40082": 0.7929447889328003, "camel_40119": 0.7940019965171814, "camel_28695": 0.7941014766693115, "camel_40133": 0.7949256896972656, "camel_45517": 0.796292245388031, "camel_40116": 0.7966324687004089, "camel_40143": 0.7974236607551575, "camel_40146": 0.8005174994468689, "camel_40157": 0.8010647892951965, "camel_40104": 0.8024264574050903, "camel_28738": 0.8040123581886292, "camel_40085": 0.8049321174621582, "camel_40155": 0.8057359457015991, "camel_40142": 0.8070294857025146, "camel_40139": 0.8071564435958862, "camel_49935": 0.8074483275413513, "camel_40094": 0.8079560399055481, "camel_28786": 0.8079971671104431, "camel_40126": 0.8087134957313538, "camel_40130": 0.8104501366615295, "camel_40136": 0.810577929019928, "camel_45480": 0.8128514289855957, "camel_40154": 0.8132226467132568, "camel_40101": 0.8146651387214661, "camel_40127": 0.816182017326355, "camel_28673": 0.8204522132873535, "camel_40112": 0.8251634240150452, "camel_40135": 0.8257598876953125, "camel_30479": 0.8315343260765076, "TheoremQA_elainewan/math_algebra_7.json": 0.8429062366485596}, "TheoremQA_wenhuchen/definite_matrix1.json": {"camel_14546": 0, "math_train_intermediate_algebra_1818": 0, "camel_15199": 0, "camel_15120": 0, "camel_15149": 0, "camel_15163": 0, "camel_15133": 0, "camel_15125": 0, "camel_15145": 0, "camel_15153": 0, "camel_14503": 0, "camel_15148": 0, "camel_15134": 0, "camel_15169": 0, "camel_15192": 0, "camel_15178": 0, "camel_15123": 0, "TheoremQA_wenhuchen/definite_matrix1.json": 0, "camel_14504": 0, "camel_15168": 0, "camel_15194": 0, "camel_15187": 0, "camel_15188": 0, "camel_15162": 0, "camel_15121": 0, "camel_15130": 0, "camel_15193": 0, "camel_19487": 0.6723143458366394, "camel_38968": 0.6726974248886108, "camel_29070": 0.6730067133903503, "camel_29641": 0.6730841994285583, "camel_29556": 0.6733681559562683, "camel_28657": 0.6734851598739624, "camel_29630": 0.6739501357078552, "camel_39033": 0.6740179657936096, "camel_29669": 0.6742334365844727, "camel_29104": 0.674274206161499, "camel_18730": 0.6744152903556824, "camel_29543": 0.6744234561920166, "camel_18747": 0.6744405031204224, "camel_18791": 0.6745226979255676, "camel_29598": 0.6747563481330872, "camel_38965": 0.6748664975166321, "camel_29186": 0.6749743223190308, "camel_29471": 0.6749958395957947, "camel_29532": 0.6754637360572815, "camel_19456": 0.6756770610809326, "camel_29679": 0.676088273525238, "camel_38260": 0.6761283874511719, "camel_29629": 0.6764072179794312, "camel_18726": 0.6764432191848755, "camel_18762": 0.6773576140403748, "camel_19375": 0.6775805354118347, "camel_29672": 0.6779541969299316, "camel_38975": 0.6784195899963379, "camel_29661": 0.678570032119751, "camel_29615": 0.678707480430603, "camel_18755": 0.6787272095680237, "camel_29607": 0.6788428425788879, "camel_29606": 0.6793457269668579, "camel_18735": 0.6795257329940796, "camel_29101": 0.6795583963394165, "camel_18751": 0.6797512769699097, "camel_19374": 0.6798208355903625, "camel_29617": 0.6803186535835266, "camel_18959": 0.6804326772689819, "camel_29642": 0.6804946660995483, "camel_38312": 0.6808041930198669, "camel_28673": 0.680846095085144, "camel_29609": 0.6809754371643066, "math_train_precalculus_727": 0.6810652017593384, "camel_38961": 0.6814935803413391, "camel_18792": 0.6816513538360596, "camel_29625": 0.6817711591720581, "camel_29658": 0.681847095489502, "camel_18793": 0.68219393491745, "camel_19479": 0.6832402944564819, "camel_18734": 0.6839829087257385, "camel_18754": 0.6840066313743591, "camel_29570": 0.6841000318527222, "camel_29605": 0.6842907071113586, "camel_18760": 0.6847419142723083, "camel_29676": 0.6856422424316406, "camel_18781": 0.685732364654541, "camel_29655": 0.6859009861946106, "camel_18736": 0.6860689520835876, "camel_18745": 0.6860775947570801, "camel_18913": 0.6861083507537842, "camel_40802": 0.6861222982406616, "camel_38978": 0.6869262456893921, "camel_18795": 0.6871517896652222, "camel_29628": 0.6881579756736755, "camel_40840": 0.6882059574127197, "camel_29596": 0.6883811354637146, "camel_40126": 0.6893796324729919, "camel_23111": 0.6908334493637085, "camel_18782": 0.6923714280128479, "camel_18741": 0.6926949620246887, "camel_18724": 0.6930491924285889, "camel_18739": 0.693149745464325, "camel_29523": 0.6932778358459473, "camel_18888": 0.6940067410469055, "camel_48338": 0.6946633458137512, "camel_39021": 0.6947615742683411, "camel_19366": 0.6952041983604431, "camel_18749": 0.6964631080627441, "camel_18752": 0.697154700756073, "camel_18798": 0.6971926093101501, "camel_19320": 0.6979510188102722, "camel_17522": 0.6983517408370972, "camel_18768": 0.6988347768783569, "camel_19411": 0.7007699608802795, "camel_39005": 0.7024180889129639, "camel_19445": 0.702558696269989, "camel_29458": 0.7031558752059937, "camel_18725": 0.7040203809738159, "camel_38976": 0.7045527696609497, "camel_39035": 0.7051540613174438, "camel_18785": 0.7053543925285339, "camel_39036": 0.705417811870575, "camel_39028": 0.7055026292800903, "camel_18753": 0.7056276202201843, "camel_18759": 0.7066701650619507, "camel_19473": 0.7080442309379578, "camel_18721": 0.7089986801147461, "camel_18799": 0.7096894979476929, "camel_18764": 0.7099786400794983, "camel_18731": 0.7101587653160095, "camel_18728": 0.7102138996124268, "camel_18729": 0.7108058333396912, "camel_18740": 0.7117747068405151, "TheoremQA_xinyi/kernel_2.json": 0.7118500471115112, "camel_18758": 0.7118625640869141, "camel_18770": 0.7121345400810242, "camel_18757": 0.7121409177780151, "camel_18742": 0.7124731540679932, "camel_18787": 0.7125940322875977, "camel_18738": 0.7134008407592773, "camel_18790": 0.7135297656059265, "camel_48332": 0.7142308354377747, "camel_38981": 0.7151537537574768, "camel_18763": 0.7174445986747742, "camel_48340": 0.7175771594047546, "camel_18774": 0.7178405523300171, "camel_39017": 0.7196872234344482, "camel_18771": 0.7203205227851868, "camel_39015": 0.7203553915023804, "camel_18723": 0.7225035429000854, "camel_39003": 0.7226174473762512, "camel_18789": 0.7226375937461853, "camel_18786": 0.7230333685874939, "camel_18775": 0.7242425680160522, "camel_38997": 0.7267442345619202, "camel_18756": 0.7329930067062378, "camel_40860": 0.7347620129585266, "camel_18780": 0.7358472347259521, "camel_39004": 0.7361190319061279, "camel_38967": 0.7392588257789612, "camel_18773": 0.7398269176483154, "camel_48373": 0.74025958776474, "camel_39001": 0.7426941990852356, "camel_38970": 0.7445530891418457, "camel_39012": 0.748880922794342, "camel_39039": 0.758132815361023, "camel_38985": 0.7609958648681641, "camel_39000": 0.761062502861023, "camel_39019": 0.7612118124961853, "camel_39034": 0.7621217370033264, "camel_39020": 0.7632577419281006, "camel_38973": 0.7632976174354553, "camel_38983": 0.7643554210662842, "camel_39030": 0.7705259323120117, "camel_39018": 0.7706714868545532, "camel_38996": 0.7738451957702637, "camel_39007": 0.7745301723480225, "camel_39008": 0.7746552228927612, "camel_38995": 0.7785210609436035, "camel_39013": 0.7842555046081543, "camel_38974": 0.7849065661430359, "camel_38972": 0.7849457263946533, "camel_38984": 0.7874712944030762, "camel_38990": 0.7894469499588013, "camel_38991": 0.7897964715957642, "camel_39023": 0.8003344535827637, "camel_39009": 0.8008390665054321, "camel_38979": 0.8032349944114685, "camel_38966": 0.803787112236023, "camel_39011": 0.8042152523994446, "camel_39025": 0.8073238730430603, "camel_38999": 0.8091184496879578, "camel_38977": 0.8116633892059326, "camel_39029": 0.8145070672035217, "camel_39037": 0.8185321688652039, "camel_38982": 0.8188551664352417, "camel_38963": 0.8190945982933044, "camel_38992": 0.8190991282463074, "camel_39038": 0.8226383924484253, "camel_38964": 0.8382706046104431, "TheoremQA_wenhuchen/definite_matrix2.json": 0.8432188034057617, "camel_38980": 0.8481846451759338}, "TheoremQA_elainewan/math_algebra_1_2.json": {"camel_411": 0, "camel_455": 0, "camel_1686": 0, "math_test_algebra_366": 0, "camel_1747": 0, "camel_448": 0, "math_test_algebra_2028": 0, "math_train_intermediate_algebra_1539": 0, "math_train_intermediate_algebra_620": 0, "math_train_intermediate_algebra_1858": 0, "TheoremQA_elainewan/math_algebra_1_2.json": 0, "camel_1723": 0, "math_test_intermediate_algebra_362": 0, "math_train_algebra_2801": 0, "math_train_algebra_1663": 0, "camel_451": 0, "camel_446": 0, "camel_413": 0, "camel_471": 0, "camel_80": 0, "math_test_algebra_611": 0, "camel_1730": 0, "camel_1741": 0, "camel_1726": 0, "camel_425": 0, "math_test_algebra_2147": 0, "camel_156": 0, "camel_439": 0, "math_train_algebra_1687": 0, "math_test_algebra_214": 0, "camel_442": 0, "math_train_algebra_2434": 0, "math_train_intermediate_algebra_2076": 0, "camel_405": 0, "camel_81": 0, "camel_1695": 0, "camel_1738": 0, "camel_454": 0, "math_test_algebra_1164": 0, "math_test_intermediate_algebra_1764": 0, "camel_1724": 0, "camel_477": 0, "camel_123": 0, "math_test_algebra_704": 0, "math_train_algebra_2244": 0, "camel_1706": 0, "camel_407": 0, "camel_141": 0, "camel_153": 0, "math_train_intermediate_algebra_1863": 0, "camel_464": 0, "camel_403": 0, "camel_99": 0, "camel_1759": 0, "camel_154": 0, "camel_116": 0, "camel_1546": 0, "camel_97": 0, "camel_1716": 0, "camel_128": 0, "camel_432": 0, "camel_1751": 0, "camel_474": 0, "math_train_intermediate_algebra_635": 0, "camel_414": 0, "camel_1696": 0, "camel_456": 0, "camel_159": 0, "camel_440": 0, "camel_430": 0, "math_train_algebra_563": 0, "camel_473": 0, "camel_400": 0, "camel_1746": 0, "math_train_algebra_47": 0, "camel_458": 0, "camel_408": 0, "camel_468": 0, "camel_434": 0, "camel_462": 0, "camel_1725": 0, "camel_426": 0, "camel_421": 0, "camel_465": 0, "camel_453": 0, "camel_438": 0, "camel_433": 0, "camel_1755": 0, "camel_420": 0, "camel_478": 0, "camel_449": 0, "camel_436": 0, "camel_443": 0, "camel_410": 0, "math_test_algebra_883": 0, "camel_467": 0, "math_train_intermediate_algebra_1206": 0, "camel_444": 0, "camel_424": 0, "camel_1742": 0, "camel_466": 0, "math_train_algebra_934": 0, "camel_422": 0, "camel_461": 0, "camel_435": 0, "camel_1715": 0, "math_train_algebra_517": 0, "camel_1691": 0, "camel_401": 0, "math_test_algebra_6": 0, "camel_1685": 0, "camel_1566": 0, "camel_459": 0, "camel_418": 0, "camel_1701": 0, "camel_1704": 0, "camel_135": 0, "camel_437": 0, "camel_1707": 0, "camel_1694": 0, "math_train_intermediate_algebra_1489": 0, "math_test_intermediate_algebra_1526": 0, "camel_423": 0, "camel_427": 0, "camel_452": 0, "camel_479": 0, "camel_90": 0, "camel_419": 0, "camel_475": 0, "camel_1745": 0, "math_train_intermediate_algebra_730": 0, "camel_445": 0, "camel_1710": 0, "camel_1717": 0, "math_test_algebra_1548": 0, "camel_450": 0, "camel_1729": 0, "camel_463": 0, "camel_447": 0, "camel_416": 0, "camel_472": 0, "camel_457": 0, "camel_409": 0, "aqua_rat_27308": 0.7940074801445007, "aqua_rat_38583": 0.7947092652320862, "aqua_rat_48672": 0.7950547933578491, "camel_7774": 0.795254647731781, "camel_49262": 0.7958139181137085, "camel_48862": 0.7959160804748535, "camel_48120": 0.7962084412574768, "aqua_rat_46099": 0.796881377696991, "aqua_rat_62627": 0.7973824739456177, "camel_48887": 0.7974409461021423, "aqua_rat_75993": 0.7983572483062744, "camel_49368": 0.7986448407173157, "aqua_rat_56295": 0.8003826141357422, "aqua_rat_2412": 0.8010798692703247, "camel_48258": 0.8011139035224915, "aqua_rat_78902": 0.8013173937797546, "camel_48096": 0.8013284802436829, "aqua_rat_23958": 0.8015960454940796, "aqua_rat_2696": 0.8017382621765137, "camel_28475": 0.8018126487731934, "aqua_rat_17105": 0.8023006319999695, "camel_48908": 0.8027998805046082, "camel_48255": 0.8034870028495789, "aqua_rat_12386": 0.8036466240882874, "camel_48941": 0.8037228584289551, "camel_48936": 0.8053166270256042, "camel_49674": 0.8065060973167419, "aqua_rat_30784": 0.807325005531311, "camel_48944": 0.8086188435554504, "aqua_rat_72719": 0.8087153434753418, "aqua_rat_21992": 0.809877336025238, "aqua_rat_23444": 0.8107536435127258, "camel_49140": 0.8108105063438416, "camel_49845": 0.8121641874313354, "camel_49437": 0.8144852519035339, "camel_49258": 0.8150486350059509, "camel_49225": 0.8177978992462158, "camel_39311": 0.8192982077598572, "camel_6576": 0.8211797475814819, "aqua_rat_66174": 0.8261657953262329, "aqua_rat_863": 0.8286527991294861, "aqua_rat_10935": 0.8308299779891968, "aqua_rat_20174": 0.8318062424659729, "aqua_rat_29813": 0.8318593502044678, "aqua_rat_55187": 0.832313597202301, "aqua_rat_75546": 0.8324844837188721, "aqua_rat_5517": 0.8332751989364624, "aqua_rat_28168": 0.833808958530426, "aqua_rat_84969": 0.833970844745636, "aqua_rat_32853": 0.8342546820640564, "aqua_rat_32416": 0.8342859148979187, "camel_44659": 0.8349044322967529, "aqua_rat_45553": 0.8349745869636536, "aqua_rat_5411": 0.8358221650123596, "aqua_rat_36743": 0.838304877281189, "camel_48888": 0.8385337591171265, "aqua_rat_62268": 0.8410294651985168}, "TheoremQA_xueguangma/future_value_2.json": {"gsm_train_30707": 0.7882916331291199, "aqua_rat_33923": 0.7883142828941345, "aqua_rat_83740": 0.7884632349014282, "aqua_rat_30447": 0.7884889841079712, "aqua_rat_48358": 0.7886757254600525, "aqua_rat_88174": 0.7887247800827026, "aqua_rat_25723": 0.7888127565383911, "gsm_rft_24617": 0.7889279127120972, "aqua_rat_7858": 0.7890449166297913, "aqua_rat_19480": 0.7892253994941711, "aqua_rat_34889": 0.789280116558075, "aqua_rat_70690": 0.7893120050430298, "gsm_rft_20456": 0.789389431476593, "aqua_rat_44671": 0.7895179986953735, "aqua_rat_21010": 0.7896183133125305, "aqua_rat_79979": 0.7896938920021057, "aqua_rat_53421": 0.7899205684661865, "aqua_rat_6703": 0.7900159955024719, "aqua_rat_60598": 0.7900332808494568, "aqua_rat_41963": 0.7900351285934448, "aqua_rat_20903": 0.7903782725334167, "aqua_rat_63070": 0.7904016971588135, "aqua_rat_64664": 0.7904236316680908, "aqua_rat_42515": 0.7905493974685669, "aqua_rat_9965": 0.7906616926193237, "aqua_rat_24705": 0.7908105850219727, "aqua_rat_1115": 0.7908415198326111, "aqua_rat_255": 0.7908737063407898, "aqua_rat_42017": 0.7910379767417908, "aqua_rat_77602": 0.7911327481269836, "aqua_rat_41404": 0.7911489009857178, "aqua_rat_47773": 0.7913438081741333, "aqua_rat_10904": 0.7913903594017029, "aqua_rat_27270": 0.7914078235626221, "aqua_rat_1353": 0.7914835810661316, "math_train_algebra_2507": 0.7915549874305725, "aqua_rat_82152": 0.7916275262832642, "aqua_rat_72794": 0.791754961013794, "aqua_rat_869": 0.7917858362197876, "aqua_rat_7674": 0.7918232083320618, "aqua_rat_32582": 0.7919502258300781, "aqua_rat_53914": 0.7920680046081543, "aqua_rat_43060": 0.7923660278320312, "aqua_rat_75737": 0.7925411462783813, "aqua_rat_12422": 0.7925748825073242, "aqua_rat_60064": 0.7927971482276917, "aqua_rat_1573": 0.7929667830467224, "aqua_rat_28520": 0.7929922938346863, "aqua_rat_53504": 0.793042004108429, "aqua_rat_2676": 0.7931001782417297, "aqua_rat_53400": 0.7932655215263367, "aqua_rat_45060": 0.7933790683746338, "aqua_rat_76956": 0.7933925986289978, "aqua_rat_76156": 0.7934771776199341, "aqua_rat_86101": 0.7937002778053284, "gsm_rft_6203": 0.793794572353363, "aqua_rat_7205": 0.7940540313720703, "aqua_rat_65985": 0.7942053079605103, "aqua_rat_32852": 0.7942930459976196, "gsm_train_26849": 0.7944084405899048, "gsm_rft_19092": 0.7944084405899048, "aqua_rat_69526": 0.7944164276123047, "aqua_rat_69937": 0.7946924567222595, "aqua_rat_38352": 0.7949650287628174, "gsm_rft_28176": 0.7950364351272583, "math_train_algebra_2129": 0.7951865792274475, "aqua_rat_58269": 0.7951927185058594, "aqua_rat_13979": 0.7953816652297974, "aqua_rat_59668": 0.7955835461616516, "aqua_rat_22299": 0.7957861423492432, "aqua_rat_61585": 0.7959246039390564, "aqua_rat_64976": 0.7959306240081787, "aqua_rat_39288": 0.7963520288467407, "aqua_rat_67841": 0.7963621616363525, "aqua_rat_34698": 0.7963804006576538, "aqua_rat_61757": 0.7965059280395508, "math_test_algebra_82": 0.796618640422821, "math_train_algebra_1011": 0.7966791987419128, "gsm_rft_9932": 0.7967615127563477, "aqua_rat_7357": 0.7967638969421387, "aqua_rat_65963": 0.7968390583992004, "aqua_rat_18368": 0.7969204783439636, "aqua_rat_26339": 0.7973217964172363, "aqua_rat_86432": 0.7975220084190369, "aqua_rat_12480": 0.7975569367408752, "aqua_rat_86835": 0.7976821064949036, "aqua_rat_78121": 0.7976987361907959, "math_test_algebra_337": 0.7978860139846802, "aqua_rat_61190": 0.7978891730308533, "aqua_rat_49963": 0.7981799840927124, "aqua_rat_31350": 0.7982431054115295, "aqua_rat_26582": 0.7985519170761108, "aqua_rat_72933": 0.7987247705459595, "aqua_rat_37382": 0.7993404865264893, "aqua_rat_87171": 0.7993478775024414, "gsm_rft_24137": 0.799349844455719, "aqua_rat_66298": 0.7994319796562195, "aqua_rat_35380": 0.7995240092277527, "aqua_rat_54891": 0.7997866868972778, "aqua_rat_13549": 0.7998620271682739, "aqua_rat_39422": 0.8001999855041504, "math_test_algebra_2626": 0.8003273010253906, "aqua_rat_65365": 0.8005678653717041, "aqua_rat_47882": 0.8006137609481812, "aqua_rat_35907": 0.8009321689605713, "aqua_rat_38071": 0.8009521961212158, "aqua_rat_54664": 0.801159679889679, "aqua_rat_42824": 0.8012198805809021, "aqua_rat_69339": 0.8012319207191467, "math_test_algebra_990": 0.8013107776641846, "aqua_rat_63322": 0.8013512492179871, "math_train_algebra_707": 0.8014903664588928, "aqua_rat_69273": 0.8015562295913696, "aqua_rat_71142": 0.8016330599784851, "aqua_rat_32851": 0.8016347289085388, "aqua_rat_27039": 0.8017160296440125, "gsm_rft_10656": 0.8018006682395935, "aqua_rat_60321": 0.8020055294036865, "aqua_rat_66803": 0.8022051453590393, "aqua_rat_87246": 0.8024280667304993, "aqua_rat_3687": 0.8024409413337708, "aqua_rat_83234": 0.802496612071991, "aqua_rat_9944": 0.8028215765953064, "aqua_rat_74003": 0.8032522201538086, "aqua_rat_62528": 0.8036913275718689, "aqua_rat_37780": 0.8038570880889893, "aqua_rat_10582": 0.8039115071296692, "aqua_rat_16693": 0.803986668586731, "aqua_rat_67076": 0.804420530796051, "aqua_rat_64635": 0.8048611283302307, "aqua_rat_56852": 0.8048716187477112, "aqua_rat_88960": 0.8050917983055115, "aqua_rat_77744": 0.8055095076560974, "aqua_rat_30386": 0.8055168390274048, "aqua_rat_3536": 0.8056350350379944, "math_test_algebra_1611": 0.8056721091270447, "aqua_rat_73739": 0.805720865726471, "aqua_rat_41143": 0.8057631850242615, "aqua_rat_50447": 0.8058137893676758, "aqua_rat_32958": 0.8065822720527649, "aqua_rat_27053": 0.8067121505737305, "aqua_rat_88415": 0.8082628846168518, "aqua_rat_88003": 0.8084269165992737, "aqua_rat_37258": 0.8085214495658875, "aqua_rat_58694": 0.8085342645645142, "aqua_rat_65964": 0.8089883327484131, "aqua_rat_34332": 0.8092312216758728, "aqua_rat_28662": 0.809563934803009, "aqua_rat_6657": 0.8095818161964417, "aqua_rat_43046": 0.8097326755523682, "math_test_algebra_608": 0.8098627328872681, "aqua_rat_53044": 0.8102007508277893, "aqua_rat_66371": 0.8113755583763123, "aqua_rat_19784": 0.8118999004364014, "aqua_rat_32642": 0.8122950196266174, "aqua_rat_68014": 0.8129156231880188, "aqua_rat_13396": 0.813102126121521, "math_train_algebra_667": 0.8131266236305237, "aqua_rat_84309": 0.8136351704597473, "aqua_rat_44549": 0.8141334056854248, "aqua_rat_33006": 0.8141905069351196, "aqua_rat_87589": 0.8151271343231201, "aqua_rat_78692": 0.8154443502426147, "aqua_rat_22060": 0.81549072265625, "gsm_rft_6559": 0.81600421667099, "math_test_algebra_1862": 0.8171406984329224, "aqua_rat_47529": 0.8172769546508789, "aqua_rat_85193": 0.8173030018806458, "aqua_rat_79904": 0.8173874020576477, "math_train_algebra_1277": 0.8174949884414673, "aqua_rat_83046": 0.8175682425498962, "aqua_rat_64092": 0.8176327347755432, "gsm_train_25622": 0.8182465434074402, "aqua_rat_24646": 0.8182531595230103, "gsm_rft_11620": 0.8187160491943359, "aqua_rat_53302": 0.8189989924430847, "aqua_rat_37580": 0.8203549385070801, "aqua_rat_25325": 0.8207530975341797, "aqua_rat_71239": 0.8212708234786987, "aqua_rat_67698": 0.8223118782043457, "aqua_rat_59403": 0.8230946063995361, "TheoremQA_wenhuchen/compound_interest1.json": 0.8231407999992371, "aqua_rat_7537": 0.8236258625984192, "gsm_rft_5849": 0.8237289786338806, "aqua_rat_29976": 0.8244830369949341, "aqua_rat_39049": 0.8245598077774048, "TheoremQA_xueguangma/future_value_1.json": 0.8247583508491516, "aqua_rat_73390": 0.8266627788543701, "aqua_rat_28282": 0.8290968537330627, "aqua_rat_86234": 0.8299387693405151, "math_train_algebra_957": 0.8300782442092896, "aqua_rat_25162": 0.831403911113739, "aqua_rat_21814": 0.8324817419052124, "aqua_rat_12597": 0.8329404592514038, "aqua_rat_83638": 0.8331652283668518, "aqua_rat_15337": 0.8343080878257751, "aqua_rat_20423": 0.8359128832817078, "aqua_rat_29321": 0.8361008763313293, "math_test_algebra_594": 0.8520956635475159, "math_train_algebra_369": 0.8600518107414246}, "TheoremQA_wenhuchen/optics2.json": {"TheoremQA_wenhuchen/optics2.json": 0, "camel_3326": 0.701650083065033, "aqua_rat_22995": 0.7017034292221069, "math_test_geometry_265": 0.7018093466758728, "math_train_geometry_816": 0.7018378973007202, "aqua_rat_54715": 0.7018419504165649, "aqua_rat_45674": 0.7018803358078003, "camel_3886": 0.7020094990730286, "camel_4827": 0.7020196914672852, "aqua_rat_64117": 0.7020292282104492, "camel_4988": 0.7020910978317261, "camel_4853": 0.7021228075027466, "aqua_rat_41018": 0.7025616765022278, "aqua_rat_66685": 0.7026136517524719, "aqua_rat_41470": 0.7026447653770447, "camel_3252": 0.7026703953742981, "aqua_rat_55162": 0.7027162313461304, "aqua_rat_43491": 0.7031556963920593, "aqua_rat_28423": 0.703163206577301, "aqua_rat_12010": 0.7031813263893127, "camel_3895": 0.7031813859939575, "camel_4807": 0.7033089399337769, "aqua_rat_18095": 0.7034595012664795, "camel_5540": 0.7034733295440674, "math_train_geometry_447": 0.7035796642303467, "aqua_rat_43435": 0.7037152051925659, "math_train_geometry_153": 0.7038010954856873, "math_test_prealgebra_1108": 0.7041429281234741, "camel_4848": 0.7041662335395813, "math_train_prealgebra_205": 0.7041954398155212, "aqua_rat_55685": 0.704232394695282, "camel_4920": 0.7043091058731079, "camel_4760": 0.7043282389640808, "camel_4895": 0.7043588757514954, "math_test_geometry_1108": 0.7044451236724854, "camel_4724": 0.7045118808746338, "aqua_rat_23369": 0.7046446800231934, "camel_5891": 0.70469731092453, "aqua_rat_67833": 0.7051862478256226, "aqua_rat_64781": 0.7052823305130005, "aqua_rat_56786": 0.705435037612915, "aqua_rat_61382": 0.705484926700592, "camel_4893": 0.7054947018623352, "camel_4981": 0.7055829167366028, "aqua_rat_19775": 0.7058585286140442, "camel_4659": 0.7059022784233093, "aqua_rat_49835": 0.7059655785560608, "aqua_rat_47344": 0.7061032652854919, "aqua_rat_42357": 0.7062151432037354, "camel_4816": 0.7062991261482239, "camel_18681": 0.7063642740249634, "aqua_rat_77596": 0.7063761949539185, "camel_3231": 0.7065352201461792, "aqua_rat_20932": 0.7065667510032654, "aqua_rat_88338": 0.7066891193389893, "gsm_rft_14765": 0.7067598700523376, "aqua_rat_42710": 0.7069194316864014, "aqua_rat_61332": 0.7069750428199768, "aqua_rat_11860": 0.7075321078300476, "aqua_rat_21058": 0.7075528502464294, "aqua_rat_86816": 0.7076409459114075, "aqua_rat_85770": 0.7077029347419739, "math_train_geometry_809": 0.7079304456710815, "aqua_rat_56629": 0.7080396413803101, "aqua_rat_23150": 0.7081614136695862, "aqua_rat_5999": 0.7085477113723755, "aqua_rat_61852": 0.7085888981819153, "aqua_rat_61422": 0.708805501461029, "aqua_rat_59768": 0.7088257670402527, "camel_4904": 0.7088938355445862, "aqua_rat_35145": 0.7089115977287292, "camel_6840": 0.7090930938720703, "math_train_geometry_752": 0.7093379497528076, "aqua_rat_85931": 0.7094535827636719, "aqua_rat_20986": 0.7096344828605652, "camel_4813": 0.7097592949867249, "aqua_rat_18034": 0.709856390953064, "math_train_geometry_117": 0.7100319266319275, "aqua_rat_49952": 0.7101454734802246, "aqua_rat_9047": 0.7104242444038391, "camel_5587": 0.7104962468147278, "aqua_rat_10607": 0.710602343082428, "aqua_rat_62614": 0.7106188535690308, "aqua_rat_4999": 0.710647702217102, "aqua_rat_71816": 0.7106637954711914, "aqua_rat_58122": 0.7113161683082581, "camel_4781": 0.71140056848526, "aqua_rat_82639": 0.7118306756019592, "camel_3974": 0.7121225595474243, "camel_3930": 0.7122270464897156, "camel_4746": 0.7125566601753235, "camel_5543": 0.712756872177124, "camel_4867": 0.7129926085472107, "camel_5563": 0.7132258415222168, "aqua_rat_2524": 0.7137138247489929, "aqua_rat_73929": 0.713718593120575, "aqua_rat_29637": 0.7137507796287537, "math_train_precalculus_592": 0.713875949382782, "camel_5033": 0.714203417301178, "aqua_rat_31294": 0.7144509553909302, "math_train_geometry_805": 0.7144529223442078, "aqua_rat_30115": 0.7145203351974487, "camel_4820": 0.7150241732597351, "camel_4552": 0.7151327729225159, "aqua_rat_13122": 0.7153127789497375, "aqua_rat_86356": 0.7154417037963867, "gsm_rft_11389": 0.715775728225708, "math_train_geometry_6068": 0.7158690094947815, "math_train_geometry_597": 0.7160808444023132, "aqua_rat_80856": 0.7161240577697754, "aqua_rat_18543": 0.7168304920196533, "camel_4798": 0.7171609997749329, "aqua_rat_17054": 0.7174071669578552, "camel_4980": 0.7176750898361206, "math_test_prealgebra_583": 0.7177485823631287, "aqua_rat_40416": 0.7180953621864319, "math_train_geometry_649": 0.7183363437652588, "aqua_rat_14896": 0.7184212803840637, "aqua_rat_78473": 0.7184417843818665, "aqua_rat_33167": 0.7187622785568237, "aqua_rat_52007": 0.7188777327537537, "aqua_rat_6857": 0.718977153301239, "math_train_geometry_659": 0.7193081974983215, "aqua_rat_35190": 0.7193330526351929, "aqua_rat_9227": 0.7193947434425354, "gsm_rft_4264": 0.7199110984802246, "gsm_train_17974": 0.7199417948722839, "aqua_rat_79701": 0.7201068997383118, "gsm_rft_35606": 0.7201138734817505, "aqua_rat_68512": 0.7207462787628174, "aqua_rat_68661": 0.7208355069160461, "aqua_rat_44239": 0.7208855152130127, "aqua_rat_52556": 0.7212379574775696, "aqua_rat_81174": 0.721409261226654, "aqua_rat_23667": 0.7215796709060669, "math_train_geometry_804": 0.7215855121612549, "math_test_prealgebra_390": 0.7217512130737305, "aqua_rat_19925": 0.7218014001846313, "aqua_rat_66222": 0.7220206260681152, "aqua_rat_46971": 0.7224765419960022, "aqua_rat_85100": 0.7228914499282837, "aqua_rat_47361": 0.7232514023780823, "aqua_rat_51750": 0.7232694029808044, "math_test_algebra_2160": 0.7235448360443115, "aqua_rat_83787": 0.7239213585853577, "aqua_rat_24795": 0.7248597145080566, "aqua_rat_35477": 0.7250474691390991, "math_train_geometry_1": 0.7264136672019958, "aqua_rat_2590": 0.7264415621757507, "aqua_rat_40593": 0.7268975377082825, "aqua_rat_66436": 0.72810298204422, "aqua_rat_23202": 0.7285263538360596, "camel_47741": 0.7289665341377258, "aqua_rat_7754": 0.7295489311218262, "math_test_prealgebra_1904": 0.7302636504173279, "math_train_geometry_25569": 0.7308136820793152, "math_train_geometry_442": 0.7309232950210571, "camel_47698": 0.7314907312393188, "math_train_geometry_407": 0.7317377924919128, "aqua_rat_38515": 0.7319225072860718, "math_train_geometry_1022": 0.7319397926330566, "math_test_geometry_105": 0.7324062585830688, "math_train_geometry_1049": 0.7325679063796997, "aqua_rat_72372": 0.7339152693748474, "math_train_prealgebra_1701": 0.7352927327156067, "aqua_rat_14967": 0.7358911037445068, "TheoremQA_wenhuchen/optics3.json": 0.7363881468772888, "math_train_geometry_70": 0.7375571727752686, "aqua_rat_75450": 0.7390889525413513, "gsm_rft_7733": 0.740953803062439, "aqua_rat_30371": 0.741184651851654, "gsm_train_19077": 0.7412312626838684, "gsm_rft_17748": 0.7412312626838684, "aqua_rat_58996": 0.7429370284080505, "aqua_rat_29187": 0.7439019680023193, "aqua_rat_32781": 0.7453321218490601, "aqua_rat_2228": 0.746145486831665, "camel_19740": 0.7464897036552429, "aqua_rat_41135": 0.7469482421875, "aqua_rat_29369": 0.7474272847175598, "math_train_geometry_1101": 0.7487269639968872, "aqua_rat_23493": 0.7507684826850891, "aqua_rat_37605": 0.7531370520591736, "aqua_rat_60805": 0.7533743977546692, "camel_5527": 0.7546854019165039, "aqua_rat_30186": 0.756120502948761, "aqua_rat_12240": 0.7572749853134155, "aqua_rat_22618": 0.759355366230011, "aqua_rat_55057": 0.7596105933189392, "TheoremQA_wenhuchen/optics7.json": 0.759709894657135, "aqua_rat_83857": 0.7611573934555054, "aqua_rat_25937": 0.762213408946991, "aqua_rat_69962": 0.7625089287757874, "aqua_rat_18718": 0.7641681432723999, "camel_4737": 0.7735265493392944, "aqua_rat_8530": 0.7746152877807617, "camel_4771": 0.7774800658226013, "camel_49646": 0.7833645939826965, "math_test_geometry_151": 0.7845156192779541, "camel_4808": 0.7863026261329651}, "TheoremQA_wenhuchen/L'H\u00f4pital_rule1.json": {"camel_6100": 0, "camel_6088": 0, "TheoremQA_wenhuchen/L'H\u00f4pital_rule1.json": 0, "camel_17363": 0.707188606262207, "aqua_rat_3061": 0.7072355151176453, "camel_42824": 0.7072814702987671, "camel_29934": 0.7073850035667419, "camel_16234": 0.7074189782142639, "camel_42361": 0.7074640989303589, "camel_42289": 0.7076296210289001, "camel_16164": 0.7079524993896484, "camel_29924": 0.708063006401062, "aqua_rat_46370": 0.7081314325332642, "camel_42820": 0.7083012461662292, "camel_29240": 0.7083043456077576, "camel_31131": 0.7084466814994812, "camel_29712": 0.7086707949638367, "camel_43821": 0.7088960409164429, "camel_29995": 0.7089106440544128, "aqua_rat_14694": 0.7090764045715332, "camel_17422": 0.7091075778007507, "camel_16230": 0.7092096209526062, "camel_28145": 0.709304928779602, "camel_42258": 0.7094250321388245, "camel_29922": 0.7095008492469788, "aqua_rat_850": 0.7096155285835266, "camel_29378": 0.7097101211547852, "camel_16614": 0.7101029753684998, "camel_28086": 0.7101167440414429, "camel_29749": 0.7101694941520691, "camel_16313": 0.7102364301681519, "camel_43346": 0.7103489637374878, "camel_29361": 0.7104491591453552, "aqua_rat_32676": 0.7104770541191101, "camel_42575": 0.7106708288192749, "camel_28848": 0.7107719779014587, "camel_28096": 0.7107964158058167, "aqua_rat_59305": 0.7107981443405151, "aqua_rat_63003": 0.7108471393585205, "camel_29693": 0.7108495235443115, "camel_29973": 0.7109770178794861, "aqua_rat_60999": 0.7111049890518188, "camel_42299": 0.711318850517273, "camel_28860": 0.7116239070892334, "camel_29373": 0.7116302251815796, "aqua_rat_26781": 0.7117415070533752, "camel_42497": 0.7117974162101746, "camel_42915": 0.7118598222732544, "aqua_rat_2101": 0.7120712399482727, "camel_29429": 0.7120876312255859, "camel_29753": 0.7121719121932983, "aqua_rat_45950": 0.712185263633728, "camel_29415": 0.7122584581375122, "camel_42261": 0.7122593522071838, "camel_42844": 0.7124220132827759, "camel_29019": 0.7125623822212219, "camel_29719": 0.7125681638717651, "aqua_rat_76787": 0.7128778100013733, "camel_42318": 0.712897539138794, "camel_42313": 0.7129138708114624, "camel_45518": 0.7129632830619812, "camel_45932": 0.7130548357963562, "camel_28805": 0.7131086587905884, "camel_29991": 0.7131609916687012, "camel_44640": 0.7134171724319458, "aqua_rat_24370": 0.7135351896286011, "aqua_rat_63615": 0.7135627865791321, "camel_28851": 0.713811457157135, "camel_42834": 0.7140481472015381, "camel_42879": 0.7143436074256897, "camel_42616": 0.7144648432731628, "camel_28814": 0.7144837975502014, "camel_42306": 0.7146553993225098, "camel_49051": 0.7149305939674377, "aqua_rat_37501": 0.7150075435638428, "camel_42331": 0.715045154094696, "aqua_rat_46351": 0.7155270576477051, "camel_16161": 0.7155327200889587, "aqua_rat_34594": 0.7156273722648621, "camel_49430": 0.7156623005867004, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus2.json": 0.7156786322593689, "camel_42269": 0.716270387172699, "camel_42302": 0.7162759304046631, "camel_29033": 0.7167013883590698, "aqua_rat_50085": 0.7167575359344482, "TheoremQA_xueguangma/maclaurin_series.json": 0.7167723774909973, "aqua_rat_53223": 0.7167931795120239, "aqua_rat_36737": 0.7168940305709839, "camel_42244": 0.7169265747070312, "camel_29965": 0.7169302701950073, "camel_17045": 0.7170318961143494, "camel_17394": 0.7170895934104919, "aqua_rat_2148": 0.7172532081604004, "camel_42762": 0.7174187898635864, "camel_43996": 0.7176381945610046, "camel_42249": 0.7176488041877747, "camel_16136": 0.7181206941604614, "camel_42324": 0.7181437611579895, "aqua_rat_65888": 0.7183299660682678, "camel_28080": 0.7186137437820435, "camel_28532": 0.7186691164970398, "camel_29735": 0.718670666217804, "camel_29365": 0.7190662622451782, "camel_17379": 0.7192173004150391, "camel_45494": 0.7193754315376282, "aqua_rat_29552": 0.7194074988365173, "aqua_rat_75287": 0.719409167766571, "aqua_rat_9017": 0.7195695638656616, "camel_42882": 0.7197661995887756, "camel_29432": 0.7197977900505066, "camel_42623": 0.7198416590690613, "camel_17389": 0.7203215956687927, "camel_29426": 0.720403790473938, "camel_29932": 0.7204042077064514, "camel_29953": 0.7204890251159668, "camel_42633": 0.72050541639328, "aqua_rat_55490": 0.7206036448478699, "camel_29422": 0.7207161784172058, "camel_29860": 0.7209084630012512, "camel_18917": 0.721492350101471, "camel_29948": 0.7218517065048218, "camel_29985": 0.7218812108039856, "aqua_rat_49646": 0.7219337224960327, "camel_29420": 0.7220233678817749, "camel_45364": 0.722373366355896, "camel_36477": 0.7224713563919067, "camel_42301": 0.7226306200027466, "camel_17384": 0.722980797290802, "camel_29374": 0.7236045002937317, "camel_31078": 0.7236090302467346, "aqua_rat_17495": 0.7238328456878662, "camel_29986": 0.7238801717758179, "aqua_rat_24364": 0.7240191698074341, "camel_42867": 0.7243300676345825, "camel_29388": 0.7243865728378296, "camel_29371": 0.724852979183197, "camel_42315": 0.7252890467643738, "camel_30889": 0.7253503203392029, "camel_44716": 0.7255299091339111, "camel_29983": 0.7257123589515686, "aqua_rat_66450": 0.7257578372955322, "camel_17092": 0.7258393168449402, "camel_42618": 0.7259055376052856, "camel_29927": 0.7262685298919678, "camel_29999": 0.7264529466629028, "camel_31206": 0.7269434928894043, "camel_29998": 0.7273615002632141, "TheoremQA_elainewan/math_real_analysis_additional_3.json": 0.7278236746788025, "camel_29969": 0.7280017137527466, "camel_29379": 0.7280258536338806, "camel_29960": 0.7288743257522583, "camel_29955": 0.729142427444458, "camel_29638": 0.7294716238975525, "camel_29395": 0.7301056981086731, "camel_18951": 0.7305269241333008, "camel_29977": 0.730688214302063, "camel_29984": 0.7307777404785156, "camel_36444": 0.7312753796577454, "camel_29970": 0.7314274907112122, "camel_29925": 0.7314407825469971, "camel_29427": 0.731443464756012, "camel_29936": 0.731889545917511, "camel_29699": 0.7330244183540344, "camel_29968": 0.7335589528083801, "camel_29989": 0.7336891293525696, "camel_29957": 0.7341419458389282, "camel_29372": 0.7349572777748108, "camel_29403": 0.7353531122207642, "camel_29417": 0.735527753829956, "camel_29419": 0.7357015609741211, "aqua_rat_11117": 0.7358826994895935, "camel_17435": 0.7366856336593628, "camel_29398": 0.73711097240448, "camel_29437": 0.737741231918335, "camel_29964": 0.7378743290901184, "camel_29941": 0.7382978200912476, "camel_29950": 0.7389699816703796, "camel_29406": 0.7393446564674377, "camel_29972": 0.7395307421684265, "camel_29438": 0.7398967742919922, "camel_29435": 0.7401154637336731, "TheoremQA_elainewan/math_calculus_2_4.json": 0.7415337562561035, "camel_29389": 0.7417272925376892, "camel_29992": 0.7417278289794922, "aqua_rat_53026": 0.7432318329811096, "camel_29360": 0.7441691756248474, "camel_29385": 0.7450733780860901, "camel_29946": 0.7455545663833618, "camel_29416": 0.7457002997398376, "camel_17361": 0.7467576265335083, "camel_18301": 0.7477724552154541, "camel_29434": 0.7478052973747253, "camel_28793": 0.7490882277488708, "camel_29381": 0.7498798966407776, "camel_29363": 0.7513989210128784, "camel_29976": 0.7521552443504333, "camel_42591": 0.7549982666969299, "camel_29943": 0.7571237087249756, "TheoremQA_elainewan/math_calculus_2_10.json": 0.7682740092277527, "camel_17390": 0.7691523432731628}, "TheoremQA_elainewan/math_calculus_2_11.json": {"camel_6172": 0, "camel_7754": 0, "camel_6576": 0, "camel_6410": 0, "math_test_precalculus_783": 0, "camel_7691": 0, "camel_7021": 0, "camel_7735": 0, "TheoremQA_elainewan/math_calculus_2_11.json": 0, "camel_7753": 0, "camel_7685": 0, "camel_7700": 0, "math_train_precalculus_1108": 0, "math_test_precalculus_893": 0, "aqua_rat_10955": 0.7200634479522705, "aqua_rat_80339": 0.7201465964317322, "camel_4289": 0.7201848030090332, "aqua_rat_76599": 0.7202017903327942, "camel_42810": 0.7202233076095581, "aqua_rat_53614": 0.720278263092041, "camel_42458": 0.7202904224395752, "camel_1835": 0.720325767993927, "aqua_rat_50085": 0.720337450504303, "camel_39084": 0.7203600406646729, "camel_43252": 0.7205104231834412, "camel_39062": 0.7205989360809326, "camel_1717": 0.720740020275116, "aqua_rat_11769": 0.7207752466201782, "camel_4990": 0.7207816243171692, "aqua_rat_57634": 0.7208181023597717, "camel_1810": 0.7211176156997681, "camel_42609": 0.7211177349090576, "camel_42965": 0.7211312055587769, "camel_42415": 0.72122722864151, "camel_5006": 0.7212482690811157, "camel_29303": 0.7214369177818298, "camel_1833": 0.7215088605880737, "camel_42470": 0.7215114235877991, "camel_40708": 0.7215970158576965, "camel_38809": 0.721613883972168, "camel_42895": 0.7217943072319031, "camel_42480": 0.7218544483184814, "camel_1811": 0.7220481634140015, "camel_42473": 0.7222354412078857, "camel_42464": 0.7222679257392883, "camel_28666": 0.7222955822944641, "camel_42525": 0.7223743796348572, "aqua_rat_48929": 0.7226020693778992, "camel_4273": 0.7226401567459106, "aqua_rat_77759": 0.7226629257202148, "aqua_rat_69050": 0.7227112650871277, "camel_29860": 0.7227473258972168, "camel_29638": 0.7227473855018616, "camel_42942": 0.7227670550346375, "camel_42485": 0.7227776050567627, "camel_48965": 0.7228936553001404, "camel_1725": 0.7228976488113403, "camel_1765": 0.7230249643325806, "camel_39292": 0.7230818271636963, "camel_4275": 0.7232000231742859, "camel_40717": 0.7233007550239563, "camel_48078": 0.723362386226654, "TheoremQA_wenhuchen/Liouville\u2019s_theorem2.json": 0.7234604358673096, "camel_30291": 0.7234758734703064, "camel_39321": 0.7237107157707214, "math_train_intermediate_algebra_830": 0.7237352728843689, "camel_1825": 0.7238634824752808, "camel_1815": 0.7241342663764954, "camel_42522": 0.7241525650024414, "camel_48110": 0.7245635390281677, "camel_43171": 0.7246452569961548, "camel_39284": 0.7247850298881531, "camel_4240": 0.724835216999054, "camel_29712": 0.7248818278312683, "camel_42450": 0.7250321507453918, "aqua_rat_73680": 0.7250522375106812, "camel_42432": 0.7251628041267395, "camel_39579": 0.7252923250198364, "camel_4315": 0.725369930267334, "camel_42455": 0.7254658937454224, "camel_4303": 0.7254760265350342, "camel_4263": 0.7256704568862915, "camel_4318": 0.725764274597168, "camel_30302": 0.7259061932563782, "camel_18910": 0.7260369062423706, "camel_4268": 0.7260798811912537, "aqua_rat_48533": 0.7262202501296997, "camel_42420": 0.7263750433921814, "camel_42550": 0.7264120578765869, "aqua_rat_60002": 0.7264434695243835, "camel_1827": 0.7264564037322998, "camel_1788": 0.726680338382721, "camel_4986": 0.7269778847694397, "camel_1826": 0.727022111415863, "camel_30166": 0.7271373867988586, "camel_4244": 0.72724449634552, "camel_1772": 0.7274376153945923, "camel_4312": 0.7274759411811829, "camel_4280": 0.7275621294975281, "camel_1775": 0.7277522683143616, "camel_18918": 0.7277656197547913, "camel_4292": 0.7281689047813416, "camel_39083": 0.7282549738883972, "camel_4299": 0.7283850312232971, "camel_42478": 0.7286830544471741, "camel_42437": 0.7286983728408813, "camel_1845": 0.7287704944610596, "camel_17092": 0.7288120985031128, "aqua_rat_21304": 0.7289479970932007, "camel_4286": 0.7289960980415344, "aqua_rat_24364": 0.7290005683898926, "camel_42428": 0.7291574478149414, "aqua_rat_65549": 0.7294909954071045, "camel_37507": 0.7295544147491455, "camel_43928": 0.7295897006988525, "camel_42411": 0.7295908331871033, "aqua_rat_24388": 0.7296956777572632, "camel_42453": 0.7297208905220032, "camel_39147": 0.7298959493637085, "camel_1808": 0.7303088903427124, "camel_1837": 0.7308653593063354, "camel_39547": 0.7309970259666443, "camel_28475": 0.7311484813690186, "camel_1777": 0.7312854528427124, "camel_28304": 0.7315567135810852, "camel_42500": 0.7319380044937134, "camel_39351": 0.7320141792297363, "camel_42433": 0.732255220413208, "camel_1874": 0.7324740290641785, "camel_39307": 0.7326441407203674, "camel_1780": 0.7327769994735718, "camel_40647": 0.7331621050834656, "camel_1791": 0.7333244681358337, "camel_42434": 0.7333694100379944, "camel_1762": 0.7334408760070801, "camel_41705": 0.7334765791893005, "camel_39125": 0.7335484623908997, "camel_4261": 0.7337237596511841, "camel_1759": 0.73381507396698, "camel_40781": 0.733955442905426, "camel_36502": 0.7339606285095215, "camel_29735": 0.7339938282966614, "camel_28080": 0.7347626090049744, "aqua_rat_79794": 0.7348983883857727, "camel_5080": 0.7354562282562256, "camel_4269": 0.7354902625083923, "camel_42410": 0.7356182932853699, "camel_42477": 0.7363962531089783, "camel_1814": 0.7364218235015869, "camel_39340": 0.736747145652771, "camel_30209": 0.7372300624847412, "camel_1796": 0.7374246120452881, "camel_1793": 0.7374610304832458, "camel_4256": 0.7377610802650452, "camel_5066": 0.7383923530578613, "camel_4266": 0.7384299635887146, "camel_30167": 0.7385043501853943, "camel_1803": 0.7385478019714355, "camel_39124": 0.739561140537262, "math_test_intermediate_algebra_1849": 0.7396588921546936, "camel_30318": 0.7397595047950745, "camel_1831": 0.739945113658905, "camel_4998": 0.7399522662162781, "camel_42520": 0.7402698397636414, "camel_1712": 0.7405710816383362, "camel_42408": 0.7412976622581482, "camel_1744": 0.7413667440414429, "camel_39357": 0.7413683533668518, "camel_4249": 0.7425826787948608, "camel_42435": 0.7425962090492249, "camel_4311": 0.7428091168403625, "camel_4960": 0.7430828809738159, "camel_42422": 0.7431878447532654, "aqua_rat_49646": 0.7435581684112549, "camel_1746": 0.7436891794204712, "camel_18936": 0.7439337372779846, "camel_4290": 0.7444869875907898, "camel_4968": 0.7446503639221191, "camel_19483": 0.7448391914367676, "camel_5005": 0.7456514239311218, "camel_29198": 0.7458323836326599, "camel_28086": 0.7465900778770447, "aqua_rat_30276": 0.746746838092804, "camel_1817": 0.7475339770317078, "camel_42463": 0.7478339076042175, "camel_1779": 0.7481233477592468, "aqua_rat_2920": 0.7483890652656555, "camel_1771": 0.7500949501991272, "camel_1794": 0.7502745389938354, "camel_4258": 0.7507975697517395, "camel_38182": 0.7516255974769592, "camel_30252": 0.7517797946929932, "camel_36936": 0.7532784342765808, "camel_4302": 0.7545138597488403, "camel_1828": 0.7545499801635742, "camel_42457": 0.7551537752151489, "camel_1800": 0.7558016180992126, "camel_42438": 0.7558457851409912, "camel_28254": 0.7639253735542297, "camel_1769": 0.7665901780128479}, "TheoremQA_elainewan/math_algebra_4.json": {"camel_15918": 0, "camel_14254": 0, "camel_15320": 0, "camel_14173": 0, "camel_15321": 0, "camel_15641": 0, "camel_15398": 0, "camel_15727": 0, "camel_14317": 0, "camel_14250": 0, "camel_15556": 0, "camel_15620": 0, "camel_14163": 0, "camel_15682": 0, "camel_14273": 0, "camel_15356": 0, "camel_14799": 0, "camel_15755": 0, "camel_15619": 0, "camel_15729": 0, "camel_15283": 0, "camel_15654": 0, "camel_14318": 0, "camel_15678": 0, "camel_15624": 0, "camel_14020": 0, "camel_14171": 0, "camel_15621": 0, "camel_15667": 0, "camel_14164": 0, "camel_15746": 0, "camel_14259": 0, "camel_14190": 0, "camel_15728": 0, "camel_15645": 0, "camel_15629": 0, "camel_14185": 0, "camel_14180": 0, "camel_15911": 0, "camel_15615": 0, "camel_14232": 0, "camel_15622": 0, "camel_14268": 0, "camel_14218": 0, "camel_15648": 0, "camel_15636": 0, "camel_15851": 0, "camel_14193": 0, "camel_14229": 0, "camel_15666": 0, "camel_15995": 0, "camel_15639": 0, "camel_15853": 0, "camel_14295": 0, "camel_15669": 0, "camel_15849": 0, "camel_15637": 0, "camel_14215": 0, "camel_14213": 0, "camel_15431": 0, "camel_14459": 0, "camel_14242": 0, "camel_15304": 0, "camel_14304": 0, "camel_14162": 0, "camel_14000": 0, "camel_15582": 0, "camel_14070": 0, "camel_15757": 0, "camel_14487": 0, "camel_14220": 0, "camel_15904": 0, "camel_15868": 0, "camel_14238": 0, "camel_14209": 0, "camel_15886": 0, "camel_14172": 0, "camel_15603": 0, "camel_14208": 0, "camel_14223": 0, "camel_14182": 0, "camel_14299": 0, "camel_14167": 0, "camel_14198": 0, "camel_14231": 0, "camel_15846": 0, "camel_15601": 0, "camel_15680": 0, "camel_15307": 0, "camel_14201": 0, "camel_14187": 0, "camel_15604": 0, "camel_15628": 0, "camel_14210": 0, "camel_15653": 0, "camel_15659": 0, "camel_14207": 0, "camel_15717": 0, "camel_15602": 0, "camel_15308": 0, "camel_14206": 0, "camel_15751": 0, "camel_15627": 0, "camel_15675": 0, "camel_15676": 0, "camel_15687": 0, "camel_15720": 0, "camel_15635": 0, "camel_14197": 0, "camel_15679": 0, "camel_14267": 0, "camel_15613": 0, "camel_15749": 0, "camel_15630": 0, "camel_15657": 0, "camel_15745": 0, "camel_14884": 0, "camel_15647": 0, "camel_15663": 0, "camel_14216": 0, "camel_15295": 0, "TheoremQA_elainewan/math_algebra_4.json": 0, "camel_15875": 0, "camel_14174": 0, "camel_14188": 0, "camel_14239": 0, "camel_15665": 0, "camel_14199": 0, "camel_15633": 0, "camel_14234": 0, "camel_15625": 0, "camel_15608": 0, "camel_15928": 0, "camel_14219": 0, "camel_15651": 0, "camel_14205": 0, "camel_15631": 0, "camel_14227": 0, "camel_14189": 0, "camel_15691": 0, "camel_15707": 0, "camel_15696": 0, "camel_15656": 0, "camel_15644": 0, "camel_14214": 0, "camel_15901": 0, "camel_14194": 0, "camel_15638": 0, "camel_15610": 0, "camel_15747": 0, "camel_14184": 0, "camel_15642": 0, "camel_14212": 0, "camel_14160": 0, "camel_14176": 0, "camel_14161": 0, "camel_14183": 0, "camel_14225": 0, "camel_15329": 0, "camel_14166": 0, "camel_15759": 0, "camel_14236": 0, "camel_14222": 0, "camel_14170": 0, "camel_14235": 0, "camel_14178": 0, "camel_14192": 0, "camel_15661": 0, "camel_14211": 0, "camel_14196": 0, "camel_14307": 0, "camel_14169": 0, "camel_14165": 0, "camel_14181": 0, "camel_14179": 0, "camel_14186": 0, "camel_15646": 0, "camel_14195": 0, "camel_14204": 0, "camel_14168": 0, "camel_14233": 0, "camel_14191": 0, "camel_14261": 0, "camel_14228": 0, "camel_14230": 0, "camel_14217": 0, "camel_14175": 0, "camel_14224": 0, "camel_14237": 0, "camel_14200": 0, "camel_14203": 0, "TheoremQA_elainewan/math_algebra_3_5.json": 0.7389376163482666, "camel_40031": 0.7400630712509155, "TheoremQA_elainewan/math_algebra_3.json": 0.7427179217338562, "TheoremQA_mingyin/gaussian-elimination1.json": 0.7461342215538025, "camel_49885": 0.7466461062431335, "math_train_counting_and_probability_5032": 0.7468647956848145, "TheoremQA_elainewan/math_algebra_2.json": 0.7472209930419922, "TheoremQA_mingyin/gaussian-elimination2.json": 0.7521094679832458, "camel_49871": 0.7579764723777771}, "TheoremQA_wenhuchen/optics7.json": {"TheoremQA_wenhuchen/optics7.json": 0, "aqua_rat_21925": 0.6535820364952087, "camel_5344": 0.6536545753479004, "aqua_rat_18320": 0.6538652777671814, "camel_19728": 0.6539777517318726, "camel_3750": 0.6540364027023315, "camel_19781": 0.6541802883148193, "camel_19694": 0.6543715596199036, "aqua_rat_50400": 0.6544823050498962, "camel_47786": 0.6545573472976685, "camel_30259": 0.6548933386802673, "camel_30786": 0.6550309658050537, "aqua_rat_83008": 0.6550406813621521, "aqua_rat_12240": 0.6551433205604553, "camel_30740": 0.6552356481552124, "camel_47760": 0.6554042100906372, "aqua_rat_35903": 0.6554089188575745, "camel_30730": 0.6556432247161865, "camel_30180": 0.6556529402732849, "camel_30744": 0.6557931900024414, "aqua_rat_40900": 0.6558668613433838, "aqua_rat_68112": 0.6559890508651733, "camel_46306": 0.6561523079872131, "aqua_rat_59927": 0.6564244031906128, "camel_46152": 0.6566221117973328, "aqua_rat_30549": 0.6567132472991943, "camel_46274": 0.6573036313056946, "aqua_rat_71386": 0.6573073863983154, "aqua_rat_22245": 0.6573789715766907, "aqua_rat_68735": 0.6575523614883423, "camel_42116": 0.6576845049858093, "camel_46700": 0.6578376293182373, "aqua_rat_35129": 0.6581248044967651, "camel_28143": 0.6584112048149109, "aqua_rat_7575": 0.6586617231369019, "camel_47437": 0.65870600938797, "gsm_rft_26574": 0.6587113738059998, "aqua_rat_42444": 0.6588082909584045, "aqua_rat_28463": 0.6588629484176636, "camel_30767": 0.6588990092277527, "gsm_rft_34396": 0.658899188041687, "gsm_train_2639": 0.658899188041687, "aqua_rat_57525": 0.6589379906654358, "aqua_rat_43085": 0.6589815020561218, "math_train_prealgebra_737": 0.6591066718101501, "camel_46137": 0.659273087978363, "camel_31459": 0.6597217917442322, "aqua_rat_16864": 0.6597506999969482, "aqua_rat_50390": 0.659991979598999, "gsm_rft_14372": 0.6599941849708557, "gsm_train_18349": 0.6599941849708557, "gsm_rft_16470": 0.6599941849708557, "camel_46148": 0.6602705121040344, "aqua_rat_71933": 0.660320520401001, "aqua_rat_45615": 0.6603795289993286, "camel_30723": 0.6605231761932373, "aqua_rat_46515": 0.6605557799339294, "camel_19687": 0.660966157913208, "camel_47492": 0.6611083149909973, "camel_46165": 0.6612105369567871, "camel_30721": 0.6614335775375366, "gsm_rft_2452": 0.6614391207695007, "camel_30797": 0.6614517569541931, "camel_30788": 0.6615554690361023, "aqua_rat_29376": 0.6615719199180603, "camel_19685": 0.661632239818573, "gsm_rft_11031": 0.6616780757904053, "gsm_rft_17551": 0.661820650100708, "gsm_train_17819": 0.661820650100708, "math_test_geometry_658": 0.6618481278419495, "camel_30766": 0.6618871092796326, "math_train_prealgebra_725": 0.6619530320167542, "gsm_rft_9344": 0.6622694134712219, "camel_46128": 0.662478506565094, "math_train_prealgebra_1919": 0.6626391410827637, "aqua_rat_37605": 0.6630094647407532, "camel_30795": 0.6633719801902771, "camel_30211": 0.6634487509727478, "camel_31104": 0.6638979911804199, "camel_30722": 0.6641010642051697, "camel_30208": 0.6642157435417175, "camel_47813": 0.6650446653366089, "camel_46101": 0.665713906288147, "gsm_rft_7733": 0.6663306355476379, "camel_47387": 0.6663394570350647, "math_train_geometry_1": 0.6665328145027161, "camel_30727": 0.6666699647903442, "camel_19713": 0.6668257117271423, "camel_46180": 0.6674898862838745, "gsm_train_19077": 0.667652428150177, "gsm_rft_17748": 0.667652428150177, "camel_28260": 0.6677613258361816, "camel_30206": 0.6684343814849854, "camel_30244": 0.6684444546699524, "camel_46661": 0.6684902310371399, "camel_28265": 0.6685764193534851, "gsm_rft_11238": 0.669218122959137, "gsm_rft_14108": 0.6693986058235168, "camel_19717": 0.6694040298461914, "camel_46281": 0.669437050819397, "camel_30763": 0.6694591641426086, "camel_46190": 0.6696160435676575, "aqua_rat_86007": 0.6696449518203735, "gsm_train_25539": 0.6696490049362183, "gsm_rft_22460": 0.6696490049362183, "camel_3701": 0.6701187491416931, "gsm_rft_20209": 0.6702530980110168, "gsm_train_22328": 0.6702530980110168, "gsm_rft_3001": 0.6702530980110168, "gsm_rft_15709": 0.6703061461448669, "camel_19735": 0.6703172326087952, "math_train_prealgebra_702": 0.6704035997390747, "aqua_rat_32925": 0.6705446243286133, "gsm_rft_9443": 0.6705769896507263, "gsm_rft_11235": 0.6708652377128601, "gsm_train_21228": 0.6708652377128601, "camel_30724": 0.6712736487388611, "aqua_rat_24388": 0.6713702082633972, "camel_30726": 0.6713945865631104, "aqua_rat_81968": 0.6714540719985962, "aqua_rat_54504": 0.6718448400497437, "math_test_algebra_1169": 0.6718460321426392, "gsm_rft_34183": 0.672046422958374, "camel_30791": 0.6721512675285339, "gsm_train_5611": 0.6722880005836487, "gsm_rft_13092": 0.6725319027900696, "gsm_rft_9484": 0.6725319027900696, "gsm_rft_33234": 0.6728301048278809, "aqua_rat_1854": 0.6732105016708374, "aqua_rat_38758": 0.6733227372169495, "camel_30745": 0.6736124753952026, "camel_46083": 0.6736900210380554, "camel_30232": 0.6738595366477966, "camel_30167": 0.6740122437477112, "math_train_geometry_583": 0.6740368008613586, "gsm_rft_8311": 0.6743932366371155, "aqua_rat_6220": 0.6746441721916199, "gsm_rft_3570": 0.674813449382782, "camel_47380": 0.6751365065574646, "camel_19752": 0.6751493215560913, "camel_46285": 0.6751564741134644, "aqua_rat_78573": 0.6751779317855835, "aqua_rat_60403": 0.6753094792366028, "aqua_rat_17798": 0.6754946112632751, "aqua_rat_38896": 0.6755094528198242, "math_train_algebra_2034": 0.6756371259689331, "camel_30733": 0.6758010983467102, "camel_46203": 0.6762160062789917, "camel_19768": 0.6763084530830383, "aqua_rat_64993": 0.6764858365058899, "aqua_rat_45660": 0.6767417192459106, "camel_19751": 0.6768619418144226, "aqua_rat_36642": 0.6773198843002319, "camel_30736": 0.677457869052887, "camel_30293": 0.6791417002677917, "camel_30729": 0.6795424222946167, "aqua_rat_23397": 0.6796818971633911, "camel_30794": 0.6803780198097229, "camel_30762": 0.6816301345825195, "camel_30776": 0.6822779774665833, "camel_30764": 0.6826097369194031, "aqua_rat_6676": 0.6834015250205994, "camel_30751": 0.6839346289634705, "camel_46100": 0.6847798228263855, "camel_30799": 0.6855405569076538, "camel_30768": 0.6859167218208313, "camel_46220": 0.6862697005271912, "camel_30783": 0.687023937702179, "camel_47371": 0.6873738765716553, "camel_46273": 0.6877276301383972, "camel_46253": 0.6879923343658447, "camel_19784": 0.688757061958313, "camel_30260": 0.6902340054512024, "aqua_rat_74461": 0.6912698745727539, "aqua_rat_22739": 0.6919443607330322, "aqua_rat_27170": 0.6920518279075623, "camel_30780": 0.6921007633209229, "camel_30753": 0.692269504070282, "camel_30725": 0.6930658221244812, "aqua_rat_70142": 0.6937957406044006, "camel_30781": 0.6938601136207581, "camel_46295": 0.6943610906600952, "camel_30796": 0.6943885087966919, "camel_30779": 0.6951006650924683, "aqua_rat_10339": 0.6952383518218994, "camel_19754": 0.6962505578994751, "camel_30731": 0.6972925662994385, "camel_30750": 0.6985322833061218, "camel_30798": 0.6989679932594299, "camel_30774": 0.6994950771331787, "camel_28271": 0.7002384662628174, "camel_30746": 0.7050699591636658, "camel_46280": 0.7059174180030823, "camel_30728": 0.7067609429359436, "camel_30741": 0.7129080295562744, "camel_30782": 0.7151716947555542, "aqua_rat_59988": 0.7172612547874451, "TheoremQA_wenhuchen/optics3.json": 0.729569673538208, "TheoremQA_wenhuchen/optics2.json": 0.7366029024124146, "camel_47373": 0.7395514845848083}, "TheoremQA_elainewan/math_calculus_2_5.json": {"camel_6817": 0, "math_test_precalculus_893": 0, "camel_6801": 0, "aqua_rat_68267": 0.734113335609436, "camel_4390": 0.734169602394104, "camel_39304": 0.7342419028282166, "camel_1809": 0.7342448234558105, "camel_5205": 0.7343384623527527, "camel_43907": 0.7344913482666016, "camel_16264": 0.7345884442329407, "camel_28816": 0.7346298098564148, "camel_5235": 0.734883725643158, "camel_28869": 0.7349531054496765, "camel_29046": 0.7350133061408997, "camel_1826": 0.7350378632545471, "camel_5026": 0.7351638674736023, "camel_1814": 0.7353467345237732, "camel_42438": 0.7353932857513428, "camel_5260": 0.7356038093566895, "camel_16245": 0.7358071804046631, "camel_4240": 0.7359710931777954, "camel_28851": 0.7361742258071899, "camel_5278": 0.7361981272697449, "camel_4335": 0.7362078428268433, "camel_16249": 0.7363144159317017, "camel_1772": 0.7364392280578613, "camel_16279": 0.7365025281906128, "camel_4391": 0.736586332321167, "camel_29962": 0.7367172241210938, "camel_28813": 0.7367889285087585, "camel_5119": 0.7369598746299744, "camel_5274": 0.7371233105659485, "camel_5153": 0.7372134923934937, "camel_16267": 0.7372242212295532, "camel_1803": 0.7372273206710815, "camel_16262": 0.7372655272483826, "camel_5126": 0.7374745011329651, "camel_5037": 0.7375843524932861, "camel_28800": 0.737903356552124, "camel_1815": 0.7382132411003113, "camel_28875": 0.73841792345047, "camel_5220": 0.7385740876197815, "camel_4280": 0.7386306524276733, "camel_5174": 0.7388347387313843, "camel_5104": 0.7389492988586426, "camel_16258": 0.7389585971832275, "camel_4357": 0.7392099499702454, "camel_28820": 0.739238977432251, "camel_16256": 0.7394320964813232, "camel_4261": 0.7403137683868408, "camel_29860": 0.7405092716217041, "camel_5109": 0.7406426668167114, "camel_28860": 0.7407187223434448, "camel_4292": 0.7407439947128296, "camel_16307": 0.7408621907234192, "camel_5125": 0.741132915019989, "camel_16243": 0.7412473559379578, "camel_16316": 0.7412633895874023, "camel_5025": 0.7413100600242615, "camel_16291": 0.7414997816085815, "camel_5006": 0.7415997982025146, "camel_45293": 0.7419253587722778, "camel_16300": 0.7420092821121216, "camel_16288": 0.7421615123748779, "camel_5356": 0.7423229813575745, "camel_5085": 0.7426708936691284, "camel_5118": 0.7431146502494812, "camel_17390": 0.7432670593261719, "camel_28824": 0.7436840534210205, "aqua_rat_28088": 0.7440606951713562, "camel_29060": 0.7440703511238098, "camel_1779": 0.7442190051078796, "camel_5178": 0.7442486882209778, "camel_16257": 0.7443386912345886, "camel_28842": 0.7445555329322815, "camel_5210": 0.7447018623352051, "camel_28254": 0.7451092004776001, "camel_4998": 0.7454579472541809, "camel_5246": 0.7457067966461182, "camel_16290": 0.7458698153495789, "camel_4352": 0.7463024854660034, "camel_16263": 0.7464703321456909, "camel_16294": 0.746681809425354, "camel_5042": 0.7467151284217834, "TheoremQA_elainewan/math_calculus_12.json": 0.7468100786209106, "camel_1777": 0.7472313642501831, "camel_39292": 0.7473202347755432, "camel_5062": 0.7474138736724854, "camel_39489": 0.7476097941398621, "camel_4993": 0.7476671934127808, "camel_4258": 0.7476822137832642, "camel_28828": 0.7477493286132812, "camel_16273": 0.7478362321853638, "TheoremQA_elainewan/math_calculus_2_6.json": 0.7479386329650879, "camel_16242": 0.7483838796615601, "camel_4269": 0.7484208345413208, "camel_16250": 0.7490394711494446, "camel_28532": 0.749642550945282, "camel_4285": 0.7496758699417114, "camel_28809": 0.7498590350151062, "camel_45342": 0.749901294708252, "camel_5081": 0.7503606677055359, "camel_5272": 0.750450611114502, "camel_1834": 0.7504968047142029, "camel_5267": 0.7505490779876709, "camel_5373": 0.7511528730392456, "camel_5024": 0.7511639595031738, "camel_29195": 0.7513770461082458, "camel_16317": 0.7515941262245178, "camel_17436": 0.7520719170570374, "camel_5050": 0.752098560333252, "camel_4960": 0.7526735663414001, "camel_28840": 0.7527932524681091, "camel_5058": 0.7528012990951538, "camel_5138": 0.7528069019317627, "camel_4311": 0.7530530691146851, "camel_1824": 0.7531501650810242, "camel_5078": 0.7531798481941223, "camel_4967": 0.7535459995269775, "camel_5045": 0.7536056637763977, "camel_16268": 0.7543072700500488, "camel_5134": 0.7543740272521973, "camel_39338": 0.7549183368682861, "camel_39327": 0.7549493312835693, "camel_5084": 0.7553005218505859, "camel_5089": 0.7553123831748962, "camel_5116": 0.7554425597190857, "camel_5198": 0.7557901740074158, "camel_16301": 0.7558048367500305, "camel_5129": 0.7560451626777649, "camel_5338": 0.756777286529541, "camel_17422": 0.7567939162254333, "camel_16311": 0.7570623159408569, "camel_16280": 0.7573696374893188, "camel_5311": 0.7575563788414001, "camel_5185": 0.7576550841331482, "camel_5077": 0.7578293681144714, "camel_5048": 0.7582010626792908, "camel_5035": 0.7585104703903198, "camel_16241": 0.7587400078773499, "camel_5333": 0.7591724395751953, "camel_5111": 0.7595430016517639, "camel_5076": 0.7596330046653748, "camel_5080": 0.7597389817237854, "camel_16240": 0.7605469822883606, "camel_16251": 0.7610095739364624, "camel_5358": 0.7615043520927429, "camel_5115": 0.7616527676582336, "camel_5083": 0.7617107033729553, "camel_5103": 0.7621473670005798, "camel_5057": 0.7621551156044006, "camel_5113": 0.7623891234397888, "camel_16298": 0.764192521572113, "camel_4968": 0.7643257975578308, "camel_5051": 0.7643445730209351, "camel_5068": 0.7644357085227966, "camel_16284": 0.7644477486610413, "camel_5047": 0.7644850015640259, "camel_5066": 0.7651033401489258, "camel_5014": 0.7653405666351318, "camel_44694": 0.7657694816589355, "camel_28137": 0.7658854126930237, "camel_5197": 0.7665788531303406, "camel_29198": 0.7669540047645569, "camel_5063": 0.7670057415962219, "camel_17389": 0.7678349018096924, "camel_5098": 0.76829993724823, "camel_5059": 0.7683186531066895, "camel_17406": 0.7687289714813232, "camel_5005": 0.769502580165863, "camel_5117": 0.7707861065864563, "camel_5189": 0.771181583404541, "camel_5334": 0.7738125920295715, "camel_5177": 0.7754987478256226, "camel_4965": 0.7761824727058411, "camel_5011": 0.7774984836578369, "camel_5055": 0.7779471278190613, "camel_5172": 0.7786557674407959, "camel_5227": 0.7801974415779114, "camel_1874": 0.780794620513916, "camel_5090": 0.7810173630714417, "camel_5158": 0.7813212871551514, "camel_5114": 0.7813609838485718, "camel_5165": 0.781376302242279, "camel_5181": 0.7814382314682007, "camel_5065": 0.7815478444099426, "camel_5180": 0.785361647605896, "camel_5188": 0.7870537638664246, "camel_28080": 0.7876452207565308, "camel_5079": 0.7888649106025696, "camel_5070": 0.7903750538825989, "camel_5008": 0.7905590534210205, "camel_5043": 0.7931053638458252, "camel_5041": 0.7974602580070496, "camel_5093": 0.7974951267242432, "camel_5094": 0.798011302947998, "camel_28086": 0.7990608811378479, "camel_5092": 0.8049514889717102, "camel_5029": 0.8195109963417053, "camel_4986": 0.8218211531639099}, "TheoremQA_wenhuchen/gauss_lemma.json": {"camel_12930": 0, "camel_12771": 0, "camel_12085": 0, "camel_12789": 0, "camel_12196": 0, "camel_12765": 0, "camel_12763": 0, "camel_12736": 0, "camel_12720": 0, "camel_13252": 0, "camel_12726": 0, "camel_13754": 0, "camel_12739": 0, "camel_12741": 0, "camel_12194": 0, "camel_12798": 0, "camel_12776": 0, "camel_12747": 0, "camel_12780": 0, "camel_12730": 0, "camel_12777": 0, "camel_12596": 0, "camel_12772": 0, "camel_12809": 0, "camel_12735": 0, "camel_13471": 0, "camel_12200": 0, "camel_12778": 0, "camel_12756": 0, "camel_12752": 0, "camel_13201": 0, "camel_12744": 0, "camel_12788": 0, "camel_12832": 0, "camel_12728": 0, "camel_12878": 0, "camel_12787": 0, "camel_12764": 0, "camel_12742": 0, "camel_12748": 0, "camel_12818": 0, "camel_12725": 0, "camel_12775": 0, "camel_13465": 0, "camel_12759": 0, "camel_12769": 0, "camel_13455": 0, "camel_13878": 0, "camel_13661": 0, "camel_12722": 0, "camel_12795": 0, "camel_12842": 0, "camel_12785": 0, "camel_12864": 0, "camel_12734": 0, "camel_12824": 0, "camel_12746": 0, "camel_12749": 0, "camel_12799": 0, "camel_12822": 0, "camel_12590": 0, "camel_12750": 0, "camel_12723": 0, "camel_13695": 0, "camel_12751": 0, "camel_12761": 0, "camel_12786": 0, "camel_12819": 0, "camel_12849": 0, "camel_12770": 0, "camel_12839": 0, "camel_12808": 0, "camel_12743": 0, "camel_12868": 0, "camel_12737": 0, "camel_12738": 0, "camel_12757": 0, "camel_12843": 0, "camel_12755": 0, "TheoremQA_wenhuchen/gauss_lemma.json": 0, "camel_12820": 0, "camel_12856": 0, "camel_12828": 0, "camel_12825": 0, "camel_12838": 0, "camel_12862": 0, "camel_12860": 0, "camel_12815": 0, "camel_12850": 0, "camel_12837": 0, "camel_12831": 0, "camel_12170": 0, "camel_12872": 0, "camel_12807": 0, "camel_12870": 0, "camel_12848": 0, "camel_12811": 0, "camel_12873": 0, "camel_12866": 0, "camel_12802": 0, "camel_12854": 0, "camel_12840": 0, "camel_12804": 0, "camel_12844": 0, "camel_12817": 0, "camel_12208": 0, "camel_12779": 0, "camel_12914": 0, "camel_12816": 0, "camel_12806": 0, "camel_12176": 0, "camel_12874": 0, "camel_12869": 0, "camel_12184": 0, "camel_12814": 0, "camel_12880": 0, "camel_12827": 0, "camel_12846": 0, "camel_12833": 0, "camel_12847": 0, "camel_12858": 0, "camel_12877": 0, "camel_12857": 0, "camel_12834": 0, "camel_12851": 0, "camel_12823": 0, "camel_12836": 0, "camel_12875": 0, "camel_12812": 0, "camel_12801": 0, "camel_12813": 0, "camel_12810": 0, "camel_12805": 0, "camel_12861": 0, "camel_12879": 0, "camel_12859": 0, "camel_12865": 0, "camel_12830": 0, "camel_12852": 0, "camel_12867": 0, "camel_12835": 0, "camel_12855": 0, "camel_12821": 0, "camel_13636": 0, "camel_12841": 0, "camel_12853": 0, "camel_12863": 0, "camel_12803": 0, "camel_12876": 0, "camel_12826": 0, "camel_12871": 0, "camel_12800": 0, "aqua_rat_24975": 0.7228400707244873, "aqua_rat_44439": 0.7229270935058594, "math_train_number_theory_885": 0.7239695191383362, "math_test_number_theory_574": 0.7240272164344788, "aqua_rat_74384": 0.7241601943969727, "math_train_number_theory_1113": 0.7241696119308472, "math_test_number_theory_1060": 0.724265456199646, "math_test_number_theory_554": 0.7246875762939453, "math_train_number_theory_617": 0.7247522473335266, "camel_48943": 0.7249059677124023, "math_test_number_theory_757": 0.725519597530365, "camel_26371": 0.7268695831298828, "camel_26093": 0.7280019521713257, "aqua_rat_9401": 0.7280383706092834, "camel_26179": 0.7280392646789551, "camel_26115": 0.729489803314209, "math_train_number_theory_1079": 0.7298421859741211, "aqua_rat_3156": 0.7298762798309326, "aqua_rat_10127": 0.7302129864692688, "aqua_rat_61608": 0.7321897149085999, "math_train_number_theory_242": 0.7330511212348938, "aqua_rat_29597": 0.7349581122398376, "camel_26348": 0.7364020347595215, "aqua_rat_88443": 0.738400936126709, "aqua_rat_82897": 0.7392928600311279, "math_train_number_theory_899": 0.7404705882072449, "aqua_rat_11083": 0.7405099272727966, "camel_26380": 0.7416185140609741, "math_train_number_theory_568": 0.7438305020332336, "math_test_number_theory_1128": 0.7469260692596436, "camel_37393": 0.7522658705711365, "aqua_rat_28035": 0.7542267441749573, "camel_26051": 0.7542775869369507, "aqua_rat_51863": 0.7567845582962036, "aqua_rat_22189": 0.7569360733032227, "math_train_number_theory_890": 0.7586846351623535, "aqua_rat_24283": 0.7627517580986023, "aqua_rat_69927": 0.7666787505149841, "aqua_rat_60360": 0.7670885324478149, "aqua_rat_15929": 0.7684807777404785, "TheoremQA_wenhuchen/gauss_lemma2.json": 0.7708768248558044, "aqua_rat_61707": 0.7712934017181396, "aqua_rat_17168": 0.7743467092514038, "aqua_rat_50295": 0.7767975330352783, "aqua_rat_1010": 0.7771193981170654, "aqua_rat_9910": 0.7817542552947998, "aqua_rat_75586": 0.7932049632072449, "aqua_rat_48398": 0.7952330112457275}, "TheoremQA_xueguangma/dividend_discount_model_2.json": {"TheoremQA_xueguangma/dividend_discount_model_2.json": 0, "aqua_rat_70690": 0.717073380947113, "aqua_rat_52815": 0.7172614932060242, "aqua_rat_31357": 0.7172820568084717, "aqua_rat_33801": 0.7173250913619995, "gsm_train_4606": 0.7174091935157776, "aqua_rat_71424": 0.7174559235572815, "aqua_rat_53735": 0.7174705862998962, "gsm_rft_32633": 0.717511773109436, "aqua_rat_9965": 0.7175852656364441, "aqua_rat_23417": 0.7175878882408142, "aqua_rat_20879": 0.7176337838172913, "gsm_rft_34608": 0.717644214630127, "aqua_rat_28151": 0.7177090644836426, "gsm_rft_29688": 0.7180265784263611, "gsm_rft_25984": 0.7182585597038269, "gsm_train_2036": 0.7182642817497253, "gsm_rft_29507": 0.7182642817497253, "gsm_rft_31139": 0.7182642817497253, "aqua_rat_51196": 0.7182732820510864, "gsm_rft_15927": 0.7183330059051514, "gsm_rft_27310": 0.7183591723442078, "gsm_train_18348": 0.7183591723442078, "gsm_rft_26823": 0.7184703946113586, "gsm_rft_1922": 0.7187332510948181, "gsm_train_32842": 0.7187332510948181, "aqua_rat_81085": 0.7187532782554626, "aqua_rat_37519": 0.718799352645874, "gsm_rft_21887": 0.718937873840332, "gsm_rft_13417": 0.7190287709236145, "aqua_rat_7346": 0.7193505167961121, "gsm_rft_12671": 0.7195984721183777, "camel_25615": 0.7196193337440491, "aqua_rat_8676": 0.7196630835533142, "aqua_rat_87884": 0.7197063565254211, "aqua_rat_47825": 0.7197075486183167, "gsm_rft_13224": 0.7197327613830566, "gsm_rft_15345": 0.7197327613830566, "gsm_train_6234": 0.7197327613830566, "aqua_rat_10392": 0.7199254035949707, "aqua_rat_14073": 0.7200751900672913, "aqua_rat_63": 0.7201140522956848, "aqua_rat_73581": 0.7201943397521973, "gsm_rft_10252": 0.7203332185745239, "aqua_rat_26935": 0.7203617095947266, "gsm_rft_31372": 0.720379650592804, "gsm_train_4730": 0.720379650592804, "aqua_rat_8756": 0.7205191850662231, "aqua_rat_26449": 0.7205387353897095, "gsm_rft_29492": 0.7207004427909851, "gsm_rft_30004": 0.7207004427909851, "gsm_train_28049": 0.7207004427909851, "aqua_rat_48285": 0.720719575881958, "aqua_rat_83354": 0.7207500338554382, "gsm_rft_31153": 0.7207835912704468, "gsm_train_27641": 0.7207835912704468, "aqua_rat_51287": 0.7208257913589478, "gsm_rft_3769": 0.7209120392799377, "aqua_rat_18140": 0.72111976146698, "gsm_rft_32408": 0.7211979031562805, "gsm_rft_23935": 0.7212159037590027, "gsm_train_24637": 0.7212159037590027, "gsm_train_14821": 0.7213760614395142, "gsm_rft_34606": 0.7214565873146057, "gsm_rft_27770": 0.7214628458023071, "aqua_rat_9160": 0.7214935421943665, "gsm_train_14713": 0.7216160297393799, "gsm_rft_9880": 0.721834123134613, "aqua_rat_54292": 0.7219098806381226, "gsm_rft_4462": 0.7219176292419434, "gsm_rft_23947": 0.7219288945198059, "aqua_rat_49263": 0.7219474911689758, "camel_45738": 0.721985936164856, "aqua_rat_64914": 0.7220550179481506, "gsm_rft_16238": 0.722782552242279, "gsm_train_9850": 0.722782552242279, "aqua_rat_27464": 0.7232453227043152, "gsm_rft_27170": 0.7232527732849121, "gsm_train_1402": 0.7232527732849121, "gsm_rft_5694": 0.7232527732849121, "aqua_rat_37786": 0.7239006757736206, "gsm_rft_25913": 0.723953902721405, "aqua_rat_24355": 0.724073588848114, "gsm_rft_2115": 0.7241043448448181, "aqua_rat_17685": 0.724128782749176, "gsm_rft_28977": 0.7242847681045532, "gsm_rft_35442": 0.724503755569458, "gsm_rft_3422": 0.7245173454284668, "gsm_rft_30423": 0.7248173952102661, "camel_8618": 0.724897027015686, "aqua_rat_46293": 0.7249016165733337, "aqua_rat_66646": 0.7249435782432556, "gsm_rft_5809": 0.7251603603363037, "aqua_rat_71966": 0.7257987260818481, "gsm_train_23925": 0.7259202599525452, "aqua_rat_22679": 0.7259507179260254, "gsm_rft_3126": 0.7259963750839233, "TheoremQA_xueguangma/present_value_2.json": 0.7260645031929016, "aqua_rat_53674": 0.7260668873786926, "gsm_rft_13670": 0.7261053919792175, "gsm_rft_5073": 0.7261171936988831, "gsm_rft_21369": 0.7261577844619751, "aqua_rat_506": 0.7262865304946899, "gsm_rft_31049": 0.72640061378479, "gsm_train_25772": 0.7264971137046814, "gsm_rft_31412": 0.7266544699668884, "aqua_rat_70338": 0.7266719937324524, "gsm_rft_32019": 0.7268701791763306, "gsm_rft_13721": 0.7269171476364136, "gsm_rft_15258": 0.7271714806556702, "aqua_rat_940": 0.7274438738822937, "aqua_rat_44929": 0.7277920246124268, "gsm_rft_2946": 0.7279112935066223, "gsm_train_29223": 0.7279950380325317, "aqua_rat_29921": 0.7281740307807922, "gsm_rft_6751": 0.7282172441482544, "gsm_rft_29292": 0.7282314896583557, "aqua_rat_76433": 0.7284829616546631, "aqua_rat_19962": 0.7284883260726929, "gsm_train_34638": 0.7286149263381958, "aqua_rat_1447": 0.7286620736122131, "aqua_rat_7307": 0.7287185788154602, "aqua_rat_32485": 0.7292531728744507, "aqua_rat_71528": 0.7296466827392578, "aqua_rat_87481": 0.7298386096954346, "gsm_rft_23519": 0.7304671406745911, "aqua_rat_81348": 0.730480968952179, "TheoremQA_xueguangma/forward_price_3.json": 0.7306609153747559, "aqua_rat_15749": 0.7309815883636475, "aqua_rat_45706": 0.730992317199707, "aqua_rat_79704": 0.7312104105949402, "gsm_rft_35508": 0.7319360375404358, "aqua_rat_57386": 0.7320170998573303, "aqua_rat_40759": 0.7320348620414734, "aqua_rat_52474": 0.7320792078971863, "aqua_rat_7378": 0.7320893406867981, "aqua_rat_63668": 0.7321421504020691, "aqua_rat_79286": 0.7322100400924683, "aqua_rat_63344": 0.7322925329208374, "aqua_rat_8292": 0.732365071773529, "gsm_train_816": 0.732399582862854, "gsm_rft_29226": 0.7324399352073669, "aqua_rat_24626": 0.7324810028076172, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7325518131256104, "aqua_rat_11763": 0.7326608896255493, "gsm_rft_31378": 0.7334364652633667, "gsm_rft_1668": 0.7334680557250977, "gsm_train_16212": 0.7334680557250977, "aqua_rat_56930": 0.7335233092308044, "gsm_rft_34495": 0.7338545322418213, "TheoremQA_xueguangma/forward_price_2.json": 0.7343479990959167, "gsm_rft_13156": 0.7345814108848572, "aqua_rat_88687": 0.7347549200057983, "gsm_rft_13281": 0.734788715839386, "aqua_rat_79970": 0.7352393865585327, "aqua_rat_55843": 0.7354589104652405, "math_test_algebra_1043": 0.7354801297187805, "aqua_rat_24048": 0.7360310554504395, "gsm_rft_8605": 0.7361619472503662, "gsm_train_18514": 0.7363151907920837, "camel_8585": 0.7366193532943726, "gsm_rft_252": 0.7371218800544739, "aqua_rat_47789": 0.7381185293197632, "gsm_rft_24497": 0.7383678555488586, "gsm_rft_13162": 0.7384907007217407, "aqua_rat_10181": 0.7387043833732605, "gsm_rft_31203": 0.7387480735778809, "aqua_rat_42852": 0.7387591004371643, "aqua_rat_41782": 0.7389974594116211, "aqua_rat_71288": 0.7391723394393921, "aqua_rat_12799": 0.73920077085495, "aqua_rat_81401": 0.7396100163459778, "aqua_rat_16605": 0.740088701248169, "aqua_rat_13033": 0.7401179671287537, "aqua_rat_15950": 0.7412911653518677, "aqua_rat_67794": 0.7414145469665527, "aqua_rat_27035": 0.742145836353302, "gsm_rft_24082": 0.742685079574585, "aqua_rat_64922": 0.7428672909736633, "gsm_rft_23795": 0.7430694699287415, "aqua_rat_77486": 0.7431385517120361, "aqua_rat_16258": 0.7436459064483643, "gsm_rft_26543": 0.744047999382019, "gsm_rft_17816": 0.7440531849861145, "aqua_rat_56922": 0.7440608739852905, "gsm_rft_31288": 0.744399905204773, "aqua_rat_46842": 0.7444723844528198, "aqua_rat_87442": 0.7448900938034058, "TheoremQA_xueguangma/spot_rate.json": 0.744933545589447, "gsm_rft_20347": 0.7471680641174316, "gsm_train_374": 0.7471680641174316, "aqua_rat_23836": 0.7478547096252441, "gsm_rft_11850": 0.7499020099639893, "aqua_rat_47176": 0.7536971569061279, "camel_37686": 0.7541229128837585, "aqua_rat_19740": 0.756765604019165, "camel_37747": 0.7619460821151733, "TheoremQA_xueguangma/dividend_discount_model_4.json": 0.7897877097129822, "TheoremQA_xueguangma/dividend_discount_model_1.json": 0.7950701117515564, "TheoremQA_xueguangma/dividend_discount_model_5.json": 0.8199682235717773}, "TheoremQA_panlu/similarity2.json": {"math_train_geometry_350": 0, "math_train_geometry_809": 0, "TheoremQA_panlu/similarity2.json": 0, "math_train_geometry_804": 0, "math_train_geometry_272": 0, "aqua_rat_65713": 0.7677565217018127, "aqua_rat_68422": 0.7677785754203796, "aqua_rat_74800": 0.7677873969078064, "aqua_rat_11523": 0.7678260803222656, "aqua_rat_79913": 0.7679044008255005, "aqua_rat_29055": 0.7679235935211182, "aqua_rat_35946": 0.7679624557495117, "aqua_rat_9329": 0.7681044340133667, "aqua_rat_25578": 0.7682006359100342, "aqua_rat_65746": 0.7682023048400879, "aqua_rat_51865": 0.7682139277458191, "aqua_rat_86550": 0.7683441042900085, "aqua_rat_77813": 0.768439531326294, "aqua_rat_33493": 0.7684807777404785, "aqua_rat_51897": 0.7684949040412903, "aqua_rat_86522": 0.7686624526977539, "aqua_rat_63922": 0.7686720490455627, "aqua_rat_85008": 0.7687586545944214, "aqua_rat_12089": 0.7687985301017761, "aqua_rat_68945": 0.7688893675804138, "aqua_rat_32230": 0.7689204812049866, "aqua_rat_81632": 0.7690026164054871, "aqua_rat_4593": 0.7691739201545715, "aqua_rat_43036": 0.7693896889686584, "aqua_rat_2143": 0.769424319267273, "aqua_rat_45764": 0.7695072889328003, "aqua_rat_88892": 0.7695518136024475, "aqua_rat_84100": 0.7696772217750549, "aqua_rat_51855": 0.7697407603263855, "aqua_rat_38912": 0.7697503566741943, "aqua_rat_11988": 0.7699251770973206, "aqua_rat_33930": 0.77020263671875, "aqua_rat_48818": 0.7702626585960388, "aqua_rat_4059": 0.7703086137771606, "aqua_rat_8164": 0.7703810930252075, "aqua_rat_16725": 0.7704049944877625, "aqua_rat_3795": 0.7706158757209778, "aqua_rat_5546": 0.7706731557846069, "aqua_rat_21387": 0.7708249092102051, "aqua_rat_82542": 0.7708418369293213, "aqua_rat_542": 0.7709130644798279, "aqua_rat_60660": 0.7709953188896179, "aqua_rat_3761": 0.7710501551628113, "aqua_rat_4901": 0.7711333632469177, "aqua_rat_51497": 0.771197497844696, "gsm_train_20726": 0.7711989283561707, "gsm_rft_34362": 0.7712247371673584, "aqua_rat_73923": 0.7713128328323364, "aqua_rat_12761": 0.7714712023735046, "aqua_rat_36163": 0.7715449333190918, "aqua_rat_21994": 0.7716166377067566, "aqua_rat_23378": 0.7716276049613953, "aqua_rat_30114": 0.7716740965843201, "aqua_rat_28927": 0.7717340588569641, "aqua_rat_6553": 0.7717590928077698, "aqua_rat_56103": 0.7717970609664917, "aqua_rat_20257": 0.7718577980995178, "aqua_rat_83024": 0.7718708515167236, "aqua_rat_69379": 0.7721474766731262, "aqua_rat_66885": 0.7723410725593567, "aqua_rat_60637": 0.7723992466926575, "aqua_rat_27168": 0.7724732160568237, "aqua_rat_2157": 0.7725497484207153, "aqua_rat_39472": 0.7726972103118896, "aqua_rat_85451": 0.7727156281471252, "camel_28143": 0.7727195024490356, "aqua_rat_86286": 0.7727434039115906, "aqua_rat_58755": 0.7729278802871704, "aqua_rat_2266": 0.7730103731155396, "TheoremQA_panlu/similarity3.json": 0.7730609774589539, "math_train_prealgebra_94": 0.7734771966934204, "aqua_rat_15032": 0.7735084295272827, "aqua_rat_7577": 0.7735971212387085, "aqua_rat_50372": 0.7737943530082703, "aqua_rat_51650": 0.7738721370697021, "aqua_rat_38464": 0.7739433646202087, "aqua_rat_38015": 0.7741801738739014, "aqua_rat_70572": 0.7741862535476685, "aqua_rat_66074": 0.7743914723396301, "aqua_rat_56299": 0.7746590375900269, "aqua_rat_74307": 0.7746634483337402, "aqua_rat_44869": 0.7747068405151367, "aqua_rat_25892": 0.7747101783752441, "aqua_rat_80152": 0.7747377157211304, "aqua_rat_43685": 0.7747443914413452, "aqua_rat_40813": 0.7749193906784058, "aqua_rat_964": 0.7750101089477539, "aqua_rat_35944": 0.7750603556632996, "aqua_rat_73351": 0.7751591801643372, "aqua_rat_55386": 0.7753878831863403, "aqua_rat_77049": 0.7754876613616943, "aqua_rat_17759": 0.7755773663520813, "aqua_rat_25987": 0.775814414024353, "aqua_rat_81993": 0.7760846018791199, "aqua_rat_82594": 0.7764177322387695, "aqua_rat_21115": 0.7764298319816589, "camel_4808": 0.7764990925788879, "aqua_rat_20301": 0.7765313386917114, "aqua_rat_2623": 0.776544451713562, "aqua_rat_56720": 0.7765491008758545, "aqua_rat_62201": 0.7765839099884033, "aqua_rat_58158": 0.7768667340278625, "aqua_rat_53846": 0.7768728733062744, "aqua_rat_45053": 0.7769020199775696, "aqua_rat_25937": 0.7771993279457092, "aqua_rat_69773": 0.7773608565330505, "aqua_rat_23211": 0.7774625420570374, "aqua_rat_50091": 0.7778380513191223, "gsm_rft_13575": 0.7779979705810547, "aqua_rat_61499": 0.7783652544021606, "aqua_rat_72078": 0.7785059213638306, "aqua_rat_79657": 0.7785067558288574, "aqua_rat_68372": 0.7786164879798889, "aqua_rat_79675": 0.7790599465370178, "aqua_rat_38676": 0.7790858745574951, "aqua_rat_41689": 0.779252827167511, "aqua_rat_82212": 0.7795427441596985, "aqua_rat_11086": 0.7796667218208313, "aqua_rat_84836": 0.7798502445220947, "aqua_rat_83857": 0.7798644304275513, "aqua_rat_73789": 0.7798689603805542, "aqua_rat_47718": 0.7800707221031189, "math_test_prealgebra_1839": 0.7804346680641174, "aqua_rat_22059": 0.7805529236793518, "aqua_rat_22618": 0.7807053327560425, "aqua_rat_57998": 0.7807489037513733, "aqua_rat_6677": 0.780892550945282, "aqua_rat_6539": 0.7812860608100891, "aqua_rat_76082": 0.7819637060165405, "camel_30449": 0.7821096777915955, "aqua_rat_4256": 0.7821970582008362, "aqua_rat_2283": 0.7824659943580627, "aqua_rat_44741": 0.7826043963432312, "aqua_rat_73119": 0.7829288840293884, "aqua_rat_28791": 0.7835367321968079, "aqua_rat_7754": 0.7836998105049133, "aqua_rat_81450": 0.7838440537452698, "aqua_rat_63134": 0.7843228578567505, "gsm_rft_14372": 0.7845475673675537, "gsm_train_18349": 0.7845475673675537, "gsm_rft_16470": 0.7845475673675537, "aqua_rat_79604": 0.7847623825073242, "aqua_rat_19916": 0.7848122715950012, "aqua_rat_13271": 0.7853569388389587, "aqua_rat_41026": 0.7854356169700623, "aqua_rat_76238": 0.7854527235031128, "gsm_rft_20209": 0.7857444882392883, "gsm_train_22328": 0.7857444882392883, "gsm_rft_3001": 0.7857444882392883, "math_train_prealgebra_1919": 0.7859387397766113, "aqua_rat_69962": 0.786054253578186, "aqua_rat_18718": 0.7862505912780762, "aqua_rat_20319": 0.7863420844078064, "aqua_rat_31385": 0.7863588333129883, "aqua_rat_6785": 0.7865576148033142, "aqua_rat_30186": 0.7867687344551086, "aqua_rat_38963": 0.7872312664985657, "aqua_rat_74046": 0.7874244451522827, "aqua_rat_9227": 0.7874889969825745, "aqua_rat_6915": 0.7881325483322144, "camel_4737": 0.7892889380455017, "camel_18647": 0.7898908257484436, "aqua_rat_66436": 0.789969265460968, "aqua_rat_19464": 0.793148398399353, "aqua_rat_13043": 0.7956463098526001, "aqua_rat_51406": 0.7963368892669678, "aqua_rat_26882": 0.7966740727424622, "aqua_rat_52886": 0.7989155054092407, "aqua_rat_55057": 0.7993999123573303, "math_train_prealgebra_725": 0.7995966076850891, "aqua_rat_71170": 0.8001293540000916, "aqua_rat_51453": 0.8027252554893494, "aqua_rat_69424": 0.804277241230011, "aqua_rat_24805": 0.8045994639396667, "aqua_rat_35180": 0.8050280213356018, "aqua_rat_76943": 0.805333137512207, "aqua_rat_20703": 0.8055524826049805, "aqua_rat_84473": 0.8056374788284302, "aqua_rat_47972": 0.8059705495834351, "aqua_rat_52952": 0.8072299957275391, "aqua_rat_74006": 0.8076167702674866, "aqua_rat_12240": 0.8081863522529602, "aqua_rat_28573": 0.8095831871032715, "aqua_rat_59295": 0.8096646666526794, "aqua_rat_58348": 0.8098675608634949, "aqua_rat_52869": 0.8104694485664368, "aqua_rat_56697": 0.8106898665428162, "aqua_rat_86238": 0.8109359741210938, "aqua_rat_57216": 0.8113429546356201, "aqua_rat_71832": 0.8115507960319519, "aqua_rat_54093": 0.8152297735214233, "aqua_rat_37605": 0.8160868883132935, "aqua_rat_46418": 0.816288948059082, "aqua_rat_3357": 0.820643424987793, "math_test_prealgebra_1586": 0.8415336608886719}, "TheoremQA_mingyin/stopping-time1.json": {"math_train_counting_and_probability_1066": 0, "math_test_counting_and_probability_727": 0, "math_train_counting_and_probability_5104": 0, "math_test_counting_and_probability_262": 0, "math_test_counting_and_probability_1044": 0, "camel_9446": 0, "camel_9514": 0, "camel_9462": 0, "camel_9489": 0, "TheoremQA_mingyin/stopping-time1.json": 0, "camel_9477": 0, "camel_9453": 0, "math_test_counting_and_probability_25780": 0, "camel_38669": 0.6688287854194641, "camel_25553": 0.6688541769981384, "aqua_rat_50672": 0.6688722372055054, "gsm_rft_22722": 0.6689348220825195, "aqua_rat_63857": 0.6689591407775879, "camel_24681": 0.6689766645431519, "aqua_rat_2561": 0.6689953804016113, "camel_25219": 0.6690564155578613, "aqua_rat_80730": 0.6693379878997803, "camel_25581": 0.6694027781486511, "camel_24644": 0.669437825679779, "camel_25612": 0.6694929599761963, "aqua_rat_73353": 0.6695936918258667, "gsm_rft_23659": 0.6696282029151917, "camel_24467": 0.6696310043334961, "camel_38672": 0.6696411967277527, "camel_41259": 0.669644296169281, "aqua_rat_40444": 0.6696673035621643, "camel_36509": 0.6697139143943787, "aqua_rat_39224": 0.6698870062828064, "camel_37606": 0.6698873043060303, "aqua_rat_23078": 0.6699790954589844, "aqua_rat_8224": 0.6700454354286194, "aqua_rat_37772": 0.6701890230178833, "camel_25635": 0.670199990272522, "camel_25537": 0.6702067255973816, "camel_17467": 0.6702776551246643, "aqua_rat_54583": 0.6702824831008911, "camel_24417": 0.6703028678894043, "aqua_rat_64889": 0.6703587174415588, "aqua_rat_1585": 0.6704701781272888, "aqua_rat_41204": 0.6705377101898193, "aqua_rat_37996": 0.6705607175827026, "camel_37713": 0.6705719828605652, "TheoremQA_wenhuchen/Poisson_process3.json": 0.6705865263938904, "camel_25549": 0.6707587242126465, "aqua_rat_61684": 0.670773446559906, "camel_25958": 0.670825183391571, "gsm_rft_33209": 0.6710106730461121, "gsm_rft_31585": 0.6710625290870667, "camel_25555": 0.6711283922195435, "gsm_train_9544": 0.6711924076080322, "gsm_rft_3283": 0.671196699142456, "aqua_rat_84407": 0.6712419986724854, "aqua_rat_21944": 0.6712645292282104, "camel_21994": 0.6712689995765686, "aqua_rat_87308": 0.671401858329773, "aqua_rat_47970": 0.67144775390625, "camel_25649": 0.6715137958526611, "aqua_rat_26864": 0.671850323677063, "TheoremQA_wenhuchen/Poisson_process2.json": 0.6718828082084656, "gsm_rft_2779": 0.6719121932983398, "camel_25560": 0.6720868349075317, "TheoremQA_mingyin/martingale2.json": 0.6721827387809753, "camel_25589": 0.6722226142883301, "camel_24336": 0.6723112463951111, "aqua_rat_29038": 0.6723504066467285, "gsm_rft_11967": 0.6724380850791931, "camel_24443": 0.672531247138977, "aqua_rat_85797": 0.6725696325302124, "aqua_rat_29959": 0.6726542711257935, "aqua_rat_64432": 0.6727020740509033, "aqua_rat_42129": 0.6727603077888489, "aqua_rat_49003": 0.672776460647583, "aqua_rat_13590": 0.6728156805038452, "gsm_rft_26501": 0.6729390621185303, "aqua_rat_58261": 0.6730222702026367, "aqua_rat_50853": 0.6730566024780273, "camel_25522": 0.6731761693954468, "gsm_rft_30777": 0.6732182502746582, "camel_25270": 0.6736212968826294, "gsm_rft_6361": 0.6737436056137085, "camel_25643": 0.6739010810852051, "aqua_rat_73441": 0.6739700436592102, "gsm_rft_4605": 0.6739783883094788, "gsm_rft_19506": 0.6740114688873291, "gsm_train_17407": 0.6740114688873291, "aqua_rat_37008": 0.6740972399711609, "camel_41420": 0.6742020845413208, "aqua_rat_53147": 0.6742122173309326, "camel_38692": 0.6742316484451294, "aqua_rat_42825": 0.6742979884147644, "camel_25911": 0.6743897795677185, "camel_25622": 0.6744509339332581, "aqua_rat_14374": 0.6749318838119507, "aqua_rat_47000": 0.6749825477600098, "gsm_rft_20712": 0.674987256526947, "camel_25577": 0.6751687526702881, "aqua_rat_49123": 0.6751801371574402, "aqua_rat_77954": 0.6752017736434937, "camel_25543": 0.6752027273178101, "camel_25950": 0.6752729415893555, "gsm_rft_26607": 0.6754636764526367, "gsm_train_33563": 0.6754636764526367, "camel_25224": 0.6755963563919067, "camel_25578": 0.6756067872047424, "camel_25678": 0.6757962703704834, "aqua_rat_27393": 0.675963282585144, "aqua_rat_77671": 0.6760103106498718, "aqua_rat_72840": 0.6760774254798889, "camel_24456": 0.6761568784713745, "math_test_algebra_2359": 0.6762235760688782, "aqua_rat_38029": 0.6763379573822021, "camel_36276": 0.6764533519744873, "camel_37741": 0.6764827966690063, "camel_25665": 0.6765298247337341, "aqua_rat_6028": 0.6766113042831421, "camel_17452": 0.6767072081565857, "aqua_rat_13970": 0.6771061420440674, "aqua_rat_31288": 0.6774171590805054, "aqua_rat_57036": 0.6774614453315735, "aqua_rat_37079": 0.6775411367416382, "aqua_rat_23005": 0.6779059767723083, "aqua_rat_67638": 0.6780102252960205, "aqua_rat_61626": 0.6781635880470276, "aqua_rat_86315": 0.6782711148262024, "camel_36306": 0.6782954931259155, "camel_25601": 0.6782993674278259, "aqua_rat_7903": 0.6783061027526855, "gsm_rft_30704": 0.6785679459571838, "gsm_rft_33243": 0.6785679459571838, "gsm_train_28946": 0.6785679459571838, "math_train_prealgebra_630": 0.6787779927253723, "camel_24422": 0.6792460083961487, "aqua_rat_83131": 0.6792515516281128, "camel_25530": 0.6793291568756104, "aqua_rat_41336": 0.6796007752418518, "TheoremQA_wenhuchen/wiener_process2.json": 0.6796552538871765, "aqua_rat_88963": 0.6797399520874023, "aqua_rat_54277": 0.6798276305198669, "camel_21966": 0.6803792119026184, "aqua_rat_27395": 0.6804479956626892, "camel_25608": 0.6804571151733398, "gsm_rft_958": 0.680602490901947, "camel_24401": 0.6809154748916626, "camel_25638": 0.6811864376068115, "gsm_rft_30318": 0.6814929842948914, "aqua_rat_59085": 0.6815139651298523, "aqua_rat_295": 0.6815267205238342, "aqua_rat_64812": 0.6816915273666382, "camel_25554": 0.6816993951797485, "aqua_rat_55472": 0.681982696056366, "aqua_rat_1237": 0.6821486353874207, "aqua_rat_56758": 0.6821548938751221, "aqua_rat_37057": 0.6821920275688171, "camel_37817": 0.682218611240387, "aqua_rat_9379": 0.6823903918266296, "aqua_rat_19750": 0.6824263334274292, "camel_24250": 0.6825875043869019, "aqua_rat_58436": 0.6826188564300537, "camel_36259": 0.6826731562614441, "camel_24711": 0.6827525496482849, "math_train_intermediate_algebra_454": 0.6827563047409058, "aqua_rat_43375": 0.6828315854072571, "aqua_rat_3131": 0.6830307245254517, "aqua_rat_58101": 0.6830451488494873, "gsm_rft_16210": 0.6835132837295532, "aqua_rat_31903": 0.6835138201713562, "aqua_rat_49358": 0.6835428476333618, "aqua_rat_55514": 0.683825671672821, "aqua_rat_68610": 0.6840766668319702, "aqua_rat_57102": 0.684353232383728, "camel_36368": 0.6846175789833069, "gsm_train_9826": 0.6871004700660706, "camel_21967": 0.6879891157150269, "aqua_rat_25750": 0.6883118748664856, "aqua_rat_13473": 0.6884458065032959, "aqua_rat_25054": 0.6886832118034363, "camel_36979": 0.6888107657432556, "aqua_rat_14333": 0.6891751289367676, "gsm_rft_14862": 0.689271092414856, "aqua_rat_21194": 0.6895843744277954, "gsm_rft_27803": 0.6908486485481262, "camel_25620": 0.6919029951095581, "aqua_rat_58094": 0.6924241185188293, "camel_25655": 0.6938842535018921, "camel_37677": 0.6939994096755981, "camel_36523": 0.6958760023117065, "camel_25976": 0.6961380839347839, "aqua_rat_9211": 0.6976335048675537, "camel_37459": 0.6983146071434021, "aqua_rat_29953": 0.7006006836891174, "camel_17509": 0.7037113308906555, "aqua_rat_62145": 0.7041062116622925, "aqua_rat_6195": 0.7058679461479187, "TheoremQA_mingyin/martingale1.json": 0.7252963185310364, "aqua_rat_21336": 0.7254241108894348}, "TheoremQA_xinyi/maximum_entropy_2.json": {"camel_8772": 0, "camel_10941": 0, "camel_10911": 0, "camel_11334": 0, "camel_11188": 0, "camel_10887": 0, "camel_11003": 0, "camel_10918": 0, "camel_10351": 0, "camel_8361": 0, "camel_11122": 0, "camel_11332": 0, "camel_10853": 0, "camel_10867": 0, "camel_11323": 0, "camel_10870": 0, "camel_8755": 0, "camel_10897": 0, "camel_10904": 0, "camel_10486": 0, "camel_8794": 0, "camel_10320": 0, "camel_11282": 0, "camel_8351": 0, "camel_11143": 0, "camel_11328": 0, "camel_10868": 0, "camel_10957": 0, "camel_11643": 0, "camel_10950": 0, "camel_11192": 0, "camel_10895": 0, "camel_9522": 0, "camel_11036": 0, "camel_10944": 0, "camel_11178": 0, "camel_11153": 0, "camel_10858": 0, "camel_10907": 0, "camel_10393": 0, "camel_11124": 0, "camel_10982": 0, "camel_11002": 0, "camel_11161": 0, "camel_11196": 0, "camel_11247": 0, "camel_11306": 0, "camel_10355": 0, "camel_10352": 0, "camel_11186": 0, "camel_10816": 0, "camel_11285": 0, "camel_11649": 0, "camel_10557": 0, "camel_11014": 0, "camel_11296": 0, "camel_10919": 0, "camel_9484": 0, "camel_10889": 0, "camel_8730": 0, "camel_11029": 0, "camel_11127": 0, "camel_11322": 0, "camel_8789": 0, "camel_9365": 0, "camel_8769": 0, "camel_10979": 0, "camel_10930": 0, "camel_10966": 0, "camel_10936": 0, "camel_11130": 0, "camel_11294": 0, "camel_10976": 0, "camel_10808": 0, "TheoremQA_xinyi/maximum_entropy_2.json": 0, "camel_10934": 0, "camel_9412": 0, "camel_10953": 0, "camel_11604": 0, "camel_8770": 0, "camel_10939": 0, "camel_10935": 0, "camel_11182": 0, "camel_8773": 0, "camel_11412": 0, "camel_11617": 0, "camel_8771": 0, "camel_10947": 0, "camel_8781": 0, "camel_11504": 0, "camel_11293": 0, "camel_11365": 0, "camel_8750": 0, "camel_11031": 0, "camel_8749": 0, "camel_11174": 0, "camel_10927": 0, "camel_11181": 0, "camel_10996": 0, "camel_8751": 0, "camel_11000": 0, "camel_10929": 0, "camel_10806": 0, "camel_8733": 0, "camel_10998": 0, "camel_8729": 0, "camel_10364": 0, "camel_11185": 0, "camel_10595": 0, "camel_11189": 0, "camel_11355": 0, "camel_8759": 0, "camel_11325": 0, "camel_9398": 0, "camel_10920": 0, "camel_8753": 0, "camel_11154": 0, "camel_8747": 0, "camel_11281": 0, "camel_11669": 0, "camel_9415": 0, "camel_11001": 0, "camel_11628": 0, "camel_8788": 0, "camel_11149": 0, "camel_11342": 0, "camel_8782": 0, "camel_11563": 0, "camel_38657": 0.6170750856399536, "camel_38705": 0.6170979738235474, "camel_25145": 0.6171188354492188, "camel_38748": 0.6171772480010986, "camel_40980": 0.6171820163726807, "TheoremQA_xinyi/expected_waiting_time.json": 0.6171889305114746, "camel_38659": 0.61734539270401, "camel_41008": 0.6176326274871826, "camel_38686": 0.6176909804344177, "camel_18301": 0.6179490685462952, "camel_41036": 0.6181142926216125, "camel_41010": 0.6181917190551758, "camel_39686": 0.6185203194618225, "camel_41023": 0.6194400787353516, "camel_38678": 0.6195014119148254, "camel_20511": 0.6195408701896667, "camel_40986": 0.6207036375999451, "camel_40973": 0.620750367641449, "camel_40993": 0.620786726474762, "camel_41038": 0.6213356852531433, "camel_39414": 0.6216453313827515, "camel_41031": 0.6216540336608887, "camel_41014": 0.621749758720398, "camel_38658": 0.621793270111084, "camel_25090": 0.6218990683555603, "camel_41034": 0.6219600439071655, "camel_39361": 0.6220195293426514, "camel_40971": 0.622064471244812, "camel_38642": 0.6226475238800049, "camel_41027": 0.6226683259010315, "TheoremQA_elainewan/econ_micro_7.json": 0.6227045655250549, "camel_41024": 0.6232137680053711, "camel_25879": 0.6233537197113037, "camel_38646": 0.6235622763633728, "camel_41033": 0.6236206889152527, "camel_41005": 0.6242250800132751, "camel_40998": 0.6242671012878418, "TheoremQA_xinyi/markov_inequality.json": 0.6252119541168213, "camel_25427": 0.6254885792732239, "camel_25543": 0.6256469488143921, "camel_38648": 0.6269586086273193, "camel_40978": 0.6270099878311157, "camel_38677": 0.6273080110549927, "camel_38717": 0.627927303314209, "camel_40967": 0.6287063360214233, "camel_25849": 0.6294661164283752, "camel_40961": 0.6295315623283386, "camel_38692": 0.6298479437828064, "camel_38685": 0.6300307512283325, "camel_38715": 0.6307518482208252, "camel_38697": 0.6315637826919556, "camel_40964": 0.6316348314285278, "camel_25029": 0.6316748261451721, "camel_41011": 0.6348888874053955, "camel_38660": 0.6353570222854614, "camel_38656": 0.6356229186058044, "camel_38693": 0.6362009644508362, "camel_25126": 0.6363129615783691, "camel_40994": 0.6363458633422852, "TheoremQA_mingyin/martingale1.json": 0.6401528716087341, "TheoremQA_xinyi/shannon_lower_bound.json": 0.6427552700042725, "camel_25589": 0.6457821130752563, "camel_29080": 0.6496980786323547, "TheoremQA_elainewan/econ_micro_7_2.json": 0.6529268026351929, "camel_38707": 0.6534419059753418, "camel_24997": 0.6557385921478271, "camel_38666": 0.6612642407417297, "camel_38643": 0.6698943376541138, "camel_38718": 0.6713316440582275, "camel_38649": 0.6735417246818542, "camel_38691": 0.6958467960357666, "TheoremQA_xinyi/maximum_entropy_1.json": 0.7291224002838135}, "TheoremQA_maxku/signalprocessing11-nyquist.json": {"TheoremQA_maxku/signalprocessing11-nyquist.json": 0, "camel_45170": 0.8000099062919617, "camel_5153": 0.8000452518463135, "camel_45155": 0.8000759482383728, "camel_45945": 0.8003098964691162, "camel_45608": 0.8004981875419617, "camel_44765": 0.8005381226539612, "camel_45432": 0.8005645275115967, "camel_45658": 0.8006410002708435, "camel_45727": 0.8007420301437378, "camel_44503": 0.8008657097816467, "camel_44564": 0.8009097576141357, "camel_44343": 0.8014362454414368, "camel_45706": 0.8018211126327515, "camel_45963": 0.8020820617675781, "camel_45725": 0.8021221160888672, "camel_44521": 0.8023353815078735, "camel_44532": 0.8026803135871887, "camel_45512": 0.8029506802558899, "camel_45708": 0.8030192255973816, "camel_44426": 0.8030222654342651, "camel_44927": 0.8030322194099426, "camel_45693": 0.8030700087547302, "camel_45699": 0.803482711315155, "camel_44433": 0.8038960695266724, "camel_44477": 0.803928792476654, "camel_44457": 0.8039581179618835, "camel_45872": 0.8042983412742615, "camel_45952": 0.8043191432952881, "camel_45609": 0.8052939772605896, "camel_44401": 0.8055449724197388, "camel_44440": 0.8055450320243835, "camel_45839": 0.8058826923370361, "camel_45606": 0.8060478568077087, "camel_45607": 0.8063156008720398, "camel_45199": 0.8069039583206177, "camel_44560": 0.8069328665733337, "camel_44462": 0.8073067665100098, "camel_45165": 0.8073484301567078, "camel_45183": 0.8074833750724792, "camel_44455": 0.8077092170715332, "camel_45142": 0.807805061340332, "camel_44494": 0.8080111145973206, "camel_45188": 0.8080360889434814, "camel_45300": 0.808485746383667, "camel_45758": 0.8085803389549255, "camel_45662": 0.8088183999061584, "camel_45138": 0.8090344667434692, "camel_44499": 0.8093209862709045, "camel_45748": 0.8093438744544983, "camel_45754": 0.8096342086791992, "camel_45755": 0.8096573948860168, "camel_45709": 0.8106522560119629, "camel_44574": 0.8106651902198792, "camel_45796": 0.8106652498245239, "camel_45684": 0.8107467293739319, "camel_45776": 0.810808002948761, "camel_45303": 0.8109122514724731, "camel_45143": 0.8111960291862488, "camel_44447": 0.8112333416938782, "camel_45835": 0.8114178776741028, "camel_45766": 0.8128461837768555, "camel_45533": 0.8132048845291138, "camel_44566": 0.8134362101554871, "camel_45149": 0.8134410381317139, "camel_45166": 0.8135162591934204, "camel_44550": 0.8148290514945984, "camel_45707": 0.8151066899299622, "camel_45763": 0.8152135014533997, "camel_45724": 0.8157826066017151, "camel_45654": 0.8159841895103455, "camel_44528": 0.8161059617996216, "camel_45182": 0.8162693381309509, "camel_44870": 0.8167573809623718, "camel_44510": 0.816778838634491, "camel_45923": 0.8173893690109253, "camel_44807": 0.8175917863845825, "camel_44490": 0.8176183104515076, "camel_45646": 0.8176594376564026, "camel_45931": 0.8177722096443176, "camel_44824": 0.8184186220169067, "camel_44872": 0.8192713260650635, "camel_45129": 0.8207488059997559, "camel_45717": 0.8207778334617615, "camel_45720": 0.821392834186554, "camel_45756": 0.8214106559753418, "camel_45811": 0.8221069574356079, "camel_44448": 0.8225904703140259, "camel_44802": 0.822631299495697, "camel_45152": 0.8227908611297607, "camel_45492": 0.8236753344535828, "camel_44514": 0.8239724636077881, "camel_45198": 0.8245491981506348, "camel_45743": 0.8248010277748108, "camel_44459": 0.8249707818031311, "camel_45133": 0.8263444900512695, "camel_44512": 0.8266315460205078, "camel_44442": 0.8267815113067627, "camel_44467": 0.8270408511161804, "camel_44621": 0.8273162245750427, "camel_45744": 0.8275096416473389, "camel_45137": 0.8275179862976074, "camel_45996": 0.8275730013847351, "camel_44545": 0.8276395201683044, "camel_45928": 0.8277138471603394, "camel_44555": 0.8283125162124634, "camel_44475": 0.82846999168396, "camel_45713": 0.8285017609596252, "camel_45604": 0.8285542130470276, "camel_45806": 0.8294664621353149, "camel_44416": 0.8299389481544495, "camel_45130": 0.83021080493927, "camel_44848": 0.8303512334823608, "camel_45798": 0.8303973078727722, "camel_44851": 0.8317763805389404, "camel_44858": 0.8319116830825806, "camel_45803": 0.8323615789413452, "camel_45308": 0.8324769735336304, "camel_44826": 0.8329401016235352, "camel_45320": 0.8330650925636292, "camel_44538": 0.8335680961608887, "camel_44861": 0.8335862755775452, "camel_45615": 0.8339830040931702, "camel_44506": 0.8342587947845459, "camel_44492": 0.834731936454773, "camel_44818": 0.8349366784095764, "camel_44421": 0.8350921869277954, "camel_44526": 0.835603654384613, "camel_44852": 0.8357745409011841, "camel_44488": 0.8363276720046997, "camel_45784": 0.8363751173019409, "camel_44429": 0.8365784287452698, "camel_44846": 0.8365936279296875, "camel_45003": 0.837252676486969, "camel_45676": 0.8374499678611755, "camel_44838": 0.8386688828468323, "camel_44724": 0.8392122387886047, "camel_45314": 0.8392670154571533, "camel_45788": 0.839480996131897, "camel_44517": 0.8400257229804993, "camel_45998": 0.8403398394584656, "camel_45176": 0.8405885100364685, "camel_44537": 0.8407011032104492, "camel_45815": 0.8408659100532532, "camel_45791": 0.8410087823867798, "camel_44544": 0.8410316705703735, "camel_45162": 0.8414953351020813, "camel_44439": 0.8415170311927795, "camel_44825": 0.8418984413146973, "camel_45759": 0.8422510623931885, "camel_44839": 0.8423149585723877, "camel_45797": 0.8438078165054321, "camel_45781": 0.8444808125495911, "camel_45790": 0.8450407385826111, "camel_44460": 0.8452156782150269, "camel_45685": 0.8457793593406677, "camel_44534": 0.8458361625671387, "camel_44473": 0.8458697199821472, "camel_45782": 0.8459147214889526, "camel_45644": 0.8463645577430725, "camel_44504": 0.8463720679283142, "camel_45966": 0.8465509414672852, "camel_45173": 0.846679151058197, "camel_44487": 0.8468635082244873, "camel_44466": 0.847075879573822, "camel_45988": 0.847283124923706, "camel_45821": 0.8474355340003967, "camel_45184": 0.8474793434143066, "camel_45134": 0.8475243449211121, "camel_45680": 0.8480989933013916, "TheoremQA_maxku/signalprocessing5-nyquist.json": 0.8491865992546082, "camel_44523": 0.8498470783233643, "camel_44828": 0.8499448895454407, "camel_44554": 0.8500155210494995, "camel_44865": 0.8503351211547852, "camel_45765": 0.85075443983078, "camel_44516": 0.8507694602012634, "camel_45700": 0.8519137501716614, "camel_45681": 0.852186381816864, "camel_45146": 0.8527120351791382, "camel_44820": 0.8527934551239014, "camel_45745": 0.8544546961784363, "camel_45764": 0.8569594025611877, "camel_44835": 0.8580888509750366, "camel_44849": 0.8602935075759888, "camel_45729": 0.8622169494628906, "camel_45171": 0.8628836870193481, "camel_44411": 0.8642095327377319, "camel_44498": 0.8660104870796204, "camel_44533": 0.8666155934333801, "camel_45778": 0.8709169626235962, "camel_45792": 0.8713629841804504, "camel_44420": 0.8742291331291199, "camel_44873": 0.8791007995605469, "camel_44860": 0.8850389122962952, "camel_45810": 0.8888194561004639, "camel_44400": 0.8956044316291809, "camel_45807": 0.9024885892868042, "TheoremQA_maxku/signalprocessing12-nyquist.json": 0.9192684292793274, "TheoremQA_maxku/signalprocessing10-nyquist.json": 0.9204721450805664}, "TheoremQA_maxku/cv-colorsci2-hsi.json": {"TheoremQA_maxku/cv-colorsci2-hsi.json": 0, "aqua_rat_4834": 0.6071100831031799, "gsm_rft_16370": 0.6071708798408508, "gsm_rft_9288": 0.6071822643280029, "aqua_rat_5732": 0.607306718826294, "aqua_rat_32649": 0.6073256134986877, "aqua_rat_73616": 0.6073520183563232, "gsm_rft_29667": 0.6073643565177917, "gsm_rft_2125": 0.6074799299240112, "aqua_rat_456": 0.6074836850166321, "aqua_rat_59441": 0.6074956655502319, "aqua_rat_38038": 0.6075393557548523, "aqua_rat_11622": 0.6076412200927734, "camel_28738": 0.6077248454093933, "gsm_rft_16684": 0.6077420711517334, "aqua_rat_19754": 0.607796311378479, "gsm_rft_28173": 0.6077989935874939, "gsm_rft_18060": 0.6078177094459534, "gsm_train_3314": 0.6078177094459534, "aqua_rat_33918": 0.6078586578369141, "gsm_rft_23876": 0.6079168915748596, "aqua_rat_18038": 0.6080071330070496, "camel_29507": 0.6080296635627747, "gsm_rft_13342": 0.6080349683761597, "aqua_rat_27057": 0.608121931552887, "aqua_rat_53706": 0.6081779599189758, "gsm_rft_17550": 0.6082541942596436, "gsm_train_19311": 0.6082541942596436, "aqua_rat_31354": 0.6082653999328613, "aqua_rat_7369": 0.6083508133888245, "aqua_rat_34861": 0.6083603501319885, "aqua_rat_25324": 0.6084758043289185, "aqua_rat_66173": 0.6086199283599854, "aqua_rat_34918": 0.6087852120399475, "aqua_rat_69519": 0.608834981918335, "camel_40114": 0.6089726686477661, "TheoremQA_maxku/cv-imageprocessing7-histogram.json": 0.6090213656425476, "aqua_rat_63612": 0.6091738343238831, "aqua_rat_3620": 0.6092770099639893, "aqua_rat_16551": 0.6093330383300781, "camel_29495": 0.6093838810920715, "aqua_rat_42878": 0.6094509363174438, "aqua_rat_29745": 0.6095513105392456, "aqua_rat_61888": 0.6096534729003906, "camel_9009": 0.6097152829170227, "aqua_rat_24258": 0.6098510026931763, "aqua_rat_66414": 0.6099847555160522, "camel_17816": 0.6099926233291626, "aqua_rat_3085": 0.6100807189941406, "camel_29460": 0.6101917624473572, "gsm_rft_35008": 0.6102405190467834, "aqua_rat_41416": 0.6103308796882629, "aqua_rat_7680": 0.6103455424308777, "gsm_rft_8067": 0.610450804233551, "aqua_rat_21684": 0.6105164289474487, "aqua_rat_59558": 0.6106814742088318, "camel_17835": 0.6107013821601868, "aqua_rat_18162": 0.6108789443969727, "gsm_rft_22363": 0.6108828783035278, "aqua_rat_30423": 0.6108976006507874, "aqua_rat_85423": 0.610901951789856, "camel_29311": 0.610903263092041, "aqua_rat_1976": 0.6109151840209961, "aqua_rat_10714": 0.6109275221824646, "aqua_rat_68678": 0.6110020279884338, "aqua_rat_1682": 0.6110406517982483, "aqua_rat_25896": 0.6111921668052673, "camel_29820": 0.6112504601478577, "aqua_rat_56075": 0.6112799048423767, "aqua_rat_44379": 0.6113486886024475, "camel_30469": 0.6113991737365723, "camel_29343": 0.6114069223403931, "camel_29502": 0.6115335822105408, "aqua_rat_57723": 0.6115947961807251, "camel_29044": 0.6117188930511475, "aqua_rat_11212": 0.611797034740448, "aqua_rat_56753": 0.611821174621582, "aqua_rat_51456": 0.6121871471405029, "camel_29108": 0.612194836139679, "aqua_rat_77436": 0.6122463941574097, "aqua_rat_31499": 0.612328827381134, "gsm_rft_4843": 0.6125928163528442, "TheoremQA_maxku/signalprocessing2-DB.json": 0.6128348112106323, "aqua_rat_35675": 0.612846851348877, "gsm_rft_10968": 0.6132567524909973, "aqua_rat_5931": 0.6135855317115784, "aqua_rat_15330": 0.6136932969093323, "aqua_rat_54992": 0.613746166229248, "aqua_rat_32105": 0.6137970089912415, "aqua_rat_6611": 0.6139231324195862, "camel_30461": 0.6140439510345459, "aqua_rat_10995": 0.6140676736831665, "camel_44741": 0.6143337488174438, "aqua_rat_83549": 0.614453911781311, "aqua_rat_49468": 0.6148409843444824, "aqua_rat_43262": 0.6150373220443726, "camel_15432": 0.6150733828544617, "aqua_rat_21200": 0.615147054195404, "aqua_rat_17416": 0.6151636838912964, "camel_9031": 0.6153581738471985, "aqua_rat_73394": 0.6154053211212158, "camel_30455": 0.615411639213562, "camel_29482": 0.6154568791389465, "aqua_rat_63695": 0.6155655384063721, "aqua_rat_46255": 0.6157482862472534, "camel_29451": 0.6158019304275513, "aqua_rat_47586": 0.6158964037895203, "aqua_rat_53874": 0.6160728335380554, "aqua_rat_59369": 0.6161245703697205, "aqua_rat_24892": 0.6161364912986755, "camel_8981": 0.6161747574806213, "camel_8969": 0.6162962317466736, "gsm_rft_30111": 0.6163866519927979, "gsm_train_28955": 0.6163866519927979, "camel_38481": 0.6164097189903259, "gsm_rft_10110": 0.6167311668395996, "gsm_rft_26010": 0.6168838739395142, "camel_28406": 0.6170607209205627, "aqua_rat_1092": 0.6171890497207642, "aqua_rat_71134": 0.6172170639038086, "gsm_rft_881": 0.61735999584198, "aqua_rat_56460": 0.6176742315292358, "aqua_rat_5613": 0.6177327632904053, "camel_40143": 0.6180592179298401, "camel_8967": 0.6182811260223389, "gsm_rft_30026": 0.6182947754859924, "gsm_rft_31476": 0.6184080243110657, "aqua_rat_29905": 0.6184236407279968, "gsm_rft_263": 0.6184560060501099, "camel_29453": 0.6184813976287842, "aqua_rat_5531": 0.618527889251709, "aqua_rat_40335": 0.6185986399650574, "aqua_rat_24033": 0.6186851263046265, "TheoremQA_maxku/cv-imageprocessing6-histogram.json": 0.6189486384391785, "aqua_rat_63536": 0.6189867258071899, "aqua_rat_47454": 0.6190615296363831, "gsm_rft_21334": 0.6190628409385681, "gsm_train_18516": 0.6194890737533569, "gsm_rft_28497": 0.6194890737533569, "camel_29295": 0.6195085048675537, "aqua_rat_6933": 0.6196156740188599, "gsm_rft_17744": 0.6196771264076233, "aqua_rat_1425": 0.6200118064880371, "camel_8977": 0.6204212307929993, "aqua_rat_6751": 0.620653510093689, "gsm_rft_33530": 0.6207818984985352, "aqua_rat_43023": 0.6208047866821289, "camel_29508": 0.621163010597229, "gsm_train_14404": 0.6214424967765808, "aqua_rat_14369": 0.6214910745620728, "gsm_rft_20996": 0.6215506196022034, "gsm_rft_16679": 0.6216201782226562, "gsm_rft_16725": 0.6217352747917175, "camel_29501": 0.6218072175979614, "gsm_rft_23035": 0.6225191354751587, "aqua_rat_18575": 0.622836172580719, "aqua_rat_48550": 0.6228452920913696, "aqua_rat_31331": 0.6229605078697205, "aqua_rat_4046": 0.6229800581932068, "camel_38813": 0.6230158805847168, "aqua_rat_14694": 0.6230762600898743, "aqua_rat_79408": 0.623191237449646, "aqua_rat_45618": 0.623316764831543, "aqua_rat_5518": 0.6236827373504639, "camel_29485": 0.6238663196563721, "aqua_rat_79381": 0.6242419481277466, "camel_29339": 0.6245653629302979, "TheoremQA_maxku/cv-colorsci1-rgb.json": 0.6245915293693542, "aqua_rat_10760": 0.6251760721206665, "gsm_rft_346": 0.6263235807418823, "gsm_train_6050": 0.6263235807418823, "camel_28096": 0.6264837980270386, "gsm_rft_22234": 0.627194881439209, "aqua_rat_4231": 0.6272525787353516, "aqua_rat_86844": 0.6278207898139954, "aqua_rat_87245": 0.6301742792129517, "aqua_rat_43884": 0.630573570728302, "aqua_rat_12459": 0.6308043599128723, "aqua_rat_60510": 0.6314241290092468, "aqua_rat_7583": 0.632352352142334, "camel_28935": 0.6327797770500183, "aqua_rat_32511": 0.6335704922676086, "aqua_rat_26453": 0.6341868042945862, "aqua_rat_1701": 0.6354617476463318, "aqua_rat_22474": 0.6383312344551086, "aqua_rat_20431": 0.6430514454841614, "aqua_rat_65183": 0.6453230977058411, "aqua_rat_22426": 0.6458948850631714, "aqua_rat_42817": 0.6460273861885071, "aqua_rat_87580": 0.6470711827278137, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.6477609872817993, "TheoremQA_maxku/cv-imageprocessing10-digital-image.json": 0.6529000401496887, "aqua_rat_82138": 0.6533795595169067, "aqua_rat_36347": 0.6591088771820068, "aqua_rat_69297": 0.6592901945114136, "aqua_rat_54325": 0.6608192920684814, "aqua_rat_61003": 0.6624833345413208, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0.6627320051193237, "TheoremQA_maxku/cv-colorsci3-rgb.json": 0.7604129910469055, "TheoremQA_maxku/cv-colorsci4-hsi.json": 0.7727813720703125}, "TheoremQA_jianyu_xu/Stirling_number_first_kind_5.json": {"camel_20988": 0, "camel_21798": 0, "camel_21198": 0, "camel_21126": 0, "camel_21123": 0, "camel_20623": 0, "camel_21159": 0, "camel_20697": 0, "camel_21299": 0, "camel_21116": 0, "camel_20621": 0, "camel_20712": 0, "camel_21168": 0, "camel_20696": 0, "camel_21200": 0, "camel_20670": 0, "camel_21175": 0, "camel_20663": 0, "camel_20514": 0, "camel_21120": 0, "camel_20714": 0, "camel_20652": 0, "camel_20644": 0, "camel_21215": 0, "camel_21085": 0, "camel_21174": 0, "camel_20787": 0, "camel_20592": 0, "camel_21039": 0, "camel_20710": 0, "camel_21167": 0, "camel_21196": 0, "camel_21372": 0, "camel_21972": 0, "camel_21425": 0, "camel_20671": 0, "camel_21246": 0, "camel_21170": 0, "camel_21004": 0, "camel_20596": 0, "camel_20609": 0, "camel_21809": 0, "camel_20688": 0, "camel_21405": 0, "camel_20707": 0, "camel_20661": 0, "camel_20680": 0, "camel_20967": 0, "camel_20658": 0, "camel_21568": 0, "camel_20540": 0, "camel_21822": 0, "camel_20665": 0, "camel_21138": 0, "camel_21269": 0, "camel_20946": 0, "camel_20618": 0, "camel_21169": 0, "camel_21360": 0, "camel_21361": 0, "camel_21188": 0, "camel_21050": 0, "camel_20743": 0, "camel_20579": 0, "camel_21228": 0, "camel_20747": 0, "camel_20640": 0, "camel_21202": 0, "camel_21218": 0, "camel_20310": 0, "camel_20674": 0, "camel_20650": 0, "camel_20626": 0, "camel_21304": 0, "camel_20711": 0, "camel_20701": 0, "camel_20571": 0, "camel_20649": 0, "camel_21431": 0, "camel_21055": 0, "camel_20825": 0, "camel_21835": 0, "camel_20841": 0, "camel_20702": 0, "camel_20577": 0, "camel_20614": 0, "camel_20700": 0, "camel_20806": 0, "camel_20637": 0, "camel_20668": 0, "camel_20695": 0, "aqua_rat_54394": 0.684263288974762, "aqua_rat_58761": 0.6844707131385803, "aqua_rat_45411": 0.6845226883888245, "aqua_rat_72606": 0.6846892237663269, "gsm_rft_111": 0.6852908134460449, "math_test_counting_and_probability_924": 0.6853992938995361, "gsm_rft_29858": 0.6854087114334106, "gsm_train_15312": 0.6854087114334106, "aqua_rat_62238": 0.6855273246765137, "aqua_rat_57502": 0.6857077479362488, "aqua_rat_25873": 0.6859522461891174, "gsm_rft_3919": 0.6861360669136047, "aqua_rat_8519": 0.6864014863967896, "math_test_prealgebra_1764": 0.6865941286087036, "camel_23312": 0.6869004368782043, "aqua_rat_53909": 0.6869632005691528, "math_test_counting_and_probability_494": 0.6870181560516357, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": 0.68732750415802, "aqua_rat_89113": 0.687563955783844, "math_train_counting_and_probability_5098": 0.6877351403236389, "aqua_rat_48187": 0.687744677066803, "gsm_rft_24350": 0.687799334526062, "math_test_counting_and_probability_238": 0.6880075335502625, "math_train_counting_and_probability_237": 0.6881356239318848, "aqua_rat_25103": 0.6883921027183533, "aqua_rat_75188": 0.6885785460472107, "aqua_rat_73402": 0.6887968182563782, "aqua_rat_26482": 0.6890518069267273, "aqua_rat_85657": 0.6892635226249695, "aqua_rat_34094": 0.6901178359985352, "aqua_rat_41875": 0.6901639103889465, "aqua_rat_68730": 0.690481960773468, "aqua_rat_84091": 0.6905791759490967, "aqua_rat_70081": 0.6910275220870972, "aqua_rat_11273": 0.6914585828781128, "aqua_rat_65738": 0.6925228834152222, "aqua_rat_65264": 0.6928175091743469, "math_train_counting_and_probability_5127": 0.69295334815979, "aqua_rat_77200": 0.693162202835083, "aqua_rat_20969": 0.6932512521743774, "camel_23284": 0.6936004161834717, "aqua_rat_35816": 0.6942888498306274, "aqua_rat_47540": 0.6943420171737671, "math_train_counting_and_probability_5090": 0.6944263577461243, "aqua_rat_55783": 0.6949184536933899, "aqua_rat_10748": 0.6952509880065918, "aqua_rat_59919": 0.6952657103538513, "aqua_rat_71336": 0.6954591870307922, "aqua_rat_11490": 0.6955044865608215, "aqua_rat_43397": 0.6966226696968079, "aqua_rat_4483": 0.6966675519943237, "math_train_counting_and_probability_1110": 0.6973095536231995, "math_test_counting_and_probability_796": 0.6977562308311462, "math_train_counting_and_probability_617": 0.6984272599220276, "aqua_rat_49668": 0.6984713673591614, "math_train_counting_and_probability_22": 0.6998624801635742, "gsm_rft_28436": 0.7000558972358704, "gsm_train_34242": 0.7003583908081055, "gsm_rft_17317": 0.7003583908081055, "aqua_rat_83490": 0.7007314562797546, "aqua_rat_56019": 0.7012230753898621, "aqua_rat_257": 0.7018634676933289, "math_test_counting_and_probability_513": 0.7020941376686096, "math_train_counting_and_probability_957": 0.7024943232536316, "math_test_counting_and_probability_134": 0.7025556564331055, "math_train_counting_and_probability_76": 0.703139066696167, "aqua_rat_43005": 0.703296422958374, "aqua_rat_56498": 0.7035155892372131, "math_test_counting_and_probability_378": 0.7035265564918518, "math_test_prealgebra_849": 0.7035596966743469, "math_test_counting_and_probability_653": 0.7044119238853455, "aqua_rat_30172": 0.7050853371620178, "math_test_counting_and_probability_987": 0.7055284380912781, "aqua_rat_60456": 0.7060291171073914, "math_train_counting_and_probability_98": 0.7061636447906494, "math_train_counting_and_probability_149": 0.7062265872955322, "math_train_counting_and_probability_646": 0.7065849304199219, "math_train_counting_and_probability_431": 0.706852376461029, "aqua_rat_76556": 0.7070181369781494, "math_train_counting_and_probability_651": 0.7073395848274231, "math_test_counting_and_probability_215": 0.7080408334732056, "math_train_counting_and_probability_667": 0.7083145976066589, "math_test_counting_and_probability_71": 0.7104625105857849, "aqua_rat_81367": 0.7115083932876587, "math_train_counting_and_probability_5119": 0.7116708755493164, "aqua_rat_61326": 0.7123655676841736, "aqua_rat_19436": 0.7130385637283325, "aqua_rat_35588": 0.7132207751274109, "math_test_counting_and_probability_294": 0.7132856845855713, "TheoremQA_jianyu_xu/Stirling_number_first_kind_6.json": 0.7142115235328674, "aqua_rat_15706": 0.7144977450370789, "math_test_counting_and_probability_650": 0.7145874500274658, "math_train_counting_and_probability_83": 0.7151967287063599, "math_test_counting_and_probability_159": 0.7158904075622559, "aqua_rat_38901": 0.7159359455108643, "aqua_rat_50326": 0.716941237449646, "math_test_counting_and_probability_103": 0.7170930504798889, "aqua_rat_47936": 0.7171487808227539, "aqua_rat_83784": 0.7182152271270752, "math_test_counting_and_probability_525": 0.7192097902297974, "math_test_counting_and_probability_416": 0.719551146030426, "math_train_counting_and_probability_914": 0.7212837338447571, "math_train_prealgebra_1075": 0.7227424383163452, "math_train_counting_and_probability_5092": 0.722977340221405, "math_test_counting_and_probability_695": 0.7233264446258545, "math_train_counting_and_probability_466": 0.7248358726501465, "math_test_counting_and_probability_1046": 0.7274647951126099, "math_test_counting_and_probability_341": 0.73313307762146, "math_test_counting_and_probability_1047": 0.7453927993774414}, "TheoremQA_tonyxia/euler-graph3.json": {"camel_22590": 0, "camel_22585": 0, "camel_22600": 0, "camel_22881": 0, "camel_23888": 0, "camel_22628": 0, "camel_23889": 0, "camel_22563": 0, "camel_22578": 0, "camel_22157": 0, "camel_22579": 0, "camel_23855": 0, "camel_23917": 0, "camel_23850": 0, "camel_22601": 0, "camel_22614": 0, "camel_22619": 0, "camel_22582": 0, "camel_22596": 0, "camel_23896": 0, "camel_23852": 0, "camel_23885": 0, "camel_23860": 0, "camel_21830": 0, "camel_23845": 0, "camel_23864": 0, "camel_23900": 0, "camel_22560": 0, "camel_23858": 0, "camel_23879": 0, "camel_23859": 0, "camel_23842": 0, "camel_22564": 0, "camel_22638": 0, "camel_22565": 0, "camel_22593": 0, "camel_22570": 0, "camel_22625": 0, "camel_22604": 0, "camel_23895": 0, "camel_23907": 0, "camel_23857": 0, "camel_23846": 0, "camel_22571": 0, "camel_23843": 0, "camel_21098": 0, "camel_23890": 0, "camel_23875": 0, "camel_23854": 0, "camel_23844": 0, "camel_23872": 0, "camel_23863": 0, "camel_23903": 0, "camel_21787": 0, "camel_23902": 0, "camel_23865": 0, "camel_22568": 0, "camel_23847": 0, "camel_23887": 0, "camel_23884": 0, "camel_22632": 0, "camel_22592": 0, "camel_22635": 0, "camel_23913": 0, "camel_23906": 0, "camel_22626": 0, "camel_22595": 0, "camel_22637": 0, "camel_23869": 0, "camel_22634": 0, "camel_22598": 0, "camel_23892": 0, "camel_22589": 0, "camel_22561": 0, "camel_22636": 0, "camel_23873": 0, "camel_23910": 0, "camel_23849": 0, "camel_22572": 0, "camel_22575": 0, "camel_22580": 0, "camel_23911": 0, "camel_23916": 0, "camel_23862": 0, "camel_23901": 0, "camel_22620": 0, "camel_23866": 0, "camel_23904": 0, "camel_22606": 0, "camel_23841": 0, "camel_23894": 0, "camel_23876": 0, "camel_22613": 0, "camel_22562": 0, "camel_22609": 0, "camel_23918": 0, "camel_22584": 0, "camel_23840": 0, "camel_23891": 0, "camel_22611": 0, "camel_23880": 0, "camel_23919": 0, "camel_22581": 0, "camel_22607": 0, "camel_23908": 0, "camel_23868": 0, "camel_22472": 0, "camel_22588": 0, "camel_23871": 0, "camel_23874": 0, "camel_23909": 0, "camel_23856": 0, "camel_22574": 0, "TheoremQA_tonyxia/euler-graph3.json": 0, "camel_23877": 0, "camel_23899": 0, "camel_22907": 0, "camel_22566": 0, "camel_23878": 0, "camel_22610": 0, "camel_22621": 0, "camel_23915": 0, "camel_23867": 0, "camel_23870": 0, "camel_22594": 0, "camel_23905": 0, "camel_22630": 0, "camel_23893": 0, "camel_23881": 0, "camel_22631": 0, "camel_22586": 0, "camel_22569": 0, "camel_23898": 0, "camel_22616": 0, "camel_22605": 0, "camel_22587": 0, "camel_23861": 0, "camel_22591": 0, "camel_23848": 0, "camel_22603": 0, "camel_22624": 0, "camel_22567": 0, "camel_22577": 0, "camel_22622": 0, "camel_22599": 0, "camel_22623": 0, "camel_22639": 0, "camel_22617": 0, "camel_22576": 0, "camel_18664": 0.7438586950302124, "aqua_rat_551": 0.7442765831947327, "camel_18624": 0.7448700666427612, "camel_19363": 0.7469404935836792, "camel_19402": 0.7503958344459534, "math_test_geometry_217": 0.7518312335014343, "camel_18877": 0.7529216408729553, "camel_18688": 0.7534705400466919, "camel_18569": 0.7559518814086914, "math_test_counting_and_probability_385": 0.7596343159675598, "camel_19969": 0.7609683871269226, "camel_18639": 0.7609899044036865, "camel_18662": 0.7612648606300354, "camel_18598": 0.7627285718917847, "math_train_geometry_758": 0.7644338011741638, "aqua_rat_16933": 0.7661305069923401, "camel_19723": 0.7664633989334106, "camel_18715": 0.7682603001594543, "camel_18674": 0.7687351703643799, "camel_18675": 0.7688896656036377, "camel_18711": 0.7711992263793945, "camel_19970": 0.7719871401786804, "camel_19956": 0.7774049639701843, "camel_19741": 0.7792492508888245, "math_train_prealgebra_519": 0.7797014117240906, "camel_18676": 0.791271984577179, "camel_18638": 0.7965978384017944, "math_train_geometry_6085": 0.7982702851295471, "camel_18686": 0.8006062507629395, "camel_18652": 0.8041368722915649, "camel_18964": 0.8046506643295288, "camel_18831": 0.8110314607620239, "camel_18634": 0.8120715618133545, "camel_18644": 0.8153693675994873, "camel_19888": 0.8238680958747864, "camel_18673": 0.8309347629547119, "camel_19812": 0.8324493765830994, "camel_18627": 0.8343521952629089, "camel_18608": 0.8356722593307495, "camel_18658": 0.836566686630249, "camel_18659": 0.8370979428291321, "math_train_geometry_6025": 0.8439277410507202, "TheoremQA_tonyxia/euler-graph2.json": 0.8439752459526062, "camel_18679": 0.8455283045768738, "TheoremQA_tonyxia/maxplanar1.json": 0.8538908958435059, "TheoremQA_tonyxia/maxplanar3.json": 0.8545510768890381, "camel_18717": 0.8555757999420166, "camel_18699": 0.859262228012085, "camel_18701": 0.8604297637939453, "camel_18672": 0.8650480508804321, "camel_18677": 0.8654801249504089}, "TheoremQA_xueguangma/forward_price_2.json": {"TheoremQA_xueguangma/forward_price_2.json": 0, "aqua_rat_18368": 0.6672645211219788, "aqua_rat_67442": 0.6674183011054993, "gsm_rft_6618": 0.6675608158111572, "aqua_rat_17751": 0.6677026748657227, "gsm_rft_35170": 0.6677592992782593, "aqua_rat_88960": 0.6679659485816956, "gsm_rft_15334": 0.6680160760879517, "gsm_train_6037": 0.6680160760879517, "aqua_rat_88415": 0.6680602431297302, "aqua_rat_47761": 0.6685755848884583, "aqua_rat_83774": 0.6685823202133179, "aqua_rat_53568": 0.6686258912086487, "aqua_rat_16445": 0.6687477827072144, "gsm_rft_11620": 0.6688066720962524, "aqua_rat_3687": 0.6689473986625671, "aqua_rat_54028": 0.6690465211868286, "aqua_rat_88758": 0.6690752506256104, "aqua_rat_47773": 0.6692109704017639, "math_test_algebra_1862": 0.669367790222168, "gsm_train_25622": 0.6694805026054382, "math_test_algebra_337": 0.6694830656051636, "aqua_rat_24052": 0.6696180701255798, "aqua_rat_69447": 0.6698896288871765, "aqua_rat_66371": 0.6699727773666382, "gsm_rft_6203": 0.6700742840766907, "aqua_rat_27039": 0.6702298521995544, "aqua_rat_42515": 0.6703392863273621, "aqua_rat_64422": 0.6706393361091614, "aqua_rat_24068": 0.6708256602287292, "aqua_rat_68014": 0.6708655953407288, "aqua_rat_40489": 0.670885443687439, "aqua_rat_75047": 0.6708892583847046, "aqua_rat_48494": 0.6713423728942871, "aqua_rat_64105": 0.6716720461845398, "aqua_rat_73739": 0.6717752814292908, "gsm_rft_5849": 0.6717820763587952, "gsm_rft_33478": 0.6718571782112122, "gsm_rft_7891": 0.6718594431877136, "gsm_rft_33006": 0.6718964576721191, "gsm_train_30707": 0.6719580292701721, "aqua_rat_33923": 0.6719939112663269, "gsm_rft_20456": 0.6721689701080322, "aqua_rat_25723": 0.6721948981285095, "aqua_rat_16448": 0.6723254919052124, "aqua_rat_28883": 0.6723905801773071, "gsm_rft_33659": 0.672616183757782, "math_train_algebra_369": 0.6730980277061462, "aqua_rat_67841": 0.6732514500617981, "aqua_rat_3402": 0.6732594966888428, "aqua_rat_75833": 0.6735334992408752, "aqua_rat_869": 0.6737480759620667, "aqua_rat_10990": 0.6739615201950073, "aqua_rat_83740": 0.6740311980247498, "aqua_rat_65263": 0.6740661859512329, "gsm_rft_3411": 0.674189567565918, "aqua_rat_49908": 0.6742417216300964, "aqua_rat_735": 0.6746746301651001, "aqua_rat_39424": 0.6747866868972778, "aqua_rat_72412": 0.6749811172485352, "aqua_rat_66298": 0.6750613451004028, "aqua_rat_46898": 0.6750833988189697, "gsm_rft_1672": 0.6751087307929993, "aqua_rat_75046": 0.6751315593719482, "aqua_rat_36240": 0.6753059029579163, "gsm_train_3010": 0.6753897070884705, "aqua_rat_77602": 0.675403892993927, "aqua_rat_67696": 0.6754255890846252, "math_train_algebra_667": 0.6757814884185791, "gsm_rft_27542": 0.6757861971855164, "aqua_rat_59829": 0.6758984923362732, "math_train_algebra_2507": 0.6761170029640198, "aqua_rat_64976": 0.676148533821106, "gsm_rft_7096": 0.6763099431991577, "gsm_rft_11804": 0.6763299107551575, "aqua_rat_34081": 0.6768245697021484, "aqua_rat_26043": 0.6769852042198181, "aqua_rat_87246": 0.6770550012588501, "aqua_rat_82669": 0.6770725846290588, "aqua_rat_30897": 0.6770733594894409, "aqua_rat_59": 0.6772527098655701, "aqua_rat_34698": 0.6772578954696655, "gsm_rft_19766": 0.6775410771369934, "aqua_rat_32350": 0.6778187155723572, "aqua_rat_59892": 0.6778690218925476, "gsm_rft_33880": 0.6779999136924744, "aqua_rat_10902": 0.6780213117599487, "aqua_rat_70690": 0.6780368089675903, "aqua_rat_64995": 0.6782437562942505, "aqua_rat_1549": 0.6783507466316223, "aqua_rat_9965": 0.679092526435852, "aqua_rat_84309": 0.679176390171051, "aqua_rat_43060": 0.6791864633560181, "aqua_rat_87884": 0.6793221235275269, "aqua_rat_63070": 0.6794891953468323, "aqua_rat_10686": 0.6799855828285217, "gsm_rft_33978": 0.6802628636360168, "gsm_train_34054": 0.6802628636360168, "aqua_rat_64914": 0.6803461909294128, "gsm_rft_7026": 0.6803577542304993, "gsm_rft_24137": 0.6804887652397156, "aqua_rat_56852": 0.680911123752594, "aqua_rat_69905": 0.6809580326080322, "aqua_rat_86517": 0.6811656951904297, "aqua_rat_59160": 0.681185781955719, "aqua_rat_28984": 0.6812158823013306, "aqua_rat_29356": 0.6814882755279541, "gsm_rft_20212": 0.6820687055587769, "aqua_rat_72794": 0.6821288466453552, "aqua_rat_54684": 0.6822646856307983, "aqua_rat_83524": 0.6825274229049683, "gsm_rft_10656": 0.6825829744338989, "aqua_rat_84646": 0.6830053925514221, "aqua_rat_33430": 0.6831727623939514, "TheoremQA_xueguangma/present_value_1.json": 0.6831764578819275, "aqua_rat_255": 0.6833628416061401, "gsm_rft_30946": 0.6836860775947571, "gsm_train_34036": 0.6840314865112305, "aqua_rat_24182": 0.6845608353614807, "aqua_rat_42017": 0.6847532987594604, "aqua_rat_67076": 0.6848134994506836, "aqua_rat_57507": 0.6849043965339661, "gsm_rft_9014": 0.6850571036338806, "aqua_rat_32852": 0.6852825880050659, "aqua_rat_7674": 0.6857059001922607, "aqua_rat_21626": 0.6862466335296631, "aqua_rat_88843": 0.68670654296875, "aqua_rat_30597": 0.6867231130599976, "math_train_algebra_940": 0.6868963837623596, "aqua_rat_23277": 0.6870664954185486, "aqua_rat_17663": 0.6870712041854858, "aqua_rat_87589": 0.687316358089447, "aqua_rat_42949": 0.6873500347137451, "aqua_rat_70031": 0.6874121427536011, "aqua_rat_30386": 0.6875091791152954, "aqua_rat_65883": 0.6875705122947693, "aqua_rat_65797": 0.6880501508712769, "aqua_rat_1058": 0.688116192817688, "aqua_rat_8732": 0.688391923904419, "aqua_rat_48160": 0.6886847615242004, "aqua_rat_77609": 0.6888320446014404, "aqua_rat_38648": 0.689255952835083, "aqua_rat_3773": 0.6894021034240723, "aqua_rat_86835": 0.6895874738693237, "aqua_rat_56436": 0.6905173659324646, "math_test_algebra_2626": 0.6906103491783142, "math_test_algebra_311": 0.6907826662063599, "aqua_rat_57943": 0.6910035014152527, "aqua_rat_78121": 0.691106379032135, "aqua_rat_41963": 0.691313624382019, "gsm_rft_12584": 0.6919932961463928, "gsm_train_28727": 0.6921380162239075, "gsm_rft_35249": 0.6928553581237793, "aqua_rat_15079": 0.6928738355636597, "aqua_rat_63322": 0.6934978365898132, "aqua_rat_10582": 0.6942581534385681, "aqua_rat_32321": 0.6948010325431824, "gsm_rft_7115": 0.6950486898422241, "gsm_train_9412": 0.6950486898422241, "aqua_rat_6283": 0.6951773166656494, "aqua_rat_69547": 0.6952611804008484, "aqua_rat_51100": 0.6958040595054626, "aqua_rat_79856": 0.6958690285682678, "aqua_rat_1115": 0.6964353322982788, "aqua_rat_21296": 0.6968399882316589, "aqua_rat_56718": 0.6970863342285156, "aqua_rat_45263": 0.697618842124939, "aqua_rat_63735": 0.6982414722442627, "aqua_rat_14728": 0.6993226408958435, "aqua_rat_49352": 0.7032543420791626, "aqua_rat_80676": 0.7048309445381165, "aqua_rat_40411": 0.7048407196998596, "aqua_rat_62727": 0.7053976655006409, "camel_16747": 0.7058942317962646, "aqua_rat_50660": 0.7059844732284546, "aqua_rat_78193": 0.7076455354690552, "aqua_rat_78533": 0.7093755602836609, "aqua_rat_26425": 0.7095204591751099, "aqua_rat_9033": 0.7096875309944153, "aqua_rat_79047": 0.7097886800765991, "aqua_rat_45586": 0.711767852306366, "aqua_rat_37463": 0.7121450304985046, "aqua_rat_3885": 0.7204909920692444, "aqua_rat_45508": 0.7236710786819458, "aqua_rat_20758": 0.7261112928390503, "aqua_rat_72737": 0.727925181388855, "aqua_rat_36461": 0.7286532521247864, "TheoremQA_xueguangma/forward_price_3.json": 0.7287833094596863, "aqua_rat_45867": 0.7301064729690552, "aqua_rat_36498": 0.733756422996521, "aqua_rat_46315": 0.7347025871276855, "camel_45730": 0.7352949380874634, "aqua_rat_31553": 0.735763669013977, "aqua_rat_29154": 0.7491856813430786, "aqua_rat_85902": 0.7494268417358398, "camel_45738": 0.7501469254493713, "TheoremQA_xueguangma/put_call_parity_1.json": 0.7506347894668579, "TheoremQA_xueguangma/forward_price_1.json": 0.7612676620483398, "TheoremQA_xueguangma/spot_rate.json": 0.770429253578186, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7806403040885925}, "TheoremQA_maxku/ipnetwork13-hammingdist.json": {"TheoremQA_maxku/ipnetwork13-hammingdist.json": 0, "aqua_rat_35061": 0.672186017036438, "camel_9134": 0.6722226738929749, "camel_35734": 0.6723357439041138, "aqua_rat_9572": 0.6724114418029785, "aqua_rat_89078": 0.6724319458007812, "aqua_rat_6669": 0.672460675239563, "gsm_rft_25314": 0.6724683046340942, "aqua_rat_78272": 0.6724880337715149, "aqua_rat_72504": 0.672723114490509, "gsm_rft_21345": 0.6728139519691467, "aqua_rat_62373": 0.6729194521903992, "aqua_rat_12473": 0.6729320287704468, "aqua_rat_33891": 0.6729405522346497, "math_train_counting_and_probability_31": 0.6729933023452759, "aqua_rat_66366": 0.6730490326881409, "aqua_rat_30525": 0.673130452632904, "gsm_rft_35151": 0.6731724143028259, "gsm_rft_10427": 0.6732176542282104, "aqua_rat_32080": 0.6732524037361145, "aqua_rat_67043": 0.6732655763626099, "aqua_rat_6489": 0.6732763051986694, "aqua_rat_37367": 0.6733455061912537, "camel_35048": 0.6733824610710144, "aqua_rat_56418": 0.6734314560890198, "aqua_rat_68474": 0.6736376285552979, "camel_35916": 0.6736515164375305, "gsm_rft_20820": 0.673668384552002, "camel_35064": 0.6736695766448975, "aqua_rat_20046": 0.673828661441803, "gsm_rft_11599": 0.6739293932914734, "camel_36838": 0.6739659309387207, "gsm_train_29880": 0.6740302443504333, "gsm_train_9366": 0.6740608215332031, "gsm_rft_14709": 0.6740608215332031, "gsm_rft_9771": 0.6740608215332031, "aqua_rat_50973": 0.6740615367889404, "aqua_rat_43800": 0.6741195917129517, "aqua_rat_87221": 0.674300491809845, "aqua_rat_85967": 0.6743074059486389, "aqua_rat_83131": 0.6743144392967224, "camel_26445": 0.6743754148483276, "aqua_rat_49131": 0.6744668483734131, "aqua_rat_15961": 0.6746360063552856, "aqua_rat_10212": 0.6746519207954407, "aqua_rat_78802": 0.674695611000061, "camel_21989": 0.6747443675994873, "camel_35947": 0.6747561097145081, "camel_38481": 0.6748230457305908, "camel_35192": 0.6748239994049072, "gsm_train_7585": 0.674907922744751, "gsm_rft_10080": 0.674907922744751, "gsm_rft_10682": 0.6749871373176575, "aqua_rat_75785": 0.6749979257583618, "camel_23088": 0.6750702857971191, "aqua_rat_12308": 0.6753228306770325, "aqua_rat_5176": 0.6753272414207458, "aqua_rat_11272": 0.6754313707351685, "gsm_rft_8475": 0.6754569411277771, "aqua_rat_32347": 0.6755154132843018, "aqua_rat_74175": 0.6755210757255554, "aqua_rat_52991": 0.6755713820457458, "camel_35063": 0.6756238341331482, "aqua_rat_8387": 0.6756329536437988, "aqua_rat_49426": 0.6756939888000488, "camel_35754": 0.6757276058197021, "gsm_rft_23120": 0.6757550239562988, "math_train_intermediate_algebra_1963": 0.6757922172546387, "aqua_rat_84064": 0.6757972240447998, "camel_21334": 0.6758046746253967, "camel_23106": 0.6758207082748413, "aqua_rat_38075": 0.6758625507354736, "camel_37456": 0.6758649945259094, "aqua_rat_26096": 0.6758694052696228, "aqua_rat_80377": 0.6758877038955688, "aqua_rat_71652": 0.675896406173706, "aqua_rat_72870": 0.6759188771247864, "gsm_rft_27829": 0.6759549379348755, "camel_21949": 0.6760358810424805, "camel_21935": 0.6761876344680786, "aqua_rat_13068": 0.6762933731079102, "aqua_rat_35957": 0.6763017773628235, "aqua_rat_78005": 0.6763549447059631, "camel_35609": 0.6764500737190247, "aqua_rat_33752": 0.6766297221183777, "camel_23063": 0.6768363118171692, "gsm_rft_4268": 0.6769094467163086, "aqua_rat_43867": 0.6769118309020996, "camel_35709": 0.6769701242446899, "aqua_rat_60004": 0.6770200133323669, "aqua_rat_34769": 0.6771420836448669, "camel_35561": 0.6772988438606262, "camel_36368": 0.6775673627853394, "camel_35845": 0.6777336597442627, "aqua_rat_26864": 0.6777439117431641, "aqua_rat_75580": 0.6782477498054504, "camel_23067": 0.6788526773452759, "aqua_rat_71449": 0.6789225339889526, "camel_21477": 0.6789991855621338, "gsm_rft_25665": 0.679047167301178, "aqua_rat_88083": 0.6790707111358643, "aqua_rat_21283": 0.6791936755180359, "aqua_rat_70072": 0.6792223453521729, "aqua_rat_49211": 0.6792774796485901, "aqua_rat_19731": 0.6793371438980103, "gsm_rft_33146": 0.6793408393859863, "aqua_rat_85269": 0.6795706152915955, "camel_35772": 0.6796374320983887, "gsm_rft_11616": 0.6796637773513794, "camel_35756": 0.6802327036857605, "aqua_rat_2854": 0.6802788972854614, "math_train_counting_and_probability_769": 0.6804178953170776, "gsm_rft_4221": 0.6805499792098999, "aqua_rat_66818": 0.6805976629257202, "camel_35790": 0.6807774305343628, "camel_35893": 0.6809893250465393, "camel_35102": 0.6809911727905273, "camel_26436": 0.6811502575874329, "camel_37444": 0.6811636686325073, "camel_35459": 0.6813808083534241, "gsm_rft_17952": 0.6813881993293762, "aqua_rat_16574": 0.6814516186714172, "gsm_rft_24803": 0.6814802289009094, "gsm_train_35467": 0.6817523837089539, "aqua_rat_66103": 0.6817668080329895, "aqua_rat_10404": 0.6820983290672302, "aqua_rat_16098": 0.6828016042709351, "camel_15836": 0.6828144788742065, "camel_35095": 0.6828999519348145, "gsm_rft_11457": 0.6829428672790527, "aqua_rat_56916": 0.6829586029052734, "camel_35783": 0.683078408241272, "camel_21952": 0.683082640171051, "aqua_rat_86075": 0.68369460105896, "camel_37459": 0.684014081954956, "camel_19952": 0.6840407252311707, "camel_23100": 0.6842750906944275, "math_train_counting_and_probability_467": 0.6843799352645874, "aqua_rat_32047": 0.6845858097076416, "aqua_rat_9869": 0.6848610639572144, "camel_21975": 0.6855894327163696, "aqua_rat_28998": 0.6856870651245117, "gsm_rft_8013": 0.6858308911323547, "camel_21980": 0.6862348318099976, "aqua_rat_10179": 0.6872392892837524, "camel_35368": 0.6872934103012085, "camel_35878": 0.6874287724494934, "aqua_rat_87185": 0.6876179575920105, "camel_21921": 0.6878713369369507, "camel_35108": 0.6878848075866699, "aqua_rat_34919": 0.6883087754249573, "aqua_rat_65518": 0.6884754300117493, "camel_31199": 0.6887181997299194, "aqua_rat_60981": 0.6890268325805664, "camel_26421": 0.6895594000816345, "camel_20866": 0.6896589994430542, "gsm_rft_31633": 0.689846396446228, "aqua_rat_85697": 0.6902117133140564, "math_test_counting_and_probability_855": 0.690712034702301, "gsm_train_29739": 0.6910735368728638, "gsm_rft_24906": 0.6911990642547607, "aqua_rat_13646": 0.6912069916725159, "gsm_rft_9540": 0.6916371583938599, "camel_36542": 0.692520260810852, "camel_36754": 0.6928702592849731, "aqua_rat_5625": 0.6933901309967041, "aqua_rat_1879": 0.6936265230178833, "aqua_rat_108": 0.6936817765235901, "aqua_rat_13625": 0.6938244700431824, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.6938770413398743, "aqua_rat_1953": 0.6940276026725769, "aqua_rat_68856": 0.6945933699607849, "aqua_rat_72814": 0.696298360824585, "math_test_number_theory_340": 0.6975607872009277, "camel_21936": 0.6985637545585632, "camel_35789": 0.6988632082939148, "aqua_rat_12157": 0.7007102370262146, "aqua_rat_43433": 0.7008564472198486, "aqua_rat_21385": 0.7012365460395813, "math_train_counting_and_probability_5109": 0.701676070690155, "aqua_rat_78747": 0.7016950249671936, "aqua_rat_15776": 0.7023324966430664, "camel_35780": 0.7023791074752808, "camel_21969": 0.7025750279426575, "camel_21940": 0.7040672898292542, "TheoremQA_maxku/cv-imageprocessing6-histogram.json": 0.7040997743606567, "camel_21942": 0.7049576044082642, "aqua_rat_69333": 0.7054277062416077, "math_train_counting_and_probability_5032": 0.7063789963722229, "camel_21923": 0.7065778374671936, "aqua_rat_33509": 0.7098507881164551, "math_train_number_theory_1088": 0.7131437063217163, "camel_21962": 0.7170432209968567, "camel_21944": 0.7188754677772522, "camel_21976": 0.7199832201004028, "camel_37553": 0.7204694747924805, "camel_21995": 0.7219712138175964, "camel_21992": 0.7288039326667786, "aqua_rat_73229": 0.740917980670929, "TheoremQA_maxku/ipnetwork14-hammingdist.json": 0.7972670793533325}, "TheoremQA_jianyu_xu/combination_1.json": {"camel_21822": 0, "camel_21215": 0, "camel_20948": 0, "camel_21000": 0, "camel_20272": 0, "camel_20804": 0, "camel_20730": 0, "camel_21572": 0, "camel_20913": 0, "camel_20240": 0, "camel_21022": 0, "camel_20984": 0, "camel_20505": 0, "camel_21227": 0, "camel_20364": 0, "camel_20525": 0, "camel_21039": 0, "camel_20312": 0, "camel_20256": 0, "camel_20378": 0, "camel_20271": 0, "camel_21005": 0, "camel_20749": 0, "camel_21568": 0, "TheoremQA_jianyu_xu/combination_1.json": 0, "camel_20336": 0, "camel_20293": 0, "camel_20394": 0, "camel_20930": 0, "camel_20046": 0, "camel_20931": 0, "aqua_rat_71071": 0.7927727699279785, "aqua_rat_76349": 0.7931585311889648, "aqua_rat_13243": 0.7935295701026917, "aqua_rat_11347": 0.7939225435256958, "aqua_rat_33834": 0.7941425442695618, "aqua_rat_15730": 0.7942001223564148, "aqua_rat_49386": 0.7947704792022705, "aqua_rat_72660": 0.7948486804962158, "aqua_rat_35428": 0.7949732542037964, "aqua_rat_49053": 0.7950376272201538, "aqua_rat_72708": 0.7950420379638672, "aqua_rat_62787": 0.7951158881187439, "aqua_rat_33011": 0.7951288819313049, "aqua_rat_78953": 0.7954270243644714, "aqua_rat_15099": 0.7955437898635864, "aqua_rat_31467": 0.7956423759460449, "aqua_rat_89036": 0.7960492372512817, "aqua_rat_39411": 0.7961531281471252, "aqua_rat_67500": 0.7961928844451904, "aqua_rat_33533": 0.7962468266487122, "aqua_rat_58792": 0.7962538599967957, "aqua_rat_87992": 0.7965787649154663, "aqua_rat_84736": 0.796646773815155, "aqua_rat_62645": 0.7966846823692322, "aqua_rat_69481": 0.796746551990509, "aqua_rat_21628": 0.7968392968177795, "aqua_rat_65893": 0.7969527244567871, "aqua_rat_8728": 0.7970690727233887, "aqua_rat_60755": 0.7973031997680664, "aqua_rat_52325": 0.7973863482475281, "aqua_rat_76624": 0.7979046106338501, "aqua_rat_80017": 0.7980255484580994, "aqua_rat_72310": 0.7981016039848328, "aqua_rat_30355": 0.7981273531913757, "aqua_rat_81792": 0.798271119594574, "aqua_rat_47740": 0.7983647584915161, "aqua_rat_74248": 0.798393189907074, "aqua_rat_26005": 0.7985305190086365, "aqua_rat_3589": 0.7985522747039795, "aqua_rat_7156": 0.7985744476318359, "math_train_counting_and_probability_910": 0.7986951470375061, "aqua_rat_73356": 0.7987834811210632, "aqua_rat_24776": 0.7988311052322388, "math_test_counting_and_probability_857": 0.7990761995315552, "math_train_counting_and_probability_949": 0.79925537109375, "aqua_rat_10993": 0.7992615699768066, "aqua_rat_44130": 0.799273669719696, "aqua_rat_52136": 0.7994357943534851, "aqua_rat_20529": 0.7994889616966248, "aqua_rat_86831": 0.7994917631149292, "aqua_rat_13918": 0.7995486855506897, "aqua_rat_74719": 0.7996591329574585, "math_train_counting_and_probability_961": 0.7997588515281677, "aqua_rat_52756": 0.7999979257583618, "aqua_rat_37642": 0.8004422187805176, "aqua_rat_19500": 0.8010381460189819, "aqua_rat_29514": 0.801630437374115, "aqua_rat_84364": 0.8017247915267944, "math_train_counting_and_probability_918": 0.8023038506507874, "aqua_rat_60892": 0.8023136258125305, "aqua_rat_33613": 0.8025799989700317, "aqua_rat_73365": 0.8027049899101257, "aqua_rat_81265": 0.8027226328849792, "aqua_rat_60522": 0.8028079867362976, "aqua_rat_29732": 0.8031413555145264, "aqua_rat_39388": 0.8031437397003174, "aqua_rat_68198": 0.8031843900680542, "aqua_rat_10290": 0.8033117055892944, "aqua_rat_48676": 0.8041980266571045, "aqua_rat_74651": 0.8045049905776978, "aqua_rat_43584": 0.8045839071273804, "aqua_rat_80108": 0.8046122789382935, "aqua_rat_81997": 0.8052436709403992, "aqua_rat_47648": 0.805932879447937, "aqua_rat_49270": 0.8062790036201477, "aqua_rat_28538": 0.8064338564872742, "aqua_rat_42155": 0.8067131638526917, "math_test_counting_and_probability_568": 0.8069705367088318, "aqua_rat_81548": 0.8069841265678406, "aqua_rat_35292": 0.8076924681663513, "aqua_rat_8402": 0.8083778023719788, "aqua_rat_21291": 0.8090406060218811, "aqua_rat_74505": 0.8090786933898926, "aqua_rat_779": 0.8092357516288757, "aqua_rat_43064": 0.8092483282089233, "aqua_rat_31872": 0.8093847632408142, "aqua_rat_50541": 0.8094387054443359, "aqua_rat_73601": 0.809539258480072, "aqua_rat_84277": 0.8096674680709839, "aqua_rat_7992": 0.8103033304214478, "aqua_rat_57693": 0.810378909111023, "math_train_counting_and_probability_531": 0.8112986087799072, "aqua_rat_66620": 0.8115535974502563, "aqua_rat_57246": 0.8118599057197571, "aqua_rat_10235": 0.8123002052307129, "aqua_rat_8381": 0.8125984072685242, "aqua_rat_12398": 0.8137311935424805, "aqua_rat_24605": 0.8139273524284363, "aqua_rat_89302": 0.813939094543457, "aqua_rat_58614": 0.8139899373054504, "aqua_rat_82553": 0.8145200610160828, "aqua_rat_62500": 0.8146184682846069, "aqua_rat_8021": 0.8153277635574341, "camel_38505": 0.8155445456504822, "aqua_rat_13853": 0.8162053823471069, "aqua_rat_82104": 0.816508412361145, "aqua_rat_52707": 0.8167477250099182, "aqua_rat_79094": 0.8169106841087341, "aqua_rat_30109": 0.8170363903045654, "aqua_rat_78895": 0.8171797394752502, "aqua_rat_62768": 0.8172035813331604, "aqua_rat_66240": 0.8173396587371826, "aqua_rat_71137": 0.8179014325141907, "aqua_rat_70861": 0.8179027438163757, "aqua_rat_83919": 0.81885826587677, "math_train_counting_and_probability_122": 0.8197742700576782, "aqua_rat_78074": 0.8204139471054077, "aqua_rat_23582": 0.8206415176391602, "aqua_rat_44882": 0.8208385705947876, "aqua_rat_72693": 0.8208532929420471, "aqua_rat_27914": 0.8210489153862, "math_train_counting_and_probability_373": 0.8223275542259216, "aqua_rat_79238": 0.822333812713623, "aqua_rat_37223": 0.8224363327026367, "aqua_rat_71649": 0.8224812746047974, "aqua_rat_88915": 0.8225935101509094, "aqua_rat_74695": 0.8225997686386108, "aqua_rat_78110": 0.8227024674415588, "math_test_counting_and_probability_776": 0.8229376673698425, "aqua_rat_17617": 0.8229864835739136, "aqua_rat_47989": 0.8234665393829346, "aqua_rat_38694": 0.8237457275390625, "aqua_rat_65642": 0.8238139748573303, "aqua_rat_42177": 0.8245574235916138, "aqua_rat_38594": 0.8249512910842896, "aqua_rat_80242": 0.8250383734703064, "aqua_rat_50942": 0.8260201215744019, "aqua_rat_88418": 0.8260735869407654, "aqua_rat_46685": 0.8262022733688354, "aqua_rat_59702": 0.8274627923965454, "aqua_rat_28657": 0.8279582858085632, "aqua_rat_29513": 0.8280196785926819, "aqua_rat_22214": 0.8281428813934326, "aqua_rat_66465": 0.8286435008049011, "aqua_rat_2510": 0.8293610215187073, "aqua_rat_35044": 0.8315519094467163, "aqua_rat_53149": 0.8324706554412842, "aqua_rat_58323": 0.8325905799865723, "aqua_rat_75767": 0.8328701257705688, "aqua_rat_25933": 0.8336288928985596, "aqua_rat_40812": 0.8337556719779968, "aqua_rat_82511": 0.834041178226471, "aqua_rat_76271": 0.8343560099601746, "aqua_rat_83206": 0.8356276750564575, "aqua_rat_8673": 0.8366538882255554, "aqua_rat_37301": 0.8370113968849182, "aqua_rat_72210": 0.8377554416656494, "aqua_rat_44716": 0.8380507230758667, "aqua_rat_67179": 0.8385134935379028, "aqua_rat_51559": 0.8392691612243652, "aqua_rat_53805": 0.8407729864120483, "aqua_rat_17402": 0.8409896492958069, "aqua_rat_27717": 0.8429286479949951, "math_test_counting_and_probability_216": 0.8453487157821655, "aqua_rat_75970": 0.8468382954597473, "aqua_rat_57520": 0.8515768051147461, "aqua_rat_7409": 0.8524948358535767, "aqua_rat_58707": 0.8551891446113586, "aqua_rat_18439": 0.855397641658783}, "TheoremQA_xinyi/linear_projection.json": {"camel_15083": 0, "camel_14483": 0, "camel_15052": 0, "camel_14465": 0, "camel_14470": 0, "camel_15142": 0, "camel_15197": 0, "camel_14508": 0, "camel_15374": 0, "camel_14504": 0, "camel_15803": 0, "camel_14529": 0, "camel_15727": 0, "camel_15425": 0, "camel_15161": 0, "camel_14492": 0, "camel_15750": 0, "camel_14517": 0, "camel_15056": 0, "camel_15182": 0, "camel_14473": 0, "camel_14548": 0, "camel_14486": 0, "camel_14451": 0, "camel_14541": 0, "camel_14522": 0, "camel_14536": 0, "camel_15436": 0, "camel_14405": 0, "camel_14484": 0, "camel_14452": 0, "camel_14509": 0, "camel_14518": 0, "camel_14469": 0, "camel_14557": 0, "camel_14495": 0, "camel_14512": 0, "camel_15190": 0, "camel_14558": 0, "camel_14515": 0, "camel_15072": 0, "camel_14552": 0, "camel_15043": 0, "camel_14533": 0, "camel_14511": 0, "camel_15728": 0, "camel_15185": 0, "camel_14407": 0, "camel_15137": 0, "camel_15777": 0, "camel_14481": 0, "camel_15199": 0, "camel_15157": 0, "camel_14446": 0, "camel_14501": 0, "camel_15704": 0, "camel_14527": 0, "camel_15796": 0, "camel_14543": 0, "camel_15586": 0, "camel_15147": 0, "camel_14491": 0, "camel_14528": 0, "camel_14413": 0, "camel_14550": 0, "camel_14453": 0, "camel_14500": 0, "camel_14540": 0, "camel_14553": 0, "camel_14416": 0, "camel_14549": 0, "camel_14502": 0, "camel_14546": 0, "camel_14551": 0, "camel_14498": 0, "camel_15108": 0, "camel_15775": 0, "camel_14523": 0, "camel_14496": 0, "camel_14521": 0, "camel_15818": 0, "camel_14392": 0, "camel_14537": 0, "camel_14513": 0, "camel_15826": 0, "camel_15822": 0, "camel_15362": 0, "camel_15835": 0, "camel_15838": 0, "camel_15365": 0, "camel_15801": 0, "camel_14488": 0, "camel_14507": 0, "camel_15794": 0, "camel_15051": 0, "camel_14468": 0, "camel_14545": 0, "camel_14506": 0, "camel_14480": 0, "camel_14516": 0, "camel_14539": 0, "camel_15170": 0, "camel_15816": 0, "camel_14499": 0, "camel_14519": 0, "camel_14457": 0, "camel_15807": 0, "camel_14494": 0, "camel_14532": 0, "camel_15768": 0, "camel_14420": 0, "camel_14531": 0, "camel_14525": 0, "camel_14556": 0, "camel_15827": 0, "camel_15806": 0, "camel_15134": 0, "camel_15427": 0, "camel_14534": 0, "camel_15591": 0, "camel_15761": 0, "camel_14555": 0, "camel_15074": 0, "camel_14547": 0, "camel_15792": 0, "camel_15760": 0, "camel_14482": 0, "camel_15765": 0, "camel_14542": 0, "camel_14524": 0, "camel_14535": 0, "camel_15812": 0, "camel_14520": 0, "camel_14505": 0, "TheoremQA_xinyi/linear_projection.json": 0, "camel_15089": 0, "camel_14526": 0, "camel_14503": 0, "camel_14485": 0, "camel_14497": 0, "math_test_precalculus_251": 0.6984107494354248, "TheoremQA_elainewan/math_algebra_5.json": 0.6987819075584412, "camel_17679": 0.69887375831604, "math_test_precalculus_968": 0.6988758444786072, "camel_47293": 0.6997528672218323, "TheoremQA_mingyin/gaussian-elimination2.json": 0.6998603343963623, "camel_27607": 0.7000344395637512, "camel_43481": 0.7000405192375183, "math_train_precalculus_975": 0.7006584405899048, "camel_49885": 0.7009080052375793, "camel_45517": 0.7017378807067871, "math_test_precalculus_1032": 0.7018375992774963, "math_test_precalculus_617": 0.7019133567810059, "camel_47797": 0.7022483944892883, "math_train_precalculus_480": 0.7031305432319641, "camel_47359": 0.7035718560218811, "camel_40124": 0.7041999697685242, "camel_18845": 0.7042284607887268, "math_train_precalculus_900": 0.7045130729675293, "math_test_precalculus_504": 0.7046478986740112, "camel_28786": 0.7054190635681152, "math_test_precalculus_1033": 0.7058521509170532, "math_test_precalculus_0": 0.7063495516777039, "camel_18998": 0.7067937254905701, "math_train_precalculus_1205": 0.7068018913269043, "TheoremQA_mingyin/minimal-polynomial1.json": 0.707678496837616, "math_train_precalculus_95": 0.708312451839447, "math_test_precalculus_636": 0.7083649635314941, "TheoremQA_elainewan/math_algebra_4_3.json": 0.7095069289207458, "math_train_precalculus_271": 0.7096086144447327, "math_train_precalculus_290": 0.7096613049507141, "camel_9251": 0.7097193002700806, "camel_45460": 0.7113268971443176, "camel_47338": 0.7119288444519043, "math_train_precalculus_152": 0.7122434377670288, "math_test_precalculus_266": 0.7140148878097534, "math_test_precalculus_356": 0.715835690498352, "math_train_precalculus_550": 0.716328501701355, "camel_18988": 0.7168141007423401, "math_test_precalculus_944": 0.7202706933021545, "math_test_precalculus_1288": 0.721430778503418, "math_train_precalculus_727": 0.7215104699134827, "math_train_precalculus_498": 0.725051999092102, "math_train_precalculus_434": 0.7267731428146362, "math_train_precalculus_510": 0.7268897891044617, "math_train_precalculus_961": 0.7271350622177124, "math_train_precalculus_583": 0.7303698658943176, "math_train_precalculus_950": 0.7330671548843384, "math_train_precalculus_670": 0.7338809370994568, "math_train_precalculus_645": 0.7403995990753174, "math_train_precalculus_404": 0.7427252531051636, "math_test_precalculus_755": 0.7445344924926758, "math_test_precalculus_744": 0.7461883425712585, "math_test_precalculus_1218": 0.7526478171348572, "math_test_precalculus_341": 0.7530582547187805, "math_train_precalculus_306": 0.7567468881607056, "math_train_precalculus_1007": 0.7588558197021484, "math_train_precalculus_1213": 0.7641075849533081, "math_train_precalculus_87": 0.777872622013092, "math_train_precalculus_368": 0.8105877637863159}, "TheoremQA_tonyxia/semiconductor1.json": {"TheoremQA_tonyxia/semiconductor1.json": 0, "camel_45629": 0.5810849070549011, "camel_16524": 0.5811793208122253, "camel_29276": 0.5816771388053894, "camel_29255": 0.5817162990570068, "camel_37938": 0.5817350745201111, "aqua_rat_73351": 0.5818274021148682, "camel_16212": 0.5820125341415405, "aqua_rat_48818": 0.5822451114654541, "camel_16192": 0.582361102104187, "camel_29121": 0.5824770331382751, "camel_45650": 0.582729160785675, "camel_29211": 0.5829411149024963, "camel_16505": 0.5829445719718933, "camel_29266": 0.5832058787345886, "camel_16536": 0.5833958387374878, "camel_29237": 0.5834643840789795, "camel_16546": 0.5834922790527344, "camel_44993": 0.5835518836975098, "camel_16510": 0.5836507678031921, "camel_17261": 0.5837773084640503, "gsm_rft_14019": 0.5840304493904114, "camel_29256": 0.5840992331504822, "camel_45148": 0.5841057896614075, "camel_45921": 0.5843676924705505, "camel_17321": 0.5848003625869751, "aqua_rat_39472": 0.584814727306366, "camel_44996": 0.5852652192115784, "camel_17270": 0.5854432582855225, "camel_16360": 0.5854668617248535, "gsm_rft_21326": 0.5854806303977966, "camel_16195": 0.5856813192367554, "camel_28122": 0.5858597755432129, "camel_17217": 0.586020290851593, "gsm_train_4193": 0.586351752281189, "gsm_rft_6591": 0.586351752281189, "camel_29202": 0.5866484045982361, "camel_29254": 0.5866546630859375, "camel_45639": 0.5867119431495667, "camel_29220": 0.5869080424308777, "camel_16350": 0.586958110332489, "camel_16226": 0.5872191190719604, "TheoremQA_panlu/molar_heat_capacity1.json": 0.5875352025032043, "camel_29206": 0.5876773595809937, "camel_29227": 0.5877805948257446, "camel_40467": 0.5877858400344849, "camel_44983": 0.5878053903579712, "camel_45964": 0.588097870349884, "camel_17256": 0.5881342887878418, "camel_45994": 0.5881818532943726, "camel_17241": 0.5882034301757812, "camel_29208": 0.5882527232170105, "gsm_rft_10941": 0.58843594789505, "gsm_train_8512": 0.58843594789505, "camel_29245": 0.5887883305549622, "camel_29222": 0.5897645354270935, "camel_16166": 0.5901464819908142, "camel_29243": 0.5903364419937134, "camel_16163": 0.5903438329696655, "camel_29244": 0.5906985998153687, "camel_45958": 0.5907225608825684, "camel_29146": 0.5912982821464539, "camel_29278": 0.5916327834129333, "camel_29251": 0.591789722442627, "camel_17264": 0.591826856136322, "camel_40433": 0.5918475985527039, "camel_29224": 0.592156171798706, "camel_17901": 0.5922350883483887, "camel_29235": 0.5922558307647705, "camel_16191": 0.5932480096817017, "camel_17323": 0.5935220718383789, "camel_29271": 0.5935710668563843, "camel_16171": 0.5938711166381836, "camel_45012": 0.594167172908783, "math_test_algebra_1865": 0.5947675108909607, "camel_16178": 0.5947827100753784, "aqua_rat_30407": 0.5952855944633484, "camel_37984": 0.5955314636230469, "camel_16197": 0.5955665707588196, "camel_28081": 0.5960028171539307, "gsm_rft_23914": 0.5965187549591064, "camel_45967": 0.5967457890510559, "camel_29225": 0.5969150066375732, "camel_16201": 0.5972631573677063, "camel_17230": 0.5974969267845154, "camel_29265": 0.5978663563728333, "camel_17273": 0.597924530506134, "camel_29258": 0.5981518030166626, "camel_29214": 0.5981636643409729, "camel_29239": 0.5982744097709656, "camel_17234": 0.5983044505119324, "camel_16344": 0.5988213419914246, "gsm_rft_35104": 0.5989380478858948, "camel_29257": 0.599381685256958, "camel_29199": 0.5993943214416504, "camel_17201": 0.5995550751686096, "aqua_rat_21063": 0.5996405482292175, "gsm_train_10153": 0.6002818942070007, "aqua_rat_21090": 0.6007570028305054, "camel_45021": 0.6008632779121399, "camel_44969": 0.6008856296539307, "gsm_rft_21213": 0.601178765296936, "camel_44982": 0.6015725135803223, "camel_29204": 0.6016536951065063, "camel_17243": 0.60187166929245, "camel_37959": 0.6020572185516357, "camel_29216": 0.6021938323974609, "camel_29218": 0.602358341217041, "aqua_rat_55520": 0.6025259494781494, "camel_16173": 0.6034625172615051, "aqua_rat_64101": 0.6034848093986511, "camel_29190": 0.6040406227111816, "aqua_rat_50074": 0.6044512987136841, "camel_17225": 0.6047226190567017, "camel_17248": 0.6047583818435669, "TheoremQA_panlu/molar_heat_capacity2.json": 0.6047793030738831, "aqua_rat_16995": 0.6049301624298096, "camel_29217": 0.6050174832344055, "camel_16230": 0.6052326560020447, "camel_29215": 0.6055211424827576, "aqua_rat_41829": 0.607650101184845, "camel_17242": 0.6082702875137329, "camel_16205": 0.6083283424377441, "camel_29205": 0.6084407567977905, "camel_16165": 0.6090950965881348, "camel_29270": 0.6091945171356201, "camel_17295": 0.6097228527069092, "camel_29273": 0.6101418137550354, "camel_17326": 0.6103391647338867, "camel_44165": 0.610599160194397, "camel_44701": 0.6114804148674011, "camel_29279": 0.6116783022880554, "camel_45626": 0.6123255491256714, "camel_40443": 0.6123379468917847, "camel_29275": 0.6123433113098145, "camel_17214": 0.6124632358551025, "camel_44994": 0.6124858856201172, "aqua_rat_28949": 0.6136649250984192, "camel_45643": 0.6141466498374939, "aqua_rat_81880": 0.6141979098320007, "camel_29603": 0.6147028803825378, "camel_17260": 0.6147735118865967, "aqua_rat_8480": 0.6160102486610413, "camel_28151": 0.6160780191421509, "camel_16161": 0.6162344217300415, "camel_16190": 0.6166839599609375, "camel_29241": 0.616974949836731, "camel_17341": 0.6175199747085571, "camel_29618": 0.6176037788391113, "camel_45925": 0.6177903413772583, "camel_19576": 0.6189444661140442, "camel_17311": 0.6197739839553833, "camel_17305": 0.6214576959609985, "camel_17267": 0.6218358874320984, "camel_17211": 0.6221214532852173, "aqua_rat_76514": 0.6221776604652405, "camel_17357": 0.6239050626754761, "camel_17251": 0.625112771987915, "camel_17208": 0.6254777312278748, "camel_45033": 0.6260865330696106, "camel_45933": 0.6261355876922607, "camel_16180": 0.62650465965271, "camel_17244": 0.6265814304351807, "camel_16231": 0.6267632246017456, "camel_16169": 0.627108633518219, "camel_16196": 0.6272632479667664, "camel_17290": 0.6276900768280029, "camel_29184": 0.6277887225151062, "camel_29252": 0.6285085678100586, "camel_17212": 0.6285735964775085, "camel_17318": 0.630174994468689, "camel_45018": 0.6330059170722961, "aqua_rat_65096": 0.634694516658783, "camel_17587": 0.6360034942626953, "aqua_rat_33202": 0.6361426711082458, "camel_43809": 0.6377439498901367, "camel_16199": 0.6380789875984192, "TheoremQA_panlu/linear_expansion1.json": 0.639261782169342, "camel_17213": 0.63985276222229, "camel_17337": 0.6400574445724487, "camel_45673": 0.6401745676994324, "camel_45016": 0.6406455039978027, "camel_17240": 0.6461412906646729, "camel_17272": 0.6466968655586243, "camel_17255": 0.6474000215530396, "camel_17252": 0.6483392715454102, "camel_17254": 0.6494653820991516, "camel_16160": 0.6530699133872986, "camel_44972": 0.6565694212913513, "camel_16209": 0.657156229019165, "camel_44967": 0.6578842997550964, "camel_16181": 0.6676721572875977, "camel_45929": 0.6763576865196228, "camel_44981": 0.6778419017791748, "camel_17873": 0.6785939931869507, "camel_16217": 0.6878371834754944, "camel_17235": 0.6899730563163757, "camel_16179": 0.7091068625450134, "camel_16223": 0.7097753882408142, "camel_16175": 0.7133057117462158}, "TheoremQA_maxku/signalprocessing15-DB.json": {"TheoremQA_maxku/signalprocessing15-DB.json": 0, "camel_29066": 0.5919710993766785, "aqua_rat_87402": 0.592070996761322, "aqua_rat_55524": 0.5920769572257996, "camel_30409": 0.5922200083732605, "camel_29184": 0.5922553539276123, "aqua_rat_29921": 0.5924643278121948, "math_test_prealgebra_1839": 0.5925599932670593, "gsm_rft_33530": 0.5925611257553101, "aqua_rat_79408": 0.5925857424736023, "aqua_rat_24675": 0.5926997661590576, "gsm_rft_28061": 0.5927366614341736, "aqua_rat_10759": 0.5927832126617432, "aqua_rat_10496": 0.5928034782409668, "gsm_rft_15045": 0.5928533673286438, "aqua_rat_20926": 0.5928933024406433, "camel_28005": 0.5929558873176575, "camel_31093": 0.5929908752441406, "gsm_train_9619": 0.5929934978485107, "aqua_rat_67847": 0.593055248260498, "gsm_rft_3825": 0.5931740403175354, "aqua_rat_73351": 0.5933186411857605, "gsm_rft_2592": 0.5934591293334961, "aqua_rat_81463": 0.5934863090515137, "gsm_rft_22234": 0.5934923887252808, "aqua_rat_3027": 0.5935882925987244, "aqua_rat_16867": 0.5935899615287781, "aqua_rat_39647": 0.5936360955238342, "gsm_train_31455": 0.5936803221702576, "camel_17235": 0.5936957001686096, "aqua_rat_84082": 0.5937022566795349, "camel_31255": 0.5937045812606812, "gsm_rft_20150": 0.5937405228614807, "camel_29638": 0.593741774559021, "gsm_rft_14019": 0.5938507914543152, "camel_31115": 0.5940387845039368, "aqua_rat_48818": 0.5940446257591248, "TheoremQA_maxku/ipnetwork5-mac.json": 0.5940820574760437, "camel_28007": 0.5941047668457031, "gsm_rft_28561": 0.5941376090049744, "gsm_rft_7433": 0.5941376090049744, "gsm_train_11581": 0.5941376090049744, "aqua_rat_21367": 0.5941523313522339, "aqua_rat_37980": 0.594226598739624, "aqua_rat_36286": 0.5942276120185852, "aqua_rat_17009": 0.5943548083305359, "camel_29603": 0.5944159626960754, "aqua_rat_24892": 0.5944502353668213, "aqua_rat_30121": 0.5944842100143433, "aqua_rat_85107": 0.594572126865387, "aqua_rat_47625": 0.5945810675621033, "camel_29593": 0.5949505567550659, "aqua_rat_31902": 0.5950784683227539, "aqua_rat_75394": 0.5951330661773682, "aqua_rat_50702": 0.5952910780906677, "aqua_rat_18977": 0.5955628752708435, "aqua_rat_16469": 0.595716118812561, "aqua_rat_41524": 0.595819890499115, "aqua_rat_34594": 0.5961428284645081, "camel_44806": 0.5963587760925293, "aqua_rat_70990": 0.596542477607727, "aqua_rat_13804": 0.5966334342956543, "aqua_rat_59220": 0.5966410040855408, "gsm_rft_10941": 0.596653938293457, "gsm_train_8512": 0.596653938293457, "aqua_rat_24370": 0.5966836214065552, "camel_31116": 0.5968531966209412, "aqua_rat_18489": 0.5969886183738708, "aqua_rat_88839": 0.5970154404640198, "aqua_rat_15143": 0.5970479846000671, "aqua_rat_65415": 0.597076416015625, "aqua_rat_28535": 0.5970819592475891, "gsm_rft_28300": 0.5973662734031677, "aqua_rat_43023": 0.5973738431930542, "aqua_rat_45657": 0.5974077582359314, "aqua_rat_87469": 0.5974245667457581, "camel_29568": 0.5974263548851013, "camel_28047": 0.5975908041000366, "aqua_rat_33257": 0.597639799118042, "aqua_rat_42745": 0.5978109836578369, "camel_30050": 0.5978164076805115, "aqua_rat_63615": 0.597831666469574, "gsm_rft_34462": 0.5978481769561768, "camel_17586": 0.5978865027427673, "gsm_train_2521": 0.597922146320343, "aqua_rat_58755": 0.5979354381561279, "camel_29545": 0.5980082750320435, "aqua_rat_69903": 0.5982621312141418, "aqua_rat_26529": 0.5982704758644104, "aqua_rat_65183": 0.598412275314331, "camel_30539": 0.5984986424446106, "gsm_train_20944": 0.5985106229782104, "gsm_rft_21298": 0.5985106229782104, "math_train_prealgebra_1498": 0.5985971093177795, "camel_29227": 0.5990632772445679, "camel_28344": 0.5993176102638245, "aqua_rat_63612": 0.5994402766227722, "aqua_rat_51028": 0.599750280380249, "aqua_rat_63126": 0.5999545454978943, "gsm_rft_33863": 0.5999552607536316, "aqua_rat_47454": 0.6003502607345581, "camel_28549": 0.6004226803779602, "aqua_rat_89240": 0.6004835367202759, "aqua_rat_39472": 0.6005809903144836, "camel_29088": 0.6006198525428772, "camel_28384": 0.6007483005523682, "aqua_rat_53630": 0.6009169220924377, "aqua_rat_21550": 0.6009858846664429, "aqua_rat_76667": 0.6011195778846741, "aqua_rat_12679": 0.601680338382721, "aqua_rat_53207": 0.6021744608879089, "camel_29114": 0.6023507118225098, "camel_31784": 0.6024256348609924, "aqua_rat_19719": 0.602547287940979, "aqua_rat_29101": 0.6026085615158081, "aqua_rat_32830": 0.6029564142227173, "camel_30536": 0.6032978892326355, "aqua_rat_77324": 0.6033309698104858, "camel_29044": 0.6035583019256592, "camel_28643": 0.6037463545799255, "gsm_rft_20209": 0.6037510633468628, "gsm_train_22328": 0.6037510633468628, "gsm_rft_3001": 0.6037510633468628, "aqua_rat_9017": 0.6037749648094177, "camel_30449": 0.6038573980331421, "gsm_rft_24420": 0.6042116284370422, "camel_28694": 0.6044691801071167, "aqua_rat_14765": 0.6046044826507568, "camel_17561": 0.6046873331069946, "camel_30433": 0.604751706123352, "aqua_rat_86249": 0.6050113439559937, "aqua_rat_56122": 0.6052922010421753, "gsm_rft_2576": 0.6055935621261597, "gsm_rft_8266": 0.6055935621261597, "gsm_train_29686": 0.6057934761047363, "aqua_rat_4046": 0.6061265468597412, "camel_29187": 0.6062452793121338, "camel_30440": 0.6065476536750793, "gsm_rft_11471": 0.6065890789031982, "camel_28672": 0.606740415096283, "aqua_rat_27263": 0.6069079041481018, "camel_29719": 0.6072500348091125, "aqua_rat_70673": 0.6075382828712463, "aqua_rat_30572": 0.6075414419174194, "gsm_rft_8537": 0.6081109046936035, "camel_30413": 0.6082372069358826, "aqua_rat_4051": 0.6082525253295898, "camel_31131": 0.6082577109336853, "camel_30441": 0.6085566878318787, "camel_31206": 0.6091479659080505, "aqua_rat_57461": 0.6094049215316772, "aqua_rat_47787": 0.609754741191864, "aqua_rat_24103": 0.6107503771781921, "aqua_rat_36517": 0.614706814289093, "aqua_rat_67357": 0.6167407035827637, "aqua_rat_82697": 0.617254912853241, "aqua_rat_64124": 0.6174094080924988, "aqua_rat_36163": 0.6176942586898804, "aqua_rat_84836": 0.6180495023727417, "camel_28685": 0.6181452870368958, "camel_28888": 0.6183068156242371, "camel_28096": 0.618939220905304, "camel_31460": 0.6189520359039307, "aqua_rat_43685": 0.6201297044754028, "aqua_rat_81450": 0.6203780770301819, "camel_31066": 0.6211417317390442, "camel_45802": 0.6237025260925293, "aqua_rat_77082": 0.6239020824432373, "aqua_rat_53348": 0.6251645684242249, "aqua_rat_7577": 0.6258929967880249, "aqua_rat_32037": 0.6260725855827332, "camel_31078": 0.6284247040748596, "camel_37938": 0.629331111907959, "aqua_rat_75099": 0.6293679475784302, "camel_28154": 0.6311123371124268, "aqua_rat_23127": 0.6320329308509827, "aqua_rat_66305": 0.6328280568122864, "aqua_rat_60714": 0.6334382891654968, "aqua_rat_6088": 0.641855776309967, "aqua_rat_84169": 0.6423672437667847, "aqua_rat_59779": 0.642598032951355, "camel_44543": 0.6463176608085632, "aqua_rat_27769": 0.6471843123435974, "camel_45834": 0.6483738422393799, "aqua_rat_73381": 0.6486491560935974, "TheoremQA_maxku/signalprocessing18-noisebark.json": 0.6493698954582214, "aqua_rat_32984": 0.6502583622932434, "aqua_rat_59558": 0.6545690298080444, "camel_28122": 0.6676890850067139, "aqua_rat_82138": 0.6685389876365662, "aqua_rat_22426": 0.6724801659584045, "aqua_rat_69297": 0.676067590713501, "aqua_rat_36347": 0.678522527217865, "aqua_rat_54325": 0.6797547340393066, "aqua_rat_61003": 0.6826028823852539, "camel_45637": 0.683387815952301, "camel_44741": 0.6840782761573792, "camel_45836": 0.750125527381897, "camel_45809": 0.7505195736885071, "TheoremQA_maxku/signalprocessing2-DB.json": 0.8102949261665344}, "TheoremQA_mingyin/Lebesgue-measure1.json": {"TheoremQA_mingyin/Lebesgue-measure1.json": 0, "camel_31918": 0.679097056388855, "camel_18271": 0.6791337728500366, "math_train_prealgebra_630": 0.679176926612854, "math_train_prealgebra_925": 0.6793448328971863, "math_train_prealgebra_1415": 0.6794574856758118, "aqua_rat_8518": 0.6795161366462708, "camel_31241": 0.679588258266449, "aqua_rat_6352": 0.6797189712524414, "aqua_rat_73720": 0.6798776388168335, "camel_30685": 0.6800009608268738, "math_train_counting_and_probability_730": 0.6800031661987305, "camel_19558": 0.6802089214324951, "camel_31884": 0.6802583336830139, "math_test_number_theory_1146": 0.6803958415985107, "camel_25448": 0.680427610874176, "camel_30544": 0.6804723739624023, "camel_37517": 0.6804725527763367, "aqua_rat_57498": 0.6805725693702698, "aqua_rat_62074": 0.6806733012199402, "camel_31154": 0.6806926727294922, "camel_30885": 0.6807150840759277, "camel_31189": 0.6808124780654907, "math_train_number_theory_492": 0.6808781623840332, "camel_30324": 0.6810358166694641, "camel_31947": 0.6811424493789673, "camel_30350": 0.6812493205070496, "gsm_rft_31633": 0.6814671158790588, "math_train_algebra_25284": 0.6815418601036072, "aqua_rat_71759": 0.6815879344940186, "camel_30895": 0.6816814541816711, "aqua_rat_57783": 0.6817134022712708, "aqua_rat_62871": 0.6818991899490356, "camel_31169": 0.6820181608200073, "camel_31858": 0.6821696162223816, "aqua_rat_18415": 0.6821963787078857, "camel_30323": 0.6822931170463562, "math_test_counting_and_probability_512": 0.682386577129364, "aqua_rat_46784": 0.6824941635131836, "camel_31419": 0.6825107932090759, "camel_30937": 0.6825264692306519, "math_train_counting_and_probability_5104": 0.6826655864715576, "math_train_algebra_1877": 0.6828444600105286, "aqua_rat_17743": 0.6833433508872986, "camel_30951": 0.683535635471344, "gsm_rft_17952": 0.6836192607879639, "camel_30921": 0.6837738156318665, "camel_30959": 0.6838064789772034, "gsm_rft_32929": 0.6838435530662537, "camel_18193": 0.6839005947113037, "camel_31420": 0.6840366125106812, "aqua_rat_27542": 0.68404620885849, "camel_18085": 0.6840615272521973, "camel_28309": 0.6841079592704773, "gsm_rft_25665": 0.684207022190094, "aqua_rat_9255": 0.6845564842224121, "camel_31123": 0.6846110820770264, "camel_31976": 0.6846669912338257, "camel_30485": 0.6847839951515198, "camel_30913": 0.6851277351379395, "camel_30367": 0.6851574182510376, "math_train_prealgebra_657": 0.6853599548339844, "aqua_rat_4648": 0.6854210495948792, "camel_37666": 0.6855353713035583, "camel_31425": 0.6855598092079163, "camel_30858": 0.6858336329460144, "math_test_number_theory_481": 0.6858928799629211, "aqua_rat_49020": 0.6861670017242432, "math_train_counting_and_probability_5094": 0.6862810254096985, "aqua_rat_82861": 0.6863588690757751, "camel_25911": 0.6865154504776001, "math_train_counting_and_probability_984": 0.6872169375419617, "camel_31864": 0.6873000264167786, "aqua_rat_13370": 0.6878061890602112, "camel_31527": 0.6879144310951233, "camel_31437": 0.6883515119552612, "aqua_rat_49646": 0.6884168982505798, "aqua_rat_23078": 0.6884866952896118, "aqua_rat_11482": 0.6885418891906738, "aqua_rat_73910": 0.6886323094367981, "camel_31444": 0.6888766288757324, "aqua_rat_83131": 0.6889986991882324, "aqua_rat_1671": 0.6890496611595154, "camel_31936": 0.6891093254089355, "math_test_counting_and_probability_25780": 0.6893668174743652, "camel_30527": 0.6897851228713989, "camel_10509": 0.6899557709693909, "aqua_rat_220": 0.6900083422660828, "camel_37504": 0.6902218461036682, "camel_30340": 0.6904414296150208, "camel_30376": 0.6912388801574707, "camel_36978": 0.6912964582443237, "camel_30927": 0.6916555166244507, "aqua_rat_37996": 0.6916833519935608, "math_test_algebra_1836": 0.691933810710907, "camel_30379": 0.6921237111091614, "aqua_rat_1729": 0.6923607587814331, "aqua_rat_20543": 0.6925646662712097, "math_train_counting_and_probability_5026": 0.6926465034484863, "math_train_number_theory_873": 0.6926601529121399, "camel_30388": 0.6931793093681335, "camel_21690": 0.6933891177177429, "math_train_counting_and_probability_259": 0.6938093900680542, "gsm_rft_15216": 0.6940112113952637, "camel_37112": 0.6943697333335876, "aqua_rat_16186": 0.6946499943733215, "camel_31401": 0.694871187210083, "camel_37491": 0.69493168592453, "camel_37551": 0.6953378915786743, "gsm_rft_25428": 0.6953413486480713, "camel_36754": 0.6954660415649414, "math_test_counting_and_probability_25": 0.6955760717391968, "aqua_rat_26864": 0.695664644241333, "aqua_rat_55514": 0.6957987546920776, "camel_30377": 0.6959683895111084, "camel_30380": 0.6960257887840271, "camel_37027": 0.6963188648223877, "camel_37456": 0.6963220834732056, "aqua_rat_20715": 0.6963273882865906, "camel_30369": 0.6966838240623474, "camel_30399": 0.6970528960227966, "camel_30900": 0.6970928311347961, "math_train_counting_and_probability_828": 0.6972258687019348, "camel_30915": 0.6974402666091919, "camel_37619": 0.6976351737976074, "camel_30375": 0.6980283260345459, "camel_30351": 0.6984673142433167, "camel_36509": 0.6986804008483887, "math_train_number_theory_1212": 0.6987396478652954, "camel_31908": 0.6993392109870911, "camel_30926": 0.6999103426933289, "math_test_number_theory_383": 0.6999174356460571, "camel_31057": 0.6999954581260681, "camel_30362": 0.7004567384719849, "camel_30360": 0.700467050075531, "gsm_rft_22281": 0.7008861899375916, "camel_30386": 0.7010383605957031, "camel_31548": 0.7011784911155701, "aqua_rat_13223": 0.7013626098632812, "gsm_rft_13556": 0.7015026807785034, "camel_30352": 0.7016642689704895, "camel_30942": 0.7017638683319092, "math_test_counting_and_probability_855": 0.7020359635353088, "camel_30382": 0.7021198868751526, "math_train_number_theory_1088": 0.7021292448043823, "camel_31061": 0.7023890614509583, "camel_30327": 0.7024984955787659, "TheoremQA_mingyin/cantor-set1.json": 0.7032437324523926, "camel_31759": 0.7040618658065796, "camel_30341": 0.7047587037086487, "camel_31880": 0.704973578453064, "camel_30334": 0.7053297162055969, "camel_30321": 0.7054638862609863, "camel_30320": 0.7055409550666809, "camel_31842": 0.7059810161590576, "camel_30886": 0.7067738771438599, "camel_31190": 0.7069203853607178, "camel_31084": 0.7069545388221741, "camel_30389": 0.7069721817970276, "gsm_rft_15632": 0.7074723839759827, "gsm_train_17342": 0.7074723839759827, "camel_30387": 0.7078419923782349, "camel_21967": 0.7081468105316162, "camel_30359": 0.709622859954834, "camel_30342": 0.7099117636680603, "camel_30390": 0.709960401058197, "gsm_rft_8731": 0.7109360694885254, "TheoremQA_xinyi/huffman_code_3.json": 0.7123861908912659, "camel_30335": 0.7128472924232483, "camel_31525": 0.7134578227996826, "camel_37493": 0.7140972018241882, "math_train_counting_and_probability_941": 0.7143980264663696, "aqua_rat_73229": 0.7151265144348145, "camel_30887": 0.715721070766449, "camel_30366": 0.7172237038612366, "camel_30374": 0.717641294002533, "camel_30396": 0.7194240093231201, "camel_36295": 0.7197204232215881, "camel_30948": 0.7197244763374329, "camel_30343": 0.7200273275375366, "math_train_number_theory_499": 0.7210782170295715, "camel_30383": 0.7280507683753967, "camel_37553": 0.7340083122253418, "camel_30368": 0.7365116477012634, "camel_30385": 0.7365677356719971, "camel_30397": 0.7391940355300903, "camel_30371": 0.7449616193771362, "camel_30372": 0.7457349300384521, "camel_30378": 0.7467910647392273, "camel_30357": 0.7507472634315491, "camel_30325": 0.7552876472473145, "camel_30345": 0.755654513835907, "camel_30392": 0.7566930055618286, "camel_30330": 0.756902277469635, "camel_30328": 0.7639053463935852, "camel_30353": 0.766543984413147, "camel_30339": 0.7678505182266235, "camel_30354": 0.77435302734375, "camel_30346": 0.7787662744522095, "camel_30338": 0.785077691078186}, "TheoremQA_mingyin/series2.json": {"math_test_precalculus_1155": 0, "math_train_precalculus_985": 0, "math_test_precalculus_24169": 0, "math_test_precalculus_588": 0, "TheoremQA_mingyin/series2.json": 0, "camel_42647": 0.6907573342323303, "camel_30357": 0.6910557150840759, "aqua_rat_38529": 0.6912121772766113, "camel_30338": 0.6912155151367188, "camel_42702": 0.6916124224662781, "camel_18137": 0.6919311881065369, "aqua_rat_16186": 0.6921195983886719, "camel_31869": 0.6921242475509644, "TheoremQA_mingyin/Limit-of-sequence3.json": 0.6922460794448853, "math_train_algebra_2506": 0.6922985911369324, "camel_49087": 0.6923052668571472, "camel_31858": 0.6923229694366455, "math_train_intermediate_algebra_1534": 0.6924538016319275, "math_train_intermediate_algebra_1728": 0.6924811005592346, "camel_42696": 0.6927565932273865, "math_train_intermediate_algebra_1064": 0.6927973031997681, "camel_42667": 0.6930994391441345, "math_test_intermediate_algebra_632": 0.6931486129760742, "camel_42665": 0.6937898993492126, "math_test_intermediate_algebra_2074": 0.6938011050224304, "camel_21967": 0.6938232779502869, "aqua_rat_41522": 0.6942676305770874, "math_train_intermediate_algebra_464": 0.6943061351776123, "camel_30797": 0.6943712830543518, "camel_20515": 0.6944037079811096, "TheoremQA_wenhuchen/taylor_expansion2.json": 0.6944389939308167, "camel_42703": 0.6944607496261597, "camel_43304": 0.6944761276245117, "camel_49105": 0.6944906115531921, "camel_42709": 0.6945750713348389, "camel_42652": 0.6945834755897522, "camel_42673": 0.6946035623550415, "math_train_intermediate_algebra_1906": 0.6947668790817261, "camel_42682": 0.694950520992279, "camel_44125": 0.6951481103897095, "camel_42646": 0.6956810355186462, "camel_42680": 0.6960678100585938, "camel_42689": 0.6964257955551147, "aqua_rat_32090": 0.6965020895004272, "aqua_rat_24093": 0.6967792510986328, "camel_42651": 0.6968232989311218, "math_train_intermediate_algebra_1785": 0.6968520879745483, "math_train_intermediate_algebra_1832": 0.6972140669822693, "camel_42641": 0.6974711418151855, "math_train_intermediate_algebra_1943": 0.697685718536377, "math_train_algebra_1589": 0.6982190012931824, "camel_30383": 0.6985779404640198, "aqua_rat_34388": 0.6986607313156128, "camel_31880": 0.6986952424049377, "camel_42713": 0.6988629698753357, "camel_42719": 0.6992060542106628, "math_train_algebra_620": 0.6994562745094299, "math_train_algebra_1269": 0.6995947957038879, "camel_42700": 0.69962477684021, "math_train_intermediate_algebra_1257": 0.6996380090713501, "TheoremQA_wenhuchen/series_convergen1.json": 0.6997356414794922, "camel_42650": 0.7000847458839417, "math_train_algebra_456": 0.7010249495506287, "math_test_algebra_2398": 0.7011603116989136, "math_train_algebra_1517": 0.7013567686080933, "math_test_algebra_2430": 0.701636016368866, "aqua_rat_83193": 0.7016564011573792, "math_train_intermediate_algebra_1278": 0.7016728520393372, "camel_30680": 0.7018112540245056, "math_test_intermediate_algebra_916": 0.7019424438476562, "camel_42717": 0.702018141746521, "camel_42669": 0.7026913166046143, "math_test_intermediate_algebra_1994": 0.702860951423645, "math_train_algebra_886": 0.7029392123222351, "math_test_intermediate_algebra_693": 0.7030153274536133, "math_train_algebra_1831": 0.7036712765693665, "math_train_intermediate_algebra_111": 0.7036950588226318, "camel_42714": 0.704064130783081, "camel_31089": 0.7042248249053955, "math_train_intermediate_algebra_1641": 0.704312801361084, "math_train_intermediate_algebra_2086": 0.7044463157653809, "camel_30372": 0.7047726511955261, "math_train_intermediate_algebra_316": 0.7049391865730286, "math_test_intermediate_algebra_1392": 0.7050312161445618, "camel_42657": 0.7054479718208313, "math_test_intermediate_algebra_430": 0.7056193947792053, "math_train_algebra_2704": 0.7057240009307861, "camel_42698": 0.705790638923645, "camel_44100": 0.7060636281967163, "camel_42056": 0.7068184614181519, "math_train_intermediate_algebra_303": 0.7070199847221375, "aqua_rat_49434": 0.7070939540863037, "camel_30354": 0.7073013186454773, "camel_30339": 0.7077159881591797, "math_train_algebra_2522": 0.7077872157096863, "math_train_intermediate_algebra_670": 0.7081334590911865, "math_test_intermediate_algebra_800": 0.7084997296333313, "math_train_algebra_745": 0.7088002562522888, "math_train_algebra_1935": 0.7090207934379578, "camel_42688": 0.7097124457359314, "TheoremQA_wenhuchen/infinite_series_sum1.json": 0.7106181979179382, "camel_20542": 0.7107846736907959, "math_train_intermediate_algebra_506": 0.7109747529029846, "math_test_intermediate_algebra_1318": 0.7112380266189575, "math_train_intermediate_algebra_1154": 0.7115238904953003, "camel_30392": 0.711549699306488, "math_train_intermediate_algebra_539": 0.7118269801139832, "math_train_intermediate_algebra_985": 0.7118931412696838, "math_test_counting_and_probability_456": 0.7119771242141724, "math_train_algebra_2317": 0.7120863795280457, "math_train_algebra_58": 0.7122456431388855, "camel_42010": 0.7122604250907898, "math_test_intermediate_algebra_1876": 0.7123372554779053, "math_train_algebra_1637": 0.712478756904602, "math_train_algebra_652": 0.7126044034957886, "math_train_algebra_515": 0.7127286195755005, "camel_31759": 0.712741494178772, "camel_42685": 0.7129258513450623, "aqua_rat_66695": 0.7130087614059448, "math_train_intermediate_algebra_502": 0.71342933177948, "math_test_number_theory_919": 0.7135317325592041, "math_train_intermediate_algebra_1753": 0.713988721370697, "math_test_intermediate_algebra_861": 0.7141619920730591, "aqua_rat_13532": 0.7151049971580505, "aqua_rat_8746": 0.7153701782226562, "aqua_rat_47530": 0.7156832814216614, "math_train_intermediate_algebra_824": 0.716127872467041, "camel_42670": 0.7162725925445557, "camel_42705": 0.7163891196250916, "camel_30374": 0.716417670249939, "aqua_rat_41553": 0.7174401879310608, "camel_42676": 0.7179243564605713, "camel_42662": 0.7180143594741821, "math_train_intermediate_algebra_1494": 0.7180278301239014, "camel_49110": 0.7181491851806641, "camel_30341": 0.7186195850372314, "aqua_rat_59396": 0.7187250852584839, "math_test_algebra_2664": 0.7196320295333862, "math_test_algebra_1428": 0.7196335792541504, "aqua_rat_73916": 0.7197457551956177, "math_train_intermediate_algebra_2179": 0.7200103998184204, "camel_30345": 0.7203241586685181, "camel_49079": 0.7204661965370178, "math_train_algebra_627": 0.7206048369407654, "camel_49073": 0.7210124731063843, "camel_49044": 0.721402645111084, "camel_28309": 0.721702516078949, "math_train_intermediate_algebra_879": 0.7222842574119568, "math_test_intermediate_algebra_1364": 0.7226186990737915, "math_train_intermediate_algebra_1594": 0.7231863141059875, "math_train_counting_and_probability_5026": 0.7233567237854004, "aqua_rat_16203": 0.7236756682395935, "camel_37619": 0.7239933013916016, "aqua_rat_54656": 0.7245879769325256, "math_test_intermediate_algebra_1870": 0.7254509329795837, "math_test_intermediate_algebra_2116": 0.7254753112792969, "aqua_rat_35538": 0.7259058952331543, "math_test_intermediate_algebra_122": 0.7260188460350037, "math_train_intermediate_algebra_1939": 0.7267901301383972, "math_test_number_theory_1077": 0.7278430461883545, "camel_31057": 0.7279421091079712, "math_test_algebra_2477": 0.7284401059150696, "aqua_rat_9679": 0.7290397882461548, "math_train_intermediate_algebra_1610": 0.7295815944671631, "math_train_intermediate_algebra_1387": 0.7296229600906372, "camel_42687": 0.729826033115387, "camel_49109": 0.7302737236022949, "aqua_rat_19560": 0.7314004302024841, "math_test_intermediate_algebra_1600": 0.7316238284111023, "math_train_intermediate_algebra_1315": 0.7319477796554565, "math_train_intermediate_algebra_1581": 0.7320640683174133, "camel_42679": 0.7322570085525513, "camel_42708": 0.7325961589813232, "camel_31084": 0.7330649495124817, "camel_30202": 0.7334595322608948, "camel_31061": 0.7339097857475281, "TheoremQA_mingyin/Lebesgue-measure1.json": 0.7341964840888977, "math_train_intermediate_algebra_451": 0.7347411513328552, "math_train_intermediate_algebra_899": 0.735903799533844, "math_train_intermediate_algebra_1527": 0.7365132570266724, "aqua_rat_35123": 0.7369451522827148, "camel_44106": 0.7387669086456299, "aqua_rat_8747": 0.7406993508338928, "camel_30330": 0.7416629791259766, "aqua_rat_67612": 0.7426419854164124, "math_train_algebra_1292": 0.7437118887901306, "aqua_rat_50166": 0.7443121075630188, "aqua_rat_53748": 0.7449294328689575, "camel_42678": 0.7452493906021118, "math_train_intermediate_algebra_1051": 0.7458276748657227, "math_train_intermediate_algebra_503": 0.7494954466819763, "math_train_intermediate_algebra_445": 0.7499532103538513, "camel_30385": 0.7502376437187195, "aqua_rat_36268": 0.7508403062820435, "math_train_intermediate_algebra_1765": 0.7534717917442322, "aqua_rat_48885": 0.7539178133010864, "TheoremQA_wenhuchen/infinite_series_sum3.json": 0.7567692995071411, "aqua_rat_69318": 0.7608479261398315, "camel_42643": 0.7801225185394287, "TheoremQA_wenhuchen/infinite_series_sum2.json": 0.8093685507774353}, "TheoremQA_wenhuchen/ODE2.json": {"camel_7442": 0, "camel_7509": 0, "camel_17030": 0, "camel_7455": 0, "camel_7479": 0, "camel_7464": 0, "camel_7971": 0, "camel_7507": 0, "camel_7505": 0, "camel_7446": 0, "camel_16914": 0, "camel_7456": 0, "camel_16893": 0, "camel_7445": 0, "camel_17039": 0, "camel_7459": 0, "camel_7472": 0, "camel_17432": 0, "camel_17420": 0, "camel_7629": 0, "camel_7500": 0, "camel_7510": 0, "camel_16921": 0, "camel_7677": 0, "camel_16900": 0, "camel_7450": 0, "camel_17395": 0, "camel_16919": 0, "camel_7487": 0, "camel_16884": 0, "camel_7669": 0, "camel_7477": 0, "camel_16898": 0, "camel_7518": 0, "camel_17430": 0, "camel_7466": 0, "camel_7614": 0, "camel_7490": 0, "camel_7503": 0, "camel_7513": 0, "camel_7465": 0, "camel_17435": 0, "camel_7504": 0, "camel_16952": 0, "camel_7482": 0, "camel_17022": 0, "camel_7502": 0, "camel_17377": 0, "camel_7497": 0, "camel_17408": 0, "camel_7441": 0, "camel_17361": 0, "camel_7457": 0, "camel_7443": 0, "camel_7485": 0, "camel_16894": 0, "camel_16922": 0, "camel_7517": 0, "camel_16943": 0, "camel_16901": 0, "camel_17431": 0, "camel_7467": 0, "camel_7492": 0, "camel_17433": 0, "camel_7481": 0, "camel_7516": 0, "camel_16996": 0, "TheoremQA_wenhuchen/ODE2.json": 0, "camel_28838": 0.7890536785125732, "camel_40335": 0.7891980409622192, "camel_29204": 0.789243221282959, "camel_28141": 0.7893522381782532, "camel_29433": 0.7893898487091064, "camel_47323": 0.7896645665168762, "camel_28789": 0.7897714376449585, "camel_29411": 0.789943277835846, "camel_28919": 0.7902141809463501, "camel_29940": 0.7904674410820007, "camel_28029": 0.7907098531723022, "camel_28861": 0.7907980680465698, "camel_28034": 0.7908144593238831, "camel_29393": 0.7908154726028442, "camel_28332": 0.7908967733383179, "camel_29394": 0.7909711003303528, "camel_28853": 0.7910350561141968, "camel_29385": 0.7912505269050598, "camel_40333": 0.7921314835548401, "camel_29631": 0.7921391725540161, "camel_29921": 0.7922323942184448, "camel_29369": 0.7925089001655579, "camel_28824": 0.7927125096321106, "camel_28055": 0.7928776741027832, "camel_29436": 0.7936239242553711, "camel_28057": 0.7938045859336853, "camel_29734": 0.7941544055938721, "camel_29398": 0.7943122982978821, "camel_29999": 0.794452428817749, "camel_39517": 0.7944807410240173, "camel_28802": 0.7947405576705933, "camel_29404": 0.7947751879692078, "camel_28785": 0.7950449585914612, "camel_28047": 0.795346736907959, "camel_29397": 0.7954429388046265, "camel_29950": 0.7955515384674072, "camel_29164": 0.7956792712211609, "camel_29890": 0.7957906723022461, "TheoremQA_wenhuchen/euler's_method1.json": 0.7962461709976196, "camel_28088": 0.7962616086006165, "camel_28098": 0.796367883682251, "camel_28863": 0.7963836193084717, "camel_28796": 0.7965349555015564, "camel_28831": 0.7968081831932068, "camel_29434": 0.7974927425384521, "camel_28852": 0.7978062033653259, "camel_28133": 0.79786616563797, "camel_39488": 0.7982947826385498, "camel_28946": 0.7985668182373047, "camel_28045": 0.799676239490509, "camel_28867": 0.7998787760734558, "camel_29985": 0.8002572059631348, "camel_28851": 0.8003444075584412, "camel_29500": 0.8005421757698059, "camel_28145": 0.8008057475090027, "camel_29597": 0.8011630177497864, "camel_29933": 0.8014765977859497, "camel_29424": 0.8019581437110901, "camel_29374": 0.8022119402885437, "camel_29725": 0.8024120926856995, "camel_29439": 0.8032856583595276, "camel_28787": 0.8037511110305786, "camel_28827": 0.8038367033004761, "camel_29528": 0.8042077422142029, "camel_29375": 0.8044284582138062, "camel_29178": 0.804877519607544, "camel_29418": 0.8051117062568665, "camel_40334": 0.8052806854248047, "camel_28845": 0.8058128356933594, "camel_28813": 0.8059269785881042, "camel_28064": 0.8061527013778687, "camel_29112": 0.8065959811210632, "camel_29925": 0.806847095489502, "camel_29396": 0.8079127073287964, "camel_28814": 0.8079336285591125, "camel_29691": 0.807958722114563, "camel_29750": 0.8080105185508728, "camel_28854": 0.8081268072128296, "camel_29362": 0.8084766864776611, "camel_28823": 0.8089682459831238, "camel_29400": 0.8091557621955872, "camel_28780": 0.8101555109024048, "camel_28830": 0.8109680414199829, "camel_29974": 0.8110915422439575, "camel_28909": 0.8113389015197754, "camel_28860": 0.8127650618553162, "camel_29705": 0.8128871321678162, "camel_28715": 0.8133229613304138, "camel_29405": 0.8133875131607056, "camel_29429": 0.8139863014221191, "camel_29163": 0.8144884705543518, "camel_29364": 0.8147485852241516, "camel_29395": 0.8155571818351746, "camel_29992": 0.8158402442932129, "camel_28878": 0.8161780834197998, "camel_28068": 0.8164106011390686, "camel_28862": 0.8176952004432678, "camel_28815": 0.8179206848144531, "camel_29430": 0.8190292119979858, "camel_28803": 0.8195399045944214, "camel_29050": 0.8196182250976562, "camel_29967": 0.8212926983833313, "camel_29413": 0.8218191862106323, "camel_29388": 0.8229689598083496, "camel_29391": 0.8235200047492981, "camel_29467": 0.8243460059165955, "camel_28826": 0.825179398059845, "camel_29432": 0.8258289694786072, "camel_28394": 0.8266481757164001, "camel_29437": 0.8270177245140076, "camel_28805": 0.8277936577796936, "camel_28848": 0.827802300453186, "camel_28794": 0.8282337188720703, "camel_28874": 0.8299444317817688, "camel_29438": 0.8306069374084473, "camel_28094": 0.8307490944862366, "camel_28869": 0.8331617712974548, "camel_29392": 0.8355446457862854, "camel_29373": 0.8357416391372681, "camel_29377": 0.836431086063385, "camel_29372": 0.8385934233665466, "camel_29997": 0.8389026522636414, "camel_29542": 0.8400834202766418, "camel_28024": 0.8428403735160828, "camel_28832": 0.8441088795661926, "camel_29972": 0.8444598913192749, "camel_29991": 0.8446154594421387, "camel_29491": 0.8487091064453125, "camel_29426": 0.8519579172134399, "camel_28837": 0.8541610836982727, "camel_29379": 0.8580362200737, "camel_29387": 0.8701838254928589}, "TheoremQA_wenhuchen/Liouville\u2019s_theorem1.json": {"camel_42942": 0, "camel_42881": 0, "camel_43566": 0, "camel_43270": 0, "camel_43171": 0, "camel_43130": 0, "camel_42589": 0, "camel_43170": 0, "camel_43158": 0, "camel_42622": 0, "camel_42408": 0, "camel_42475": 0, "camel_42452": 0, "camel_43256": 0, "camel_42011": 0, "camel_42789": 0, "camel_42583": 0, "camel_43141": 0, "camel_42000": 0, "camel_43010": 0, "camel_42487": 0, "camel_42517": 0, "camel_42869": 0, "camel_42405": 0, "camel_43126": 0, "camel_42956": 0, "camel_42925": 0, "camel_42422": 0, "camel_43546": 0, "camel_42615": 0, "camel_42629": 0, "camel_43189": 0, "camel_43381": 0, "camel_42635": 0, "camel_42612": 0, "camel_43190": 0, "camel_43182": 0, "camel_43137": 0, "camel_42929": 0, "camel_42966": 0, "camel_42975": 0, "camel_42420": 0, "camel_42051": 0, "camel_42565": 0, "camel_43055": 0, "camel_42426": 0, "camel_42441": 0, "camel_42907": 0, "camel_43181": 0, "camel_42005": 0, "camel_42976": 0, "camel_42634": 0, "camel_42448": 0, "camel_42505": 0, "camel_42403": 0, "camel_42455": 0, "camel_42912": 0, "camel_43176": 0, "camel_42466": 0, "camel_43191": 0, "camel_42536": 0, "camel_42464": 0, "camel_42598": 0, "camel_42616": 0, "camel_42510": 0, "camel_42996": 0, "camel_43154": 0, "camel_43252": 0, "camel_42450": 0, "camel_42061": 0, "camel_42515": 0, "camel_42047": 0, "camel_42432": 0, "camel_43152": 0, "camel_43214": 0, "camel_42887": 0, "camel_42546": 0, "camel_42430": 0, "camel_42427": 0, "camel_42972": 0, "camel_42497": 0, "camel_42013": 0, "camel_43006": 0, "camel_42985": 0, "camel_42406": 0, "camel_42007": 0, "camel_42607": 0, "camel_42074": 0, "camel_42896": 0, "camel_42989": 0, "camel_43035": 0, "camel_42400": 0, "camel_42412": 0, "camel_43082": 0, "camel_42596": 0, "camel_42410": 0, "camel_42558": 0, "camel_42437": 0, "camel_42488": 0, "camel_42462": 0, "camel_42500": 0, "camel_42428": 0, "camel_42551": 0, "camel_42445": 0, "camel_42549": 0, "camel_42550": 0, "camel_42539": 0, "camel_43173": 0, "camel_43133": 0, "camel_42431": 0, "camel_42486": 0, "camel_42435": 0, "camel_42553": 0, "camel_42621": 0, "camel_42522": 0, "camel_43163": 0, "camel_42528": 0, "camel_42407": 0, "camel_42417": 0, "camel_42404": 0, "camel_42636": 0, "camel_42423": 0, "camel_43105": 0, "camel_42442": 0, "camel_42538": 0, "camel_42625": 0, "camel_42520": 0, "camel_43164": 0, "camel_42480": 0, "camel_42575": 0, "camel_42429": 0, "camel_42910": 0, "camel_42519": 0, "camel_42533": 0, "camel_42512": 0, "camel_42469": 0, "camel_42507": 0, "camel_42477": 0, "camel_42954": 0, "camel_42880": 0, "camel_42529": 0, "camel_42456": 0, "camel_42559": 0, "camel_42402": 0, "camel_42424": 0, "camel_43557": 0, "camel_42434": 0, "camel_42530": 0, "camel_42623": 0, "camel_42614": 0, "camel_43239": 0, "camel_42494": 0, "camel_42444": 0, "camel_42002": 0, "camel_43263": 0, "camel_42485": 0, "camel_42518": 0, "camel_42478": 0, "camel_42053": 0, "camel_42526": 0, "camel_42472": 0, "camel_42454": 0, "camel_42439": 0, "camel_42525": 0, "camel_42585": 0, "camel_42474": 0, "camel_43027": 0, "camel_42557": 0, "camel_42508": 0, "camel_42921": 0, "camel_42603": 0, "camel_42552": 0, "camel_42839": 0, "camel_42491": 0, "TheoremQA_wenhuchen/Liouville\u2019s_theorem1.json": 0, "camel_42547": 0, "camel_43110": 0, "camel_42019": 0, "camel_42070": 0, "camel_42498": 0, "camel_42458": 0, "camel_43131": 0, "camel_42582": 0, "camel_42630": 0, "camel_42888": 0, "camel_42548": 0, "camel_42021": 0, "camel_43020": 0, "camel_42501": 0, "camel_42504": 0, "camel_42531": 0, "camel_42492": 0, "camel_42564": 0, "camel_42556": 0, "camel_30252": 0.7533603310585022, "camel_49104": 0.7573000192642212, "camel_30217": 0.7585073113441467, "camel_49083": 0.791098415851593, "TheoremQA_wenhuchen/Liouville\u2019s_theorem2.json": 0.8554682731628418, "TheoremQA_mingyin/liouville-theorem1.json": 0.8688762187957764}, "TheoremQA_elainewan/math_abstact_algebra_7_8.json": {"camel_32614": 0, "camel_33129": 0, "camel_33082": 0, "camel_32562": 0, "camel_33364": 0, "camel_32485": 0, "camel_33191": 0, "camel_33137": 0, "camel_32909": 0, "camel_33682": 0, "camel_33168": 0, "camel_33196": 0, "camel_32990": 0, "camel_32931": 0, "camel_32727": 0, "camel_33063": 0, "camel_33449": 0, "camel_32890": 0, "camel_32860": 0, "camel_32855": 0, "camel_33387": 0, "camel_32852": 0, "camel_32792": 0, "camel_33848": 0, "camel_33501": 0, "camel_33838": 0, "camel_33936": 0, "camel_32598": 0, "camel_33584": 0, "camel_33824": 0, "camel_33022": 0, "camel_33141": 0, "camel_33175": 0, "camel_33592": 0, "camel_32902": 0, "camel_33170": 0, "camel_33494": 0, "camel_33055": 0, "camel_33564": 0, "camel_32796": 0, "camel_32504": 0, "camel_33558": 0, "camel_33512": 0, "camel_32620": 0, "camel_32891": 0, "camel_32618": 0, "camel_33533": 0, "camel_32777": 0, "camel_32923": 0, "camel_32493": 0, "camel_32625": 0, "camel_33090": 0, "camel_32905": 0, "camel_33140": 0, "camel_33159": 0, "camel_33530": 0, "camel_32747": 0, "camel_32787": 0, "camel_33593": 0, "camel_32601": 0, "camel_33537": 0, "camel_32838": 0, "camel_33625": 0, "camel_32544": 0, "camel_32638": 0, "camel_32568": 0, "camel_33027": 0, "camel_33173": 0, "camel_32588": 0, "camel_32622": 0, "camel_33472": 0, "camel_33480": 0, "camel_33187": 0, "camel_33657": 0, "camel_32835": 0, "camel_33495": 0, "camel_32573": 0, "camel_33150": 0, "camel_33284": 0, "camel_33748": 0, "camel_33467": 0, "camel_33003": 0, "camel_32950": 0, "camel_33968": 0, "camel_33595": 0, "camel_32851": 0, "camel_33434": 0, "camel_33448": 0, "camel_32612": 0, "camel_33513": 0, "camel_33315": 0, "camel_33446": 0, "camel_33497": 0, "camel_33509": 0, "camel_32955": 0, "camel_33854": 0, "camel_32580": 0, "camel_33382": 0, "camel_32634": 0, "camel_33704": 0, "camel_32944": 0, "camel_33148": 0, "camel_32600": 0, "camel_33351": 0, "camel_33596": 0, "camel_32904": 0, "camel_32892": 0, "camel_33574": 0, "camel_33376": 0, "camel_33047": 0, "camel_32849": 0, "camel_33947": 0, "camel_33941": 0, "camel_32605": 0, "camel_33755": 0, "camel_33397": 0, "camel_32946": 0, "camel_33171": 0, "camel_32637": 0, "camel_32953": 0, "camel_32570": 0, "camel_33156": 0, "camel_33781": 0, "camel_32635": 0, "camel_32629": 0, "camel_32927": 0, "camel_33453": 0, "camel_33070": 0, "camel_33402": 0, "camel_32995": 0, "camel_33071": 0, "camel_33091": 0, "camel_32751": 0, "camel_32906": 0, "camel_32569": 0, "camel_33192": 0, "camel_33154": 0, "camel_33138": 0, "camel_33073": 0, "camel_32928": 0, "camel_33538": 0, "camel_33430": 0, "camel_33160": 0, "camel_32786": 0, "camel_32578": 0, "camel_33069": 0, "camel_33519": 0, "camel_33598": 0, "camel_32741": 0, "camel_32938": 0, "camel_33113": 0, "camel_33013": 0, "camel_33618": 0, "camel_32988": 0, "camel_33050": 0, "camel_33411": 0, "camel_32781": 0, "camel_32775": 0, "camel_32951": 0, "camel_32623": 0, "camel_33727": 0, "camel_32900": 0, "camel_32954": 0, "camel_33457": 0, "camel_32769": 0, "camel_33416": 0, "camel_32936": 0, "camel_32945": 0, "camel_32729": 0, "camel_33407": 0, "camel_33413": 0, "camel_32886": 0, "camel_33404": 0, "camel_32877": 0, "camel_32857": 0, "camel_32541": 0, "camel_32750": 0, "camel_33435": 0, "camel_33470": 0, "camel_32761": 0, "camel_32582": 0, "camel_33462": 0, "camel_33832": 0, "camel_33417": 0, "camel_32827": 0, "TheoremQA_elainewan/math_abstact_algebra_7_8.json": 0, "camel_33517": 0, "camel_32526": 0, "camel_32802": 0, "camel_33818": 0, "camel_32045": 0, "camel_32766": 0, "camel_33395": 0, "camel_33199": 0, "camel_32608": 0, "camel_33529": 0, "camel_33344": 0, "camel_33750": 0, "camel_32864": 0, "camel_33325": 0}, "TheoremQA_panlu/rigid-body3.json": {"TheoremQA_panlu/rigid-body3.json": 0, "aqua_rat_8007": 0.679989218711853, "camel_28869": 0.6800091862678528, "aqua_rat_74967": 0.680073618888855, "aqua_rat_72820": 0.6802127361297607, "gsm_rft_32618": 0.6802477836608887, "gsm_rft_8463": 0.6802874207496643, "aqua_rat_79312": 0.6805235147476196, "camel_39503": 0.6806464195251465, "aqua_rat_1054": 0.6807308793067932, "camel_28736": 0.6807538866996765, "camel_16568": 0.6808806657791138, "aqua_rat_31586": 0.6809176206588745, "camel_16299": 0.6809765696525574, "aqua_rat_33328": 0.6810038685798645, "camel_28854": 0.6811414957046509, "gsm_rft_28645": 0.6812751293182373, "gsm_rft_30836": 0.6812751293182373, "gsm_rft_28878": 0.6812751293182373, "gsm_train_31124": 0.6812751293182373, "aqua_rat_70812": 0.6813966035842896, "gsm_rft_2575": 0.6814044117927551, "gsm_rft_870": 0.6814044117927551, "aqua_rat_67301": 0.6814545392990112, "aqua_rat_33439": 0.6815299987792969, "aqua_rat_50476": 0.6815493702888489, "gsm_rft_34580": 0.6816707253456116, "gsm_rft_7695": 0.6817115545272827, "camel_5029": 0.6817591786384583, "math_test_precalculus_893": 0.6818602681159973, "aqua_rat_49753": 0.6818795800209045, "camel_16628": 0.6818808913230896, "aqua_rat_45615": 0.6821474432945251, "camel_5093": 0.6821895241737366, "aqua_rat_48696": 0.6823063492774963, "aqua_rat_24571": 0.682320237159729, "aqua_rat_24084": 0.6825847625732422, "camel_28856": 0.682619571685791, "aqua_rat_11256": 0.6826317310333252, "camel_39446": 0.6826674938201904, "camel_28823": 0.6826971173286438, "aqua_rat_33504": 0.6829437613487244, "aqua_rat_21925": 0.6830270886421204, "camel_28813": 0.6831868886947632, "aqua_rat_80424": 0.6832571625709534, "aqua_rat_17090": 0.684016227722168, "aqua_rat_84659": 0.6840292811393738, "aqua_rat_69168": 0.6840468645095825, "aqua_rat_28463": 0.6841429471969604, "camel_17542": 0.6844156384468079, "gsm_rft_15228": 0.6847749352455139, "aqua_rat_18441": 0.6848442554473877, "aqua_rat_15385": 0.6848614811897278, "camel_28822": 0.6850036382675171, "math_test_prealgebra_1007": 0.6851280331611633, "camel_28871": 0.6852807998657227, "camel_5092": 0.6854344606399536, "aqua_rat_71601": 0.685461163520813, "aqua_rat_86656": 0.6854766607284546, "camel_28846": 0.6854970455169678, "camel_47347": 0.6854970455169678, "aqua_rat_20401": 0.6856063008308411, "aqua_rat_71386": 0.6859427094459534, "gsm_rft_14362": 0.6860262155532837, "gsm_rft_34879": 0.6860262155532837, "camel_28859": 0.6860536932945251, "aqua_rat_28946": 0.6860660314559937, "aqua_rat_22428": 0.6860930919647217, "aqua_rat_6040": 0.6861514449119568, "aqua_rat_33984": 0.6862465143203735, "aqua_rat_57525": 0.6862736344337463, "gsm_rft_12209": 0.686340868473053, "gsm_train_21935": 0.6863934397697449, "aqua_rat_14324": 0.68650221824646, "camel_28879": 0.686808705329895, "gsm_rft_24796": 0.6872386336326599, "aqua_rat_25003": 0.6875017881393433, "camel_28858": 0.6876275539398193, "aqua_rat_6326": 0.6877774000167847, "camel_5358": 0.6878111362457275, "gsm_rft_9784": 0.6879287958145142, "aqua_rat_48959": 0.6880409717559814, "aqua_rat_71907": 0.6882444620132446, "camel_47290": 0.6882628202438354, "gsm_rft_9980": 0.688468873500824, "aqua_rat_82369": 0.6886155605316162, "aqua_rat_12925": 0.6887520551681519, "camel_28804": 0.6890367865562439, "aqua_rat_8349": 0.6890423893928528, "aqua_rat_40900": 0.6890923380851746, "aqua_rat_64374": 0.689124345779419, "aqua_rat_68112": 0.6893202066421509, "camel_5114": 0.6895118355751038, "camel_28841": 0.6895215511322021, "aqua_rat_49292": 0.6895257234573364, "aqua_rat_6773": 0.6895333528518677, "camel_28852": 0.6895790696144104, "aqua_rat_36249": 0.6896565556526184, "aqua_rat_60788": 0.6897403597831726, "aqua_rat_28523": 0.6897560954093933, "camel_28833": 0.6897757053375244, "camel_28537": 0.6898061037063599, "camel_28826": 0.6899555921554565, "camel_28820": 0.6900370717048645, "gsm_rft_29698": 0.6900635361671448, "aqua_rat_81657": 0.6900734901428223, "aqua_rat_83008": 0.6901035904884338, "camel_5035": 0.6904520392417908, "aqua_rat_50400": 0.6907843351364136, "camel_39513": 0.6909760236740112, "aqua_rat_43215": 0.6912497878074646, "aqua_rat_8211": 0.6912553310394287, "aqua_rat_14107": 0.6913629174232483, "gsm_rft_15250": 0.691512405872345, "aqua_rat_75022": 0.6916157007217407, "aqua_rat_71933": 0.6917648911476135, "gsm_train_13418": 0.691886842250824, "camel_39271": 0.6919022798538208, "gsm_train_21544": 0.6919669508934021, "TheoremQA_panlu/uniform_circular_motion1.json": 0.6919849514961243, "gsm_rft_21678": 0.6920937299728394, "aqua_rat_59927": 0.6921009421348572, "gsm_rft_7812": 0.6922744512557983, "aqua_rat_71031": 0.6924414038658142, "gsm_rft_6897": 0.692624568939209, "camel_24382": 0.6926370859146118, "aqua_rat_79908": 0.6926866769790649, "aqua_rat_6162": 0.6927897930145264, "camel_28805": 0.6929171681404114, "camel_16285": 0.6929776668548584, "camel_5178": 0.6934311985969543, "aqua_rat_70370": 0.6936120390892029, "camel_28830": 0.6937370300292969, "camel_16249": 0.6937422156333923, "camel_28878": 0.6940329670906067, "gsm_rft_11389": 0.6944102048873901, "camel_28864": 0.6944975852966309, "gsm_rft_22295": 0.6945179104804993, "camel_28861": 0.6946225166320801, "aqua_rat_59937": 0.6948859691619873, "aqua_rat_13604": 0.6949833035469055, "gsm_rft_11031": 0.6953554749488831, "camel_28872": 0.6956233382225037, "camel_39475": 0.6956340074539185, "camel_28832": 0.6961952447891235, "camel_28836": 0.6962118148803711, "aqua_rat_77586": 0.6963656544685364, "aqua_rat_59621": 0.69642174243927, "camel_5138": 0.6965456008911133, "aqua_rat_64811": 0.6965698003768921, "aqua_rat_42233": 0.696776270866394, "camel_28532": 0.6972547173500061, "aqua_rat_6709": 0.697598934173584, "aqua_rat_3331": 0.6976739764213562, "gsm_train_17819": 0.6977464556694031, "gsm_rft_17551": 0.6977464556694031, "gsm_rft_9344": 0.6982272267341614, "gsm_rft_2452": 0.6984028816223145, "camel_16275": 0.6987489461898804, "camel_5188": 0.6988925337791443, "camel_28806": 0.6992996335029602, "aqua_rat_9793": 0.6997035145759583, "camel_28860": 0.7009626030921936, "camel_28808": 0.7010003924369812, "camel_5311": 0.7017698884010315, "aqua_rat_57461": 0.7021042108535767, "aqua_rat_4051": 0.7023470997810364, "aqua_rat_32037": 0.7026312947273254, "camel_28800": 0.7026519179344177, "camel_28873": 0.7029908895492554, "gsm_rft_57": 0.7032713294029236, "camel_24344": 0.7048428654670715, "camel_28853": 0.7048900723457336, "camel_5011": 0.7051655650138855, "camel_28815": 0.7054264545440674, "camel_28866": 0.7060061097145081, "camel_28875": 0.7068966031074524, "camel_28845": 0.7075703144073486, "camel_5001": 0.7077795267105103, "aqua_rat_77082": 0.7090017795562744, "aqua_rat_53348": 0.7092044949531555, "camel_28137": 0.7092072367668152, "camel_28828": 0.7096816301345825, "TheoremQA_panlu/uniform_circular_motion2.json": 0.7097728848457336, "camel_28801": 0.7106046080589294, "camel_28867": 0.7108630537986755, "camel_16246": 0.7109041213989258, "camel_28811": 0.711645781993866, "TheoremQA_xinyi/rotation.json": 0.7121149897575378, "camel_28812": 0.7122161388397217, "camel_28847": 0.7132182121276855, "camel_28831": 0.7132965326309204, "camel_4979": 0.7151473164558411, "camel_28840": 0.7210031747817993, "camel_28809": 0.7214350700378418, "camel_28816": 0.7375338077545166, "camel_17406": 0.7400293946266174, "camel_5004": 0.7444644570350647, "camel_28842": 0.7459675073623657, "TheoremQA_xinyi/newtons_laws_1.json": 0.7715612649917603}, "TheoremQA_xinyi/cramer_rao_lower_bound_2.json": {"camel_9484": 0, "camel_9364": 0, "camel_9424": 0, "camel_8383": 0, "TheoremQA_xinyi/cramer_rao_lower_bound_2.json": 0, "camel_9412": 0, "camel_9370": 0, "camel_9365": 0, "camel_9415": 0, "camel_9398": 0, "camel_17118": 0.6857755780220032, "camel_17086": 0.6859055757522583, "camel_16078": 0.6859845519065857, "camel_17085": 0.6860182285308838, "camel_17495": 0.6860420107841492, "aqua_rat_29552": 0.6860610842704773, "camel_16010": 0.6860615611076355, "camel_17042": 0.6860870718955994, "camel_17084": 0.6861315369606018, "camel_11029": 0.6861443519592285, "camel_17108": 0.6861695051193237, "aqua_rat_53223": 0.6862314343452454, "camel_11001": 0.6862503290176392, "camel_40852": 0.6863816976547241, "camel_17581": 0.6864709258079529, "camel_17054": 0.6865053772926331, "camel_17444": 0.6865706443786621, "camel_17055": 0.6866127848625183, "camel_10998": 0.6866530776023865, "camel_6347": 0.68668532371521, "camel_17067": 0.6868041753768921, "camel_41651": 0.68692946434021, "camel_17033": 0.6870361566543579, "camel_6392": 0.6872537732124329, "camel_17098": 0.6872990727424622, "camel_10979": 0.6873267292976379, "camel_17115": 0.6873956918716431, "camel_11604": 0.6874115467071533, "camel_6329": 0.6875094175338745, "TheoremQA_xinyi/maximum_entropy_1.json": 0.6875290274620056, "camel_11002": 0.6875931620597839, "camel_17065": 0.6876255869865417, "camel_6325": 0.6877030730247498, "camel_11178": 0.6877855658531189, "camel_16836": 0.6878136992454529, "camel_17576": 0.6878665089607239, "camel_17556": 0.6879414916038513, "camel_16805": 0.687964677810669, "camel_10929": 0.6880738139152527, "camel_16443": 0.6881075501441956, "camel_40948": 0.6884166598320007, "camel_10934": 0.6884572505950928, "TheoremQA_xinyi/distortion_rate_function_2.json": 0.6888090968132019, "camel_17107": 0.6888211369514465, "camel_16940": 0.6889113187789917, "camel_16806": 0.6891859173774719, "camel_16474": 0.6893298625946045, "aqua_rat_46351": 0.6894192695617676, "camel_38642": 0.6894401907920837, "camel_17015": 0.6894983649253845, "camel_16879": 0.6895700097084045, "camel_17740": 0.6899124979972839, "aqua_rat_37501": 0.6899511218070984, "camel_16108": 0.689984917640686, "camel_11365": 0.6902652382850647, "camel_10352": 0.6903631091117859, "camel_16804": 0.6904467940330505, "camel_16839": 0.6905180215835571, "camel_17478": 0.6909003257751465, "camel_16050": 0.69091796875, "camel_16155": 0.6912935376167297, "camel_40889": 0.6913965344429016, "camel_16026": 0.6915188431739807, "camel_17114": 0.6916425824165344, "camel_17515": 0.6916577219963074, "camel_16021": 0.6917756199836731, "camel_17452": 0.6919735074043274, "camel_28793": 0.6921079754829407, "camel_16132": 0.6921154856681824, "camel_16018": 0.6922022104263306, "camel_6331": 0.6922553181648254, "camel_17048": 0.6923462748527527, "camel_16005": 0.6923525333404541, "camel_16814": 0.6924084424972534, "camel_40652": 0.692568838596344, "camel_17073": 0.6926096081733704, "camel_16828": 0.6926763653755188, "camel_11161": 0.6926836967468262, "camel_16455": 0.6928299069404602, "camel_16121": 0.6929800510406494, "camel_16414": 0.693058967590332, "camel_16054": 0.6931302547454834, "camel_16464": 0.6935228705406189, "camel_16038": 0.6935551166534424, "camel_16040": 0.693665623664856, "camel_17060": 0.693713366985321, "TheoremQA_xinyi/fano_inequality.json": 0.6938768029212952, "camel_17476": 0.6944790482521057, "camel_16065": 0.6946134567260742, "camel_17095": 0.6946386098861694, "camel_6323": 0.6947140693664551, "camel_16045": 0.6947365403175354, "camel_16849": 0.6949445605278015, "camel_16068": 0.6949574947357178, "camel_28988": 0.6950504779815674, "camel_40705": 0.6951320767402649, "camel_16041": 0.6951429843902588, "camel_17082": 0.6951485872268677, "camel_16052": 0.6952978372573853, "camel_16466": 0.6953153014183044, "camel_17119": 0.6953408122062683, "camel_17494": 0.6954163312911987, "camel_17063": 0.6959075927734375, "camel_16067": 0.695916473865509, "camel_17041": 0.6960805058479309, "camel_16062": 0.6962951421737671, "TheoremQA_wenhuchen/morera's_theorem1.json": 0.6963338255882263, "camel_11000": 0.6963706612586975, "camel_16832": 0.6965408325195312, "camel_17090": 0.6972946524620056, "camel_16967": 0.6973652243614197, "camel_16149": 0.6976547837257385, "camel_17053": 0.6977077126502991, "camel_10833": 0.698046863079071, "camel_16011": 0.6980915665626526, "camel_16152": 0.6983336210250854, "camel_16037": 0.6985112428665161, "camel_16401": 0.6985765695571899, "camel_16133": 0.698620080947876, "camel_16843": 0.6987881660461426, "camel_16079": 0.698958158493042, "camel_17087": 0.6991577744483948, "camel_17007": 0.6992170214653015, "camel_16437": 0.6993381977081299, "camel_16063": 0.6995189785957336, "camel_16086": 0.6995978355407715, "camel_28974": 0.699984073638916, "camel_17037": 0.6999964714050293, "camel_16826": 0.7001007199287415, "camel_17195": 0.7003388404846191, "camel_16803": 0.7009826898574829, "camel_16126": 0.7011020183563232, "camel_17112": 0.7011837959289551, "camel_17092": 0.7012410163879395, "camel_16854": 0.7012773752212524, "camel_16122": 0.701770007610321, "camel_16036": 0.7021447420120239, "camel_17070": 0.702299952507019, "camel_16425": 0.7023037075996399, "camel_16842": 0.7025431394577026, "camel_16813": 0.7027928233146667, "camel_16450": 0.7028275728225708, "camel_16049": 0.7029774188995361, "camel_16434": 0.7030344009399414, "camel_17062": 0.7037781476974487, "camel_16075": 0.7042483687400818, "camel_17462": 0.7045561671257019, "camel_16891": 0.7045787572860718, "camel_16033": 0.7046756148338318, "camel_16864": 0.704784095287323, "camel_16850": 0.7052480578422546, "camel_16142": 0.7060800790786743, "camel_17045": 0.706596314907074, "camel_39499": 0.7067936062812805, "camel_16469": 0.7069820761680603, "camel_17369": 0.7075234651565552, "camel_17750": 0.708488404750824, "camel_16118": 0.7087571620941162, "camel_16106": 0.7088749408721924, "camel_16834": 0.7089616060256958, "camel_16113": 0.7094637751579285, "camel_16830": 0.7104941606521606, "camel_16072": 0.7107864618301392, "camel_17125": 0.7123116850852966, "camel_38649": 0.71286940574646, "camel_16857": 0.7133194804191589, "camel_16131": 0.7133258581161499, "camel_16412": 0.7134640216827393, "camel_16815": 0.7144290804862976, "camel_16860": 0.714489221572876, "camel_16013": 0.7149838209152222, "TheoremQA_xinyi/chi_square_test.json": 0.7150194048881531, "camel_16835": 0.7152128219604492, "camel_16002": 0.7155490517616272, "camel_16862": 0.7160202860832214, "TheoremQA_wenhuchen/Poisson_process2.json": 0.7169566750526428, "camel_17184": 0.7193864583969116, "camel_16104": 0.7203518152236938, "camel_17551": 0.721329391002655, "camel_16840": 0.7217615246772766, "camel_16112": 0.7222306132316589, "camel_17178": 0.7228426337242126, "camel_16136": 0.7312352061271667, "TheoremQA_xinyi/Concavity_of_second_law_of_thermodynamics.json": 0.7316222190856934, "camel_16119": 0.7319068312644958, "TheoremQA_xinyi/fisher_information_4.json": 0.7496769428253174, "TheoremQA_mingyin/log-concave1.json": 0.7547352910041809, "TheoremQA_xinyi/maximum_entropy_2.json": 0.7566096186637878, "TheoremQA_xinyi/fisher_information_3.json": 0.8215554356575012, "TheoremQA_xinyi/cramer_rao_lower_bound_1.json": 0.8658237457275391}, "TheoremQA_elainewan/math_algebra_5.json": {"camel_14476": 0, "camel_14440": 0, "camel_14442": 0, "camel_14475": 0, "camel_15114": 0, "camel_14448": 0, "camel_14548": 0, "camel_14493": 0, "camel_14474": 0, "camel_14401": 0, "camel_15098": 0, "camel_14421": 0, "camel_14450": 0, "camel_14428": 0, "camel_14531": 0, "camel_14543": 0, "camel_14544": 0, "camel_14455": 0, "camel_14443": 0, "camel_14403": 0, "camel_14414": 0, "camel_14471": 0, "camel_14536": 0, "camel_14479": 0, "camel_14437": 0, "camel_14410": 0, "camel_14406": 0, "camel_14449": 0, "camel_14444": 0, "camel_15106": 0, "camel_14478": 0, "camel_14409": 0, "camel_14452": 0, "camel_14515": 0, "camel_14501": 0, "camel_14456": 0, "camel_14411": 0, "camel_14427": 0, "camel_15043": 0, "camel_15074": 0, "camel_14529": 0, "camel_14504": 0, "camel_14404": 0, "camel_14441": 0, "TheoremQA_elainewan/math_algebra_5.json": 0, "camel_14498": 0, "camel_14554": 0, "camel_15072": 0, "camel_14424": 0, "camel_14429": 0, "camel_14415": 0, "camel_14436": 0, "camel_15051": 0, "camel_14472": 0, "camel_14538": 0, "camel_14530": 0, "camel_14503": 0, "camel_15063": 0, "camel_15108": 0, "camel_40153": 0.7365291714668274, "math_test_precalculus_356": 0.736603319644928, "camel_5888": 0.7366398572921753, "camel_5892": 0.7369909286499023, "camel_9320": 0.737092912197113, "math_train_precalculus_404": 0.7371538281440735, "camel_9310": 0.7374120950698853, "camel_47699": 0.7376651763916016, "camel_39008": 0.7379998564720154, "camel_47761": 0.7380715012550354, "camel_9329": 0.738081157207489, "camel_40139": 0.738581657409668, "camel_47820": 0.7386521697044373, "camel_9292": 0.7390258312225342, "math_test_precalculus_254": 0.7390312552452087, "camel_47548": 0.7390902042388916, "camel_40146": 0.7391000390052795, "camel_47438": 0.7392857670783997, "camel_47833": 0.739379346370697, "math_train_precalculus_1213": 0.7393863797187805, "camel_9348": 0.7395452260971069, "camel_5664": 0.7396547198295593, "math_train_precalculus_1007": 0.7398102283477783, "camel_5906": 0.7403154969215393, "camel_49135": 0.7403361201286316, "camel_47702": 0.7403374314308167, "camel_9330": 0.7406336069107056, "camel_49851": 0.7407639026641846, "camel_49888": 0.7411029934883118, "camel_5819": 0.7411386966705322, "math_test_precalculus_1044": 0.7412604689598083, "camel_5866": 0.7415066957473755, "camel_40104": 0.7419993281364441, "camel_9317": 0.7420157194137573, "camel_9287": 0.7421549558639526, "camel_40127": 0.7422704100608826, "camel_40142": 0.7424212098121643, "camel_40081": 0.7427094578742981, "camel_39003": 0.7428781986236572, "camel_40110": 0.7430617809295654, "math_train_precalculus_900": 0.7431362271308899, "camel_40150": 0.7431413531303406, "camel_40096": 0.7432330846786499, "camel_47757": 0.7433170080184937, "math_train_precalculus_188": 0.7434446811676025, "camel_9351": 0.7436325550079346, "math_test_precalculus_980": 0.7437433004379272, "camel_28918": 0.7439077496528625, "camel_40136": 0.7441266775131226, "camel_49165": 0.7441360354423523, "camel_40102": 0.7441381812095642, "camel_5917": 0.7443259358406067, "camel_40083": 0.7445800304412842, "camel_40089": 0.7447112202644348, "math_train_precalculus_125": 0.7448025345802307, "camel_40135": 0.7448963522911072, "camel_5823": 0.745250940322876, "camel_47348": 0.745682954788208, "camel_40118": 0.7458183765411377, "camel_40141": 0.7458298802375793, "camel_47337": 0.7461283206939697, "camel_40103": 0.7462431192398071, "camel_5846": 0.7462707757949829, "camel_5889": 0.7463440299034119, "camel_47352": 0.7467970848083496, "camel_5622": 0.7473381161689758, "camel_40154": 0.7473827004432678, "camel_40111": 0.7474413514137268, "camel_30479": 0.747624933719635, "math_train_precalculus_1187": 0.7479722499847412, "camel_40112": 0.7480630278587341, "camel_47729": 0.7485549449920654, "camel_47776": 0.7487922310829163, "camel_5875": 0.748879611492157, "camel_5843": 0.7490425109863281, "camel_5858": 0.7490525245666504, "camel_40108": 0.7492478489875793, "camel_47740": 0.7493463754653931, "camel_47297": 0.7493675351142883, "camel_9288": 0.7494068145751953, "camel_40092": 0.7496454119682312, "camel_40114": 0.7496610879898071, "camel_40152": 0.7497010231018066, "camel_47301": 0.7497727870941162, "camel_49146": 0.7509021759033203, "camel_40128": 0.7512533068656921, "camel_40097": 0.7512695789337158, "camel_49126": 0.7513226270675659, "camel_40143": 0.7515121102333069, "camel_5903": 0.751573383808136, "camel_5851": 0.7516225576400757, "camel_5898": 0.7518128156661987, "camel_5882": 0.752265989780426, "camel_40132": 0.7524120807647705, "camel_19702": 0.7524796724319458, "camel_9344": 0.753198504447937, "math_test_precalculus_341": 0.7533380389213562, "camel_5913": 0.7551026344299316, "camel_49882": 0.7552378177642822, "camel_5872": 0.7558807730674744, "camel_5739": 0.7558818459510803, "camel_5910": 0.756150484085083, "camel_40157": 0.7569770216941833, "camel_47592": 0.7570483088493347, "camel_40082": 0.7575232982635498, "camel_40116": 0.7576894760131836, "camel_40133": 0.7578228712081909, "camel_5847": 0.758145272731781, "camel_47774": 0.759491503238678, "aqua_rat_67418": 0.7605176568031311, "camel_5865": 0.760619580745697, "camel_9342": 0.7617225050926208, "camel_9333": 0.7630294561386108, "camel_40140": 0.7631636261940002, "camel_40145": 0.7632851600646973, "camel_5915": 0.7634682059288025, "camel_5870": 0.7647534608840942, "math_train_precalculus_975": 0.7648093104362488, "camel_5878": 0.7655567526817322, "camel_5876": 0.7658482789993286, "camel_5869": 0.7663645148277283, "camel_40137": 0.7670806050300598, "camel_47693": 0.7674089074134827, "camel_47742": 0.7688685059547424, "camel_5871": 0.7700132727622986, "camel_47759": 0.7708412408828735, "camel_5914": 0.7712405920028687, "math_train_precalculus_271": 0.7717388868331909, "camel_5874": 0.776573121547699, "camel_5919": 0.7768183946609497, "camel_5879": 0.777644157409668, "camel_47291": 0.7787803411483765, "camel_5916": 0.7797892689704895, "camel_40126": 0.7828166484832764, "camel_8985": 0.7849525213241577, "camel_5863": 0.787249743938446, "camel_36766": 0.7910349369049072, "camel_5911": 0.7910652756690979, "camel_5877": 0.7914695739746094, "math_test_precalculus_1218": 0.792984664440155, "camel_5859": 0.7931659817695618}, "TheoremQA_xueguangma/taylors_approximation_theorem.json": {"camel_7622": 0, "camel_7646": 0, "camel_6620": 0, "camel_6878": 0, "camel_7630": 0, "camel_6009": 0, "camel_6386": 0, "camel_6066": 0, "camel_6605": 0, "camel_6001": 0, "camel_6053": 0, "camel_6599": 0, "camel_6896": 0, "camel_6012": 0, "camel_6812": 0, "camel_6032": 0, "camel_6586": 0, "camel_7632": 0, "camel_6078": 0, "camel_7620": 0, "camel_7603": 0, "camel_6026": 0, "camel_6037": 0, "camel_6014": 0, "camel_6028": 0, "camel_6070": 0, "camel_6574": 0, "camel_7621": 0, "camel_6043": 0, "camel_6049": 0, "camel_6655": 0, "camel_6602": 0, "camel_6075": 0, "camel_6074": 0, "camel_6611": 0, "camel_6035": 0, "camel_6045": 0, "camel_6054": 0, "camel_6617": 0, "camel_6635": 0, "camel_6041": 0, "camel_7613": 0, "camel_7602": 0, "camel_7486": 0, "camel_7670": 0, "camel_7628": 0, "camel_6572": 0, "camel_7512": 0, "camel_6076": 0, "camel_6013": 0, "camel_6632": 0, "camel_7493": 0, "camel_6618": 0, "camel_6601": 0, "camel_6561": 0, "camel_6563": 0, "camel_6571": 0, "camel_6570": 0, "camel_6578": 0, "camel_6612": 0, "camel_6627": 0, "camel_6633": 0, "camel_6025": 0, "camel_6589": 0, "camel_6565": 0, "camel_6060": 0, "camel_6024": 0, "camel_6598": 0, "camel_6587": 0, "camel_6015": 0, "camel_6860": 0, "camel_6577": 0, "camel_6027": 0, "camel_6005": 0, "camel_6596": 0, "camel_6624": 0, "camel_6628": 0, "camel_6044": 0, "camel_6613": 0, "camel_6615": 0, "camel_6583": 0, "camel_6569": 0, "camel_6039": 0, "camel_6614": 0, "camel_6592": 0, "camel_6588": 0, "camel_7625": 0, "camel_6597": 0, "camel_7458": 0, "camel_7442": 0, "camel_6638": 0, "camel_7466": 0, "camel_7501": 0, "camel_7477": 0, "camel_7509": 0, "camel_7472": 0, "camel_7474": 0, "camel_7659": 0, "camel_7517": 0, "camel_7482": 0, "camel_7443": 0, "camel_7679": 0, "camel_7502": 0, "camel_7450": 0, "camel_7447": 0, "camel_6077": 0, "camel_7445": 0, "camel_7479": 0, "camel_7481": 0, "camel_7516": 0, "camel_7506": 0, "camel_7449": 0, "camel_6031": 0, "camel_7503": 0, "camel_7607": 0, "camel_7455": 0, "camel_6566": 0, "camel_7456": 0, "camel_7941": 0, "camel_6604": 0, "camel_6033": 0, "camel_6849": 0, "camel_7629": 0, "camel_7515": 0, "camel_6068": 0, "camel_7614": 0, "camel_7469": 0, "camel_7464": 0, "camel_6625": 0, "camel_7457": 0, "camel_6630": 0, "camel_7507": 0, "camel_7636": 0, "camel_6575": 0, "camel_6600": 0, "camel_6560": 0, "camel_6581": 0, "camel_7510": 0, "camel_7465": 0, "camel_7518": 0, "camel_6629": 0, "camel_7965": 0, "camel_6593": 0, "camel_6622": 0, "camel_6019": 0, "camel_7513": 0, "camel_6580": 0, "camel_7446": 0, "camel_6017": 0, "camel_7504": 0, "camel_6022": 0, "camel_7410": 0, "camel_6616": 0, "camel_7487": 0, "camel_7971": 0, "camel_7441": 0, "camel_6591": 0, "camel_7669": 0, "camel_6623": 0, "camel_7467": 0, "camel_6573": 0, "camel_7497": 0, "camel_6607": 0, "camel_7459": 0, "camel_6579": 0, "camel_7485": 0, "camel_6637": 0, "camel_6634": 0, "camel_6606": 0, "camel_7500": 0, "camel_7677": 0, "camel_7505": 0, "camel_6562": 0, "camel_7490": 0, "camel_6621": 0, "camel_6610": 0, "camel_6619": 0, "camel_7492": 0, "camel_6609": 0, "camel_7483": 0, "camel_6626": 0, "camel_7462": 0, "camel_7448": 0, "camel_7996": 0, "camel_6825": 0, "camel_6608": 0, "camel_6594": 0, "camel_6585": 0, "camel_7926": 0, "camel_7453": 0, "camel_7452": 0, "camel_7924": 0, "camel_6061": 0, "TheoremQA_wenhuchen/morera's_theorem1.json": 0.7561079263687134, "camel_5425": 0.7618680000305176, "camel_45322": 0.7619028687477112, "camel_18886": 0.7663694620132446, "camel_18951": 0.7720327377319336, "camel_18905": 0.7908154129981995, "TheoremQA_elainewan/math_calculus_3_6.json": 0.7965654134750366}, "TheoremQA_maxku/signalprocessing5-nyquist.json": {"TheoremQA_maxku/signalprocessing5-nyquist.json": 0, "camel_44869": 0.6751272678375244, "camel_45766": 0.675389289855957, "camel_45504": 0.6754427552223206, "camel_44870": 0.675592839717865, "camel_45903": 0.6758098602294922, "camel_45937": 0.6759032607078552, "camel_45973": 0.6760158538818359, "camel_45776": 0.676124095916748, "camel_45745": 0.6766210794448853, "camel_44530": 0.6766281723976135, "camel_44499": 0.6767289042472839, "camel_45687": 0.6767440438270569, "camel_45635": 0.6769719123840332, "camel_44758": 0.6770246028900146, "camel_45003": 0.6774556636810303, "camel_44343": 0.6776500940322876, "camel_45528": 0.6779617667198181, "camel_44421": 0.6781485080718994, "camel_45259": 0.6781497001647949, "camel_45199": 0.6783459782600403, "camel_44826": 0.6783463954925537, "camel_45193": 0.6783544421195984, "camel_45320": 0.6784932613372803, "camel_45690": 0.6785231232643127, "camel_45533": 0.678706705570221, "camel_44440": 0.6792043447494507, "camel_45693": 0.6792722344398499, "camel_45945": 0.6794279217720032, "camel_44551": 0.6794950366020203, "camel_45432": 0.6795174479484558, "camel_45948": 0.6797869205474854, "camel_44762": 0.6798753142356873, "camel_45506": 0.6800493597984314, "camel_44455": 0.6801000833511353, "camel_45818": 0.6802585124969482, "camel_44510": 0.6807157397270203, "camel_44485": 0.6809320449829102, "camel_44490": 0.6810070872306824, "camel_45798": 0.6810503602027893, "camel_45658": 0.6812335848808289, "camel_44500": 0.6812931895256042, "camel_45130": 0.6813662648200989, "camel_45952": 0.6814482808113098, "camel_44574": 0.6815562844276428, "camel_45762": 0.6816030144691467, "camel_45162": 0.682309091091156, "camel_45771": 0.6826063394546509, "camel_45681": 0.6826814413070679, "camel_45182": 0.6828213930130005, "camel_43748": 0.6828312277793884, "camel_44560": 0.6828895807266235, "camel_45775": 0.6834496259689331, "camel_45835": 0.6835293769836426, "camel_45725": 0.6836872100830078, "camel_44462": 0.6837411522865295, "camel_44477": 0.6837570071220398, "camel_43690": 0.6841009855270386, "camel_45830": 0.6842120289802551, "camel_45729": 0.6845577955245972, "camel_44825": 0.6850051879882812, "camel_45176": 0.6850829720497131, "camel_45151": 0.6852596402168274, "camel_45709": 0.6853488683700562, "camel_45700": 0.6856715679168701, "camel_44555": 0.6857194900512695, "camel_45314": 0.6862744092941284, "camel_45518": 0.6864618062973022, "camel_45489": 0.6866796016693115, "camel_45949": 0.686955451965332, "camel_44426": 0.6873167753219604, "camel_45791": 0.6875633597373962, "camel_44473": 0.687830924987793, "camel_45928": 0.688040554523468, "camel_45754": 0.6880576610565186, "camel_45821": 0.6884412169456482, "camel_45799": 0.6887456178665161, "camel_45782": 0.6888291239738464, "camel_45815": 0.6891883015632629, "camel_45923": 0.6894951462745667, "camel_45786": 0.6897899508476257, "camel_44545": 0.6902352571487427, "camel_44852": 0.6909670829772949, "camel_44506": 0.691231369972229, "camel_44429": 0.6916462182998657, "camel_44447": 0.6917065382003784, "camel_44507": 0.6923316717147827, "camel_45606": 0.6923607587814331, "camel_44858": 0.6928325891494751, "camel_44523": 0.6930999755859375, "camel_45184": 0.6931561827659607, "camel_45706": 0.6933291554450989, "camel_44466": 0.6933491230010986, "camel_44865": 0.6933837532997131, "camel_44824": 0.6933901906013489, "camel_45931": 0.693571925163269, "camel_45492": 0.6949732899665833, "camel_44517": 0.6949874758720398, "camel_45644": 0.6955852508544922, "camel_45609": 0.6955858469009399, "camel_45936": 0.695796012878418, "camel_45682": 0.6959229111671448, "camel_44504": 0.695955216884613, "camel_44766": 0.6961221098899841, "camel_45772": 0.6963278651237488, "camel_44514": 0.69643235206604, "camel_44416": 0.6964479684829712, "camel_44536": 0.6970793008804321, "camel_45607": 0.6972525119781494, "camel_45988": 0.6976415514945984, "camel_44424": 0.6976624727249146, "camel_45755": 0.6977809071540833, "camel_45615": 0.6981146931648254, "camel_44488": 0.6987169981002808, "camel_45744": 0.6988204121589661, "camel_45133": 0.698874831199646, "camel_45713": 0.6990229487419128, "camel_44544": 0.6994605660438538, "camel_45756": 0.6997892260551453, "camel_44566": 0.6999489068984985, "camel_45809": 0.7007505297660828, "camel_44448": 0.7012665867805481, "camel_45765": 0.7015858292579651, "camel_44851": 0.7017359733581543, "camel_45173": 0.7018213868141174, "camel_45134": 0.7020477056503296, "camel_44839": 0.7024700045585632, "camel_45998": 0.702988862991333, "camel_44621": 0.7033071517944336, "camel_45781": 0.7034338712692261, "camel_45763": 0.703705370426178, "camel_45788": 0.7040037512779236, "camel_45684": 0.7040969729423523, "camel_44534": 0.7041710019111633, "camel_45627": 0.7045232653617859, "camel_45790": 0.7045364379882812, "camel_44401": 0.7055835127830505, "camel_45792": 0.7069244980812073, "camel_44554": 0.7072656750679016, "camel_45152": 0.7076646089553833, "camel_45727": 0.7077714800834656, "camel_44526": 0.7078101634979248, "camel_45680": 0.7078914046287537, "TheoremQA_maxku/signalprocessing19-period.json": 0.7080092430114746, "camel_44828": 0.7084274888038635, "camel_45784": 0.7092645764350891, "camel_45654": 0.710681676864624, "camel_44420": 0.7106886506080627, "camel_45966": 0.7109537124633789, "camel_44475": 0.7125347852706909, "camel_44820": 0.7138524055480957, "camel_45198": 0.7146608829498291, "camel_44807": 0.7164379358291626, "camel_45512": 0.7165748476982117, "camel_44533": 0.7174736857414246, "camel_44846": 0.7176539897918701, "camel_44442": 0.7181471586227417, "camel_44516": 0.7195388078689575, "camel_44872": 0.7209761142730713, "camel_44538": 0.7211468815803528, "camel_45604": 0.7214348316192627, "camel_45803": 0.7226535081863403, "camel_44491": 0.723807156085968, "camel_44848": 0.7242733240127563, "camel_44861": 0.7259872555732727, "camel_44528": 0.726708173751831, "camel_45171": 0.727008581161499, "camel_45146": 0.727184534072876, "camel_44849": 0.7274205684661865, "camel_44498": 0.7304109334945679, "camel_45797": 0.7324588894844055, "camel_44467": 0.7329657077789307, "camel_45813": 0.7334807515144348, "camel_44487": 0.7350417375564575, "camel_45600": 0.7354554533958435, "camel_44439": 0.7399850487709045, "camel_44537": 0.7421835064888, "camel_45805": 0.7425363659858704, "camel_45676": 0.7450622320175171, "camel_44492": 0.7451675534248352, "camel_44411": 0.7496247887611389, "camel_45796": 0.7521029114723206, "camel_44459": 0.7556072473526001, "camel_45812": 0.7556413412094116, "camel_44838": 0.7572279572486877, "camel_44724": 0.7622039914131165, "camel_45646": 0.7881655097007751, "camel_45764": 0.7894508838653564, "camel_44460": 0.7911615371704102, "camel_44873": 0.7964122295379639, "camel_44400": 0.8301994800567627, "camel_44835": 0.8328268527984619, "camel_45819": 0.8462046980857849, "TheoremQA_maxku/signalprocessing10-nyquist.json": 0.8597067594528198, "camel_44860": 0.8651490211486816, "TheoremQA_maxku/signalprocessing12-nyquist.json": 0.8666943311691284, "camel_45810": 0.8712795972824097, "camel_45807": 0.8805387616157532, "TheoremQA_maxku/signalprocessing11-nyquist.json": 0.8898093104362488, "camel_45778": 0.9083231687545776}, "TheoremQA_xueguangma/spot_rate.json": {"TheoremQA_xueguangma/spot_rate.json": 0, "aqua_rat_27039": 0.6348711252212524, "aqua_rat_39813": 0.6348817348480225, "aqua_rat_43665": 0.6349532604217529, "aqua_rat_24247": 0.6350035071372986, "math_train_algebra_1658": 0.6350154280662537, "aqua_rat_80518": 0.6350921988487244, "aqua_rat_84755": 0.6351122260093689, "aqua_rat_37174": 0.6351407766342163, "aqua_rat_13348": 0.6351732015609741, "aqua_rat_86517": 0.6352949142456055, "aqua_rat_58694": 0.6353089809417725, "aqua_rat_63070": 0.6353144645690918, "aqua_rat_19769": 0.6353512406349182, "aqua_rat_45487": 0.6354073286056519, "aqua_rat_34332": 0.6355270147323608, "aqua_rat_24068": 0.6357256174087524, "aqua_rat_80078": 0.6358610391616821, "aqua_rat_56852": 0.6358633637428284, "aqua_rat_67841": 0.6358920335769653, "aqua_rat_70447": 0.6359506249427795, "aqua_rat_84309": 0.6360147595405579, "aqua_rat_69764": 0.6360182166099548, "aqua_rat_53305": 0.6360349059104919, "aqua_rat_50447": 0.6361274719238281, "aqua_rat_31099": 0.6361284255981445, "aqua_rat_39424": 0.6361671090126038, "gsm_rft_19766": 0.6363366842269897, "aqua_rat_29356": 0.6363558173179626, "aqua_rat_73739": 0.63693767786026, "aqua_rat_34029": 0.6370927095413208, "aqua_rat_72412": 0.6371903419494629, "aqua_rat_42893": 0.637298047542572, "aqua_rat_32568": 0.6373597383499146, "aqua_rat_65425": 0.6373957991600037, "gsm_rft_20212": 0.6375260353088379, "aqua_rat_23277": 0.6376051902770996, "aqua_rat_48456": 0.637605607509613, "math_train_algebra_667": 0.6378567218780518, "aqua_rat_62371": 0.6380858421325684, "aqua_rat_75047": 0.6381264925003052, "math_test_algebra_608": 0.6381430625915527, "aqua_rat_70506": 0.6381539702415466, "aqua_rat_3830": 0.6383489370346069, "aqua_rat_65263": 0.6385024785995483, "camel_37735": 0.6385883092880249, "aqua_rat_5272": 0.6385982632637024, "aqua_rat_47761": 0.63865727186203, "aqua_rat_67076": 0.6388106346130371, "aqua_rat_68": 0.6389605402946472, "gsm_rft_30946": 0.6389608979225159, "aqua_rat_75273": 0.6389842629432678, "aqua_rat_14235": 0.6391882300376892, "aqua_rat_9488": 0.6391984224319458, "gsm_rft_9014": 0.6394167542457581, "aqua_rat_3773": 0.6394224762916565, "aqua_rat_30897": 0.6395294070243835, "gsm_train_34036": 0.6395546793937683, "aqua_rat_64215": 0.6395578384399414, "aqua_rat_778": 0.6396671533584595, "aqua_rat_32852": 0.6397070288658142, "aqua_rat_87486": 0.6397092938423157, "aqua_rat_37203": 0.6397191286087036, "aqua_rat_26508": 0.6397293210029602, "aqua_rat_44830": 0.639922022819519, "aqua_rat_67696": 0.6399738788604736, "aqua_rat_30386": 0.6399741768836975, "aqua_rat_42017": 0.6401407718658447, "aqua_rat_15079": 0.6402808427810669, "aqua_rat_81404": 0.6407395601272583, "aqua_rat_33430": 0.6409249305725098, "aqua_rat_6475": 0.6410753130912781, "aqua_rat_70031": 0.6412068605422974, "aqua_rat_87246": 0.6414353847503662, "aqua_rat_33294": 0.6415975093841553, "aqua_rat_65316": 0.6416895389556885, "aqua_rat_66298": 0.6418713331222534, "aqua_rat_48160": 0.6419821381568909, "aqua_rat_74699": 0.642150342464447, "aqua_rat_7674": 0.6423845291137695, "aqua_rat_72794": 0.6424374580383301, "aqua_rat_64523": 0.6425659656524658, "aqua_rat_63322": 0.6429759860038757, "aqua_rat_24542": 0.6430750489234924, "aqua_rat_25723": 0.6433582901954651, "aqua_rat_84779": 0.6435949802398682, "aqua_rat_67914": 0.6443014144897461, "aqua_rat_40840": 0.6443031430244446, "aqua_rat_14876": 0.6443732380867004, "aqua_rat_86835": 0.644788384437561, "math_test_algebra_2626": 0.6449306011199951, "aqua_rat_64995": 0.6450214385986328, "aqua_rat_10582": 0.6450318098068237, "aqua_rat_78121": 0.6454697251319885, "aqua_rat_38068": 0.6457297205924988, "aqua_rat_87884": 0.6460373401641846, "aqua_rat_255": 0.6463665962219238, "aqua_rat_77602": 0.6464099287986755, "aqua_rat_87589": 0.6464099884033203, "aqua_rat_54028": 0.64641273021698, "math_train_algebra_369": 0.6464254260063171, "aqua_rat_21626": 0.6466761231422424, "aqua_rat_70690": 0.6472621560096741, "aqua_rat_47773": 0.6473808288574219, "aqua_rat_42949": 0.6474438309669495, "aqua_rat_9965": 0.6476308703422546, "aqua_rat_64914": 0.6480538845062256, "aqua_rat_51100": 0.6484339833259583, "aqua_rat_57943": 0.6485400199890137, "aqua_rat_59587": 0.6486485600471497, "math_test_algebra_1862": 0.6486583948135376, "aqua_rat_41963": 0.649329662322998, "aqua_rat_46607": 0.6499168276786804, "aqua_rat_56240": 0.6504640579223633, "aqua_rat_44264": 0.6504688262939453, "aqua_rat_34698": 0.650478720664978, "math_test_algebra_311": 0.6504929661750793, "aqua_rat_64976": 0.6510283350944519, "aqua_rat_78570": 0.6515592932701111, "aqua_rat_75833": 0.6521222591400146, "aqua_rat_28984": 0.6525332927703857, "aqua_rat_43060": 0.6525631546974182, "aqua_rat_33923": 0.6527940630912781, "aqua_rat_2632": 0.6528084874153137, "aqua_rat_83740": 0.6534383296966553, "aqua_rat_83524": 0.6534444689750671, "aqua_rat_56718": 0.6538981795310974, "aqua_rat_69547": 0.6540973782539368, "aqua_rat_71866": 0.6546173095703125, "aqua_rat_10990": 0.6546218991279602, "camel_37747": 0.6546884179115295, "aqua_rat_77105": 0.6550682783126831, "aqua_rat_52978": 0.6554844975471497, "aqua_rat_71911": 0.655700147151947, "aqua_rat_83774": 0.6561980247497559, "aqua_rat_79789": 0.6564474105834961, "aqua_rat_56845": 0.6568067073822021, "aqua_rat_1115": 0.6569691300392151, "math_test_algebra_1611": 0.6570149064064026, "aqua_rat_83756": 0.6573114991188049, "aqua_rat_17663": 0.6575586199760437, "aqua_rat_9874": 0.6589642763137817, "aqua_rat_67442": 0.6603684425354004, "aqua_rat_8732": 0.6616793870925903, "aqua_rat_10902": 0.6636554598808289, "aqua_rat_38648": 0.6642720699310303, "aqua_rat_1058": 0.6646262407302856, "aqua_rat_14728": 0.6658754944801331, "aqua_rat_79856": 0.6659055352210999, "aqua_rat_65797": 0.6663121581077576, "aqua_rat_65883": 0.6665752530097961, "aqua_rat_59160": 0.6672419309616089, "aqua_rat_77609": 0.6686553955078125, "TheoremQA_xueguangma/present_value_2.json": 0.6689940690994263, "aqua_rat_62727": 0.6693298816680908, "aqua_rat_50660": 0.6709690093994141, "aqua_rat_40411": 0.6718147993087769, "aqua_rat_78533": 0.6720033884048462, "aqua_rat_6283": 0.6723886132240295, "aqua_rat_54684": 0.6725719571113586, "aqua_rat_79047": 0.6727447509765625, "aqua_rat_21296": 0.6732052564620972, "aqua_rat_63735": 0.6742162108421326, "aqua_rat_88843": 0.6748718023300171, "aqua_rat_30597": 0.6774712800979614, "aqua_rat_32321": 0.6794713735580444, "aqua_rat_26425": 0.6802372932434082, "aqua_rat_78193": 0.6804362535476685, "aqua_rat_45263": 0.6810761094093323, "aqua_rat_56436": 0.681354820728302, "aqua_rat_57507": 0.6814608573913574, "aqua_rat_45586": 0.6814852356910706, "aqua_rat_26043": 0.6816521286964417, "aqua_rat_9033": 0.6817451119422913, "camel_37746": 0.682557225227356, "aqua_rat_37463": 0.686693012714386, "aqua_rat_3885": 0.690055251121521, "aqua_rat_80676": 0.6910085082054138, "aqua_rat_45508": 0.6914012432098389, "TheoremQA_xueguangma/forward_price_3.json": 0.6925220489501953, "camel_16747": 0.6926019191741943, "TheoremQA_xueguangma/present_value_1.json": 0.6955084800720215, "math_train_algebra_940": 0.6966471076011658, "aqua_rat_20758": 0.6973406076431274, "aqua_rat_36461": 0.6988275051116943, "aqua_rat_72737": 0.6989529132843018, "TheoremQA_xueguangma/forward_rate_1.json": 0.7005014419555664, "aqua_rat_49352": 0.7026150226593018, "aqua_rat_45867": 0.7027269601821899, "aqua_rat_46315": 0.709313690662384, "aqua_rat_36498": 0.7109147906303406, "TheoremQA_xueguangma/forward_price_1.json": 0.7187358140945435, "aqua_rat_31553": 0.7221925258636475, "TheoremQA_xueguangma/put_call_parity_1.json": 0.738960862159729, "aqua_rat_29154": 0.7437655925750732, "aqua_rat_85902": 0.7440586686134338, "camel_45730": 0.7517876625061035, "camel_45738": 0.7626579999923706, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7680204510688782, "TheoremQA_xueguangma/forward_price_2.json": 0.8016805648803711}, "TheoremQA_xueguangma/binomial_model_2.json": {"TheoremQA_xueguangma/binomial_model_2.json": 0, "gsm_rft_29683": 0.6561623811721802, "gsm_rft_24497": 0.656190812587738, "gsm_rft_25001": 0.6562298536300659, "aqua_rat_9965": 0.6562387943267822, "aqua_rat_47176": 0.6562556028366089, "camel_16779": 0.6563565731048584, "camel_25323": 0.6564203500747681, "aqua_rat_70690": 0.6565175652503967, "aqua_rat_28151": 0.6565352082252502, "camel_25645": 0.6567319631576538, "aqua_rat_67841": 0.6568149328231812, "camel_25276": 0.6569158434867859, "camel_17938": 0.6569355130195618, "camel_16777": 0.6571894288063049, "gsm_rft_24227": 0.6572372317314148, "camel_17930": 0.6572909355163574, "camel_16782": 0.6573305130004883, "camel_17946": 0.6573858261108398, "gsm_rft_27168": 0.6575269103050232, "aqua_rat_87884": 0.6579052209854126, "camel_25654": 0.6580494046211243, "camel_16759": 0.658073902130127, "aqua_rat_10855": 0.6581393480300903, "aqua_rat_87246": 0.6584116220474243, "camel_25665": 0.6584762930870056, "gsm_rft_3318": 0.6585201621055603, "aqua_rat_24347": 0.6585379242897034, "aqua_rat_22731": 0.658565104007721, "aqua_rat_32321": 0.6585689187049866, "aqua_rat_66371": 0.6586705446243286, "camel_25763": 0.6589693427085876, "camel_17981": 0.6589771509170532, "camel_25177": 0.6589967608451843, "camel_38660": 0.6590487360954285, "camel_25670": 0.6590638160705566, "camel_17945": 0.6591823697090149, "gsm_train_14713": 0.6592859625816345, "gsm_rft_27770": 0.6593745946884155, "camel_25157": 0.6594669222831726, "camel_25131": 0.6595894694328308, "gsm_rft_2241": 0.6596639156341553, "aqua_rat_64914": 0.6597646474838257, "gsm_rft_10252": 0.6597954034805298, "aqua_rat_77486": 0.6603102087974548, "gsm_rft_5811": 0.6608548760414124, "camel_25660": 0.6610268950462341, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.6612560153007507, "camel_25278": 0.6614457368850708, "camel_25658": 0.6615451574325562, "camel_25302": 0.6615819931030273, "camel_17999": 0.6620082259178162, "gsm_rft_252": 0.6620684266090393, "camel_25785": 0.6621304750442505, "camel_25332": 0.6621860265731812, "aqua_rat_19740": 0.6623741984367371, "TheoremQA_elainewan/econ_micro_18.json": 0.6624976992607117, "camel_17979": 0.6627597808837891, "camel_17931": 0.6629883646965027, "camel_25165": 0.6630337834358215, "aqua_rat_42733": 0.6630348563194275, "camel_25367": 0.6633254885673523, "camel_25244": 0.6634379029273987, "camel_38714": 0.6637639999389648, "camel_16727": 0.664040744304657, "camel_17968": 0.6641424298286438, "camel_37714": 0.664171040058136, "camel_17955": 0.6642162799835205, "gsm_train_32027": 0.6644455194473267, "aqua_rat_82406": 0.6645523309707642, "gsm_rft_6879": 0.6646857857704163, "camel_45730": 0.6646913886070251, "camel_10544": 0.6647325158119202, "aqua_rat_11679": 0.6648017168045044, "camel_16795": 0.6648055911064148, "gsm_rft_11189": 0.6648707985877991, "gsm_rft_24082": 0.6650636196136475, "camel_17943": 0.6653504371643066, "camel_17976": 0.6654004454612732, "camel_25174": 0.6656463742256165, "camel_25299": 0.6657575368881226, "math_test_algebra_2626": 0.6660130620002747, "aqua_rat_255": 0.6663000583648682, "camel_25256": 0.6663221716880798, "aqua_rat_36141": 0.6664050817489624, "camel_25810": 0.6664484739303589, "camel_25357": 0.6669712662696838, "camel_17988": 0.6670103073120117, "camel_25239": 0.6672752499580383, "camel_17991": 0.6673204302787781, "aqua_rat_85600": 0.6674216389656067, "camel_25170": 0.6674676537513733, "camel_25291": 0.667578399181366, "camel_25139": 0.6676398515701294, "gsm_rft_32195": 0.6676591634750366, "camel_10558": 0.6679261922836304, "camel_16733": 0.6681824922561646, "camel_25637": 0.6682639718055725, "math_test_algebra_1611": 0.6683384776115417, "gsm_rft_30206": 0.6684684753417969, "gsm_train_32871": 0.6684684753417969, "camel_25600": 0.6686320304870605, "camel_17947": 0.6689873933792114, "camel_17929": 0.6693878173828125, "camel_17922": 0.6694994568824768, "camel_17937": 0.6698290705680847, "camel_25320": 0.6703487038612366, "camel_38709": 0.6704168915748596, "camel_17974": 0.6705219745635986, "camel_25219": 0.6707996129989624, "camel_10543": 0.6711732149124146, "camel_25329": 0.671186089515686, "camel_38702": 0.6713404059410095, "aqua_rat_22889": 0.6717495918273926, "camel_17957": 0.6717577576637268, "camel_24831": 0.6720151901245117, "camel_37693": 0.6724839210510254, "camel_25644": 0.6725810766220093, "camel_10514": 0.6728579998016357, "aqua_rat_79363": 0.6729662418365479, "camel_25252": 0.673101544380188, "camel_17994": 0.6731775999069214, "camel_25168": 0.6731901168823242, "camel_25664": 0.673471212387085, "camel_25190": 0.67388916015625, "camel_17967": 0.673992395401001, "camel_25635": 0.6746450066566467, "camel_17998": 0.6750221848487854, "camel_10482": 0.6750351190567017, "math_test_algebra_1043": 0.6751478314399719, "camel_17940": 0.6751543879508972, "camel_25270": 0.6751779913902283, "camel_25184": 0.6754313111305237, "camel_16763": 0.6759724020957947, "camel_10555": 0.6766403913497925, "camel_16783": 0.6767988204956055, "camel_16780": 0.6773248910903931, "camel_25212": 0.6773494482040405, "camel_25676": 0.6777963042259216, "math_train_prealgebra_1338": 0.6778140664100647, "aqua_rat_13263": 0.6780652403831482, "camel_17936": 0.6785967350006104, "camel_25255": 0.678816556930542, "camel_17990": 0.6790079474449158, "camel_25223": 0.6791924238204956, "camel_17995": 0.6797670125961304, "camel_16754": 0.6801106929779053, "camel_17954": 0.680288553237915, "aqua_rat_68410": 0.6806488037109375, "camel_17950": 0.6807530522346497, "camel_17960": 0.6809393167495728, "aqua_rat_21750": 0.6810189485549927, "camel_25808": 0.6811281442642212, "gsm_rft_23795": 0.6811304688453674, "camel_17984": 0.6813156604766846, "camel_16755": 0.6833567023277283, "gsm_rft_20347": 0.683647096157074, "gsm_train_374": 0.683647096157074, "gsm_rft_17816": 0.6839154958724976, "camel_17939": 0.6844208240509033, "camel_16740": 0.6844403147697449, "camel_25136": 0.6857426166534424, "gsm_rft_26543": 0.6857854127883911, "gsm_rft_11850": 0.6868059039115906, "camel_17926": 0.6868225932121277, "camel_10492": 0.6873582005500793, "camel_17983": 0.6875423789024353, "camel_17964": 0.6875965595245361, "camel_10480": 0.6885501146316528, "camel_16789": 0.6888974905014038, "camel_16748": 0.6889182925224304, "camel_45695": 0.6898285746574402, "camel_17975": 0.6899924874305725, "camel_17941": 0.6903968453407288, "TheoremQA_xueguangma/forward_price_3.json": 0.6917343139648438, "camel_25253": 0.6927106976509094, "camel_10506": 0.6936047077178955, "camel_17924": 0.693847119808197, "camel_25251": 0.6943219304084778, "camel_10488": 0.695021390914917, "camel_25615": 0.6962345838546753, "camel_17921": 0.6981586813926697, "camel_25224": 0.6994279026985168, "TheoremQA_xueguangma/forward_price_1.json": 0.6999845504760742, "camel_16791": 0.702038049697876, "camel_10542": 0.703052818775177, "camel_17952": 0.7044488787651062, "camel_17927": 0.7053367495536804, "camel_17961": 0.7066836953163147, "TheoremQA_xueguangma/forward_price_2.json": 0.7075571417808533, "camel_17935": 0.7120684385299683, "camel_17965": 0.7181708812713623, "TheoremQA_xueguangma/geometric_brownian_motion.json": 0.7255166172981262, "camel_17963": 0.7303974032402039, "TheoremQA_xueguangma/options_theory.json": 0.7319134473800659, "camel_17989": 0.7419444918632507, "camel_17923": 0.7465007305145264, "camel_16747": 0.7511279582977295, "TheoremQA_xueguangma/binomial_model_1.json": 0.7578856348991394, "TheoremQA_xueguangma/put_call_parity_1.json": 0.7660345435142517}, "TheoremQA_panlu/molar_heat_capacity2.json": {"TheoremQA_panlu/molar_heat_capacity2.json": 0, "aqua_rat_54137": 0.617746889591217, "gsm_train_28209": 0.6180865168571472, "gsm_train_21309": 0.6181073188781738, "gsm_rft_2838": 0.6181821823120117, "aqua_rat_82505": 0.6182477474212646, "gsm_rft_13663": 0.618481457233429, "gsm_rft_3495": 0.6185038089752197, "gsm_rft_29430": 0.6185833215713501, "gsm_rft_16020": 0.6186262369155884, "gsm_rft_32941": 0.6186419725418091, "aqua_rat_40611": 0.6187050342559814, "gsm_rft_21129": 0.6188031435012817, "aqua_rat_59033": 0.6188675165176392, "aqua_rat_56029": 0.6188814640045166, "aqua_rat_52083": 0.6189646124839783, "aqua_rat_18519": 0.6189663410186768, "gsm_rft_10339": 0.6189687848091125, "aqua_rat_26982": 0.6189996004104614, "gsm_rft_31896": 0.6190619468688965, "aqua_rat_35163": 0.6192962527275085, "aqua_rat_6824": 0.6193692088127136, "aqua_rat_35656": 0.619428813457489, "aqua_rat_80897": 0.6194518804550171, "aqua_rat_56556": 0.6194942593574524, "camel_41035": 0.6195487976074219, "aqua_rat_81791": 0.6195518970489502, "gsm_rft_22573": 0.6195840239524841, "aqua_rat_55426": 0.6196315288543701, "camel_40998": 0.619651198387146, "aqua_rat_5694": 0.6197278499603271, "aqua_rat_8427": 0.6198948621749878, "gsm_rft_27494": 0.6200289726257324, "camel_41009": 0.6200489401817322, "gsm_rft_34227": 0.620086669921875, "gsm_train_34452": 0.620086669921875, "gsm_train_23489": 0.6201710104942322, "aqua_rat_49469": 0.6203066110610962, "gsm_rft_32869": 0.6204946041107178, "aqua_rat_54332": 0.6205930709838867, "gsm_rft_23705": 0.6207782626152039, "gsm_rft_27697": 0.6212677955627441, "aqua_rat_22146": 0.6214468479156494, "gsm_rft_20284": 0.6218856573104858, "gsm_rft_8140": 0.6220099925994873, "gsm_rft_13546": 0.6220397353172302, "gsm_rft_33310": 0.6221672892570496, "aqua_rat_20180": 0.6227046847343445, "camel_41002": 0.6230313777923584, "gsm_rft_2300": 0.623502254486084, "gsm_train_8215": 0.6235830187797546, "gsm_rft_1891": 0.6236081719398499, "gsm_rft_28262": 0.6236650347709656, "gsm_rft_32188": 0.6236650347709656, "gsm_rft_25936": 0.6237687468528748, "gsm_rft_7694": 0.6239866018295288, "gsm_rft_5168": 0.6240781545639038, "aqua_rat_12104": 0.6243526935577393, "aqua_rat_31644": 0.6244102716445923, "gsm_train_11492": 0.6246002912521362, "gsm_rft_7772": 0.6246002912521362, "gsm_rft_25765": 0.6246963739395142, "gsm_rft_27445": 0.6247923374176025, "gsm_rft_108": 0.6248602271080017, "gsm_rft_18137": 0.6249152421951294, "gsm_train_8842": 0.6249706149101257, "aqua_rat_44307": 0.6251828074455261, "gsm_rft_16550": 0.6251907348632812, "gsm_rft_26557": 0.6253758668899536, "aqua_rat_43180": 0.6254293322563171, "gsm_rft_14132": 0.6254838705062866, "gsm_train_665": 0.6259533762931824, "gsm_rft_16075": 0.6259627342224121, "aqua_rat_54949": 0.6261646747589111, "aqua_rat_75205": 0.6261869072914124, "gsm_rft_25502": 0.6263113617897034, "aqua_rat_53252": 0.6263602375984192, "gsm_rft_31522": 0.6263611316680908, "gsm_train_10599": 0.6263611316680908, "gsm_rft_22219": 0.6265754699707031, "gsm_rft_10892": 0.6265780329704285, "gsm_rft_8044": 0.6267234086990356, "gsm_rft_5908": 0.6268014907836914, "gsm_train_6141": 0.6268014907836914, "gsm_rft_24776": 0.6270392537117004, "gsm_rft_8497": 0.6270910501480103, "gsm_rft_12680": 0.6275059580802917, "gsm_train_13297": 0.6275059580802917, "gsm_rft_513": 0.6275059580802917, "aqua_rat_17861": 0.6275301575660706, "aqua_rat_55150": 0.6276312470436096, "aqua_rat_50560": 0.6276994347572327, "gsm_rft_22912": 0.6279366612434387, "gsm_train_35436": 0.6279366612434387, "aqua_rat_68302": 0.6285431981086731, "aqua_rat_16313": 0.6285969614982605, "gsm_rft_11723": 0.628769040107727, "gsm_rft_30002": 0.6287928223609924, "aqua_rat_44185": 0.6288377642631531, "gsm_rft_7048": 0.6291617751121521, "gsm_train_16188": 0.6291617751121521, "aqua_rat_72461": 0.6291974782943726, "aqua_rat_61666": 0.6294596791267395, "gsm_rft_6660": 0.6296707987785339, "aqua_rat_22936": 0.6302121877670288, "aqua_rat_4588": 0.6303015947341919, "aqua_rat_29911": 0.6304999589920044, "aqua_rat_41829": 0.6306487321853638, "aqua_rat_43074": 0.6306663155555725, "aqua_rat_14988": 0.6315414309501648, "gsm_train_33171": 0.6317690014839172, "aqua_rat_79178": 0.6318989992141724, "gsm_rft_28086": 0.6320171356201172, "gsm_rft_5803": 0.6320956349372864, "gsm_train_31498": 0.6320956349372864, "gsm_rft_34553": 0.6322582364082336, "aqua_rat_73234": 0.6324490904808044, "gsm_rft_33297": 0.6325163841247559, "aqua_rat_12763": 0.6326927542686462, "gsm_rft_24993": 0.6327521204948425, "gsm_rft_33340": 0.6328319311141968, "aqua_rat_86062": 0.6330070495605469, "gsm_rft_29159": 0.6335710883140564, "gsm_train_15489": 0.6337200403213501, "gsm_train_13248": 0.6337494254112244, "gsm_rft_21990": 0.6338764429092407, "camel_28081": 0.6339978575706482, "gsm_rft_13049": 0.6347625255584717, "gsm_rft_23476": 0.6350619196891785, "aqua_rat_47102": 0.6355589628219604, "gsm_rft_27655": 0.6391583681106567, "aqua_rat_64101": 0.6401606202125549, "aqua_rat_25759": 0.6404163837432861, "gsm_rft_20649": 0.6405173540115356, "aqua_rat_48607": 0.6412580609321594, "camel_37933": 0.6416172385215759, "aqua_rat_7859": 0.6426331400871277, "gsm_rft_25975": 0.6427117586135864, "aqua_rat_4598": 0.6435234546661377, "gsm_rft_26258": 0.6437894105911255, "aqua_rat_47999": 0.6437982320785522, "gsm_rft_12636": 0.6445425152778625, "gsm_train_24555": 0.6445425152778625, "aqua_rat_55213": 0.6452234387397766, "aqua_rat_75763": 0.645875871181488, "aqua_rat_23539": 0.6460307836532593, "aqua_rat_8581": 0.6471317410469055, "aqua_rat_1653": 0.6473626494407654, "aqua_rat_38504": 0.6480458378791809, "gsm_rft_28838": 0.6493953466415405, "gsm_train_22269": 0.6494007706642151, "gsm_rft_32487": 0.6494007706642151, "aqua_rat_55821": 0.6503788232803345, "gsm_rft_34322": 0.6508220434188843, "aqua_rat_27001": 0.6508460640907288, "aqua_rat_72360": 0.6508597731590271, "gsm_rft_9894": 0.6514386534690857, "aqua_rat_7630": 0.6514611840248108, "gsm_rft_2592": 0.651881754398346, "gsm_rft_10857": 0.6522184014320374, "gsm_train_232": 0.6522184014320374, "aqua_rat_3199": 0.6523483991622925, "gsm_rft_33719": 0.652401864528656, "gsm_train_23183": 0.6525230407714844, "gsm_rft_34578": 0.6525776386260986, "gsm_rft_16954": 0.6526504755020142, "gsm_rft_28746": 0.6527895927429199, "aqua_rat_21803": 0.6528597474098206, "gsm_rft_14019": 0.6534735560417175, "aqua_rat_32250": 0.6536101698875427, "aqua_rat_21090": 0.6538828015327454, "gsm_rft_3972": 0.6544883847236633, "gsm_rft_26786": 0.6562850475311279, "gsm_rft_7862": 0.6562883257865906, "gsm_rft_14007": 0.6578145027160645, "gsm_rft_22576": 0.6582764983177185, "gsm_rft_10941": 0.65848708152771, "gsm_train_8512": 0.65848708152771, "gsm_rft_30536": 0.6587125658988953, "gsm_rft_12582": 0.6589072346687317, "aqua_rat_28949": 0.6597276926040649, "gsm_rft_22822": 0.6639568209648132, "aqua_rat_8480": 0.6664978265762329, "camel_17587": 0.6756452322006226, "gsm_rft_15366": 0.6762061715126038, "gsm_rft_22401": 0.6795029044151306, "camel_45925": 0.6806060671806335, "gsm_rft_19423": 0.6816411018371582, "gsm_train_15924": 0.6816411018371582, "gsm_rft_14462": 0.6816411018371582, "camel_28151": 0.6820109486579895, "gsm_train_4193": 0.6911321878433228, "gsm_rft_6591": 0.6911321878433228, "gsm_rft_21326": 0.6927032470703125, "gsm_rft_35104": 0.6929587721824646, "gsm_rft_21213": 0.693454921245575, "gsm_train_10153": 0.6936557292938232, "gsm_rft_23914": 0.7005226016044617, "TheoremQA_panlu/molar_heat_capacity1.json": 0.7077893614768982, "camel_37984": 0.7215818166732788}, "TheoremQA_mingyin/cauchy-integral-theorem1.json": {"camel_42011": 0, "camel_42741": 0, "camel_43268": 0, "camel_42163": 0, "camel_43270": 0, "camel_42553": 0, "camel_42510": 0, "camel_42012": 0, "camel_42495": 0, "camel_42588": 0, "camel_42065": 0, "camel_42429": 0, "camel_42196": 0, "camel_43154": 0, "camel_42599": 0, "camel_42615": 0, "camel_42785": 0, "camel_42323": 0, "camel_42610": 0, "camel_43498": 0, "camel_42616": 0, "camel_43123": 0, "camel_42288": 0, "camel_42799": 0, "camel_42774": 0, "camel_43164": 0, "camel_43130": 0, "camel_42798": 0, "camel_42756": 0, "camel_42596": 0, "camel_43521": 0, "camel_43851": 0, "camel_42454": 0, "camel_42187": 0, "camel_42617": 0, "camel_42045": 0, "camel_43869": 0, "camel_43189": 0, "camel_43163": 0, "camel_42526": 0, "camel_43442": 0, "camel_43517": 0, "camel_43460": 0, "camel_42229": 0, "camel_42180": 0, "camel_43020": 0, "camel_43486": 0, "camel_42211": 0, "camel_43382": 0, "camel_42792": 0, "camel_42734": 0, "camel_42554": 0, "camel_43455": 0, "camel_42432": 0, "camel_43582": 0, "camel_42186": 0, "camel_42585": 0, "camel_43105": 0, "camel_42224": 0, "camel_42759": 0, "camel_42172": 0, "camel_42729": 0, "camel_43152": 0, "camel_43381": 0, "camel_42720": 0, "camel_42812": 0, "camel_43546": 0, "camel_42557": 0, "camel_42042": 0, "camel_43559": 0, "camel_43230": 0, "camel_42760": 0, "camel_42424": 0, "camel_42777": 0, "camel_42201": 0, "camel_42584": 0, "camel_42488": 0, "camel_42417": 0, "camel_42009": 0, "camel_42167": 0, "camel_42909": 0, "camel_42171": 0, "camel_42525": 0, "camel_42032": 0, "camel_43175": 0, "camel_42202": 0, "camel_42757": 0, "camel_42053": 0, "camel_42073": 0, "camel_42787": 0, "camel_42181": 0, "camel_42518": 0, "camel_42236": 0, "camel_43450": 0, "camel_42735": 0, "camel_42564": 0, "camel_43480": 0, "camel_42223": 0, "camel_43495": 0, "camel_42746": 0, "camel_42747": 0, "camel_42494": 0, "camel_43263": 0, "camel_42019": 0, "camel_43104": 0, "camel_43001": 0, "camel_42752": 0, "camel_42881": 0, "camel_43237": 0, "camel_42782": 0, "camel_43170": 0, "camel_42482": 0, "camel_43499": 0, "camel_42020": 0, "camel_42748": 0, "camel_42486": 0, "camel_42767": 0, "camel_42474": 0, "camel_42828": 0, "camel_42005": 0, "camel_42727": 0, "camel_43557": 0, "camel_42968": 0, "camel_42031": 0, "camel_43551": 0, "camel_43191": 0, "camel_42776": 0, "camel_42614": 0, "camel_43560": 0, "camel_42217": 0, "camel_42547": 0, "camel_43478": 0, "camel_42206": 0, "camel_42750": 0, "camel_42982": 0, "camel_42026": 0, "camel_42607": 0, "camel_42006": 0, "camel_43454": 0, "camel_43131": 0, "camel_42636": 0, "camel_42519": 0, "camel_43129": 0, "camel_43103": 0, "camel_42835": 0, "camel_43011": 0, "camel_42055": 0, "camel_43133": 0, "camel_42740": 0, "camel_42477": 0, "camel_42732": 0, "camel_43596": 0, "camel_43181": 0, "camel_42193": 0, "camel_42218": 0, "camel_42220": 0, "camel_43743": 0, "camel_42197": 0, "camel_43493": 0, "camel_42789": 0, "camel_42764": 0, "camel_42078": 0, "camel_43132": 0, "camel_42235": 0, "camel_43444": 0, "camel_42198": 0, "camel_42772": 0, "camel_42480": 0, "camel_42478": 0, "camel_43500": 0, "camel_42231": 0, "camel_42023": 0, "camel_42538": 0, "camel_43153": 0, "camel_43137": 0, "camel_42061": 0, "camel_43159": 0, "camel_42954": 0, "camel_43158": 0, "camel_42002": 0, "TheoremQA_mingyin/cauchy-integral-theorem1.json": 0, "camel_42192": 0, "camel_43110": 0, "camel_42635": 0, "camel_43160": 0, "camel_42749": 0, "camel_42989": 0, "camel_43504": 0, "camel_42899": 0, "camel_42021": 0, "camel_42070": 0, "camel_42175": 0, "camel_42587": 0, "camel_42549": 0, "camel_42907": 0, "camel_43035": 0, "camel_42208": 0, "camel_43501": 0, "camel_42051": 0, "TheoremQA_wenhuchen/cauchy_integral1.json": 0.78533935546875}, "TheoremQA_wenhuchen/determinant2.json": {"camel_14824": 0, "camel_14130": 0, "camel_14088": 0, "camel_14652": 0, "camel_15298": 0, "camel_14906": 0, "camel_14123": 0, "camel_14099": 0, "camel_14138": 0, "camel_15590": 0, "camel_14001": 0, "camel_14913": 0, "camel_14862": 0, "camel_14131": 0, "camel_14840": 0, "camel_14146": 0, "camel_14648": 0, "camel_14679": 0, "camel_14143": 0, "camel_15670": 0, "camel_14848": 0, "camel_14924": 0, "camel_14908": 0, "camel_14822": 0, "camel_14914": 0, "camel_14866": 0, "camel_14912": 0, "camel_14113": 0, "camel_14093": 0, "camel_14831": 0, "camel_15652": 0, "camel_14877": 0, "camel_14152": 0, "camel_14693": 0, "camel_14671": 0, "camel_14087": 0, "camel_14116": 0, "camel_14107": 0, "camel_14938": 0, "camel_14834": 0, "camel_14678": 0, "camel_14819": 0, "camel_14027": 0, "camel_14043": 0, "camel_14901": 0, "camel_14675": 0, "camel_14945": 0, "camel_14937": 0, "camel_14081": 0, "camel_14944": 0, "camel_15360": 0, "camel_14142": 0, "camel_14118": 0, "camel_14872": 0, "camel_15650": 0, "camel_14850": 0, "camel_15387": 0, "camel_14830": 0, "camel_14849": 0, "camel_14932": 0, "camel_14833": 0, "camel_14918": 0, "camel_14864": 0, "camel_14814": 0, "camel_14823": 0, "camel_14841": 0, "camel_14875": 0, "camel_14104": 0, "camel_14718": 0, "camel_14112": 0, "camel_14943": 0, "camel_14700": 0, "camel_14649": 0, "camel_14684": 0, "camel_14905": 0, "camel_14680": 0, "camel_15583": 0, "camel_14643": 0, "camel_14655": 0, "camel_14713": 0, "camel_14670": 0, "camel_14040": 0, "camel_14661": 0, "camel_14676": 0, "camel_14708": 0, "camel_14889": 0, "camel_14712": 0, "camel_14871": 0, "camel_14865": 0, "camel_14098": 0, "camel_14807": 0, "camel_14874": 0, "camel_14843": 0, "camel_14127": 0, "camel_14892": 0, "camel_14868": 0, "camel_14911": 0, "camel_14860": 0, "camel_14804": 0, "camel_14837": 0, "camel_14898": 0, "camel_14829": 0, "camel_14691": 0, "camel_14955": 0, "camel_14869": 0, "camel_14826": 0, "camel_14856": 0, "camel_14878": 0, "camel_14681": 0, "camel_14672": 0, "camel_14697": 0, "camel_14659": 0, "camel_14660": 0, "camel_14836": 0, "camel_14855": 0, "camel_14821": 0, "camel_14686": 0, "camel_14851": 0, "camel_14084": 0, "camel_14662": 0, "camel_14654": 0, "camel_14664": 0, "camel_14847": 0, "camel_14141": 0, "camel_14690": 0, "camel_14644": 0, "camel_14657": 0, "camel_14674": 0, "camel_14667": 0, "camel_14695": 0, "camel_14646": 0, "camel_14642": 0, "camel_14703": 0, "camel_15655": 0, "camel_14647": 0, "camel_14715": 0, "camel_14663": 0, "camel_15618": 0, "camel_15711": 0, "camel_14845": 0, "camel_14818": 0, "camel_14839": 0, "camel_14852": 0, "camel_14879": 0, "camel_14651": 0, "camel_14802": 0, "camel_14883": 0, "camel_14838": 0, "camel_14701": 0, "camel_15547": 0, "camel_14705": 0, "camel_14068": 0, "camel_14103": 0, "camel_14645": 0, "camel_14861": 0, "camel_14863": 0, "camel_14082": 0, "camel_14846": 0, "camel_14666": 0, "camel_14835": 0, "camel_14151": 0, "camel_15748": 0, "camel_14719": 0, "camel_14714": 0, "camel_14811": 0, "camel_14673": 0, "camel_14692": 0, "camel_14092": 0, "camel_14827": 0, "camel_14873": 0, "camel_14817": 0, "camel_14109": 0, "camel_14947": 0, "camel_14120": 0, "camel_14716": 0, "camel_14121": 0, "camel_14859": 0, "camel_14702": 0, "camel_14707": 0, "camel_14095": 0, "TheoremQA_wenhuchen/determinant2.json": 0, "camel_14656": 0, "camel_14640": 0, "camel_14685": 0, "camel_14159": 0, "camel_14696": 0, "camel_14158": 0, "camel_14136": 0, "camel_14682": 0, "camel_14687": 0, "camel_14717": 0, "camel_14641": 0, "camel_23205": 0.7875131964683533, "camel_19761": 0.7889018654823303, "camel_27628": 0.7891260981559753, "TheoremQA_elainewan/math_algebra_2.json": 0.7933884263038635, "camel_27611": 0.7941120862960815, "TheoremQA_wenhuchen/determinant1.json": 0.7941251397132874, "TheoremQA_wenhuchen/cramer's_rule1.json": 0.7975103259086609, "camel_27639": 0.8047291040420532}, "TheoremQA_elainewan/math_abstact_algebra_7_5.json": {"camel_32232": 0, "camel_32215": 0, "camel_32160": 0, "math_test_prealgebra_105": 0, "aqua_rat_8497": 0.7017568349838257, "aqua_rat_7627": 0.7017900347709656, "aqua_rat_44769": 0.7018285989761353, "aqua_rat_87480": 0.7018918991088867, "aqua_rat_57897": 0.7019162774085999, "aqua_rat_25232": 0.7019228339195251, "aqua_rat_41631": 0.7019355297088623, "aqua_rat_62139": 0.7019984126091003, "aqua_rat_48820": 0.7021476626396179, "math_train_number_theory_890": 0.7022843360900879, "aqua_rat_74864": 0.7023400068283081, "aqua_rat_8772": 0.702344536781311, "aqua_rat_17161": 0.7024766802787781, "camel_21948": 0.7025500535964966, "aqua_rat_8778": 0.7026035785675049, "aqua_rat_5175": 0.7026753425598145, "aqua_rat_45075": 0.702754020690918, "camel_12572": 0.7027974724769592, "gsm_rft_33541": 0.7030108571052551, "gsm_train_35077": 0.7030108571052551, "aqua_rat_65464": 0.7030701041221619, "aqua_rat_52611": 0.7031172513961792, "gsm_rft_18486": 0.7032167315483093, "camel_27913": 0.7033069729804993, "camel_26753": 0.7033122181892395, "aqua_rat_11166": 0.7036464214324951, "aqua_rat_11337": 0.7037718296051025, "aqua_rat_69087": 0.7039394974708557, "aqua_rat_37176": 0.7039413452148438, "aqua_rat_69177": 0.7041386961936951, "aqua_rat_56869": 0.7041536569595337, "aqua_rat_84040": 0.7041547894477844, "aqua_rat_28475": 0.7043347954750061, "aqua_rat_32110": 0.7043395638465881, "aqua_rat_87477": 0.7044046521186829, "aqua_rat_17232": 0.7046607136726379, "aqua_rat_1311": 0.7047534584999084, "aqua_rat_70372": 0.705094575881958, "aqua_rat_72820": 0.7051306962966919, "aqua_rat_76842": 0.7051512002944946, "aqua_rat_81532": 0.705238401889801, "aqua_rat_75488": 0.705298900604248, "aqua_rat_46495": 0.705359697341919, "aqua_rat_24548": 0.7053659558296204, "camel_37853": 0.7054029107093811, "math_test_number_theory_574": 0.7054612040519714, "aqua_rat_84573": 0.7055014967918396, "aqua_rat_62041": 0.705524206161499, "aqua_rat_35860": 0.7055612206459045, "aqua_rat_55310": 0.7057814002037048, "aqua_rat_22907": 0.7057950496673584, "aqua_rat_77732": 0.7061188220977783, "math_train_number_theory_1026": 0.706232488155365, "aqua_rat_43230": 0.7063345313072205, "math_test_counting_and_probability_789": 0.706467866897583, "aqua_rat_65915": 0.7066950798034668, "aqua_rat_52841": 0.7071061134338379, "aqua_rat_74851": 0.7071067094802856, "aqua_rat_12473": 0.7071706652641296, "aqua_rat_33984": 0.7073030471801758, "aqua_rat_85042": 0.7074178457260132, "aqua_rat_32089": 0.7074456214904785, "aqua_rat_85151": 0.7075948715209961, "aqua_rat_37562": 0.7077438831329346, "aqua_rat_24078": 0.7080773115158081, "aqua_rat_26616": 0.7083588242530823, "math_train_number_theory_973": 0.7085719108581543, "aqua_rat_33204": 0.7088474631309509, "aqua_rat_75486": 0.7089400887489319, "camel_12117": 0.7091481685638428, "camel_12189": 0.7093610167503357, "aqua_rat_76265": 0.7093680500984192, "aqua_rat_87106": 0.7094743847846985, "aqua_rat_1227": 0.7095568776130676, "aqua_rat_54689": 0.7096377611160278, "aqua_rat_73496": 0.7099508047103882, "aqua_rat_60208": 0.7101261615753174, "aqua_rat_47921": 0.7101413011550903, "aqua_rat_43874": 0.7101956605911255, "aqua_rat_13165": 0.7106505632400513, "aqua_rat_63600": 0.7110345363616943, "aqua_rat_52627": 0.7112168669700623, "math_test_number_theory_397": 0.7118200659751892, "math_train_number_theory_387": 0.711905300617218, "aqua_rat_32173": 0.7120665907859802, "aqua_rat_29889": 0.7122859954833984, "aqua_rat_13374": 0.7124028205871582, "aqua_rat_23957": 0.7125899195671082, "aqua_rat_79852": 0.712618887424469, "math_test_number_theory_170": 0.7130410075187683, "aqua_rat_5850": 0.7131745219230652, "aqua_rat_87505": 0.71330326795578, "math_train_number_theory_509": 0.7135023474693298, "aqua_rat_52297": 0.7135133743286133, "aqua_rat_25833": 0.7136176228523254, "camel_26790": 0.7136181592941284, "aqua_rat_77573": 0.7137701511383057, "aqua_rat_54834": 0.713780403137207, "aqua_rat_30534": 0.7141342759132385, "camel_21956": 0.7143206000328064, "aqua_rat_55599": 0.7144803404808044, "aqua_rat_66903": 0.7146129608154297, "aqua_rat_86538": 0.7146399617195129, "aqua_rat_38301": 0.7153021693229675, "aqua_rat_11641": 0.71579909324646, "math_train_number_theory_308": 0.715980589389801, "math_train_number_theory_893": 0.7162571549415588, "math_train_number_theory_307": 0.7163482904434204, "math_test_number_theory_960": 0.7165344953536987, "aqua_rat_80821": 0.7165663242340088, "aqua_rat_9296": 0.7165915966033936, "aqua_rat_63345": 0.7167322039604187, "aqua_rat_60571": 0.7167596817016602, "math_test_number_theory_1101": 0.716805636882782, "aqua_rat_60879": 0.7170014381408691, "aqua_rat_19600": 0.7171605229377747, "aqua_rat_49415": 0.7171805500984192, "math_test_number_theory_694": 0.7178530097007751, "aqua_rat_35529": 0.7178739905357361, "aqua_rat_24026": 0.7179379463195801, "math_test_number_theory_1019": 0.7179554104804993, "aqua_rat_28009": 0.7180382609367371, "aqua_rat_68705": 0.718044102191925, "math_test_counting_and_probability_41": 0.7185631990432739, "camel_12194": 0.7187820076942444, "camel_12215": 0.7198914289474487, "aqua_rat_36027": 0.7200356125831604, "aqua_rat_35257": 0.7202749848365784, "aqua_rat_2932": 0.720564067363739, "aqua_rat_88982": 0.7205643057823181, "math_train_number_theory_633": 0.7205737233161926, "aqua_rat_26493": 0.7205976843833923, "camel_12225": 0.7211751341819763, "aqua_rat_2144": 0.7218647599220276, "aqua_rat_23632": 0.7221912741661072, "aqua_rat_31136": 0.7224410772323608, "aqua_rat_46387": 0.7224807143211365, "aqua_rat_81984": 0.7225935459136963, "math_train_number_theory_431": 0.7226976752281189, "aqua_rat_31772": 0.7232823967933655, "aqua_rat_76146": 0.7233268618583679, "aqua_rat_34665": 0.7233917713165283, "aqua_rat_32844": 0.723502516746521, "aqua_rat_16804": 0.7237287759780884, "aqua_rat_65101": 0.7237398028373718, "aqua_rat_11744": 0.7243116497993469, "aqua_rat_51685": 0.7252035140991211, "aqua_rat_80447": 0.7252377867698669, "math_test_counting_and_probability_883": 0.7252550721168518, "aqua_rat_66503": 0.7254621982574463, "aqua_rat_71050": 0.7255302667617798, "aqua_rat_49145": 0.7262477278709412, "aqua_rat_80212": 0.7270063757896423, "aqua_rat_41205": 0.7271044850349426, "aqua_rat_43515": 0.7272157073020935, "aqua_rat_30682": 0.7279024124145508, "camel_21260": 0.7283290028572083, "aqua_rat_78156": 0.7286311984062195, "aqua_rat_69582": 0.7286598086357117, "aqua_rat_14595": 0.7287735342979431, "aqua_rat_32986": 0.7288690805435181, "aqua_rat_38893": 0.7288896441459656, "aqua_rat_23666": 0.7289119958877563, "aqua_rat_29119": 0.7297810912132263, "aqua_rat_12112": 0.7300864458084106, "aqua_rat_26404": 0.7300924062728882, "aqua_rat_66733": 0.7303380966186523, "aqua_rat_8921": 0.7312001585960388, "gsm_train_21935": 0.7316880226135254, "aqua_rat_65586": 0.732279360294342, "aqua_rat_71250": 0.7326520681381226, "gsm_rft_14362": 0.7327696084976196, "gsm_rft_34879": 0.7327696084976196, "aqua_rat_73398": 0.7329327464103699, "aqua_rat_83588": 0.7344657182693481, "aqua_rat_16058": 0.7347543239593506, "math_test_number_theory_631": 0.7401125431060791, "aqua_rat_32396": 0.7403388619422913, "aqua_rat_31483": 0.7420032024383545, "math_test_number_theory_23": 0.7422739267349243, "aqua_rat_88322": 0.7429288625717163, "math_train_number_theory_538": 0.7492735385894775, "aqua_rat_66272": 0.7553128600120544, "aqua_rat_31017": 0.7583439946174622, "aqua_rat_82251": 0.7588916420936584, "aqua_rat_87692": 0.7593094110488892, "aqua_rat_32099": 0.7639146447181702, "aqua_rat_2978": 0.7641720175743103, "math_train_number_theory_360": 0.7771474719047546, "aqua_rat_41243": 0.7810724973678589, "math_train_number_theory_803": 0.7825292944908142, "math_test_number_theory_200": 0.7985039949417114, "aqua_rat_12612": 0.8099091053009033, "aqua_rat_41681": 0.8147684335708618, "aqua_rat_4189": 0.8154747486114502, "aqua_rat_74037": 0.8191747665405273}, "TheoremQA_tonyxia/wave2.json": {"camel_16598": 0, "camel_16707": 0, "camel_17815": 0, "camel_16649": 0, "camel_17787": 0, "camel_16616": 0, "camel_16590": 0, "camel_17808": 0, "camel_16562": 0, "camel_17821": 0, "camel_16579": 0, "camel_17812": 0, "camel_17901": 0, "camel_16658": 0, "camel_17805": 0, "camel_16623": 0, "camel_16618": 0, "camel_16615": 0, "camel_16650": 0, "camel_16564": 0, "camel_16695": 0, "camel_16675": 0, "camel_16673": 0, "camel_16637": 0, "camel_16603": 0, "camel_17818": 0, "camel_16570": 0, "camel_16683": 0, "camel_16719": 0, "camel_16588": 0, "camel_16624": 0, "camel_16704": 0, "camel_16627": 0, "camel_16577": 0, "camel_17769": 0, "camel_16568": 0, "camel_17773": 0, "camel_16592": 0, "camel_16586": 0, "camel_17298": 0, "camel_16679": 0, "camel_17798": 0, "camel_16626": 0, "camel_17807": 0, "camel_16573": 0, "camel_17811": 0, "camel_16632": 0, "camel_16597": 0, "camel_16605": 0, "camel_16608": 0, "camel_16703": 0, "camel_16676": 0, "camel_16702": 0, "camel_16602": 0, "camel_16696": 0, "camel_16628": 0, "camel_16672": 0, "camel_16622": 0, "camel_16657": 0, "camel_16716": 0, "camel_16565": 0, "camel_16656": 0, "camel_16680": 0, "camel_16587": 0, "camel_16621": 0, "camel_16652": 0, "camel_16712": 0, "camel_16660": 0, "camel_16678": 0, "camel_16606": 0, "camel_16686": 0, "camel_16662": 0, "camel_16641": 0, "camel_17288": 0, "camel_16692": 0, "camel_16691": 0, "camel_16670": 0, "camel_16571": 0, "camel_16646": 0, "camel_16713": 0, "camel_16647": 0, "camel_16619": 0, "camel_16681": 0, "camel_16699": 0, "camel_16567": 0, "camel_16581": 0, "camel_16583": 0, "camel_16634": 0, "camel_16718": 0, "camel_16671": 0, "camel_16682": 0, "camel_16589": 0, "camel_16666": 0, "camel_17772": 0, "camel_16613": 0, "camel_16690": 0, "camel_16665": 0, "camel_16560": 0, "camel_16499": 0, "camel_16674": 0, "camel_16636": 0, "camel_16677": 0, "camel_16572": 0, "camel_16653": 0, "camel_16651": 0, "camel_16596": 0, "camel_16575": 0, "TheoremQA_tonyxia/wave2.json": 0, "aqua_rat_62133": 0.594591498374939, "camel_45155": 0.5948922038078308, "camel_43965": 0.5953130125999451, "camel_45062": 0.5955967307090759, "camel_45178": 0.5960586071014404, "camel_43975": 0.5961396098136902, "camel_43796": 0.5962292551994324, "camel_29844": 0.596573531627655, "camel_29908": 0.597458004951477, "camel_43923": 0.5977089405059814, "camel_45077": 0.599860668182373, "camel_45149": 0.6003367304801941, "gsm_rft_10505": 0.6003966927528381, "camel_45645": 0.6011149883270264, "camel_45302": 0.601422131061554, "camel_43978": 0.6026023626327515, "camel_45957": 0.6027497053146362, "camel_45144": 0.6028003692626953, "camel_43921": 0.6034611463546753, "camel_45295": 0.6035216450691223, "camel_43961": 0.6044277548789978, "camel_43952": 0.6047324538230896, "gsm_train_29099": 0.6053218841552734, "camel_45067": 0.6054867506027222, "camel_45040": 0.6058213114738464, "camel_43936": 0.6061424612998962, "camel_43995": 0.6063442230224609, "gsm_rft_17764": 0.6070168018341064, "camel_29914": 0.6072118282318115, "camel_43827": 0.6072718501091003, "camel_45102": 0.6076879501342773, "camel_45992": 0.608213484287262, "camel_45192": 0.6087712645530701, "gsm_rft_22397": 0.6094130873680115, "camel_43983": 0.6095288991928101, "camel_43945": 0.6105579733848572, "camel_43949": 0.6106114387512207, "camel_43925": 0.6110478043556213, "camel_43998": 0.6144133806228638, "camel_45141": 0.6151828765869141, "camel_45299": 0.6152384877204895, "camel_45352": 0.6155828833580017, "camel_45195": 0.6157839298248291, "TheoremQA_xinyi/momentum.json": 0.6160328984260559, "gsm_rft_11031": 0.6161412000656128, "camel_29886": 0.6171561479568481, "gsm_rft_9344": 0.617973268032074, "gsm_rft_17551": 0.6180356740951538, "gsm_train_17819": 0.6180356740951538, "gsm_rft_2452": 0.6182863116264343, "camel_45053": 0.6187970638275146, "camel_43944": 0.6191977262496948, "camel_45131": 0.6198768615722656, "camel_45324": 0.6201015710830688, "camel_43956": 0.6205965876579285, "TheoremQA_tonyxia/quantum3.json": 0.6206475496292114, "camel_43926": 0.620702862739563, "camel_43979": 0.6220909357070923, "camel_45169": 0.6221860647201538, "camel_43922": 0.6225070357322693, "camel_43963": 0.6244395971298218, "camel_29915": 0.6244801878929138, "camel_43991": 0.6259273290634155, "camel_45340": 0.6260958909988403, "TheoremQA_tonyxia/particle5.json": 0.6265589594841003, "camel_45199": 0.6300740242004395, "camel_43934": 0.6359431743621826, "camel_43964": 0.6361844539642334, "camel_45323": 0.6371762752532959, "TheoremQA_tonyxia/photoelectric1.json": 0.6383588910102844, "camel_43779": 0.6409880518913269, "camel_43792": 0.6416323781013489, "TheoremQA_tonyxia/statisticalphysics5.json": 0.6424638628959656, "camel_45136": 0.6435586810112, "camel_43947": 0.6459709405899048, "camel_45677": 0.6486349701881409, "camel_43782": 0.6537618041038513, "camel_43931": 0.6549293398857117, "camel_45075": 0.6630411744117737, "camel_45174": 0.6651418209075928, "camel_45956": 0.6660594940185547, "math_test_algebra_578": 0.6663127541542053, "camel_45140": 0.6689517498016357, "camel_45935": 0.6768954992294312, "camel_45074": 0.6784911751747131, "TheoremQA_panlu/wave_speed1.json": 0.6796331405639648, "camel_45163": 0.6855764985084534, "TheoremQA_tonyxia/semiconductor2.json": 0.7010791301727295, "TheoremQA_tonyxia/semiconductor3.json": 0.7010951042175293, "camel_45967": 0.7084781527519226, "TheoremQA_panlu/wave_length1.json": 0.7276261448860168, "camel_45999": 0.7555087804794312}, "TheoremQA_jianyu_xu/Ramsey_4.json": {"camel_22117": 0, "camel_21204": 0, "camel_21782": 0, "camel_23696": 0, "camel_23699": 0, "camel_21079": 0, "camel_21798": 0, "camel_23712": 0, "camel_23721": 0, "camel_23685": 0, "camel_23744": 0, "camel_21809": 0, "camel_21271": 0, "camel_21993": 0, "camel_23753": 0, "camel_21167": 0, "camel_21035": 0, "camel_23752": 0, "camel_23715": 0, "camel_21156": 0, "camel_22120": 0, "camel_21761": 0, "camel_21135": 0, "camel_21920": 0, "camel_20803": 0, "camel_21953": 0, "camel_21123": 0, "camel_23722": 0, "camel_23689": 0, "camel_21129": 0, "camel_21948": 0, "camel_21126": 0, "camel_21974": 0, "camel_21208": 0, "camel_21935": 0, "camel_20577": 0, "camel_21152": 0, "camel_23693": 0, "camel_21147": 0, "camel_23703": 0, "camel_21120": 0, "camel_21189": 0, "camel_21128": 0, "camel_23690": 0, "camel_21176": 0, "camel_21183": 0, "camel_21155": 0, "camel_21166": 0, "camel_23754": 0, "camel_21196": 0, "camel_21125": 0, "camel_21172": 0, "camel_23750": 0, "camel_21162": 0, "camel_21134": 0, "camel_21199": 0, "camel_21168": 0, "camel_21124": 0, "camel_21182": 0, "camel_23737": 0, "camel_21159": 0, "camel_21181": 0, "camel_21193": 0, "camel_21185": 0, "camel_23686": 0, "camel_23707": 0, "camel_21160": 0, "camel_21154": 0, "camel_21192": 0, "camel_21141": 0, "camel_21173": 0, "camel_23682": 0, "camel_21137": 0, "camel_21184": 0, "camel_21139": 0, "camel_21163": 0, "camel_21130": 0, "camel_21122": 0, "camel_21171": 0, "camel_21157": 0, "camel_23755": 0, "camel_21822": 0, "camel_23285": 0, "camel_21146": 0, "camel_21170": 0, "camel_21143": 0, "camel_21136": 0, "camel_23731": 0, "camel_23695": 0, "camel_21190": 0, "camel_21149": 0, "camel_21127": 0, "camel_23729": 0, "camel_21178": 0, "camel_21179": 0, "camel_23711": 0, "camel_21142": 0, "camel_21194": 0, "camel_21148": 0, "camel_21186": 0, "camel_21151": 0, "camel_21195": 0, "camel_21191": 0, "camel_21153": 0, "camel_21144": 0, "camel_21121": 0, "camel_21132": 0, "camel_21131": 0, "camel_21175": 0, "TheoremQA_jianyu_xu/Ramsey_4.json": 0, "camel_21188": 0, "camel_21807": 0, "camel_21428": 0, "camel_21187": 0, "camel_21169": 0, "camel_21161": 0, "camel_23714": 0, "camel_21164": 0, "camel_21145": 0, "camel_21180": 0, "camel_23748": 0, "camel_21198": 0, "aqua_rat_35937": 0.7005782723426819, "aqua_rat_36721": 0.7006407976150513, "aqua_rat_21385": 0.7007860541343689, "aqua_rat_51470": 0.7008622288703918, "aqua_rat_40713": 0.701056182384491, "aqua_rat_71540": 0.7011101841926575, "camel_36342": 0.7011906504631042, "aqua_rat_48010": 0.701231062412262, "aqua_rat_12157": 0.7013304233551025, "aqua_rat_20302": 0.7015888094902039, "camel_36347": 0.7017365097999573, "math_test_counting_and_probability_1081": 0.7019301056861877, "aqua_rat_75127": 0.7019736766815186, "aqua_rat_29990": 0.7021543979644775, "aqua_rat_69238": 0.7021600008010864, "aqua_rat_14545": 0.7024768590927124, "aqua_rat_80435": 0.7025624513626099, "aqua_rat_15480": 0.7031733989715576, "aqua_rat_15776": 0.70364910364151, "math_test_prealgebra_1764": 0.703658938407898, "aqua_rat_6437": 0.7037749290466309, "aqua_rat_64812": 0.7040639519691467, "aqua_rat_78747": 0.7042770981788635, "aqua_rat_43433": 0.7048283815383911, "aqua_rat_53479": 0.7049256563186646, "aqua_rat_55983": 0.7052910923957825, "aqua_rat_85357": 0.706071138381958, "aqua_rat_10004": 0.7061993479728699, "math_test_prealgebra_1071": 0.7062098383903503, "aqua_rat_57036": 0.7064443826675415, "aqua_rat_73009": 0.7071300745010376, "aqua_rat_57329": 0.7073649168014526, "aqua_rat_67638": 0.7075330018997192, "camel_37615": 0.7083103060722351, "aqua_rat_50073": 0.709434986114502, "math_train_prealgebra_815": 0.7094811201095581, "aqua_rat_34841": 0.7098039984703064, "aqua_rat_54277": 0.7101302742958069, "aqua_rat_76352": 0.7101613879203796, "camel_37642": 0.7103562951087952, "math_train_counting_and_probability_979": 0.7105903029441833, "aqua_rat_47465": 0.7109017968177795, "math_train_counting_and_probability_817": 0.7120435833930969, "math_train_counting_and_probability_431": 0.712291419506073, "aqua_rat_50640": 0.7124541997909546, "aqua_rat_12645": 0.7127366065979004, "TheoremQA_jianyu_xu/Ramsey_5.json": 0.7130536437034607, "math_test_counting_and_probability_341": 0.7135629653930664, "aqua_rat_41875": 0.7143924832344055, "aqua_rat_87729": 0.714973509311676, "math_test_counting_and_probability_513": 0.7164923548698425, "aqua_rat_48212": 0.7171805500984192, "aqua_rat_38718": 0.7175267934799194, "math_train_counting_and_probability_5119": 0.7178941965103149, "TheoremQA_jianyu_xu/Ramsey_6.json": 0.7179096341133118, "math_train_counting_and_probability_5032": 0.7193182706832886, "camel_37649": 0.7205301523208618, "math_train_counting_and_probability_1110": 0.7212445735931396, "math_train_prealgebra_701": 0.7224502563476562, "aqua_rat_34677": 0.7238401174545288, "math_train_counting_and_probability_757": 0.7251208424568176, "aqua_rat_76154": 0.7264311909675598, "aqua_rat_60481": 0.7270848155021667, "math_test_prealgebra_1306": 0.7282916307449341, "aqua_rat_84407": 0.7289047837257385, "math_test_counting_and_probability_686": 0.729040265083313, "aqua_rat_63918": 0.7291474938392639, "math_train_prealgebra_446": 0.7292662858963013, "camel_36542": 0.7327874898910522, "camel_36368": 0.7344472408294678, "aqua_rat_46132": 0.7382912039756775, "math_test_counting_and_probability_763": 0.7390265464782715, "aqua_rat_37692": 0.7392562031745911, "aqua_rat_51040": 0.7392883896827698, "aqua_rat_75954": 0.7469266057014465, "aqua_rat_44859": 0.7512452602386475, "aqua_rat_47964": 0.757736086845398, "aqua_rat_46637": 0.7624731063842773}, "TheoremQA_wenhuchen/determinant1.json": {"camel_14086": 0, "camel_14885": 0, "camel_15643": 0, "camel_14150": 0, "camel_14284": 0, "camel_15540": 0, "camel_14114": 0, "camel_14147": 0, "camel_14134": 0, "camel_15717": 0, "camel_14878": 0, "camel_14053": 0, "camel_15681": 0, "camel_14888": 0, "camel_14091": 0, "camel_14884": 0, "camel_14933": 0, "camel_14126": 0, "camel_15683": 0, "camel_15348": 0, "camel_14046": 0, "camel_14920": 0, "camel_14851": 0, "camel_14919": 0, "camel_14850": 0, "camel_14954": 0, "camel_14894": 0, "camel_14903": 0, "camel_14905": 0, "camel_14145": 0, "camel_14094": 0, "camel_14111": 0, "camel_14040": 0, "camel_14938": 0, "camel_15620": 0, "camel_14949": 0, "camel_14886": 0, "camel_14008": 0, "camel_15530": 0, "camel_14859": 0, "camel_14897": 0, "camel_15522": 0, "camel_15426": 0, "camel_14861": 0, "camel_14836": 0, "camel_14923": 0, "camel_14945": 0, "camel_14928": 0, "camel_14062": 0, "camel_14846": 0, "camel_14811": 0, "camel_14054": 0, "camel_14927": 0, "camel_15623": 0, "camel_14847": 0, "camel_14948": 0, "camel_14043": 0, "camel_14826": 0, "camel_14898": 0, "camel_15624": 0, "camel_14085": 0, "camel_14001": 0, "camel_14102": 0, "camel_14083": 0, "camel_14113": 0, "camel_14944": 0, "camel_14827": 0, "camel_14068": 0, "camel_14802": 0, "camel_14911": 0, "camel_14835": 0, "camel_14152": 0, "camel_14131": 0, "camel_14937": 0, "camel_14105": 0, "camel_14099": 0, "camel_14117": 0, "camel_14935": 0, "camel_14116": 0, "camel_14807": 0, "camel_14112": 0, "camel_14939": 0, "camel_14138": 0, "camel_14932": 0, "camel_15652": 0, "camel_14891": 0, "camel_14682": 0, "camel_14872": 0, "camel_14912": 0, "camel_14914": 0, "camel_14860": 0, "camel_14839": 0, "camel_15590": 0, "camel_14149": 0, "camel_14685": 0, "camel_14883": 0, "camel_14892": 0, "camel_15339": 0, "camel_14874": 0, "camel_14924": 0, "camel_15730": 0, "camel_15617": 0, "camel_15650": 0, "camel_14901": 0, "camel_15583": 0, "camel_14821": 0, "camel_14947": 0, "camel_14943": 0, "camel_14913": 0, "camel_14917": 0, "camel_15547": 0, "camel_14027": 0, "camel_14081": 0, "camel_14039": 0, "camel_14908": 0, "camel_14695": 0, "camel_14837": 0, "camel_14118": 0, "camel_15618": 0, "camel_14863": 0, "camel_14659": 0, "camel_14686": 0, "camel_14660": 0, "camel_14663": 0, "camel_14715": 0, "camel_14141": 0, "camel_14906": 0, "camel_14672": 0, "camel_14697": 0, "camel_15679": 0, "camel_14088": 0, "camel_14130": 0, "camel_14127": 0, "camel_14829": 0, "camel_14955": 0, "camel_14115": 0, "camel_14918": 0, "camel_14146": 0, "camel_14093": 0, "camel_15656": 0, "camel_14084": 0, "camel_14654": 0, "camel_14647": 0, "camel_14644": 0, "camel_14690": 0, "camel_14662": 0, "camel_14703": 0, "camel_14674": 0, "camel_15748": 0, "camel_14889": 0, "camel_15711": 0, "camel_14667": 0, "camel_15676": 0, "camel_14657": 0, "camel_14646": 0, "camel_14642": 0, "camel_14645": 0, "camel_14089": 0, "camel_14153": 0, "camel_15387": 0, "camel_15619": 0, "camel_14123": 0, "camel_14082": 0, "camel_14664": 0, "camel_14144": 0, "camel_14087": 0, "camel_14156": 0, "camel_15360": 0, "camel_14107": 0, "camel_14104": 0, "camel_14103": 0, "camel_14833": 0, "camel_14151": 0, "camel_14143": 0, "camel_14120": 0, "camel_14092": 0, "camel_14109": 0, "camel_14121": 0, "camel_14095": 0, "camel_15655": 0, "camel_14098": 0, "camel_14159": 0, "camel_14717": 0, "camel_14158": 0, "camel_14687": 0, "camel_14136": 0, "camel_14641": 0, "camel_27627": 0.7513511180877686, "camel_27602": 0.7519240975379944, "camel_19761": 0.7539474964141846, "camel_27644": 0.754655122756958, "math_train_precalculus_822": 0.756188154220581, "math_train_precalculus_163": 0.7563750743865967, "TheoremQA_wenhuchen/cramer's_rule1.json": 0.7575605511665344, "camel_27607": 0.7613319158554077, "camel_27628": 0.7677333354949951, "camel_27667": 0.7713639140129089, "camel_27611": 0.7776690721511841, "camel_27639": 0.798784613609314, "TheoremQA_elainewan/math_algebra_2.json": 0.7991558909416199}, "TheoremQA_wenhuchen/trapezoidal_rule2.json": {"camel_7066": 0, "camel_7259": 0, "camel_7224": 0, "TheoremQA_wenhuchen/trapezoidal_rule2.json": 0, "camel_7823": 0, "camel_40280": 0, "camel_7203": 0, "camel_7218": 0, "camel_7264": 0, "camel_7231": 0, "camel_7268": 0, "camel_7216": 0, "camel_7220": 0, "camel_7265": 0, "camel_6257": 0, "camel_7243": 0, "gsm_rft_10603": 0.6913589239120483, "aqua_rat_1977": 0.6915506720542908, "aqua_rat_54674": 0.6915687322616577, "gsm_rft_20209": 0.6917909979820251, "gsm_rft_3001": 0.6917909979820251, "gsm_train_22328": 0.6917909979820251, "gsm_rft_30397": 0.6918331980705261, "aqua_rat_3097": 0.6920274496078491, "gsm_rft_960": 0.6920527815818787, "aqua_rat_21997": 0.6922231316566467, "gsm_rft_33960": 0.6922285556793213, "camel_30888": 0.6923081874847412, "gsm_rft_12758": 0.692423939704895, "gsm_rft_12456": 0.6924469470977783, "gsm_rft_11149": 0.692635715007782, "gsm_train_22437": 0.692635715007782, "gsm_rft_28940": 0.692676842212677, "gsm_train_5416": 0.692676842212677, "gsm_rft_2916": 0.6927462816238403, "gsm_rft_7837": 0.6930410265922546, "aqua_rat_55069": 0.6930464506149292, "gsm_rft_13385": 0.6931545734405518, "gsm_rft_31046": 0.6932021975517273, "gsm_rft_24756": 0.6934254765510559, "gsm_train_29003": 0.6936731934547424, "math_train_prealgebra_208": 0.6936954259872437, "aqua_rat_59822": 0.6937906742095947, "gsm_rft_26992": 0.6938090324401855, "aqua_rat_88394": 0.6938501596450806, "gsm_rft_22799": 0.694001317024231, "gsm_rft_26885": 0.6940255165100098, "gsm_rft_28449": 0.694026529788971, "aqua_rat_15784": 0.6942125558853149, "gsm_rft_25696": 0.6942929625511169, "gsm_rft_17924": 0.6945786476135254, "aqua_rat_45628": 0.6946357488632202, "gsm_rft_2784": 0.6947565674781799, "gsm_rft_368": 0.6947565674781799, "gsm_train_10122": 0.6948164701461792, "gsm_rft_1857": 0.6948827505111694, "gsm_train_18924": 0.6948827505111694, "gsm_train_16223": 0.6950587034225464, "gsm_rft_4841": 0.6950713396072388, "gsm_rft_21867": 0.6950770020484924, "aqua_rat_53577": 0.6951267123222351, "aqua_rat_33076": 0.6952274441719055, "gsm_rft_23175": 0.6952659487724304, "gsm_rft_14077": 0.6952901482582092, "aqua_rat_87387": 0.695343017578125, "gsm_rft_8546": 0.6955177187919617, "aqua_rat_81028": 0.6955380439758301, "aqua_rat_87405": 0.6958683729171753, "gsm_train_33883": 0.6958969235420227, "gsm_train_27703": 0.6959327459335327, "gsm_rft_34505": 0.6960970759391785, "aqua_rat_17035": 0.6961786150932312, "gsm_rft_21502": 0.6961869597434998, "aqua_rat_253": 0.6962555646896362, "gsm_train_9254": 0.6962571144104004, "gsm_rft_22976": 0.6962571144104004, "gsm_rft_25388": 0.6964278817176819, "gsm_rft_28794": 0.6964695453643799, "gsm_rft_20655": 0.696490466594696, "gsm_rft_6053": 0.6966250538825989, "gsm_rft_18326": 0.6968793272972107, "gsm_train_3176": 0.6970162391662598, "gsm_rft_6154": 0.6970579624176025, "gsm_rft_30314": 0.697167158126831, "gsm_train_31076": 0.6971694827079773, "gsm_rft_31676": 0.6973897218704224, "gsm_rft_16567": 0.6974530220031738, "math_test_prealgebra_1108": 0.6981391906738281, "gsm_rft_8066": 0.6981923580169678, "gsm_train_9379": 0.6981923580169678, "gsm_rft_2111": 0.698239803314209, "aqua_rat_45482": 0.6984054446220398, "gsm_train_34670": 0.698413610458374, "gsm_train_22804": 0.6984944939613342, "gsm_rft_6680": 0.6989003419876099, "gsm_rft_29104": 0.6989558339118958, "gsm_rft_27782": 0.6990470886230469, "gsm_rft_33995": 0.699241578578949, "gsm_rft_14259": 0.6992496252059937, "aqua_rat_23008": 0.6993153691291809, "aqua_rat_28315": 0.6993270516395569, "aqua_rat_5634": 0.6994205713272095, "gsm_rft_5315": 0.7002376317977905, "gsm_rft_24748": 0.7003649473190308, "gsm_rft_11366": 0.7003883719444275, "gsm_rft_19111": 0.7004395723342896, "camel_39190": 0.7008799314498901, "gsm_rft_837": 0.7011898756027222, "gsm_rft_17910": 0.7012806534767151, "gsm_train_28924": 0.701368510723114, "TheoremQA_wenhuchen/trapezoidal_rule3.json": 0.7015267610549927, "aqua_rat_31829": 0.701616108417511, "camel_5287": 0.7016804814338684, "gsm_rft_20157": 0.7017234563827515, "gsm_rft_17313": 0.7017946243286133, "gsm_rft_22391": 0.7018408179283142, "gsm_train_16316": 0.7019098997116089, "gsm_rft_18087": 0.7019098997116089, "gsm_rft_11838": 0.7022727727890015, "gsm_rft_11840": 0.7028104662895203, "gsm_train_25869": 0.7031026482582092, "gsm_rft_28196": 0.7031026482582092, "gsm_rft_3747": 0.7031026482582092, "gsm_rft_14096": 0.7033362984657288, "gsm_rft_13994": 0.7033376693725586, "gsm_rft_2359": 0.7033717036247253, "gsm_train_11033": 0.7034881711006165, "aqua_rat_47230": 0.7035329937934875, "gsm_train_15590": 0.7036179900169373, "gsm_rft_17364": 0.7036179900169373, "gsm_rft_15742": 0.7036179900169373, "gsm_rft_16142": 0.7037217617034912, "gsm_rft_11277": 0.7038524150848389, "gsm_rft_11074": 0.704103410243988, "gsm_train_9402": 0.704103410243988, "gsm_rft_29042": 0.7045116424560547, "aqua_rat_61580": 0.7046804428100586, "aqua_rat_43895": 0.7047975063323975, "aqua_rat_43715": 0.7052401900291443, "aqua_rat_22056": 0.7056207060813904, "gsm_rft_2329": 0.7062399983406067, "gsm_rft_2105": 0.7065072059631348, "gsm_train_23574": 0.7068751454353333, "gsm_rft_24307": 0.7068751454353333, "gsm_rft_7754": 0.7068751454353333, "gsm_rft_26539": 0.7069499492645264, "gsm_rft_5163": 0.7069776654243469, "gsm_train_21508": 0.7070024609565735, "gsm_rft_30730": 0.7072305083274841, "gsm_rft_14014": 0.7072519659996033, "aqua_rat_18095": 0.7072532176971436, "gsm_rft_32392": 0.7078840136528015, "gsm_train_31894": 0.7079386115074158, "gsm_rft_5297": 0.7083407640457153, "gsm_rft_28321": 0.7089223861694336, "gsm_rft_25418": 0.7089567184448242, "gsm_rft_21096": 0.7091019153594971, "gsm_rft_27927": 0.7093489766120911, "gsm_rft_20393": 0.7094756364822388, "gsm_rft_6536": 0.7094756364822388, "gsm_train_24556": 0.7094776630401611, "gsm_rft_11392": 0.709520697593689, "gsm_train_23531": 0.7104167342185974, "gsm_rft_33390": 0.7104727625846863, "gsm_rft_30904": 0.7105081677436829, "gsm_train_4350": 0.7105815410614014, "gsm_rft_20964": 0.7105838060379028, "gsm_rft_32158": 0.7108001708984375, "gsm_rft_8436": 0.7109298706054688, "gsm_rft_8810": 0.7109298706054688, "gsm_train_18870": 0.7110319137573242, "gsm_rft_1283": 0.7110319137573242, "gsm_rft_3430": 0.7113249897956848, "gsm_rft_29601": 0.7115813493728638, "gsm_rft_13043": 0.7115813493728638, "gsm_rft_11031": 0.7116432785987854, "gsm_rft_28906": 0.7122716307640076, "gsm_train_35065": 0.7123442888259888, "gsm_rft_10281": 0.7132318615913391, "gsm_train_17819": 0.7139045596122742, "gsm_rft_17551": 0.7139045596122742, "gsm_train_35547": 0.7140471935272217, "gsm_rft_9807": 0.7140471935272217, "gsm_rft_9344": 0.7144193053245544, "gsm_rft_2452": 0.7144848108291626, "gsm_rft_1103": 0.7172306776046753, "gsm_train_8683": 0.7172306776046753, "gsm_train_18047": 0.7210690975189209, "gsm_rft_21346": 0.7212418913841248, "gsm_rft_459": 0.7212418913841248, "gsm_rft_20099": 0.7213411331176758, "gsm_rft_7352": 0.7218212485313416, "gsm_train_32872": 0.7218390703201294, "gsm_rft_29693": 0.7219789028167725, "gsm_train_19303": 0.7224999666213989, "gsm_rft_2358": 0.7255483865737915, "gsm_train_1555": 0.7258932590484619, "gsm_rft_13368": 0.7265573740005493, "gsm_rft_4710": 0.7280629873275757, "gsm_rft_27772": 0.7348272800445557}, "TheoremQA_xinyi/huffman_code_1.json": {"TheoremQA_xinyi/huffman_code_1.json": 0, "camel_26757": 0.6420561075210571, "aqua_rat_16538": 0.6420812010765076, "aqua_rat_87229": 0.6422623991966248, "camel_26545": 0.6423073410987854, "aqua_rat_37342": 0.6428853869438171, "camel_37112": 0.6428983807563782, "aqua_rat_64829": 0.642961859703064, "math_train_counting_and_probability_5128": 0.6430414915084839, "aqua_rat_14276": 0.643058717250824, "aqua_rat_79806": 0.643079400062561, "camel_27424": 0.643093466758728, "aqua_rat_3845": 0.6433019042015076, "aqua_rat_81964": 0.6433146595954895, "aqua_rat_21599": 0.6433393359184265, "camel_26453": 0.643448531627655, "aqua_rat_13069": 0.6434840559959412, "math_train_intermediate_algebra_1319": 0.6434886455535889, "aqua_rat_43377": 0.6435353755950928, "aqua_rat_13873": 0.6436800360679626, "aqua_rat_77604": 0.6438461542129517, "aqua_rat_47432": 0.6438978314399719, "camel_26470": 0.6440418362617493, "aqua_rat_20808": 0.6440813541412354, "camel_13785": 0.644128143787384, "aqua_rat_60260": 0.6441530585289001, "camel_26500": 0.6441752314567566, "aqua_rat_19137": 0.64422607421875, "camel_22040": 0.6443364024162292, "aqua_rat_26258": 0.6445157527923584, "aqua_rat_77026": 0.6445187330245972, "math_test_counting_and_probability_855": 0.6445297002792358, "aqua_rat_38034": 0.6445386409759521, "aqua_rat_34195": 0.6446593999862671, "aqua_rat_81482": 0.6446885466575623, "aqua_rat_68315": 0.6449124813079834, "camel_27970": 0.6451176404953003, "aqua_rat_23848": 0.6451416015625, "aqua_rat_88152": 0.6451559066772461, "aqua_rat_28998": 0.6451777815818787, "aqua_rat_63641": 0.6452159881591797, "aqua_rat_53574": 0.6454358696937561, "camel_37479": 0.6455917954444885, "aqua_rat_65849": 0.6455997228622437, "camel_37496": 0.6456026434898376, "aqua_rat_9255": 0.6457404494285583, "aqua_rat_45907": 0.6459758281707764, "aqua_rat_63338": 0.6462147235870361, "aqua_rat_42479": 0.6463303565979004, "camel_27355": 0.6463747024536133, "camel_27938": 0.6465910077095032, "camel_27961": 0.6466692090034485, "aqua_rat_71883": 0.6467634439468384, "aqua_rat_7277": 0.6469751000404358, "camel_13823": 0.6472147703170776, "math_train_counting_and_probability_941": 0.6472210884094238, "camel_37489": 0.6472597718238831, "aqua_rat_50286": 0.6473192572593689, "camel_26427": 0.6473603248596191, "camel_21934": 0.6476531624794006, "TheoremQA_xinyi/shannon_lower_bound.json": 0.6477598547935486, "math_train_counting_and_probability_769": 0.6478312611579895, "aqua_rat_43867": 0.6479249000549316, "camel_26460": 0.6479910016059875, "aqua_rat_37569": 0.6480002403259277, "camel_26529": 0.6480954885482788, "camel_27426": 0.6484725475311279, "camel_13808": 0.6486039757728577, "aqua_rat_19653": 0.6487076878547668, "math_test_number_theory_942": 0.6488634943962097, "camel_26469": 0.64911288022995, "camel_37504": 0.649125337600708, "camel_37462": 0.64927077293396, "aqua_rat_16872": 0.6492718458175659, "camel_27982": 0.6495218276977539, "aqua_rat_11482": 0.649592936038971, "aqua_rat_83830": 0.6496198773384094, "aqua_rat_2861": 0.6497928500175476, "aqua_rat_67135": 0.649807870388031, "aqua_rat_78369": 0.6498132348060608, "aqua_rat_70662": 0.6499428153038025, "camel_37523": 0.6500910520553589, "aqua_rat_24779": 0.6501618027687073, "aqua_rat_80459": 0.6504928469657898, "camel_37480": 0.6507018208503723, "camel_27931": 0.6507031917572021, "aqua_rat_54583": 0.6507589221000671, "camel_26557": 0.6508244276046753, "aqua_rat_4581": 0.6508834362030029, "camel_27940": 0.6509439945220947, "TheoremQA_xinyi/rate_distortion_function_2.json": 0.650970995426178, "aqua_rat_23851": 0.6511102914810181, "aqua_rat_80113": 0.6512355208396912, "aqua_rat_51193": 0.6512491703033447, "camel_27326": 0.6512886881828308, "aqua_rat_33448": 0.6513749957084656, "aqua_rat_13370": 0.6515605449676514, "aqua_rat_63386": 0.652075469493866, "aqua_rat_69333": 0.6522234678268433, "aqua_rat_88939": 0.6524724960327148, "aqua_rat_77219": 0.6525348424911499, "aqua_rat_16015": 0.6526415348052979, "camel_13811": 0.6529262661933899, "aqua_rat_71178": 0.6531917452812195, "aqua_rat_83119": 0.6533082127571106, "aqua_rat_34069": 0.65340656042099, "aqua_rat_57498": 0.653485119342804, "aqua_rat_19311": 0.6537994742393494, "aqua_rat_55739": 0.6539983749389648, "aqua_rat_2960": 0.6541593074798584, "camel_13772": 0.6541616916656494, "camel_22043": 0.6542618274688721, "aqua_rat_84935": 0.6543029546737671, "aqua_rat_86949": 0.6545805931091309, "aqua_rat_33959": 0.6546181440353394, "camel_26483": 0.654624342918396, "aqua_rat_74669": 0.6546655297279358, "aqua_rat_47622": 0.6549875140190125, "math_train_counting_and_probability_5042": 0.655086100101471, "TheoremQA_xinyi/huffman_code_3.json": 0.6551487445831299, "aqua_rat_77787": 0.655329704284668, "aqua_rat_13318": 0.6555008292198181, "camel_26435": 0.655573308467865, "aqua_rat_64299": 0.6556897759437561, "aqua_rat_17334": 0.6560941934585571, "camel_26534": 0.6564440131187439, "aqua_rat_81541": 0.6566146612167358, "aqua_rat_40310": 0.6566442251205444, "aqua_rat_57783": 0.6575102806091309, "TheoremQA_mingyin/cantor-set1.json": 0.6577334403991699, "aqua_rat_69971": 0.6577587723731995, "camel_13805": 0.6581214070320129, "camel_22000": 0.6581308245658875, "aqua_rat_21454": 0.6582136750221252, "aqua_rat_30271": 0.6582428216934204, "aqua_rat_53465": 0.6585204601287842, "camel_37459": 0.6593055725097656, "aqua_rat_52711": 0.6594403982162476, "camel_31199": 0.6594864130020142, "camel_22060": 0.6596314907073975, "aqua_rat_53686": 0.6596876978874207, "camel_37469": 0.6597253084182739, "camel_13791": 0.6597422957420349, "camel_13764": 0.6598309874534607, "aqua_rat_19620": 0.6598643064498901, "aqua_rat_12172": 0.6598918437957764, "camel_26518": 0.6600911617279053, "aqua_rat_60244": 0.6604006886482239, "camel_26363": 0.6608969569206238, "aqua_rat_48337": 0.6609789133071899, "aqua_rat_79033": 0.6610055565834045, "aqua_rat_57240": 0.6613656878471375, "aqua_rat_78639": 0.6621136665344238, "camel_37455": 0.6628973484039307, "aqua_rat_87221": 0.663530707359314, "aqua_rat_3522": 0.6636026501655579, "camel_37464": 0.6637938618659973, "camel_37521": 0.6638186573982239, "camel_37475": 0.664776623249054, "camel_37513": 0.6649208664894104, "camel_26540": 0.6655753254890442, "aqua_rat_61109": 0.6671473383903503, "aqua_rat_35612": 0.6677854061126709, "aqua_rat_23250": 0.6678853034973145, "camel_37478": 0.6680966019630432, "aqua_rat_12000": 0.6688668727874756, "aqua_rat_36194": 0.6692425012588501, "aqua_rat_15319": 0.6692515015602112, "aqua_rat_17743": 0.6698831915855408, "aqua_rat_15961": 0.6717000603675842, "camel_37449": 0.6743095517158508, "camel_37465": 0.6748292446136475, "camel_26421": 0.6769229173660278, "camel_26791": 0.6776329278945923, "math_train_number_theory_492": 0.6780112385749817, "camel_37491": 0.6781870722770691, "aqua_rat_31336": 0.678835391998291, "aqua_rat_5625": 0.6798391342163086, "camel_37553": 0.6819064617156982, "math_train_counting_and_probability_428": 0.6822636723518372, "aqua_rat_73229": 0.6833863258361816, "camel_37494": 0.6835652589797974, "aqua_rat_1953": 0.6857506036758423, "TheoremQA_maxku/ipnetwork13-hammingdist.json": 0.6863969564437866, "aqua_rat_10179": 0.6863990426063538, "aqua_rat_72814": 0.6875288486480713, "aqua_rat_60981": 0.6878567337989807, "aqua_rat_9869": 0.6893116235733032, "TheoremQA_maxku/ipnetwork14-hammingdist.json": 0.6910282969474792, "camel_37493": 0.6911818981170654, "aqua_rat_85697": 0.6913372874259949, "aqua_rat_87185": 0.691647469997406, "camel_13838": 0.6922003626823425, "aqua_rat_1879": 0.6953190565109253, "aqua_rat_108": 0.6994602680206299, "aqua_rat_73449": 0.7089536190032959, "camel_37500": 0.7210776209831238, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.7276609539985657, "TheoremQA_xinyi/huffman_code_2.json": 0.7580443024635315, "TheoremQA_xinyi/kraft_inequality.json": 0.7674875259399414}, "TheoremQA_wenhuchen/ODE3.json": {"camel_16617": 0, "camel_7509": 0, "camel_16262": 0, "camel_16282": 0, "camel_16257": 0, "camel_7456": 0, "camel_16263": 0, "camel_16245": 0, "camel_16253": 0, "camel_7474": 0, "camel_7442": 0, "camel_16314": 0, "camel_16280": 0, "camel_16317": 0, "camel_7455": 0, "camel_7467": 0, "camel_7492": 0, "camel_7487": 0, "camel_16627": 0, "camel_7449": 0, "camel_16583": 0, "camel_16254": 0, "camel_7503": 0, "camel_16283": 0, "camel_7518": 0, "camel_7971": 0, "camel_7486": 0, "camel_7510": 0, "camel_16316": 0, "camel_16626": 0, "camel_7505": 0, "camel_16251": 0, "camel_16272": 0, "camel_7445": 0, "camel_17406": 0, "camel_16318": 0, "camel_7506": 0, "camel_16308": 0, "camel_16271": 0, "camel_7466": 0, "camel_16310": 0, "camel_7472": 0, "camel_16598": 0, "camel_7502": 0, "camel_16300": 0, "camel_16588": 0, "camel_16291": 0, "camel_6594": 0, "camel_7481": 0, "camel_16240": 0, "camel_16241": 0, "camel_16267": 0, "camel_7517": 0, "camel_16273": 0, "camel_16264": 0, "camel_16243": 0, "camel_16268": 0, "camel_17422": 0, "camel_7477": 0, "camel_16307": 0, "camel_16296": 0, "camel_16301": 0, "camel_16256": 0, "camel_16294": 0, "camel_7441": 0, "camel_16250": 0, "camel_16290": 0, "camel_7950": 0, "camel_17389": 0, "camel_7504": 0, "camel_7497": 0, "camel_16279": 0, "camel_7457": 0, "camel_16289": 0, "camel_17436": 0, "camel_7482": 0, "camel_7479": 0, "camel_7443": 0, "camel_7513": 0, "camel_16242": 0, "camel_7447": 0, "camel_16311": 0, "camel_16284": 0, "camel_7516": 0, "camel_7450": 0, "camel_16258": 0, "camel_16298": 0, "camel_29936": 0.7708345055580139, "camel_5284": 0.7709245085716248, "camel_28858": 0.7711020112037659, "camel_45156": 0.7713236212730408, "camel_28313": 0.7715466022491455, "camel_28909": 0.7716131806373596, "camel_28826": 0.771888256072998, "camel_45299": 0.7721878290176392, "camel_29426": 0.772277295589447, "camel_5216": 0.7723590731620789, "camel_5250": 0.7723613381385803, "camel_28537": 0.7724189162254333, "camel_45296": 0.7724874019622803, "camel_29950": 0.7724919319152832, "camel_28140": 0.7730458378791809, "camel_28715": 0.773575484752655, "camel_19715": 0.7735996842384338, "camel_29438": 0.7738724946975708, "camel_45318": 0.7740932106971741, "camel_5129": 0.7741803526878357, "camel_29379": 0.7741847038269043, "camel_5334": 0.7749781608581543, "camel_5057": 0.7750036120414734, "camel_5185": 0.7757622003555298, "camel_28080": 0.7760283946990967, "camel_29467": 0.7761926054954529, "camel_39473": 0.7762642502784729, "camel_5232": 0.7763482332229614, "camel_47347": 0.7764067053794861, "camel_5319": 0.7764536142349243, "camel_28854": 0.7765416502952576, "camel_28853": 0.7766523361206055, "camel_5134": 0.7766885161399841, "camel_5235": 0.7767452597618103, "camel_5358": 0.7771958708763123, "camel_29388": 0.7772594690322876, "TheoremQA_elainewan/math_calculus_3_6.json": 0.7775372266769409, "camel_28814": 0.7775419354438782, "camel_29195": 0.7781538367271423, "camel_28843": 0.7784408330917358, "camel_28869": 0.7785377502441406, "camel_45342": 0.7786042094230652, "camel_5004": 0.7794867157936096, "camel_5043": 0.7797213196754456, "camel_5113": 0.780139684677124, "camel_5188": 0.780217170715332, "camel_5295": 0.7806462645530701, "camel_45191": 0.7813830375671387, "camel_5138": 0.7814640998840332, "camel_5158": 0.7816116809844971, "camel_5189": 0.7816810607910156, "camel_45174": 0.782275378704071, "camel_28845": 0.7824668288230896, "camel_28832": 0.7825801968574524, "camel_28805": 0.7826967239379883, "camel_28878": 0.7830355167388916, "camel_5267": 0.7831695079803467, "camel_28844": 0.7846575975418091, "camel_5227": 0.7849118113517761, "camel_28831": 0.7851297855377197, "camel_47290": 0.7853237390518188, "camel_44680": 0.7855902314186096, "camel_28024": 0.7860137224197388, "camel_45444": 0.7869601249694824, "camel_44694": 0.78754723072052, "camel_28824": 0.7875682711601257, "camel_28794": 0.788054347038269, "camel_5272": 0.7881366014480591, "camel_5011": 0.788245677947998, "camel_28867": 0.7884353399276733, "camel_5125": 0.7884665131568909, "camel_5172": 0.788497269153595, "aqua_rat_74869": 0.7885675430297852, "camel_5198": 0.7885916233062744, "camel_5246": 0.789406418800354, "camel_5153": 0.7901220321655273, "camel_28876": 0.7901483178138733, "camel_28848": 0.7904665470123291, "camel_28862": 0.7909001111984253, "camel_4965": 0.7910937070846558, "aqua_rat_75605": 0.7914859056472778, "camel_5041": 0.7915846109390259, "camel_28813": 0.7918436527252197, "camel_28861": 0.7922390699386597, "camel_5331": 0.7926768064498901, "camel_5055": 0.7931106686592102, "camel_45315": 0.7931427359580994, "camel_28086": 0.7934406399726868, "camel_4986": 0.7935559749603271, "camel_28823": 0.7937097549438477, "camel_5356": 0.7944914102554321, "camel_5114": 0.7947402000427246, "camel_5285": 0.7948536276817322, "camel_5029": 0.7953638434410095, "camel_28851": 0.7956130504608154, "camel_28852": 0.7959538102149963, "camel_28532": 0.7962387204170227, "camel_28860": 0.7971068024635315, "camel_5197": 0.7974624633789062, "camel_5177": 0.7989615201950073, "camel_5008": 0.7990136742591858, "camel_5070": 0.8001493811607361, "camel_5333": 0.8006398677825928, "camel_5165": 0.8025602698326111, "camel_5180": 0.8026893138885498, "camel_5094": 0.8054295182228088, "camel_28137": 0.8081344962120056, "camel_29060": 0.8085614442825317, "camel_5311": 0.8114508986473083, "camel_5092": 0.8159552216529846, "camel_5079": 0.819939911365509, "camel_5117": 0.8273167610168457, "camel_5093": 0.8302305340766907}, "TheoremQA_maxku/ipnetwork4-mac.json": {"aqua_rat_64832": 0.7647157311439514, "math_train_counting_and_probability_555": 0.7647265791893005, "camel_10703": 0.7647322416305542, "camel_11368": 0.7648571133613586, "camel_10620": 0.7648828625679016, "aqua_rat_77539": 0.7648897171020508, "camel_8784": 0.7650541663169861, "camel_11796": 0.7650997638702393, "camel_11870": 0.7651732563972473, "aqua_rat_23058": 0.7653028964996338, "camel_25515": 0.7653206586837769, "camel_11827": 0.7654333710670471, "camel_11909": 0.765461266040802, "camel_11084": 0.7654627561569214, "camel_10628": 0.7655207514762878, "camel_24714": 0.7655859589576721, "camel_37620": 0.7656543850898743, "camel_11062": 0.765687108039856, "aqua_rat_10401": 0.7657195925712585, "aqua_rat_29951": 0.7657535076141357, "camel_11085": 0.7657570242881775, "aqua_rat_3261": 0.7657966613769531, "aqua_rat_3316": 0.7658445835113525, "aqua_rat_7098": 0.7658904194831848, "camel_10913": 0.7660595774650574, "camel_11038": 0.766164243221283, "aqua_rat_39712": 0.7661769390106201, "camel_10568": 0.7662478685379028, "camel_11647": 0.7662621736526489, "camel_11631": 0.7662908434867859, "aqua_rat_48783": 0.7663947939872742, "camel_10327": 0.7664244771003723, "aqua_rat_37538": 0.7664250135421753, "camel_8732": 0.7665449380874634, "aqua_rat_71767": 0.7665833234786987, "aqua_rat_12289": 0.766607403755188, "camel_11883": 0.7667447924613953, "camel_11792": 0.7667833566665649, "aqua_rat_45994": 0.7669250965118408, "aqua_rat_19891": 0.7670288681983948, "camel_11101": 0.7671477198600769, "camel_11889": 0.7673009037971497, "camel_10910": 0.7674198150634766, "camel_11637": 0.7674453854560852, "aqua_rat_42090": 0.7676159739494324, "camel_11853": 0.767687201499939, "aqua_rat_32040": 0.7677850127220154, "camel_10365": 0.7678165435791016, "aqua_rat_59468": 0.7678385376930237, "math_train_counting_and_probability_460": 0.7678508758544922, "camel_11861": 0.7678558826446533, "aqua_rat_18423": 0.7679346799850464, "camel_11944": 0.7679675221443176, "camel_11078": 0.7680551409721375, "camel_24322": 0.7681453824043274, "camel_11900": 0.7682703733444214, "aqua_rat_54546": 0.7682826519012451, "camel_11316": 0.7684354186058044, "aqua_rat_65049": 0.7684900760650635, "camel_11667": 0.7686799764633179, "camel_11376": 0.7689284086227417, "camel_11123": 0.7689377665519714, "aqua_rat_84424": 0.7690641283988953, "aqua_rat_88905": 0.7692971229553223, "aqua_rat_57490": 0.7693941593170166, "camel_11360": 0.7695276141166687, "camel_11898": 0.7696903347969055, "aqua_rat_3021": 0.7697176933288574, "camel_11449": 0.7697470188140869, "aqua_rat_80172": 0.7700279355049133, "camel_11846": 0.7700957655906677, "camel_11660": 0.7701842784881592, "camel_8737": 0.7705839276313782, "camel_11741": 0.7706496715545654, "aqua_rat_9196": 0.770672619342804, "camel_8735": 0.7709895372390747, "aqua_rat_16520": 0.7710484266281128, "aqua_rat_13890": 0.7713138461112976, "aqua_rat_67228": 0.7713229060173035, "camel_10374": 0.7716987729072571, "camel_37666": 0.7717474699020386, "camel_10809": 0.7718127965927124, "aqua_rat_83772": 0.7718315720558167, "camel_11470": 0.7719365358352661, "aqua_rat_61302": 0.7723705768585205, "camel_9485": 0.7724621891975403, "camel_11907": 0.772505521774292, "aqua_rat_79964": 0.7725160717964172, "camel_11128": 0.7727971076965332, "camel_10972": 0.7729189991950989, "aqua_rat_50317": 0.7729946374893188, "aqua_rat_85290": 0.7733569741249084, "camel_11169": 0.7734698057174683, "camel_11150": 0.7738170027732849, "camel_10849": 0.7739148139953613, "camel_10570": 0.7739464044570923, "aqua_rat_68133": 0.7739753127098083, "camel_10812": 0.7739865779876709, "camel_11048": 0.7740331292152405, "camel_11864": 0.774070143699646, "aqua_rat_58360": 0.774092972278595, "camel_11092": 0.774175763130188, "aqua_rat_80380": 0.7744139432907104, "camel_11132": 0.7745013236999512, "aqua_rat_38172": 0.7745875716209412, "aqua_rat_44578": 0.7746942639350891, "camel_11191": 0.7751649022102356, "aqua_rat_43971": 0.7753212451934814, "aqua_rat_22881": 0.7753495573997498, "aqua_rat_65680": 0.7755635976791382, "camel_10874": 0.7757383584976196, "camel_25892": 0.7757708430290222, "aqua_rat_55374": 0.7758533358573914, "aqua_rat_65962": 0.7760391235351562, "aqua_rat_14351": 0.776122510433197, "camel_11548": 0.7761602401733398, "aqua_rat_3208": 0.7764713764190674, "camel_11151": 0.7766973972320557, "camel_25887": 0.7767124176025391, "camel_10872": 0.7768933773040771, "math_train_counting_and_probability_948": 0.776929497718811, "camel_11180": 0.7773362994194031, "camel_11175": 0.7774532437324524, "camel_11138": 0.7775094509124756, "aqua_rat_63581": 0.7777358293533325, "aqua_rat_1783": 0.7777867317199707, "aqua_rat_70748": 0.7779077291488647, "camel_11677": 0.7780967354774475, "aqua_rat_50672": 0.7784163951873779, "camel_25895": 0.7784306406974792, "aqua_rat_38490": 0.7785226702690125, "aqua_rat_44765": 0.7788386344909668, "aqua_rat_50853": 0.7789165377616882, "aqua_rat_34416": 0.7789530754089355, "camel_11467": 0.7792317867279053, "aqua_rat_41204": 0.7792423367500305, "camel_10300": 0.7793624997138977, "camel_11979": 0.7795226573944092, "camel_24442": 0.7799801826477051, "aqua_rat_49213": 0.7801628708839417, "camel_11456": 0.7801675200462341, "aqua_rat_42825": 0.7802557945251465, "camel_10361": 0.7804558873176575, "camel_11903": 0.7806435227394104, "camel_10657": 0.7806722521781921, "camel_10848": 0.7806981801986694, "aqua_rat_61684": 0.780707597732544, "aqua_rat_84514": 0.780735969543457, "camel_11635": 0.7810072898864746, "aqua_rat_14212": 0.7811880707740784, "camel_25447": 0.7813361883163452, "aqua_rat_10224": 0.7814300060272217, "aqua_rat_52712": 0.7817507982254028, "camel_11914": 0.781843900680542, "camel_11942": 0.7819349765777588, "aqua_rat_45977": 0.7820131182670593, "camel_11600": 0.7820224761962891, "camel_11024": 0.7830907702445984, "camel_11076": 0.7836753726005554, "aqua_rat_8224": 0.783768892288208, "aqua_rat_36486": 0.7838624119758606, "camel_11988": 0.7840909361839294, "aqua_rat_37772": 0.7847430109977722, "camel_11719": 0.7848588824272156, "camel_11871": 0.7850314974784851, "camel_11461": 0.7851821780204773, "aqua_rat_62298": 0.7852991223335266, "camel_11874": 0.7862871885299683, "camel_11854": 0.786561906337738, "camel_11159": 0.7873302102088928, "camel_11137": 0.787346601486206, "camel_11133": 0.788038969039917, "camel_9464": 0.789984941482544, "camel_9476": 0.790219783782959, "aqua_rat_38029": 0.7904917001724243, "camel_25891": 0.791297435760498, "camel_11508": 0.791486918926239, "camel_11872": 0.7933745384216309, "camel_11339": 0.7939765453338623, "camel_11167": 0.7963832020759583, "camel_11320": 0.7972053289413452, "camel_37886": 0.7973485589027405, "camel_11064": 0.7979723215103149, "aqua_rat_20632": 0.8011708855628967, "camel_36523": 0.8034634590148926, "aqua_rat_74224": 0.8102361559867859, "aqua_rat_86209": 0.8117491602897644, "aqua_rat_64039": 0.8120341897010803, "camel_11946": 0.8131035566329956, "aqua_rat_88015": 0.8135861754417419, "aqua_rat_6577": 0.8195279240608215, "aqua_rat_87308": 0.82772296667099, "aqua_rat_37698": 0.832040011882782, "aqua_rat_40444": 0.8335105776786804, "aqua_rat_60327": 0.8338859677314758, "aqua_rat_50510": 0.8339834213256836, "aqua_rat_80730": 0.8340217471122742, "aqua_rat_69941": 0.8352454304695129, "aqua_rat_21944": 0.8363236784934998, "aqua_rat_47751": 0.8375689387321472}, "TheoremQA_maxku/graphtheory5-vertexcover.json": {"camel_22197": 0, "camel_23477": 0, "camel_22347": 0, "camel_23426": 0, "camel_23371": 0, "camel_23308": 0, "camel_23146": 0, "camel_22779": 0, "camel_22181": 0, "camel_22375": 0, "camel_22772": 0, "camel_22192": 0, "camel_22788": 0, "camel_22384": 0, "camel_22149": 0, "camel_22145": 0, "camel_21763": 0, "camel_22180": 0, "camel_21833": 0, "camel_23296": 0, "camel_21780": 0, "camel_22782": 0, "camel_22208": 0, "camel_22747": 0, "camel_21784": 0, "camel_22176": 0, "camel_22099": 0, "camel_22794": 0, "camel_22361": 0, "camel_22791": 0, "camel_21133": 0, "camel_23505": 0, "camel_22224": 0, "camel_22187": 0, "camel_22751": 0, "camel_23360": 0, "camel_23395": 0, "camel_22137": 0, "camel_22104": 0, "camel_22116": 0, "camel_21773": 0, "camel_22133": 0, "camel_22101": 0, "camel_22092": 0, "camel_22774": 0, "camel_22091": 0, "camel_23511": 0, "camel_22790": 0, "camel_23512": 0, "camel_22166": 0, "camel_22084": 0, "camel_22363": 0, "camel_22398": 0, "camel_22123": 0, "camel_21116": 0, "camel_22097": 0, "camel_23363": 0, "camel_23463": 0, "camel_22088": 0, "camel_22140": 0, "camel_22080": 0, "camel_22335": 0, "camel_23484": 0, "camel_22119": 0, "camel_22200": 0, "camel_23374": 0, "camel_22376": 0, "camel_23392": 0, "camel_22147": 0, "camel_22089": 0, "camel_22204": 0, "camel_23287": 0, "camel_23435": 0, "camel_22188": 0, "camel_22085": 0, "camel_23438": 0, "camel_22776": 0, "camel_22356": 0, "camel_22087": 0, "camel_22100": 0, "camel_22216": 0, "camel_22789": 0, "camel_22780": 0, "camel_22753": 0, "camel_22771": 0, "camel_22775": 0, "camel_22190": 0, "camel_21795": 0, "camel_22799": 0, "camel_22786": 0, "camel_22792": 0, "camel_22150": 0, "camel_22746": 0, "camel_22377": 0, "camel_22154": 0, "camel_23481": 0, "camel_22756": 0, "camel_22117": 0, "camel_22787": 0, "camel_22766": 0, "camel_22740": 0, "camel_22765": 0, "camel_22106": 0, "camel_22082": 0, "camel_22729": 0, "camel_22762": 0, "camel_22179": 0, "camel_22328": 0, "camel_22763": 0, "camel_22122": 0, "camel_23397": 0, "camel_22193": 0, "camel_22778": 0, "camel_23381": 0, "camel_22108": 0, "camel_22329": 0, "camel_22210": 0, "camel_23367": 0, "camel_23306": 0, "camel_22388": 0, "camel_22761": 0, "camel_23409": 0, "camel_22742": 0, "camel_22129": 0, "camel_22724": 0, "camel_22182": 0, "camel_22127": 0, "camel_23362": 0, "camel_22744": 0, "camel_21782": 0, "camel_22723": 0, "camel_21812": 0, "TheoremQA_maxku/graphtheory5-vertexcover.json": 0, "camel_23442": 0, "camel_23291": 0, "camel_23285": 0, "camel_22735": 0, "camel_22752": 0, "camel_22736": 0, "camel_22754": 0, "camel_22749": 0, "camel_22755": 0, "camel_22738": 0, "camel_22121": 0, "camel_22098": 0, "camel_22113": 0, "camel_22168": 0, "camel_21792": 0, "camel_22223": 0, "camel_23472": 0, "camel_22734": 0, "camel_22731": 0, "camel_22796": 0, "camel_23379": 0, "camel_22726": 0, "camel_22103": 0, "camel_23410": 0, "camel_22768": 0, "camel_22764": 0, "camel_23364": 0, "camel_22218": 0, "camel_22793": 0, "camel_22185": 0, "camel_22739": 0, "camel_22798": 0, "camel_22770": 0, "camel_22745": 0, "camel_22758": 0, "camel_22777": 0, "camel_22760": 0, "camel_22784": 0, "camel_22785": 0, "camel_22795": 0, "camel_22773": 0, "camel_22720": 0, "camel_22767": 0, "camel_22757": 0, "camel_22728": 0, "camel_22769": 0, "camel_22743": 0, "camel_22783": 0, "camel_22737": 0, "camel_22721": 0, "camel_22722": 0, "camel_22727": 0, "camel_22170": 0, "camel_39941": 0.7299019694328308, "camel_39977": 0.7336097359657288, "camel_39938": 0.73457932472229, "camel_39997": 0.7393478751182556, "aqua_rat_70645": 0.7457922697067261, "aqua_rat_44831": 0.7504086494445801, "aqua_rat_28685": 0.7522956728935242, "aqua_rat_54929": 0.7542940974235535, "aqua_rat_76009": 0.7546058893203735, "aqua_rat_83797": 0.7568497657775879, "TheoremQA_maxku/graphtheory4-vertexcover.json": 0.7606732845306396, "TheoremQA_maxku/graphtheory2-vertexcover.json": 0.7668694853782654, "TheoremQA_maxku/graphtheory3-vertexcover.json": 0.7711817622184753, "camel_38526": 0.7914287447929382}, "TheoremQA_xueguangma/dividend_discount_model_5.json": {"TheoremQA_xueguangma/dividend_discount_model_5.json": 0, "gsm_rft_3769": 0.6156967878341675, "camel_45738": 0.615818440914154, "aqua_rat_73323": 0.6158429980278015, "gsm_rft_3097": 0.6158486008644104, "gsm_rft_23131": 0.6158741116523743, "gsm_train_4730": 0.6159395575523376, "gsm_rft_31372": 0.6159395575523376, "gsm_train_14821": 0.6159729957580566, "aqua_rat_63119": 0.6159771084785461, "aqua_rat_13471": 0.6161551475524902, "gsm_rft_13755": 0.6162280440330505, "aqua_rat_15749": 0.6162407994270325, "aqua_rat_52197": 0.6162565350532532, "aqua_rat_940": 0.6162832379341125, "gsm_rft_5012": 0.6162987947463989, "aqua_rat_18140": 0.6163778901100159, "aqua_rat_26339": 0.6164145469665527, "aqua_rat_15639": 0.6164832711219788, "aqua_rat_18473": 0.6165180206298828, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.6165993809700012, "gsm_train_32842": 0.6166097521781921, "gsm_rft_1922": 0.6166097521781921, "gsm_rft_20277": 0.6166202425956726, "gsm_rft_6105": 0.6166772246360779, "gsm_train_34827": 0.6167637705802917, "gsm_rft_16945": 0.6167703866958618, "gsm_rft_13721": 0.6168012619018555, "gsm_rft_28380": 0.6169039011001587, "gsm_train_10049": 0.6169828176498413, "gsm_rft_14506": 0.6169956922531128, "gsm_rft_31049": 0.6170371770858765, "gsm_rft_24493": 0.6170749664306641, "gsm_train_27582": 0.6170749664306641, "gsm_train_16035": 0.6171901226043701, "aqua_rat_7378": 0.6171906590461731, "aqua_rat_29921": 0.6171948909759521, "gsm_rft_24615": 0.6172085404396057, "aqua_rat_55929": 0.61722332239151, "TheoremQA_xueguangma/present_value_1.json": 0.6172346472740173, "aqua_rat_75451": 0.6173467040061951, "gsm_train_25772": 0.6173478364944458, "aqua_rat_506": 0.6174196600914001, "aqua_rat_10227": 0.617461085319519, "aqua_rat_86309": 0.6174907684326172, "aqua_rat_85762": 0.6175647974014282, "aqua_rat_32321": 0.6176109313964844, "gsm_rft_2192": 0.6177586913108826, "gsm_rft_13078": 0.6177586913108826, "gsm_rft_34606": 0.6177879571914673, "aqua_rat_4236": 0.6178712248802185, "gsm_rft_32917": 0.6178794503211975, "gsm_rft_31412": 0.6179386377334595, "gsm_train_11080": 0.6181272268295288, "aqua_rat_20382": 0.618240237236023, "TheoremQA_xueguangma/earnings_multiplier_3.json": 0.6183980703353882, "gsm_rft_34457": 0.6184738278388977, "gsm_rft_14010": 0.6185593008995056, "aqua_rat_44615": 0.6186036467552185, "gsm_rft_15208": 0.6186437010765076, "gsm_rft_30764": 0.6187039613723755, "gsm_rft_29906": 0.6187525391578674, "aqua_rat_59298": 0.6187574863433838, "gsm_rft_33029": 0.6187962889671326, "aqua_rat_55450": 0.618798553943634, "gsm_train_14735": 0.618800163269043, "aqua_rat_16849": 0.6188441514968872, "gsm_rft_4086": 0.618881106376648, "gsm_rft_1289": 0.6189077496528625, "gsm_rft_29637": 0.6190782785415649, "gsm_rft_35442": 0.619087815284729, "gsm_rft_21062": 0.6191345453262329, "camel_25615": 0.6192599534988403, "gsm_rft_31720": 0.6193459033966064, "camel_37746": 0.61937415599823, "gsm_rft_13885": 0.6196314096450806, "gsm_train_26362": 0.6196943521499634, "aqua_rat_24347": 0.6197628974914551, "aqua_rat_46842": 0.6199105978012085, "gsm_train_17995": 0.6200686097145081, "gsm_rft_6083": 0.6200954914093018, "gsm_rft_25112": 0.6201609969139099, "gsm_rft_15258": 0.6201933026313782, "gsm_train_29580": 0.6202666759490967, "camel_25344": 0.6204157471656799, "gsm_rft_32819": 0.6204399466514587, "gsm_rft_3890": 0.6204845905303955, "gsm_rft_13670": 0.6205794811248779, "aqua_rat_80962": 0.6206293702125549, "aqua_rat_22632": 0.6206864714622498, "aqua_rat_67841": 0.6207253336906433, "aqua_rat_19454": 0.6207887530326843, "aqua_rat_88960": 0.6208948493003845, "gsm_rft_29683": 0.621155321598053, "gsm_train_18102": 0.6216193437576294, "gsm_rft_27170": 0.6216533780097961, "gsm_rft_5694": 0.6216533780097961, "gsm_train_1402": 0.6216533780097961, "gsm_rft_14167": 0.6217186450958252, "gsm_rft_8874": 0.621830940246582, "TheoremQA_xueguangma/spot_rate.json": 0.6220733523368835, "aqua_rat_56784": 0.6223675012588501, "aqua_rat_13817": 0.6227655410766602, "gsm_rft_32019": 0.6229162812232971, "math_test_algebra_1611": 0.6229308247566223, "aqua_rat_17685": 0.6230539083480835, "gsm_rft_876": 0.6235165596008301, "gsm_rft_749": 0.6235165596008301, "gsm_train_6548": 0.6235165596008301, "TheoremQA_xueguangma/forward_price_2.json": 0.6235388517379761, "aqua_rat_27039": 0.6235876083374023, "gsm_rft_34694": 0.6238278150558472, "aqua_rat_9512": 0.6239861249923706, "aqua_rat_56922": 0.6240432858467102, "gsm_rft_10252": 0.6242859959602356, "aqua_rat_46293": 0.6243211030960083, "aqua_rat_19740": 0.6243603229522705, "aqua_rat_67283": 0.6244493126869202, "aqua_rat_1364": 0.6246903538703918, "gsm_train_14713": 0.6248210668563843, "gsm_rft_27770": 0.6248258948326111, "aqua_rat_30650": 0.6250476241111755, "gsm_rft_22073": 0.6255934834480286, "gsm_rft_252": 0.6257234811782837, "aqua_rat_71288": 0.6257336139678955, "aqua_rat_57433": 0.6258754730224609, "gsm_rft_30093": 0.6259747743606567, "gsm_rft_29507": 0.6263657808303833, "gsm_train_2036": 0.6263657808303833, "gsm_rft_31139": 0.6263657808303833, "aqua_rat_87442": 0.6266193985939026, "aqua_rat_52815": 0.6266694664955139, "aqua_rat_23836": 0.6267140507698059, "aqua_rat_26820": 0.6274779438972473, "camel_37747": 0.6276270151138306, "gsm_rft_29226": 0.6277093291282654, "gsm_rft_23795": 0.6278579235076904, "aqua_rat_13033": 0.6280504465103149, "aqua_rat_64922": 0.628105878829956, "gsm_rft_5809": 0.6282725930213928, "aqua_rat_16258": 0.628288984298706, "aqua_rat_15950": 0.6284555792808533, "gsm_rft_8880": 0.6285508275032043, "gsm_rft_17816": 0.6289966106414795, "aqua_rat_87246": 0.6301931142807007, "gsm_train_9850": 0.6303421854972839, "gsm_rft_16238": 0.6303421854972839, "gsm_rft_2115": 0.6307450532913208, "aqua_rat_255": 0.6314327120780945, "gsm_train_374": 0.631666898727417, "gsm_rft_20347": 0.631666898727417, "gsm_rft_11850": 0.6319046020507812, "aqua_rat_67794": 0.6320098042488098, "aqua_rat_49749": 0.6326902508735657, "gsm_rft_32408": 0.6327396035194397, "aqua_rat_59668": 0.6351012587547302, "aqua_rat_53421": 0.6358052492141724, "aqua_rat_72933": 0.6361308693885803, "gsm_rft_3720": 0.6364273428916931, "aqua_rat_83234": 0.6367955207824707, "aqua_rat_42852": 0.6369354724884033, "aqua_rat_64664": 0.6372142434120178, "aqua_rat_37382": 0.6378968358039856, "aqua_rat_36913": 0.6379912495613098, "gsm_rft_31378": 0.6382893919944763, "gsm_rft_1668": 0.6386014819145203, "gsm_train_16212": 0.6386014819145203, "gsm_rft_26543": 0.6386986374855042, "aqua_rat_70856": 0.639188289642334, "aqua_rat_66298": 0.639601469039917, "aqua_rat_79547": 0.639678418636322, "aqua_rat_14738": 0.6418598890304565, "aqua_rat_26449": 0.6435608267784119, "math_test_algebra_1043": 0.6441441178321838, "aqua_rat_87884": 0.644929826259613, "aqua_rat_9965": 0.6459394693374634, "aqua_rat_70690": 0.6463748812675476, "gsm_rft_8605": 0.6466790437698364, "gsm_train_18514": 0.6469031572341919, "aqua_rat_89004": 0.6487608551979065, "gsm_rft_24497": 0.6488234996795654, "aqua_rat_64914": 0.6489046812057495, "gsm_rft_24082": 0.6502811312675476, "aqua_rat_47176": 0.6510525941848755, "aqua_rat_23319": 0.6514442563056946, "aqua_rat_48285": 0.6515718102455139, "aqua_rat_22679": 0.6517768502235413, "aqua_rat_27035": 0.6549228429794312, "aqua_rat_12799": 0.655328094959259, "aqua_rat_77486": 0.6575334072113037, "aqua_rat_33283": 0.6580277681350708, "aqua_rat_88687": 0.6623913645744324, "aqua_rat_52474": 0.6646061539649963, "aqua_rat_8292": 0.6647037863731384, "aqua_rat_24626": 0.6656796932220459, "aqua_rat_57386": 0.6677680611610413, "aqua_rat_81348": 0.6708528399467468, "TheoremQA_xueguangma/dividend_discount_model_1.json": 0.7541359066963196, "TheoremQA_xueguangma/dividend_discount_model_2.json": 0.7865731120109558, "TheoremQA_xueguangma/dividend_discount_model_4.json": 0.8510531187057495}, "TheoremQA_maxku/ipnetwork5-mac.json": {"TheoremQA_maxku/ipnetwork5-mac.json": 0, "aqua_rat_55755": 0.5646347999572754, "gsm_rft_14650": 0.5646556615829468, "gsm_train_28511": 0.5646663308143616, "camel_37454": 0.5648384690284729, "gsm_rft_20273": 0.5648816227912903, "gsm_rft_21310": 0.5648816227912903, "camel_39510": 0.5649024248123169, "camel_26485": 0.564917802810669, "gsm_rft_3619": 0.5649311542510986, "camel_21857": 0.5652391910552979, "gsm_rft_7978": 0.5652619004249573, "gsm_rft_1020": 0.5652619004249573, "gsm_rft_1309": 0.5652782320976257, "gsm_rft_16951": 0.5652782320976257, "gsm_train_1372": 0.5652782320976257, "gsm_train_26217": 0.5653573274612427, "aqua_rat_55730": 0.5654172897338867, "aqua_rat_76531": 0.5654251575469971, "camel_38551": 0.5655482411384583, "gsm_train_32344": 0.5655636191368103, "gsm_rft_10256": 0.565605103969574, "gsm_rft_12469": 0.565605103969574, "aqua_rat_22015": 0.565637469291687, "camel_22521": 0.5656706094741821, "gsm_rft_7449": 0.5656850934028625, "aqua_rat_6431": 0.5656980276107788, "aqua_rat_34688": 0.5658262968063354, "aqua_rat_40634": 0.5662946701049805, "aqua_rat_83815": 0.5666166543960571, "aqua_rat_65849": 0.5666520595550537, "aqua_rat_2322": 0.5666741132736206, "gsm_rft_30989": 0.5668436884880066, "gsm_train_20496": 0.5668436884880066, "gsm_rft_1963": 0.5668604969978333, "aqua_rat_683": 0.5669630765914917, "aqua_rat_22130": 0.5671921372413635, "camel_39647": 0.5672202110290527, "gsm_rft_33997": 0.5672543048858643, "gsm_rft_23590": 0.5672557950019836, "gsm_rft_2378": 0.5672569870948792, "gsm_rft_23684": 0.5672569870948792, "aqua_rat_6162": 0.5673444867134094, "camel_39673": 0.5673859119415283, "aqua_rat_77909": 0.5674014091491699, "gsm_train_6694": 0.5674037933349609, "aqua_rat_76589": 0.5674279928207397, "gsm_rft_35561": 0.567459762096405, "camel_36470": 0.5674776434898376, "aqua_rat_41340": 0.567615807056427, "gsm_rft_5063": 0.5676352381706238, "camel_26554": 0.5676411390304565, "aqua_rat_75568": 0.5678186416625977, "aqua_rat_53438": 0.5680485963821411, "camel_21911": 0.5682309865951538, "gsm_rft_10321": 0.5684436559677124, "math_train_number_theory_492": 0.5684513449668884, "aqua_rat_49095": 0.5687536001205444, "math_test_prealgebra_1863": 0.5687784552574158, "camel_26555": 0.5689438581466675, "gsm_train_17757": 0.5689499378204346, "gsm_rft_24388": 0.5689680576324463, "gsm_train_30183": 0.5690528154373169, "gsm_rft_27157": 0.5690612196922302, "gsm_rft_24214": 0.5690637826919556, "gsm_rft_28461": 0.5690637826919556, "gsm_train_17444": 0.5690637826919556, "gsm_rft_33965": 0.5691308379173279, "gsm_rft_8738": 0.5691544413566589, "aqua_rat_9358": 0.5692338943481445, "camel_13767": 0.5692368745803833, "aqua_rat_20808": 0.5692776441574097, "aqua_rat_2828": 0.5694043636322021, "aqua_rat_27932": 0.5694191455841064, "camel_21893": 0.56949383020401, "gsm_rft_22096": 0.5696224570274353, "gsm_rft_27931": 0.5696224570274353, "camel_37595": 0.5697219967842102, "gsm_rft_11215": 0.5699424743652344, "aqua_rat_64829": 0.5700346827507019, "gsm_rft_34745": 0.5701372027397156, "camel_37507": 0.5703383684158325, "aqua_rat_6709": 0.5703677535057068, "aqua_rat_9793": 0.5705471634864807, "aqua_rat_40004": 0.5705505013465881, "gsm_rft_8374": 0.5705870389938354, "camel_26565": 0.5710585713386536, "aqua_rat_21925": 0.5711112022399902, "aqua_rat_16872": 0.5712160468101501, "gsm_rft_34523": 0.5713886022567749, "gsm_rft_7226": 0.5715003609657288, "aqua_rat_65264": 0.5715358257293701, "aqua_rat_53574": 0.571978747844696, "aqua_rat_54520": 0.5721032023429871, "gsm_rft_17336": 0.5721948742866516, "gsm_rft_20390": 0.5727587342262268, "gsm_rft_6098": 0.5728102326393127, "gsm_rft_25236": 0.5728189945220947, "gsm_train_33933": 0.5728189945220947, "gsm_rft_5069": 0.5728811621665955, "aqua_rat_49292": 0.5729184746742249, "gsm_train_15441": 0.5731191635131836, "camel_26460": 0.5731319785118103, "aqua_rat_3469": 0.573184609413147, "camel_22490": 0.5732412338256836, "gsm_rft_23745": 0.5732699036598206, "camel_26538": 0.5734007358551025, "aqua_rat_3331": 0.5734227895736694, "camel_26385": 0.5734377503395081, "gsm_rft_15660": 0.5734902620315552, "gsm_train_21959": 0.5734902620315552, "camel_22548": 0.5735123753547668, "camel_13792": 0.5736212730407715, "gsm_rft_12105": 0.5736290812492371, "gsm_rft_9514": 0.5736314058303833, "TheoremQA_xinyi/kraft_inequality.json": 0.5741097331047058, "gsm_rft_11073": 0.5744662284851074, "camel_27920": 0.5745115280151367, "gsm_rft_21828": 0.574539065361023, "camel_39614": 0.5751913189888, "camel_13805": 0.5755206346511841, "gsm_rft_33571": 0.5755413770675659, "camel_21909": 0.5756522417068481, "gsm_rft_9023": 0.5758665204048157, "camel_39494": 0.5761933326721191, "gsm_train_4199": 0.5767610669136047, "gsm_rft_229": 0.5767610669136047, "gsm_rft_9272": 0.5767610669136047, "gsm_rft_11046": 0.5772168636322021, "gsm_rft_8122": 0.5772168636322021, "gsm_train_13336": 0.5774548649787903, "camel_26547": 0.5777405500411987, "math_test_prealgebra_2073": 0.5779284834861755, "gsm_rft_9162": 0.5782364010810852, "camel_26506": 0.5788464546203613, "gsm_rft_13859": 0.5788773894309998, "camel_26363": 0.5793073177337646, "camel_39662": 0.5796494483947754, "camel_21835": 0.5800477862358093, "aqua_rat_78286": 0.5800560712814331, "aqua_rat_11272": 0.5809638500213623, "camel_26392": 0.581287145614624, "camel_26497": 0.5818532109260559, "gsm_rft_19302": 0.5821598768234253, "aqua_rat_65718": 0.582240104675293, "gsm_rft_28181": 0.5825312733650208, "gsm_rft_20159": 0.5826132893562317, "gsm_rft_4746": 0.5826380252838135, "camel_13826": 0.5826447606086731, "camel_13777": 0.5827673077583313, "aqua_rat_21971": 0.583881676197052, "camel_13773": 0.5838971734046936, "gsm_rft_2717": 0.5840088725090027, "camel_36295": 0.5840281248092651, "camel_26322": 0.5843219757080078, "aqua_rat_9712": 0.5848375558853149, "aqua_rat_30892": 0.5853811502456665, "aqua_rat_73185": 0.5860838294029236, "gsm_rft_17389": 0.5866034030914307, "gsm_rft_20353": 0.5872754454612732, "gsm_rft_12027": 0.5877543687820435, "aqua_rat_10496": 0.5880836248397827, "gsm_rft_27102": 0.5882769823074341, "gsm_train_5555": 0.5882769823074341, "gsm_rft_32533": 0.5883318185806274, "gsm_rft_35293": 0.5884520411491394, "camel_26483": 0.5888713598251343, "camel_36765": 0.58930903673172, "camel_22539": 0.5904569029808044, "aqua_rat_19908": 0.5912865996360779, "camel_45819": 0.5913119912147522, "aqua_rat_53867": 0.5915091633796692, "gsm_rft_21298": 0.5929486155509949, "gsm_train_20944": 0.5929486155509949, "gsm_rft_11471": 0.5930983424186707, "math_train_counting_and_probability_708": 0.5937722325325012, "gsm_rft_33863": 0.594128429889679, "aqua_rat_60195": 0.5946689248085022, "gsm_rft_25272": 0.5948402881622314, "gsm_rft_18202": 0.5952205657958984, "gsm_rft_3729": 0.5965033769607544, "gsm_train_19829": 0.5967326760292053, "aqua_rat_48": 0.5986472368240356, "aqua_rat_43759": 0.6019303202629089, "gsm_rft_33753": 0.602145254611969, "camel_24344": 0.6033721566200256, "camel_39395": 0.604964554309845, "aqua_rat_85903": 0.6106579303741455, "camel_26526": 0.6108177304267883, "aqua_rat_87402": 0.6114268898963928, "aqua_rat_52087": 0.6127833724021912, "aqua_rat_27910": 0.6133463978767395, "TheoremQA_maxku/ipnetwork4-mac.json": 0.6139425039291382, "math_train_number_theory_7070": 0.618257462978363, "aqua_rat_36286": 0.6202767491340637, "camel_39644": 0.6226453185081482, "TheoremQA_maxku/ipnetwork10-datatransmission.json": 0.6267377734184265, "aqua_rat_81119": 0.6293727159500122, "camel_26540": 0.6464225649833679, "TheoremQA_maxku/ipnetwork7-lan.json": 0.6829906105995178}, "TheoremQA_wenhuchen/optics8.json": {"TheoremQA_wenhuchen/optics8.json": 0, "gsm_rft_22397": 0.5710474252700806, "camel_7693": 0.5710884928703308, "aqua_rat_68324": 0.5711347460746765, "camel_4552": 0.5712057948112488, "aqua_rat_78493": 0.5712076425552368, "camel_4444": 0.5712359547615051, "aqua_rat_61971": 0.5712716579437256, "camel_4646": 0.5714426636695862, "aqua_rat_17252": 0.571580171585083, "camel_4400": 0.5716482400894165, "camel_3983": 0.5718553066253662, "camel_5672": 0.5718564987182617, "aqua_rat_41853": 0.571927011013031, "gsm_rft_28133": 0.5719299912452698, "gsm_train_34815": 0.5719299912452698, "aqua_rat_41455": 0.5719764232635498, "aqua_rat_9793": 0.5720506310462952, "aqua_rat_3331": 0.5720958709716797, "gsm_rft_8463": 0.5721368193626404, "camel_4980": 0.5723342895507812, "aqua_rat_40900": 0.5724689364433289, "camel_4981": 0.5724989771842957, "camel_4476": 0.5725194811820984, "aqua_rat_57401": 0.5729399919509888, "camel_5988": 0.5731503963470459, "camel_4426": 0.5731677412986755, "aqua_rat_83008": 0.573186993598938, "camel_4724": 0.573253870010376, "camel_19705": 0.5733333230018616, "camel_5034": 0.5733643174171448, "aqua_rat_10607": 0.5734466910362244, "aqua_rat_6188": 0.5735448598861694, "aqua_rat_59927": 0.5735720992088318, "aqua_rat_51750": 0.5735757946968079, "camel_4898": 0.5735812187194824, "camel_5654": 0.5736032128334045, "camel_5671": 0.573675811290741, "camel_4469": 0.5736780166625977, "camel_7757": 0.5737079977989197, "camel_4409": 0.5737224817276001, "camel_4946": 0.5737566947937012, "camel_4456": 0.5737934708595276, "camel_17811": 0.5738584399223328, "aqua_rat_21925": 0.5739888548851013, "camel_5007": 0.5740059018135071, "aqua_rat_1335": 0.5740966200828552, "aqua_rat_55579": 0.5741506814956665, "aqua_rat_38140": 0.5744104385375977, "camel_5909": 0.5744451284408569, "camel_4819": 0.5745262503623962, "camel_4425": 0.574616551399231, "camel_5968": 0.5746346116065979, "camel_5974": 0.5747653841972351, "aqua_rat_23334": 0.5748606324195862, "camel_28842": 0.5749025940895081, "aqua_rat_86790": 0.5750731825828552, "aqua_rat_12658": 0.5751312375068665, "aqua_rat_50400": 0.5751456022262573, "aqua_rat_85100": 0.5751594305038452, "camel_3947": 0.5752268433570862, "aqua_rat_69487": 0.5752711892127991, "aqua_rat_81193": 0.5753455758094788, "aqua_rat_84165": 0.5754178762435913, "camel_19685": 0.5754393935203552, "aqua_rat_70812": 0.5754554867744446, "camel_5920": 0.5755015015602112, "aqua_rat_56182": 0.5755379796028137, "camel_3937": 0.5755813717842102, "camel_5856": 0.5756427049636841, "aqua_rat_26780": 0.5756906270980835, "aqua_rat_20614": 0.5756977796554565, "gsm_rft_5789": 0.5757005214691162, "camel_4820": 0.5757297873497009, "aqua_rat_85440": 0.5757464170455933, "camel_39503": 0.5759032368659973, "camel_5980": 0.5759691596031189, "aqua_rat_51397": 0.5759752988815308, "camel_5922": 0.5760635137557983, "aqua_rat_19333": 0.5760660767555237, "camel_4473": 0.5761605501174927, "camel_4475": 0.5762773156166077, "aqua_rat_6040": 0.5763530731201172, "camel_28875": 0.5763719081878662, "gsm_rft_21678": 0.5763985514640808, "camel_5854": 0.5764087438583374, "camel_5921": 0.5764122009277344, "camel_4404": 0.5764818787574768, "camel_4422": 0.5765231251716614, "camel_5287": 0.5765371918678284, "aqua_rat_3859": 0.5765743851661682, "camel_39465": 0.5766025185585022, "camel_5675": 0.5766242146492004, "camel_4449": 0.5766378045082092, "camel_5037": 0.5767295956611633, "aqua_rat_12260": 0.5767735838890076, "math_test_precalculus_893": 0.5768466591835022, "camel_4438": 0.5770529508590698, "camel_5926": 0.5771456956863403, "aqua_rat_39907": 0.5772684216499329, "camel_4479": 0.5772687196731567, "camel_4406": 0.5772820711135864, "camel_24382": 0.5773745179176331, "camel_4434": 0.5776885151863098, "gsm_rft_29698": 0.5777212381362915, "camel_4455": 0.5777974128723145, "camel_5886": 0.5778573155403137, "camel_5017": 0.5780023336410522, "aqua_rat_7506": 0.5784811973571777, "gsm_train_13418": 0.5785968899726868, "aqua_rat_72645": 0.5786336660385132, "camel_4432": 0.5788906216621399, "camel_5928": 0.5790356397628784, "camel_5649": 0.5792692303657532, "gsm_rft_34580": 0.5795964002609253, "aqua_rat_17760": 0.5797688961029053, "camel_6239": 0.5799869894981384, "camel_5972": 0.5802923440933228, "math_train_prealgebra_243": 0.5807475447654724, "camel_5893": 0.5812041759490967, "camel_5853": 0.5813835859298706, "aqua_rat_44457": 0.5814173221588135, "camel_19693": 0.5814367532730103, "aqua_rat_16469": 0.5815675258636475, "camel_28143": 0.5816242694854736, "camel_39489": 0.5816587805747986, "camel_4443": 0.5817514061927795, "aqua_rat_23842": 0.5818720459938049, "camel_4983": 0.5821790099143982, "camel_4413": 0.582259476184845, "camel_4457": 0.5824339985847473, "camel_5840": 0.5824959874153137, "camel_4545": 0.5828738212585449, "camel_5997": 0.5829441547393799, "camel_5963": 0.5829477310180664, "aqua_rat_16415": 0.5831867456436157, "aqua_rat_48959": 0.583332896232605, "camel_39351": 0.5835233926773071, "camel_4478": 0.5835261940956116, "camel_5521": 0.5836927890777588, "camel_5938": 0.583708643913269, "aqua_rat_22582": 0.5837714672088623, "aqua_rat_3234": 0.584037184715271, "camel_4415": 0.5840417742729187, "camel_4445": 0.584145188331604, "aqua_rat_81926": 0.5843214392662048, "camel_4874": 0.5843511819839478, "camel_19753": 0.5845954418182373, "aqua_rat_4580": 0.5846614837646484, "aqua_rat_8162": 0.5852706432342529, "camel_24344": 0.5853649377822876, "aqua_rat_75111": 0.5855865478515625, "aqua_rat_24901": 0.5857009887695312, "aqua_rat_88321": 0.5859633088111877, "camel_5861": 0.5861728191375732, "aqua_rat_33103": 0.5863302946090698, "camel_19734": 0.5864712595939636, "aqua_rat_83787": 0.5865389704704285, "aqua_rat_23105": 0.5865890383720398, "aqua_rat_12925": 0.5865959525108337, "camel_46111": 0.5869541168212891, "camel_4431": 0.5870420932769775, "aqua_rat_28523": 0.5884622931480408, "camel_19709": 0.588560163974762, "camel_5645": 0.588703989982605, "camel_5899": 0.5891138911247253, "camel_4416": 0.5895591974258423, "math_test_geometry_903": 0.5895936489105225, "camel_4798": 0.5897560715675354, "aqua_rat_46971": 0.5898995995521545, "aqua_rat_69929": 0.5905185341835022, "camel_47404": 0.5909638404846191, "camel_5967": 0.5913127660751343, "aqua_rat_36249": 0.5922871232032776, "aqua_rat_8610": 0.5925450921058655, "camel_19735": 0.5928477644920349, "aqua_rat_33439": 0.5930688977241516, "camel_5635": 0.594222903251648, "camel_39440": 0.5945897698402405, "aqua_rat_66162": 0.5947863459587097, "TheoremQA_tonyxia/semiconductor5.json": 0.5955181121826172, "gsm_rft_2452": 0.596230149269104, "camel_19727": 0.5970185995101929, "camel_5962": 0.5972515940666199, "gsm_train_17819": 0.5972630381584167, "gsm_rft_17551": 0.5972630381584167, "gsm_rft_11031": 0.597723662853241, "aqua_rat_7575": 0.5978642106056213, "gsm_rft_9344": 0.597905158996582, "aqua_rat_46515": 0.5989719033241272, "camel_4806": 0.599536657333374, "camel_4429": 0.6009002327919006, "camel_4853": 0.6009349226951599, "camel_39308": 0.6020220518112183, "aqua_rat_18320": 0.6030744910240173, "aqua_rat_35903": 0.603235125541687, "camel_18649": 0.6108927130699158, "camel_4979": 0.6120266914367676, "camel_45970": 0.6182301640510559, "TheoremQA_wenhuchen/optics5.json": 0.7954989671707153}, "TheoremQA_wenhuchen/t_test1.json": {"camel_8108": 0, "camel_9952": 0, "camel_8921": 0, "camel_8708": 0, "camel_8836": 0, "camel_8831": 0, "camel_8698": 0, "camel_8883": 0, "camel_8654": 0, "camel_8127": 0, "camel_8846": 0, "camel_9938": 0, "camel_8847": 0, "camel_8876": 0, "camel_9735": 0, "camel_8953": 0, "camel_9932": 0, "camel_8676": 0, "camel_8045": 0, "camel_8310": 0, "camel_8680": 0, "camel_8817": 0, "camel_9969": 0, "camel_8866": 0, "camel_9242": 0, "camel_8034": 0, "camel_8024": 0, "camel_8031": 0, "camel_8044": 0, "camel_8826": 0, "camel_8843": 0, "camel_9991": 0, "camel_9960": 0, "camel_8814": 0, "camel_9998": 0, "camel_8827": 0, "camel_8665": 0, "camel_8898": 0, "camel_8844": 0, "camel_9900": 0, "camel_8905": 0, "camel_8670": 0, "camel_9920": 0, "camel_9656": 0, "camel_8065": 0, "camel_8849": 0, "camel_9954": 0, "camel_8825": 0, "camel_8000": 0, "camel_8853": 0, "camel_8064": 0, "camel_8078": 0, "camel_8768": 0, "camel_9945": 0, "camel_9996": 0, "camel_8811": 0, "camel_8016": 0, "camel_8852": 0, "camel_9979": 0, "camel_8926": 0, "camel_8056": 0, "camel_8046": 0, "camel_8076": 0, "camel_8802": 0, "camel_9983": 0, "camel_8835": 0, "camel_8812": 0, "camel_8644": 0, "camel_8007": 0, "camel_8807": 0, "camel_8028": 0, "camel_9941": 0, "camel_8871": 0, "camel_8002": 0, "camel_9980": 0, "camel_8855": 0, "camel_8934": 0, "camel_9958": 0, "camel_9930": 0, "camel_8062": 0, "camel_8714": 0, "camel_8011": 0, "camel_8840": 0, "camel_8664": 0, "camel_8824": 0, "camel_8803": 0, "camel_8140": 0, "camel_8660": 0, "camel_8053": 0, "camel_8025": 0, "camel_9392": 0, "camel_8084": 0, "camel_8689": 0, "camel_8075": 0, "camel_8047": 0, "camel_8838": 0, "camel_8068": 0, "camel_8073": 0, "camel_8069": 0, "camel_8878": 0, "camel_8026": 0, "camel_8023": 0, "camel_8033": 0, "camel_8863": 0, "camel_8071": 0, "camel_9978": 0, "camel_8061": 0, "camel_8864": 0, "camel_9971": 0, "camel_8041": 0, "camel_8810": 0, "camel_9994": 0, "camel_8074": 0, "camel_8018": 0, "camel_8005": 0, "camel_9929": 0, "camel_8006": 0, "camel_9967": 0, "camel_8067": 0, "camel_8823": 0, "TheoremQA_wenhuchen/t_test1.json": 0, "camel_8013": 0, "camel_8079": 0, "camel_9944": 0, "camel_8004": 0, "camel_8070": 0, "camel_8059": 0, "camel_8035": 0, "camel_8072": 0, "camel_8057": 0, "camel_9988": 0, "camel_8804": 0, "camel_8040": 0, "camel_8066": 0, "camel_8048": 0, "camel_8854": 0, "camel_8020": 0, "camel_8014": 0, "camel_8052": 0, "camel_8832": 0, "camel_8001": 0, "camel_8063": 0, "camel_8003": 0, "camel_8037": 0, "camel_9977": 0, "camel_8051": 0, "camel_8850": 0, "camel_8008": 0, "camel_8054": 0, "camel_9951": 0, "camel_9963": 0, "camel_8017": 0, "camel_8012": 0, "camel_8058": 0, "camel_9931": 0, "camel_8036": 0, "camel_8021": 0, "camel_8038": 0, "camel_8805": 0, "camel_9709": 0, "camel_9962": 0, "camel_8042": 0, "camel_8872": 0, "camel_9925": 0, "camel_8049": 0, "camel_8010": 0, "camel_9947": 0, "camel_8019": 0, "camel_8055": 0, "camel_8060": 0, "camel_8653": 0, "camel_9926": 0, "camel_9982": 0, "camel_9950": 0, "camel_8837": 0, "camel_8032": 0, "camel_8819": 0, "camel_8050": 0, "camel_8648": 0, "camel_8029": 0, "camel_8077": 0, "camel_8022": 0, "camel_8940": 0, "camel_8009": 0, "camel_8039": 0, "camel_8015": 0, "camel_8948": 0, "camel_8027": 0, "camel_9972": 0, "camel_8043": 0, "camel_8715": 0, "camel_8030": 0, "gsm_train_6762": 0.7265492677688599, "gsm_rft_22746": 0.7268382906913757, "TheoremQA_wenhuchen/p_value2.json": 0.7367405295372009, "camel_37940": 0.7485750317573547, "camel_37974": 0.7534952759742737, "camel_37953": 0.7569533586502075, "TheoremQA_wenhuchen/t_test2.json": 0.7885005474090576, "TheoremQA_wenhuchen/t_test3.json": 0.8134055733680725}, "TheoremQA_maxku/signalprocessing6-Ztransform.json": {"TheoremQA_maxku/signalprocessing6-Ztransform.json": 0, "camel_31241": 0.6273729801177979, "camel_37819": 0.6274703741073608, "camel_30357": 0.6275444626808167, "camel_29832": 0.627581775188446, "aqua_rat_59416": 0.627762496471405, "camel_29685": 0.627817690372467, "camel_28122": 0.6278234720230103, "camel_30936": 0.6278753280639648, "camel_29680": 0.6280344724655151, "camel_16996": 0.6281202435493469, "aqua_rat_13812": 0.6284118890762329, "camel_41862": 0.6284131407737732, "camel_30717": 0.6284334659576416, "camel_31212": 0.6284842491149902, "camel_30689": 0.628500759601593, "camel_30093": 0.6285097599029541, "camel_30918": 0.6285344958305359, "camel_28874": 0.628574788570404, "camel_30806": 0.6286694407463074, "aqua_rat_77963": 0.628811776638031, "aqua_rat_8383": 0.6288225054740906, "camel_37825": 0.6288314461708069, "camel_30701": 0.628836989402771, "camel_31605": 0.6288905739784241, "aqua_rat_25938": 0.6289038062095642, "camel_29638": 0.6289072036743164, "camel_31213": 0.6289594769477844, "camel_25615": 0.6290868520736694, "camel_30672": 0.6291323304176331, "camel_30655": 0.6291690468788147, "camel_28869": 0.629224956035614, "camel_28309": 0.6292393803596497, "camel_36623": 0.6295453906059265, "camel_37883": 0.629594087600708, "camel_31510": 0.6299497485160828, "gsm_rft_34686": 0.6300056576728821, "camel_31263": 0.6300405859947205, "camel_31354": 0.6300420165061951, "camel_16914": 0.6300786137580872, "camel_36502": 0.6302301287651062, "camel_29078": 0.6302527785301208, "camel_37764": 0.6305073499679565, "camel_30433": 0.6305596828460693, "camel_31356": 0.6307934522628784, "camel_17545": 0.6308013796806335, "camel_30435": 0.6309778690338135, "camel_29108": 0.6310007572174072, "camel_30951": 0.6310179233551025, "camel_31084": 0.6311874389648438, "camel_31497": 0.6312353014945984, "camel_31252": 0.6312422156333923, "camel_31057": 0.6313002109527588, "camel_30843": 0.6313627362251282, "camel_29227": 0.6316347122192383, "camel_29752": 0.6317062973976135, "camel_30423": 0.6317667961120605, "camel_30409": 0.631920337677002, "aqua_rat_16066": 0.6319713592529297, "camel_28837": 0.6321912407875061, "camel_31969": 0.6321941614151001, "gsm_rft_31508": 0.632195770740509, "camel_29746": 0.6322804093360901, "camel_30467": 0.6323049664497375, "camel_30740": 0.6323527693748474, "camel_31253": 0.6325702667236328, "camel_30947": 0.6328229904174805, "camel_29097": 0.6329636573791504, "camel_30415": 0.6330350637435913, "camel_31759": 0.6331820487976074, "camel_29749": 0.6332132816314697, "camel_29861": 0.6332211494445801, "camel_28802": 0.6333897113800049, "camel_30685": 0.6334229111671448, "camel_31174": 0.6335264444351196, "camel_30950": 0.633689820766449, "camel_36269": 0.6338614225387573, "camel_29691": 0.633905827999115, "camel_30871": 0.6339212656021118, "aqua_rat_87911": 0.63396155834198, "camel_31641": 0.6340487599372864, "camel_20527": 0.6340675950050354, "aqua_rat_10571": 0.634147047996521, "aqua_rat_17300": 0.6341959834098816, "gsm_rft_17172": 0.634263813495636, "gsm_train_5852": 0.6343061923980713, "camel_30935": 0.6343218088150024, "gsm_rft_14019": 0.6343390345573425, "camel_36612": 0.6346783638000488, "gsm_rft_33929": 0.6346971988677979, "camel_28148": 0.6349645853042603, "camel_29205": 0.6349795460700989, "camel_37817": 0.6351222991943359, "camel_37507": 0.635184645652771, "gsm_rft_8043": 0.6351929306983948, "camel_25661": 0.6352257132530212, "camel_31467": 0.6352800726890564, "camel_28815": 0.635352611541748, "camel_29163": 0.6353608965873718, "camel_29705": 0.6355774998664856, "gsm_train_15936": 0.6355976462364197, "camel_31098": 0.6356897354125977, "camel_29273": 0.6357141137123108, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.6357851624488831, "gsm_rft_35215": 0.6358396410942078, "camel_30864": 0.6358765959739685, "gsm_rft_18737": 0.636142909526825, "camel_28787": 0.6362562775611877, "camel_30894": 0.6362778544425964, "camel_30948": 0.63634192943573, "gsm_train_8512": 0.6364883184432983, "gsm_rft_10941": 0.6364883184432983, "camel_37771": 0.6365812420845032, "camel_31164": 0.6367015242576599, "camel_31612": 0.6369002461433411, "camel_29279": 0.6370776295661926, "camel_26505": 0.6370914578437805, "camel_29240": 0.6374903917312622, "camel_30644": 0.6375887989997864, "camel_29042": 0.6375904679298401, "aqua_rat_42385": 0.6375912427902222, "camel_28407": 0.6375951170921326, "camel_25530": 0.6376055479049683, "camel_29394": 0.6376605033874512, "camel_31256": 0.6377981305122375, "camel_28604": 0.6378004550933838, "camel_31190": 0.6382274031639099, "camel_20486": 0.6383935213088989, "camel_30946": 0.6385028958320618, "camel_29750": 0.6385751366615295, "camel_31095": 0.6386660933494568, "camel_26497": 0.6386812329292297, "camel_29877": 0.6387689113616943, "camel_17561": 0.6389603018760681, "camel_28156": 0.6393604278564453, "camel_25578": 0.6395574808120728, "camel_28384": 0.6395639777183533, "camel_31633": 0.6397740244865417, "camel_31180": 0.6397934556007385, "camel_17657": 0.6398173570632935, "camel_30179": 0.6399441361427307, "camel_17621": 0.6402406692504883, "camel_29687": 0.6405550837516785, "camel_29727": 0.6406726837158203, "camel_25579": 0.6407466530799866, "camel_30927": 0.6412121653556824, "camel_30440": 0.641360342502594, "camel_29065": 0.6415139436721802, "camel_30934": 0.6415401697158813, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.6417953372001648, "camel_28123": 0.6418642401695251, "camel_30897": 0.6425551176071167, "camel_31047": 0.6428256630897522, "camel_36493": 0.6433109045028687, "camel_29429": 0.6435348987579346, "camel_19558": 0.6438265442848206, "camel_28821": 0.6442792415618896, "camel_39510": 0.6448242664337158, "camel_31202": 0.644838273525238, "camel_17674": 0.6448732614517212, "camel_17639": 0.6452415585517883, "camel_31179": 0.6456900238990784, "camel_31045": 0.6457515358924866, "camel_30939": 0.6467163562774658, "gsm_train_20944": 0.6467602849006653, "gsm_rft_21298": 0.6467602849006653, "TheoremQA_maxku/signalprocessing14-Ztransform.json": 0.6470361351966858, "camel_29695": 0.6483531594276428, "camel_29178": 0.6483958959579468, "gsm_rft_33863": 0.6488926410675049, "camel_30413": 0.6496571898460388, "camel_29218": 0.6503594517707825, "camel_29711": 0.6505826115608215, "camel_28149": 0.6515366435050964, "camel_30959": 0.6525954008102417, "camel_29693": 0.6529114246368408, "camel_29681": 0.6531095504760742, "camel_31176": 0.6533236503601074, "gsm_rft_22822": 0.6536786556243896, "gsm_rft_11471": 0.6541540026664734, "camel_31323": 0.6548084020614624, "camel_29252": 0.6551585793495178, "camel_30407": 0.6552248597145081, "camel_37933": 0.6559973359107971, "camel_29704": 0.6560155153274536, "camel_28946": 0.6560426354408264, "camel_30474": 0.6563970446586609, "gsm_rft_2592": 0.6564992070198059, "camel_29184": 0.657118022441864, "gsm_rft_28838": 0.6589924693107605, "gsm_train_23183": 0.6598531603813171, "gsm_rft_3972": 0.6600961089134216, "gsm_rft_28746": 0.6603586673736572, "gsm_rft_7862": 0.6625990271568298, "camel_29708": 0.6657320857048035, "camel_28081": 0.6694751977920532, "camel_29734": 0.6737892627716064, "TheoremQA_maxku/signalprocessing13-Ztransform.json": 0.6817436814308167, "camel_29719": 0.6833094954490662, "TheoremQA_maxku/signalprocessing4-Ztransform.json": 0.7311280369758606}, "TheoremQA_tonyxia/semiconductor5.json": {"TheoremQA_tonyxia/semiconductor5.json": 0, "gsm_rft_13895": 0.6075596809387207, "gsm_rft_4120": 0.6075743436813354, "gsm_rft_1939": 0.6076425313949585, "gsm_train_31158": 0.6076425313949585, "gsm_rft_18492": 0.6076500415802002, "aqua_rat_28384": 0.6076904535293579, "aqua_rat_18805": 0.607723593711853, "gsm_rft_33035": 0.6077449321746826, "camel_44806": 0.6078125238418579, "gsm_rft_14259": 0.6078540682792664, "aqua_rat_47020": 0.6079366207122803, "camel_46220": 0.6080675721168518, "gsm_rft_11031": 0.6080980896949768, "gsm_rft_12210": 0.608115017414093, "aqua_rat_64322": 0.6081520318984985, "gsm_rft_29368": 0.608176589012146, "gsm_rft_18391": 0.6082553863525391, "gsm_rft_8656": 0.608263373374939, "gsm_rft_27194": 0.608383059501648, "gsm_rft_27207": 0.6084287166595459, "gsm_rft_14979": 0.6084386706352234, "gsm_rft_9956": 0.6084544658660889, "gsm_train_7625": 0.6084544658660889, "gsm_train_15179": 0.6084756851196289, "gsm_rft_34304": 0.608478844165802, "gsm_rft_29057": 0.608513355255127, "gsm_rft_25278": 0.6086105108261108, "gsm_train_34992": 0.6086235046386719, "gsm_rft_16965": 0.6086314916610718, "gsm_train_18247": 0.6086314916610718, "gsm_rft_34442": 0.6086373925209045, "gsm_rft_469": 0.608732283115387, "gsm_rft_34816": 0.6087929010391235, "gsm_rft_1431": 0.6088522672653198, "gsm_rft_18494": 0.6088942289352417, "gsm_rft_2452": 0.6090918779373169, "gsm_train_24355": 0.6091455221176147, "gsm_rft_15641": 0.609286904335022, "gsm_rft_8950": 0.6093174815177917, "gsm_rft_13998": 0.6093540787696838, "gsm_train_7105": 0.6093540787696838, "gsm_rft_530": 0.6093546748161316, "gsm_rft_10209": 0.6094197034835815, "gsm_rft_7740": 0.6094980239868164, "gsm_rft_16332": 0.6095094084739685, "gsm_rft_1925": 0.6095275282859802, "gsm_rft_17551": 0.6095523834228516, "gsm_train_17819": 0.6095523834228516, "gsm_rft_27675": 0.6099807024002075, "gsm_rft_30177": 0.6100078821182251, "gsm_rft_9344": 0.6100578308105469, "aqua_rat_71661": 0.6102057099342346, "gsm_rft_34686": 0.6102950572967529, "gsm_train_34454": 0.610332190990448, "aqua_rat_28545": 0.6103819012641907, "gsm_rft_21366": 0.610602855682373, "gsm_rft_759": 0.6106370687484741, "gsm_rft_13166": 0.6106370687484741, "math_test_prealgebra_105": 0.6106418967247009, "gsm_train_10907": 0.6106659173965454, "gsm_rft_21182": 0.6106659173965454, "aqua_rat_19288": 0.6107043623924255, "gsm_rft_21198": 0.6107616424560547, "gsm_rft_16142": 0.6107701063156128, "aqua_rat_19705": 0.6107916831970215, "math_train_prealgebra_201": 0.6108123660087585, "gsm_rft_882": 0.6108914613723755, "gsm_train_11033": 0.6113946437835693, "gsm_rft_22460": 0.6116994023323059, "gsm_train_25539": 0.6116994023323059, "gsm_rft_19729": 0.6118574142456055, "gsm_rft_1803": 0.6118596792221069, "gsm_rft_14108": 0.6120463609695435, "gsm_rft_23224": 0.612168550491333, "gsm_rft_21897": 0.6121706366539001, "aqua_rat_83310": 0.6121896505355835, "gsm_train_33048": 0.6123436689376831, "gsm_train_553": 0.6126001477241516, "gsm_rft_18266": 0.6126001477241516, "gsm_rft_13484": 0.6126129031181335, "gsm_rft_5569": 0.6126129031181335, "aqua_rat_88476": 0.6127605438232422, "gsm_rft_21929": 0.6131864190101624, "gsm_rft_28391": 0.6132761836051941, "aqua_rat_29281": 0.6133432388305664, "camel_28656": 0.6133518218994141, "gsm_rft_14019": 0.6133911609649658, "gsm_rft_24023": 0.6133965849876404, "gsm_rft_34282": 0.6134232878684998, "gsm_rft_32172": 0.613467812538147, "gsm_rft_4684": 0.6134819388389587, "gsm_train_26111": 0.6134819388389587, "gsm_rft_14096": 0.6135163903236389, "aqua_rat_43160": 0.6137268543243408, "gsm_rft_14762": 0.6139025092124939, "gsm_rft_24668": 0.6139864921569824, "gsm_rft_25684": 0.6139901280403137, "gsm_rft_11759": 0.6140170097351074, "aqua_rat_23008": 0.6141893267631531, "gsm_train_17798": 0.6144166588783264, "math_train_geometry_946": 0.6147529482841492, "gsm_rft_35240": 0.6150296330451965, "gsm_train_30563": 0.6151098012924194, "gsm_rft_28403": 0.6151098012924194, "gsm_rft_33471": 0.6152843236923218, "gsm_rft_20038": 0.6154839396476746, "gsm_rft_22295": 0.6155444979667664, "gsm_rft_22280": 0.6156715154647827, "gsm_rft_13783": 0.6157476305961609, "gsm_train_6685": 0.6158013343811035, "gsm_train_34683": 0.6158100962638855, "gsm_rft_34783": 0.615898072719574, "gsm_rft_900": 0.615951418876648, "gsm_rft_35392": 0.616026759147644, "gsm_rft_19857": 0.6160838007926941, "gsm_rft_33771": 0.6161426305770874, "gsm_train_35541": 0.6162278056144714, "gsm_rft_30647": 0.6162278056144714, "gsm_rft_1561": 0.6162816882133484, "gsm_rft_33903": 0.6165167689323425, "gsm_rft_14306": 0.6165664196014404, "gsm_rft_27397": 0.6165856719017029, "aqua_rat_79015": 0.6166960000991821, "aqua_rat_78576": 0.6173610687255859, "gsm_rft_33348": 0.6174567937850952, "aqua_rat_40859": 0.6175384521484375, "aqua_rat_51108": 0.61754310131073, "gsm_rft_57": 0.6176596879959106, "aqua_rat_29146": 0.6176725625991821, "aqua_rat_71372": 0.6178737878799438, "aqua_rat_68914": 0.6179423928260803, "gsm_rft_1589": 0.6186492443084717, "gsm_rft_2390": 0.619140625, "aqua_rat_14555": 0.6193413734436035, "gsm_train_8512": 0.6195586323738098, "gsm_rft_10941": 0.6195586323738098, "gsm_rft_24231": 0.6195671558380127, "gsm_rft_25518": 0.6206067800521851, "gsm_train_3954": 0.6210668683052063, "gsm_rft_31703": 0.6211375594139099, "aqua_rat_7290": 0.621227502822876, "gsm_rft_1849": 0.6215365529060364, "gsm_rft_15426": 0.6217137575149536, "gsm_rft_32619": 0.6218778491020203, "gsm_rft_9980": 0.6219916343688965, "gsm_rft_10802": 0.6227471828460693, "gsm_rft_7553": 0.6231815814971924, "gsm_rft_21919": 0.6231952905654907, "gsm_train_9354": 0.6231952905654907, "gsm_rft_18182": 0.6233215928077698, "gsm_rft_35680": 0.6233438849449158, "gsm_rft_25098": 0.6233717203140259, "gsm_rft_22156": 0.6234435439109802, "gsm_train_3873": 0.6234903931617737, "gsm_rft_26441": 0.623672604560852, "gsm_rft_15003": 0.6236866116523743, "gsm_rft_23738": 0.6237834692001343, "gsm_train_28486": 0.6240777373313904, "gsm_rft_34166": 0.6240777373313904, "aqua_rat_2689": 0.624313235282898, "gsm_rft_15366": 0.6257781982421875, "gsm_train_15924": 0.6266104578971863, "gsm_rft_19423": 0.6266104578971863, "gsm_rft_14462": 0.6266104578971863, "gsm_rft_22401": 0.6275128722190857, "aqua_rat_45026": 0.6281307339668274, "gsm_rft_26363": 0.6289562582969666, "gsm_rft_35102": 0.629094660282135, "gsm_train_5772": 0.6292895078659058, "aqua_rat_48599": 0.6304715871810913, "aqua_rat_24388": 0.6311295032501221, "aqua_rat_71967": 0.6312623620033264, "gsm_rft_28086": 0.6328604221343994, "math_test_algebra_2631": 0.6331453323364258, "gsm_train_33171": 0.6335968375205994, "aqua_rat_73083": 0.6336489915847778, "camel_5287": 0.6339980959892273, "gsm_rft_10110": 0.6345798969268799, "gsm_rft_26574": 0.6365535259246826, "gsm_rft_34396": 0.6366791129112244, "gsm_train_2639": 0.6366791129112244, "aqua_rat_52068": 0.637231171131134, "aqua_rat_52535": 0.6378545165061951, "aqua_rat_77682": 0.6380208134651184, "aqua_rat_65009": 0.6385899782180786, "gsm_rft_13049": 0.638596773147583, "gsm_rft_26010": 0.6389909386634827, "aqua_rat_24258": 0.640038251876831, "camel_28081": 0.6402194499969482, "gsm_rft_33530": 0.6415428519248962, "aqua_rat_31331": 0.641685962677002, "gsm_rft_28497": 0.6417956352233887, "gsm_train_18516": 0.6417956352233887, "aqua_rat_28001": 0.6427516937255859, "aqua_rat_18575": 0.6430994868278503, "aqua_rat_48550": 0.6443395614624023, "aqua_rat_79408": 0.6454312205314636, "aqua_rat_4231": 0.6458407044410706, "aqua_rat_33683": 0.648847222328186}, "TheoremQA_maxku/ipnetwork14-hammingdist.json": {"TheoremQA_maxku/ipnetwork14-hammingdist.json": 0, "aqua_rat_75785": 0.6414347290992737, "aqua_rat_12308": 0.6416820287704468, "gsm_rft_25314": 0.6417474746704102, "camel_26534": 0.6417480707168579, "gsm_train_29880": 0.6418434977531433, "aqua_rat_2817": 0.6418834328651428, "aqua_rat_46007": 0.6419690847396851, "camel_37311": 0.6419715881347656, "camel_18222": 0.6420241594314575, "aqua_rat_35061": 0.6420297026634216, "math_train_counting_and_probability_5060": 0.6420698165893555, "camel_23082": 0.6421137452125549, "aqua_rat_57735": 0.6421164274215698, "math_train_counting_and_probability_5094": 0.6421247720718384, "camel_22332": 0.6421684622764587, "math_train_counting_and_probability_431": 0.6421726942062378, "aqua_rat_33891": 0.642228364944458, "gsm_rft_11441": 0.6423280835151672, "gsm_rft_23120": 0.6423283815383911, "camel_35916": 0.642414391040802, "aqua_rat_49426": 0.642440915107727, "aqua_rat_1671": 0.6424524784088135, "gsm_rft_33146": 0.6427919864654541, "camel_23111": 0.6428041458129883, "math_train_counting_and_probability_5042": 0.642882227897644, "camel_18196": 0.6429803371429443, "camel_23096": 0.6429826021194458, "aqua_rat_78272": 0.6430198550224304, "camel_26472": 0.6431321501731873, "camel_9274": 0.6432604193687439, "camel_23113": 0.6432626247406006, "aqua_rat_58787": 0.6433700919151306, "camel_9134": 0.6437792181968689, "gsm_rft_11616": 0.6437793970108032, "aqua_rat_67987": 0.6437857747077942, "math_test_counting_and_probability_990": 0.6438450217247009, "aqua_rat_27645": 0.6438966989517212, "gsm_train_35467": 0.6440395712852478, "gsm_rft_24803": 0.644140362739563, "camel_23802": 0.6442561149597168, "camel_26459": 0.6443278193473816, "aqua_rat_4058": 0.6444313526153564, "aqua_rat_15961": 0.6446292996406555, "gsm_rft_25665": 0.6446635723114014, "aqua_rat_87221": 0.6447342038154602, "aqua_rat_2854": 0.6447365283966064, "aqua_rat_12478": 0.6447448134422302, "camel_35108": 0.644883394241333, "camel_36969": 0.6449765563011169, "math_train_intermediate_algebra_1733": 0.644989550113678, "camel_23079": 0.6450140476226807, "aqua_rat_84064": 0.6450387835502625, "aqua_rat_50973": 0.6450871825218201, "math_train_counting_and_probability_428": 0.645103394985199, "camel_36978": 0.6451162695884705, "aqua_rat_56916": 0.6452309489250183, "camel_35368": 0.6453169584274292, "aqua_rat_75580": 0.6453931927680969, "aqua_rat_49211": 0.6455162167549133, "aqua_rat_19731": 0.6455833911895752, "aqua_rat_39962": 0.6458209156990051, "camel_26452": 0.6458717584609985, "camel_21989": 0.6460782885551453, "camel_37493": 0.6460864543914795, "camel_9133": 0.6462085247039795, "gsm_rft_4221": 0.6462486386299133, "aqua_rat_72870": 0.6462596654891968, "aqua_rat_17743": 0.646266520023346, "aqua_rat_88083": 0.646437406539917, "camel_36975": 0.646532416343689, "gsm_rft_17952": 0.6465582251548767, "camel_23056": 0.6467626094818115, "camel_35783": 0.6468947529792786, "aqua_rat_36780": 0.6469829082489014, "camel_26470": 0.6470056176185608, "math_train_counting_and_probability_31": 0.6471145749092102, "aqua_rat_9869": 0.6471390724182129, "aqua_rat_23446": 0.647166907787323, "aqua_rat_31214": 0.6473060250282288, "math_train_intermediate_algebra_1963": 0.6473656892776489, "aqua_rat_32347": 0.6475571393966675, "camel_23076": 0.6475926637649536, "aqua_rat_85269": 0.6476148366928101, "gsm_rft_8013": 0.647962212562561, "camel_21935": 0.6483705043792725, "aqua_rat_51781": 0.6484580039978027, "TheoremQA_elainewan/math_algebra_4.json": 0.6486227512359619, "gsm_rft_10682": 0.6487532258033752, "gsm_train_7585": 0.6487547755241394, "gsm_rft_10080": 0.6487547755241394, "math_test_counting_and_probability_970": 0.6489262580871582, "camel_26445": 0.6490088701248169, "aqua_rat_60004": 0.6496197581291199, "aqua_rat_10179": 0.6496619582176208, "aqua_rat_83131": 0.64973384141922, "camel_23071": 0.6497744917869568, "gsm_rft_11457": 0.6498456001281738, "aqua_rat_15488": 0.6499903798103333, "aqua_rat_60981": 0.650387167930603, "camel_21334": 0.6504772305488586, "gsm_train_29739": 0.6509818434715271, "aqua_rat_56264": 0.6509996652603149, "gsm_rft_24906": 0.6510014533996582, "math_train_counting_and_probability_382": 0.651127278804779, "camel_23106": 0.651131272315979, "aqua_rat_16574": 0.6512385606765747, "gsm_rft_9540": 0.6514024138450623, "aqua_rat_13646": 0.6516315937042236, "aqua_rat_66366": 0.6516377925872803, "camel_36754": 0.6518539786338806, "camel_35789": 0.6518788933753967, "math_train_intermediate_algebra_215": 0.6519086956977844, "aqua_rat_87185": 0.6521889567375183, "aqua_rat_85697": 0.6526280045509338, "aqua_rat_1879": 0.6529852747917175, "camel_15836": 0.6531888246536255, "aqua_rat_16098": 0.6532199382781982, "camel_37444": 0.6532542705535889, "aqua_rat_108": 0.6533938050270081, "aqua_rat_8387": 0.6534483432769775, "aqua_rat_26096": 0.6536627411842346, "aqua_rat_66818": 0.6537714600563049, "camel_37459": 0.6538013815879822, "camel_13802": 0.6539391279220581, "camel_21949": 0.6539419293403625, "aqua_rat_33752": 0.6540089249610901, "aqua_rat_1953": 0.6541868448257446, "aqua_rat_52991": 0.6542249917984009, "camel_21980": 0.6543384194374084, "gsm_rft_2190": 0.6543955206871033, "gsm_rft_16246": 0.6543955206871033, "camel_23063": 0.654427707195282, "aqua_rat_5625": 0.6544308066368103, "gsm_train_32556": 0.6544599533081055, "camel_21952": 0.6546497941017151, "aqua_rat_80377": 0.6546557545661926, "aqua_rat_28998": 0.6547350883483887, "aqua_rat_13625": 0.6549107432365417, "aqua_rat_26864": 0.6551347374916077, "camel_19952": 0.6558014750480652, "aqua_rat_43867": 0.6559597253799438, "camel_31199": 0.656280517578125, "math_train_counting_and_probability_5051": 0.6564729809761047, "aqua_rat_25877": 0.657578706741333, "aqua_rat_86075": 0.6576257944107056, "aqua_rat_72814": 0.6581004858016968, "gsm_rft_31633": 0.6581305265426636, "aqua_rat_71449": 0.6585740447044373, "aqua_rat_21283": 0.6589478850364685, "camel_23095": 0.6594102382659912, "math_train_counting_and_probability_769": 0.6594217419624329, "math_train_counting_and_probability_467": 0.659677267074585, "aqua_rat_34919": 0.6603543162345886, "camel_35878": 0.6606969237327576, "aqua_rat_32047": 0.661213755607605, "camel_26436": 0.6612764596939087, "camel_23091": 0.6613947749137878, "aqua_rat_68856": 0.6627383232116699, "camel_23067": 0.6634576916694641, "aqua_rat_43433": 0.6635236144065857, "aqua_rat_12157": 0.6636555194854736, "camel_35780": 0.6639772653579712, "aqua_rat_21385": 0.6643763184547424, "aqua_rat_78747": 0.6647159457206726, "camel_23081": 0.6652860045433044, "camel_21477": 0.6658698320388794, "camel_21975": 0.6661617755889893, "aqua_rat_15776": 0.6664206981658936, "camel_23064": 0.6665410995483398, "aqua_rat_69333": 0.6669833660125732, "aqua_rat_65518": 0.6673677563667297, "camel_21921": 0.6676604151725769, "camel_23100": 0.6679045557975769, "camel_23101": 0.6682460308074951, "camel_20866": 0.669242262840271, "camel_23088": 0.670491635799408, "camel_37456": 0.6705798506736755, "camel_26421": 0.6726998090744019, "camel_21942": 0.6729047298431396, "camel_21923": 0.6729444861412048, "camel_21969": 0.6730981469154358, "camel_21940": 0.6738206744194031, "camel_21936": 0.6759349703788757, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.6771750450134277, "math_train_counting_and_probability_5109": 0.6779180765151978, "math_test_number_theory_340": 0.6788429021835327, "aqua_rat_33509": 0.680672287940979, "math_test_counting_and_probability_855": 0.6810961365699768, "TheoremQA_maxku/cv-imageprocessing6-histogram.json": 0.6831172704696655, "camel_21976": 0.6888028979301453, "camel_21944": 0.691624641418457, "math_train_counting_and_probability_5032": 0.6923805475234985, "camel_21962": 0.6938329339027405, "camel_21995": 0.6938716769218445, "camel_21992": 0.6954071521759033, "math_train_number_theory_1088": 0.7057174444198608, "camel_37553": 0.7065218091011047, "aqua_rat_73229": 0.7237248420715332, "TheoremQA_maxku/ipnetwork13-hammingdist.json": 0.8114790320396423}, "TheoremQA_jianyu_xu/Ramsey_2.json": {"camel_23707": 0, "camel_23696": 0, "camel_21181": 0, "camel_23729": 0, "camel_21015": 0, "camel_21809": 0, "camel_21798": 0, "camel_21151": 0, "camel_21835": 0, "camel_21167": 0, "camel_23750": 0, "camel_21192": 0, "camel_21199": 0, "camel_21131": 0, "camel_21120": 0, "camel_21177": 0, "camel_21149": 0, "camel_21158": 0, "camel_21127": 0, "camel_20577": 0, "camel_23695": 0, "camel_23748": 0, "camel_23755": 0, "camel_21122": 0, "camel_23690": 0, "camel_21183": 0, "camel_21125": 0, "camel_21137": 0, "camel_21168": 0, "camel_21180": 0, "camel_21194": 0, "camel_23693": 0, "camel_21195": 0, "camel_21134": 0, "camel_21123": 0, "camel_21159": 0, "camel_23711": 0, "camel_21178": 0, "camel_21148": 0, "camel_21146": 0, "camel_21152": 0, "camel_21184": 0, "camel_21198": 0, "camel_21124": 0, "camel_21188": 0, "camel_21186": 0, "camel_21179": 0, "camel_21174": 0, "camel_21141": 0, "camel_21126": 0, "camel_23682": 0, "camel_21162": 0, "camel_21193": 0, "camel_21156": 0, "camel_21121": 0, "camel_21129": 0, "camel_21169": 0, "camel_21163": 0, "camel_21191": 0, "camel_21175": 0, "camel_21185": 0, "camel_21139": 0, "camel_21160": 0, "camel_23686": 0, "camel_21130": 0, "camel_23714": 0, "camel_21568": 0, "camel_21153": 0, "camel_21822": 0, "camel_21161": 0, "camel_21170": 0, "camel_21136": 0, "camel_21172": 0, "camel_21154": 0, "camel_21147": 0, "camel_21143": 0, "camel_21144": 0, "camel_21145": 0, "camel_21135": 0, "camel_21155": 0, "camel_21055": 0, "camel_21190": 0, "camel_21164": 0, "camel_21187": 0, "camel_21128": 0, "camel_21173": 0, "camel_21157": 0, "camel_21166": 0, "camel_21196": 0, "TheoremQA_jianyu_xu/Ramsey_2.json": 0, "camel_21182": 0, "camel_21171": 0, "camel_23752": 0, "camel_21142": 0, "camel_21176": 0, "camel_21132": 0, "math_test_prealgebra_1560": 0.6939594745635986, "aqua_rat_57502": 0.6947134733200073, "camel_37851": 0.6950111985206604, "aqua_rat_69680": 0.695442795753479, "aqua_rat_78488": 0.6971580982208252, "aqua_rat_15706": 0.6972015500068665, "aqua_rat_82495": 0.6972935795783997, "aops_2017_AMC_10B_Problems/Problem_13": 0.6975829005241394, "aqua_rat_51353": 0.6976597309112549, "camel_36342": 0.6982245445251465, "aqua_rat_53788": 0.6985300183296204, "aqua_rat_50073": 0.6989130973815918, "aqua_rat_36983": 0.6994525194168091, "math_test_prealgebra_1034": 0.6995365023612976, "math_train_prealgebra_109": 0.6995439529418945, "aqua_rat_39765": 0.6996005773544312, "aqua_rat_38718": 0.6997281312942505, "aqua_rat_41228": 0.6999447345733643, "aqua_rat_33643": 0.7005627751350403, "aqua_rat_70146": 0.7006046772003174, "aqua_rat_15630": 0.7007737755775452, "TheoremQA_jianyu_xu/pigeonhole_3.json": 0.7013117074966431, "math_train_counting_and_probability_5123": 0.7022096514701843, "aqua_rat_40888": 0.7027223706245422, "aqua_rat_64140": 0.7039811611175537, "math_train_counting_and_probability_5119": 0.7046616077423096, "aqua_rat_15442": 0.7049465775489807, "aqua_rat_30343": 0.7049885988235474, "aqua_rat_26962": 0.7059217095375061, "aqua_rat_73560": 0.7066609859466553, "aqua_rat_26254": 0.7067979574203491, "aqua_rat_29842": 0.7068163156509399, "aqua_rat_49308": 0.7068923711776733, "aqua_rat_6737": 0.7077403664588928, "math_test_counting_and_probability_686": 0.7079141736030579, "aqua_rat_7964": 0.7081571221351624, "math_train_prealgebra_325": 0.7096880078315735, "aqua_rat_16788": 0.7099575996398926, "math_train_counting_and_probability_667": 0.7106272578239441, "aqua_rat_84115": 0.7106332182884216, "aqua_rat_55950": 0.7109825611114502, "aqua_rat_25753": 0.7113702297210693, "aqua_rat_44416": 0.7120453715324402, "aqua_rat_52213": 0.7120659351348877, "aqua_rat_70004": 0.712395191192627, "aqua_rat_69238": 0.7125352025032043, "aqua_rat_86896": 0.7125864028930664, "aqua_rat_80224": 0.7126926183700562, "math_train_counting_and_probability_617": 0.7128585577011108, "aqua_rat_27636": 0.7129549980163574, "aqua_rat_23524": 0.7130621671676636, "math_train_prealgebra_1573": 0.7133219242095947, "aqua_rat_32341": 0.7135042548179626, "aqua_rat_15480": 0.7151415348052979, "aqua_rat_66460": 0.7152712941169739, "aqua_rat_13831": 0.715890645980835, "aqua_rat_64699": 0.7159430980682373, "aqua_rat_20302": 0.7160535454750061, "aqua_rat_62094": 0.7161340713500977, "math_train_prealgebra_1917": 0.7161879539489746, "aqua_rat_17862": 0.7167184352874756, "aqua_rat_30710": 0.7172269821166992, "aqua_rat_83796": 0.7176265120506287, "aqua_rat_87294": 0.717995822429657, "aqua_rat_7521": 0.7180322408676147, "aqua_rat_22669": 0.7180444002151489, "aqua_rat_149": 0.7183472514152527, "aqua_rat_84086": 0.7183903455734253, "aqua_rat_74390": 0.718546450138092, "aqua_rat_73303": 0.7202584743499756, "aqua_rat_23636": 0.7204083204269409, "aqua_rat_48028": 0.7206087112426758, "aqua_rat_84469": 0.7209091782569885, "aqua_rat_50597": 0.7213867902755737, "aqua_rat_40065": 0.7217982411384583, "aqua_rat_87746": 0.721851110458374, "aqua_rat_33710": 0.7226611375808716, "aqua_rat_34164": 0.7228953242301941, "aqua_rat_34677": 0.7236694693565369, "aqua_rat_80435": 0.7239060401916504, "aqua_rat_63041": 0.7241467237472534, "aqua_rat_17359": 0.7252752780914307, "aqua_rat_53649": 0.7281901240348816, "camel_36505": 0.7282336354255676, "aqua_rat_76356": 0.7284091711044312, "aqua_rat_71213": 0.7286966443061829, "aqua_rat_67387": 0.7294324040412903, "aqua_rat_6686": 0.7302510738372803, "aqua_rat_78018": 0.7305247187614441, "aqua_rat_38285": 0.7318100333213806, "aqua_rat_20004": 0.7326256036758423, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0.7330068349838257, "aqua_rat_24238": 0.734083354473114, "aqua_rat_47084": 0.7349538207054138, "aqua_rat_59053": 0.7370584011077881, "math_test_counting_and_probability_341": 0.7382335066795349, "aqua_rat_70890": 0.7388793230056763, "aqua_rat_29990": 0.7394380569458008, "aqua_rat_48010": 0.7406416535377502, "aqua_rat_14782": 0.7406653761863708, "aqua_rat_65028": 0.7420777678489685, "aqua_rat_80759": 0.7432957291603088, "aqua_rat_39271": 0.7450488805770874, "TheoremQA_jianyu_xu/Ramsey_3.json": 0.7706159353256226}, "TheoremQA_wenhuchen/viterbi2.json": {"camel_9448": 0, "camel_8757": 0, "math_test_counting_and_probability_727": 0, "math_train_counting_and_probability_97": 0, "camel_9480": 0, "camel_9479": 0, "camel_9513": 0, "camel_9262": 0, "camel_8790": 0, "camel_9452": 0, "camel_9487": 0, "camel_8777": 0, "camel_9482": 0, "camel_8741": 0, "math_train_counting_and_probability_81": 0, "camel_9505": 0, "camel_9511": 0, "camel_9500": 0, "camel_9445": 0, "camel_9516": 0, "camel_9502": 0, "camel_9506": 0, "camel_9476": 0, "camel_9495": 0, "camel_9453": 0, "camel_8727": 0, "camel_8784": 0, "camel_9497": 0, "camel_9489": 0, "camel_8774": 0, "camel_9441": 0, "TheoremQA_wenhuchen/viterbi2.json": 0, "camel_9508": 0, "camel_9481": 0, "camel_9496": 0, "camel_9491": 0, "camel_9471": 0, "camel_9461": 0, "camel_9514": 0, "camel_9517": 0, "camel_9446": 0, "camel_9503": 0, "camel_8723": 0, "math_train_counting_and_probability_557": 0, "camel_9447": 0, "camel_9477": 0, "camel_9464": 0, "camel_9485": 0, "camel_9454": 0, "camel_37612": 0.7655888795852661, "aqua_rat_64548": 0.7656311988830566, "camel_11792": 0.7658620476722717, "camel_24661": 0.7661247253417969, "aqua_rat_36135": 0.7661856412887573, "aqua_rat_42842": 0.766194760799408, "aqua_rat_54177": 0.7664114832878113, "aqua_rat_81825": 0.7664543986320496, "camel_10888": 0.7665148973464966, "aqua_rat_64138": 0.7665792107582092, "camel_25435": 0.766605794429779, "camel_36530": 0.7666345238685608, "aqua_rat_3261": 0.7667681574821472, "aqua_rat_32748": 0.7672861218452454, "camel_24422": 0.7677310705184937, "camel_37861": 0.7677779793739319, "camel_39439": 0.7678363919258118, "camel_24242": 0.7678467035293579, "camel_24680": 0.7683563828468323, "camel_25434": 0.768385112285614, "camel_25413": 0.7687316536903381, "camel_37631": 0.7689709663391113, "aqua_rat_88602": 0.7691611647605896, "camel_24718": 0.7692486643791199, "camel_37823": 0.7692778706550598, "camel_25364": 0.7693303823471069, "camel_36361": 0.7696324586868286, "camel_25254": 0.7698772549629211, "camel_24675": 0.7705639004707336, "aqua_rat_79335": 0.7705973982810974, "camel_36345": 0.7709470391273499, "aqua_rat_80201": 0.7710893154144287, "camel_25419": 0.7713136672973633, "camel_11449": 0.7715776562690735, "camel_24659": 0.7719964981079102, "camel_36523": 0.7721555829048157, "camel_24640": 0.7726449370384216, "camel_24650": 0.7728597521781921, "camel_25385": 0.773077130317688, "camel_25401": 0.7731832265853882, "aqua_rat_11482": 0.7732064723968506, "camel_11869": 0.7733878493309021, "camel_25505": 0.7734383344650269, "camel_25410": 0.7737444043159485, "camel_24688": 0.7738602757453918, "aqua_rat_14596": 0.7738653421401978, "camel_24678": 0.7740542888641357, "aqua_rat_20380": 0.7741442918777466, "camel_24671": 0.7741797566413879, "camel_24643": 0.7742151021957397, "aqua_rat_29721": 0.7742487192153931, "camel_10622": 0.7742632627487183, "camel_25485": 0.7751550078392029, "camel_28142": 0.7753391861915588, "camel_25358": 0.7754206657409668, "camel_24716": 0.7759896516799927, "camel_37842": 0.77606600522995, "camel_39391": 0.776109516620636, "camel_36519": 0.7761811017990112, "camel_10937": 0.7763444781303406, "camel_37859": 0.7765281200408936, "aqua_rat_71874": 0.7768742442131042, "aqua_rat_63293": 0.7771099209785461, "camel_25508": 0.7772553563117981, "aqua_rat_40444": 0.7778346538543701, "camel_37849": 0.7778730988502502, "camel_24683": 0.7779210805892944, "camel_25892": 0.7779759764671326, "camel_24656": 0.7782438397407532, "camel_25396": 0.7785264849662781, "aqua_rat_60327": 0.778598964214325, "camel_25407": 0.7788346409797668, "aqua_rat_86042": 0.778857409954071, "camel_37875": 0.7791575789451599, "aqua_rat_58885": 0.7797316312789917, "aqua_rat_85293": 0.7804277539253235, "aqua_rat_37698": 0.7808752655982971, "camel_25353": 0.780933678150177, "aqua_rat_50510": 0.7811060547828674, "camel_37946": 0.7811443209648132, "camel_39375": 0.7812706828117371, "camel_24652": 0.7814674377441406, "camel_24660": 0.7818796634674072, "aqua_rat_47751": 0.7821016311645508, "camel_25303": 0.7829877138137817, "camel_25420": 0.7838278412818909, "camel_36384": 0.7843143343925476, "aqua_rat_10224": 0.7849588394165039, "aqua_rat_61684": 0.7849798798561096, "aqua_rat_69941": 0.7849997282028198, "aqua_rat_41204": 0.7851517796516418, "aqua_rat_6577": 0.7857289910316467, "aqua_rat_42825": 0.78610759973526, "camel_36276": 0.7861804962158203, "aqua_rat_37772": 0.786247968673706, "aqua_rat_17728": 0.7863115668296814, "aqua_rat_80730": 0.7863124012947083, "camel_24693": 0.7863450050354004, "aqua_rat_21944": 0.7864925265312195, "aqua_rat_87308": 0.7866687178611755, "aqua_rat_65962": 0.78714519739151, "camel_10568": 0.7877702116966248, "camel_37912": 0.7879243493080139, "aqua_rat_8224": 0.7880426645278931, "aqua_rat_44578": 0.7882821559906006, "camel_36399": 0.7888919115066528, "camel_36330": 0.7892255187034607, "camel_25515": 0.7894193530082703, "camel_25403": 0.7895829081535339, "aqua_rat_50672": 0.7904331088066101, "camel_25517": 0.7907280325889587, "aqua_rat_45407": 0.7927209734916687, "camel_25423": 0.7928637266159058, "camel_36368": 0.7937591075897217, "aqua_rat_61314": 0.7937947511672974, "camel_24709": 0.7941033244132996, "TheoremQA_wenhuchen/viterbi1.json": 0.794253945350647, "aqua_rat_38490": 0.7949254512786865, "camel_25404": 0.7949619293212891, "camel_25361": 0.7954268455505371, "camel_25462": 0.7956238985061646, "aqua_rat_50853": 0.7961772680282593, "camel_24711": 0.796255350112915, "camel_11796": 0.7965811491012573, "camel_37907": 0.7973313331604004, "camel_36388": 0.8006273508071899, "aqua_rat_14944": 0.802570641040802, "aqua_rat_75801": 0.8028465509414673, "camel_11619": 0.8031830787658691, "camel_36358": 0.8033892512321472, "camel_24654": 0.8038130402565002, "camel_25494": 0.8043843507766724, "camel_25478": 0.8044461607933044, "camel_25471": 0.806608259677887, "camel_25405": 0.8068379163742065, "aqua_rat_67820": 0.806956946849823, "aqua_rat_84401": 0.807105541229248, "camel_25284": 0.808134913444519, "aqua_rat_69505": 0.808170735836029, "aqua_rat_30573": 0.8086037635803223, "camel_24714": 0.808604896068573, "camel_25447": 0.8091047406196594, "aqua_rat_71018": 0.8092871904373169, "aqua_rat_2646": 0.8096295595169067, "aqua_rat_73156": 0.8098758459091187, "aqua_rat_87100": 0.8102154731750488, "camel_25438": 0.8104745149612427, "aqua_rat_86707": 0.8130936026573181, "aqua_rat_51142": 0.8137614130973816, "camel_10635": 0.8248120546340942, "camel_10639": 0.8345160484313965}, "TheoremQA_panlu/molar_heat_capacity1.json": {"TheoremQA_panlu/molar_heat_capacity1.json": 0, "gsm_rft_12805": 0.5498402118682861, "aqua_rat_78143": 0.5499254465103149, "gsm_rft_27697": 0.5501375198364258, "gsm_rft_572": 0.550147533416748, "camel_16175": 0.5503135919570923, "aqua_rat_62599": 0.5505313873291016, "gsm_rft_20590": 0.550669252872467, "aqua_rat_41833": 0.5508114695549011, "gsm_rft_34322": 0.5508425831794739, "gsm_rft_20286": 0.550919771194458, "gsm_rft_26756": 0.5509528517723083, "gsm_train_8091": 0.5510438084602356, "aqua_rat_82279": 0.5512999892234802, "gsm_rft_6094": 0.5514315366744995, "gsm_rft_23514": 0.5514920949935913, "aqua_rat_24899": 0.5515432953834534, "aqua_rat_70628": 0.5515601634979248, "gsm_rft_16550": 0.5516548752784729, "gsm_train_8842": 0.551674485206604, "gsm_rft_32549": 0.5517113208770752, "gsm_train_8964": 0.5517113208770752, "aqua_rat_35656": 0.5518177151679993, "aqua_rat_43732": 0.5521900653839111, "aqua_rat_40134": 0.552198052406311, "gsm_rft_25341": 0.552263081073761, "aqua_rat_76816": 0.5523149967193604, "gsm_train_6841": 0.5525591373443604, "gsm_rft_3840": 0.5526114702224731, "gsm_rft_19860": 0.5526620745658875, "aqua_rat_30350": 0.5526646971702576, "gsm_train_10943": 0.5526683330535889, "aqua_rat_72055": 0.5527541041374207, "aqua_rat_55426": 0.5529303550720215, "gsm_rft_25245": 0.553066074848175, "aqua_rat_47720": 0.5530661344528198, "aqua_rat_64638": 0.5531504154205322, "aqua_rat_33202": 0.5531525015830994, "gsm_rft_3968": 0.5531814694404602, "aqua_rat_32205": 0.553200900554657, "gsm_rft_31280": 0.5532127618789673, "gsm_train_10396": 0.5532127618789673, "gsm_rft_478": 0.5534477233886719, "gsm_rft_5754": 0.5535544157028198, "gsm_rft_31420": 0.5537687540054321, "gsm_train_11287": 0.553775429725647, "gsm_rft_10701": 0.553775429725647, "gsm_train_22933": 0.5538317561149597, "aqua_rat_34926": 0.5538827180862427, "gsm_rft_34553": 0.5541020631790161, "gsm_rft_14948": 0.5541663765907288, "aqua_rat_82073": 0.5541800856590271, "gsm_rft_28024": 0.5542845129966736, "gsm_rft_17953": 0.5542845129966736, "aqua_rat_46000": 0.5543215870857239, "gsm_rft_18983": 0.5544084906578064, "camel_16209": 0.5544821619987488, "gsm_rft_1232": 0.5544888377189636, "gsm_train_11268": 0.5544888377189636, "TheoremQA_tonyxia/semiconductor1.json": 0.5546066761016846, "aqua_rat_56252": 0.5548104643821716, "gsm_rft_24775": 0.5549606680870056, "aqua_rat_50273": 0.5551763772964478, "aqua_rat_23467": 0.5552608370780945, "gsm_rft_13692": 0.5553731918334961, "gsm_rft_14519": 0.5555998682975769, "aqua_rat_45859": 0.5556554198265076, "aqua_rat_66241": 0.5558515787124634, "gsm_rft_18537": 0.5558668971061707, "gsm_rft_14784": 0.5558990836143494, "gsm_rft_12897": 0.5560681819915771, "aqua_rat_9626": 0.5561266541481018, "aqua_rat_79036": 0.5562570095062256, "aqua_rat_18519": 0.5562732815742493, "gsm_rft_7211": 0.5563341379165649, "aqua_rat_72520": 0.5563986301422119, "aqua_rat_23056": 0.5567913055419922, "aqua_rat_22936": 0.556881308555603, "aqua_rat_5019": 0.5569021701812744, "aqua_rat_470": 0.5570316910743713, "gsm_rft_24094": 0.5570729970932007, "gsm_train_10381": 0.5570729970932007, "aqua_rat_49469": 0.5570918321609497, "camel_16217": 0.5571257472038269, "aqua_rat_79178": 0.5571635961532593, "aqua_rat_53252": 0.5572714805603027, "aqua_rat_55150": 0.5573886632919312, "aqua_rat_42735": 0.5574879050254822, "aqua_rat_29162": 0.5576655268669128, "gsm_rft_6327": 0.5577484965324402, "aqua_rat_89310": 0.5578166246414185, "gsm_rft_22127": 0.5578349828720093, "camel_16179": 0.5578892230987549, "gsm_rft_14007": 0.5580309629440308, "aqua_rat_52083": 0.5580490827560425, "gsm_rft_22445": 0.5582773685455322, "gsm_train_11745": 0.5583910942077637, "gsm_rft_10274": 0.5583910942077637, "aqua_rat_13478": 0.5584906339645386, "aqua_rat_88150": 0.558626651763916, "gsm_rft_26243": 0.558668851852417, "aqua_rat_37420": 0.5586788058280945, "aqua_rat_64107": 0.5587087273597717, "aqua_rat_54949": 0.5589715242385864, "aqua_rat_73348": 0.5594015121459961, "aqua_rat_81955": 0.559731125831604, "gsm_rft_24257": 0.5597888827323914, "aqua_rat_38750": 0.5599150657653809, "gsm_rft_23284": 0.5600619912147522, "gsm_rft_9556": 0.5601940155029297, "gsm_rft_33282": 0.560767412185669, "gsm_rft_24393": 0.560967206954956, "gsm_train_34664": 0.560967206954956, "aqua_rat_76629": 0.5610353350639343, "aqua_rat_49591": 0.5611463785171509, "aqua_rat_43686": 0.561381459236145, "gsm_rft_22401": 0.5615593194961548, "aqua_rat_47102": 0.5617513656616211, "gsm_rft_15366": 0.5617830157279968, "aqua_rat_55213": 0.5618683099746704, "aqua_rat_84479": 0.5625621676445007, "aqua_rat_65923": 0.5625647902488708, "gsm_rft_23705": 0.5627409815788269, "aqua_rat_16106": 0.5628248453140259, "gsm_rft_14462": 0.5633707642555237, "gsm_rft_19423": 0.5633707642555237, "gsm_train_15924": 0.5633707642555237, "gsm_rft_14019": 0.5636427402496338, "aqua_rat_3837": 0.5637200474739075, "camel_28081": 0.5637863278388977, "aqua_rat_12100": 0.5641189813613892, "aqua_rat_30120": 0.5651893615722656, "gsm_rft_28691": 0.5653772950172424, "aqua_rat_70908": 0.5654975771903992, "gsm_rft_25936": 0.5661358833312988, "gsm_rft_8176": 0.5661597847938538, "aqua_rat_46260": 0.5668047666549683, "gsm_rft_31346": 0.5669367909431458, "aqua_rat_26686": 0.5676802396774292, "gsm_train_8512": 0.567801833152771, "gsm_rft_10941": 0.567801833152771, "gsm_rft_18791": 0.5681192278862, "camel_16223": 0.5684551000595093, "aqua_rat_29911": 0.5687198042869568, "gsm_train_8166": 0.5692059397697449, "gsm_rft_20284": 0.5692769289016724, "aqua_rat_75356": 0.5706867575645447, "aqua_rat_71792": 0.5724146366119385, "aqua_rat_56411": 0.5726268291473389, "aqua_rat_73234": 0.5727310180664062, "gsm_rft_10857": 0.5750805735588074, "gsm_train_232": 0.5750805735588074, "gsm_rft_34578": 0.5753341317176819, "aqua_rat_72360": 0.5776466131210327, "aqua_rat_32250": 0.5813592672348022, "camel_16169": 0.5816682577133179, "aqua_rat_48607": 0.5841492414474487, "gsm_train_23183": 0.5848460793495178, "gsm_rft_28838": 0.5852163434028625, "gsm_rft_28746": 0.5852735042572021, "gsm_rft_2592": 0.5861309766769409, "aqua_rat_47999": 0.5862425565719604, "aqua_rat_12763": 0.5880706906318665, "aqua_rat_3199": 0.5885923504829407, "gsm_rft_7862": 0.5886289477348328, "gsm_rft_3972": 0.5902946591377258, "aqua_rat_25759": 0.5910556316375732, "aqua_rat_75763": 0.5912206768989563, "aqua_rat_38504": 0.5927722454071045, "gsm_rft_21326": 0.5928897857666016, "aqua_rat_31644": 0.5955460071563721, "gsm_rft_6591": 0.5963186621665955, "gsm_train_4193": 0.5963186621665955, "gsm_rft_35104": 0.5964822173118591, "gsm_train_10153": 0.5968335270881653, "aqua_rat_44185": 0.5975480675697327, "gsm_rft_22822": 0.5975880026817322, "gsm_rft_21213": 0.5979459285736084, "camel_37933": 0.5989184975624084, "aqua_rat_27001": 0.6015163660049438, "aqua_rat_68302": 0.6015189290046692, "aqua_rat_16313": 0.6045091152191162, "aqua_rat_1653": 0.6066675186157227, "aqua_rat_23539": 0.6066960692405701, "aqua_rat_14988": 0.6068150997161865, "aqua_rat_41829": 0.6084346771240234, "aqua_rat_55821": 0.6092584133148193, "aqua_rat_64101": 0.610683023929596, "gsm_rft_23914": 0.6126930713653564, "aqua_rat_7630": 0.6130003333091736, "aqua_rat_21803": 0.6140625476837158, "TheoremQA_tonyxia/statisticalphysics2.json": 0.6141828298568726, "camel_17587": 0.6145723462104797, "aqua_rat_21090": 0.6180111765861511, "aqua_rat_28949": 0.624739408493042, "aqua_rat_8480": 0.6278297901153564, "camel_28151": 0.7300711274147034, "camel_45925": 0.7503023147583008, "camel_37984": 0.7831020355224609, "TheoremQA_panlu/molar_heat_capacity2.json": 0.8319055438041687}, "TheoremQA_elainewan/math_algebra_3_2.json": {"TheoremQA_elainewan/math_algebra_3_2.json": 0, "camel_15605": 0, "camel_14303": 0, "camel_15632": 0, "camel_15869": 0, "camel_15980": 0, "camel_15983": 0, "camel_15944": 0, "camel_15925": 0, "camel_15967": 0, "camel_15629": 0, "camel_15608": 0, "camel_15895": 0, "camel_15855": 0, "camel_15738": 0, "camel_15679": 0, "camel_15901": 0, "camel_15933": 0, "camel_14249": 0, "camel_15634": 0, "camel_15845": 0, "camel_15906": 0, "camel_15992": 0, "camel_15872": 0, "camel_15651": 0, "camel_15868": 0, "camel_15307": 0, "camel_15852": 0, "camel_15911": 0, "camel_15674": 0, "camel_15846": 0, "camel_15913": 0, "camel_15883": 0, "camel_15916": 0, "camel_14261": 0, "camel_15899": 0, "camel_15575": 0, "camel_15612": 0, "camel_15990": 0, "camel_15613": 0, "camel_15853": 0, "camel_15532": 0, "camel_15896": 0, "camel_15857": 0, "camel_15876": 0, "camel_15918": 0, "camel_14274": 0, "camel_15607": 0, "camel_14250": 0, "camel_15890": 0, "camel_14312": 0, "camel_15729": 0, "camel_15848": 0, "camel_15620": 0, "camel_15879": 0, "camel_14297": 0, "camel_15631": 0, "camel_14241": 0, "camel_15922": 0, "camel_15884": 0, "math_test_algebra_1586": 0, "camel_15615": 0, "camel_15878": 0, "camel_15882": 0, "camel_15904": 0, "camel_15661": 0, "camel_15603": 0, "camel_15859": 0, "camel_15601": 0, "camel_15897": 0, "camel_15886": 0, "camel_5921": 0.7033641934394836, "math_test_precalculus_100": 0.7035405039787292, "camel_5930": 0.7035807967185974, "camel_5758": 0.7035893797874451, "aqua_rat_49771": 0.7036004066467285, "math_train_precalculus_865": 0.7036027908325195, "math_train_geometry_332": 0.7037206292152405, "camel_5626": 0.7039313912391663, "camel_5672": 0.704069197177887, "gsm_rft_10726": 0.7042686343193054, "camel_49882": 0.7048876285552979, "camel_47291": 0.7051904201507568, "math_train_precalculus_955": 0.7053083777427673, "camel_5833": 0.7056305408477783, "camel_5942": 0.7062482833862305, "aqua_rat_65557": 0.7066811323165894, "camel_49692": 0.7068716287612915, "camel_5765": 0.7070267796516418, "camel_5818": 0.7073042988777161, "gsm_rft_9028": 0.7074611783027649, "gsm_train_2988": 0.7074611783027649, "camel_5788": 0.7075028419494629, "camel_5662": 0.7076231837272644, "camel_5962": 0.7079804539680481, "math_train_counting_and_probability_5052": 0.7080228328704834, "camel_18683": 0.7081415057182312, "camel_5836": 0.7081975936889648, "camel_5861": 0.7085622549057007, "math_test_precalculus_716": 0.7089235186576843, "camel_5876": 0.7090129852294922, "camel_5762": 0.7092071175575256, "math_train_geometry_426": 0.7093278169631958, "camel_48226": 0.709568202495575, "math_train_precalculus_1173": 0.7101379632949829, "camel_5938": 0.7103137969970703, "gsm_rft_9056": 0.7104659676551819, "camel_49899": 0.7105657458305359, "camel_5767": 0.7108385562896729, "camel_5834": 0.7109770178794861, "camel_5622": 0.711277425289154, "camel_5838": 0.711422324180603, "camel_5825": 0.7114908695220947, "math_train_precalculus_1206": 0.7115101218223572, "camel_5786": 0.7121322751045227, "camel_5760": 0.7122687101364136, "camel_5759": 0.7123145461082458, "camel_48210": 0.7125122547149658, "camel_5955": 0.7128375172615051, "camel_5705": 0.7128562927246094, "math_test_precalculus_840": 0.7130079865455627, "math_test_precalculus_659": 0.7131944894790649, "camel_5822": 0.7137320637702942, "camel_5704": 0.7145301699638367, "math_train_precalculus_284": 0.7148323655128479, "camel_5983": 0.7149114608764648, "math_test_precalculus_1172": 0.7154068946838379, "camel_47348": 0.7157626748085022, "camel_5779": 0.7158567905426025, "camel_5809": 0.7162439227104187, "aqua_rat_78360": 0.7165822386741638, "TheoremQA_mingyin/gaussian-elimination2.json": 0.7167385220527649, "math_test_precalculus_102": 0.7168879508972168, "camel_5803": 0.7174856066703796, "camel_5785": 0.7177942991256714, "camel_5819": 0.7180356979370117, "camel_5835": 0.7185181975364685, "aqua_rat_68080": 0.7190287113189697, "camel_5645": 0.7194182872772217, "math_test_precalculus_184": 0.7199333906173706, "math_train_precalculus_978": 0.7206231951713562, "math_test_geometry_781": 0.7206341624259949, "camel_49253": 0.7214065194129944, "camel_5781": 0.7222015857696533, "camel_5903": 0.7223588228225708, "math_test_counting_and_probability_990": 0.7229281067848206, "camel_5739": 0.723230242729187, "camel_5768": 0.723433792591095, "camel_5824": 0.723481297492981, "math_train_precalculus_665": 0.7261282205581665, "aqua_rat_14551": 0.7264253497123718, "math_train_precalculus_11": 0.7270471453666687, "math_test_precalculus_802": 0.7276023626327515, "math_train_precalculus_618": 0.7279580235481262, "math_train_precalculus_410": 0.7280353307723999, "camel_5812": 0.7283466458320618, "TheoremQA_elainewan/math_algebra_3_4.json": 0.7290753722190857, "camel_5859": 0.7294732928276062, "math_train_precalculus_448": 0.7298594117164612, "camel_49146": 0.7302272319793701, "camel_48218": 0.7303141951560974, "camel_5766": 0.7305226922035217, "math_train_precalculus_593": 0.7307775616645813, "camel_48219": 0.7310020923614502, "camel_5778": 0.731764018535614, "math_test_precalculus_927": 0.7320137619972229, "camel_5771": 0.7321375608444214, "camel_5807": 0.7326551675796509, "camel_49417": 0.7333106398582458, "camel_5804": 0.7346769571304321, "aqua_rat_67418": 0.7346794009208679, "TheoremQA_elainewan/math_algebra_3.json": 0.7349125742912292, "camel_5791": 0.7349435091018677, "camel_5832": 0.7352805733680725, "camel_5801": 0.7355495095252991, "camel_5795": 0.7369349598884583, "math_test_precalculus_644": 0.7379392385482788, "camel_5828": 0.7387011051177979, "camel_5805": 0.7393643260002136, "camel_48234": 0.7408967018127441, "camel_36766": 0.7415298819541931, "camel_5831": 0.7416176795959473, "camel_5683": 0.7447441816329956, "aqua_rat_70287": 0.7466062903404236, "camel_48074": 0.7467736601829529, "math_train_precalculus_1107": 0.7477841377258301, "math_train_precalculus_1010": 0.7480669617652893, "camel_19702": 0.7509965896606445, "camel_5870": 0.7519739270210266, "camel_49121": 0.7555089592933655, "camel_49141": 0.7571632862091064, "camel_49165": 0.7575667500495911, "camel_5823": 0.7602644562721252, "camel_49126": 0.762450098991394, "camel_49173": 0.7671995162963867, "camel_49182": 0.7711744904518127, "math_test_geometry_167": 0.7730368375778198, "camel_5772": 0.7746493816375732, "camel_49180": 0.7788020372390747, "camel_49168": 0.7908146977424622}, "TheoremQA_elainewan/math_calculus_12.json": {"camel_7035": 0, "camel_7032": 0, "camel_6194": 0, "camel_7024": 0, "camel_7949": 0, "camel_7690": 0, "camel_7963": 0, "camel_7508": 0, "camel_6185": 0, "camel_6182": 0, "camel_7682": 0, "camel_7745": 0, "camel_7519": 0, "camel_7016": 0, "camel_6175": 0, "camel_7727": 0, "camel_6229": 0, "camel_7737": 0, "camel_6211": 0, "camel_7958": 0, "camel_7741": 0, "camel_7927": 0, "camel_7681": 0, "camel_7021": 0, "camel_6210": 0, "camel_6199": 0, "camel_6222": 0, "camel_7740": 0, "camel_7688": 0, "camel_7188": 0, "camel_6217": 0, "camel_7721": 0, "camel_6223": 0, "camel_7488": 0, "camel_7990": 0, "camel_6166": 0, "camel_7935": 0, "camel_6998": 0, "camel_7720": 0, "camel_6183": 0, "camel_7716": 0, "camel_6167": 0, "camel_7730": 0, "camel_7970": 0, "camel_6161": 0, "camel_7696": 0, "camel_7986": 0, "camel_7719": 0, "camel_7495": 0, "camel_7698": 0, "camel_7026": 0, "camel_7967": 0, "camel_6518": 0, "camel_7953": 0, "camel_7686": 0, "camel_6197": 0, "camel_6192": 0, "camel_6309": 0, "camel_6224": 0, "camel_6970": 0, "camel_7729": 0, "camel_6204": 0, "camel_6976": 0, "camel_6218": 0, "camel_7004": 0, "camel_7962": 0, "camel_7478": 0, "camel_7920": 0, "camel_6164": 0, "camel_6165": 0, "camel_7725": 0, "camel_7961": 0, "camel_7931": 0, "camel_6179": 0, "camel_7987": 0, "camel_7019": 0, "camel_6237": 0, "camel_7979": 0, "camel_6202": 0, "camel_6196": 0, "camel_7940": 0, "camel_7484": 0, "TheoremQA_elainewan/math_calculus_12.json": 0, "camel_40788": 0.7870187163352966, "camel_38931": 0.7871311902999878, "camel_38205": 0.7871911525726318, "camel_29979": 0.7872146964073181, "camel_410": 0.7872851490974426, "camel_38237": 0.7873636484146118, "camel_1733": 0.7875466346740723, "camel_39120": 0.7875874042510986, "camel_39186": 0.7875946164131165, "camel_38105": 0.787740170955658, "camel_38942": 0.7879992723464966, "camel_39182": 0.7881842255592346, "camel_468": 0.7882838249206543, "camel_39321": 0.7884976267814636, "camel_448": 0.7888497114181519, "camel_1694": 0.7889607548713684, "camel_39187": 0.789154052734375, "camel_471": 0.7892807126045227, "camel_39595": 0.789718508720398, "camel_39250": 0.7900832295417786, "camel_38913": 0.7904542088508606, "camel_38232": 0.7906365394592285, "camel_39343": 0.7907376885414124, "camel_440": 0.7911745309829712, "camel_39125": 0.7913270592689514, "camel_38248": 0.791365921497345, "camel_39134": 0.7914800643920898, "math_train_algebra_1344": 0.7915651202201843, "camel_39121": 0.7918015718460083, "camel_466": 0.7919268012046814, "camel_39333": 0.792043924331665, "camel_39148": 0.7921314835548401, "camel_39145": 0.7922947406768799, "aqua_rat_88293": 0.7923958897590637, "camel_449": 0.7924418449401855, "camel_37999": 0.7927241921424866, "camel_39347": 0.7929263710975647, "math_test_algebra_1396": 0.7931138873100281, "camel_1708": 0.7931226491928101, "camel_39193": 0.7938090562820435, "camel_39179": 0.7940239906311035, "camel_38169": 0.7941269278526306, "camel_38954": 0.7941503524780273, "camel_465": 0.7943588495254517, "camel_39334": 0.7945441007614136, "camel_39177": 0.7945783138275146, "camel_39181": 0.7946017980575562, "camel_38121": 0.7948387861251831, "camel_39159": 0.7949644923210144, "camel_41967": 0.7949709296226501, "camel_39330": 0.7949755787849426, "camel_1696": 0.7951765060424805, "camel_39248": 0.795177698135376, "camel_423": 0.7957261204719543, "camel_39298": 0.7959429025650024, "camel_39136": 0.7961625456809998, "camel_427": 0.7972191572189331, "camel_413": 0.7974831461906433, "camel_39129": 0.797620415687561, "camel_39140": 0.7978854775428772, "camel_39183": 0.7979782819747925, "camel_39189": 0.7983256578445435, "camel_1757": 0.7986937165260315, "camel_39174": 0.7987467646598816, "camel_39578": 0.7987915277481079, "camel_39184": 0.7989850044250488, "camel_38162": 0.7998555898666382, "camel_38176": 0.800237238407135, "camel_39152": 0.801585853099823, "camel_39126": 0.8018090128898621, "camel_39358": 0.8019695281982422, "camel_39151": 0.8019717335700989, "camel_475": 0.8019728660583496, "camel_39548": 0.8020854592323303, "camel_39294": 0.8023166060447693, "camel_39130": 0.8023614883422852, "camel_39139": 0.8033698201179504, "camel_41904": 0.8038305640220642, "camel_39155": 0.8050429821014404, "camel_469": 0.805425763130188, "camel_39168": 0.8063146471977234, "camel_38215": 0.807890772819519, "camel_39511": 0.8082416653633118, "aqua_rat_66854": 0.8086645007133484, "camel_38141": 0.8094879388809204, "camel_39468": 0.8095504641532898, "camel_476": 0.8099910020828247, "camel_39335": 0.8101733922958374, "camel_39534": 0.8102290034294128, "camel_39579": 0.810426652431488, "camel_39251": 0.8137496709823608, "camel_39172": 0.8144842982292175, "camel_39544": 0.8163312077522278, "camel_38911": 0.8167931437492371, "camel_39176": 0.8187920451164246, "camel_39297": 0.8200778961181641, "camel_39164": 0.8206641674041748, "camel_39171": 0.821897029876709, "camel_39188": 0.8224281668663025, "camel_39194": 0.822592556476593, "camel_5016": 0.8260160684585571, "camel_39457": 0.8275998830795288, "camel_39466": 0.8277198076248169, "camel_39471": 0.8312399983406067, "camel_4996": 0.8328193426132202, "camel_39486": 0.8465786576271057, "aqua_rat_68267": 0.854297935962677, "aqua_rat_9643": 0.8560982346534729, "camel_28147": 0.8589137196540833, "camel_39441": 0.8622341156005859, "camel_39448": 0.8743487000465393, "camel_39312": 0.8744025230407715, "aqua_rat_57946": 0.8785775303840637, "camel_441": 0.8795278668403625, "camel_39483": 0.8821775317192078, "aqua_rat_48488": 0.8822668790817261, "aqua_rat_47425": 0.8831911087036133}, "TheoremQA_maxku/graphtheory7-shortestpath.json": {"camel_38576": 0, "camel_22023": 0, "camel_39968": 0, "camel_22811": 0, "camel_23952": 0, "camel_22008": 0, "camel_22072": 0, "camel_23924": 0, "camel_21606": 0, "camel_23989": 0, "camel_23933": 0, "camel_21620": 0, "camel_21675": 0, "camel_22400": 0, "camel_21626": 0, "camel_21647": 0, "camel_22026": 0, "camel_21635": 0, "camel_22818": 0, "camel_22061": 0, "camel_22073": 0, "camel_22368": 0, "camel_22826": 0, "camel_22954": 0, "camel_38481": 0, "camel_22044": 0, "camel_22027": 0, "camel_22875": 0, "camel_22868": 0, "camel_22850": 0, "camel_21610": 0, "camel_21654": 0, "camel_23961": 0, "camel_22039": 0, "camel_22768": 0, "camel_21622": 0, "camel_38575": 0, "camel_22354": 0, "camel_22435": 0, "camel_22005": 0, "camel_22466": 0, "camel_23947": 0, "camel_38611": 0, "camel_23940": 0, "camel_22332": 0, "camel_21621": 0, "camel_22806": 0, "camel_23990": 0, "camel_21639": 0, "camel_22344": 0, "camel_22074": 0, "camel_39977": 0, "camel_22001": 0, "camel_22288": 0, "camel_22841": 0, "camel_22076": 0, "camel_23957": 0, "camel_22252": 0, "camel_21672": 0, "camel_22251": 0, "camel_22062": 0, "camel_39978": 0, "camel_22324": 0, "camel_22870": 0, "camel_22029": 0, "camel_22920": 0, "camel_22266": 0, "camel_22038": 0, "camel_39970": 0, "camel_38584": 0, "camel_39987": 0, "camel_21633": 0, "camel_22054": 0, "camel_22855": 0, "camel_39940": 0, "camel_39983": 0, "camel_22295": 0, "camel_22064": 0, "camel_23976": 0, "camel_23068": 0, "camel_21646": 0, "camel_22049": 0, "camel_22067": 0, "camel_23966": 0, "camel_23192": 0, "camel_22461": 0, "camel_22016": 0, "camel_21607": 0, "camel_23938": 0, "camel_38572": 0, "camel_39975": 0, "camel_23997": 0, "camel_23968": 0, "camel_23963": 0, "camel_22367": 0, "camel_22814": 0, "camel_22417": 0, "camel_22442": 0, "camel_22414": 0, "camel_22017": 0, "camel_38491": 0, "camel_23973": 0, "camel_38501": 0, "camel_22003": 0, "camel_38622": 0, "camel_22041": 0, "camel_23971": 0, "camel_22033": 0, "camel_22306": 0, "camel_39997": 0, "camel_39959": 0, "camel_21628": 0, "camel_38619": 0, "camel_21658": 0, "camel_22276": 0, "camel_38621": 0, "camel_39954": 0, "camel_23981": 0, "camel_22300": 0, "camel_22057": 0, "camel_22036": 0, "camel_23979": 0, "camel_22449": 0, "camel_22361": 0, "camel_38630": 0, "camel_22040": 0, "camel_22035": 0, "camel_22009": 0, "camel_23980": 0, "camel_22847": 0, "camel_22066": 0, "camel_22844": 0, "camel_39927": 0, "camel_22000": 0, "camel_22443": 0, "camel_23967": 0, "camel_22330": 0, "camel_21663": 0, "camel_22438": 0, "camel_23184": 0, "camel_39982": 0, "camel_22043": 0, "camel_22296": 0, "camel_22004": 0, "camel_39938": 0, "camel_23982": 0, "camel_23955": 0, "camel_22885": 0, "camel_22474": 0, "camel_38581": 0, "camel_39931": 0, "camel_22075": 0, "camel_22059": 0, "camel_22846": 0, "camel_23920": 0, "camel_22813": 0, "camel_22463": 0, "camel_23926": 0, "camel_22403": 0, "camel_22809": 0, "camel_22022": 0, "camel_22011": 0, "camel_22068": 0, "camel_22010": 0, "camel_22432": 0, "camel_21678": 0, "TheoremQA_maxku/graphtheory7-shortestpath.json": 0, "camel_23985": 0, "camel_38560": 0, "camel_22053": 0, "camel_22440": 0, "camel_23935": 0, "camel_22046": 0, "camel_22024": 0, "camel_39960": 0, "camel_38609": 0, "camel_39999": 0, "camel_22015": 0, "camel_23942": 0, "camel_23923": 0, "camel_39996": 0, "camel_22031": 0, "camel_39920": 0, "camel_22069": 0, "camel_22433": 0, "camel_23143": 0, "camel_23922": 0, "camel_23930": 0, "camel_38489": 0, "camel_39974": 0, "camel_22467": 0, "camel_22071": 0, "camel_23193": 0, "camel_23998": 0, "camel_22060": 0, "camel_23127": 0, "camel_23960": 0, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0.7974012494087219, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": 0.8044335842132568, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0.8173708915710449}, "TheoremQA_elainewan/econ_micro_7.json": {"camel_25502": 0, "camel_25644": 0, "camel_25479": 0, "camel_24708": 0, "camel_24223": 0, "camel_24181": 0, "camel_25160": 0, "camel_24355": 0, "camel_25346": 0, "camel_25170": 0, "camel_25463": 0, "camel_25726": 0, "camel_24232": 0, "camel_25171": 0, "camel_24190": 0, "camel_25911": 0, "camel_24463": 0, "camel_25253": 0, "camel_25671": 0, "camel_25329": 0, "camel_25139": 0, "camel_25241": 0, "camel_24691": 0, "camel_24644": 0, "camel_24462": 0, "camel_25262": 0, "camel_24174": 0, "camel_25062": 0, "camel_24658": 0, "camel_25359": 0, "camel_25221": 0, "camel_25270": 0, "camel_24316": 0, "camel_24982": 0, "camel_25227": 0, "camel_25546": 0, "camel_25733": 0, "camel_25146": 0, "camel_24685": 0, "camel_24649": 0, "camel_25324": 0, "camel_24186": 0, "camel_25066": 0, "camel_25698": 0, "camel_25157": 0, "camel_24715": 0, "camel_24653": 0, "camel_25785": 0, "camel_24690": 0, "camel_24672": 0, "camel_25043": 0, "camel_24684": 0, "camel_24682": 0, "camel_24467": 0, "camel_25225": 0, "camel_25810": 0, "camel_25902": 0, "camel_24331": 0, "camel_25343": 0, "camel_25148": 0, "camel_25357": 0, "camel_25322": 0, "camel_24166": 0, "camel_24183": 0, "camel_25333": 0, "camel_25287": 0, "camel_25136": 0, "camel_25176": 0, "camel_24171": 0, "camel_25021": 0, "camel_24663": 0, "camel_25487": 0, "camel_25165": 0, "camel_24169": 0, "camel_25763": 0, "camel_24198": 0, "camel_25722": 0, "camel_25518": 0, "camel_24369": 0, "camel_25135": 0, "camel_25600": 0, "camel_24386": 0, "camel_24291": 0, "camel_24196": 0, "camel_25349": 0, "camel_25175": 0, "camel_24168": 0, "camel_24712": 0, "camel_25332": 0, "camel_25212": 0, "camel_24676": 0, "camel_25238": 0, "camel_25208": 0, "camel_24707": 0, "camel_24235": 0, "camel_25248": 0, "camel_25686": 0, "camel_25470": 0, "camel_25239": 0, "camel_25857": 0, "camel_25278": 0, "camel_25635": 0, "camel_25721": 0, "camel_24699": 0, "camel_25230": 0, "camel_25265": 0, "camel_25131": 0, "camel_25155": 0, "camel_24197": 0, "camel_25318": 0, "camel_25501": 0, "camel_25249": 0, "camel_25282": 0, "camel_25207": 0, "camel_25334": 0, "camel_25464": 0, "TheoremQA_elainewan/econ_micro_7.json": 0, "camel_25514": 0, "camel_25125": 0, "camel_25274": 0, "camel_25159": 0, "camel_25751": 0, "camel_25112": 0, "camel_25491": 0, "camel_25126": 0, "camel_24963": 0, "camel_25279": 0, "camel_25724": 0, "camel_25302": 0, "camel_24652": 0, "camel_25256": 0, "camel_25140": 0, "camel_25152": 0, "camel_25185": 0, "camel_24974": 0, "camel_25172": 0, "camel_25216": 0, "camel_25620": 0, "camel_24656": 0, "camel_25198": 0, "camel_24206": 0, "camel_25124": 0, "camel_25247": 0, "camel_25903": 0, "camel_24160": 0, "camel_25244": 0, "camel_25299": 0, "camel_25703": 0, "camel_25513": 0, "camel_25263": 0, "camel_25704": 0, "camel_25226": 0, "camel_25664": 0, "camel_24368": 0, "camel_25291": 0, "camel_25168": 0, "camel_25224": 0, "camel_25272": 0, "camel_25121": 0, "camel_25156": 0, "camel_25660": 0, "camel_24664": 0, "camel_25181": 0, "camel_25275": 0, "camel_25489": 0, "camel_24252": 0, "camel_25214": 0, "camel_25219": 0, "camel_25321": 0, "camel_25496": 0, "camel_24354": 0, "camel_25812": 0, "camel_25849": 0, "camel_25688": 0, "camel_25367": 0, "camel_25808": 0, "camel_25240": 0, "camel_25446": 0, "camel_25314": 0, "camel_24669": 0, "camel_37713": 0.6936755776405334, "camel_36361": 0.6938441395759583, "camel_37691": 0.6944214105606079, "camel_39397": 0.6951219439506531, "camel_37618": 0.6956306099891663, "camel_37716": 0.6962209939956665, "camel_37693": 0.6975822448730469, "camel_37676": 0.6985566020011902, "camel_38662": 0.6989150047302246, "camel_37742": 0.6991889476776123, "camel_39434": 0.6992290019989014, "camel_37680": 0.6996963620185852, "camel_37740": 0.7000176906585693, "camel_39363": 0.7040159106254578, "camel_37669": 0.7135011553764343, "camel_37701": 0.7173170447349548, "TheoremQA_elainewan/econ_micro_7_2.json": 0.7190809845924377, "camel_37741": 0.7245550751686096, "camel_37651": 0.743353545665741, "TheoremQA_elainewan/econ_micro_18.json": 0.756318211555481}, "TheoremQA_xinyi/dag_2.json": {"camel_22811": 0, "camel_22871": 0, "camel_23676": 0, "camel_23442": 0, "camel_23938": 0, "camel_22861": 0, "camel_23924": 0, "camel_23969": 0, "camel_23975": 0, "camel_23935": 0, "camel_22848": 0, "camel_23063": 0, "camel_22860": 0, "camel_23056": 0, "camel_22438": 0, "camel_23988": 0, "camel_23966": 0, "camel_22857": 0, "camel_22022": 0, "camel_23885": 0, "camel_22820": 0, "camel_23070": 0, "camel_23224": 0, "camel_23973": 0, "camel_23048": 0, "camel_22858": 0, "camel_22813": 0, "camel_23198": 0, "camel_22401": 0, "camel_22849": 0, "camel_22814": 0, "camel_23852": 0, "camel_21846": 0, "camel_23158": 0, "camel_22378": 0, "camel_22824": 0, "camel_23393": 0, "camel_22053": 0, "camel_23976": 0, "camel_23989": 0, "camel_23932": 0, "camel_23046": 0, "camel_22875": 0, "camel_23113": 0, "camel_22802": 0, "camel_23201": 0, "camel_23085": 0, "camel_22865": 0, "camel_23928": 0, "camel_23051": 0, "camel_23661": 0, "camel_21107": 0, "camel_23177": 0, "camel_23119": 0, "camel_22859": 0, "camel_23089": 0, "camel_23069": 0, "camel_23221": 0, "camel_23098": 0, "camel_22850": 0, "camel_23931": 0, "camel_22463": 0, "camel_21100": 0, "camel_22583": 0, "camel_22461": 0, "camel_22863": 0, "camel_22579": 0, "camel_22804": 0, "camel_23181": 0, "camel_23076": 0, "camel_23074": 0, "camel_22433": 0, "camel_22879": 0, "camel_22608": 0, "camel_23958": 0, "camel_22398": 0, "camel_23998": 0, "camel_23335": 0, "camel_23997": 0, "camel_22557": 0, "camel_23196": 0, "camel_23055": 0, "camel_22628": 0, "camel_23077": 0, "camel_23062": 0, "camel_22840": 0, "camel_22826": 0, "camel_22866": 0, "camel_22803": 0, "camel_22801": 0, "camel_23071": 0, "camel_22832": 0, "camel_23097": 0, "camel_22847": 0, "camel_23612": 0, "camel_23971": 0, "camel_22443": 0, "camel_22466": 0, "camel_23672": 0, "camel_22816": 0, "camel_22397": 0, "camel_22862": 0, "camel_22854": 0, "camel_23934": 0, "camel_22573": 0, "camel_22835": 0, "camel_23114": 0, "camel_22442": 0, "camel_22345": 0, "camel_23067": 0, "camel_23075": 0, "camel_22809": 0, "camel_21064": 0, "camel_23423": 0, "camel_22807": 0, "camel_22853": 0, "camel_23068": 0, "camel_22400": 0, "camel_23060": 0, "camel_22844": 0, "camel_23090": 0, "TheoremQA_xinyi/dag_2.json": 0, "camel_22806": 0, "camel_22387": 0, "camel_22808": 0, "camel_22805": 0, "camel_22440": 0, "camel_23985": 0, "camel_23083": 0, "camel_22828": 0, "camel_22867": 0, "camel_23093": 0, "camel_23059": 0, "camel_23052": 0, "camel_23944": 0, "camel_23065": 0, "camel_22061": 0, "camel_22843": 0, "camel_22068": 0, "camel_22462": 0, "camel_22361": 0, "camel_23933": 0, "camel_22432": 0, "camel_22868": 0, "camel_23112": 0, "camel_22417": 0, "camel_22876": 0, "camel_22812": 0, "camel_22823": 0, "camel_23364": 0, "camel_23103": 0, "camel_23058": 0, "camel_22855": 0, "camel_23939": 0, "camel_23106": 0, "camel_23391": 0, "camel_23613": 0, "camel_23143": 0, "camel_22841": 0, "camel_23084": 0, "camel_23960": 0, "camel_23117": 0, "camel_23923": 0, "camel_23968": 0, "camel_23049": 0, "camel_23131": 0, "camel_23942": 0, "camel_22870": 0, "camel_22467": 0, "camel_23080": 0, "camel_22585": 0, "camel_23087": 0, "camel_23922": 0, "camel_22819": 0, "camel_23109": 0, "camel_23073": 0, "camel_23127": 0, "camel_23105": 0, "camel_23057": 0, "camel_23193": 0, "camel_37847": 0.6234892010688782, "camel_19979": 0.6241028904914856, "camel_36490": 0.624648928642273, "camel_19799": 0.627285361289978, "aqua_rat_40504": 0.627403199672699, "camel_19973": 0.6300121545791626, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0.6312618851661682, "aqua_rat_56101": 0.6318086385726929, "camel_36805": 0.6341580152511597, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0.6354212760925293, "aqua_rat_116": 0.6389372944831848, "aqua_rat_38316": 0.6428671479225159, "camel_19957": 0.6443421840667725, "camel_36848": 0.6502847075462341, "camel_36422": 0.6517795324325562, "aqua_rat_72283": 0.6533899903297424, "aqua_rat_35578": 0.6542658805847168, "aqua_rat_44063": 0.6558958888053894, "TheoremQA_xinyi/dag_3.json": 0.7216288447380066, "TheoremQA_xinyi/dag_1.json": 0.7406545877456665}, "TheoremQA_tonyxia/particle6.json": {"TheoremQA_tonyxia/particle6.json": 0, "camel_28833": 0.549447238445282, "aqua_rat_47058": 0.549487292766571, "aqua_rat_20462": 0.5494986176490784, "gsm_rft_8990": 0.5495080351829529, "gsm_train_7372": 0.5495080351829529, "aqua_rat_81193": 0.549523651599884, "gsm_train_7370": 0.5496534705162048, "aqua_rat_10943": 0.5497140288352966, "gsm_rft_9473": 0.5497729182243347, "gsm_rft_20023": 0.5498450398445129, "camel_5938": 0.54988032579422, "gsm_rft_16725": 0.5498866438865662, "gsm_rft_4474": 0.549973726272583, "gsm_train_10506": 0.549994170665741, "gsm_rft_7812": 0.5500165224075317, "camel_28871": 0.5500618815422058, "gsm_rft_21334": 0.5502124428749084, "aqua_rat_7845": 0.550282895565033, "aqua_rat_63830": 0.5503219366073608, "gsm_rft_30111": 0.5505728125572205, "gsm_train_28955": 0.5505728125572205, "aqua_rat_35905": 0.5505770444869995, "aqua_rat_22847": 0.5506319403648376, "gsm_rft_18313": 0.5507800579071045, "gsm_rft_20286": 0.5508447885513306, "aqua_rat_7651": 0.5511226058006287, "gsm_rft_31476": 0.5511897206306458, "gsm_rft_34991": 0.5512128472328186, "gsm_rft_881": 0.551329493522644, "gsm_rft_6897": 0.5513578057289124, "gsm_rft_18704": 0.5515022277832031, "camel_29490": 0.55157071352005, "gsm_rft_9527": 0.5515804290771484, "gsm_rft_32549": 0.551624059677124, "gsm_train_8964": 0.551624059677124, "gsm_rft_10319": 0.5519037246704102, "gsm_rft_10502": 0.5523644089698792, "aqua_rat_11192": 0.5525639057159424, "aqua_rat_62767": 0.5526485443115234, "math_test_algebra_578": 0.5526661276817322, "camel_5714": 0.5528143644332886, "camel_5672": 0.55292809009552, "gsm_rft_18266": 0.5530090928077698, "gsm_train_553": 0.5530090928077698, "aqua_rat_78218": 0.5530549883842468, "camel_29498": 0.5530649423599243, "camel_28812": 0.5531260967254639, "camel_16676": 0.5534485578536987, "camel_5921": 0.5534635186195374, "camel_43944": 0.5535271167755127, "gsm_rft_6531": 0.5538302659988403, "camel_5983": 0.5538827180862427, "gsm_rft_14239": 0.5541293025016785, "gsm_train_9482": 0.5541293025016785, "gsm_rft_18370": 0.5541504621505737, "gsm_rft_26706": 0.5543062686920166, "gsm_rft_26010": 0.5546120405197144, "gsm_rft_23853": 0.5546663999557495, "camel_45074": 0.554720401763916, "camel_39517": 0.554818332195282, "aqua_rat_27451": 0.554905116558075, "aqua_rat_71816": 0.5549334287643433, "aqua_rat_3432": 0.5549866557121277, "aqua_rat_42716": 0.5550044775009155, "camel_17811": 0.5550368428230286, "camel_39494": 0.5551450252532959, "camel_5683": 0.5551841855049133, "gsm_rft_10110": 0.5554428100585938, "gsm_train_18516": 0.5555338263511658, "gsm_rft_28497": 0.5555338263511658, "aqua_rat_81821": 0.555805504322052, "aqua_rat_47620": 0.5560855269432068, "gsm_rft_17754": 0.5562015771865845, "gsm_rft_33530": 0.5562281012535095, "aqua_rat_33317": 0.5563345551490784, "gsm_rft_9980": 0.5565747022628784, "aqua_rat_20932": 0.556628406047821, "aqua_rat_48959": 0.5568599700927734, "aqua_rat_33103": 0.5569159388542175, "camel_7995": 0.5569570660591125, "gsm_rft_12209": 0.5571833848953247, "gsm_rft_20337": 0.5573157072067261, "gsm_train_12934": 0.5573157072067261, "gsm_rft_21267": 0.5573157072067261, "gsm_rft_35619": 0.5575480461120605, "camel_5759": 0.5577298402786255, "aqua_rat_12925": 0.5577569603919983, "aqua_rat_8426": 0.5577914714813232, "camel_28800": 0.5579368472099304, "gsm_rft_497": 0.5584003329277039, "aqua_rat_58051": 0.5584586262702942, "gsm_rft_14979": 0.5586339235305786, "gsm_rft_15250": 0.5588093400001526, "camel_16651": 0.5588311553001404, "gsm_rft_15764": 0.5588391423225403, "camel_39509": 0.5589475631713867, "camel_29440": 0.5591076016426086, "gsm_rft_1756": 0.5591089129447937, "gsm_train_9534": 0.5591089129447937, "gsm_rft_15228": 0.559456467628479, "camel_16677": 0.5596899390220642, "gsm_rft_22295": 0.5597756505012512, "gsm_rft_29129": 0.5598909854888916, "camel_5854": 0.5603209137916565, "camel_28656": 0.5603601336479187, "camel_28856": 0.5603958964347839, "aqua_rat_82624": 0.5605127811431885, "aqua_rat_43435": 0.5608058571815491, "camel_29482": 0.5608114004135132, "gsm_train_6133": 0.5610085129737854, "gsm_rft_14306": 0.5610701441764832, "gsm_rft_19435": 0.5611486434936523, "gsm_rft_26941": 0.5611668825149536, "gsm_rft_57": 0.5615785121917725, "aqua_rat_12010": 0.5615840554237366, "camel_5861": 0.5616522431373596, "gsm_rft_29727": 0.5617560148239136, "camel_28808": 0.5618268251419067, "camel_28804": 0.5618389844894409, "aqua_rat_88321": 0.5619906783103943, "aqua_rat_47775": 0.5622807741165161, "gsm_rft_15416": 0.5625080466270447, "gsm_rft_24421": 0.5626663565635681, "camel_5705": 0.5626738667488098, "gsm_train_2068": 0.5628008842468262, "gsm_rft_4583": 0.5628008842468262, "gsm_train_25711": 0.5628730058670044, "gsm_rft_17440": 0.5630567073822021, "gsm_rft_29222": 0.5630567073822021, "camel_5859": 0.5634884238243103, "aqua_rat_24901": 0.5639380812644958, "aqua_rat_69977": 0.5643596053123474, "camel_28840": 0.5650378465652466, "camel_28809": 0.5651205778121948, "gsm_rft_16695": 0.5655010938644409, "camel_16713": 0.5657051205635071, "camel_43979": 0.565952479839325, "camel_16690": 0.5665830373764038, "camel_16647": 0.5671260952949524, "TheoremQA_xinyi/work_energy_theorem.json": 0.5672416687011719, "camel_5645": 0.5672904253005981, "camel_28822": 0.5677064061164856, "camel_29487": 0.5678126215934753, "camel_5894": 0.5680237412452698, "camel_16646": 0.5687409043312073, "TheoremQA_tonyxia/statisticalphysics5.json": 0.5691584944725037, "gsm_rft_11389": 0.5700566172599792, "camel_39446": 0.570292055606842, "camel_28811": 0.5704548358917236, "camel_28873": 0.5712524056434631, "aqua_rat_41482": 0.5719422698020935, "aqua_rat_33439": 0.5721720457077026, "aqua_rat_57727": 0.5722793936729431, "camel_16673": 0.5722920298576355, "aqua_rat_36249": 0.5729613900184631, "camel_16680": 0.5732683539390564, "aqua_rat_54375": 0.5733200907707214, "aqua_rat_73760": 0.5739110112190247, "camel_29496": 0.5745609998703003, "camel_29464": 0.5748900175094604, "camel_16682": 0.575188398361206, "camel_28866": 0.5758989453315735, "camel_16671": 0.5759725570678711, "gsm_rft_35145": 0.5760913491249084, "gsm_rft_6656": 0.576195478439331, "gsm_train_31725": 0.576195478439331, "camel_28847": 0.5763968825340271, "aqua_rat_70812": 0.5764097571372986, "camel_16703": 0.5764992237091064, "math_train_algebra_24942": 0.5766055583953857, "TheoremQA_tonyxia/wave2.json": 0.5770722031593323, "aqua_rat_11549": 0.5782080292701721, "gsm_rft_22887": 0.5783923864364624, "camel_16712": 0.5784351229667664, "gsm_rft_22533": 0.578974187374115, "camel_39513": 0.5793052315711975, "TheoremQA_panlu/rigid-body3.json": 0.580701470375061, "camel_16663": 0.5816060900688171, "TheoremQA_tonyxia/atom4.json": 0.5842181444168091, "camel_16681": 0.5854970216751099, "camel_24382": 0.5868027210235596, "TheoremQA_tonyxia/semiconductor2.json": 0.5868217945098877, "gsm_rft_10505": 0.5890795588493347, "camel_24344": 0.5903275609016418, "aqua_rat_9493": 0.5903652906417847, "camel_16674": 0.5925168395042419, "gsm_train_29099": 0.5932127237319946, "gsm_rft_17764": 0.5955326557159424, "camel_29484": 0.5960578322410583, "gsm_rft_22397": 0.5985947847366333, "camel_28846": 0.5989351272583008, "TheoremQA_tonyxia/semiconductor3.json": 0.6012137532234192, "camel_45999": 0.601601243019104, "TheoremQA_tonyxia/photoelectric1.json": 0.6073341369628906, "TheoremQA_tonyxia/relativity3.json": 0.6830244064331055, "TheoremQA_tonyxia/particle5.json": 0.71974116563797, "TheoremQA_tonyxia/nuclear3.json": 0.7264958024024963, "TheoremQA_xinyi/momentum.json": 0.7341744303703308, "TheoremQA_tonyxia/particle4.json": 0.8889711499214172}, "TheoremQA_tonyxia/semiconductor3.json": {"TheoremQA_tonyxia/semiconductor3.json": 0, "gsm_rft_8537": 0.5731754899024963, "camel_29444": 0.5731933116912842, "camel_17252": 0.5732459425926208, "camel_16634": 0.5733170509338379, "camel_45140": 0.573357880115509, "camel_16231": 0.5736861228942871, "camel_45983": 0.5740507245063782, "camel_28096": 0.57416170835495, "camel_17772": 0.5744377374649048, "camel_16709": 0.5745612978935242, "TheoremQA_panlu/wave_length1.json": 0.5745710134506226, "camel_40982": 0.5753639936447144, "gsm_rft_17754": 0.5754038095474243, "camel_17208": 0.5757094025611877, "camel_17244": 0.5758146643638611, "camel_17267": 0.5759280323982239, "camel_29880": 0.5759953260421753, "camel_29451": 0.5759962797164917, "camel_29886": 0.5761324167251587, "camel_45053": 0.5766482353210449, "camel_16669": 0.576700747013092, "camel_29868": 0.5770002603530884, "camel_16652": 0.577118456363678, "camel_16621": 0.5771318674087524, "gsm_rft_15764": 0.5773130655288696, "camel_17818": 0.5773415565490723, "camel_17805": 0.5773791074752808, "camel_43985": 0.5774540901184082, "gsm_rft_1756": 0.5774960517883301, "gsm_train_9534": 0.5774960517883301, "camel_19982": 0.5775753259658813, "gsm_train_29099": 0.577673614025116, "aqua_rat_33683": 0.5779178142547607, "camel_43966": 0.5782565474510193, "camel_41207": 0.5784432888031006, "camel_45922": 0.5784910917282104, "TheoremQA_tonyxia/quantum3.json": 0.578491747379303, "camel_17834": 0.5785090923309326, "camel_17709": 0.5786272883415222, "camel_17347": 0.5790318250656128, "camel_16230": 0.5790759921073914, "camel_43959": 0.5792492628097534, "camel_45964": 0.5795735120773315, "gsm_rft_17764": 0.579642117023468, "camel_45018": 0.5798258185386658, "camel_44806": 0.5801660418510437, "camel_16628": 0.580984890460968, "camel_43963": 0.5811424255371094, "camel_17298": 0.5811732411384583, "camel_16715": 0.5812094807624817, "camel_16664": 0.5813897848129272, "camel_29915": 0.5815686583518982, "camel_43941": 0.581935703754425, "camel_43927": 0.581980288028717, "camel_17213": 0.5824422836303711, "camel_43989": 0.5835974216461182, "gsm_rft_22397": 0.5843513607978821, "camel_45933": 0.5845690369606018, "camel_16696": 0.5846875309944153, "camel_43990": 0.5849823355674744, "gsm_rft_26010": 0.5851494073867798, "camel_29490": 0.5853769779205322, "camel_29498": 0.5859999656677246, "camel_16642": 0.5862638354301453, "camel_16223": 0.5863248109817505, "camel_43995": 0.5866556763648987, "camel_44967": 0.5866978764533997, "camel_43983": 0.5868732333183289, "camel_16708": 0.5870327353477478, "camel_29487": 0.5873819589614868, "camel_16209": 0.5875698924064636, "camel_43948": 0.5880146026611328, "aqua_rat_76514": 0.5880846977233887, "camel_17254": 0.5882533192634583, "gsm_rft_10110": 0.5883620977401733, "camel_45148": 0.5885614156723022, "gsm_rft_28497": 0.5892661809921265, "gsm_train_18516": 0.5892661809921265, "gsm_rft_33530": 0.5895040035247803, "camel_17807": 0.5905314087867737, "camel_17272": 0.5906463861465454, "camel_29482": 0.5906946659088135, "camel_43975": 0.5918527841567993, "camel_45967": 0.5931099653244019, "camel_45673": 0.5938560962677002, "camel_16714": 0.5940839052200317, "camel_43949": 0.5944386124610901, "camel_19981": 0.5944440364837646, "camel_29155": 0.5953699350357056, "camel_43994": 0.595504105091095, "camel_16706": 0.5961078405380249, "camel_16668": 0.5965362191200256, "camel_45986": 0.598168671131134, "camel_43960": 0.5982344746589661, "camel_16719": 0.5983028411865234, "camel_29484": 0.5988098978996277, "camel_45932": 0.5990416407585144, "camel_43967": 0.5997182130813599, "camel_43926": 0.6000771522521973, "camel_43961": 0.6002664566040039, "camel_43779": 0.6004842519760132, "camel_45174": 0.6007304191589355, "camel_16701": 0.6007769703865051, "camel_16655": 0.6012540459632874, "camel_43925": 0.6012653112411499, "camel_43972": 0.6027576923370361, "camel_43936": 0.6033006906509399, "camel_43931": 0.6038748025894165, "camel_17235": 0.6041673421859741, "camel_43988": 0.6041948199272156, "camel_16657": 0.6042523980140686, "camel_43923": 0.604921817779541, "camel_43924": 0.6050695776939392, "camel_16675": 0.6062803268432617, "camel_16711": 0.6066073179244995, "camel_16695": 0.6070114374160767, "camel_29496": 0.6071522235870361, "camel_43978": 0.6072531342506409, "camel_16670": 0.6093196868896484, "camel_16663": 0.6095705032348633, "camel_29464": 0.6103226542472839, "camel_16683": 0.6122918128967285, "camel_43942": 0.6126417517662048, "camel_17287": 0.6126989722251892, "camel_16665": 0.6163817644119263, "camel_16707": 0.6172976493835449, "camel_38919": 0.6184524297714233, "camel_16716": 0.618459939956665, "camel_16704": 0.6195493340492249, "camel_16653": 0.6213592886924744, "camel_43965": 0.6220597624778748, "camel_16662": 0.6233730912208557, "camel_16656": 0.6235185265541077, "camel_16718": 0.623894989490509, "camel_43934": 0.6245200634002686, "TheoremQA_tonyxia/nuclear3.json": 0.6260466575622559, "camel_45956": 0.6264601349830627, "camel_43921": 0.6265591979026794, "camel_45992": 0.6283878087997437, "camel_19920": 0.6286797523498535, "camel_17288": 0.6292279362678528, "camel_16650": 0.6303843259811401, "camel_16679": 0.6304131150245667, "camel_16702": 0.6306443810462952, "camel_16649": 0.6309843063354492, "camel_43964": 0.6310007572174072, "camel_16692": 0.6311081051826477, "camel_16691": 0.6312505006790161, "camel_16648": 0.6313167810440063, "camel_45677": 0.6321020126342773, "camel_16641": 0.6331038475036621, "camel_43952": 0.6332861185073853, "camel_43991": 0.633831262588501, "TheoremQA_tonyxia/particle6.json": 0.6354078054428101, "TheoremQA_tonyxia/particle4.json": 0.635463297367096, "camel_16645": 0.6357479691505432, "camel_16658": 0.6365339756011963, "camel_43947": 0.6369643807411194, "camel_43998": 0.6371001601219177, "camel_43956": 0.6375670433044434, "camel_45935": 0.6379539966583252, "math_test_algebra_578": 0.6398036479949951, "camel_43922": 0.6406152844429016, "camel_16676": 0.6452283263206482, "camel_43944": 0.6464818716049194, "TheoremQA_tonyxia/relativity3.json": 0.6488751769065857, "camel_16686": 0.6504158973693848, "TheoremQA_tonyxia/atom4.json": 0.651779055595398, "camel_16666": 0.6535859107971191, "camel_43981": 0.6555647850036621, "TheoremQA_xinyi/momentum.json": 0.6560493111610413, "TheoremQA_tonyxia/particle5.json": 0.6593477725982666, "camel_16651": 0.6598166823387146, "camel_43979": 0.6609351634979248, "camel_43987": 0.661701500415802, "TheoremQA_tonyxia/wave2.json": 0.6617830991744995, "camel_16672": 0.6642193794250488, "camel_16713": 0.6670897006988525, "camel_16699": 0.6675970554351807, "camel_16660": 0.6686225533485413, "camel_45999": 0.672124445438385, "camel_45074": 0.6732779741287231, "camel_16677": 0.6756383180618286, "camel_43945": 0.6793512105941772, "camel_16673": 0.6849875450134277, "camel_16646": 0.6857045292854309, "camel_16647": 0.6894131302833557, "camel_16682": 0.6896683573722839, "camel_16671": 0.6900708079338074, "camel_16690": 0.691226601600647, "TheoremQA_tonyxia/statisticalphysics5.json": 0.6928843855857849, "camel_16703": 0.6959918737411499, "camel_16680": 0.7019469141960144, "camel_45075": 0.7048919796943665, "camel_16712": 0.7063919305801392, "camel_16681": 0.7174773812294006, "camel_16674": 0.7228057384490967, "TheoremQA_tonyxia/photoelectric1.json": 0.7539602518081665, "TheoremQA_tonyxia/semiconductor2.json": 0.8177977204322815}, "TheoremQA_tonyxia/statisticalphysics2.json": {"TheoremQA_tonyxia/statisticalphysics2.json": 0, "camel_29514": 0.4940652549266815, "camel_29833": 0.4940948188304901, "camel_39508": 0.4941060543060303, "gsm_train_27909": 0.49417123198509216, "gsm_rft_18537": 0.49424445629119873, "camel_41034": 0.4942692518234253, "aqua_rat_68302": 0.4942713677883148, "camel_7943": 0.49443283677101135, "camel_45018": 0.4945058226585388, "camel_29453": 0.4945772886276245, "aqua_rat_47102": 0.49490246176719666, "gsm_rft_32487": 0.4949043393135071, "gsm_train_22269": 0.4949043393135071, "gsm_rft_29098": 0.4951741397380829, "camel_41031": 0.49518248438835144, "gsm_rft_34553": 0.4951959550380707, "camel_41001": 0.49525225162506104, "camel_28803": 0.4953215420246124, "camel_40972": 0.49537044763565063, "aqua_rat_16313": 0.49539339542388916, "camel_29507": 0.49540722370147705, "aqua_rat_80111": 0.4954163730144501, "gsm_rft_32627": 0.4954528510570526, "camel_28149": 0.4955103099346161, "math_train_geometry_225": 0.49554261565208435, "camel_16628": 0.49574485421180725, "camel_16663": 0.495792031288147, "gsm_rft_32070": 0.49586430191993713, "camel_29508": 0.4960545003414154, "aqua_rat_55821": 0.49610352516174316, "camel_29466": 0.4962500035762787, "aqua_rat_21803": 0.49631309509277344, "camel_28808": 0.4964904189109802, "camel_40993": 0.49649912118911743, "camel_28715": 0.496506005525589, "camel_41023": 0.4965493381023407, "camel_41000": 0.4965934157371521, "aqua_rat_50724": 0.4966074824333191, "aqua_rat_15183": 0.4966316223144531, "aqua_rat_75331": 0.49704334139823914, "camel_41037": 0.49706748127937317, "aqua_rat_32927": 0.49716731905937195, "aqua_rat_31644": 0.49780476093292236, "gsm_rft_30666": 0.497920423746109, "gsm_rft_14007": 0.49802854657173157, "camel_29486": 0.4980734884738922, "camel_29102": 0.4981915354728699, "gsm_rft_21326": 0.49826106429100037, "gsm_rft_15497": 0.4985123574733734, "gsm_rft_34322": 0.49863681197166443, "gsm_train_23621": 0.4987016022205353, "gsm_rft_25352": 0.4987016022205353, "gsm_rft_17129": 0.4988386332988739, "camel_16169": 0.49885809421539307, "camel_29516": 0.4988763630390167, "gsm_rft_33070": 0.4990079998970032, "gsm_train_9533": 0.4992755353450775, "gsm_rft_5984": 0.4994085431098938, "camel_17406": 0.49995291233062744, "camel_40986": 0.5000635981559753, "gsm_rft_14019": 0.5002179741859436, "gsm_rft_31280": 0.500460147857666, "gsm_train_10396": 0.500460147857666, "gsm_rft_33282": 0.5005826354026794, "aqua_rat_55710": 0.5006080865859985, "aqua_rat_44185": 0.5007221102714539, "camel_41025": 0.5008233785629272, "camel_29818": 0.500998854637146, "gsm_train_9756": 0.5010401606559753, "gsm_train_4193": 0.5010881423950195, "gsm_rft_6591": 0.5010881423950195, "camel_29503": 0.5012670159339905, "camel_40982": 0.501285195350647, "aqua_rat_25590": 0.5012896060943604, "gsm_rft_19855": 0.5013341307640076, "gsm_rft_9556": 0.5013509392738342, "camel_28822": 0.5013656616210938, "camel_40971": 0.5014182925224304, "gsm_rft_4285": 0.5015159845352173, "camel_41021": 0.5015489459037781, "camel_29480": 0.5016603469848633, "gsm_rft_3972": 0.5017126202583313, "camel_28810": 0.5017570853233337, "camel_16712": 0.5018419623374939, "gsm_train_23183": 0.5018985271453857, "gsm_rft_28746": 0.5019026398658752, "camel_41011": 0.5021819472312927, "gsm_rft_28838": 0.5022606253623962, "aqua_rat_14988": 0.5023244619369507, "aqua_rat_5592": 0.5030736923217773, "camel_41036": 0.5033200979232788, "gsm_rft_22822": 0.5040937662124634, "gsm_rft_7862": 0.5040978789329529, "gsm_rft_31420": 0.5041020512580872, "aqua_rat_85270": 0.5042115449905396, "gsm_train_8512": 0.5043086409568787, "gsm_rft_10941": 0.5043086409568787, "camel_41002": 0.5043427348136902, "camel_28815": 0.5043781399726868, "camel_29097": 0.504595935344696, "gsm_rft_3968": 0.5050503015518188, "aqua_rat_33202": 0.5051166415214539, "camel_29485": 0.5052605271339417, "camel_7951": 0.5052782297134399, "camel_29469": 0.5054891109466553, "aqua_rat_81913": 0.5057826042175293, "camel_29451": 0.5061171054840088, "camel_29454": 0.5065720677375793, "camel_28873": 0.5067071914672852, "gsm_rft_6327": 0.5067555904388428, "camel_40980": 0.5069581270217896, "aqua_rat_74118": 0.5069664120674133, "TheoremQA_tonyxia/semiconductor1.json": 0.507003903388977, "aqua_rat_4385": 0.5070484280586243, "aqua_rat_14534": 0.5072892904281616, "camel_29442": 0.5075762867927551, "camel_40967": 0.5076208710670471, "camel_40998": 0.5083512663841248, "aqua_rat_24071": 0.5084072351455688, "gsm_rft_23914": 0.5084271430969238, "camel_7995": 0.5085563659667969, "camel_40988": 0.5085651874542236, "aqua_rat_6253": 0.5088648200035095, "gsm_rft_32549": 0.5093632936477661, "gsm_train_8964": 0.5093632936477661, "gsm_rft_2592": 0.5094089508056641, "aqua_rat_44157": 0.5095328688621521, "camel_29175": 0.5098249912261963, "camel_41027": 0.5100557804107666, "aqua_rat_74394": 0.5103217363357544, "camel_37938": 0.5104271173477173, "gsm_rft_12897": 0.5106949210166931, "camel_16681": 0.5110694169998169, "camel_28811": 0.5113639235496521, "TheoremQA_xinyi/momentum.json": 0.5113716721534729, "aqua_rat_7783": 0.5116683840751648, "camel_41038": 0.5117053389549255, "TheoremQA_tonyxia/nuclear3.json": 0.5117965340614319, "aqua_rat_12684": 0.512000322341919, "gsm_rft_10274": 0.5121735334396362, "gsm_train_11745": 0.5121735334396362, "gsm_rft_2125": 0.512183427810669, "gsm_rft_20286": 0.5127848386764526, "gsm_rft_12805": 0.5130608081817627, "gsm_rft_22127": 0.513131856918335, "TheoremQA_tonyxia/semiconductor2.json": 0.5134934186935425, "camel_29440": 0.5136489868164062, "aqua_rat_38595": 0.5138429999351501, "aqua_rat_41829": 0.513891875743866, "camel_41009": 0.5148265957832336, "camel_29444": 0.515928328037262, "TheoremQA_tonyxia/statisticalphysics5.json": 0.5165461301803589, "aqua_rat_70170": 0.5166745781898499, "camel_16680": 0.5167957544326782, "camel_16223": 0.5171350836753845, "aqua_rat_48677": 0.5177192091941833, "camel_16674": 0.5177885293960571, "gsm_rft_21213": 0.5185496211051941, "gsm_rft_35104": 0.5188124179840088, "gsm_train_10153": 0.5188403725624084, "TheoremQA_tonyxia/particle4.json": 0.5195826888084412, "aqua_rat_31835": 0.5197278261184692, "camel_16209": 0.5205622911453247, "camel_29487": 0.5205700397491455, "camel_28081": 0.5212554335594177, "aqua_rat_64101": 0.522527813911438, "camel_28812": 0.5239601135253906, "camel_28656": 0.5252360105514526, "camel_28847": 0.5267996191978455, "camel_29482": 0.5270041823387146, "aqua_rat_76514": 0.5270846486091614, "TheoremQA_tonyxia/relativity3.json": 0.5288186073303223, "camel_29498": 0.52972412109375, "TheoremQA_tonyxia/atom4.json": 0.5297974944114685, "gsm_rft_10742": 0.5298738479614258, "gsm_rft_32833": 0.5300081372261047, "gsm_train_28209": 0.5305230617523193, "camel_29496": 0.5305885672569275, "camel_29080": 0.5309838652610779, "gsm_train_232": 0.5313243269920349, "gsm_rft_10857": 0.5313243269920349, "gsm_rft_34578": 0.5317440629005432, "TheoremQA_xinyi/work_energy_theorem.json": 0.5331736207008362, "aqua_rat_21090": 0.5334361791610718, "camel_17587": 0.5355885624885559, "camel_29464": 0.5360729098320007, "aqua_rat_28949": 0.5376236438751221, "aqua_rat_8480": 0.5442912578582764, "camel_28846": 0.5529248714447021, "math_train_algebra_1913": 0.5557777285575867, "TheoremQA_tonyxia/semiconductor3.json": 0.5594125986099243, "camel_29484": 0.5648369789123535, "math_test_algebra_1049": 0.5731009244918823, "TheoremQA_panlu/molar_heat_capacity1.json": 0.5951500535011292, "camel_37984": 0.6006345152854919, "camel_45925": 0.6106863021850586, "TheoremQA_panlu/molar_heat_capacity2.json": 0.6112748980522156, "camel_28151": 0.6664843559265137, "camel_38919": 0.6697540879249573}, "TheoremQA_wenhuchen/gauss_lemma2.json": {"camel_12802": 0, "math_test_prealgebra_1217": 0, "camel_12874": 0, "camel_12839": 0, "camel_12844": 0, "camel_12499": 0, "camel_12872": 0, "camel_12837": 0, "camel_13259": 0, "math_train_algebra_1400": 0, "camel_12879": 0, "camel_12801": 0, "camel_12855": 0, "camel_12875": 0, "camel_12870": 0, "camel_12873": 0, "camel_12832": 0, "camel_12840": 0, "camel_12807": 0, "math_train_prealgebra_906": 0, "math_test_prealgebra_1155": 0, "camel_13695": 0, "camel_12857": 0, "camel_12812": 0, "math_train_prealgebra_1949": 0, "math_train_prealgebra_612": 0, "camel_12861": 0, "camel_12530": 0, "camel_12859": 0, "camel_12867": 0, "camel_12865": 0, "camel_12803": 0, "camel_12831": 0, "math_train_algebra_982": 0, "camel_12821": 0, "math_test_algebra_689": 0, "camel_12816": 0, "camel_12877": 0, "camel_12505": 0, "camel_12817": 0, "camel_12810": 0, "camel_12808": 0, "camel_12854": 0, "math_train_prealgebra_413": 0, "camel_12818": 0, "camel_12811": 0, "camel_12827": 0, "camel_12850": 0, "camel_12851": 0, "camel_12853": 0, "camel_13636": 0, "camel_12828": 0, "camel_12819": 0, "camel_12848": 0, "camel_12813": 0, "camel_12805": 0, "camel_12836": 0, "camel_12852": 0, "camel_12822": 0, "camel_12835": 0, "camel_12841": 0, "camel_12863": 0, "camel_12826": 0, "camel_12830": 0, "math_test_prealgebra_1728": 0, "camel_12876": 0, "camel_12871": 0, "camel_12800": 0, "camel_13252": 0, "aqua_rat_15625": 0.7232642769813538, "aqua_rat_74896": 0.723308801651001, "aqua_rat_37988": 0.7235012650489807, "aqua_rat_12905": 0.7235274910926819, "aqua_rat_25677": 0.7235549688339233, "aqua_rat_53752": 0.7235772013664246, "aqua_rat_8187": 0.723601222038269, "aqua_rat_28938": 0.7236015200614929, "camel_37843": 0.7237327694892883, "aqua_rat_62069": 0.7238290905952454, "aqua_rat_34890": 0.7239696979522705, "aqua_rat_10664": 0.724145233631134, "aqua_rat_14262": 0.7244397401809692, "camel_37393": 0.7245879769325256, "aqua_rat_60441": 0.7245887517929077, "aqua_rat_81247": 0.7246374487876892, "aqua_rat_51863": 0.7249448299407959, "aqua_rat_5410": 0.7249550819396973, "aqua_rat_54717": 0.725459098815918, "aqua_rat_79243": 0.7255330681800842, "aqua_rat_76929": 0.7255592346191406, "aqua_rat_77778": 0.7258665561676025, "aqua_rat_3106": 0.7262518405914307, "aqua_rat_87975": 0.7263047099113464, "aqua_rat_57597": 0.7264721989631653, "aqua_rat_10182": 0.7264920473098755, "aqua_rat_4906": 0.7266439199447632, "aqua_rat_21048": 0.7267836332321167, "aqua_rat_60952": 0.7268757820129395, "aqua_rat_39662": 0.7269086241722107, "aqua_rat_19960": 0.7269262075424194, "aqua_rat_34461": 0.7271415591239929, "aqua_rat_76305": 0.727149486541748, "aqua_rat_27311": 0.7275456190109253, "aqua_rat_66984": 0.7277441620826721, "aqua_rat_73004": 0.7280144095420837, "aqua_rat_5745": 0.7280563712120056, "math_train_number_theory_995": 0.7280598282814026, "aqua_rat_22220": 0.7280715703964233, "aqua_rat_38163": 0.7281675338745117, "aqua_rat_21174": 0.728172779083252, "aqua_rat_46907": 0.7281844019889832, "aqua_rat_3788": 0.7285300493240356, "aqua_rat_77742": 0.7286363840103149, "aqua_rat_63556": 0.7286538481712341, "aqua_rat_52199": 0.7288883328437805, "aqua_rat_23027": 0.7289453148841858, "aqua_rat_19668": 0.7290183901786804, "aqua_rat_77353": 0.730370283126831, "aqua_rat_5942": 0.7309382557868958, "camel_37815": 0.7314565777778625, "aqua_rat_3825": 0.7314732074737549, "camel_37820": 0.7315077781677246, "aqua_rat_4039": 0.7315808534622192, "aqua_rat_43270": 0.73175448179245, "aqua_rat_81641": 0.7317796349525452, "aqua_rat_60767": 0.732142984867096, "aqua_rat_25821": 0.7327395677566528, "aqua_rat_17753": 0.7331140041351318, "aqua_rat_21173": 0.7331592440605164, "aqua_rat_8985": 0.7333257794380188, "aqua_rat_6320": 0.7336224317550659, "aqua_rat_73256": 0.7336345911026001, "aqua_rat_79633": 0.7337446808815002, "aqua_rat_4714": 0.7338495850563049, "aqua_rat_73948": 0.7342838048934937, "aqua_rat_52038": 0.7344596982002258, "aqua_rat_40667": 0.7347053289413452, "aqua_rat_81783": 0.7351526021957397, "aqua_rat_44345": 0.7352420091629028, "aqua_rat_2511": 0.7352493405342102, "aqua_rat_5944": 0.7353029847145081, "aqua_rat_40421": 0.7353355288505554, "aqua_rat_71847": 0.7354405522346497, "math_train_number_theory_7031": 0.7361209392547607, "aqua_rat_82945": 0.7370717525482178, "aqua_rat_24283": 0.7376586198806763, "aqua_rat_39666": 0.7392483353614807, "aqua_rat_15929": 0.7393850088119507, "aqua_rat_60360": 0.7394124865531921, "aqua_rat_18870": 0.7395350933074951, "aqua_rat_691": 0.7396188974380493, "aqua_rat_8345": 0.7397441864013672, "aqua_rat_23384": 0.739903450012207, "aqua_rat_25593": 0.740205705165863, "aqua_rat_69927": 0.7410629391670227, "aqua_rat_82840": 0.7413292527198792, "aqua_rat_66005": 0.7418591380119324, "aqua_rat_45563": 0.7425191402435303, "aqua_rat_61707": 0.74269038438797, "aqua_rat_39906": 0.742813229560852, "aqua_rat_58636": 0.7431386709213257, "aqua_rat_17168": 0.7437471151351929, "camel_37796": 0.7439625859260559, "aqua_rat_41930": 0.7449023127555847, "aqua_rat_21159": 0.7458504438400269, "aqua_rat_79127": 0.7458981275558472, "camel_37853": 0.746854305267334, "math_train_number_theory_7057": 0.7470119595527649, "aqua_rat_12667": 0.747657299041748, "aqua_rat_17657": 0.7481194734573364, "aqua_rat_65745": 0.7482616305351257, "aqua_rat_43204": 0.7483698129653931, "aqua_rat_33946": 0.7486544847488403, "aqua_rat_10423": 0.7487545609474182, "aqua_rat_2973": 0.748819887638092, "aqua_rat_76961": 0.7488844990730286, "aqua_rat_80863": 0.7488906979560852, "aqua_rat_21524": 0.7489465475082397, "aqua_rat_60140": 0.7493111491203308, "aqua_rat_51788": 0.7496618032455444, "aqua_rat_1606": 0.7498899698257446, "aqua_rat_8357": 0.7499287128448486, "math_train_number_theory_56": 0.7500477433204651, "aqua_rat_52369": 0.751320481300354, "aqua_rat_50295": 0.7516418099403381, "aqua_rat_9910": 0.7524690628051758, "aqua_rat_62422": 0.7529972195625305, "aqua_rat_1010": 0.7533441185951233, "aqua_rat_10502": 0.753571093082428, "aqua_rat_86239": 0.7539900541305542, "aqua_rat_35443": 0.7544947266578674, "aqua_rat_30801": 0.7545998096466064, "aqua_rat_37848": 0.755407452583313, "aqua_rat_33807": 0.7567540407180786, "aqua_rat_75586": 0.760172963142395, "aqua_rat_48398": 0.7625080347061157, "aqua_rat_66817": 0.762842059135437, "aqua_rat_19690": 0.7648988962173462, "camel_36084": 0.7665778994560242, "aqua_rat_49568": 0.7766063213348389}, "TheoremQA_panlu/angular_frequency3.json": {"TheoremQA_panlu/angular_frequency3.json": 0, "camel_7943": 0.6793166399002075, "camel_16291": 0.679429292678833, "camel_29960": 0.6801719069480896, "camel_7558": 0.6803252696990967, "camel_45135": 0.6806121468544006, "math_test_algebra_518": 0.680996298789978, "camel_5180": 0.6812849640846252, "camel_7970": 0.6815296411514282, "camel_16272": 0.6817377805709839, "camel_28836": 0.6817829608917236, "TheoremQA_panlu/wave_speed1.json": 0.6818102598190308, "camel_29398": 0.6824790239334106, "camel_7986": 0.6832392811775208, "camel_45141": 0.6842233538627625, "camel_7528": 0.6843481063842773, "camel_5125": 0.6844393610954285, "camel_7958": 0.6845394968986511, "camel_7997": 0.684661328792572, "math_test_algebra_1233": 0.6849713921546936, "gsm_rft_18241": 0.6851676106452942, "gsm_train_8834": 0.6851676106452942, "camel_7954": 0.6853685975074768, "gsm_rft_34949": 0.6855896711349487, "camel_7948": 0.6857097744941711, "camel_16265": 0.6862803101539612, "camel_28828": 0.6864646077156067, "camel_28137": 0.6868230700492859, "camel_16243": 0.6872243285179138, "camel_16240": 0.6874132752418518, "camel_7949": 0.6877217888832092, "camel_5311": 0.6889347434043884, "camel_7569": 0.6907790303230286, "camel_7935": 0.6909136176109314, "camel_28532": 0.6914688944816589, "camel_7610": 0.6918768882751465, "camel_5844": 0.6922063231468201, "camel_16290": 0.6922165751457214, "camel_7568": 0.6923025250434875, "camel_7940": 0.6923061013221741, "camel_16245": 0.6925756335258484, "camel_39511": 0.6926411986351013, "camel_45120": 0.6936401724815369, "camel_16317": 0.693877637386322, "camel_39476": 0.6940809488296509, "camel_7945": 0.6946833729743958, "camel_28864": 0.6948899030685425, "camel_7962": 0.6951917409896851, "camel_7480": 0.6963070631027222, "camel_7973": 0.6965500116348267, "camel_7927": 0.6966431140899658, "camel_7987": 0.6969223618507385, "camel_7526": 0.6971339583396912, "camel_28826": 0.697836697101593, "camel_16250": 0.6982709169387817, "camel_7581": 0.6985188722610474, "camel_16288": 0.6985386610031128, "camel_16294": 0.6986621022224426, "camel_16268": 0.6987921595573425, "camel_7570": 0.6993489265441895, "camel_7988": 0.6995736360549927, "camel_7574": 0.700191855430603, "camel_7980": 0.7004887461662292, "camel_28909": 0.7015332579612732, "camel_39467": 0.7028967142105103, "camel_7523": 0.7031426429748535, "camel_7508": 0.7033207416534424, "camel_7920": 0.7036061882972717, "camel_5880": 0.7037261128425598, "camel_7972": 0.7038801908493042, "camel_5188": 0.7039870619773865, "camel_39308": 0.7040174007415771, "camel_7583": 0.7042267918586731, "camel_7977": 0.7043595314025879, "camel_5842": 0.7055633664131165, "camel_7931": 0.7060990929603577, "camel_7922": 0.706244945526123, "camel_16628": 0.7067659497261047, "camel_39452": 0.7071900367736816, "camel_28812": 0.7073252201080322, "camel_7527": 0.7090292572975159, "camel_39455": 0.7091359496116638, "camel_7525": 0.7091883420944214, "camel_7557": 0.7093849182128906, "camel_7960": 0.7098226547241211, "camel_16286": 0.7098706364631653, "camel_28022": 0.7101203203201294, "camel_5001": 0.7104748487472534, "camel_28068": 0.7106395363807678, "camel_7478": 0.7107261419296265, "camel_7520": 0.7113589644432068, "camel_7587": 0.7114385962486267, "camel_7947": 0.7117227911949158, "camel_7590": 0.711737334728241, "camel_28842": 0.7123466730117798, "camel_16257": 0.7129659652709961, "camel_39485": 0.7135031819343567, "camel_7993": 0.7138230800628662, "camel_4979": 0.7139019966125488, "camel_7484": 0.7145299315452576, "camel_16316": 0.7145506739616394, "camel_7565": 0.7154337167739868, "camel_28822": 0.7157062888145447, "camel_7982": 0.7158654928207397, "camel_16311": 0.7163017392158508, "camel_4731": 0.716550886631012, "camel_28820": 0.7172320485115051, "camel_7535": 0.7183457612991333, "camel_17565": 0.7184396386146545, "camel_16315": 0.7185565829277039, "camel_28871": 0.7195965647697449, "camel_7588": 0.720034122467041, "camel_7546": 0.7203039526939392, "camel_7944": 0.7209965586662292, "camel_7597": 0.7217743992805481, "camel_39479": 0.7218648791313171, "camel_7984": 0.7220441102981567, "camel_16282": 0.7225358486175537, "camel_7999": 0.7238308191299438, "camel_28809": 0.7246429324150085, "camel_7519": 0.7248127460479736, "camel_7594": 0.7248250842094421, "camel_7937": 0.7254115343093872, "camel_7595": 0.7257010340690613, "camel_16284": 0.7258961200714111, "camel_7966": 0.7264783978462219, "camel_7567": 0.7269988059997559, "camel_7998": 0.7270594835281372, "camel_7934": 0.7271636724472046, "camel_16242": 0.7276458144187927, "camel_7578": 0.7281519770622253, "camel_16251": 0.7285903692245483, "camel_16253": 0.7290651798248291, "camel_16263": 0.7295230031013489, "camel_7476": 0.7299212217330933, "camel_16267": 0.7305725812911987, "camel_5857": 0.7309382557868958, "aqua_rat_19334": 0.73114013671875, "camel_16304": 0.7317453026771545, "camel_7552": 0.7322691082954407, "camel_7959": 0.7324712872505188, "camel_7928": 0.7339181303977966, "camel_28816": 0.73394775390625, "camel_7498": 0.7346354722976685, "camel_7563": 0.7346643805503845, "camel_7572": 0.7347356081008911, "camel_28865": 0.7348058223724365, "camel_7995": 0.7350033521652222, "camel_28875": 0.7353816032409668, "camel_7592": 0.7357355356216431, "camel_39461": 0.7365818023681641, "camel_28808": 0.7372342348098755, "camel_28879": 0.7376992106437683, "camel_28873": 0.7379204034805298, "camel_7586": 0.7380905151367188, "camel_7938": 0.738490641117096, "camel_16299": 0.7389448285102844, "camel_28866": 0.7398015856742859, "camel_16312": 0.7399236559867859, "camel_39475": 0.7401814460754395, "camel_16244": 0.7403173446655273, "camel_16303": 0.7408245205879211, "camel_7951": 0.7408298254013062, "camel_7541": 0.7420124411582947, "camel_16280": 0.7445552349090576, "camel_16275": 0.7447570562362671, "camel_16254": 0.7448015809059143, "camel_29979": 0.7457472085952759, "camel_16258": 0.745987594127655, "camel_16277": 0.7469608187675476, "camel_16285": 0.7477191686630249, "camel_28872": 0.747952938079834, "camel_7580": 0.7487696409225464, "camel_16310": 0.7496525645256042, "camel_39508": 0.7496532797813416, "camel_16308": 0.7500122785568237, "camel_16302": 0.7505000829696655, "camel_28833": 0.7524798512458801, "camel_16295": 0.753696620464325, "camel_28804": 0.7548649311065674, "camel_16289": 0.7577086687088013, "camel_28846": 0.75844407081604, "camel_28840": 0.7606895565986633, "camel_16252": 0.7639029622077942, "camel_17406": 0.7651363015174866, "camel_28847": 0.7669598460197449, "camel_16283": 0.7673874497413635, "camel_16276": 0.7675599455833435, "camel_28856": 0.7692878842353821, "camel_16266": 0.7729176878929138, "camel_28868": 0.7749066948890686, "camel_7584": 0.7755139470100403, "camel_16281": 0.7766621708869934, "camel_16314": 0.7775275707244873, "TheoremQA_xinyi/work_energy_theorem.json": 0.783022940158844, "camel_28811": 0.7868776321411133, "camel_17542": 0.8067419528961182, "camel_16246": 0.8092074990272522, "camel_16247": 0.8118799328804016, "camel_16249": 0.8281442523002625}, "TheoremQA_panlu/trapezoid1.json": {"TheoremQA_panlu/trapezoid1.json": 0, "aqua_rat_85532": 0.7999022006988525, "math_test_prealgebra_1154": 0.8000089526176453, "aqua_rat_20096": 0.8000696897506714, "aqua_rat_20554": 0.8001000881195068, "aqua_rat_57787": 0.8001458048820496, "aqua_rat_88204": 0.8001488447189331, "camel_2519": 0.8001819252967834, "aqua_rat_1281": 0.8002117872238159, "camel_3857": 0.8002184629440308, "aqua_rat_22577": 0.8002728223800659, "camel_2539": 0.8003032207489014, "aqua_rat_65696": 0.80030757188797, "camel_2532": 0.8003461956977844, "aqua_rat_49835": 0.8003634810447693, "aqua_rat_74347": 0.8003928065299988, "aqua_rat_49232": 0.8004546165466309, "camel_2494": 0.8004931211471558, "aqua_rat_29692": 0.8005076050758362, "aqua_rat_35145": 0.8005520105361938, "aqua_rat_2558": 0.8005538582801819, "camel_2483": 0.8007373213768005, "aqua_rat_65273": 0.8007391095161438, "camel_2516": 0.8007497787475586, "camel_3918": 0.8007670044898987, "aqua_rat_63123": 0.800876259803772, "aqua_rat_39672": 0.800993025302887, "camel_2535": 0.8010156154632568, "aqua_rat_12998": 0.8010225296020508, "camel_2495": 0.8011037111282349, "camel_2498": 0.8011102676391602, "aqua_rat_1782": 0.8011457920074463, "aqua_rat_55534": 0.8011487126350403, "aqua_rat_21742": 0.8011624813079834, "aqua_rat_22626": 0.8011711835861206, "aqua_rat_4980": 0.8011740446090698, "aqua_rat_86489": 0.8014668226242065, "aqua_rat_62392": 0.8015832304954529, "aqua_rat_54994": 0.8015891313552856, "aqua_rat_35029": 0.8016215562820435, "camel_3875": 0.8016237020492554, "aqua_rat_69586": 0.801629364490509, "aqua_rat_34984": 0.8016716241836548, "camel_3845": 0.8017144799232483, "camel_2503": 0.8017231225967407, "aqua_rat_40471": 0.8018125891685486, "aqua_rat_68480": 0.801967203617096, "aqua_rat_65655": 0.8021376729011536, "aqua_rat_65960": 0.8021881580352783, "aqua_rat_4599": 0.8023601174354553, "gsm_rft_4960": 0.8023674488067627, "gsm_train_26463": 0.8024129271507263, "aqua_rat_54009": 0.8024885654449463, "gsm_rft_9807": 0.8025039434432983, "gsm_train_35547": 0.8025039434432983, "camel_2542": 0.802506685256958, "aqua_rat_74652": 0.8025414943695068, "camel_2510": 0.8026134371757507, "aqua_rat_67761": 0.8026226758956909, "camel_3939": 0.8026341199874878, "aqua_rat_46952": 0.8026555180549622, "camel_3885": 0.802879273891449, "aqua_rat_25214": 0.8031218647956848, "camel_2549": 0.8031253218650818, "camel_2559": 0.8033085465431213, "camel_3878": 0.8033355474472046, "camel_2546": 0.8033981919288635, "aqua_rat_49692": 0.8036401867866516, "camel_3919": 0.8037598133087158, "camel_2485": 0.8038262724876404, "camel_3876": 0.8038849830627441, "aqua_rat_20863": 0.8040046095848083, "aqua_rat_27888": 0.8040532469749451, "camel_3855": 0.8041085600852966, "aqua_rat_50119": 0.804191529750824, "aqua_rat_32501": 0.8042809963226318, "math_train_geometry_542": 0.8043017983436584, "aqua_rat_8634": 0.8043484687805176, "camel_3894": 0.8046373724937439, "camel_2514": 0.804823637008667, "aqua_rat_436": 0.8049818277359009, "gsm_rft_17971": 0.805004894733429, "gsm_rft_21344": 0.805004894733429, "gsm_train_22927": 0.805004894733429, "aqua_rat_69882": 0.8050674796104431, "camel_2558": 0.8051111698150635, "math_test_algebra_498": 0.8051614165306091, "camel_3908": 0.8052892088890076, "aqua_rat_53602": 0.8053685426712036, "camel_3852": 0.8054120540618896, "camel_2551": 0.8055462837219238, "camel_3917": 0.8055776357650757, "camel_2526": 0.8056681156158447, "aqua_rat_27892": 0.8058748245239258, "aqua_rat_86393": 0.8059620261192322, "gsm_rft_32158": 0.8060007691383362, "gsm_rft_5812": 0.8061540126800537, "camel_3862": 0.8061649799346924, "camel_2543": 0.8063277006149292, "math_train_geometry_1131": 0.8063477873802185, "aqua_rat_66987": 0.8064939975738525, "aqua_rat_88696": 0.8065891861915588, "aqua_rat_74399": 0.8066462278366089, "aqua_rat_43690": 0.8066906929016113, "camel_3870": 0.8067424893379211, "aqua_rat_45607": 0.8067434430122375, "camel_2493": 0.8067629337310791, "camel_3859": 0.8068413138389587, "aqua_rat_85812": 0.8068708181381226, "camel_3853": 0.8068885207176208, "gsm_rft_17917": 0.8069421052932739, "aqua_rat_55327": 0.8069875836372375, "gsm_train_14021": 0.8069970607757568, "math_train_prealgebra_445": 0.8072137236595154, "aqua_rat_46498": 0.8073683977127075, "aqua_rat_27548": 0.8076521158218384, "aqua_rat_47424": 0.8077247142791748, "aqua_rat_62896": 0.8081908226013184, "camel_2484": 0.8087120652198792, "camel_2525": 0.8087984323501587, "aqua_rat_41860": 0.8088486194610596, "math_train_algebra_66": 0.8088504672050476, "aqua_rat_73785": 0.8090745210647583, "camel_3988": 0.809234082698822, "gsm_rft_20964": 0.8094561696052551, "aqua_rat_64960": 0.8098408579826355, "aqua_rat_74266": 0.8100646734237671, "camel_4695": 0.8100824952125549, "gsm_rft_27927": 0.810088038444519, "math_train_geometry_636": 0.8102859258651733, "gsm_rft_18078": 0.8103025555610657, "camel_3912": 0.8103394508361816, "aqua_rat_27962": 0.8103585243225098, "aqua_rat_73980": 0.8103668689727783, "aqua_rat_1569": 0.810631275177002, "gsm_train_33962": 0.8106487393379211, "aqua_rat_49039": 0.8107684254646301, "gsm_rft_604": 0.810829758644104, "gsm_rft_23551": 0.8108310699462891, "aqua_rat_41391": 0.8109274506568909, "aqua_rat_63446": 0.8109380602836609, "math_test_geometry_462": 0.8109449148178101, "camel_3896": 0.8111644387245178, "camel_3893": 0.8116917014122009, "aqua_rat_27226": 0.8118351101875305, "camel_3843": 0.8119304776191711, "aqua_rat_52348": 0.8122699856758118, "camel_3907": 0.8125782012939453, "aqua_rat_2387": 0.8131129741668701, "aqua_rat_771": 0.8133810758590698, "aqua_rat_55650": 0.8134426474571228, "aqua_rat_26054": 0.8141568303108215, "math_test_geometry_452": 0.8144910335540771, "aqua_rat_71154": 0.8152424693107605, "aqua_rat_35797": 0.8154632449150085, "aqua_rat_8053": 0.815780758857727, "camel_3866": 0.8159676194190979, "aqua_rat_69445": 0.8164301514625549, "aqua_rat_87317": 0.8173741102218628, "camel_3886": 0.8186023235321045, "aqua_rat_5418": 0.8186593651771545, "aqua_rat_50875": 0.8189727067947388, "gsm_rft_30682": 0.8191366791725159, "gsm_rft_24539": 0.8191366791725159, "gsm_train_28692": 0.8191366791725159, "gsm_rft_24757": 0.8191366791725159, "camel_3889": 0.8192585706710815, "aqua_rat_4783": 0.8204560279846191, "camel_3863": 0.8211106061935425, "camel_3849": 0.8213403224945068, "aqua_rat_44109": 0.821358859539032, "camel_3946": 0.821728527545929, "camel_3860": 0.821926474571228, "aqua_rat_53755": 0.8223806023597717, "aqua_rat_50526": 0.8227401971817017, "camel_3879": 0.8228818774223328, "camel_3895": 0.8231473565101624, "aqua_rat_8110": 0.8232662081718445, "camel_3891": 0.8233469724655151, "gsm_rft_16925": 0.8234923481941223, "camel_3981": 0.8247239589691162, "aqua_rat_88624": 0.8255628347396851, "camel_3850": 0.8258945345878601, "aqua_rat_17501": 0.8275255560874939, "camel_3959": 0.828002393245697, "aqua_rat_87596": 0.8285243511199951, "aqua_rat_51693": 0.8296053409576416, "aqua_rat_84489": 0.83021080493927, "aqua_rat_79868": 0.8307983875274658, "aqua_rat_5394": 0.8312577605247498, "camel_3989": 0.8319104909896851, "camel_3998": 0.8322435617446899, "camel_3954": 0.8326655030250549, "aqua_rat_39071": 0.8326762318611145, "camel_3934": 0.8365250825881958, "camel_3999": 0.8408585786819458, "camel_3944": 0.8424027562141418, "camel_3922": 0.8432661294937134, "camel_3971": 0.8471815586090088, "camel_3973": 0.848479151725769}, "TheoremQA_wenhuchen/t_test2.json": {"camel_8084": 0, "camel_8127": 0, "camel_8685": 0, "camel_8660": 0, "camel_8940": 0, "camel_8883": 0, "camel_8029": 0, "camel_8024": 0, "camel_8844": 0, "camel_8007": 0, "camel_8703": 0, "camel_8679": 0, "camel_9980": 0, "camel_9950": 0, "camel_8038": 0, "camel_8077": 0, "camel_8714": 0, "camel_8855": 0, "camel_8926": 0, "camel_8668": 0, "camel_9932": 0, "camel_8712": 0, "camel_8062": 0, "camel_8275": 0, "camel_9938": 0, "camel_8063": 0, "camel_8005": 0, "camel_8948": 0, "camel_8069": 0, "camel_8015": 0, "camel_8049": 0, "camel_8050": 0, "camel_9969": 0, "camel_8803": 0, "camel_9391": 0, "camel_9945": 0, "camel_9983": 0, "camel_9991": 0, "camel_8076": 0, "camel_8035": 0, "camel_8824": 0, "camel_8034": 0, "camel_9920": 0, "camel_8680": 0, "camel_9941": 0, "camel_8837": 0, "camel_8670": 0, "camel_8008": 0, "camel_8817": 0, "camel_8012": 0, "camel_8653": 0, "camel_8872": 0, "camel_8042": 0, "camel_9996": 0, "camel_9944": 0, "camel_8805": 0, "camel_8064": 0, "camel_8018": 0, "camel_8002": 0, "camel_9926": 0, "camel_8041": 0, "camel_8067": 0, "camel_8025": 0, "camel_8843": 0, "camel_8074": 0, "camel_8033": 0, "camel_8070": 0, "camel_9925": 0, "camel_8016": 0, "camel_8054": 0, "camel_9994": 0, "camel_9709": 0, "camel_8659": 0, "camel_8858": 0, "camel_8078": 0, "camel_8010": 0, "camel_8065": 0, "camel_9735": 0, "camel_8698": 0, "camel_8046": 0, "camel_8807": 0, "camel_8644": 0, "camel_9960": 0, "camel_9978": 0, "camel_8665": 0, "camel_8675": 0, "camel_8028": 0, "camel_8648": 0, "camel_8806": 0, "camel_8953": 0, "camel_9988": 0, "camel_8661": 0, "camel_9930": 0, "camel_8676": 0, "camel_9958": 0, "camel_8036": 0, "camel_8691": 0, "camel_8800": 0, "camel_8835": 0, "camel_8068": 0, "camel_8009": 0, "camel_8047": 0, "camel_8823": 0, "camel_8061": 0, "camel_9242": 0, "camel_8044": 0, "camel_8847": 0, "camel_9979": 0, "camel_8811": 0, "camel_8021": 0, "camel_8825": 0, "camel_8072": 0, "camel_8019": 0, "camel_8854": 0, "camel_8058": 0, "camel_9931": 0, "camel_8048": 0, "camel_8849": 0, "camel_8071": 0, "camel_8056": 0, "camel_8856": 0, "camel_8017": 0, "camel_8689": 0, "camel_8838": 0, "camel_8043": 0, "camel_8827": 0, "TheoremQA_wenhuchen/t_test2.json": 0, "camel_8876": 0, "camel_8020": 0, "camel_8853": 0, "camel_8023": 0, "camel_9967": 0, "camel_8014": 0, "camel_8852": 0, "camel_8052": 0, "camel_8004": 0, "camel_8826": 0, "camel_8836": 0, "camel_8013": 0, "camel_9951": 0, "camel_8708": 0, "camel_8832": 0, "camel_8051": 0, "camel_9971": 0, "camel_8039": 0, "camel_8871": 0, "camel_8079": 0, "camel_8075": 0, "camel_8768": 0, "camel_8863": 0, "camel_8032": 0, "camel_9929": 0, "camel_9972": 0, "camel_9962": 0, "camel_8073": 0, "camel_8804": 0, "camel_8850": 0, "camel_8814": 0, "camel_9977": 0, "camel_8878": 0, "camel_8066": 0, "camel_8026": 0, "camel_8654": 0, "camel_8846": 0, "camel_9952": 0, "camel_8819": 0, "camel_9998": 0, "camel_8030": 0, "camel_8060": 0, "camel_8000": 0, "camel_8003": 0, "camel_8810": 0, "camel_8037": 0, "camel_8059": 0, "camel_9982": 0, "camel_8006": 0, "camel_8011": 0, "camel_8715": 0, "camel_8802": 0, "camel_8040": 0, "camel_8057": 0, "camel_9963": 0, "camel_8027": 0, "camel_9954": 0, "camel_8055": 0, "camel_8905": 0, "camel_8864": 0, "camel_8831": 0, "camel_8031": 0, "camel_8022": 0, "camel_8812": 0, "camel_8001": 0, "camel_8053": 0, "camel_8813": 0, "camel_8857": 0, "TheoremQA_wenhuchen/t_test1.json": 0.8005375266075134, "camel_37940": 0.8052855730056763, "camel_37974": 0.8203442096710205, "TheoremQA_wenhuchen/t_test3.json": 0.8292967677116394, "camel_37953": 0.835957407951355}, "TheoremQA_jianyu_xu/Stirling_number_second_kind_3.json": {"camel_20512": 0, "camel_21168": 0, "camel_20931": 0, "camel_21400": 0, "camel_20658": 0, "camel_20863": 0, "camel_20647": 0, "camel_21761": 0, "camel_20414": 0, "camel_20571": 0, "camel_21219": 0, "camel_20618": 0, "camel_20564": 0, "camel_20563": 0, "camel_20948": 0, "camel_20640": 0, "camel_20804": 0, "camel_21015": 0, "camel_21039": 0, "camel_20813": 0, "camel_20308": 0, "camel_21567": 0, "camel_20711": 0, "camel_20293": 0, "camel_20693": 0, "camel_21218": 0, "camel_20700": 0, "camel_21246": 0, "camel_20611": 0, "camel_21055": 0, "camel_21202": 0, "camel_20688": 0, "camel_20540": 0, "camel_20514": 0, "camel_21360": 0, "camel_21386": 0, "camel_20818": 0, "camel_20665": 0, "camel_20626": 0, "camel_20841": 0, "camel_20499": 0, "camel_20609": 0, "camel_20577": 0, "camel_21568": 0, "camel_21822": 0, "camel_20946": 0, "camel_20583": 0, "camel_20849": 0, "camel_20312": 0, "camel_20614": 0, "camel_20309": 0, "camel_20805": 0, "camel_21809": 0, "camel_20302": 0, "camel_21405": 0, "camel_20661": 0, "camel_20301": 0, "camel_20656": 0, "camel_20623": 0, "camel_20698": 0, "camel_20702": 0, "camel_20668": 0, "camel_20310": 0, "camel_21215": 0, "camel_20598": 0, "camel_20596": 0, "camel_21050": 0, "camel_21361": 0, "camel_20695": 0, "camel_20637": 0, "aqua_rat_18129": 0.7283456921577454, "math_train_counting_and_probability_918": 0.7283974885940552, "aqua_rat_52832": 0.728398859500885, "aqua_rat_71434": 0.7284534573554993, "aqua_rat_77972": 0.7284852862358093, "aqua_rat_27573": 0.7285981774330139, "aqua_rat_54121": 0.7286524176597595, "aqua_rat_34": 0.7291343212127686, "aqua_rat_87992": 0.7294149398803711, "aqua_rat_48430": 0.7294406294822693, "aqua_rat_39610": 0.7295000553131104, "aqua_rat_74970": 0.7299342155456543, "aqua_rat_82511": 0.7299534678459167, "math_test_counting_and_probability_494": 0.7299787402153015, "aqua_rat_45483": 0.7306846380233765, "aqua_rat_82109": 0.7307989001274109, "aqua_rat_50942": 0.7310121059417725, "aqua_rat_28538": 0.7310265898704529, "aqua_rat_58323": 0.7310819029808044, "aqua_rat_67159": 0.7311001420021057, "aqua_rat_72708": 0.7312792539596558, "aqua_rat_31768": 0.7314050793647766, "aqua_rat_22648": 0.7314184308052063, "aqua_rat_16354": 0.7318419218063354, "aqua_rat_42460": 0.7318881750106812, "aqua_rat_83158": 0.7320484519004822, "aqua_rat_61965": 0.732126772403717, "math_test_counting_and_probability_935": 0.7324660420417786, "aqua_rat_15615": 0.7325422167778015, "aqua_rat_37301": 0.7325439453125, "aqua_rat_62645": 0.7326335310935974, "aqua_rat_22507": 0.732758641242981, "aqua_rat_70803": 0.7328971028327942, "aqua_rat_10102": 0.7329636216163635, "math_test_counting_and_probability_695": 0.7329872250556946, "aqua_rat_44837": 0.7331601977348328, "aqua_rat_29513": 0.7331862449645996, "aqua_rat_33533": 0.7334089279174805, "aqua_rat_19830": 0.7335773706436157, "aqua_rat_77140": 0.7336434125900269, "aqua_rat_60624": 0.7339027523994446, "aqua_rat_71336": 0.7339093089103699, "aqua_rat_56536": 0.7340758442878723, "aqua_rat_40812": 0.734199047088623, "math_train_counting_and_probability_375": 0.7343190312385559, "aqua_rat_54525": 0.7344914078712463, "aqua_rat_72130": 0.7346643805503845, "aqua_rat_43584": 0.7348459362983704, "aqua_rat_89036": 0.7352259159088135, "aqua_rat_68198": 0.7353236079216003, "aqua_rat_55250": 0.7353636026382446, "aqua_rat_13918": 0.7358365654945374, "aops_2019_AMC_8_Problems/Problem_25": 0.7363007068634033, "aqua_rat_78074": 0.7363943457603455, "aqua_rat_49270": 0.7364667654037476, "aqua_rat_18760": 0.7364687919616699, "aqua_rat_62261": 0.7367538213729858, "aqua_rat_88418": 0.7369160652160645, "aqua_rat_74651": 0.7377544641494751, "aqua_rat_21868": 0.7377862334251404, "aqua_rat_66841": 0.7387006282806396, "math_test_counting_and_probability_650": 0.7388834953308105, "aqua_rat_30172": 0.7393783330917358, "aqua_rat_32732": 0.7397764325141907, "aqua_rat_62903": 0.7401683330535889, "aqua_rat_26524": 0.7410079836845398, "aqua_rat_6365": 0.7412568926811218, "aqua_rat_57985": 0.7416709065437317, "aqua_rat_53149": 0.7417958378791809, "aqua_rat_37223": 0.7427406311035156, "aqua_rat_8673": 0.7428804636001587, "aqua_rat_3279": 0.7429354190826416, "math_train_counting_and_probability_667": 0.7432475686073303, "aqua_rat_25369": 0.7437312006950378, "aqua_rat_30109": 0.7444919347763062, "aqua_rat_76714": 0.7450659275054932, "aqua_rat_60238": 0.7451671361923218, "aqua_rat_2658": 0.7452852129936218, "aqua_rat_55783": 0.7456461191177368, "math_train_counting_and_probability_373": 0.745749831199646, "aqua_rat_70861": 0.7457653880119324, "aqua_rat_40683": 0.746832549571991, "aqua_rat_83206": 0.7472297549247742, "aqua_rat_74550": 0.7475237846374512, "math_test_counting_and_probability_776": 0.7478644251823425, "aqua_rat_14884": 0.7479700446128845, "math_train_counting_and_probability_651": 0.748062789440155, "aqua_rat_13369": 0.7482650876045227, "aqua_rat_58757": 0.7483939528465271, "aqua_rat_75767": 0.7486892342567444, "aqua_rat_70446": 0.7488389611244202, "aqua_rat_66118": 0.7496577501296997, "aqua_rat_77698": 0.749902069568634, "aqua_rat_11273": 0.7500271201133728, "aqua_rat_40108": 0.7501929402351379, "aqua_rat_41861": 0.7505671381950378, "aqua_rat_65310": 0.7511253952980042, "aqua_rat_75188": 0.7520104646682739, "aqua_rat_50641": 0.7523625493049622, "math_test_counting_and_probability_341": 0.7528920769691467, "aqua_rat_18404": 0.7530964612960815, "aqua_rat_575": 0.7535648345947266, "aqua_rat_34678": 0.7555199265480042, "aqua_rat_61885": 0.7558244466781616, "math_test_counting_and_probability_216": 0.7566225528717041, "aqua_rat_7248": 0.75673508644104, "aqua_rat_56015": 0.757011353969574, "aqua_rat_18901": 0.7572275996208191, "math_train_counting_and_probability_961": 0.7573105096817017, "aqua_rat_54461": 0.7583592534065247, "aqua_rat_60936": 0.7584672570228577, "aqua_rat_29651": 0.7593187689781189, "aqua_rat_4294": 0.7617030143737793, "math_train_counting_and_probability_83": 0.7622836232185364, "math_test_counting_and_probability_513": 0.7626836895942688, "aqua_rat_16877": 0.7628663778305054, "aqua_rat_73122": 0.763197124004364, "aqua_rat_13585": 0.7634389400482178, "math_test_counting_and_probability_79": 0.7651807069778442, "aqua_rat_19436": 0.7668612599372864, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": 0.7682006359100342, "math_train_counting_and_probability_696": 0.7685739994049072, "aqua_rat_2480": 0.7702877521514893, "aqua_rat_61326": 0.7717968225479126, "math_train_counting_and_probability_617": 0.7733867764472961, "aqua_rat_73402": 0.7736815214157104, "aqua_rat_89113": 0.7738338112831116, "aqua_rat_37185": 0.7753746509552002, "camel_38505": 0.7788985371589661, "aqua_rat_83784": 0.7882149815559387}, "TheoremQA_xinyi/channel_capacity_1.json": {"TheoremQA_xinyi/channel_capacity_1.json": 0, "camel_25773": 0.5922387838363647, "camel_26626": 0.592242419719696, "camel_25836": 0.5922555327415466, "camel_29327": 0.5923697352409363, "camel_26607": 0.5928115248680115, "camel_36413": 0.5928272008895874, "camel_22539": 0.592867374420166, "camel_36473": 0.5929137468338013, "camel_26586": 0.5931963324546814, "camel_36518": 0.5933026671409607, "camel_36949": 0.5933387279510498, "camel_37288": 0.5933732390403748, "camel_25809": 0.5934338569641113, "camel_26585": 0.5935297608375549, "camel_27441": 0.5936464667320251, "camel_26634": 0.5936669707298279, "camel_36443": 0.5937454104423523, "camel_36465": 0.5938032269477844, "camel_26403": 0.5938221216201782, "camel_36438": 0.5938640236854553, "camel_36477": 0.5938699841499329, "aqua_rat_36286": 0.5939085483551025, "camel_28084": 0.5940070748329163, "camel_36671": 0.5940399765968323, "camel_36533": 0.594065248966217, "camel_36736": 0.5940779447555542, "camel_27426": 0.594155490398407, "camel_28127": 0.5941792726516724, "camel_25802": 0.5942074656486511, "camel_29787": 0.5943211913108826, "camel_37510": 0.5943838953971863, "camel_26651": 0.5943950414657593, "camel_36424": 0.5945430397987366, "camel_25838": 0.5945674180984497, "camel_28948": 0.5947498679161072, "camel_36805": 0.5947757959365845, "camel_36912": 0.5948018431663513, "camel_26460": 0.5949708223342896, "camel_29329": 0.595026969909668, "camel_29302": 0.5951375961303711, "camel_28129": 0.5952666401863098, "camel_27920": 0.5952785611152649, "camel_37446": 0.5953773856163025, "camel_22548": 0.5954394340515137, "camel_18936": 0.5954791903495789, "gsm_rft_24984": 0.5955214500427246, "camel_36335": 0.5956340432167053, "camel_26637": 0.5956878662109375, "camel_36493": 0.595784604549408, "camel_26671": 0.5959358811378479, "camel_26692": 0.5960330367088318, "camel_36441": 0.5961172580718994, "camel_27449": 0.5961360335350037, "camel_26624": 0.5961942076683044, "camel_25778": 0.5961979627609253, "camel_36512": 0.5962755680084229, "camel_29910": 0.5963770747184753, "camel_36884": 0.5967763662338257, "camel_28326": 0.5967900156974792, "camel_27942": 0.5969671607017517, "camel_36417": 0.5970941185951233, "camel_26555": 0.5972058773040771, "camel_25766": 0.5972740650177002, "camel_36045": 0.5973529815673828, "camel_37516": 0.5974308848381042, "camel_29148": 0.5974881052970886, "camel_36472": 0.5976512432098389, "camel_36321": 0.5977523922920227, "camel_36369": 0.5979737043380737, "camel_26778": 0.5980316996574402, "camel_29097": 0.5981305837631226, "camel_26745": 0.598207950592041, "camel_36333": 0.598235011100769, "camel_25505": 0.5983050465583801, "camel_26701": 0.5983340740203857, "camel_13805": 0.5983651280403137, "camel_26567": 0.5983680486679077, "camel_36418": 0.5984740853309631, "camel_36367": 0.5985358953475952, "camel_28087": 0.5987722873687744, "camel_25761": 0.5988224744796753, "gsm_rft_33247": 0.5988889336585999, "camel_36336": 0.5990109443664551, "camel_36355": 0.5992790460586548, "camel_26676": 0.5993131995201111, "camel_37460": 0.599359393119812, "camel_37450": 0.5995127558708191, "camel_36397": 0.5995867252349854, "camel_28095": 0.599593997001648, "camel_36502": 0.5996127128601074, "gsm_rft_14732": 0.5997509360313416, "camel_26435": 0.5999026298522949, "camel_37112": 0.5999455451965332, "gsm_train_27118": 0.6000572443008423, "camel_26464": 0.6000990867614746, "TheoremQA_xinyi/rate_distortion_function_2.json": 0.6001084446907043, "camel_37713": 0.6004263758659363, "camel_29041": 0.6004881262779236, "camel_25788": 0.6005066633224487, "camel_25818": 0.6005384922027588, "camel_26505": 0.6005884408950806, "camel_26791": 0.6006302833557129, "camel_36929": 0.6006675362586975, "camel_36683": 0.6009156107902527, "camel_30474": 0.6009323000907898, "camel_36419": 0.6009386777877808, "camel_25772": 0.6012994050979614, "camel_25808": 0.6013568043708801, "camel_26596": 0.6015359163284302, "camel_36544": 0.6015774011611938, "camel_36169": 0.6016950011253357, "camel_27398": 0.6022754907608032, "camel_25514": 0.6025509238243103, "camel_26538": 0.6025537252426147, "camel_26662": 0.6026593446731567, "camel_26678": 0.6033014059066772, "camel_26694": 0.6033379435539246, "camel_36907": 0.6035605669021606, "camel_36325": 0.6035671234130859, "camel_25823": 0.6038671135902405, "camel_26638": 0.6040805578231812, "camel_25774": 0.60410475730896, "camel_26565": 0.6042525172233582, "camel_36387": 0.6042584776878357, "camel_36422": 0.6042705178260803, "camel_26605": 0.6043211817741394, "camel_13838": 0.6044213175773621, "camel_36490": 0.6044239401817322, "camel_25832": 0.6049278974533081, "camel_36440": 0.6050718426704407, "camel_28468": 0.6051257848739624, "camel_36447": 0.6053645610809326, "camel_29321": 0.6055353283882141, "camel_36323": 0.6060235500335693, "camel_37440": 0.6060253977775574, "camel_36921": 0.6064232587814331, "camel_36457": 0.6065195798873901, "camel_26587": 0.6067327857017517, "camel_36456": 0.6069341897964478, "camel_36754": 0.6070929765701294, "camel_29082": 0.6072410345077515, "camel_25489": 0.6074023246765137, "camel_36557": 0.607524037361145, "camel_26647": 0.608272135257721, "camel_36170": 0.6083731651306152, "camel_36497": 0.6084104776382446, "camel_25785": 0.6084193587303162, "camel_25477": 0.6085494756698608, "camel_26402": 0.6088180541992188, "camel_25775": 0.6091954708099365, "camel_29078": 0.6093164682388306, "camel_28124": 0.6093555092811584, "camel_29346": 0.6099427342414856, "camel_26703": 0.6100866198539734, "camel_13785": 0.6100959777832031, "camel_44798": 0.610243558883667, "camel_26570": 0.6102990508079529, "camel_37453": 0.6104407906532288, "camel_26669": 0.6109621524810791, "camel_26497": 0.6109664440155029, "camel_36195": 0.6113873720169067, "TheoremQA_xinyi/shannon_lower_bound.json": 0.6117755174636841, "camel_26560": 0.6118464469909668, "camel_37517": 0.6119585633277893, "camel_37480": 0.6123301386833191, "camel_36201": 0.6135382056236267, "TheoremQA_xinyi/kraft_inequality.json": 0.6139445900917053, "camel_36891": 0.6142681837081909, "aqua_rat_79062": 0.6147047281265259, "camel_36893": 0.6147691607475281, "camel_26540": 0.6157448887825012, "math_train_number_theory_492": 0.6158950924873352, "camel_25481": 0.616710364818573, "camel_37467": 0.6169751286506653, "camel_37455": 0.6171552538871765, "camel_37553": 0.6179871559143066, "camel_37470": 0.6187030673027039, "camel_26451": 0.618796169757843, "TheoremQA_xinyi/data_processing.json": 0.6190282106399536, "camel_26580": 0.6192267537117004, "camel_36356": 0.6211996674537659, "TheoremQA_xinyi/fano_inequality.json": 0.6231706142425537, "camel_37493": 0.6238960027694702, "camel_27320": 0.6254387497901917, "aqua_rat_73449": 0.6261917352676392, "camel_37491": 0.6262252926826477, "camel_37500": 0.6262355446815491, "camel_37490": 0.6264485716819763, "camel_37507": 0.6273095011711121, "camel_37441": 0.6278036236763, "camel_36395": 0.6291824579238892, "camel_27961": 0.6299715638160706, "camel_36756": 0.6320816874504089, "camel_36765": 0.6377037167549133, "camel_26406": 0.638428270816803, "TheoremQA_xinyi/binary_symmetric_channel_1.json": 0.6461585164070129, "TheoremQA_xinyi/channel_capacity_3.json": 0.646598219871521, "camel_36360": 0.6506766080856323, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.6671148538589478}, "TheoremQA_wenhuchen/Rolle's_theorem.json": {"camel_7147": 0, "camel_7181": 0, "camel_7120": 0, "TheoremQA_wenhuchen/Rolle's_theorem.json": 0, "camel_7700": 0, "camel_7149": 0, "camel_6430": 0, "camel_6467": 0, "camel_7160": 0, "camel_7754": 0, "camel_7686": 0, "camel_6174": 0, "camel_7173": 0, "camel_7194": 0, "camel_7752": 0, "camel_6594": 0, "camel_6192": 0, "camel_6196": 0, "camel_6227": 0, "camel_6564": 0, "camel_6518": 0, "camel_6449": 0, "camel_6197": 0, "camel_7161": 0, "camel_6440": 0, "camel_7121": 0, "camel_6168": 0, "camel_6413": 0, "camel_7174": 0, "camel_7740": 0, "camel_7691": 0, "camel_7714": 0, "camel_7178": 0, "math_test_precalculus_893": 0, "camel_6229": 0, "camel_6478": 0, "camel_6989": 0, "camel_6166": 0, "camel_7234": 0, "camel_6576": 0, "camel_30211": 0.7480520606040955, "math_train_geometry_6109": 0.7481208443641663, "camel_44694": 0.7482900619506836, "camel_46145": 0.7483336925506592, "camel_5048": 0.7483832240104675, "camel_39182": 0.7484715580940247, "camel_39125": 0.7485417723655701, "camel_5197": 0.748650848865509, "camel_42434": 0.7487542629241943, "camel_39139": 0.7488487958908081, "camel_40945": 0.7489511966705322, "camel_42432": 0.7491421699523926, "camel_4998": 0.7492774724960327, "camel_19717": 0.7495065331459045, "camel_5103": 0.7496737837791443, "camel_49344": 0.7497256994247437, "gsm_rft_17551": 0.7497431039810181, "gsm_train_17819": 0.7497431039810181, "camel_5113": 0.7498200535774231, "gsm_rft_11031": 0.7500835657119751, "gsm_rft_9344": 0.7501041293144226, "gsm_rft_2452": 0.7502208948135376, "camel_1733": 0.7504051327705383, "camel_39330": 0.7504749894142151, "camel_18727": 0.7505654692649841, "camel_5267": 0.7505821585655212, "camel_39172": 0.7506992816925049, "camel_38931": 0.7507455348968506, "camel_41637": 0.7507768869400024, "camel_19584": 0.7508136630058289, "camel_5050": 0.7508139610290527, "camel_1748": 0.7508302330970764, "camel_40650": 0.7509470582008362, "camel_19759": 0.7509890794754028, "camel_38942": 0.7510555982589722, "camel_4999": 0.7513468265533447, "camel_5181": 0.7513614892959595, "aqua_rat_9643": 0.7514359354972839, "camel_5189": 0.7514591813087463, "camel_39166": 0.7515220642089844, "camel_5037": 0.7517787218093872, "camel_5045": 0.7518492341041565, "camel_39307": 0.7518991827964783, "camel_39126": 0.752299427986145, "camel_46151": 0.7523311972618103, "aqua_rat_68267": 0.7525299787521362, "camel_19901": 0.7527446746826172, "camel_39151": 0.7527470588684082, "camel_4965": 0.752792239189148, "camel_39580": 0.7528948783874512, "camel_4968": 0.7529255151748657, "camel_46100": 0.7533228397369385, "camel_5098": 0.7534224390983582, "camel_38141": 0.7536917924880981, "camel_39132": 0.7537972331047058, "camel_5111": 0.7540152668952942, "camel_5178": 0.754148542881012, "camel_4972": 0.7541866302490234, "camel_5177": 0.7542485594749451, "camel_19275": 0.7543169260025024, "camel_39349": 0.7551758885383606, "camel_5051": 0.7551810145378113, "camel_4987": 0.7552011013031006, "camel_39311": 0.7553080916404724, "camel_46124": 0.7553274035453796, "camel_47380": 0.7556806802749634, "camel_39489": 0.755868673324585, "camel_39598": 0.7561072111129761, "camel_39308": 0.756359338760376, "camel_19784": 0.7564095854759216, "camel_1750": 0.7564895749092102, "camel_39578": 0.7564963698387146, "camel_47356": 0.756526529788971, "camel_5063": 0.7565274238586426, "camel_30260": 0.7565969228744507, "camel_5055": 0.756908655166626, "camel_1757": 0.7569354772567749, "camel_39147": 0.7570804357528687, "camel_5084": 0.7571982741355896, "camel_39164": 0.7572139501571655, "camel_38913": 0.7574104070663452, "camel_5165": 0.7576092481613159, "camel_18891": 0.7577039003372192, "camel_39331": 0.7577223777770996, "camel_18918": 0.7579240202903748, "camel_5058": 0.7581956386566162, "camel_5011": 0.7582347989082336, "camel_36936": 0.758280336856842, "camel_1746": 0.7583867311477661, "camel_5041": 0.7586413621902466, "camel_4990": 0.7587918639183044, "camel_40850": 0.7591512799263, "camel_5083": 0.7592511177062988, "camel_39168": 0.7595644593238831, "camel_28086": 0.7602102756500244, "camel_5068": 0.7608057260513306, "camel_5172": 0.7608246207237244, "camel_5078": 0.7618163228034973, "camel_1708": 0.7620996236801147, "camel_5077": 0.7621774077415466, "camel_18783": 0.7622657418251038, "camel_5090": 0.7623705267906189, "camel_19483": 0.7626000046730042, "camel_5057": 0.7632362842559814, "camel_39083": 0.763262927532196, "camel_4960": 0.7637165784835815, "camel_5116": 0.7639612555503845, "camel_30318": 0.7643240094184875, "camel_46097": 0.7645974159240723, "camel_19401": 0.7647010087966919, "camel_28147": 0.7648860812187195, "camel_39579": 0.7650850415229797, "camel_5114": 0.7653779983520508, "camel_41705": 0.7654881477355957, "camel_1759": 0.7656466364860535, "camel_19754": 0.7663455009460449, "camel_5070": 0.7663880586624146, "camel_5080": 0.7672768235206604, "camel_39124": 0.7679048776626587, "camel_43845": 0.7680534720420837, "camel_1702": 0.7680821418762207, "camel_5079": 0.7689017653465271, "camel_45342": 0.768954336643219, "camel_39475": 0.7690285444259644, "camel_45293": 0.7693783640861511, "camel_5065": 0.7705413699150085, "camel_47373": 0.7710782885551453, "camel_5043": 0.7717621922492981, "camel_38182": 0.7725540995597839, "camel_39486": 0.7736003994941711, "camel_30167": 0.7737039923667908, "camel_40781": 0.7747989892959595, "camel_5066": 0.7755005955696106, "camel_43036": 0.7761397957801819, "camel_46101": 0.7773439884185791, "camel_5094": 0.7777814269065857, "camel_46135": 0.7779904007911682, "camel_44659": 0.779676616191864, "camel_39327": 0.7797325253486633, "camel_46120": 0.7821249961853027, "camel_5093": 0.7821671366691589, "camel_4993": 0.7837940454483032, "camel_1744": 0.7853252291679382, "camel_39351": 0.786287248134613, "camel_4967": 0.7866509556770325, "camel_39357": 0.7872706055641174, "camel_18784": 0.7892287969589233, "camel_5008": 0.7893424034118652, "camel_4986": 0.790142297744751, "camel_5035": 0.7905193567276001, "camel_28254": 0.7917604446411133, "camel_5092": 0.7922005653381348, "camel_5029": 0.7937345504760742, "TheoremQA_elainewan/math_calculus_12.json": 0.7943605780601501, "camel_46096": 0.7965189814567566, "camel_5227": 0.797084629535675, "camel_39254": 0.7987323999404907, "camel_29198": 0.8019042015075684, "camel_19728": 0.8058510422706604, "camel_39338": 0.8112509846687317}, "TheoremQA_maxku/cv-cnn4.json": {"TheoremQA_maxku/cv-cnn4.json": 0, "gsm_rft_28921": 0.6145094633102417, "camel_30849": 0.6145182251930237, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0.6146489381790161, "gsm_rft_2761": 0.6147683262825012, "camel_44781": 0.6148426532745361, "gsm_rft_13006": 0.6149106025695801, "aqua_rat_86075": 0.6151320338249207, "gsm_rft_34505": 0.6151466965675354, "camel_44726": 0.6153680086135864, "camel_31180": 0.615446925163269, "camel_31968": 0.6155893802642822, "camel_30838": 0.6157937049865723, "gsm_rft_20239": 0.6158861517906189, "camel_30834": 0.6159647703170776, "camel_31865": 0.6160240173339844, "camel_30506": 0.6160397529602051, "camel_30858": 0.6162238717079163, "gsm_rft_29593": 0.6164873838424683, "gsm_rft_33800": 0.6167048215866089, "camel_44796": 0.6167111992835999, "gsm_rft_26269": 0.6167777180671692, "camel_30508": 0.6168691515922546, "camel_30831": 0.6169889569282532, "gsm_rft_17186": 0.6170641779899597, "camel_31571": 0.61724454164505, "camel_31855": 0.617388904094696, "camel_30824": 0.6176381707191467, "camel_31963": 0.6177010536193848, "TheoremQA_maxku/cv-imageprocessing6-histogram.json": 0.6178482174873352, "camel_30857": 0.6180896162986755, "aqua_rat_76117": 0.618204653263092, "gsm_rft_22391": 0.6182863116264343, "gsm_train_10809": 0.6182959675788879, "gsm_rft_12896": 0.6182959675788879, "camel_30870": 0.6185624003410339, "camel_31699": 0.6187387704849243, "camel_44751": 0.6188028454780579, "camel_30179": 0.6188468337059021, "gsm_rft_4689": 0.6188973188400269, "gsm_train_19003": 0.6188973188400269, "gsm_rft_8508": 0.6188973188400269, "gsm_rft_33771": 0.6190344095230103, "gsm_rft_2528": 0.6191028952598572, "math_test_prealgebra_969": 0.6191422343254089, "camel_30821": 0.6192960739135742, "camel_31778": 0.6194198727607727, "camel_44738": 0.6197221279144287, "gsm_rft_22799": 0.6198028922080994, "camel_31596": 0.6198580265045166, "camel_30822": 0.619873046875, "gsm_rft_1103": 0.6198822259902954, "gsm_train_8683": 0.6198822259902954, "gsm_rft_21298": 0.6199120283126831, "gsm_train_20944": 0.6199120283126831, "aqua_rat_53724": 0.6201089024543762, "camel_44806": 0.6201097965240479, "TheoremQA_maxku/signalprocessing4-Ztransform.json": 0.6201105713844299, "camel_31552": 0.6202856302261353, "gsm_rft_33863": 0.620287299156189, "camel_31174": 0.6205460429191589, "camel_17641": 0.6206973195075989, "camel_30819": 0.6208770275115967, "camel_17629": 0.6209298968315125, "aqua_rat_14739": 0.6209378838539124, "aqua_rat_5820": 0.6210010051727295, "camel_31871": 0.6210160255432129, "camel_31918": 0.6212176084518433, "aqua_rat_25646": 0.6212480664253235, "camel_30524": 0.6215993165969849, "camel_31952": 0.6217774748802185, "aqua_rat_24133": 0.6223175525665283, "camel_31864": 0.6226453185081482, "camel_30851": 0.6228185892105103, "camel_28271": 0.6229939460754395, "camel_30801": 0.6231441497802734, "camel_30740": 0.6232411861419678, "gsm_rft_4658": 0.6234432458877563, "gsm_rft_159": 0.6234432458877563, "gsm_train_15116": 0.6234432458877563, "camel_31190": 0.6238656640052795, "camel_31903": 0.6239661574363708, "camel_31902": 0.6240560412406921, "camel_44769": 0.624291181564331, "camel_31990": 0.6245275735855103, "camel_17615": 0.6246698498725891, "camel_18719": 0.6247883439064026, "camel_31852": 0.6248351335525513, "camel_30853": 0.6255474090576172, "camel_30843": 0.6257516741752625, "gsm_rft_32650": 0.6262853145599365, "camel_31882": 0.6264129281044006, "camel_44747": 0.6264500617980957, "camel_30868": 0.6272050142288208, "camel_44731": 0.6272280216217041, "camel_31179": 0.6276566386222839, "camel_17656": 0.6277551054954529, "camel_30877": 0.6277714967727661, "camel_31986": 0.6280605792999268, "camel_44777": 0.6287816166877747, "camel_44741": 0.6292537450790405, "gsm_rft_10602": 0.6296423673629761, "gsm_rft_2925": 0.6296423673629761, "gsm_train_705": 0.6296423673629761, "camel_30826": 0.6302089691162109, "camel_44721": 0.6303905844688416, "camel_30556": 0.6306285262107849, "camel_31887": 0.6307283639907837, "camel_31886": 0.631386935710907, "gsm_rft_30647": 0.6319173574447632, "gsm_train_35541": 0.6319173574447632, "camel_31946": 0.6321972012519836, "gsm_rft_31275": 0.6329793930053711, "camel_30876": 0.633078396320343, "math_train_counting_and_probability_5109": 0.6331827044487, "TheoremQA_maxku/cv-imageprocessing1-morphology.json": 0.6335837244987488, "camel_30837": 0.6338083744049072, "camel_31912": 0.6343143582344055, "gsm_rft_33903": 0.6354622840881348, "camel_44786": 0.6355607509613037, "camel_44732": 0.6355729699134827, "camel_40462": 0.6356620788574219, "camel_44788": 0.6358689665794373, "camel_31840": 0.636075496673584, "camel_44768": 0.6361979246139526, "camel_30812": 0.636483907699585, "camel_31997": 0.636499285697937, "camel_44784": 0.6367238163948059, "gsm_rft_24803": 0.6367734670639038, "camel_44795": 0.6367865800857544, "gsm_train_35467": 0.6376537084579468, "camel_44799": 0.6385763883590698, "camel_30815": 0.638821005821228, "camel_31875": 0.6389656066894531, "camel_30833": 0.6391071081161499, "camel_31859": 0.6395352482795715, "camel_44742": 0.6397782564163208, "camel_44793": 0.6400895118713379, "gsm_rft_8013": 0.6402760148048401, "camel_17657": 0.6404542922973633, "camel_44752": 0.6405725479125977, "camel_44761": 0.6407920718193054, "camel_44722": 0.6417264938354492, "camel_44744": 0.6418225765228271, "camel_44424": 0.6426689624786377, "camel_44775": 0.6428173184394836, "camel_30229": 0.6435946822166443, "camel_44773": 0.6445952653884888, "camel_44774": 0.6453091502189636, "camel_30874": 0.6454845070838928, "TheoremQA_maxku/cv-imageprocessing2-morphology.json": 0.6458295583724976, "camel_44729": 0.6460003852844238, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.647083044052124, "camel_44776": 0.6472167372703552, "camel_44783": 0.647504985332489, "camel_44758": 0.6478860974311829, "camel_30223": 0.6481478810310364, "camel_30859": 0.648619532585144, "camel_44746": 0.6492671966552734, "camel_44778": 0.6493494510650635, "camel_44785": 0.65138179063797, "camel_17631": 0.6526772379875183, "camel_44725": 0.6532938480377197, "camel_44794": 0.6536099314689636, "camel_44759": 0.6539340615272522, "camel_17632": 0.6542470455169678, "camel_44792": 0.6547169089317322, "camel_44720": 0.6575219035148621, "camel_44755": 0.6582849621772766, "camel_44743": 0.6595569252967834, "camel_44767": 0.6604213714599609, "camel_44727": 0.6604276299476624, "camel_44782": 0.6604679226875305, "camel_44762": 0.6609946489334106, "camel_44735": 0.6610844135284424, "camel_44757": 0.6610907316207886, "camel_44723": 0.6617664694786072, "camel_44749": 0.661819577217102, "camel_44750": 0.6626834869384766, "camel_44748": 0.6634125113487244, "camel_30476": 0.6644434332847595, "camel_30407": 0.6666939854621887, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.6668670177459717, "camel_44760": 0.6693825721740723, "camel_44779": 0.6695123314857483, "camel_17621": 0.6742011308670044, "camel_44772": 0.6759445071220398, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.6801207661628723, "camel_44790": 0.6816685795783997, "camel_44798": 0.6817149519920349, "camel_17618": 0.6914561986923218, "camel_44787": 0.6924911141395569, "camel_44728": 0.6949054002761841, "camel_44766": 0.6992054581642151, "camel_17639": 0.7191145420074463, "camel_17637": 0.7201244831085205, "camel_44797": 0.7228374481201172, "TheoremQA_maxku/cv-cnn1.json": 0.7345428466796875, "camel_17654": 0.7650083899497986, "camel_17674": 0.8253316283226013}, "TheoremQA_maxku/graphtheory3-vertexcover.json": {"camel_23402": 0, "camel_22162": 0, "camel_23617": 0, "camel_23608": 0, "camel_22218": 0, "camel_22831": 0, "camel_22339": 0, "camel_23419": 0, "camel_23433": 0, "camel_22330": 0, "camel_23385": 0, "camel_22787": 0, "camel_23607": 0, "camel_22842": 0, "camel_22040": 0, "camel_22324": 0, "camel_23431": 0, "camel_23432": 0, "camel_22770": 0, "camel_22798": 0, "camel_22874": 0, "camel_22840": 0, "camel_22792": 0, "camel_22803": 0, "camel_23171": 0, "camel_22347": 0, "camel_22357": 0, "camel_22796": 0, "camel_23394": 0, "camel_22333": 0, "camel_22830": 0, "camel_22858": 0, "camel_22373": 0, "camel_23146": 0, "camel_23380": 0, "camel_22764": 0, "camel_22820": 0, "camel_21057": 0, "camel_23408": 0, "camel_22832": 0, "camel_23371": 0, "camel_22817": 0, "camel_22024": 0, "camel_22127": 0, "camel_22322": 0, "camel_23393": 0, "camel_23367": 0, "camel_22326": 0, "camel_22356": 0, "camel_22847": 0, "camel_22848": 0, "camel_22154": 0, "camel_22855": 0, "camel_22224": 0, "camel_22355": 0, "camel_22116": 0, "camel_22726": 0, "camel_22352": 0, "camel_23131": 0, "camel_22087": 0, "camel_22168": 0, "camel_23642": 0, "camel_22186": 0, "camel_22360": 0, "camel_22057": 0, "camel_22362": 0, "camel_23386": 0, "camel_22108": 0, "camel_22736": 0, "camel_23396": 0, "camel_22809": 0, "camel_22755": 0, "camel_22378": 0, "camel_22777": 0, "camel_22210": 0, "camel_23125": 0, "camel_22368": 0, "camel_23411": 0, "camel_22185": 0, "camel_22789": 0, "camel_22359": 0, "camel_22810": 0, "camel_22760": 0, "camel_23152": 0, "camel_22753": 0, "camel_23435": 0, "camel_22376": 0, "camel_22875": 0, "camel_23389": 0, "camel_22785": 0, "camel_22335": 0, "camel_22768": 0, "camel_23197": 0, "camel_22724": 0, "camel_22379": 0, "camel_22821": 0, "camel_22793": 0, "camel_22374": 0, "camel_23362": 0, "camel_22344": 0, "camel_22835": 0, "camel_22754": 0, "camel_23672": 0, "camel_22728": 0, "camel_22738": 0, "camel_22744": 0, "camel_22396": 0, "camel_23381": 0, "camel_22756": 0, "camel_23363": 0, "camel_21044": 0, "camel_22860": 0, "camel_22383": 0, "camel_22377": 0, "camel_22870": 0, "camel_22841": 0, "camel_23426": 0, "camel_22802": 0, "camel_22088": 0, "camel_22734": 0, "camel_23397": 0, "camel_23409": 0, "camel_22369": 0, "camel_22868": 0, "camel_23374": 0, "camel_22328": 0, "camel_22816": 0, "camel_22345": 0, "camel_21918": 0, "camel_22381": 0, "camel_22873": 0, "camel_22856": 0, "camel_22375": 0, "camel_22354": 0, "camel_22806": 0, "camel_22763": 0, "camel_22746": 0, "camel_22807": 0, "camel_22397": 0, "camel_22367": 0, "camel_22859": 0, "camel_22147": 0, "camel_22826": 0, "camel_22857": 0, "camel_22818": 0, "camel_22749": 0, "camel_22861": 0, "TheoremQA_maxku/graphtheory3-vertexcover.json": 0, "camel_23675": 0, "camel_22761": 0, "camel_22329": 0, "camel_22729": 0, "camel_22338": 0, "camel_22398": 0, "camel_23387": 0, "camel_22829": 0, "camel_22739": 0, "camel_22361": 0, "camel_22800": 0, "camel_22742": 0, "camel_22745": 0, "camel_22778": 0, "camel_22795": 0, "camel_22758": 0, "camel_22773": 0, "camel_22384": 0, "camel_22735": 0, "camel_22332": 0, "camel_22363": 0, "camel_22720": 0, "camel_22722": 0, "camel_23379": 0, "camel_22387": 0, "camel_22784": 0, "camel_22769": 0, "camel_23360": 0, "camel_22767": 0, "camel_23364": 0, "camel_22783": 0, "camel_23438": 0, "camel_22854": 0, "camel_22727": 0, "camel_22170": 0, "camel_22737": 0, "camel_22743": 0, "camel_23410": 0, "camel_22757": 0, "camel_22721": 0, "camel_22799": 0, "camel_38609": 0.7310027480125427, "camel_38561": 0.7313580513000488, "camel_39938": 0.7340807318687439, "camel_39941": 0.7382211685180664, "camel_39997": 0.74024897813797, "TheoremQA_maxku/graphtheory7-shortestpath.json": 0.7409948110580444, "TheoremQA_maxku/graphtheory4-vertexcover.json": 0.7417271733283997, "camel_38586": 0.7464393377304077, "camel_38526": 0.750970184803009, "TheoremQA_maxku/graphtheory5-vertexcover.json": 0.7547847628593445, "TheoremQA_maxku/graphtheory2-vertexcover.json": 0.7604132890701294}, "TheoremQA_jianyu_xu/Stirling_number_second_kind_6.json": {"camel_20801": 0, "camel_20800": 0, "camel_20302": 0, "camel_20650": 0, "camel_20621": 0, "camel_20844": 0, "camel_21126": 0, "camel_20825": 0, "math_test_number_theory_612": 0, "camel_21567": 0, "camel_21202": 0, "camel_21261": 0, "camel_21174": 0, "camel_21798": 0, "camel_20640": 0, "camel_20714": 0, "camel_20707": 0, "camel_20698": 0, "camel_21169": 0, "camel_21568": 0, "camel_20297": 0, "camel_20668": 0, "camel_21055": 0, "camel_20806": 0, "camel_21246": 0, "camel_20661": 0, "camel_21117": 0, "camel_20579": 0, "camel_20609": 0, "camel_20827": 0, "camel_20499": 0, "camel_20688": 0, "camel_20863": 0, "camel_21219": 0, "camel_20602": 0, "camel_20514": 0, "camel_20414": 0, "camel_20818": 0, "camel_20614": 0, "camel_20841": 0, "camel_20626": 0, "camel_20860": 0, "camel_20665": 0, "camel_20812": 0, "camel_20658": 0, "camel_21223": 0, "camel_21360": 0, "camel_20845": 0, "camel_20805": 0, "camel_20262": 0, "camel_20248": 0, "camel_20577": 0, "camel_21050": 0, "camel_20813": 0, "camel_21361": 0, "camel_20656": 0, "camel_20623": 0, "camel_20946": 0, "camel_20578": 0, "camel_20856": 0, "camel_20317": 0, "camel_20849": 0, "camel_20702": 0, "camel_20700": 0, "camel_20867": 0, "camel_20583": 0, "camel_20301": 0, "camel_20637": 0, "camel_20695": 0, "camel_20563": 0, "camel_20310": 0, "camel_20596": 0, "aqua_rat_39259": 0.7222386598587036, "aqua_rat_46335": 0.7225862741470337, "aqua_rat_34205": 0.7229411602020264, "aqua_rat_87198": 0.7234157919883728, "aqua_rat_41861": 0.7238378524780273, "aqua_rat_56536": 0.7238873243331909, "aqua_rat_54461": 0.723935067653656, "math_train_counting_and_probability_5131": 0.7239548563957214, "math_train_counting_and_probability_911": 0.7243109345436096, "aqua_rat_55250": 0.7243491411209106, "aqua_rat_83986": 0.7244382500648499, "aqua_rat_58193": 0.7245581150054932, "aqua_rat_88173": 0.7247291803359985, "aqua_rat_575": 0.7247598767280579, "aqua_rat_50641": 0.7248826622962952, "aqua_rat_74550": 0.7251555323600769, "aqua_rat_5877": 0.7253010869026184, "aqua_rat_58958": 0.7255228161811829, "aqua_rat_13455": 0.7256965637207031, "aqua_rat_39610": 0.7257781028747559, "aqua_rat_18404": 0.7264103889465332, "aqua_rat_56383": 0.726807177066803, "aqua_rat_60624": 0.7272181510925293, "aqua_rat_77406": 0.7274643778800964, "aqua_rat_27087": 0.7277219891548157, "aqua_rat_75517": 0.7284154295921326, "aqua_rat_39642": 0.7285886406898499, "aqua_rat_46009": 0.7286093831062317, "aqua_rat_40108": 0.7287032008171082, "aqua_rat_18901": 0.728848397731781, "aqua_rat_84826": 0.728904128074646, "math_test_counting_and_probability_416": 0.7291841506958008, "math_train_counting_and_probability_149": 0.7293647527694702, "aqua_rat_76891": 0.7295485138893127, "aqua_rat_65050": 0.7296090722084045, "aqua_rat_34762": 0.7299680709838867, "aqua_rat_9231": 0.7301819920539856, "math_train_counting_and_probability_167": 0.7305991649627686, "aqua_rat_53707": 0.730614185333252, "math_train_counting_and_probability_500": 0.7306446433067322, "math_train_algebra_2532": 0.7306962609291077, "aqua_rat_3279": 0.731460690498352, "math_train_counting_and_probability_70": 0.7319077849388123, "math_train_counting_and_probability_784": 0.7319909930229187, "aqua_rat_77698": 0.7322233319282532, "aqua_rat_1295": 0.732275128364563, "aqua_rat_78656": 0.7327478528022766, "aqua_rat_34678": 0.7329049110412598, "aqua_rat_29651": 0.7329105138778687, "math_test_prealgebra_1443": 0.7337144613265991, "aqua_rat_77972": 0.7337880730628967, "math_train_counting_and_probability_348": 0.7338442802429199, "math_train_counting_and_probability_125": 0.7344161868095398, "aqua_rat_76714": 0.7347027659416199, "math_train_counting_and_probability_296": 0.7348202466964722, "math_train_algebra_770": 0.7354140877723694, "aqua_rat_48430": 0.7356131076812744, "aqua_rat_18129": 0.7364636659622192, "aqua_rat_22531": 0.7376142740249634, "aqua_rat_16320": 0.737895131111145, "aqua_rat_40683": 0.7385523319244385, "aqua_rat_16877": 0.7385991215705872, "aqua_rat_73393": 0.7388198971748352, "aqua_rat_42460": 0.7394541501998901, "aqua_rat_61885": 0.7401652336120605, "aqua_rat_19830": 0.740379273891449, "aqua_rat_74970": 0.7404349446296692, "aqua_rat_60936": 0.7407436370849609, "aqua_rat_82109": 0.7419785261154175, "aqua_rat_27573": 0.7423903942108154, "aqua_rat_44837": 0.7425197958946228, "math_train_counting_and_probability_696": 0.7426713109016418, "math_train_counting_and_probability_371": 0.7430598735809326, "aqua_rat_5049": 0.7432394623756409, "math_test_counting_and_probability_695": 0.744069516658783, "aqua_rat_37185": 0.7448118329048157, "aqua_rat_67159": 0.7453828454017639, "camel_12727": 0.7455321550369263, "aqua_rat_7248": 0.7456316351890564, "aqua_rat_73122": 0.7459315061569214, "aqua_rat_16354": 0.7461122870445251, "TheoremQA_jianyu_xu/combination_and_permutation_1.json": 0.7463564276695251, "aqua_rat_13585": 0.746563196182251, "aqua_rat_61965": 0.7466931343078613, "aqua_rat_9655": 0.747511088848114, "math_test_counting_and_probability_1092": 0.7486315369606018, "math_test_counting_and_probability_461": 0.7486461997032166, "math_train_counting_and_probability_617": 0.7502695322036743, "aqua_rat_65310": 0.7504737973213196, "aqua_rat_3903": 0.7508814334869385, "aqua_rat_36396": 0.7512091398239136, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": 0.7516074180603027, "aqua_rat_4294": 0.7524213790893555, "aqua_rat_53475": 0.7527583837509155, "math_train_counting_and_probability_651": 0.7528752088546753, "aqua_rat_5242": 0.7535982131958008, "aqua_rat_71434": 0.7543240189552307, "aqua_rat_37634": 0.7546242475509644, "aqua_rat_11061": 0.7546655535697937, "aqua_rat_48130": 0.755939245223999, "aqua_rat_49569": 0.7563364505767822, "aqua_rat_73402": 0.7594923973083496, "aqua_rat_77140": 0.7600650787353516, "aqua_rat_2480": 0.7601868510246277, "aqua_rat_45483": 0.7611489295959473, "aqua_rat_66118": 0.7624099850654602, "math_train_counting_and_probability_375": 0.7624472379684448, "math_test_counting_and_probability_494": 0.7626360654830933, "aqua_rat_37649": 0.7670966982841492, "aqua_rat_25369": 0.7688236236572266, "aqua_rat_66391": 0.7697860598564148, "math_test_counting_and_probability_71": 0.7699021100997925, "aqua_rat_11273": 0.7710144519805908, "aqua_rat_89113": 0.7749000191688538, "aqua_rat_57502": 0.7757545113563538, "aqua_rat_34": 0.775814414024353, "math_train_counting_and_probability_273": 0.7761394381523132, "aqua_rat_56015": 0.780235230922699, "aops_2019_AMC_8_Problems/Problem_25": 0.7813231348991394, "math_train_counting_and_probability_241": 0.786923348903656, "math_train_counting_and_probability_98": 0.7876732349395752, "math_test_counting_and_probability_294": 0.7888608574867249, "aqua_rat_19436": 0.7896658778190613, "aqua_rat_26524": 0.7959171533584595, "aqua_rat_75188": 0.8002398610115051, "aqua_rat_83784": 0.8021705746650696, "aqua_rat_61326": 0.8082464337348938, "math_train_counting_and_probability_83": 0.8260076642036438}, "TheoremQA_elainewan/econ_micro_14_3.json": {"TheoremQA_elainewan/econ_micro_14_3.json": 0, "camel_40916": 0.7984150052070618, "camel_38131": 0.7987318634986877, "camel_24937": 0.7988064885139465, "camel_24907": 0.7992261052131653, "camel_39094": 0.7993377447128296, "camel_6982": 0.7993558049201965, "math_test_algebra_812": 0.7994833588600159, "camel_24915": 0.7995079159736633, "camel_24930": 0.7995538115501404, "camel_24898": 0.7998344302177429, "camel_24955": 0.8004530072212219, "camel_24739": 0.8008366227149963, "camel_40717": 0.8010191917419434, "camel_39855": 0.8012400269508362, "camel_24924": 0.801293134689331, "camel_24899": 0.801369845867157, "camel_24887": 0.80149906873703, "camel_24902": 0.8023037910461426, "camel_24727": 0.8032482862472534, "camel_40800": 0.8032532930374146, "camel_24900": 0.8034965395927429, "camel_24921": 0.8037835359573364, "camel_24942": 0.8040497899055481, "camel_24957": 0.8041719198226929, "camel_24741": 0.8042315244674683, "camel_39093": 0.8043954372406006, "camel_39875": 0.80491042137146, "camel_40901": 0.8051167726516724, "camel_25123": 0.8051674962043762, "camel_40647": 0.8051880598068237, "camel_24553": 0.805395781993866, "camel_24929": 0.8058790564537048, "camel_24922": 0.8059170246124268, "camel_40712": 0.8059407472610474, "camel_38304": 0.8061256408691406, "camel_24894": 0.8062118291854858, "camel_24797": 0.8062208294868469, "camel_38628": 0.8062527775764465, "camel_39115": 0.8067145943641663, "camel_41898": 0.8067264556884766, "camel_24916": 0.8069493770599365, "camel_6185": 0.8069586157798767, "camel_38205": 0.807104766368866, "camel_41923": 0.8071804046630859, "camel_38644": 0.8073515295982361, "camel_24889": 0.8077298402786255, "camel_24728": 0.8077523708343506, "camel_24903": 0.8078225255012512, "camel_40697": 0.8081002235412598, "camel_39889": 0.8082271814346313, "camel_24945": 0.808854341506958, "camel_24927": 0.8088569045066833, "camel_24926": 0.8089762926101685, "camel_24891": 0.8090305924415588, "camel_24936": 0.8096480369567871, "camel_24881": 0.8098946213722229, "camel_24934": 0.8100630044937134, "camel_24910": 0.8101887702941895, "camel_24778": 0.810327410697937, "camel_39106": 0.8104763031005859, "aqua_rat_39466": 0.8105752468109131, "camel_24897": 0.81111079454422, "camel_24938": 0.811458945274353, "camel_40669": 0.8116721510887146, "camel_39861": 0.8119702339172363, "camel_24755": 0.8121249675750732, "camel_24884": 0.8126486539840698, "camel_38099": 0.8129881024360657, "camel_24944": 0.8130629658699036, "camel_38155": 0.81307452917099, "camel_24787": 0.8131956458091736, "camel_38256": 0.8133902549743652, "camel_39891": 0.8135697245597839, "camel_24883": 0.8142272233963013, "camel_39883": 0.8146644234657288, "camel_39869": 0.8147323727607727, "camel_25161": 0.8153524994850159, "camel_24952": 0.8154342770576477, "camel_38863": 0.8155157566070557, "camel_39911": 0.8155434131622314, "camel_24901": 0.8162744045257568, "camel_24943": 0.8179343342781067, "camel_39437": 0.8182727098464966, "camel_24928": 0.8184749484062195, "camel_7017": 0.8190430998802185, "camel_40661": 0.8195062875747681, "camel_40704": 0.8195944428443909, "camel_24816": 0.820073664188385, "camel_40759": 0.8202399015426636, "camel_24725": 0.8202652931213379, "camel_39918": 0.8206819891929626, "camel_24531": 0.8210688233375549, "camel_39848": 0.8212382793426514, "camel_24920": 0.8217530250549316, "camel_39892": 0.8219058513641357, "camel_25178": 0.8223270177841187, "camel_40698": 0.8223845362663269, "camel_41143": 0.8231537938117981, "camel_25187": 0.8232404589653015, "camel_39906": 0.8236046433448792, "camel_39900": 0.8239451050758362, "camel_39876": 0.8240054249763489, "camel_39908": 0.8253763914108276, "camel_25133": 0.8258494138717651, "camel_39912": 0.8258737325668335, "camel_39850": 0.8261540532112122, "camel_39849": 0.8264994621276855, "camel_6214": 0.827727198600769, "camel_24754": 0.8279909491539001, "camel_39871": 0.8283346891403198, "camel_39899": 0.8285780549049377, "camel_39603": 0.8287180066108704, "camel_39847": 0.8288560509681702, "camel_39114": 0.8290368914604187, "camel_39907": 0.8291457295417786, "camel_40682": 0.8294098973274231, "camel_41451": 0.829907238483429, "camel_39915": 0.8303297758102417, "camel_24853": 0.8307581543922424, "camel_38220": 0.831802248954773, "camel_24743": 0.8321415185928345, "camel_38928": 0.8327086567878723, "camel_40942": 0.8331624865531921, "camel_39885": 0.8334100246429443, "camel_24823": 0.8334445357322693, "camel_39874": 0.8340744376182556, "camel_39879": 0.8342962861061096, "camel_39084": 0.8345122337341309, "camel_40772": 0.834676206111908, "camel_39882": 0.8348132371902466, "camel_39870": 0.8353766798973083, "camel_39904": 0.8354038000106812, "camel_39865": 0.8354871869087219, "camel_39859": 0.8359166979789734, "camel_40796": 0.8359258770942688, "camel_24893": 0.8361274003982544, "camel_39845": 0.8364230990409851, "camel_39119": 0.8365395069122314, "camel_39519": 0.8366610407829285, "camel_39867": 0.8371825218200684, "camel_6228": 0.8373520374298096, "camel_39863": 0.8375895023345947, "camel_39872": 0.8385341763496399, "camel_39873": 0.8389019966125488, "camel_39854": 0.8395496606826782, "camel_38362": 0.8404088616371155, "camel_39919": 0.8404749035835266, "camel_39860": 0.8407526016235352, "camel_39844": 0.8408979773521423, "camel_39895": 0.8409125804901123, "camel_39846": 0.8416382670402527, "camel_39868": 0.8419004678726196, "camel_39552": 0.8432037234306335, "camel_39896": 0.8433595895767212, "camel_39894": 0.8436734676361084, "camel_39502": 0.8437850475311279, "camel_39843": 0.8438044786453247, "camel_39388": 0.843872606754303, "camel_24925": 0.8440424203872681, "camel_39902": 0.8446205258369446, "camel_39887": 0.8451167941093445, "camel_39893": 0.8451471924781799, "camel_39858": 0.8451756834983826, "camel_39877": 0.8453468084335327, "camel_24892": 0.8454697132110596, "camel_39857": 0.8457503914833069, "camel_24909": 0.8457589149475098, "camel_40933": 0.8461436033248901, "camel_39888": 0.8462020754814148, "camel_41906": 0.8471102714538574, "camel_39905": 0.84754878282547, "camel_39886": 0.8476098775863647, "camel_39852": 0.8478027582168579, "camel_24729": 0.8478549718856812, "camel_39856": 0.8480576872825623, "camel_39878": 0.8481535911560059, "camel_39332": 0.8495899438858032, "camel_39917": 0.8498002290725708, "camel_39866": 0.8498982191085815, "camel_39851": 0.8503156304359436, "camel_39842": 0.8505809307098389, "camel_39881": 0.8506558537483215, "TheoremQA_elainewan/econ_micro_11.json": 0.8509272336959839, "camel_39884": 0.8515307903289795, "camel_39914": 0.8520278334617615, "camel_38203": 0.8528897166252136, "camel_39498": 0.8546637296676636, "camel_41749": 0.8549802303314209, "camel_39909": 0.856593668460846, "camel_39880": 0.8572214841842651, "camel_41835": 0.8597108721733093, "camel_39897": 0.8599924445152283, "camel_39853": 0.8614161014556885, "camel_39910": 0.8638233542442322, "camel_39903": 0.865405261516571, "camel_39840": 0.8676815032958984, "camel_39890": 0.8681763410568237, "camel_39464": 0.8686280846595764, "camel_39913": 0.8752734661102295}, "TheoremQA_wenhuchen/euler's_method1.json": {"camel_6825": 0, "camel_16007": 0, "camel_16807": 0, "camel_7502": 0, "camel_16854": 0, "camel_16128": 0, "camel_16921": 0, "camel_16158": 0, "camel_7443": 0, "camel_17030": 0, "camel_7503": 0, "camel_16153": 0, "camel_16072": 0, "camel_7441": 0, "camel_6347": 0, "camel_40249": 0, "camel_7507": 0, "camel_16943": 0, "camel_16958": 0, "camel_17167": 0, "camel_16902": 0, "camel_16825": 0, "camel_6392": 0, "camel_16032": 0, "camel_7496": 0, "camel_16096": 0, "camel_16997": 0, "camel_16879": 0, "camel_7203": 0, "camel_16903": 0, "camel_16030": 0, "camel_7517": 0, "camel_16106": 0, "camel_16069": 0, "camel_16044": 0, "camel_17027": 0, "camel_16113": 0, "camel_6329": 0, "camel_16112": 0, "camel_6381": 0, "camel_16057": 0, "camel_16108": 0, "camel_16474": 0, "camel_17109": 0, "camel_16804": 0, "camel_17157": 0, "camel_7444": 0, "camel_17162": 0, "camel_7445": 0, "camel_16125": 0, "camel_16123": 0, "camel_16894": 0, "camel_16140": 0, "camel_6248": 0, "camel_16961": 0, "camel_7978": 0, "camel_16089": 0, "camel_16132": 0, "camel_16862": 0, "camel_16402": 0, "camel_16914": 0, "camel_16901": 0, "camel_16003": 0, "camel_7955": 0, "camel_6358": 0, "camel_16952": 0, "camel_16900": 0, "camel_16806": 0, "camel_16815": 0, "camel_16837": 0, "camel_16956": 0, "camel_7457": 0, "camel_6359": 0, "camel_16131": 0, "camel_7513": 0, "camel_7950": 0, "camel_7494": 0, "camel_17028": 0, "camel_16133": 0, "camel_16860": 0, "camel_16122": 0, "camel_16149": 0, "camel_16922": 0, "camel_16996": 0, "camel_16522": 0, "camel_16100": 0, "camel_6849": 0, "camel_6325": 0, "camel_7921": 0, "camel_6375": 0, "camel_16083": 0, "camel_17171": 0, "camel_17421": 0, "camel_16104": 0, "camel_16828": 0, "camel_16851": 0, "camel_16890": 0, "camel_16401": 0, "camel_16080": 0, "camel_17158": 0, "camel_16893": 0, "camel_16151": 0, "camel_6337": 0, "camel_17000": 0, "camel_6386": 0, "camel_7468": 0, "gsm_rft_27771": 0.6794055104255676, "gsm_train_31678": 0.6794055104255676, "aqua_rat_47199": 0.6795197129249573, "gsm_rft_15440": 0.6796915531158447, "gsm_train_32181": 0.6796915531158447, "aqua_rat_40634": 0.6797645688056946, "aqua_rat_8703": 0.6798702478408813, "aqua_rat_84494": 0.6801962852478027, "gsm_rft_31224": 0.6802424788475037, "camel_48260": 0.6804017424583435, "camel_45318": 0.6805790066719055, "aqua_rat_65312": 0.6808506846427917, "gsm_rft_26470": 0.680875301361084, "gsm_train_24702": 0.680875301361084, "gsm_rft_1904": 0.6809226870536804, "gsm_rft_24824": 0.6811608672142029, "gsm_rft_33118": 0.6812660098075867, "math_train_prealgebra_180": 0.6812736392021179, "gsm_train_10153": 0.6813397407531738, "gsm_rft_35104": 0.6814127564430237, "camel_29184": 0.6814484596252441, "gsm_rft_34874": 0.6815775632858276, "aqua_rat_18924": 0.6821584105491638, "aqua_rat_56038": 0.6823301911354065, "gsm_rft_21229": 0.6827977299690247, "aqua_rat_11429": 0.6828439235687256, "aqua_rat_62048": 0.6829925179481506, "gsm_rft_21213": 0.6830768585205078, "aqua_rat_59416": 0.6833133697509766, "camel_29146": 0.6836104393005371, "aqua_rat_6030": 0.6836822628974915, "camel_39471": 0.6838679313659668, "aqua_rat_42850": 0.6838681697845459, "aqua_rat_84419": 0.6838967204093933, "camel_28094": 0.6844651699066162, "camel_28715": 0.6845632195472717, "camel_28024": 0.6853429675102234, "gsm_rft_18015": 0.685487687587738, "gsm_rft_12148": 0.6855918169021606, "gsm_rft_12947": 0.6855918169021606, "gsm_train_15394": 0.6855918169021606, "camel_39458": 0.6856776475906372, "gsm_train_19319": 0.686789870262146, "gsm_rft_4647": 0.6869924664497375, "camel_45301": 0.687082052230835, "gsm_rft_17396": 0.6871584057807922, "camel_29060": 0.6871733069419861, "gsm_rft_7323": 0.6873325705528259, "camel_28081": 0.6876360774040222, "gsm_rft_32045": 0.6879542469978333, "gsm_train_26876": 0.6880660057067871, "aqua_rat_76902": 0.6885990500450134, "gsm_rft_4992": 0.6887800097465515, "gsm_rft_15048": 0.6895613074302673, "gsm_rft_22580": 0.6897097229957581, "gsm_train_5958": 0.6897433400154114, "gsm_rft_11799": 0.6897433400154114, "gsm_rft_33604": 0.6899193525314331, "aqua_rat_75339": 0.6905927658081055, "gsm_rft_28444": 0.6908066272735596, "gsm_rft_30976": 0.6908812522888184, "aqua_rat_59651": 0.6909354329109192, "aqua_rat_3097": 0.6909810304641724, "gsm_rft_15498": 0.6913120746612549, "gsm_train_26692": 0.6913496851921082, "gsm_rft_1002": 0.6913496851921082, "gsm_train_22796": 0.6914089322090149, "aqua_rat_4149": 0.6915854811668396, "gsm_rft_22441": 0.6917610764503479, "gsm_rft_8250": 0.6918025612831116, "aqua_rat_33076": 0.692043125629425, "gsm_rft_31968": 0.6925778388977051, "gsm_rft_7981": 0.6933850646018982, "aqua_rat_67211": 0.6937986016273499, "gsm_rft_24176": 0.6939498782157898, "aqua_rat_31829": 0.6956634521484375, "gsm_rft_6375": 0.6963256597518921, "gsm_rft_17523": 0.6963256597518921, "camel_28149": 0.6970276236534119, "aqua_rat_5634": 0.6970815062522888, "gsm_train_31368": 0.6981196999549866, "aqua_rat_88394": 0.6984378695487976, "gsm_rft_14397": 0.6992663145065308, "gsm_rft_11794": 0.6992663145065308, "gsm_rft_30774": 0.7003645300865173, "gsm_train_11391": 0.7004620432853699, "gsm_rft_30266": 0.7008388638496399, "gsm_rft_5217": 0.7008388638496399, "camel_36269": 0.7069413661956787, "camel_39505": 0.7137650847434998, "aqua_rat_8383": 0.7193771600723267, "aqua_rat_27506": 0.7219191789627075, "camel_37933": 0.7285391092300415, "aqua_rat_12508": 0.7299842238426208}, "TheoremQA_maxku/graphtheory10-shortestpath.json": {"camel_39949": 0, "camel_22395": 0, "camel_22023": 0, "camel_22288": 0, "camel_23964": 0, "camel_39931": 0, "camel_38598": 0, "camel_38625": 0, "camel_22027": 0, "camel_39980": 0, "camel_22467": 0, "camel_22029": 0, "camel_39975": 0, "camel_22294": 0, "camel_21639": 0, "camel_23924": 0, "camel_22020": 0, "camel_22019": 0, "camel_22032": 0, "camel_39978": 0, "camel_22281": 0, "camel_21607": 0, "camel_39928": 0, "camel_22008": 0, "camel_23973": 0, "camel_22266": 0, "camel_22066": 0, "camel_39927": 0, "camel_38585": 0, "camel_22350": 0, "camel_38611": 0, "camel_23967": 0, "camel_22062": 0, "camel_22818": 0, "camel_21648": 0, "camel_39934": 0, "camel_22417": 0, "camel_38608": 0, "camel_23921": 0, "camel_38906": 0, "camel_21627": 0, "camel_22078": 0, "camel_38584": 0, "camel_22279": 0, "camel_23980": 0, "camel_23938": 0, "camel_23952": 0, "camel_22015": 0, "camel_22300": 0, "camel_21621": 0, "camel_22067": 0, "camel_22051": 0, "camel_23184": 0, "camel_22065": 0, "camel_39970": 0, "camel_22056": 0, "camel_22054": 0, "camel_22276": 0, "camel_22044": 0, "camel_22035": 0, "camel_22037": 0, "camel_38573": 0, "camel_22315": 0, "camel_23947": 0, "camel_22076": 0, "camel_21633": 0, "camel_22285": 0, "camel_22073": 0, "camel_22018": 0, "camel_22030": 0, "camel_22304": 0, "camel_23961": 0, "camel_22261": 0, "camel_22252": 0, "camel_22058": 0, "camel_39979": 0, "camel_23981": 0, "camel_21675": 0, "camel_22875": 0, "camel_22004": 0, "camel_38619": 0, "camel_38617": 0, "camel_22264": 0, "camel_22033": 0, "camel_22013": 0, "camel_22290": 0, "camel_22345": 0, "camel_39960": 0, "camel_22003": 0, "camel_22053": 0, "camel_22052": 0, "camel_23957": 0, "camel_23983": 0, "camel_23942": 0, "camel_22007": 0, "camel_22038": 0, "camel_23143": 0, "camel_22368": 0, "camel_21646": 0, "camel_22000": 0, "camel_21610": 0, "camel_39938": 0, "camel_21601": 0, "camel_22043": 0, "camel_39998": 0, "camel_39920": 0, "camel_22005": 0, "camel_38560": 0, "camel_22326": 0, "camel_22017": 0, "camel_38622": 0, "camel_38489": 0, "camel_38621": 0, "camel_21667": 0, "camel_21634": 0, "camel_22016": 0, "camel_22025": 0, "camel_22041": 0, "camel_22006": 0, "camel_39977": 0, "camel_22028": 0, "camel_22361": 0, "camel_21654": 0, "camel_38615": 0, "camel_22316": 0, "camel_21589": 0, "camel_39997": 0, "camel_21658": 0, "camel_38630": 0, "camel_22449": 0, "camel_38581": 0, "camel_22240": 0, "camel_38609": 0, "camel_22034": 0, "camel_22009": 0, "camel_22079": 0, "camel_22354": 0, "camel_38576": 0, "camel_39959": 0, "camel_22077": 0, "camel_22021": 0, "camel_22398": 0, "camel_22057": 0, "camel_21663": 0, "camel_22324": 0, "camel_38627": 0, "camel_21641": 0, "camel_21612": 0, "camel_23991": 0, "camel_38569": 0, "camel_39996": 0, "camel_23970": 0, "camel_39983": 0, "camel_39963": 0, "camel_21664": 0, "camel_38501": 0, "camel_22296": 0, "camel_22390": 0, "camel_22040": 0, "camel_21678": 0, "camel_22367": 0, "camel_38572": 0, "camel_22344": 0, "camel_39941": 0, "camel_21628": 0, "camel_22248": 0, "camel_22247": 0, "camel_38564": 0, "camel_22246": 0, "camel_39952": 0, "camel_22340": 0, "camel_22055": 0, "camel_22059": 0, "camel_22046": 0, "camel_22061": 0, "camel_22022": 0, "camel_22049": 0, "camel_39999": 0, "camel_22068": 0, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0, "camel_22001": 0, "camel_22075": 0, "camel_39946": 0, "camel_22010": 0, "camel_39932": 0, "camel_22070": 0, "camel_23997": 0, "camel_22031": 0, "camel_22024": 0, "camel_22069": 0, "camel_22330": 0, "camel_22332": 0, "camel_22011": 0, "camel_22060": 0, "camel_39974": 0, "camel_22071": 0, "camel_41246": 0.7768669724464417, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0.8196865916252136, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": 0.8211070895195007, "TheoremQA_maxku/graphtheory7-shortestpath.json": 0.8316251635551453}, "TheoremQA_wenhuchen/euler's_method2.json": {"camel_16970": 0, "camel_16882": 0, "camel_17109": 0, "camel_16941": 0, "camel_16120": 0, "camel_16133": 0, "camel_16820": 0, "camel_16971": 0, "camel_16904": 0, "camel_16001": 0, "camel_17032": 0, "camel_16823": 0, "camel_16131": 0, "camel_16057": 0, "camel_16964": 0, "camel_17007": 0, "camel_16953": 0, "camel_16938": 0, "camel_16084": 0, "camel_16033": 0, "camel_17097": 0, "camel_16838": 0, "camel_17020": 0, "camel_17012": 0, "camel_16989": 0, "camel_16115": 0, "camel_16963": 0, "camel_16898": 0, "camel_16837": 0, "camel_16992": 0, "camel_16030": 0, "camel_16950": 0, "camel_16815": 0, "camel_16937": 0, "camel_16972": 0, "camel_16081": 0, "camel_16107": 0, "camel_17003": 0, "camel_16895": 0, "camel_16899": 0, "camel_16860": 0, "camel_16905": 0, "camel_40334": 0, "camel_16867": 0, "camel_16824": 0, "camel_16140": 0, "camel_17022": 0, "camel_17028": 0, "camel_16894": 0, "camel_16929": 0, "camel_16903": 0, "camel_17018": 0, "camel_16044": 0, "camel_16007": 0, "camel_16884": 0, "camel_17010": 0, "camel_16976": 0, "camel_16153": 0, "camel_16996": 0, "camel_17066": 0, "camel_16089": 0, "camel_16906": 0, "camel_16080": 0, "camel_16919": 0, "camel_16966": 0, "camel_16958": 0, "camel_17030": 0, "camel_16003": 0, "camel_17027": 0, "camel_16154": 0, "camel_16083": 0, "camel_16914": 0, "camel_16888": 0, "camel_16978": 0, "camel_16046": 0, "camel_16961": 0, "camel_16897": 0, "camel_16960": 0, "camel_16922": 0, "camel_17004": 0, "camel_16995": 0, "camel_16952": 0, "camel_16825": 0, "camel_16918": 0, "camel_16901": 0, "camel_16956": 0, "camel_16940": 0, "camel_16997": 0, "camel_16979": 0, "camel_16936": 0, "camel_16157": 0, "camel_17017": 0, "camel_16889": 0, "camel_16988": 0, "camel_16890": 0, "camel_16916": 0, "camel_16973": 0, "camel_16913": 0, "camel_16986": 0, "camel_16925": 0, "camel_16893": 0, "camel_16125": 0, "camel_16944": 0, "camel_16980": 0, "camel_16965": 0, "camel_16917": 0, "camel_16942": 0, "camel_6358": 0, "camel_17000": 0, "camel_16902": 0, "camel_17039": 0, "camel_16943": 0, "camel_16900": 0, "camel_16851": 0, "camel_16921": 0, "camel_16053": 0, "camel_16151": 0, "camel_16149": 0, "camel_20504": 0.7027988433837891, "gsm_rft_21229": 0.7028030753135681, "camel_29790": 0.7028234601020813, "camel_30843": 0.7028577327728271, "gsm_rft_34430": 0.7029376029968262, "camel_29972": 0.7035782337188721, "camel_28789": 0.7036051750183105, "aqua_rat_27960": 0.7036488056182861, "camel_28967": 0.7037258148193359, "camel_28531": 0.7037429213523865, "gsm_train_32181": 0.703942060470581, "gsm_rft_15440": 0.703942060470581, "gsm_train_5852": 0.7039580345153809, "camel_28837": 0.7042280435562134, "camel_29719": 0.7045745253562927, "camel_28107": 0.7045989632606506, "camel_28491": 0.7046770453453064, "aqua_rat_59147": 0.7050949931144714, "aqua_rat_60986": 0.7052504420280457, "camel_29178": 0.7052678465843201, "aqua_rat_32037": 0.7059584856033325, "camel_28515": 0.7060713768005371, "camel_28123": 0.7061156034469604, "camel_30440": 0.7062552571296692, "camel_28064": 0.7067108154296875, "camel_29252": 0.7069699764251709, "camel_29379": 0.7070392370223999, "camel_30409": 0.7074850797653198, "camel_29597": 0.7076677083969116, "aqua_rat_77082": 0.7079977989196777, "camel_28138": 0.7081645131111145, "aqua_rat_84494": 0.7089201807975769, "camel_36269": 0.7092396020889282, "camel_29725": 0.7094211578369141, "camel_29026": 0.7094404697418213, "camel_29072": 0.7097106575965881, "camel_25661": 0.709999680519104, "camel_28993": 0.7103270292282104, "camel_30930": 0.7103759050369263, "aqua_rat_53348": 0.7107717394828796, "aqua_rat_63555": 0.7109866738319397, "camel_28946": 0.7110880613327026, "aqua_rat_47365": 0.7113310098648071, "camel_28178": 0.7113479971885681, "camel_29705": 0.7126220464706421, "camel_29060": 0.7126556038856506, "aqua_rat_12537": 0.7133075594902039, "aqua_rat_12444": 0.7134121060371399, "camel_28549": 0.7135500311851501, "camel_28218": 0.7139211297035217, "gsm_rft_35104": 0.7139943838119507, "gsm_train_10153": 0.7139960527420044, "camel_31255": 0.7144302129745483, "aqua_rat_65312": 0.7144758701324463, "aqua_rat_8703": 0.7149814963340759, "aqua_rat_32487": 0.7152247428894043, "camel_29750": 0.715251624584198, "aqua_rat_56755": 0.7153682112693787, "gsm_rft_21213": 0.7154154181480408, "camel_28024": 0.715823769569397, "camel_29218": 0.7158884406089783, "aqua_rat_8383": 0.7162091135978699, "aqua_rat_11429": 0.7172489166259766, "camel_29108": 0.7186828255653381, "camel_29387": 0.7195038199424744, "camel_20544": 0.7196181416511536, "aqua_rat_58277": 0.7204416394233704, "camel_31045": 0.7211253046989441, "camel_29734": 0.7220346927642822, "camel_28098": 0.7228727340698242, "camel_28973": 0.7233187556266785, "camel_29034": 0.7250717878341675, "camel_28094": 0.7255471348762512, "camel_28227": 0.7262049913406372, "camel_29542": 0.72906893491745, "camel_29163": 0.7293760180473328, "camel_29065": 0.7329513430595398, "camel_28081": 0.7339532375335693, "camel_28502": 0.746004045009613, "camel_28149": 0.7555877566337585, "camel_20486": 0.7577542662620544, "camel_37933": 0.7688894867897034}, "TheoremQA_jianyu_xu/Catalan_2.json": {"camel_20757": 0, "camel_20495": 0, "camel_20741": 0, "camel_20742": 0, "camel_20794": 0, "camel_20548": 0, "camel_21935": 0, "camel_20775": 0, "camel_20773": 0, "camel_20721": 0, "camel_20752": 0, "camel_20760": 0, "camel_20796": 0, "TheoremQA_jianyu_xu/Catalan_2.json": 0, "camel_21970": 0, "camel_21972": 0, "camel_31123": 0.649538516998291, "aqua_rat_56091": 0.6495410799980164, "camel_31171": 0.6500612497329712, "math_train_counting_and_probability_1020": 0.6502366065979004, "aqua_rat_1003": 0.6503475308418274, "camel_30915": 0.6503742337226868, "camel_18691": 0.6505905389785767, "math_train_counting_and_probability_92": 0.6506268382072449, "camel_31935": 0.6507061123847961, "camel_155": 0.6508054137229919, "camel_31170": 0.6508429646492004, "aqua_rat_9047": 0.6509376764297485, "math_train_counting_and_probability_267": 0.6510407328605652, "aqua_rat_39106": 0.6510814428329468, "camel_31933": 0.651290237903595, "camel_31966": 0.6513990163803101, "camel_30925": 0.6514824032783508, "aqua_rat_14484": 0.6516487002372742, "aqua_rat_56916": 0.6516551375389099, "aqua_rat_83284": 0.6518933773040771, "camel_30882": 0.652050256729126, "camel_99": 0.6521068811416626, "aqua_rat_417": 0.6521157026290894, "aqua_rat_60469": 0.652237594127655, "camel_30907": 0.6525949835777283, "camel_31353": 0.6526739001274109, "math_test_algebra_2700": 0.6528468132019043, "camel_30674": 0.653024435043335, "camel_31306": 0.6530292630195618, "math_test_prealgebra_1208": 0.6535709500312805, "camel_154": 0.6537565588951111, "camel_31175": 0.6538147926330566, "camel_30877": 0.6538810729980469, "camel_19685": 0.6539318561553955, "camel_31126": 0.6539382338523865, "aqua_rat_48672": 0.6540184617042542, "aqua_rat_38583": 0.6540682911872864, "aqua_rat_60927": 0.6547533273696899, "camel_31135": 0.654772937297821, "camel_18660": 0.6549896597862244, "aqua_rat_6548": 0.6552624702453613, "camel_18709": 0.6553621888160706, "camel_39138": 0.6558011770248413, "aqua_rat_26025": 0.6559102535247803, "aqua_rat_75509": 0.6563709378242493, "aqua_rat_17054": 0.6572032570838928, "camel_30938": 0.6573615074157715, "math_train_prealgebra_1911": 0.657396674156189, "math_train_geometry_6177": 0.6575409173965454, "math_test_algebra_1592": 0.6577762961387634, "aqua_rat_76534": 0.6581167578697205, "camel_31125": 0.6584975123405457, "aqua_rat_28315": 0.6585993766784668, "aqua_rat_6857": 0.6588432788848877, "aops_2013_AMC_12A_Problems/Problem_13": 0.6588616371154785, "math_test_counting_and_probability_158": 0.6591793298721313, "aqua_rat_58250": 0.6593829989433289, "aqua_rat_41715": 0.6594545841217041, "aqua_rat_18095": 0.6595777869224548, "camel_30702": 0.6596114635467529, "aqua_rat_80856": 0.6597021818161011, "camel_18706": 0.6598613262176514, "math_test_geometry_380": 0.6598783135414124, "math_test_counting_and_probability_1115": 0.6600087285041809, "aqua_rat_61580": 0.6605846285820007, "aqua_rat_34528": 0.6608672142028809, "aqua_rat_28989": 0.660893976688385, "camel_18705": 0.6610522866249084, "camel_30699": 0.661090612411499, "aqua_rat_67605": 0.6614659428596497, "camel_18707": 0.6616199016571045, "camel_18694": 0.6628349423408508, "camel_19973": 0.663318395614624, "camel_31158": 0.6633776426315308, "aqua_rat_47230": 0.663561999797821, "aqua_rat_43895": 0.6636106371879578, "aqua_rat_5820": 0.6638848185539246, "camel_30952": 0.6639664769172668, "camel_30687": 0.6642477512359619, "camel_30908": 0.6643325686454773, "camel_31661": 0.6644206643104553, "camel_30924": 0.6646054983139038, "math_test_algebra_2072": 0.6649104356765747, "math_train_counting_and_probability_802": 0.6653589010238647, "math_test_prealgebra_1608": 0.6655163168907166, "camel_31615": 0.6661921143531799, "aqua_rat_34441": 0.6663458943367004, "camel_31327": 0.6678507328033447, "aqua_rat_66999": 0.6679170727729797, "math_test_counting_and_probability_139": 0.6680293679237366, "aqua_rat_44391": 0.6681755781173706, "camel_18719": 0.6683534979820251, "camel_18664": 0.6688668727874756, "math_train_counting_and_probability_5077": 0.6689803600311279, "camel_31129": 0.6693137884140015, "aqua_rat_78360": 0.6695014238357544, "aqua_rat_57399": 0.6696541905403137, "aqua_rat_57428": 0.6699333190917969, "camel_30931": 0.6712454557418823, "aqua_rat_70794": 0.6713851690292358, "aqua_rat_66103": 0.6717759370803833, "math_train_algebra_545": 0.6719135046005249, "aqua_rat_82949": 0.67197185754776, "aqua_rat_84808": 0.6721403002738953, "aqua_rat_25886": 0.6733915209770203, "camel_19275": 0.6734164953231812, "math_train_prealgebra_403": 0.6743912696838379, "aqua_rat_45906": 0.6747977137565613, "aqua_rat_15854": 0.6751948595046997, "aqua_rat_15080": 0.6756142377853394, "camel_18684": 0.6760138273239136, "aqua_rat_82156": 0.6769130229949951, "camel_30880": 0.6778688430786133, "aqua_rat_47847": 0.6788631677627563, "aqua_rat_70782": 0.6800527572631836, "aqua_rat_88083": 0.680130660533905, "aqua_rat_16851": 0.6801480054855347, "aqua_rat_64536": 0.6806045770645142, "aqua_rat_33200": 0.6811886429786682, "aqua_rat_26236": 0.682584822177887, "math_test_counting_and_probability_767": 0.6827142238616943, "math_test_counting_and_probability_660": 0.6829760670661926, "aqua_rat_76669": 0.6830445528030396, "aqua_rat_40381": 0.6832312345504761, "aqua_rat_43406": 0.6835490465164185, "aqua_rat_47040": 0.683843195438385, "aqua_rat_23372": 0.6841345429420471, "aqua_rat_9503": 0.6841628551483154, "aqua_rat_16581": 0.6843742728233337, "aqua_rat_47821": 0.6844353675842285, "aqua_rat_68227": 0.6844654679298401, "math_test_counting_and_probability_25149": 0.6848973035812378, "aqua_rat_21726": 0.684924304485321, "aqua_rat_66989": 0.6851208806037903, "math_test_counting_and_probability_900": 0.6856934428215027, "aqua_rat_32953": 0.6860080361366272, "camel_18666": 0.6865476369857788, "camel_30700": 0.6878395080566406, "aqua_rat_72870": 0.688653290271759, "aqua_rat_39186": 0.6901543736457825, "math_test_counting_and_probability_195": 0.6908279657363892, "math_test_counting_and_probability_990": 0.6908561587333679, "math_test_geometry_1097": 0.6915583610534668, "aqua_rat_65513": 0.6927301287651062, "aqua_rat_80058": 0.6927935481071472, "math_train_counting_and_probability_5060": 0.6942769289016724, "camel_19952": 0.6953251957893372, "camel_30888": 0.6957424879074097, "camel_18648": 0.6964672207832336, "aqua_rat_50793": 0.6964988708496094, "math_train_counting_and_probability_467": 0.7003462314605713, "aqua_rat_18327": 0.7012701034545898, "aqua_rat_30975": 0.7018429636955261, "camel_18704": 0.7020666599273682, "camel_18654": 0.7030256390571594, "aqua_rat_19919": 0.7035682201385498, "camel_18656": 0.7035858631134033, "aqua_rat_26519": 0.7062130570411682, "math_train_prealgebra_2052": 0.7067042589187622, "aops_1998_AIME_Problems/Problem_2": 0.7076753973960876, "math_train_counting_and_probability_800": 0.7085797190666199, "math_train_counting_and_probability_1034": 0.7093466520309448, "camel_18651": 0.7110786437988281, "math_train_geometry_6105": 0.7133369445800781, "camel_18703": 0.7138891816139221, "camel_18678": 0.7142194509506226, "aqua_rat_86075": 0.7152592539787292, "aqua_rat_49204": 0.7161695957183838, "camel_18718": 0.7168154716491699, "aqua_rat_63779": 0.7171298861503601, "camel_31168": 0.7171713709831238, "camel_18375": 0.7213965058326721, "aqua_rat_912": 0.7232218384742737, "camel_18689": 0.727982759475708, "math_train_counting_and_probability_687": 0.7333747744560242, "aqua_rat_34919": 0.7410957217216492, "aqua_rat_37691": 0.74449622631073, "aqua_rat_66818": 0.748555600643158, "aqua_rat_19731": 0.748669445514679, "aqua_rat_85269": 0.7513816356658936, "aqua_rat_16574": 0.7515981793403625, "aqua_rat_688": 0.7516670823097229, "aqua_rat_51558": 0.7588980793952942, "math_train_counting_and_probability_1024": 0.7742107510566711}, "TheoremQA_wenhuchen/double_integral2.json": {"camel_7779": 0, "camel_7791": 0, "camel_7089": 0, "camel_6340": 0, "camel_6297": 0, "camel_7772": 0, "camel_7778": 0, "camel_7561": 0, "camel_7832": 0, "camel_6384": 0, "camel_6372": 0, "camel_6301": 0, "camel_7811": 0, "camel_7090": 0, "camel_7826": 0, "camel_7817": 0, "camel_7785": 0, "camel_7761": 0, "camel_7555": 0, "camel_7819": 0, "camel_7812": 0, "camel_7709": 0, "camel_6266": 0, "camel_6274": 0, "camel_6241": 0, "camel_6284": 0, "camel_7780": 0, "camel_7072": 0, "camel_7536": 0, "camel_7814": 0, "camel_7069": 0, "camel_7805": 0, "camel_7760": 0, "camel_7786": 0, "camel_7058": 0, "camel_7117": 0, "camel_7776": 0, "camel_7728": 0, "camel_7358": 0, "camel_7837": 0, "camel_6178": 0, "camel_7781": 0, "camel_6257": 0, "camel_7798": 0, "camel_7821": 0, "camel_7815": 0, "camel_7822": 0, "camel_6269": 0, "camel_7783": 0, "camel_7105": 0, "camel_7775": 0, "camel_7764": 0, "camel_6243": 0, "camel_6245": 0, "camel_7100": 0, "camel_7061": 0, "camel_7099": 0, "camel_6983": 0, "camel_7064": 0, "camel_7040": 0, "camel_7831": 0, "camel_7046": 0, "camel_7044": 0, "camel_7803": 0, "camel_7057": 0, "camel_7042": 0, "camel_7092": 0, "camel_7073": 0, "camel_7106": 0, "camel_7074": 0, "camel_7054": 0, "camel_7079": 0, "camel_7045": 0, "camel_7082": 0, "camel_7115": 0, "camel_7816": 0, "camel_7063": 0, "camel_7052": 0, "camel_7093": 0, "camel_7113": 0, "camel_7087": 0, "camel_7076": 0, "camel_7800": 0, "camel_7060": 0, "camel_7112": 0, "camel_7820": 0, "camel_7108": 0, "camel_7796": 0, "camel_7071": 0, "camel_7083": 0, "camel_7114": 0, "camel_7767": 0, "camel_7050": 0, "camel_7830": 0, "camel_7097": 0, "camel_7081": 0, "camel_7056": 0, "TheoremQA_wenhuchen/double_integral2.json": 0, "camel_7051": 0, "camel_7836": 0, "camel_7084": 0, "camel_7086": 0, "camel_7075": 0, "camel_7096": 0, "camel_7119": 0, "camel_7078": 0, "camel_7770": 0, "camel_7088": 0, "camel_7062": 0, "camel_7104": 0, "camel_7801": 0, "camel_6276": 0, "camel_7102": 0, "camel_7048": 0, "camel_7065": 0, "camel_7768": 0, "camel_6286": 0, "camel_6293": 0, "camel_6339": 0, "camel_7080": 0, "camel_7085": 0, "camel_7110": 0, "camel_6252": 0, "camel_7566": 0, "camel_7107": 0, "camel_7043": 0, "camel_7101": 0, "camel_7068": 0, "camel_7047": 0, "camel_7103": 0, "camel_6302": 0, "camel_7041": 0, "camel_3031": 0.7333686947822571, "camel_47000": 0.7334451079368591, "gsm_rft_20767": 0.7335612773895264, "camel_5490": 0.7336122393608093, "camel_17896": 0.7337993383407593, "gsm_train_2385": 0.7338317632675171, "camel_3033": 0.7343508005142212, "camel_43047": 0.7345207333564758, "camel_3014": 0.734821617603302, "camel_2976": 0.7348608374595642, "aqua_rat_41306": 0.7349755764007568, "aqua_rat_45603": 0.735094428062439, "gsm_rft_6982": 0.7351623773574829, "camel_17879": 0.7352545261383057, "aqua_rat_9698": 0.7352668046951294, "camel_39173": 0.7352901697158813, "camel_9006": 0.7356055974960327, "aqua_rat_4140": 0.7358934879302979, "aqua_rat_8308": 0.7365201711654663, "aqua_rat_67621": 0.7370700240135193, "camel_17618": 0.7372780442237854, "camel_2964": 0.7373273372650146, "camel_2998": 0.7374678254127502, "aqua_rat_47444": 0.73750901222229, "aqua_rat_86892": 0.7376704216003418, "aqua_rat_32140": 0.7393122315406799, "aqua_rat_26579": 0.7395818829536438, "camel_3025": 0.7397438287734985, "math_train_geometry_446": 0.7405052185058594, "camel_3037": 0.7407731413841248, "camel_45306": 0.7410498857498169, "gsm_train_11153": 0.7417988181114197, "gsm_rft_35098": 0.7417988181114197, "camel_45338": 0.7433316111564636, "camel_18952": 0.7433851361274719, "math_train_geometry_123": 0.7434998750686646, "math_test_geometry_116": 0.7437585592269897, "gsm_rft_19620": 0.7440781593322754, "gsm_rft_33366": 0.744128406047821, "gsm_rft_3492": 0.7458701133728027, "gsm_train_2325": 0.7458701133728027, "gsm_rft_35006": 0.7462102174758911, "camel_49151": 0.7463191151618958, "camel_45301": 0.7465798854827881, "gsm_train_8387": 0.7468683123588562, "gsm_rft_22116": 0.7476075887680054, "aqua_rat_17718": 0.7490662336349487, "camel_16549": 0.7492430210113525, "camel_45941": 0.7494637370109558, "camel_45310": 0.7506603598594666, "aqua_rat_57267": 0.7514091730117798, "camel_39597": 0.7527300715446472, "TheoremQA_wenhuchen/double_integral1.json": 0.7533969283103943, "gsm_rft_24307": 0.7584421634674072, "gsm_train_23574": 0.7584421634674072, "gsm_rft_14014": 0.7587049603462219, "TheoremQA_xueguangma/fubini_theorem.json": 0.7592819929122925, "camel_39590": 0.7598342895507812, "camel_37070": 0.7602253556251526, "TheoremQA_elainewan/math_calculus_16.json": 0.761033296585083, "camel_16483": 0.766915500164032, "camel_19639": 0.7697224020957947, "math_train_geometry_480": 0.7704291343688965, "camel_19568": 0.7712126970291138, "camel_17238": 0.7748695015907288, "camel_16214": 0.7773029208183289, "camel_45968": 0.7827483415603638, "camel_19895": 0.7993419170379639}, "TheoremQA_xueguangma/forward_price_1.json": {"TheoremQA_xueguangma/forward_price_1.json": 0, "aqua_rat_46898": 0.6673104763031006, "camel_25167": 0.6673259735107422, "gsm_rft_10732": 0.6674206852912903, "gsm_train_7824": 0.6674206852912903, "aqua_rat_55503": 0.6674935221672058, "math_train_algebra_369": 0.667550265789032, "aqua_rat_25723": 0.6675544381141663, "aqua_rat_9965": 0.6675853133201599, "gsm_rft_31646": 0.667742908000946, "aqua_rat_34698": 0.6681520342826843, "gsm_rft_13162": 0.668179452419281, "aqua_rat_18368": 0.6682078838348389, "aqua_rat_40489": 0.6682236194610596, "aqua_rat_56852": 0.6683275103569031, "aqua_rat_49908": 0.6683943271636963, "gsm_train_15200": 0.6684573888778687, "camel_37747": 0.6686614155769348, "aqua_rat_64422": 0.6686677932739258, "gsm_rft_32242": 0.6687942743301392, "gsm_rft_23562": 0.6687942743301392, "aqua_rat_255": 0.6688709259033203, "aqua_rat_77602": 0.6690661311149597, "gsm_rft_33880": 0.6690680980682373, "aqua_rat_83949": 0.6690914034843445, "gsm_rft_33781": 0.6691508293151855, "aqua_rat_87884": 0.6693049073219299, "aqua_rat_15749": 0.6693514585494995, "aqua_rat_32852": 0.6695842742919922, "aqua_rat_33430": 0.6696650385856628, "gsm_rft_23131": 0.6697203516960144, "gsm_rft_32633": 0.6697399616241455, "aqua_rat_7674": 0.6698670387268066, "aqua_rat_80303": 0.6699792742729187, "aqua_rat_28883": 0.6700006127357483, "gsm_rft_34374": 0.670057475566864, "aqua_rat_42017": 0.6700652241706848, "aqua_rat_43060": 0.6701653599739075, "gsm_rft_23250": 0.6701909899711609, "gsm_rft_31288": 0.6702263951301575, "aqua_rat_16442": 0.6702951788902283, "aqua_rat_64914": 0.6703888177871704, "aqua_rat_6008": 0.6713367700576782, "aqua_rat_84309": 0.6714590787887573, "gsm_rft_12005": 0.6714807152748108, "aqua_rat_87589": 0.6715037226676941, "aqua_rat_10855": 0.6715531349182129, "aqua_rat_73390": 0.6716723442077637, "aqua_rat_64976": 0.6720896363258362, "aqua_rat_74914": 0.6721240282058716, "aqua_rat_10582": 0.6722074747085571, "aqua_rat_6634": 0.6722164154052734, "aqua_rat_26022": 0.672471284866333, "aqua_rat_37258": 0.6726047992706299, "gsm_rft_25508": 0.6727030873298645, "gsm_train_22552": 0.6727030873298645, "gsm_train_21876": 0.6727131605148315, "gsm_rft_15888": 0.6727131605148315, "math_test_algebra_1611": 0.6728382110595703, "math_train_algebra_667": 0.672896146774292, "aqua_rat_88687": 0.6729864478111267, "aqua_rat_19740": 0.6730067729949951, "aqua_rat_84306": 0.6733736991882324, "gsm_rft_11628": 0.6733903884887695, "camel_45730": 0.6734601259231567, "aqua_rat_10200": 0.6734828352928162, "gsm_rft_14240": 0.6734937429428101, "gsm_rft_8126": 0.6735178232192993, "gsm_rft_17545": 0.673612654209137, "aqua_rat_68014": 0.6738449931144714, "math_train_algebra_2507": 0.6741600632667542, "aqua_rat_56845": 0.6741891503334045, "gsm_rft_20558": 0.6742135286331177, "gsm_train_2595": 0.6742162108421326, "aqua_rat_87442": 0.67427659034729, "aqua_rat_71424": 0.6742938756942749, "aqua_rat_3773": 0.6744141578674316, "gsm_rft_35170": 0.6745851635932922, "aqua_rat_47176": 0.6746644973754883, "aqua_rat_4548": 0.6747600436210632, "gsm_rft_33006": 0.6747638583183289, "gsm_rft_32767": 0.6751716732978821, "aqua_rat_41101": 0.6751915812492371, "aqua_rat_69905": 0.675268828868866, "aqua_rat_11679": 0.6753476858139038, "aqua_rat_26043": 0.6755396127700806, "aqua_rat_58924": 0.6755469441413879, "aqua_rat_73957": 0.6755985617637634, "aqua_rat_57431": 0.6756134629249573, "gsm_rft_10656": 0.6756253242492676, "gsm_rft_7115": 0.6756510138511658, "gsm_train_9412": 0.6756510138511658, "aqua_rat_24068": 0.675705075263977, "aqua_rat_67076": 0.6761648058891296, "aqua_rat_40411": 0.6761830449104309, "aqua_rat_67442": 0.6762202382087708, "math_test_algebra_2626": 0.6762327551841736, "aqua_rat_51100": 0.6765378713607788, "gsm_rft_7924": 0.6766242980957031, "aqua_rat_30386": 0.6766926646232605, "aqua_rat_3885": 0.6767846345901489, "aqua_rat_16258": 0.6770616769790649, "aqua_rat_27035": 0.6772199273109436, "gsm_rft_31720": 0.6772974729537964, "gsm_train_22362": 0.6774917840957642, "aqua_rat_71239": 0.677664577960968, "gsm_rft_24249": 0.6780076026916504, "gsm_rft_15345": 0.6780427694320679, "gsm_train_6234": 0.6780427694320679, "gsm_rft_13224": 0.6780427694320679, "gsm_rft_15946": 0.6781681180000305, "aqua_rat_57864": 0.6782594919204712, "aqua_rat_63322": 0.6784092783927917, "gsm_rft_18143": 0.6791359782218933, "aqua_rat_69547": 0.6792213916778564, "gsm_rft_3890": 0.6792302131652832, "aqua_rat_15079": 0.6794491410255432, "aqua_rat_66917": 0.6796663999557495, "aqua_rat_611": 0.67977374792099, "aqua_rat_60935": 0.6800299882888794, "gsm_train_29580": 0.6804256439208984, "aqua_rat_23836": 0.6804648637771606, "gsm_rft_24082": 0.6806457042694092, "aqua_rat_50660": 0.6807251572608948, "aqua_rat_15556": 0.6809585690498352, "aqua_rat_56922": 0.6809653043746948, "aqua_rat_78121": 0.6810176968574524, "gsm_rft_30907": 0.681137204170227, "aqua_rat_78533": 0.6820587515830994, "aqua_rat_72737": 0.6822336316108704, "aqua_rat_79047": 0.6822596788406372, "gsm_rft_6422": 0.6826016902923584, "math_test_algebra_311": 0.6826629638671875, "TheoremQA_xueguangma/present_value_1.json": 0.6831684112548828, "math_train_algebra_1658": 0.683342695236206, "aqua_rat_11544": 0.6835875511169434, "aqua_rat_26425": 0.6835921406745911, "aqua_rat_20758": 0.6839964389801025, "aqua_rat_9530": 0.6839988231658936, "aqua_rat_36461": 0.6842601299285889, "aqua_rat_66371": 0.6842734217643738, "aqua_rat_57507": 0.6846285462379456, "math_test_algebra_1862": 0.6848275065422058, "aqua_rat_62727": 0.6851181387901306, "aqua_rat_57683": 0.685525119304657, "gsm_rft_7026": 0.6855287551879883, "aqua_rat_88843": 0.685529887676239, "aqua_rat_45867": 0.6855679154396057, "aqua_rat_70160": 0.685626208782196, "gsm_rft_16062": 0.6856968998908997, "gsm_rft_33978": 0.6859990954399109, "gsm_train_34054": 0.6859990954399109, "gsm_train_19719": 0.6862044930458069, "gsm_rft_25231": 0.6862044930458069, "math_train_algebra_940": 0.6863588094711304, "aqua_rat_30597": 0.6872574090957642, "aqua_rat_54684": 0.6872662901878357, "camel_16747": 0.6875774264335632, "aqua_rat_32321": 0.6875910758972168, "aqua_rat_67914": 0.6893031001091003, "aqua_rat_46315": 0.6894766092300415, "aqua_rat_56436": 0.6896787285804749, "aqua_rat_77486": 0.689895749092102, "gsm_train_6037": 0.6899614334106445, "gsm_rft_15334": 0.6899614334106445, "gsm_rft_8605": 0.6917108297348022, "gsm_rft_33659": 0.6919379234313965, "gsm_train_18514": 0.6919980645179749, "gsm_rft_24497": 0.6928988695144653, "camel_45738": 0.694132924079895, "aqua_rat_87484": 0.6945942044258118, "aqua_rat_47761": 0.6952111124992371, "aqua_rat_16445": 0.6956548690795898, "aqua_rat_14728": 0.6957079768180847, "gsm_rft_7096": 0.696441650390625, "gsm_rft_11804": 0.6966245770454407, "camel_37735": 0.696785032749176, "gsm_rft_26458": 0.7014483213424683, "camel_37746": 0.7027772068977356, "aqua_rat_79856": 0.7087821364402771, "aqua_rat_80676": 0.708782434463501, "gsm_rft_12584": 0.7128936052322388, "gsm_train_28727": 0.7131608128547668, "gsm_rft_35249": 0.7134889960289001, "aqua_rat_85902": 0.713604748249054, "TheoremQA_xueguangma/spot_rate.json": 0.7138116359710693, "aqua_rat_29154": 0.7148988246917725, "gsm_rft_19766": 0.7174257636070251, "gsm_rft_30946": 0.718981146812439, "gsm_train_34036": 0.7196752429008484, "gsm_rft_20212": 0.7211974263191223, "gsm_rft_9014": 0.722934365272522, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7236188650131226, "aqua_rat_49352": 0.7276201248168945, "aqua_rat_45508": 0.7276995778083801, "aqua_rat_36498": 0.7277798056602478, "TheoremQA_xueguangma/put_call_parity_1.json": 0.7401455044746399, "aqua_rat_31553": 0.7430400252342224, "TheoremQA_xueguangma/forward_price_3.json": 0.7576732635498047, "TheoremQA_xueguangma/forward_price_2.json": 0.7937291860580444}, "TheoremQA_wenhuchen/cauchy_integral1.json": {"camel_42065": 0, "camel_42071": 0, "camel_42193": 0, "camel_42201": 0, "camel_43486": 0, "camel_42819": 0, "camel_42207": 0, "camel_42206": 0, "camel_42190": 0, "camel_42192": 0, "camel_42359": 0, "camel_43494": 0, "camel_42186": 0, "camel_43117": 0, "camel_42238": 0, "camel_42169": 0, "camel_42495": 0, "camel_43455": 0, "camel_42195": 0, "camel_42191": 0, "camel_42161": 0, "camel_42225": 0, "camel_42218": 0, "camel_42168": 0, "camel_42220": 0, "camel_42224": 0, "camel_42187": 0, "camel_42176": 0, "camel_43809": 0, "camel_43823": 0, "camel_42197": 0, "camel_42164": 0, "camel_42167": 0, "camel_42183": 0, "camel_43426": 0, "camel_42198": 0, "camel_43009": 0, "camel_43019": 0, "camel_42178": 0, "camel_42229": 0, "camel_42200": 0, "camel_43493": 0, "TheoremQA_wenhuchen/cauchy_integral1.json": 0, "camel_42131": 0, "camel_42165": 0, "camel_43480": 0, "camel_42211": 0, "camel_42181": 0, "camel_42180": 0, "camel_42166": 0, "camel_43450": 0, "camel_42230": 0, "camel_42237": 0, "camel_42223": 0, "camel_42214": 0, "camel_43501": 0, "camel_42162": 0, "camel_42236": 0, "camel_42208": 0, "camel_2418": 0.6949763298034668, "camel_2449": 0.6949763298034668, "camel_47766": 0.695054829120636, "camel_3546": 0.6950615644454956, "camel_5342": 0.6951388120651245, "aqua_rat_21981": 0.6952089071273804, "camel_30305": 0.6953728795051575, "camel_28273": 0.6954095959663391, "camel_17294": 0.6954687833786011, "camel_45120": 0.6958481073379517, "camel_17299": 0.6958963871002197, "camel_3587": 0.6958970427513123, "camel_45299": 0.6959271430969238, "camel_3570": 0.6959487795829773, "camel_30242": 0.6960290670394897, "camel_45622": 0.6962302327156067, "camel_46105": 0.6962391138076782, "camel_5354": 0.6964316368103027, "aqua_rat_51123": 0.6970545053482056, "camel_3557": 0.697075605392456, "math_test_prealgebra_1423": 0.6973604559898376, "camel_3197": 0.6974555253982544, "camel_17252": 0.6976280212402344, "camel_5079": 0.697766900062561, "camel_3583": 0.6977764964103699, "camel_28299": 0.6978551149368286, "camel_17273": 0.6981245875358582, "camel_2408": 0.6981709599494934, "camel_47290": 0.6982460618019104, "camel_45174": 0.698381245136261, "camel_17270": 0.698824405670166, "camel_28260": 0.6989233493804932, "camel_45003": 0.6990507245063782, "camel_2469": 0.699139416217804, "camel_3530": 0.6992316246032715, "camel_5177": 0.6996669769287109, "camel_30319": 0.7000861167907715, "camel_44981": 0.7004015445709229, "camel_5093": 0.7005853652954102, "camel_2479": 0.7007975578308105, "camel_3194": 0.7011701464653015, "camel_5004": 0.7013898491859436, "camel_46101": 0.7014129757881165, "camel_28306": 0.7015051245689392, "math_test_prealgebra_393": 0.7015916705131531, "camel_17282": 0.701592206954956, "camel_17337": 0.7017551064491272, "camel_3593": 0.7019941806793213, "camel_5197": 0.7023835182189941, "camel_17353": 0.7024033665657043, "camel_7053": 0.7026940584182739, "camel_5285": 0.7027716636657715, "camel_30306": 0.7027975916862488, "camel_5070": 0.702887237071991, "camel_3701": 0.7029007077217102, "camel_30211": 0.7031128406524658, "camel_17265": 0.7032980918884277, "camel_2476": 0.704513430595398, "camel_2445": 0.7048954367637634, "camel_30171": 0.7049713730812073, "camel_47373": 0.704976499080658, "camel_3592": 0.7057862281799316, "camel_17283": 0.7059556841850281, "camel_30260": 0.7059963345527649, "camel_30160": 0.7064242362976074, "camel_17285": 0.7066280841827393, "camel_2413": 0.7069160342216492, "camel_17251": 0.7071616649627686, "camel_3750": 0.7072983980178833, "camel_19728": 0.7073243856430054, "camel_39338": 0.7073678374290466, "camel_5178": 0.7077658176422119, "camel_17256": 0.7077664732933044, "camel_30206": 0.7079950571060181, "camel_30219": 0.7080894112586975, "camel_3145": 0.708685040473938, "camel_19715": 0.7089372277259827, "camel_45639": 0.7091379761695862, "camel_28245": 0.7092725038528442, "camel_28265": 0.7103078365325928, "math_train_algebra_2034": 0.7114419341087341, "camel_2456": 0.7120013236999512, "camel_17213": 0.7121591567993164, "camel_5189": 0.7121865153312683, "camel_17254": 0.7124337553977966, "camel_39254": 0.7124824523925781, "camel_46100": 0.7126851677894592, "math_test_algebra_1169": 0.7126863598823547, "camel_45620": 0.7128931283950806, "camel_28262": 0.7129701375961304, "camel_47769": 0.7135753035545349, "camel_17280": 0.7143862247467041, "camel_17354": 0.7144171595573425, "camel_30293": 0.7144842147827148, "camel_17225": 0.7145319581031799, "camel_17358": 0.7147397994995117, "camel_17269": 0.7153096795082092, "aqua_rat_16864": 0.7153298854827881, "camel_19664": 0.7155038118362427, "camel_17243": 0.7159247994422913, "camel_7731": 0.7161505222320557, "camel_47478": 0.7171661257743835, "camel_17325": 0.7174915075302124, "math_test_geometry_602": 0.7176592350006104, "camel_3537": 0.71799236536026, "camel_45626": 0.718818724155426, "camel_17301": 0.7188447713851929, "camel_45645": 0.719121515750885, "camel_47347": 0.7193915843963623, "math_test_prealgebra_1007": 0.7199805378913879, "camel_17335": 0.7206947207450867, "camel_19622": 0.7209572792053223, "camel_19600": 0.7209875583648682, "camel_30167": 0.721074640750885, "camel_45673": 0.7212862968444824, "camel_28313": 0.7215087413787842, "camel_5165": 0.7219514846801758, "camel_17286": 0.7222859859466553, "camel_47356": 0.7237762808799744, "camel_19768": 0.7240820527076721, "camel_28279": 0.7243048548698425, "camel_17272": 0.7251957058906555, "camel_17333": 0.7259249091148376, "camel_17340": 0.7266234755516052, "camel_17352": 0.7266530394554138, "camel_30303": 0.727344810962677, "aqua_rat_74869": 0.7279581427574158, "camel_17261": 0.729471743106842, "camel_44680": 0.731322169303894, "camel_5344": 0.7324252128601074, "aqua_rat_75605": 0.7344743609428406, "camel_45668": 0.7368567585945129, "camel_45621": 0.7430053353309631, "camel_5284": 0.7451472282409668, "camel_45679": 0.7452161908149719, "camel_17214": 0.7460830211639404, "camel_17323": 0.7461218237876892, "camel_3148": 0.7480359673500061, "camel_45315": 0.7495401501655579, "camel_19717": 0.7738083004951477, "camel_19647": 0.7815435528755188}, "TheoremQA_panlu/gravitational_force1.json": {"TheoremQA_panlu/gravitational_force1.json": 0, "gsm_rft_8897": 0.6123120188713074, "gsm_rft_4583": 0.6123287677764893, "gsm_train_2068": 0.6123287677764893, "camel_7993": 0.6123685836791992, "gsm_rft_9527": 0.6124293208122253, "gsm_rft_10259": 0.6125264763832092, "gsm_train_12141": 0.6125264763832092, "camel_7527": 0.6125271916389465, "gsm_rft_15576": 0.6125771999359131, "gsm_rft_21589": 0.6128602623939514, "gsm_rft_18791": 0.6135608553886414, "gsm_rft_24421": 0.6137808561325073, "math_train_algebra_256": 0.6138289570808411, "camel_28815": 0.6138343214988708, "gsm_train_8166": 0.6141892075538635, "gsm_rft_7211": 0.6144565343856812, "camel_28823": 0.6145435571670532, "camel_28837": 0.6152698993682861, "camel_28861": 0.615461528301239, "camel_28845": 0.6157771348953247, "camel_28836": 0.616039514541626, "gsm_rft_14306": 0.6161718964576721, "camel_7997": 0.616184413433075, "gsm_rft_14979": 0.616661012172699, "gsm_rft_16695": 0.6169727444648743, "aqua_rat_5613": 0.6170608997344971, "gsm_rft_18266": 0.6184065937995911, "gsm_train_553": 0.6184065937995911, "camel_7528": 0.6185461282730103, "camel_7567": 0.6185537576675415, "camel_28806": 0.6187778115272522, "camel_7972": 0.6189643144607544, "camel_39462": 0.619209349155426, "camel_7973": 0.619422197341919, "camel_7550": 0.6195961236953735, "camel_45673": 0.6197754144668579, "camel_7557": 0.6200795769691467, "camel_28855": 0.6202872395515442, "camel_28818": 0.6208191514015198, "camel_28537": 0.6208796501159668, "aqua_rat_19334": 0.6209139227867126, "camel_29489": 0.6209844946861267, "camel_28532": 0.6217923164367676, "camel_39450": 0.6219787001609802, "camel_28860": 0.6222542524337769, "camel_7535": 0.6222985982894897, "camel_7565": 0.6224207878112793, "camel_7964": 0.6227002739906311, "camel_29484": 0.6227065324783325, "camel_7588": 0.6228306293487549, "camel_28832": 0.6232216954231262, "camel_28137": 0.6234533786773682, "gsm_rft_29554": 0.6238909959793091, "camel_28862": 0.6241440773010254, "camel_5885": 0.6242232322692871, "camel_7988": 0.6250645518302917, "TheoremQA_panlu/fluid_pressure1.json": 0.6252432465553284, "camel_7947": 0.6254454255104065, "TheoremQA_tonyxia/atom4.json": 0.6256049871444702, "camel_28864": 0.6256757378578186, "camel_16249": 0.6258204579353333, "gsm_rft_10505": 0.6261477470397949, "camel_7960": 0.6261842846870422, "camel_28867": 0.6262152194976807, "TheoremQA_panlu/young\u2019s_modulus1.json": 0.626571774482727, "camel_7954": 0.6267122626304626, "gsm_rft_22533": 0.6270241737365723, "camel_28807": 0.6271607279777527, "camel_39511": 0.6273927688598633, "camel_28022": 0.6275955438613892, "TheoremQA_panlu/uniform_circular_motion1.json": 0.6282743215560913, "camel_4979": 0.6284363269805908, "aqua_rat_36865": 0.628987193107605, "aqua_rat_18184": 0.62947678565979, "aqua_rat_2612": 0.6303732991218567, "camel_7922": 0.6304315328598022, "aqua_rat_4869": 0.6314296126365662, "camel_7966": 0.6318873763084412, "camel_5759": 0.6328185796737671, "camel_16246": 0.6330239176750183, "gsm_rft_10934": 0.6332205533981323, "gsm_rft_1431": 0.6332749128341675, "aqua_rat_75922": 0.6341006755828857, "camel_28842": 0.6345080733299255, "gsm_train_23496": 0.6348081231117249, "camel_7480": 0.6350532174110413, "TheoremQA_wenhuchen/Fluid_mechanics2.json": 0.6354144215583801, "camel_28800": 0.6356271505355835, "TheoremQA_tonyxia/relativity3.json": 0.6359479427337646, "gsm_rft_32685": 0.6361998915672302, "camel_28853": 0.6372025609016418, "camel_5705": 0.6375827193260193, "camel_39517": 0.6377462148666382, "camel_7590": 0.6378183960914612, "aqua_rat_67038": 0.6383801102638245, "camel_17542": 0.6384463906288147, "camel_7999": 0.6387515664100647, "gsm_rft_17764": 0.6387656331062317, "camel_7951": 0.6388672590255737, "gsm_train_29099": 0.6390124559402466, "camel_28831": 0.639067530632019, "camel_7945": 0.6396335363388062, "gsm_rft_22397": 0.6398962736129761, "camel_5714": 0.6419146060943604, "camel_39475": 0.6424097418785095, "camel_7587": 0.6427708268165588, "camel_39469": 0.644041121006012, "camel_7594": 0.6445895433425903, "camel_17565": 0.6448181867599487, "camel_7476": 0.6448854207992554, "camel_16247": 0.6455665230751038, "camel_39504": 0.6456631422042847, "camel_39460": 0.6476201415061951, "camel_4731": 0.6480919122695923, "camel_28909": 0.6485208868980408, "camel_5844": 0.6485369801521301, "camel_28812": 0.6489676833152771, "camel_28875": 0.6496583223342896, "camel_7934": 0.6503953337669373, "camel_7597": 0.6515289545059204, "math_train_algebra_1622": 0.6518543362617493, "camel_6246": 0.6520206928253174, "TheoremQA_wenhuchen/kepler's_law3.json": 0.6522319912910461, "camel_7998": 0.6522424221038818, "camel_28826": 0.6535757184028625, "camel_7498": 0.6541190147399902, "camel_7980": 0.6558302044868469, "camel_43563": 0.6572454571723938, "camel_7959": 0.6572991013526917, "camel_39308": 0.6573104858398438, "camel_29979": 0.6575482487678528, "camel_28816": 0.6590092778205872, "camel_7928": 0.6592730283737183, "camel_7592": 0.6593844890594482, "camel_28871": 0.6594425439834595, "camel_7584": 0.6604169607162476, "camel_28809": 0.6612148880958557, "camel_39452": 0.6616737246513367, "camel_39476": 0.6627300381660461, "TheoremQA_xinyi/work_energy_theorem.json": 0.6630750894546509, "camel_5880": 0.6634626388549805, "camel_7546": 0.6640934944152832, "camel_28068": 0.6646119356155396, "camel_39484": 0.6650969982147217, "camel_39467": 0.6668521761894226, "camel_7580": 0.6698610186576843, "camel_7984": 0.6699470281600952, "camel_28879": 0.6733799576759338, "camel_28820": 0.6773713827133179, "camel_28808": 0.6783323884010315, "camel_7982": 0.6788886189460754, "camel_39513": 0.6794317960739136, "camel_7578": 0.6796038150787354, "camel_28822": 0.6805174350738525, "camel_5842": 0.6808506846427917, "camel_28833": 0.6811550855636597, "camel_39485": 0.6823869347572327, "camel_39453": 0.6830188632011414, "camel_17406": 0.6839056611061096, "camel_28865": 0.684343159198761, "math_train_algebra_24942": 0.6884459853172302, "camel_28872": 0.6886667013168335, "camel_7995": 0.689524233341217, "camel_28866": 0.6905614733695984, "camel_39461": 0.6913688778877258, "camel_28873": 0.692773699760437, "camel_7595": 0.6948608756065369, "camel_7563": 0.6951320171356201, "TheoremQA_panlu/angular_frequency3.json": 0.6970251202583313, "TheoremQA_panlu/black_hole1.json": 0.6971433162689209, "camel_39479": 0.6985606551170349, "camel_7572": 0.6988820433616638, "camel_5001": 0.6991110444068909, "camel_7977": 0.6996647119522095, "camel_7541": 0.7017984986305237, "camel_28804": 0.7065491080284119, "camel_39449": 0.7065738439559937, "camel_5857": 0.7072404026985168, "camel_28868": 0.7084755897521973, "camel_7937": 0.7100942134857178, "camel_28840": 0.7173405289649963, "camel_7586": 0.7174501419067383, "camel_28856": 0.7211616635322571, "camel_39488": 0.7243367433547974, "camel_28811": 0.7262707352638245, "camel_39455": 0.7353652715682983, "camel_28846": 0.7381134629249573, "camel_39515": 0.7381241917610168, "math_test_algebra_518": 0.7382512092590332, "camel_28847": 0.7414533495903015, "camel_7552": 0.746971070766449, "camel_39447": 0.7477637529373169, "camel_7938": 0.7667821049690247, "TheoremQA_panlu/energy_conservation1.json": 0.7683402895927429, "camel_39508": 0.7708170413970947, "camel_7944": 0.7827001214027405, "TheoremQA_panlu/gravitational_force2.json": 0.8697109818458557, "math_train_algebra_2156": 0.8852187395095825, "TheoremQA_wenhuchen/kepler's_law2.json": 0.9014198184013367}, "TheoremQA_maxku/signalprocessing13-Ztransform.json": {"TheoremQA_maxku/signalprocessing13-Ztransform.json": 0, "camel_44769": 0.6354613900184631, "camel_45312": 0.6355052590370178, "camel_17813": 0.6355581283569336, "camel_29832": 0.6356149315834045, "camel_45689": 0.6356614232063293, "camel_29371": 0.6357731223106384, "camel_29951": 0.635780930519104, "camel_44759": 0.6359481811523438, "camel_45829": 0.6360307931900024, "camel_17621": 0.6360346674919128, "camel_29964": 0.6360487341880798, "camel_29877": 0.6361849904060364, "camel_45740": 0.6362366676330566, "camel_29244": 0.6362524628639221, "camel_16346": 0.6362990736961365, "camel_16331": 0.636622965335846, "camel_45414": 0.6368349194526672, "camel_45392": 0.6372069716453552, "camel_45384": 0.6372429728507996, "camel_44751": 0.6375811100006104, "camel_45516": 0.6377488970756531, "camel_29971": 0.6377546787261963, "camel_28119": 0.6377990245819092, "camel_45508": 0.6381758451461792, "camel_31176": 0.6382686495780945, "camel_29437": 0.6384530067443848, "camel_29685": 0.6386007070541382, "camel_29277": 0.6386040449142456, "camel_45507": 0.6386264562606812, "camel_17435": 0.6386291980743408, "camel_44373": 0.6386361122131348, "camel_29432": 0.6387407183647156, "camel_29684": 0.6388760209083557, "camel_45803": 0.6389291882514954, "camel_45831": 0.639038622379303, "camel_45503": 0.639183521270752, "camel_39510": 0.63918536901474, "camel_45315": 0.6392868161201477, "camel_17631": 0.6395208239555359, "camel_29379": 0.6395609974861145, "camel_29972": 0.6396598815917969, "camel_29434": 0.6397481560707092, "camel_29215": 0.6397729516029358, "camel_45453": 0.6397757530212402, "camel_45627": 0.6397922039031982, "camel_29710": 0.6399965882301331, "camel_45452": 0.6402704119682312, "camel_45754": 0.6404035687446594, "camel_44848": 0.6404416561126709, "camel_29893": 0.6405055522918701, "camel_45462": 0.6405332684516907, "camel_45418": 0.6406543850898743, "camel_28081": 0.6407622694969177, "camel_29916": 0.6408072710037231, "camel_29178": 0.6409150958061218, "camel_29725": 0.6409602761268616, "camel_44451": 0.6409706473350525, "camel_29997": 0.6411629319190979, "camel_31323": 0.6412276029586792, "camel_29750": 0.6412801742553711, "camel_45494": 0.6412903666496277, "camel_29276": 0.641446590423584, "camel_29229": 0.6414971947669983, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.6419029831886292, "camel_29992": 0.6419424414634705, "camel_45786": 0.6422088742256165, "camel_29692": 0.6423494219779968, "camel_29749": 0.6424967646598816, "camel_29395": 0.6429336667060852, "camel_26484": 0.6429579854011536, "camel_45823": 0.6430225372314453, "camel_17789": 0.643099844455719, "camel_29729": 0.6431416869163513, "camel_29243": 0.6431681513786316, "camel_29969": 0.6433727741241455, "camel_45370": 0.6434276103973389, "camel_44774": 0.6435263156890869, "camel_28379": 0.6437217593193054, "camel_29899": 0.6437471508979797, "camel_29861": 0.6437593698501587, "camel_45409": 0.6440443396568298, "camel_44746": 0.6440565586090088, "camel_29392": 0.6441887617111206, "camel_44772": 0.6442086696624756, "camel_45498": 0.6442168354988098, "camel_45429": 0.6443472504615784, "camel_45836": 0.6446343660354614, "camel_45457": 0.6447138786315918, "camel_29741": 0.6448237299919128, "TheoremQA_maxku/cv-cnn1.json": 0.6448419094085693, "camel_45171": 0.6448462605476379, "camel_45834": 0.6450966596603394, "camel_44786": 0.6453084349632263, "camel_45772": 0.6453408598899841, "camel_29228": 0.6453512907028198, "camel_45402": 0.6454267501831055, "camel_29438": 0.6455405354499817, "camel_44768": 0.6455911993980408, "camel_44732": 0.6458039879798889, "camel_44760": 0.6459463834762573, "camel_44752": 0.6460615396499634, "camel_45826": 0.6460703611373901, "camel_44775": 0.6464895009994507, "camel_26522": 0.646516740322113, "camel_29925": 0.6465897560119629, "camel_29387": 0.6466189622879028, "camel_29184": 0.6467787027359009, "camel_29245": 0.6467820405960083, "camel_45701": 0.6467994451522827, "camel_44806": 0.6470111012458801, "camel_44795": 0.6470124125480652, "camel_45722": 0.6472650170326233, "camel_45174": 0.6472991108894348, "camel_37933": 0.647367000579834, "TheoremQA_maxku/cv-cnn4.json": 0.6475186347961426, "camel_44796": 0.6475338935852051, "camel_37476": 0.6480918526649475, "camel_29372": 0.648194432258606, "camel_29429": 0.6485635042190552, "camel_29388": 0.649005115032196, "camel_28787": 0.6490283012390137, "camel_45502": 0.6490288376808167, "camel_44742": 0.64922696352005, "camel_29711": 0.6497290134429932, "camel_17776": 0.6500312089920044, "camel_44443": 0.6502834558486938, "camel_44793": 0.6504381895065308, "camel_29426": 0.650450587272644, "camel_29693": 0.6505627036094666, "camel_45151": 0.6506205797195435, "camel_45693": 0.6506556272506714, "camel_44776": 0.6510250568389893, "camel_45368": 0.6511606574058533, "camel_45682": 0.6512611508369446, "camel_29705": 0.6516855359077454, "camel_44727": 0.6519104242324829, "camel_44744": 0.6521310806274414, "camel_44790": 0.6527918577194214, "camel_45688": 0.6527936458587646, "camel_45684": 0.6528486013412476, "camel_45936": 0.6532856225967407, "camel_29227": 0.6535425782203674, "camel_29687": 0.653560221195221, "camel_44797": 0.6539437174797058, "camel_44872": 0.6540112495422363, "camel_45146": 0.6542514562606812, "camel_45709": 0.6543770432472229, "camel_45410": 0.6545880436897278, "camel_45489": 0.654768705368042, "camel_44766": 0.6549015045166016, "camel_45374": 0.654922604560852, "camel_29204": 0.6556452512741089, "camel_26519": 0.6562438607215881, "camel_29695": 0.6566715836524963, "gsm_train_20944": 0.6571118831634521, "gsm_rft_21298": 0.6571118831634521, "camel_45430": 0.6575367450714111, "camel_29273": 0.6578295230865479, "camel_45698": 0.658039927482605, "camel_45490": 0.6582193374633789, "camel_45518": 0.6584151983261108, "camel_45762": 0.6591569185256958, "camel_29373": 0.659285306930542, "camel_45487": 0.6593618392944336, "camel_29691": 0.659485399723053, "camel_45476": 0.6595535278320312, "gsm_rft_33863": 0.6603268980979919, "camel_17639": 0.6605881452560425, "camel_45512": 0.6606499552726746, "camel_44748": 0.660986065864563, "camel_45931": 0.6612067222595215, "camel_29278": 0.6616836190223694, "camel_29727": 0.6620135307312012, "camel_45468": 0.6624982357025146, "camel_45380": 0.662777841091156, "camel_29279": 0.6629141569137573, "camel_44838": 0.6646141409873962, "gsm_rft_11471": 0.6648770570755005, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.6649968028068542, "camel_29708": 0.6652886271476746, "camel_29219": 0.6652889251708984, "camel_29681": 0.6654950380325317, "camel_44728": 0.6660326719284058, "camel_44424": 0.6663589477539062, "camel_26497": 0.6669548749923706, "camel_45318": 0.6675593852996826, "camel_29205": 0.6681382656097412, "camel_29252": 0.6684097647666931, "camel_29218": 0.6698783040046692, "camel_44782": 0.6703372597694397, "camel_26505": 0.6756507158279419, "camel_29734": 0.6795740127563477, "camel_44798": 0.6809530854225159, "camel_29704": 0.6872554421424866, "camel_17674": 0.6951189637184143, "camel_29719": 0.6976024508476257, "TheoremQA_maxku/signalprocessing14-Ztransform.json": 0.7080630660057068, "TheoremQA_maxku/signalprocessing6-Ztransform.json": 0.7528656125068665, "TheoremQA_maxku/signalprocessing4-Ztransform.json": 0.8608679175376892}, "TheoremQA_jianyu_xu/Multinomial_2.json": {"camel_21015": 0, "camel_20637": 0, "camel_20609": 0, "camel_20802": 0, "camel_20693": 0, "camel_21251": 0, "camel_21049": 0, "camel_20661": 0, "camel_21236": 0, "camel_21528": 0, "camel_20256": 0, "camel_21360": 0, "camel_21363": 0, "camel_21431": 0, "camel_21429": 0, "camel_21050": 0, "camel_21264": 0, "camel_20540": 0, "camel_21055": 0, "camel_21213": 0, "camel_20378": 0, "camel_21379": 0, "camel_21110": 0, "camel_20656": 0, "camel_21022": 0, "camel_20808": 0, "camel_21822": 0, "camel_21808": 0, "camel_20623": 0, "camel_20255": 0, "camel_21572": 0, "camel_20571": 0, "camel_20611": 0, "camel_21430": 0, "camel_21568": 0, "camel_21034": 0, "camel_20598": 0, "camel_21411": 0, "camel_21405": 0, "camel_21371": 0, "camel_20364": 0, "camel_21215": 0, "camel_20946": 0, "camel_21393": 0, "camel_20851": 0, "camel_21386": 0, "camel_20599": 0, "camel_20577": 0, "camel_20564": 0, "camel_21081": 0, "camel_20596": 0, "camel_20046": 0, "camel_20309": 0, "camel_20512": 0, "camel_21202": 0, "camel_21039": 0, "TheoremQA_jianyu_xu/Multinomial_2.json": 0, "aqua_rat_82553": 0.7362322211265564, "aqua_rat_30355": 0.7364229559898376, "aqua_rat_27717": 0.7366822957992554, "aqua_rat_26756": 0.736840546131134, "aqua_rat_2725": 0.7368952035903931, "aqua_rat_14532": 0.7369182705879211, "aqua_rat_13232": 0.7369517683982849, "math_train_counting_and_probability_122": 0.7372207045555115, "aqua_rat_79193": 0.7372549772262573, "aqua_rat_72210": 0.7373734712600708, "aqua_rat_52067": 0.7375485301017761, "aqua_rat_73402": 0.7382584810256958, "aqua_rat_82104": 0.7382647395133972, "aqua_rat_34205": 0.7383444309234619, "aqua_rat_87992": 0.7385097742080688, "aqua_rat_6961": 0.7387006282806396, "aqua_rat_51352": 0.7388885617256165, "aqua_rat_48109": 0.7389817237854004, "aqua_rat_73122": 0.7391082048416138, "aqua_rat_37185": 0.7391411066055298, "aqua_rat_73040": 0.7392758131027222, "aqua_rat_65651": 0.7397491931915283, "math_train_counting_and_probability_249": 0.7397838830947876, "aqua_rat_39411": 0.7398766875267029, "aqua_rat_39610": 0.739885687828064, "aqua_rat_9556": 0.7398907542228699, "math_train_counting_and_probability_897": 0.7399062514305115, "math_train_counting_and_probability_929": 0.739923894405365, "aqua_rat_43064": 0.740121066570282, "aqua_rat_76271": 0.7402476668357849, "aqua_rat_61965": 0.7404874563217163, "aqua_rat_34420": 0.7409696578979492, "aqua_rat_54461": 0.7409891486167908, "aqua_rat_41506": 0.7410076260566711, "math_test_counting_and_probability_341": 0.7417300939559937, "aqua_rat_55839": 0.7417314648628235, "aqua_rat_7341": 0.7419605851173401, "aqua_rat_78732": 0.7420215010643005, "aqua_rat_81265": 0.7422101497650146, "aqua_rat_38594": 0.7423122525215149, "math_train_counting_and_probability_373": 0.742487370967865, "aqua_rat_8519": 0.7429669499397278, "aqua_rat_28657": 0.7431127429008484, "aqua_rat_60755": 0.7433966994285583, "math_train_counting_and_probability_918": 0.7439401745796204, "aqua_rat_34946": 0.7441807985305786, "aqua_rat_66465": 0.7443686723709106, "aqua_rat_80668": 0.7444132566452026, "aqua_rat_65907": 0.7445085644721985, "aqua_rat_42155": 0.7445463538169861, "aqua_rat_19436": 0.7446534633636475, "aqua_rat_13585": 0.7450603246688843, "aqua_rat_36385": 0.7452101111412048, "math_test_prealgebra_1572": 0.7459853887557983, "aqua_rat_24605": 0.7462325692176819, "math_train_counting_and_probability_591": 0.7462935447692871, "aqua_rat_73601": 0.746363639831543, "aqua_rat_39390": 0.7465906739234924, "aqua_rat_24776": 0.7468873262405396, "math_train_counting_and_probability_1110": 0.7474582195281982, "aqua_rat_42815": 0.7476145029067993, "aqua_rat_79094": 0.7480019927024841, "aqua_rat_58579": 0.7484265565872192, "aqua_rat_62768": 0.7486118674278259, "aqua_rat_42445": 0.7491973042488098, "aqua_rat_57693": 0.7492456436157227, "aqua_rat_44882": 0.7492842674255371, "math_test_counting_and_probability_776": 0.7493399977684021, "aqua_rat_8728": 0.749351978302002, "TheoremQA_jianyu_xu/Stirling_number_second_kind_6.json": 0.7498005628585815, "aqua_rat_52707": 0.7499215006828308, "aqua_rat_41742": 0.7502175569534302, "math_train_counting_and_probability_831": 0.7512894868850708, "math_train_prealgebra_351": 0.7513763904571533, "aqua_rat_56015": 0.7532693147659302, "aqua_rat_57246": 0.7533935308456421, "math_test_prealgebra_1764": 0.7537422180175781, "aqua_rat_38314": 0.7537429928779602, "aqua_rat_34318": 0.7548354864120483, "aqua_rat_29513": 0.7549344301223755, "aqua_rat_21868": 0.7552582025527954, "math_train_counting_and_probability_236": 0.7555942535400391, "aqua_rat_71137": 0.7557079195976257, "math_train_counting_and_probability_149": 0.756205677986145, "aqua_rat_82511": 0.7565265893936157, "aqua_rat_64485": 0.7566832304000854, "aqua_rat_52092": 0.7570387721061707, "camel_38493": 0.7586467862129211, "math_train_counting_and_probability_146": 0.7587358951568604, "aqua_rat_16780": 0.7598951458930969, "math_train_counting_and_probability_949": 0.7608063817024231, "aqua_rat_52832": 0.7611063718795776, "aqua_rat_84159": 0.7611613273620605, "aqua_rat_21179": 0.7619480490684509, "math_train_counting_and_probability_437": 0.7624871134757996, "aqua_rat_41875": 0.7630395889282227, "aqua_rat_30109": 0.7631503343582153, "aqua_rat_78830": 0.763386607170105, "aqua_rat_11651": 0.7635596990585327, "aqua_rat_87094": 0.7638232707977295, "aqua_rat_41924": 0.7641680836677551, "aqua_rat_72708": 0.765725314617157, "aqua_rat_33533": 0.7661414742469788, "math_train_counting_and_probability_165": 0.7665175795555115, "aqua_rat_54525": 0.7668177485466003, "aqua_rat_28538": 0.7669093608856201, "aqua_rat_68946": 0.7676790356636047, "math_train_counting_and_probability_617": 0.7678644061088562, "aqua_rat_81997": 0.7691231966018677, "math_test_counting_and_probability_416": 0.7700808048248291, "aqua_rat_74651": 0.7704229354858398, "aqua_rat_68198": 0.7711448073387146, "aqua_rat_14281": 0.7715505957603455, "math_train_counting_and_probability_445": 0.7716222405433655, "math_train_counting_and_probability_696": 0.7719541192054749, "aqua_rat_34272": 0.7722681164741516, "aqua_rat_49270": 0.7728185057640076, "aqua_rat_3870": 0.7740093469619751, "aqua_rat_13918": 0.7750619053840637, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": 0.7757008671760559, "aqua_rat_62645": 0.7761950492858887, "aqua_rat_29967": 0.777120053768158, "camel_38505": 0.7789813280105591, "math_test_counting_and_probability_79": 0.7816004157066345, "aqua_rat_70861": 0.7824240326881409, "aqua_rat_22648": 0.7825810313224792, "aqua_rat_55783": 0.7874526381492615, "math_train_counting_and_probability_961": 0.7884699106216431, "aqua_rat_10102": 0.7892404198646545, "aqua_rat_22507": 0.7905684113502502, "math_test_counting_and_probability_935": 0.7907462120056152, "aqua_rat_66841": 0.7961885929107666, "aqua_rat_32732": 0.796985924243927, "math_test_counting_and_probability_513": 0.7971206903457642, "aqua_rat_62903": 0.8010492920875549, "aqua_rat_89175": 0.8029154539108276, "aqua_rat_15615": 0.8084132075309753, "aqua_rat_70803": 0.8106399774551392, "aqua_rat_64131": 0.8115208745002747, "aqua_rat_56019": 0.8133666515350342, "math_test_counting_and_probability_650": 0.8163888454437256, "aqua_rat_71336": 0.818017840385437, "aqua_rat_30172": 0.8191768527030945}, "TheoremQA_maxku/ipnetwork21-ip-2.json": {"TheoremQA_maxku/ipnetwork21-ip-2.json": 0, "camel_38615": 0.6698279976844788, "camel_41392": 0.6699725985527039, "camel_22559": 0.6699985861778259, "camel_22514": 0.6701359152793884, "camel_22534": 0.670198917388916, "camel_21846": 0.6702342629432678, "camel_22809": 0.6706134676933289, "camel_21667": 0.6707108020782471, "camel_23973": 0.671308696269989, "camel_22828": 0.6714146137237549, "camel_22855": 0.6714792847633362, "camel_22281": 0.671606719493866, "camel_41214": 0.6716895699501038, "camel_21890": 0.6717679500579834, "camel_38585": 0.6718119382858276, "camel_38635": 0.672416090965271, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0.6726787686347961, "camel_21883": 0.6727110147476196, "camel_38619": 0.6729236245155334, "camel_41158": 0.672949492931366, "camel_23193": 0.673180878162384, "camel_23991": 0.6734926104545593, "camel_22819": 0.6735528707504272, "camel_39983": 0.6736520528793335, "camel_38501": 0.6744287610054016, "camel_21912": 0.6748219728469849, "camel_21891": 0.6749588251113892, "camel_38561": 0.6750993728637695, "camel_22296": 0.6751687526702881, "camel_39941": 0.6756172776222229, "camel_22847": 0.6760385632514954, "camel_21630": 0.6762672662734985, "camel_22387": 0.6763399243354797, "camel_41277": 0.6764070391654968, "camel_41221": 0.6768556833267212, "camel_22398": 0.6768573522567749, "camel_36493": 0.6777058243751526, "camel_23970": 0.6777418851852417, "camel_22803": 0.6777428388595581, "camel_22531": 0.6778759956359863, "camel_39934": 0.6781606674194336, "camel_22816": 0.6783546805381775, "camel_22548": 0.6786120533943176, "camel_40982": 0.6788590550422668, "camel_39975": 0.6793322563171387, "camel_22539": 0.6794637441635132, "camel_39992": 0.6798668503761292, "camel_41208": 0.6798941493034363, "camel_39999": 0.6801500916481018, "camel_22542": 0.6804689168930054, "camel_41223": 0.6805259585380554, "camel_38572": 0.6807636618614197, "camel_38569": 0.6811715364456177, "camel_41204": 0.6814889907836914, "camel_21628": 0.6822675466537476, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": 0.6825348734855652, "camel_22345": 0.6832275390625, "camel_22840": 0.6833736300468445, "camel_38578": 0.6836534738540649, "camel_39947": 0.6837091445922852, "camel_22876": 0.6839152574539185, "camel_41254": 0.6844815015792847, "camel_41269": 0.6846287846565247, "camel_22868": 0.6846386194229126, "camel_21658": 0.6853278875350952, "camel_22503": 0.6859818696975708, "camel_41217": 0.6863036155700684, "camel_22053": 0.6863101720809937, "camel_21663": 0.6864635348320007, "camel_22806": 0.6865203976631165, "camel_22300": 0.6867705583572388, "camel_41206": 0.6870285868644714, "camel_21610": 0.6871069073677063, "camel_23967": 0.688042163848877, "camel_22484": 0.6881003379821777, "camel_22417": 0.6882504224777222, "camel_39964": 0.6884596943855286, "camel_22449": 0.6893274784088135, "camel_41241": 0.6894473433494568, "camel_41753": 0.6895238161087036, "camel_39952": 0.6896449327468872, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0.6900354623794556, "camel_39960": 0.6902240514755249, "camel_21664": 0.6903429627418518, "camel_22832": 0.6904112100601196, "camel_38621": 0.6908820271492004, "camel_38587": 0.6916306018829346, "camel_22336": 0.6919569373130798, "camel_22841": 0.6930711269378662, "camel_21678": 0.6933791637420654, "camel_41200": 0.6937738060951233, "camel_38609": 0.6937937140464783, "camel_22361": 0.6938327550888062, "camel_38581": 0.6945179104804993, "camel_41247": 0.6946907043457031, "camel_41246": 0.6959511637687683, "camel_39977": 0.6965152621269226, "camel_22013": 0.6978625059127808, "camel_23971": 0.6981360912322998, "camel_22059": 0.6988105177879333, "camel_22940": 0.6990774869918823, "camel_22015": 0.6993783712387085, "camel_22042": 0.6997293829917908, "camel_41252": 0.6997526288032532, "camel_41263": 0.699836015701294, "camel_38611": 0.6999979019165039, "camel_22037": 0.7007964849472046, "camel_39920": 0.7018716335296631, "camel_22807": 0.7019933462142944, "camel_22826": 0.7019996643066406, "camel_41202": 0.7026320695877075, "camel_21641": 0.7038351893424988, "camel_22854": 0.7053949236869812, "camel_22069": 0.7054910063743591, "camel_38489": 0.706902265548706, "camel_39959": 0.7071310877799988, "camel_41255": 0.7071682214736938, "camel_22058": 0.7078317403793335, "camel_38630": 0.7079952955245972, "camel_22070": 0.7085484266281128, "camel_22007": 0.7091654539108276, "camel_22010": 0.7095417380332947, "camel_22014": 0.709735631942749, "camel_39996": 0.710503339767456, "camel_22048": 0.7106347680091858, "camel_38586": 0.7108324766159058, "camel_22061": 0.7108367681503296, "camel_22055": 0.7124631404876709, "camel_22052": 0.7132994532585144, "camel_22026": 0.7134014964103699, "camel_22031": 0.7134291529655457, "camel_39938": 0.7141187787055969, "camel_22041": 0.7154027223587036, "camel_22025": 0.7170828580856323, "camel_22079": 0.7178566455841064, "camel_39974": 0.7185318470001221, "camel_22056": 0.7188965678215027, "camel_22034": 0.7196792364120483, "camel_22006": 0.7197160720825195, "camel_22064": 0.7198604345321655, "camel_22003": 0.7199357151985168, "camel_22040": 0.7200568318367004, "camel_22028": 0.7201073169708252, "camel_22018": 0.7204139232635498, "camel_23980": 0.7207152843475342, "camel_22043": 0.7220315337181091, "camel_39997": 0.7227375507354736, "camel_22020": 0.7228737473487854, "camel_22002": 0.7230733036994934, "camel_22049": 0.7239907383918762, "camel_22032": 0.7240572571754456, "camel_22016": 0.7244764566421509, "camel_22074": 0.7251176238059998, "camel_22019": 0.7252815365791321, "camel_22078": 0.7252818942070007, "camel_22066": 0.7271878123283386, "camel_22004": 0.7274677753448486, "camel_22027": 0.7276533842086792, "camel_22022": 0.7284826040267944, "camel_22039": 0.7286280989646912, "camel_22046": 0.7295253872871399, "camel_22065": 0.7301823496818542, "camel_38560": 0.7304176688194275, "camel_22071": 0.7314515709877014, "camel_22023": 0.7325589656829834, "camel_22060": 0.7328852415084839, "TheoremQA_maxku/graphtheory7-shortestpath.json": 0.7345504760742188, "camel_22067": 0.7352063655853271, "camel_22072": 0.7354285717010498, "camel_22044": 0.7356217503547668, "camel_22068": 0.7359859943389893, "camel_22000": 0.7365767359733582, "camel_22075": 0.73675537109375, "camel_22063": 0.7371014356613159, "camel_22051": 0.7375362515449524, "camel_22062": 0.7378765940666199, "camel_22033": 0.7383456230163574, "camel_22030": 0.7394060492515564, "camel_22012": 0.7403343915939331, "camel_22008": 0.7405592203140259, "camel_22045": 0.7415834069252014, "camel_22017": 0.7421765327453613, "camel_22029": 0.7433417439460754, "camel_22077": 0.7434569597244263, "camel_22035": 0.7457188963890076, "camel_22009": 0.7462111115455627, "camel_22005": 0.7470683455467224, "camel_22021": 0.7497202157974243, "camel_22001": 0.7503959536552429, "camel_22073": 0.7572420835494995, "camel_22057": 0.7576944828033447, "camel_22038": 0.7583631873130798, "camel_38576": 0.7589853405952454, "camel_22036": 0.7595468759536743, "camel_22024": 0.7648845911026001, "camel_22076": 0.7651095390319824, "camel_22047": 0.7688710689544678, "camel_22054": 0.7720839381217957, "camel_22011": 0.7777157425880432}, "TheoremQA_wenhuchen/kepler's_law1.json": {"TheoremQA_wenhuchen/kepler's_law1.json": 0, "TheoremQA_panlu/black_hole1.json": 0.6548023819923401, "camel_3710": 0.6549184918403625, "camel_30782": 0.6552285552024841, "aqua_rat_11256": 0.6554722189903259, "aqua_rat_50937": 0.6555728316307068, "aqua_rat_15385": 0.6556809544563293, "camel_30741": 0.6558218002319336, "camel_28823": 0.6559305191040039, "camel_19687": 0.6559814214706421, "aqua_rat_76350": 0.6559829115867615, "camel_28744": 0.6560525894165039, "aqua_rat_70738": 0.6561130285263062, "aqua_rat_84942": 0.6561654210090637, "camel_28861": 0.6564137935638428, "TheoremQA_wenhuchen/kepler's_law2.json": 0.6566401720046997, "aqua_rat_35886": 0.656714677810669, "camel_46128": 0.656821608543396, "camel_2456": 0.6568456888198853, "aqua_rat_40402": 0.6569459438323975, "aqua_rat_24571": 0.6570220589637756, "TheoremQA_xinyi/newtons_laws_1.json": 0.6570620536804199, "aqua_rat_12166": 0.6571027636528015, "math_test_geometry_865": 0.6571114659309387, "camel_30724": 0.6573857069015503, "aqua_rat_12236": 0.6574963331222534, "camel_30779": 0.6577150821685791, "aqua_rat_4416": 0.657753586769104, "aqua_rat_65204": 0.6577546000480652, "aqua_rat_50400": 0.658123791217804, "aqua_rat_30563": 0.6581287980079651, "aqua_rat_8908": 0.6584847569465637, "camel_16295": 0.6588500142097473, "camel_30731": 0.658936083316803, "aqua_rat_75261": 0.6592379212379456, "aqua_rat_86431": 0.6595689058303833, "camel_28779": 0.6596543788909912, "aqua_rat_28240": 0.6597105264663696, "camel_16266": 0.6597731113433838, "math_test_prealgebra_393": 0.6599644422531128, "aqua_rat_76089": 0.6600501537322998, "camel_29603": 0.6600573658943176, "aqua_rat_64885": 0.6602090001106262, "aqua_rat_75694": 0.6602265238761902, "math_test_prealgebra_1873": 0.6604412198066711, "aqua_rat_40900": 0.6605194807052612, "aqua_rat_60956": 0.6605578660964966, "camel_19768": 0.6606432795524597, "aqua_rat_51918": 0.6608957648277283, "aqua_rat_74967": 0.661003589630127, "camel_30774": 0.6611960530281067, "aqua_rat_25003": 0.6612299084663391, "aqua_rat_8007": 0.6612499356269836, "aqua_rat_60136": 0.6613037586212158, "aqua_rat_22863": 0.6615117788314819, "aqua_rat_59927": 0.6615768671035767, "camel_5035": 0.6617206335067749, "aqua_rat_43860": 0.6618950366973877, "aqua_rat_20126": 0.6623274683952332, "aqua_rat_83008": 0.6626424193382263, "camel_46100": 0.6626489162445068, "aqua_rat_85261": 0.6627801060676575, "aqua_rat_40694": 0.6628404855728149, "camel_5165": 0.6630018353462219, "aqua_rat_47721": 0.6631773710250854, "aqua_rat_64811": 0.6632101535797119, "camel_46083": 0.6638458967208862, "aqua_rat_29570": 0.6645395755767822, "aqua_rat_71386": 0.6645659804344177, "aqua_rat_69168": 0.6650158762931824, "aqua_rat_20401": 0.6651042103767395, "camel_28838": 0.6652827858924866, "aqua_rat_69021": 0.6654093861579895, "camel_19647": 0.6655163764953613, "aqua_rat_45615": 0.6657162308692932, "aqua_rat_52791": 0.6657270789146423, "aqua_rat_46161": 0.6658762693405151, "aqua_rat_16120": 0.665932834148407, "aqua_rat_46495": 0.6660062670707703, "aqua_rat_50476": 0.6662824153900146, "aqua_rat_75486": 0.6663230657577515, "aqua_rat_69548": 0.6665098667144775, "aqua_rat_46616": 0.6666780114173889, "aqua_rat_86656": 0.6667782664299011, "aqua_rat_8921": 0.6672956943511963, "camel_39513": 0.6673495769500732, "aqua_rat_37176": 0.6673501133918762, "aqua_rat_48820": 0.6675909161567688, "aqua_rat_60788": 0.6678011417388916, "aqua_rat_29629": 0.6679917573928833, "camel_30206": 0.668035089969635, "camel_17406": 0.6686022281646729, "aqua_rat_70741": 0.668668806552887, "camel_3701": 0.6686863899230957, "aqua_rat_24084": 0.6687917709350586, "aqua_rat_64977": 0.6689051389694214, "camel_5197": 0.669011116027832, "aqua_rat_41869": 0.6694069504737854, "camel_30750": 0.6694108247756958, "aqua_rat_24548": 0.669414222240448, "gsm_rft_26567": 0.6694945693016052, "aqua_rat_57525": 0.6698164343833923, "gsm_rft_7556": 0.6699212193489075, "aqua_rat_72820": 0.6699835658073425, "aqua_rat_27383": 0.6701454520225525, "aqua_rat_66733": 0.6701586246490479, "aqua_rat_45304": 0.670170783996582, "gsm_train_15621": 0.6704328060150146, "TheoremQA_panlu/energy_conservation1.json": 0.6705151796340942, "camel_5093": 0.6706820726394653, "aqua_rat_11867": 0.670782744884491, "aqua_rat_11744": 0.6710006594657898, "aqua_rat_12254": 0.6710652709007263, "aqua_rat_79312": 0.6714858412742615, "camel_5344": 0.6715350151062012, "camel_28736": 0.6720102429389954, "aqua_rat_33984": 0.6721574664115906, "aqua_rat_6326": 0.6721810102462769, "camel_5189": 0.6722076535224915, "aqua_rat_26489": 0.672301173210144, "aqua_rat_32986": 0.6723840236663818, "aqua_rat_1054": 0.6725694537162781, "camel_3148": 0.6731909513473511, "math_test_geometry_169": 0.6732981204986572, "aqua_rat_28463": 0.6733887195587158, "aqua_rat_6249": 0.6738592386245728, "aqua_rat_48696": 0.6738688945770264, "camel_29467": 0.6745808720588684, "camel_16283": 0.6757001876831055, "aqua_rat_63716": 0.6759519577026367, "aqua_rat_36823": 0.6760890483856201, "aqua_rat_70370": 0.6761996150016785, "aqua_rat_82369": 0.6763945817947388, "aqua_rat_49753": 0.6766051650047302, "aqua_rat_41324": 0.6766499876976013, "aqua_rat_14107": 0.6766946315765381, "aqua_rat_79908": 0.6766947507858276, "aqua_rat_43215": 0.6768642067909241, "aqua_rat_8211": 0.6770855188369751, "camel_5178": 0.6773292422294617, "aqua_rat_5309": 0.6775248646736145, "camel_16285": 0.6778271198272705, "aqua_rat_68112": 0.6781026721000671, "aqua_rat_29644": 0.6781028509140015, "aqua_rat_22374": 0.6786039471626282, "aqua_rat_71933": 0.6787770986557007, "aqua_rat_64374": 0.6788105964660645, "camel_5284": 0.6789652705192566, "gsm_rft_21861": 0.6811099052429199, "gsm_train_25944": 0.6811099052429199, "aqua_rat_51123": 0.6815968751907349, "aqua_rat_80393": 0.6818423271179199, "gsm_rft_14753": 0.6820524334907532, "gsm_rft_6137": 0.6820560097694397, "aqua_rat_59621": 0.6822460889816284, "aqua_rat_88322": 0.6827274560928345, "gsm_rft_35605": 0.6837466955184937, "aqua_rat_55212": 0.684048056602478, "aqua_rat_59533": 0.6842024326324463, "aqua_rat_86642": 0.6845040917396545, "gsm_rft_20646": 0.6845705509185791, "gsm_train_8611": 0.6845705509185791, "aqua_rat_43112": 0.6852930188179016, "aqua_rat_24388": 0.6866326332092285, "aqua_rat_39664": 0.6874452829360962, "TheoremQA_panlu/uniform_circular_motion2.json": 0.687857449054718, "aqua_rat_84659": 0.6882901191711426, "aqua_rat_88155": 0.6883128881454468, "aqua_rat_18805": 0.6888329982757568, "math_test_prealgebra_1007": 0.6894871592521667, "camel_5138": 0.6898627281188965, "math_test_geometry_602": 0.6904221177101135, "camel_5004": 0.6906886100769043, "TheoremQA_xinyi/rotation.json": 0.690780758857727, "aqua_rat_79015": 0.6910346150398254, "camel_30293": 0.6915428638458252, "aqua_rat_75022": 0.6936833262443542, "aqua_rat_18441": 0.6941244006156921, "aqua_rat_8349": 0.6980276703834534, "aqua_rat_81657": 0.6984381079673767, "aqua_rat_79757": 0.7018325328826904, "aqua_rat_32454": 0.7026931047439575, "aqua_rat_19853": 0.7029058933258057, "aqua_rat_56518": 0.703181803226471, "camel_28532": 0.7047690749168396, "aqua_rat_79557": 0.7052628993988037, "aqua_rat_28149": 0.7064643502235413, "aqua_rat_66318": 0.7086858153343201, "aqua_rat_6305": 0.7109594345092773, "aqua_rat_54538": 0.7123968601226807, "aqua_rat_4364": 0.712704598903656, "aqua_rat_34465": 0.7129164338111877, "camel_28537": 0.7151201367378235, "math_train_algebra_2034": 0.7156081795692444, "math_test_algebra_1169": 0.7177586555480957, "aqua_rat_42233": 0.732249915599823, "camel_28137": 0.7325695157051086, "camel_29489": 0.7359703183174133, "camel_39449": 0.8022701144218445, "TheoremQA_wenhuchen/kepler's_law3.json": 0.8038113713264465}, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": {"TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0, "aqua_rat_25896": 0.6679289937019348, "camel_26460": 0.6679462194442749, "gsm_rft_2105": 0.6681265830993652, "gsm_rft_3120": 0.668434202671051, "gsm_train_10718": 0.668434202671051, "gsm_rft_33997": 0.6684422492980957, "gsm_rft_900": 0.6685605049133301, "aqua_rat_8371": 0.6685668230056763, "camel_31190": 0.6687772870063782, "aqua_rat_19653": 0.6688675284385681, "gsm_rft_5163": 0.6688871383666992, "camel_26622": 0.6689434051513672, "gsm_rft_7911": 0.6692338585853577, "gsm_rft_13386": 0.6692472100257874, "camel_26485": 0.6692909002304077, "aqua_rat_58530": 0.6693019866943359, "math_train_number_theory_230": 0.6693158745765686, "gsm_rft_89": 0.6694048643112183, "gsm_train_5776": 0.6694048643112183, "gsm_rft_9": 0.6695091724395752, "gsm_rft_24553": 0.6696506142616272, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.6696983575820923, "gsm_rft_8738": 0.6698697805404663, "gsm_rft_21057": 0.669903039932251, "gsm_rft_10110": 0.66994309425354, "camel_30858": 0.670179545879364, "camel_31120": 0.6703044176101685, "aqua_rat_1976": 0.6703935861587524, "gsm_rft_32874": 0.6704362630844116, "gsm_rft_14650": 0.6705965399742126, "aqua_rat_87221": 0.6707828640937805, "aqua_rat_76189": 0.6708506345748901, "gsm_rft_16775": 0.6708755493164062, "gsm_rft_22546": 0.6709485650062561, "gsm_rft_20755": 0.6709485650062561, "camel_13805": 0.6713228225708008, "gsm_rft_9272": 0.6715494394302368, "gsm_rft_229": 0.6715494394302368, "gsm_train_4199": 0.6715494394302368, "aqua_rat_33918": 0.6715729236602783, "aqua_rat_4834": 0.6716690063476562, "gsm_rft_34505": 0.6716747283935547, "aqua_rat_5881": 0.6719793677330017, "gsm_rft_7620": 0.672005832195282, "gsm_rft_22256": 0.6720705032348633, "aqua_rat_22404": 0.6721304655075073, "camel_27940": 0.6723082661628723, "camel_31197": 0.6724068522453308, "math_test_number_theory_383": 0.6726701855659485, "aqua_rat_35043": 0.672816812992096, "math_train_number_theory_7008": 0.6731629371643066, "camel_13764": 0.6731839776039124, "gsm_rft_23242": 0.6733177304267883, "aqua_rat_57267": 0.6734306812286377, "camel_26437": 0.6735040545463562, "aqua_rat_17718": 0.6736364960670471, "gsm_train_25779": 0.6736788153648376, "aqua_rat_68132": 0.6736819744110107, "aqua_rat_78369": 0.6741957068443298, "camel_26434": 0.6742077469825745, "aqua_rat_69971": 0.6743624806404114, "gsm_rft_12052": 0.6743677258491516, "aqua_rat_48337": 0.6745340824127197, "gsm_rft_4746": 0.6746789813041687, "aqua_rat_88778": 0.6753597855567932, "gsm_rft_12713": 0.6754374504089355, "aqua_rat_25089": 0.675561785697937, "gsm_rft_33639": 0.6758882403373718, "gsm_rft_8555": 0.6758882403373718, "aqua_rat_59366": 0.6759864091873169, "aqua_rat_49275": 0.6760873794555664, "camel_26637": 0.6760952472686768, "gsm_train_12825": 0.6761125326156616, "aqua_rat_69799": 0.6761724948883057, "gsm_rft_1963": 0.6761922836303711, "gsm_rft_16361": 0.6763178706169128, "gsm_rft_21828": 0.6766619086265564, "aqua_rat_87229": 0.6766728758811951, "aqua_rat_70662": 0.6767734289169312, "gsm_rft_6860": 0.6769357919692993, "camel_27949": 0.6771421432495117, "gsm_rft_157": 0.6772251129150391, "camel_26575": 0.677281379699707, "aqua_rat_88092": 0.6773865818977356, "aqua_rat_50724": 0.6774319410324097, "gsm_rft_24388": 0.6775233149528503, "gsm_rft_11985": 0.6775839328765869, "camel_26680": 0.6778515577316284, "gsm_rft_25368": 0.6782927513122559, "aqua_rat_52087": 0.6784017086029053, "math_test_geometry_116": 0.6784045100212097, "gsm_train_31599": 0.678450345993042, "camel_31131": 0.679356038570404, "gsm_rft_15313": 0.6794567704200745, "gsm_rft_10255": 0.6794567704200745, "gsm_rft_14307": 0.6795154213905334, "aqua_rat_85903": 0.679673433303833, "math_test_number_theory_481": 0.6799502372741699, "gsm_train_26101": 0.6799918413162231, "aqua_rat_36286": 0.6805015802383423, "camel_13823": 0.6805418133735657, "camel_13806": 0.6805768609046936, "gsm_rft_33571": 0.6807946562767029, "camel_13838": 0.6814996004104614, "math_train_number_theory_400": 0.6815571784973145, "aqua_rat_27910": 0.6816000938415527, "gsm_rft_12105": 0.6816967725753784, "aqua_rat_5613": 0.6824071407318115, "camel_13765": 0.682632327079773, "gsm_rft_4943": 0.6828839182853699, "gsm_rft_4658": 0.6829443573951721, "gsm_train_15116": 0.6829443573951721, "gsm_rft_159": 0.6829443573951721, "gsm_rft_14419": 0.6829525232315063, "camel_26623": 0.6833797097206116, "gsm_rft_23312": 0.6834487318992615, "gsm_rft_20353": 0.6842103600502014, "aqua_rat_78443": 0.6843265891075134, "gsm_rft_18202": 0.6843597292900085, "gsm_rft_11215": 0.6844144463539124, "aqua_rat_71393": 0.68451327085495, "gsm_rft_29593": 0.6846272349357605, "camel_26631": 0.6846895217895508, "gsm_rft_9162": 0.685121476650238, "gsm_rft_28181": 0.6852167248725891, "camel_31193": 0.6854282021522522, "gsm_rft_3729": 0.6855033040046692, "gsm_train_27467": 0.6855851411819458, "gsm_rft_32270": 0.6856088638305664, "aqua_rat_87402": 0.6856549382209778, "gsm_train_19829": 0.6857394576072693, "gsm_rft_20159": 0.6858452558517456, "math_test_number_theory_493": 0.6860246658325195, "math_train_prealgebra_1358": 0.6860883831977844, "camel_26538": 0.6864277720451355, "aqua_rat_3461": 0.6865362524986267, "math_train_number_theory_455": 0.6872248649597168, "camel_13811": 0.6874937415122986, "camel_26585": 0.6881206035614014, "camel_26590": 0.6881263256072998, "gsm_rft_32533": 0.6885442733764648, "camel_28096": 0.6890676617622375, "gsm_rft_13859": 0.689082682132721, "camel_26692": 0.6900566816329956, "camel_27970": 0.6901229619979858, "camel_13789": 0.6908343434333801, "camel_27994": 0.6911070346832275, "gsm_rft_5276": 0.6911771297454834, "gsm_train_13705": 0.6911771297454834, "gsm_train_12172": 0.6913964748382568, "gsm_rft_411": 0.6913964748382568, "gsm_rft_34987": 0.691616415977478, "gsm_rft_12027": 0.6923147439956665, "aqua_rat_57783": 0.6925597786903381, "camel_26540": 0.6928628087043762, "camel_37501": 0.6930294036865234, "camel_26612": 0.6931591033935547, "gsm_rft_19302": 0.693932056427002, "gsm_rft_25272": 0.6944119930267334, "camel_13795": 0.6945789456367493, "camel_26591": 0.6948544383049011, "gsm_rft_2717": 0.6949150562286377, "math_train_number_theory_195": 0.6949930191040039, "gsm_rft_17389": 0.6955006718635559, "camel_26610": 0.696434736251831, "aqua_rat_9712": 0.6965261101722717, "math_test_number_theory_691": 0.6977889537811279, "gsm_rft_23745": 0.6991912126541138, "gsm_train_15441": 0.6993587613105774, "gsm_rft_33753": 0.69936603307724, "camel_26601": 0.6993999481201172, "gsm_rft_9514": 0.6999188661575317, "camel_26365": 0.7001636028289795, "gsm_rft_33965": 0.7002567052841187, "camel_26638": 0.7011815309524536, "camel_26584": 0.7016919851303101, "camel_26609": 0.7018565535545349, "camel_13808": 0.7027480602264404, "camel_26570": 0.7042674422264099, "camel_26565": 0.7046257257461548, "camel_36295": 0.7048413753509521, "camel_13791": 0.7061529159545898, "camel_26581": 0.7068005800247192, "camel_44798": 0.7173217535018921, "math_train_prealgebra_1637": 0.7238548994064331, "camel_27982": 0.7242040038108826, "gsm_rft_24062": 0.735157310962677, "camel_44748": 0.7374259829521179, "gsm_rft_24925": 0.7446907758712769, "gsm_train_27821": 0.7446907758712769, "gsm_train_21444": 0.7474953532218933, "gsm_rft_6010": 0.7474953532218933, "gsm_rft_4843": 0.7510218620300293, "gsm_rft_17939": 0.7522301077842712, "gsm_rft_4144": 0.7580038905143738, "gsm_train_25080": 0.7583304047584534, "gsm_rft_15756": 0.758422315120697, "TheoremQA_maxku/cv-colorsci1-rgb.json": 0.7892876863479614, "TheoremQA_maxku/cv-imageprocessing10-digital-image.json": 0.8234469294548035}, "TheoremQA_jianyu_xu/pigeonhole_4.json": {"camel_21188": 0, "math_train_number_theory_265": 0, "math_train_number_theory_78": 0, "camel_21121": 0, "camel_21170": 0, "camel_21798": 0, "math_train_number_theory_717": 0, "camel_21198": 0, "camel_21162": 0, "math_test_number_theory_612": 0, "math_train_number_theory_637": 0, "camel_21137": 0, "camel_21141": 0, "math_test_number_theory_1248": 0, "camel_21055": 0, "math_train_number_theory_267": 0, "math_train_number_theory_887": 0, "math_train_number_theory_605": 0, "camel_21835": 0, "camel_21159": 0, "camel_21126": 0, "math_train_number_theory_767": 0, "math_test_number_theory_846": 0, "math_train_number_theory_688": 0, "camel_21165": 0, "math_train_number_theory_7113": 0, "camel_21177": 0, "math_train_number_theory_118": 0, "camel_21196": 0, "camel_21120": 0, "camel_21128": 0, "camel_21174": 0, "camel_21372": 0, "camel_21169": 0, "camel_21154": 0, "camel_21147": 0, "camel_21160": 0, "camel_21040": 0, "camel_21183": 0, "TheoremQA_jianyu_xu/pigeonhole_4.json": 0, "aqua_rat_78018": 0.6327769160270691, "aqua_rat_41989": 0.6329576969146729, "aqua_rat_71607": 0.6331199407577515, "aqua_rat_9180": 0.6333083510398865, "aqua_rat_81420": 0.6333133578300476, "aqua_rat_47936": 0.6335197687149048, "aqua_rat_46387": 0.6335784196853638, "aqua_rat_72312": 0.6336503624916077, "aqua_rat_43666": 0.6345483660697937, "aqua_rat_17162": 0.6346662044525146, "aqua_rat_31828": 0.6348443627357483, "aqua_rat_87294": 0.6350113153457642, "math_test_prealgebra_1443": 0.6350165605545044, "aqua_rat_70890": 0.635281503200531, "aqua_rat_25453": 0.6353484392166138, "aqua_rat_32772": 0.6355193257331848, "aqua_rat_45469": 0.635846734046936, "gsm_rft_13977": 0.6360060572624207, "aqua_rat_12069": 0.6360535621643066, "aqua_rat_56885": 0.6360891461372375, "aqua_rat_257": 0.6361754536628723, "aqua_rat_8919": 0.636398434638977, "aqua_rat_24463": 0.6364212036132812, "camel_36391": 0.6364932060241699, "aqua_rat_36027": 0.6364954113960266, "aqua_rat_65742": 0.6365240216255188, "aqua_rat_49256": 0.6365752220153809, "camel_36341": 0.6369083523750305, "aqua_rat_39047": 0.6370818614959717, "aqua_rat_14919": 0.6371400952339172, "aqua_rat_70101": 0.6371973156929016, "aqua_rat_20969": 0.6375675797462463, "aqua_rat_33710": 0.638263463973999, "camel_13832": 0.6385225057601929, "aqua_rat_52525": 0.6388912796974182, "aqua_rat_82478": 0.6390901207923889, "camel_11574": 0.6392351388931274, "aqua_rat_19152": 0.6392987966537476, "aqua_rat_31932": 0.6393017172813416, "aqua_rat_42905": 0.6396585702896118, "aqua_rat_1006": 0.6397492289543152, "aqua_rat_49147": 0.639821469783783, "aqua_rat_59821": 0.6400711536407471, "aqua_rat_65028": 0.6401229500770569, "aqua_rat_35683": 0.6402031779289246, "aqua_rat_73914": 0.640370786190033, "aqua_rat_46009": 0.640424370765686, "aqua_rat_83986": 0.6408039331436157, "aqua_rat_48010": 0.64101243019104, "aqua_rat_63725": 0.64146488904953, "aqua_rat_43005": 0.6418110132217407, "aqua_rat_39271": 0.6431290507316589, "aqua_rat_46361": 0.6431365609169006, "aqua_rat_79070": 0.6433348655700684, "aqua_rat_21541": 0.6434127688407898, "aqua_rat_80759": 0.6434910297393799, "aqua_rat_59053": 0.6438454985618591, "aqua_rat_61487": 0.643902063369751, "aqua_rat_61238": 0.6443668603897095, "aqua_rat_31815": 0.6443876624107361, "aqua_rat_26661": 0.6444692015647888, "aqua_rat_23909": 0.64505535364151, "aqua_rat_78805": 0.6460853815078735, "aqua_rat_273": 0.6461114287376404, "aqua_rat_4199": 0.6466794610023499, "aqua_rat_20004": 0.6467748284339905, "aqua_rat_149": 0.6469814777374268, "aqua_rat_57031": 0.6472411751747131, "aqua_rat_26932": 0.6472811102867126, "aqua_rat_60266": 0.6474224925041199, "aqua_rat_46632": 0.6477888822555542, "aqua_rat_2556": 0.6480504870414734, "aqua_rat_38419": 0.6482740044593811, "aqua_rat_15630": 0.6485106945037842, "aqua_rat_25103": 0.6486786603927612, "aqua_rat_15480": 0.6487410664558411, "math_test_prealgebra_996": 0.6490916609764099, "aqua_rat_60456": 0.649444043636322, "aqua_rat_56383": 0.6501079201698303, "aqua_rat_65177": 0.6502970457077026, "aqua_rat_52187": 0.6503402590751648, "aqua_rat_1131": 0.6508871912956238, "aqua_rat_41002": 0.6509675979614258, "math_train_algebra_770": 0.6510436534881592, "aqua_rat_47694": 0.6516088843345642, "aqua_rat_140": 0.6522750854492188, "math_test_prealgebra_805": 0.6524046063423157, "math_train_counting_and_probability_5015": 0.652604877948761, "aqua_rat_58635": 0.6528125405311584, "aqua_rat_31046": 0.653037428855896, "aqua_rat_76192": 0.6533758044242859, "aqua_rat_48685": 0.653518557548523, "aqua_rat_84675": 0.6538929343223572, "aqua_rat_88268": 0.6539748907089233, "math_train_prealgebra_213": 0.654037594795227, "aqua_rat_17862": 0.6545277833938599, "aqua_rat_30610": 0.6545340418815613, "aqua_rat_49569": 0.6545416712760925, "math_train_algebra_2532": 0.6548173427581787, "aqua_rat_17359": 0.6548745036125183, "aqua_rat_80435": 0.6551699042320251, "aqua_rat_17318": 0.6555616855621338, "aqua_rat_10148": 0.6559484601020813, "aqua_rat_50798": 0.6560528874397278, "aqua_rat_83796": 0.6566896438598633, "aqua_rat_17717": 0.6567551493644714, "aqua_rat_15442": 0.6567686200141907, "aqua_rat_23524": 0.656876266002655, "aqua_rat_40065": 0.6569822430610657, "aqua_rat_16788": 0.6569969654083252, "math_train_counting_and_probability_963": 0.6570481657981873, "aqua_rat_69238": 0.6571754217147827, "aqua_rat_14782": 0.6577919721603394, "aqua_rat_20302": 0.6580218076705933, "aqua_rat_58088": 0.6594455242156982, "aqua_rat_30710": 0.6598429083824158, "aqua_rat_50073": 0.6601085066795349, "aqua_rat_45273": 0.6622359156608582, "aqua_rat_37649": 0.6626337766647339, "aqua_rat_34164": 0.6631363034248352, "aqua_rat_73303": 0.6634096503257751, "aqua_rat_67387": 0.6634682416915894, "aqua_rat_22669": 0.6642910838127136, "aqua_rat_73560": 0.6645280718803406, "camel_11529": 0.6645848751068115, "aqua_rat_48028": 0.6653768420219421, "aqua_rat_50597": 0.6660616993904114, "aqua_rat_27921": 0.6664370894432068, "aqua_rat_66391": 0.6668672561645508, "aqua_rat_40277": 0.6670108437538147, "aqua_rat_19090": 0.6673921346664429, "aqua_rat_38285": 0.6702391505241394, "camel_11562": 0.6724497675895691, "aqua_rat_76356": 0.6731300950050354, "aqua_rat_48130": 0.6734732985496521, "aqua_rat_71213": 0.6754269003868103, "aqua_rat_51045": 0.6759107708930969, "aqua_rat_65264": 0.6762308478355408, "aqua_rat_57502": 0.6779269576072693, "camel_11523": 0.6805930137634277, "aqua_rat_86939": 0.6872901320457458, "aqua_rat_27348": 0.6896741390228271, "aqua_rat_6686": 0.6905527114868164, "math_train_counting_and_probability_5123": 0.6915823817253113, "aqua_rat_6737": 0.6919017434120178, "aqua_rat_15286": 0.694629967212677, "aqua_rat_25877": 0.6952635049819946, "aqua_rat_23494": 0.6956668496131897, "aqua_rat_52776": 0.695889413356781, "camel_11579": 0.7016867995262146, "aqua_rat_18128": 0.708573579788208, "aqua_rat_72179": 0.709197461605072, "aqua_rat_5662": 0.718601644039154, "camel_11570": 0.7228419184684753, "aqua_rat_56614": 0.7244008183479309, "TheoremQA_jianyu_xu/pigeonhole_3.json": 0.7263724207878113, "aqua_rat_11601": 0.7289386987686157, "aqua_rat_75262": 0.7333552837371826, "aqua_rat_86710": 0.7452802062034607, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0.8292499780654907}, "TheoremQA_elainewan/math_calculus_5.json": {"camel_7115": 0, "camel_7069": 0, "camel_7773": 0, "camel_7776": 0, "camel_6277": 0, "camel_6257": 0, "camel_7533": 0, "camel_7048": 0, "camel_7072": 0, "camel_7791": 0, "camel_6278": 0, "camel_6271": 0, "camel_7534": 0, "camel_7081": 0, "camel_7823": 0, "camel_7787": 0, "camel_7040": 0, "camel_7104": 0, "camel_6310": 0, "camel_7797": 0, "camel_7101": 0, "camel_7760": 0, "camel_7829": 0, "camel_7805": 0, "camel_7762": 0, "camel_7114": 0, "camel_7058": 0, "camel_7075": 0, "camel_7103": 0, "camel_7834": 0, "camel_7043": 0, "camel_7042": 0, "camel_7994": 0, "camel_7074": 0, "camel_7818": 0, "camel_6270": 0, "camel_7076": 0, "camel_6288": 0, "camel_7825": 0, "camel_7110": 0, "camel_7052": 0, "camel_6287": 0, "camel_7065": 0, "camel_7106": 0, "camel_7087": 0, "camel_7060": 0, "camel_7786": 0, "camel_7795": 0, "camel_7763": 0, "camel_7113": 0, "camel_7769": 0, "camel_7050": 0, "camel_7119": 0, "camel_7780": 0, "camel_7808": 0, "camel_6285": 0, "camel_7061": 0, "camel_7555": 0, "camel_7794": 0, "camel_7112": 0, "camel_7068": 0, "camel_6267": 0, "camel_6281": 0, "camel_7096": 0, "camel_7824": 0, "camel_7041": 0, "camel_7828": 0, "camel_7802": 0, "camel_7097": 0, "camel_7086": 0, "camel_7082": 0, "camel_7790": 0, "camel_6259": 0, "camel_6291": 0, "camel_6317": 0, "camel_7540": 0, "camel_6254": 0, "camel_6251": 0, "camel_6265": 0, "camel_6283": 0, "camel_6282": 0, "camel_6314": 0, "camel_7092": 0, "camel_7051": 0, "camel_6279": 0, "camel_7088": 0, "camel_7822": 0, "camel_7814": 0, "camel_7837": 0, "camel_6256": 0, "camel_7080": 0, "camel_7784": 0, "camel_6274": 0, "camel_7781": 0, "camel_7817": 0, "camel_7093": 0, "camel_7811": 0, "camel_7793": 0, "camel_7826": 0, "camel_7083": 0, "camel_6250": 0, "camel_7804": 0, "camel_7778": 0, "camel_7792": 0, "camel_7838": 0, "camel_7102": 0, "camel_7836": 0, "camel_7085": 0, "camel_6315": 0, "camel_7831": 0, "camel_6307": 0, "camel_7785": 0, "camel_7057": 0, "camel_6247": 0, "camel_6319": 0, "camel_7820": 0, "camel_6275": 0, "camel_7566": 0, "camel_6308": 0, "camel_6303": 0, "camel_7107": 0, "camel_7839": 0, "camel_7079": 0, "camel_7084": 0, "camel_7063": 0, "camel_7772": 0, "camel_7815": 0, "camel_7045": 0, "camel_7830": 0, "camel_6268": 0, "camel_7767": 0, "camel_7789": 0, "camel_7768": 0, "camel_7078": 0, "camel_7821": 0, "camel_7761": 0, "camel_7764": 0, "camel_7054": 0, "camel_7783": 0, "camel_7833": 0, "camel_7798": 0, "camel_7816": 0, "camel_7800": 0, "camel_7108": 0, "camel_6296": 0, "camel_6313": 0, "camel_6304": 0, "camel_6318": 0, "camel_6294": 0, "camel_6244": 0, "camel_6312": 0, "camel_6253": 0, "camel_7064": 0, "camel_6316": 0, "camel_6240": 0, "camel_6311": 0, "camel_6252": 0, "camel_7770": 0, "camel_7819": 0, "camel_6260": 0, "camel_7812": 0, "camel_6300": 0, "camel_7803": 0, "camel_7779": 0, "camel_7801": 0, "camel_6306": 0, "camel_7832": 0, "camel_6242": 0, "camel_6261": 0, "camel_6266": 0, "camel_6264": 0, "camel_6299": 0, "camel_7796": 0, "camel_6272": 0, "camel_6255": 0, "camel_6290": 0, "camel_7775": 0, "camel_6249": 0, "camel_6305": 0, "camel_6297": 0, "camel_6280": 0, "camel_6292": 0, "camel_6295": 0, "camel_6273": 0, "camel_6298": 0, "camel_6262": 0, "camel_6263": 0, "camel_6286": 0, "camel_6284": 0, "camel_6269": 0, "camel_6276": 0, "camel_6302": 0, "camel_6243": 0, "camel_6245": 0, "camel_6301": 0, "camel_6241": 0, "camel_19568": 0.8041808009147644, "camel_19895": 0.812303364276886, "camel_37096": 0.813063383102417, "camel_45941": 0.8328276872634888}, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": {"camel_21215": 0, "camel_21218": 0, "camel_20680": 0, "camel_21261": 0, "camel_21117": 0, "camel_20711": 0, "camel_20856": 0, "camel_20308": 0, "camel_20647": 0, "camel_21822": 0, "camel_20804": 0, "camel_20540": 0, "camel_20578": 0, "camel_20812": 0, "camel_20710": 0, "camel_21177": 0, "camel_20618": 0, "camel_20650": 0, "camel_20845": 0, "camel_20825": 0, "camel_21015": 0, "camel_20656": 0, "camel_21798": 0, "camel_20297": 0, "camel_21147": 0, "camel_21809": 0, "camel_21154": 0, "camel_20877": 0, "camel_20701": 0, "camel_20317": 0, "camel_21219": 0, "camel_21055": 0, "camel_21246": 0, "camel_20860": 0, "camel_20248": 0, "camel_21202": 0, "camel_20583": 0, "math_test_number_theory_612": 0, "camel_20609": 0, "camel_20262": 0, "camel_20514": 0, "camel_20714": 0, "camel_20579": 0, "camel_20707": 0, "camel_20658": 0, "camel_20665": 0, "camel_20946": 0, "camel_20813": 0, "camel_20614": 0, "camel_20849": 0, "camel_20863": 0, "camel_20414": 0, "camel_21223": 0, "camel_20652": 0, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": 0, "camel_20621": 0, "camel_20640": 0, "camel_20661": 0, "camel_20698": 0, "camel_21361": 0, "camel_20818": 0, "camel_20577": 0, "camel_20499": 0, "camel_20602": 0, "camel_21126": 0, "camel_21568": 0, "camel_20688": 0, "camel_20805": 0, "camel_21169": 0, "camel_20626": 0, "camel_20841": 0, "camel_21567": 0, "camel_20867": 0, "camel_21360": 0, "camel_20668": 0, "camel_20623": 0, "camel_20702": 0, "camel_20806": 0, "camel_20700": 0, "camel_20301": 0, "camel_21050": 0, "camel_20637": 0, "camel_20563": 0, "camel_20310": 0, "camel_20695": 0, "camel_20596": 0, "aqua_rat_52832": 0.7144303321838379, "aqua_rat_2658": 0.7147465348243713, "aqua_rat_73393": 0.7152374982833862, "math_test_counting_and_probability_79": 0.7158000469207764, "math_train_counting_and_probability_348": 0.7164928913116455, "aqua_rat_58757": 0.7167288064956665, "aqua_rat_56536": 0.7173301577568054, "TheoremQA_jianyu_xu/combination_and_permutation_1.json": 0.7176154851913452, "aqua_rat_81317": 0.7184204459190369, "aqua_rat_54461": 0.7187846302986145, "aqua_rat_67159": 0.7187881469726562, "aqua_rat_41861": 0.719273030757904, "aqua_rat_29651": 0.7193523645401001, "math_test_counting_and_probability_650": 0.7193917632102966, "aqua_rat_13369": 0.7200681567192078, "aqua_rat_74550": 0.72010338306427, "math_train_algebra_2532": 0.7204035520553589, "aqua_rat_55250": 0.7205018997192383, "aqua_rat_27573": 0.720722496509552, "aqua_rat_75517": 0.7213818430900574, "aqua_rat_3279": 0.7216835021972656, "aqua_rat_41924": 0.7216866612434387, "math_test_counting_and_probability_485": 0.7217645645141602, "math_train_counting_and_probability_431": 0.7218049764633179, "aqua_rat_34205": 0.7222565412521362, "math_test_counting_and_probability_686": 0.7225242257118225, "aqua_rat_1295": 0.7228686809539795, "aqua_rat_70446": 0.7229676842689514, "aqua_rat_39642": 0.7233273983001709, "aqua_rat_77698": 0.7234393954277039, "aqua_rat_9655": 0.7234707474708557, "math_train_counting_and_probability_371": 0.72358638048172, "math_train_algebra_770": 0.7238155007362366, "aqua_rat_9092": 0.7243395447731018, "aqua_rat_16877": 0.7247964143753052, "aqua_rat_39610": 0.7248415946960449, "aqua_rat_40683": 0.7249895930290222, "math_train_counting_and_probability_667": 0.7261054515838623, "aqua_rat_61885": 0.7263221740722656, "aqua_rat_575": 0.726533055305481, "aqua_rat_50641": 0.7265375852584839, "math_test_counting_and_probability_341": 0.7270134687423706, "aqua_rat_76714": 0.7273160815238953, "math_test_counting_and_probability_461": 0.7279555797576904, "aqua_rat_5049": 0.7279984354972839, "camel_12727": 0.728865385055542, "aqua_rat_66118": 0.7292348742485046, "aqua_rat_3903": 0.7295893430709839, "aqua_rat_19096": 0.7296415567398071, "aqua_rat_52771": 0.7297583222389221, "aqua_rat_54525": 0.7298239469528198, "math_test_counting_and_probability_416": 0.7299636602401733, "aqua_rat_18404": 0.7306384444236755, "aqua_rat_53475": 0.7311743497848511, "aqua_rat_7648": 0.731737494468689, "aqua_rat_36396": 0.7328037619590759, "aqua_rat_37634": 0.7328957915306091, "aqua_rat_77140": 0.7330532073974609, "math_train_counting_and_probability_296": 0.7330697178840637, "aqua_rat_5242": 0.7331523895263672, "aqua_rat_18901": 0.7333182096481323, "aqua_rat_55838": 0.7335616946220398, "aqua_rat_33304": 0.7344760298728943, "aqua_rat_76846": 0.7351110577583313, "aqua_rat_16354": 0.7355650067329407, "math_train_counting_and_probability_784": 0.7367351651191711, "math_train_counting_and_probability_70": 0.7371503114700317, "aqua_rat_13585": 0.7386140823364258, "aqua_rat_71434": 0.7391389012336731, "math_test_counting_and_probability_695": 0.7396383881568909, "aqua_rat_45483": 0.7402479648590088, "math_test_counting_and_probability_1092": 0.7402589917182922, "aqua_rat_34678": 0.7406946420669556, "math_train_counting_and_probability_167": 0.7410309910774231, "aqua_rat_11061": 0.7421283721923828, "math_train_counting_and_probability_125": 0.7448224425315857, "aqua_rat_65310": 0.7454246878623962, "aqua_rat_7248": 0.7457408308982849, "aqua_rat_37185": 0.7465092539787292, "math_train_counting_and_probability_617": 0.7477328777313232, "aqua_rat_60936": 0.7477576732635498, "aqua_rat_61965": 0.7479986548423767, "math_train_counting_and_probability_696": 0.7483000159263611, "math_train_counting_and_probability_149": 0.7487679123878479, "math_train_counting_and_probability_375": 0.7494409084320068, "aqua_rat_5877": 0.7500610947608948, "aqua_rat_48130": 0.7505019307136536, "aqua_rat_49569": 0.751031756401062, "math_train_counting_and_probability_651": 0.7519405484199524, "aqua_rat_11273": 0.7519607543945312, "aqua_rat_73122": 0.7530777454376221, "math_train_counting_and_probability_273": 0.7536429166793823, "aops_2019_AMC_8_Problems/Problem_25": 0.7583413124084473, "aqua_rat_2480": 0.7587345838546753, "aqua_rat_89113": 0.7589595913887024, "aqua_rat_34": 0.7610859274864197, "aqua_rat_4294": 0.7611509561538696, "math_train_counting_and_probability_241": 0.7612619400024414, "math_test_counting_and_probability_494": 0.7616099119186401, "math_test_counting_and_probability_71": 0.7626351118087769, "aqua_rat_73402": 0.7628802061080933, "aqua_rat_37649": 0.7631255984306335, "aqua_rat_66391": 0.7644903659820557, "aqua_rat_26524": 0.7671568393707275, "aqua_rat_57502": 0.7687534689903259, "aqua_rat_75188": 0.7772845029830933, "aqua_rat_56015": 0.7778656482696533, "aqua_rat_19436": 0.7788112163543701, "aqua_rat_25369": 0.7837816476821899, "math_train_counting_and_probability_98": 0.7870374917984009, "aqua_rat_61326": 0.7874439358711243, "math_test_counting_and_probability_294": 0.7892043590545654, "aqua_rat_83784": 0.7967003583908081, "math_train_counting_and_probability_83": 0.8135863542556763}, "TheoremQA_xinyi/dag_3.json": {"camel_23545": 0, "camel_20512": 0, "camel_21817": 0, "camel_20734": 0, "camel_21299": 0, "camel_23542": 0, "camel_21809": 0, "camel_23285": 0, "camel_23103": 0, "camel_23284": 0, "camel_20648": 0, "camel_22828": 0, "camel_21321": 0, "camel_21292": 0, "camel_22868": 0, "camel_22819": 0, "camel_21266": 0, "camel_20654": 0, "camel_20744": 0, "camel_23526": 0, "camel_21100": 0, "camel_23098": 0, "camel_21063": 0, "camel_22816": 0, "camel_21344": 0, "camel_20679": 0, "camel_21085": 0, "camel_23573": 0, "camel_21018": 0, "camel_23581": 0, "camel_23057": 0, "camel_20711": 0, "camel_20992": 0, "camel_23553": 0, "camel_23119": 0, "camel_21287": 0, "camel_20650": 0, "camel_23060": 0, "camel_21286": 0, "camel_20645": 0, "camel_20721": 0, "camel_21064": 0, "camel_23093": 0, "camel_20717": 0, "camel_20663": 0, "camel_23312": 0, "camel_21004": 0, "camel_21228": 0, "camel_20516": 0, "camel_21815": 0, "camel_22807": 0, "camel_23558": 0, "camel_23561": 0, "camel_21260": 0, "camel_23105": 0, "camel_21059": 0, "camel_21269": 0, "camel_23114": 0, "camel_23061": 0, "camel_23528": 0, "camel_20967": 0, "camel_20641": 0, "camel_21112": 0, "camel_23073": 0, "camel_23117": 0, "camel_23106": 0, "camel_20050": 0, "TheoremQA_xinyi/dag_3.json": 0, "aqua_rat_71277": 0.6146625876426697, "aqua_rat_49516": 0.6146653294563293, "aqua_rat_49652": 0.6150965094566345, "aqua_rat_11490": 0.6152431964874268, "math_test_prealgebra_1562": 0.6154196858406067, "camel_26733": 0.6154443025588989, "aqua_rat_27920": 0.6154512166976929, "aqua_rat_64036": 0.6156020760536194, "aqua_rat_88199": 0.6156113743782043, "math_train_counting_and_probability_5092": 0.6158663630485535, "camel_26769": 0.6160110235214233, "aqua_rat_47649": 0.6164172291755676, "aqua_rat_42992": 0.6165922284126282, "aqua_rat_116": 0.6166021227836609, "math_test_counting_and_probability_924": 0.6166576147079468, "math_train_prealgebra_158": 0.6167906522750854, "aqua_rat_351": 0.6170130372047424, "aqua_rat_25794": 0.6171768307685852, "aqua_rat_51466": 0.6175705790519714, "math_test_counting_and_probability_477": 0.6176065802574158, "aqua_rat_20745": 0.6176177859306335, "aqua_rat_56019": 0.6176543235778809, "aqua_rat_67804": 0.6179021596908569, "aqua_rat_55136": 0.6179130673408508, "camel_37120": 0.617954671382904, "math_train_counting_and_probability_22": 0.6180577874183655, "aqua_rat_7949": 0.6183810234069824, "aqua_rat_11605": 0.6186413168907166, "aqua_rat_73857": 0.6188221573829651, "aqua_rat_56829": 0.618935227394104, "aqua_rat_70796": 0.6189546585083008, "aqua_rat_40504": 0.6195312738418579, "aqua_rat_15856": 0.6197514533996582, "aqua_rat_5839": 0.6200981736183167, "aqua_rat_7564": 0.6201900839805603, "aqua_rat_44904": 0.6206000447273254, "aqua_rat_13247": 0.6213105320930481, "aqua_rat_39088": 0.6215285062789917, "aqua_rat_57478": 0.6222240924835205, "aqua_rat_15263": 0.6223061680793762, "math_test_counting_and_probability_697": 0.6223084330558777, "aqua_rat_78595": 0.6225265264511108, "aqua_rat_26378": 0.6228867173194885, "TheoremQA_jianyu_xu/Graph_2.json": 0.6234963536262512, "aqua_rat_38316": 0.6237882971763611, "math_train_prealgebra_1621": 0.6240633726119995, "math_train_counting_and_probability_5127": 0.6242143511772156, "math_test_counting_and_probability_134": 0.6246740818023682, "aqua_rat_797": 0.6249175071716309, "math_train_counting_and_probability_5098": 0.6252171993255615, "camel_19957": 0.6252628564834595, "math_train_counting_and_probability_487": 0.6256321668624878, "aqua_rat_24191": 0.6268744468688965, "aqua_rat_8052": 0.6269091963768005, "aqua_rat_43496": 0.6269964575767517, "aqua_rat_72490": 0.6273648142814636, "aqua_rat_26470": 0.6276494264602661, "aqua_rat_12094": 0.6277572512626648, "aqua_rat_44063": 0.6286706924438477, "aqua_rat_72283": 0.6288052797317505, "aqua_rat_14817": 0.6289343237876892, "math_test_counting_and_probability_103": 0.6290658712387085, "aqua_rat_85987": 0.6292127370834351, "aqua_rat_10748": 0.6293644905090332, "aqua_rat_43397": 0.6293911337852478, "TheoremQA_jianyu_xu/Cayley_3.json": 0.6294918060302734, "aqua_rat_16904": 0.629570484161377, "math_train_counting_and_probability_817": 0.6296969056129456, "math_train_counting_and_probability_76": 0.629780113697052, "aqua_rat_85657": 0.6299622058868408, "aqua_rat_35578": 0.630850076675415, "aqua_rat_38881": 0.6313496232032776, "aqua_rat_72930": 0.6327266097068787, "aqua_rat_52342": 0.6329531669616699, "aqua_rat_54745": 0.6331074237823486, "aqua_rat_34175": 0.6332809329032898, "aqua_rat_28558": 0.6334949731826782, "aqua_rat_38197": 0.633603572845459, "math_train_counting_and_probability_301": 0.6351882815361023, "aqua_rat_74262": 0.6353693604469299, "aqua_rat_53443": 0.6354267001152039, "aqua_rat_48187": 0.6356695890426636, "aqua_rat_35816": 0.6357722878456116, "aqua_rat_55263": 0.636203408241272, "aqua_rat_59796": 0.6362700462341309, "math_test_counting_and_probability_378": 0.636421263217926, "math_test_counting_and_probability_796": 0.6377204656600952, "aqua_rat_78326": 0.6382508277893066, "math_test_counting_and_probability_525": 0.6384650468826294, "aqua_rat_10077": 0.6385849118232727, "math_train_counting_and_probability_646": 0.6388556361198425, "aqua_rat_62566": 0.6402360796928406, "aqua_rat_80580": 0.6403452754020691, "aqua_rat_15245": 0.6403506398200989, "math_test_counting_and_probability_238": 0.6407669186592102, "aqua_rat_5729": 0.6410039067268372, "aqua_rat_58284": 0.6410332918167114, "aqua_rat_67046": 0.6413702964782715, "aqua_rat_17277": 0.641852617263794, "aqua_rat_47629": 0.642130970954895, "aqua_rat_22747": 0.6425150036811829, "math_train_counting_and_probability_797": 0.6436149477958679, "aqua_rat_21785": 0.6442789435386658, "math_train_counting_and_probability_957": 0.6442939043045044, "aqua_rat_48706": 0.6444480419158936, "math_train_counting_and_probability_720": 0.6445216536521912, "aqua_rat_11087": 0.6455671787261963, "math_test_counting_and_probability_159": 0.645682156085968, "aqua_rat_69610": 0.6459167003631592, "math_test_counting_and_probability_215": 0.6463602781295776, "math_train_counting_and_probability_237": 0.6464030742645264, "aqua_rat_75260": 0.6468786001205444, "aqua_rat_65989": 0.6482778787612915, "aqua_rat_35588": 0.6485493779182434, "aqua_rat_6563": 0.6487197875976562, "aqua_rat_2574": 0.6494010090827942, "aqua_rat_26482": 0.6496059894561768, "aqua_rat_62784": 0.6507389545440674, "aqua_rat_8977": 0.6510188579559326, "aqua_rat_30701": 0.6512985825538635, "math_train_counting_and_probability_466": 0.6520112752914429, "math_test_counting_and_probability_653": 0.6524925231933594, "aqua_rat_83838": 0.6532483100891113, "aqua_rat_68730": 0.6564763784408569, "aqua_rat_84091": 0.663022518157959, "math_test_counting_and_probability_1047": 0.6650391817092896, "aqua_rat_12408": 0.6653722524642944, "TheoremQA_xinyi/dag_1.json": 0.6662163138389587, "aqua_rat_81312": 0.6689584851264954, "math_test_counting_and_probability_1046": 0.6693013310432434, "aqua_rat_65738": 0.6706799864768982, "math_test_counting_and_probability_623": 0.6760286688804626}, "TheoremQA_jianyu_xu/Graph_2.json": {"camel_22327": 0, "camel_21091": 0, "camel_22384": 0, "camel_22476": 0, "camel_22423": 0, "camel_22369": 0, "camel_23155": 0, "camel_22437": 0, "camel_22827": 0, "camel_23187": 0, "camel_23195": 0, "camel_23188": 0, "camel_22444": 0, "camel_23149": 0, "camel_23971": 0, "camel_22434": 0, "camel_22418": 0, "camel_22404": 0, "camel_22345": 0, "camel_23127": 0, "camel_22405": 0, "camel_23162": 0, "camel_22333": 0, "camel_22439": 0, "camel_23170": 0, "camel_23394": 0, "camel_23180": 0, "camel_22364": 0, "camel_22477": 0, "camel_22335": 0, "camel_22442": 0, "camel_22397": 0, "camel_22466": 0, "camel_23431": 0, "camel_23237": 0, "camel_22382": 0, "camel_22362": 0, "camel_22858": 0, "camel_23975": 0, "camel_22424": 0, "camel_22389": 0, "camel_23156": 0, "camel_23145": 0, "camel_22807": 0, "camel_22450": 0, "camel_22387": 0, "camel_23376": 0, "camel_21098": 0, "camel_22445": 0, "camel_22430": 0, "camel_22573": 0, "camel_23403": 0, "camel_22816": 0, "camel_22453": 0, "camel_21064": 0, "camel_23402": 0, "camel_22383": 0, "camel_23169": 0, "camel_23190": 0, "camel_22386": 0, "camel_22391": 0, "camel_22478": 0, "camel_22469": 0, "camel_23114": 0, "camel_22417": 0, "camel_22320": 0, "camel_23386": 0, "camel_22407": 0, "camel_22425": 0, "camel_22401": 0, "camel_22329": 0, "camel_23363": 0, "camel_23392": 0, "camel_23427": 0, "camel_22819": 0, "camel_22415": 0, "camel_23988": 0, "camel_23125": 0, "camel_22422": 0, "camel_22473": 0, "camel_23154": 0, "camel_23157": 0, "camel_23932": 0, "camel_22373": 0, "camel_22451": 0, "camel_21804": 0, "camel_23163": 0, "camel_22411": 0, "camel_23147": 0, "camel_21067": 0, "camel_22412": 0, "camel_23364": 0, "camel_22334": 0, "camel_23164": 0, "camel_22393": 0, "camel_22862": 0, "camel_23124": 0, "camel_21063": 0, "camel_23128": 0, "camel_23423": 0, "camel_23060": 0, "camel_21083": 0, "camel_23141": 0, "camel_23196": 0, "camel_21044": 0, "camel_22352": 0, "camel_22458": 0, "camel_23189": 0, "camel_21107": 0, "camel_23174": 0, "camel_23132": 0, "camel_22824": 0, "camel_22454": 0, "camel_22443": 0, "camel_23342": 0, "camel_22863": 0, "camel_22378": 0, "camel_22823": 0, "camel_22398": 0, "camel_23150": 0, "camel_23167": 0, "camel_23404": 0, "camel_22400": 0, "camel_23181": 0, "camel_22812": 0, "camel_23177": 0, "camel_21100": 0, "camel_23131": 0, "camel_23934": 0, "camel_22448": 0, "camel_22452": 0, "camel_23159": 0, "camel_22361": 0, "camel_23161": 0, "camel_22379": 0, "camel_21072": 0, "camel_22471": 0, "camel_22867": 0, "camel_22879": 0, "camel_22801": 0, "camel_22464": 0, "camel_23158": 0, "camel_22328": 0, "camel_22338": 0, "camel_22356": 0, "camel_22808": 0, "camel_23965": 0, "camel_23198": 0, "camel_22462": 0, "camel_23430": 0, "camel_22068": 0, "camel_22853": 0, "camel_23172": 0, "camel_23165": 0, "camel_23944": 0, "camel_23391": 0, "camel_22061": 0, "camel_23182": 0, "camel_23175": 0, "camel_23372": 0, "camel_22456": 0, "camel_22849": 0, "camel_23123": 0, "camel_23424": 0, "camel_23138": 0, "camel_22825": 0, "camel_21102": 0, "camel_23393": 0, "camel_23425": 0, "camel_22843": 0, "camel_23122": 0, "camel_22866": 0, "camel_23176": 0, "camel_23191": 0, "camel_23166": 0, "camel_22838": 0, "camel_23151": 0, "camel_23400": 0, "camel_23126": 0, "camel_23144": 0, "camel_21764": 0, "camel_21057": 0, "camel_23179": 0, "camel_23378": 0, "camel_22805": 0, "camel_23382": 0, "camel_23135": 0, "camel_23193": 0, "camel_23432": 0, "aqua_rat_36545": 0.7270246148109436, "TheoremQA_xinyi/dag_3.json": 0.7271863222122192, "math_train_prealgebra_350": 0.7285058498382568, "aqua_rat_54929": 0.7336102724075317, "aqua_rat_28685": 0.7369005084037781, "aqua_rat_44831": 0.743766725063324, "aqua_rat_76009": 0.74558424949646, "aqua_rat_70645": 0.7519480586051941, "aqua_rat_40504": 0.7537973523139954, "aqua_rat_25794": 0.7559002041816711, "camel_19957": 0.7663794159889221}, "TheoremQA_tonyxia/euler-graph2.json": {"camel_22582": 0, "camel_23907": 0, "camel_23879": 0, "camel_22601": 0, "camel_22620": 0, "camel_22625": 0, "camel_23864": 0, "camel_23908": 0, "camel_23902": 0, "camel_22572": 0, "camel_22614": 0, "camel_22578": 0, "camel_23896": 0, "camel_23903": 0, "camel_23876": 0, "camel_23917": 0, "camel_23872": 0, "camel_23901": 0, "camel_22635": 0, "camel_23863": 0, "camel_23899": 0, "camel_23915": 0, "camel_22638": 0, "camel_22563": 0, "camel_23849": 0, "camel_22570": 0, "camel_22157": 0, "camel_23852": 0, "camel_23858": 0, "camel_23865": 0, "camel_22631": 0, "camel_23869": 0, "camel_22594": 0, "camel_23846": 0, "camel_22621": 0, "camel_23910": 0, "camel_22588": 0, "camel_23904": 0, "camel_23868": 0, "camel_22584": 0, "camel_23845": 0, "camel_22632": 0, "camel_23889": 0, "camel_22610": 0, "camel_22560": 0, "camel_23856": 0, "camel_22630": 0, "camel_22593": 0, "camel_22564": 0, "camel_23906": 0, "camel_23894": 0, "camel_22565": 0, "camel_22600": 0, "camel_22636": 0, "camel_22606": 0, "camel_22611": 0, "camel_22619": 0, "camel_23862": 0, "camel_23844": 0, "camel_23857": 0, "camel_22586": 0, "camel_23854": 0, "camel_23918": 0, "camel_23871": 0, "camel_23884": 0, "camel_22569": 0, "camel_23905": 0, "camel_22587": 0, "camel_23842": 0, "camel_22616": 0, "camel_23861": 0, "camel_23900": 0, "camel_22577": 0, "camel_23867": 0, "camel_22617": 0, "camel_23870": 0, "camel_22599": 0, "camel_23911": 0, "camel_23891": 0, "camel_22580": 0, "camel_23890": 0, "camel_22562": 0, "camel_23866": 0, "camel_23843": 0, "camel_23909": 0, "camel_22598": 0, "camel_23841": 0, "camel_23850": 0, "camel_22605": 0, "camel_22609": 0, "camel_22595": 0, "camel_23859": 0, "camel_22907": 0, "camel_23887": 0, "camel_22575": 0, "camel_23892": 0, "camel_22607": 0, "camel_23877": 0, "camel_23840": 0, "camel_23880": 0, "camel_23919": 0, "camel_22561": 0, "camel_23913": 0, "TheoremQA_tonyxia/euler-graph2.json": 0, "camel_23848": 0, "camel_23874": 0, "camel_22634": 0, "camel_22589": 0, "camel_22604": 0, "camel_23873": 0, "camel_23893": 0, "camel_22637": 0, "camel_22568": 0, "camel_23898": 0, "camel_23878": 0, "camel_22591": 0, "camel_23881": 0, "camel_23847": 0, "camel_22592": 0, "camel_22574": 0, "camel_23916": 0, "camel_22603": 0, "camel_22567": 0, "camel_22624": 0, "camel_22626": 0, "camel_22623": 0, "camel_22622": 0, "camel_22639": 0, "camel_22576": 0, "camel_18561": 0.7511133551597595, "camel_19416": 0.7520946860313416, "camel_18618": 0.7524275183677673, "camel_19363": 0.7553831934928894, "camel_18586": 0.7560432553291321, "camel_18599": 0.7572697997093201, "camel_19995": 0.758021891117096, "camel_18631": 0.7597848773002625, "math_train_counting_and_probability_501": 0.7599507570266724, "camel_19969": 0.7629886865615845, "camel_18606": 0.7645097374916077, "math_train_geometry_46": 0.7650851607322693, "camel_18611": 0.7678161859512329, "camel_19921": 0.767906665802002, "camel_18873": 0.7745740413665771, "camel_19402": 0.7759257555007935, "math_test_geometry_188": 0.7762702703475952, "camel_18639": 0.7820301055908203, "math_train_geometry_821": 0.7830895185470581, "aqua_rat_15736": 0.7838818430900574, "camel_18626": 0.7842567563056946, "math_test_geometry_154": 0.7859402894973755, "math_test_geometry_713": 0.7872909307479858, "camel_18624": 0.7932998538017273, "camel_18698": 0.7960142493247986, "camel_18658": 0.7963140606880188, "camel_18598": 0.7987507581710815, "camel_18638": 0.7995886206626892, "aqua_rat_72587": 0.8000500798225403, "aqua_rat_49777": 0.8026639819145203, "aqua_rat_23171": 0.8031126856803894, "camel_18877": 0.8036929965019226, "camel_18569": 0.8039147853851318, "camel_19956": 0.8049377799034119, "camel_18643": 0.8060604929924011, "camel_18692": 0.8090611696243286, "math_test_counting_and_probability_385": 0.8091300129890442, "camel_18688": 0.8125127553939819, "camel_18634": 0.8146164417266846, "camel_18676": 0.8146275877952576, "camel_19970": 0.8157302141189575, "camel_18715": 0.8180935978889465, "aqua_rat_551": 0.8187527060508728, "camel_19723": 0.8200770020484924, "TheoremQA_tonyxia/maxplanar3.json": 0.8206830024719238, "camel_19812": 0.8215467929840088, "math_test_geometry_217": 0.8218168020248413, "TheoremQA_tonyxia/maxplanar1.json": 0.8307849764823914, "camel_18644": 0.8332713842391968, "camel_18831": 0.8356838226318359, "camel_18672": 0.8359378576278687, "aqua_rat_16933": 0.838224470615387, "math_train_geometry_758": 0.8390159606933594, "camel_18627": 0.8397274613380432, "camel_18608": 0.8398919701576233, "camel_18717": 0.8408582210540771, "math_train_prealgebra_519": 0.8433275818824768, "camel_19741": 0.844050943851471, "math_train_geometry_6085": 0.8488355875015259, "camel_18964": 0.8488638401031494, "camel_18679": 0.851925253868103, "camel_18659": 0.8527743816375732, "camel_18701": 0.8528575301170349, "camel_19888": 0.8540824055671692, "TheoremQA_tonyxia/euler-graph3.json": 0.8544176816940308, "camel_18686": 0.8579074144363403, "camel_18699": 0.8593824505805969, "camel_18652": 0.8610600829124451, "camel_18673": 0.8792716860771179, "math_train_geometry_6025": 0.8831977248191833, "camel_18677": 0.8900768756866455}, "TheoremQA_jianyu_xu/Stirling_number_first_kind_6.json": {"camel_20980": 0, "camel_20990": 0, "camel_21762": 0, "camel_21269": 0, "camel_21059": 0, "camel_21004": 0, "camel_20967": 0, "camel_21018": 0, "camel_21815": 0, "camel_21006": 0, "camel_21581": 0, "camel_20995": 0, "TheoremQA_jianyu_xu/Stirling_number_first_kind_6.json": 0, "camel_21085": 0, "camel_20663": 0, "camel_20971": 0, "camel_21112": 0, "camel_21260": 0, "camel_21228": 0, "camel_20992": 0, "aqua_rat_22351": 0.7242783904075623, "aqua_rat_76792": 0.7244638800621033, "aqua_rat_58230": 0.7250778675079346, "aqua_rat_87133": 0.725246012210846, "aqua_rat_34500": 0.7259997129440308, "aqua_rat_3776": 0.7263323664665222, "aqua_rat_33137": 0.7267475724220276, "aqua_rat_2647": 0.7269355058670044, "aqua_rat_19157": 0.7269445657730103, "aqua_rat_46190": 0.7271909117698669, "aqua_rat_57598": 0.7280482649803162, "aqua_rat_68341": 0.7286028861999512, "aqua_rat_32302": 0.7295553684234619, "aqua_rat_25143": 0.7295827865600586, "aqua_rat_32673": 0.7300223708152771, "aqua_rat_73194": 0.7303935289382935, "aqua_rat_81651": 0.7305924296379089, "aqua_rat_5839": 0.7309331297874451, "aqua_rat_72932": 0.7316531538963318, "aqua_rat_34666": 0.7316647171974182, "aqua_rat_15987": 0.7339485883712769, "aqua_rat_54933": 0.7343855500221252, "math_test_counting_and_probability_849": 0.735734760761261, "aqua_rat_67136": 0.7357679009437561, "aqua_rat_16110": 0.7385613918304443, "aqua_rat_35701": 0.7386704087257385, "aqua_rat_18382": 0.7391526103019714, "aqua_rat_4389": 0.7391771078109741, "aqua_rat_25771": 0.7402012944221497, "aqua_rat_65743": 0.74146968126297, "aqua_rat_43904": 0.7415050268173218, "aqua_rat_14194": 0.7417736649513245, "math_test_counting_and_probability_277": 0.7422094345092773, "math_test_counting_and_probability_525": 0.742366373538971, "math_train_counting_and_probability_5": 0.742607593536377, "aqua_rat_73606": 0.7442619204521179, "aqua_rat_37078": 0.7445523142814636, "aqua_rat_56084": 0.745812714099884, "aqua_rat_59877": 0.7470751404762268, "aqua_rat_1243": 0.7478503584861755, "aqua_rat_10259": 0.7481909394264221, "camel_49896": 0.7484191060066223, "math_test_counting_and_probability_352": 0.7490487098693848, "aqua_rat_70746": 0.7492749691009521, "camel_23593": 0.7495326399803162, "aqua_rat_26444": 0.7509350776672363, "aqua_rat_58183": 0.7513445615768433, "aqua_rat_24589": 0.7513987421989441, "aqua_rat_48187": 0.7518957257270813, "aqua_rat_79173": 0.7527706027030945, "aqua_rat_43496": 0.7533420920372009, "aqua_rat_35816": 0.7559394836425781, "aqua_rat_43248": 0.7561630606651306, "aqua_rat_34094": 0.7564756274223328, "aqua_rat_10055": 0.7578144073486328, "aqua_rat_75260": 0.7613192796707153, "aqua_rat_26470": 0.7624005675315857, "math_train_counting_and_probability_301": 0.7630847692489624, "aqua_rat_77200": 0.7636961936950684, "aqua_rat_85657": 0.7645387649536133, "aqua_rat_20745": 0.7657142281532288, "math_test_counting_and_probability_212": 0.7665849924087524, "aqua_rat_797": 0.7669751048088074, "aqua_rat_13247": 0.7678853273391724, "aqua_rat_57577": 0.7693436145782471, "aqua_rat_72930": 0.7701582312583923, "aqua_rat_16904": 0.7702135443687439, "aqua_rat_68044": 0.7717576622962952, "math_test_counting_and_probability_488": 0.7720252275466919, "aqua_rat_63326": 0.7724577188491821, "aqua_rat_82470": 0.7732338905334473, "math_test_counting_and_probability_134": 0.7763850092887878, "aqua_rat_22143": 0.7766334414482117, "aqua_rat_75483": 0.7771568298339844, "aqua_rat_44714": 0.777472972869873, "aqua_rat_11605": 0.7780643701553345, "aqua_rat_35588": 0.7781798839569092, "aqua_rat_51769": 0.778430163860321, "aqua_rat_12675": 0.7787835597991943, "aqua_rat_28375": 0.7794196009635925, "aqua_rat_15245": 0.781877338886261, "aqua_rat_83838": 0.7819675207138062, "aqua_rat_1079": 0.7822402715682983, "aqua_rat_79164": 0.7829281687736511, "aqua_rat_77984": 0.7829403877258301, "math_train_counting_and_probability_5127": 0.7830608487129211, "aqua_rat_6563": 0.7834402322769165, "aqua_rat_35918": 0.7840142250061035, "aqua_rat_8977": 0.7843204736709595, "aqua_rat_84814": 0.7846431732177734, "math_test_counting_and_probability_519": 0.7849176526069641, "aqua_rat_62617": 0.7849228382110596, "aqua_rat_8052": 0.7852665185928345, "aqua_rat_69466": 0.7858184576034546, "math_train_counting_and_probability_194": 0.7858924865722656, "aqua_rat_66893": 0.7860820293426514, "aqua_rat_70049": 0.7863990664482117, "aqua_rat_28522": 0.7865659594535828, "aqua_rat_62970": 0.7865925431251526, "aqua_rat_49928": 0.7868071794509888, "aqua_rat_43681": 0.7871571183204651, "aqua_rat_15635": 0.7876529097557068, "aqua_rat_25491": 0.7878000140190125, "math_test_counting_and_probability_477": 0.7881621718406677, "aqua_rat_55136": 0.7881926894187927, "aqua_rat_49470": 0.7882563471794128, "aqua_rat_63462": 0.7884303331375122, "aqua_rat_12094": 0.7887651324272156, "aqua_rat_9008": 0.7892431020736694, "aqua_rat_5511": 0.7894361615180969, "math_test_counting_and_probability_472": 0.7895733118057251, "aqua_rat_15263": 0.790547788143158, "aqua_rat_49516": 0.793234646320343, "aqua_rat_10748": 0.7937330007553101, "aqua_rat_10077": 0.7939888834953308, "aqua_rat_43397": 0.794700026512146, "aqua_rat_39587": 0.7950590252876282, "aqua_rat_7949": 0.7965567708015442, "aqua_rat_50417": 0.7966936230659485, "math_test_counting_and_probability_1046": 0.7976641654968262, "aqua_rat_72490": 0.7978186011314392, "aqua_rat_70809": 0.7980082631111145, "aqua_rat_68644": 0.7992350459098816, "aqua_rat_12909": 0.8011859059333801, "aqua_rat_70944": 0.801417887210846, "math_train_counting_and_probability_76": 0.8026619553565979, "math_test_counting_and_probability_159": 0.8027197122573853, "aqua_rat_22061": 0.8032504320144653, "math_test_counting_and_probability_623": 0.8054304122924805, "aqua_rat_80989": 0.8056163191795349, "aqua_rat_78055": 0.8064090609550476, "aqua_rat_15999": 0.8070120215415955, "math_test_counting_and_probability_796": 0.8071385622024536, "aqua_rat_18622": 0.8077943325042725, "aqua_rat_50865": 0.8084115982055664, "aqua_rat_39020": 0.8092652559280396, "aqua_rat_84091": 0.809755802154541, "aqua_rat_5282": 0.8107838034629822, "math_test_counting_and_probability_103": 0.8110050559043884, "math_train_counting_and_probability_466": 0.8114297389984131, "aqua_rat_26482": 0.8121773600578308, "aqua_rat_83431": 0.8127844929695129, "aqua_rat_53443": 0.8128039836883545, "aqua_rat_17277": 0.8128331899642944, "aqua_rat_27882": 0.8129212856292725, "aqua_rat_55411": 0.8139281272888184, "aqua_rat_28558": 0.815090537071228, "aqua_rat_73694": 0.8151578903198242, "aqua_rat_11818": 0.8152510523796082, "aqua_rat_51288": 0.8163455128669739, "math_train_counting_and_probability_237": 0.8168894648551941, "aqua_rat_62784": 0.816896378993988, "math_train_counting_and_probability_487": 0.8172780871391296, "math_test_counting_and_probability_653": 0.819665253162384, "aqua_rat_67395": 0.8202203512191772, "aqua_rat_78326": 0.8211732506752014, "math_test_counting_and_probability_238": 0.8211818933486938, "aqua_rat_48525": 0.8218066692352295, "aqua_rat_76078": 0.8253400325775146, "aqua_rat_47815": 0.825419545173645, "math_test_counting_and_probability_378": 0.8260473608970642, "math_train_counting_and_probability_646": 0.8270451426506042, "aqua_rat_27360": 0.8272053003311157, "aqua_rat_38197": 0.827455997467041, "aqua_rat_38881": 0.828822135925293, "aqua_rat_34175": 0.8308638334274292, "aqua_rat_78595": 0.8311883211135864, "aqua_rat_59796": 0.8319884538650513, "math_train_counting_and_probability_957": 0.8328471779823303, "aqua_rat_88199": 0.8343179821968079, "math_test_counting_and_probability_215": 0.8346067667007446, "aqua_rat_49652": 0.8352844715118408, "aqua_rat_5884": 0.8361427783966064, "aqua_rat_58284": 0.8370030522346497, "aqua_rat_23659": 0.8397775888442993, "aqua_rat_23742": 0.8405737280845642, "math_test_counting_and_probability_1047": 0.8462421894073486, "aqua_rat_47629": 0.8535717129707336, "aqua_rat_54745": 0.855665385723114, "aqua_rat_74262": 0.8558413982391357}, "TheoremQA_xueguangma/present_value_1.json": {"TheoremQA_xueguangma/present_value_1.json": 0, "aqua_rat_10706": 0.706162691116333, "aqua_rat_62727": 0.7064056396484375, "gsm_rft_14423": 0.7065055966377258, "aqua_rat_36498": 0.7066555023193359, "aqua_rat_78121": 0.7067074775695801, "gsm_rft_35249": 0.7069112062454224, "aqua_rat_15556": 0.7069659233093262, "aqua_rat_21814": 0.7072271704673767, "aqua_rat_42949": 0.7073056697845459, "aqua_rat_85780": 0.7073966860771179, "aqua_rat_7357": 0.7074329853057861, "gsm_rft_15888": 0.7077056765556335, "gsm_train_21876": 0.7077056765556335, "aqua_rat_71866": 0.7077546119689941, "aqua_rat_85467": 0.7079306840896606, "aqua_rat_68287": 0.7079808115959167, "aqua_rat_59403": 0.7080082893371582, "aqua_rat_79047": 0.7080704569816589, "math_train_algebra_1011": 0.7081599831581116, "aqua_rat_39049": 0.7082140445709229, "aqua_rat_16445": 0.7082529664039612, "aqua_rat_25723": 0.7084136605262756, "aqua_rat_5231": 0.7085686922073364, "camel_45730": 0.7087872624397278, "aqua_rat_50660": 0.7089807987213135, "aqua_rat_19797": 0.7091569304466248, "aqua_rat_81805": 0.7094611525535583, "aqua_rat_56852": 0.7095459699630737, "aqua_rat_32958": 0.7095853686332703, "aqua_rat_72794": 0.7096300721168518, "aqua_rat_3773": 0.7096444964408875, "aqua_rat_38785": 0.7097322344779968, "gsm_rft_5849": 0.7097498178482056, "aqua_rat_30386": 0.7101608514785767, "gsm_rft_13078": 0.7103264331817627, "gsm_rft_2192": 0.7103264331817627, "gsm_train_11080": 0.7108060717582703, "gsm_rft_20558": 0.7108601331710815, "aqua_rat_40411": 0.7110460996627808, "aqua_rat_77602": 0.7111333608627319, "aqua_rat_64484": 0.7113484740257263, "gsm_rft_33880": 0.7113552093505859, "aqua_rat_53421": 0.7114099860191345, "TheoremQA_xueguangma/future_value_1.json": 0.711486279964447, "gsm_rft_16062": 0.7114965319633484, "aqua_rat_88065": 0.7117526531219482, "gsm_train_19719": 0.7123082876205444, "gsm_rft_25231": 0.7123082876205444, "aqua_rat_84309": 0.7125879526138306, "aqua_rat_55357": 0.7125898599624634, "aqua_rat_15682": 0.7127116918563843, "aqua_rat_37258": 0.7127444744110107, "aqua_rat_78349": 0.7129504084587097, "aqua_rat_16693": 0.7132729887962341, "aqua_rat_83578": 0.7134082913398743, "aqua_rat_34573": 0.7137024402618408, "aqua_rat_60321": 0.7137356400489807, "aqua_rat_29321": 0.7142121195793152, "aqua_rat_79904": 0.7147437334060669, "gsm_rft_33659": 0.7147824764251709, "math_test_algebra_990": 0.7148301005363464, "aqua_rat_7537": 0.7148455381393433, "aqua_rat_10582": 0.7149189114570618, "aqua_rat_62528": 0.7150182127952576, "aqua_rat_59668": 0.715195894241333, "aqua_rat_68014": 0.7153109312057495, "aqua_rat_63322": 0.7154455184936523, "aqua_rat_56436": 0.715480625629425, "math_train_algebra_667": 0.7156210541725159, "aqua_rat_64664": 0.7156906127929688, "aqua_rat_86835": 0.7157138586044312, "aqua_rat_41963": 0.7158380150794983, "aqua_rat_72933": 0.7158644795417786, "aqua_rat_29170": 0.715971052646637, "aqua_rat_34698": 0.7159981727600098, "aqua_rat_42893": 0.7160326838493347, "aqua_rat_28282": 0.7162525057792664, "aqua_rat_26425": 0.7162930965423584, "gsm_rft_32408": 0.716520369052887, "aqua_rat_20878": 0.7165411114692688, "aqua_rat_43060": 0.7165495753288269, "aqua_rat_59587": 0.7165499925613403, "aqua_rat_1115": 0.7166121602058411, "aqua_rat_64976": 0.7169731855392456, "aqua_rat_58629": 0.7170037627220154, "gsm_rft_7026": 0.7170152068138123, "aqua_rat_88843": 0.7171873450279236, "aqua_rat_56718": 0.7171989679336548, "math_test_algebra_311": 0.7172530889511108, "gsm_rft_30907": 0.7173112630844116, "gsm_train_34054": 0.717323899269104, "gsm_rft_33978": 0.717323899269104, "aqua_rat_67074": 0.7173479199409485, "gsm_train_6037": 0.7174409627914429, "gsm_rft_15334": 0.7174409627914429, "aqua_rat_46525": 0.7174949645996094, "aqua_rat_37382": 0.7176318168640137, "aqua_rat_44615": 0.7176737785339355, "aqua_rat_45508": 0.7177817225456238, "aqua_rat_27053": 0.7178713083267212, "aqua_rat_83234": 0.717920184135437, "aqua_rat_69273": 0.7179473042488098, "aqua_rat_21642": 0.7183271050453186, "TheoremQA_xueguangma/future_value_2.json": 0.7184051275253296, "aqua_rat_36703": 0.7185752987861633, "gsm_rft_11804": 0.7188505530357361, "aqua_rat_26339": 0.7190280556678772, "aqua_rat_78427": 0.7191553115844727, "math_test_algebra_337": 0.7192111015319824, "math_train_algebra_2129": 0.7192133665084839, "aqua_rat_69526": 0.7193971276283264, "aqua_rat_39856": 0.719456672668457, "aqua_rat_71239": 0.7195724844932556, "aqua_rat_44549": 0.7197244763374329, "aqua_rat_3885": 0.7198277115821838, "aqua_rat_30597": 0.7200571894645691, "aqua_rat_73739": 0.7202510237693787, "aqua_rat_23247": 0.7203048467636108, "aqua_rat_73390": 0.7204957008361816, "aqua_rat_86432": 0.7206029295921326, "aqua_rat_66371": 0.7206240296363831, "aqua_rat_87589": 0.7210788726806641, "aqua_rat_20758": 0.7213534116744995, "aqua_rat_79979": 0.7215042114257812, "aqua_rat_24347": 0.7217260599136353, "TheoremQA_xueguangma/spot_rate.json": 0.721763551235199, "aqua_rat_72737": 0.7219722867012024, "aqua_rat_57507": 0.7222149968147278, "gsm_rft_1820": 0.7223275303840637, "aqua_rat_36461": 0.722419261932373, "aqua_rat_80269": 0.7224592566490173, "gsm_rft_15208": 0.7225050330162048, "aqua_rat_47773": 0.7225250601768494, "aqua_rat_53504": 0.7229593396186829, "aqua_rat_15337": 0.7229909896850586, "aqua_rat_80676": 0.7243866324424744, "math_train_algebra_1277": 0.7244499325752258, "math_test_algebra_608": 0.7245440483093262, "gsm_train_17995": 0.7246699333190918, "aqua_rat_45867": 0.7246741652488708, "math_test_algebra_2626": 0.7247477769851685, "aqua_rat_10990": 0.7247673273086548, "gsm_rft_7096": 0.7249064445495605, "gsm_rft_25112": 0.7249432802200317, "aqua_rat_75833": 0.7250552773475647, "aqua_rat_33923": 0.7252625823020935, "gsm_rft_22073": 0.7255892157554626, "gsm_rft_22572": 0.7256229519844055, "camel_45738": 0.7259688973426819, "aqua_rat_83740": 0.7268332242965698, "aqua_rat_85193": 0.7277482748031616, "aqua_rat_29154": 0.7278610467910767, "aqua_rat_52978": 0.7280300855636597, "aqua_rat_85902": 0.7281977534294128, "aqua_rat_3536": 0.7288667559623718, "gsm_train_30707": 0.729278028011322, "gsm_rft_20456": 0.7298544645309448, "gsm_rft_26458": 0.7299863696098328, "gsm_rft_6203": 0.7306900024414062, "aqua_rat_14728": 0.7307259440422058, "math_train_algebra_1658": 0.7317777872085571, "math_train_algebra_2507": 0.7321670055389404, "aqua_rat_46315": 0.7322556972503662, "aqua_rat_50447": 0.7326140999794006, "aqua_rat_67698": 0.7330408692359924, "TheoremQA_xueguangma/present_value_2.json": 0.7337096929550171, "TheoremQA_xueguangma/forward_price_2.json": 0.734439492225647, "aqua_rat_6475": 0.7347094416618347, "aqua_rat_67841": 0.7364646792411804, "aqua_rat_58694": 0.7373932003974915, "aqua_rat_67442": 0.7379629611968994, "math_test_algebra_594": 0.7382195591926575, "aqua_rat_66298": 0.7385410070419312, "aqua_rat_87884": 0.7389926314353943, "aqua_rat_34332": 0.7393925786018372, "math_train_algebra_957": 0.7395394444465637, "aqua_rat_64914": 0.7398774027824402, "aqua_rat_88960": 0.7405154705047607, "aqua_rat_255": 0.7406973242759705, "aqua_rat_27039": 0.7413502335548401, "aqua_rat_70690": 0.7414250373840332, "gsm_rft_19766": 0.7419924736022949, "aqua_rat_9965": 0.7421834468841553, "gsm_rft_30946": 0.7421903610229492, "gsm_rft_9014": 0.7423424124717712, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7432981133460999, "gsm_train_34036": 0.7435255646705627, "gsm_rft_20212": 0.7437199354171753, "aqua_rat_49352": 0.7441211342811584, "aqua_rat_54684": 0.7445219159126282, "aqua_rat_87246": 0.7458705902099609, "camel_37735": 0.7464559674263, "aqua_rat_24068": 0.7469330430030823, "math_train_algebra_369": 0.7512844204902649, "math_test_algebra_1862": 0.7538697719573975, "aqua_rat_31553": 0.7571589946746826, "camel_37746": 0.7706039547920227, "math_test_algebra_1611": 0.7986898422241211, "math_train_algebra_940": 0.8083764314651489}, "TheoremQA_maxku/graphtheory4-vertexcover.json": {"camel_22189": 0, "camel_22212": 0, "camel_22377": 0, "camel_22177": 0, "camel_23369": 0, "camel_23422": 0, "camel_22782": 0, "camel_23146": 0, "camel_22788": 0, "camel_22220": 0, "camel_22092": 0, "camel_22106": 0, "camel_22772": 0, "camel_23427": 0, "camel_21769": 0, "camel_22116": 0, "camel_23654": 0, "camel_22151": 0, "camel_21793": 0, "camel_22202": 0, "camel_22117": 0, "camel_22131": 0, "camel_22121": 0, "camel_22135": 0, "camel_22127": 0, "camel_22204": 0, "camel_22193": 0, "camel_22771": 0, "camel_22137": 0, "camel_22154": 0, "camel_21179": 0, "camel_21824": 0, "camel_22238": 0, "camel_23412": 0, "camel_22110": 0, "camel_22206": 0, "camel_22147": 0, "camel_22175": 0, "camel_22225": 0, "camel_22119": 0, "camel_22235": 0, "camel_22388": 0, "camel_22138": 0, "camel_22149": 0, "camel_21795": 0, "camel_23426": 0, "camel_22781": 0, "camel_22195": 0, "camel_22797": 0, "camel_23381": 0, "camel_22158": 0, "camel_21116": 0, "camel_22104": 0, "camel_21800": 0, "camel_21794": 0, "camel_22192": 0, "camel_21788": 0, "camel_23409": 0, "camel_22088": 0, "camel_23416": 0, "camel_22692": 0, "camel_22091": 0, "camel_22171": 0, "camel_22735": 0, "camel_22208": 0, "camel_21765": 0, "camel_23395": 0, "camel_22211": 0, "camel_21774": 0, "camel_22790": 0, "camel_22101": 0, "camel_22169": 0, "camel_21838": 0, "camel_21133": 0, "camel_22165": 0, "camel_22787": 0, "camel_22227": 0, "camel_22201": 0, "camel_22751": 0, "camel_22356": 0, "camel_23364": 0, "camel_22226": 0, "camel_23414": 0, "camel_21826": 0, "camel_22191": 0, "camel_22739": 0, "camel_21779": 0, "camel_22764": 0, "camel_22756": 0, "TheoremQA_maxku/graphtheory4-vertexcover.json": 0, "camel_22140": 0, "camel_22231": 0, "camel_21833": 0, "camel_22720": 0, "camel_22168": 0, "camel_22754": 0, "camel_22176": 0, "camel_22752": 0, "camel_22161": 0, "camel_22108": 0, "camel_22209": 0, "camel_22778": 0, "camel_22221": 0, "camel_23405": 0, "camel_21797": 0, "camel_22182": 0, "camel_22239": 0, "camel_22160": 0, "camel_22724": 0, "camel_23367": 0, "camel_22224": 0, "camel_22780": 0, "camel_22738": 0, "camel_22347": 0, "camel_22187": 0, "camel_22166": 0, "camel_22729": 0, "camel_22762": 0, "camel_22786": 0, "camel_22228": 0, "camel_21773": 0, "camel_21780": 0, "camel_22731": 0, "camel_22186": 0, "camel_22761": 0, "camel_22768": 0, "camel_22742": 0, "camel_21828": 0, "camel_22746": 0, "camel_22774": 0, "camel_21768": 0, "camel_22156": 0, "camel_22753": 0, "camel_22190": 0, "camel_22723": 0, "camel_21831": 0, "camel_23397": 0, "camel_22223": 0, "camel_21784": 0, "camel_22363": 0, "camel_22728": 0, "camel_22775": 0, "camel_22210": 0, "camel_22736": 0, "camel_22216": 0, "camel_22755": 0, "camel_22749": 0, "camel_22791": 0, "camel_21792": 0, "camel_21803": 0, "camel_21763": 0, "camel_22740": 0, "camel_21785": 0, "camel_21772": 0, "camel_22215": 0, "camel_22793": 0, "camel_22179": 0, "camel_22765": 0, "camel_21782": 0, "camel_22726": 0, "camel_22183": 0, "camel_22796": 0, "camel_22180": 0, "camel_22763": 0, "camel_22181": 0, "camel_22200": 0, "camel_22784": 0, "camel_21812": 0, "camel_22185": 0, "camel_22218": 0, "camel_21818": 0, "camel_22734": 0, "camel_22188": 0, "camel_22798": 0, "camel_22745": 0, "camel_22744": 0, "camel_22789": 0, "camel_22170": 0, "camel_22799": 0, "camel_22760": 0, "camel_22769": 0, "camel_22770": 0, "camel_22773": 0, "camel_22795": 0, "camel_22722": 0, "camel_22758": 0, "camel_22785": 0, "camel_22792": 0, "camel_22777": 0, "camel_22757": 0, "camel_22783": 0, "camel_22727": 0, "camel_22767": 0, "camel_22743": 0, "camel_22737": 0, "camel_22721": 0, "camel_38526": 0.7961321473121643, "TheoremQA_maxku/graphtheory5-vertexcover.json": 0.8197380900382996, "TheoremQA_maxku/graphtheory2-vertexcover.json": 0.8229305148124695, "TheoremQA_maxku/graphtheory3-vertexcover.json": 0.8261179327964783}, "TheoremQA_maxku/signalprocessing19-period.json": {"TheoremQA_maxku/signalprocessing19-period.json": 0, "camel_5134": 0.6522329449653625, "camel_29321": 0.652238130569458, "camel_5272": 0.6527025699615479, "camel_45129": 0.6527026891708374, "camel_45504": 0.652826189994812, "camel_5147": 0.6528915762901306, "camel_5113": 0.6529632210731506, "camel_29407": 0.6531718373298645, "camel_44732": 0.6535545587539673, "camel_45923": 0.6538465619087219, "camel_29964": 0.6539859771728516, "camel_44723": 0.6541314125061035, "camel_5093": 0.6541324257850647, "camel_28751": 0.6544358730316162, "camel_44788": 0.6548155546188354, "camel_45988": 0.6549034118652344, "camel_45315": 0.6549130082130432, "camel_44848": 0.6550835371017456, "aqua_rat_83794": 0.6551252007484436, "camel_29370": 0.6553465127944946, "camel_28388": 0.655378520488739, "camel_28370": 0.6555938124656677, "camel_44766": 0.6556020379066467, "camel_29145": 0.6556203365325928, "camel_45939": 0.6556844711303711, "math_train_counting_and_probability_708": 0.6557626128196716, "camel_5158": 0.656158983707428, "TheoremQA_maxku/fourier6-FT.json": 0.6562438011169434, "camel_45928": 0.6564285159111023, "camel_44786": 0.6564424633979797, "camel_29664": 0.6564810872077942, "camel_29972": 0.6565574407577515, "camel_5185": 0.6569223403930664, "camel_44735": 0.6569725871086121, "camel_44795": 0.6571421027183533, "camel_29981": 0.6573402881622314, "camel_44806": 0.6576144695281982, "camel_44760": 0.6576330661773682, "camel_44785": 0.6578733325004578, "camel_44787": 0.6587941646575928, "camel_28779": 0.6588060855865479, "camel_28803": 0.6589066982269287, "camel_29695": 0.659084677696228, "camel_29362": 0.6593092083930969, "camel_28407": 0.6594023108482361, "camel_5197": 0.6594582796096802, "camel_28802": 0.6596525311470032, "camel_29987": 0.6597087979316711, "camel_26554": 0.6601970791816711, "camel_29372": 0.6604644656181335, "camel_29060": 0.6608670949935913, "camel_44775": 0.6609385013580322, "camel_45699": 0.6610360741615295, "camel_29692": 0.661249041557312, "camel_44749": 0.6615864634513855, "camel_29681": 0.6617311239242554, "camel_29155": 0.6618046760559082, "camel_44772": 0.6618107557296753, "camel_5235": 0.6618345975875854, "camel_44750": 0.6619085073471069, "camel_28384": 0.6623818278312683, "camel_27561": 0.6625418663024902, "camel_29122": 0.6625652313232422, "camel_29730": 0.6625897884368896, "camel_45169": 0.6626965999603271, "camel_45683": 0.6627748012542725, "camel_44727": 0.6635291576385498, "camel_28874": 0.663770854473114, "camel_29916": 0.6637712121009827, "camel_29741": 0.6638033986091614, "camel_28836": 0.6638985872268677, "camel_45712": 0.6641941070556641, "camel_45708": 0.6643224358558655, "camel_29166": 0.664583146572113, "camel_44790": 0.6647024154663086, "camel_45749": 0.6648393869400024, "camel_29928": 0.665253221988678, "camel_28357": 0.6658390760421753, "camel_26497": 0.6659223437309265, "camel_28321": 0.6663122177124023, "camel_45745": 0.6664790511131287, "camel_45174": 0.6665760278701782, "camel_28815": 0.6667454838752747, "camel_29195": 0.6667759418487549, "camel_28869": 0.6671974062919617, "camel_45685": 0.6673133373260498, "camel_5165": 0.6673774123191833, "camel_29124": 0.6674666404724121, "camel_45314": 0.6674745082855225, "camel_29042": 0.6678099632263184, "camel_45171": 0.6678894758224487, "camel_29374": 0.6679333448410034, "camel_44782": 0.6683464050292969, "camel_28532": 0.6684423089027405, "camel_29752": 0.6686233878135681, "camel_29903": 0.6686609387397766, "camel_28787": 0.6691272854804993, "camel_29961": 0.6696125864982605, "camel_29969": 0.670104444026947, "camel_45199": 0.6703283786773682, "camel_29925": 0.6705551147460938, "camel_28793": 0.6706879138946533, "camel_29420": 0.6708154082298279, "camel_29899": 0.6712202429771423, "camel_17776": 0.6714485287666321, "camel_44728": 0.6715683341026306, "camel_29415": 0.6715995669364929, "camel_29877": 0.6717515587806702, "camel_28794": 0.6717631220817566, "camel_45146": 0.6719236969947815, "camel_44411": 0.6719743013381958, "camel_29948": 0.6721503734588623, "camel_44798": 0.6723666191101074, "camel_29845": 0.6728988289833069, "camel_29305": 0.6736955642700195, "camel_29973": 0.6737744212150574, "camel_29863": 0.6739246249198914, "camel_28754": 0.6744138598442078, "camel_29421": 0.67454993724823, "camel_28785": 0.6748247742652893, "camel_29184": 0.6753578782081604, "camel_29467": 0.6762610673904419, "camel_28348": 0.6762614250183105, "camel_44400": 0.6762975454330444, "camel_45952": 0.6768240928649902, "camel_45734": 0.6772727370262146, "camel_45726": 0.6776203513145447, "camel_28404": 0.6780138611793518, "camel_28851": 0.6780496835708618, "camel_45757": 0.6783300638198853, "camel_45711": 0.6791868805885315, "camel_45729": 0.6792027950286865, "camel_28780": 0.679404079914093, "camel_29734": 0.6797653436660767, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.6797845363616943, "camel_29121": 0.6803348660469055, "camel_44872": 0.6804962754249573, "camel_45740": 0.6808255314826965, "camel_29046": 0.6810742020606995, "camel_29684": 0.6817325353622437, "camel_45710": 0.6821160912513733, "camel_29364": 0.6828745603561401, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.6831238865852356, "camel_29719": 0.6850623488426208, "camel_29429": 0.6853154301643372, "camel_45706": 0.6856144070625305, "camel_45727": 0.6857280135154724, "camel_45696": 0.6861237287521362, "camel_45681": 0.6861572265625, "camel_29438": 0.6868240237236023, "camel_45736": 0.6868870854377747, "camel_45936": 0.687583863735199, "camel_45722": 0.6877632737159729, "camel_45744": 0.6879767775535583, "camel_45680": 0.6887332797050476, "camel_29971": 0.6897993683815002, "camel_29154": 0.6899274587631226, "camel_45700": 0.6900069713592529, "camel_44424": 0.6909139752388, "camel_28740": 0.6911128163337708, "camel_45720": 0.6918053030967712, "camel_5303": 0.6926510334014893, "camel_45748": 0.6927580237388611, "camel_29371": 0.6930026412010193, "camel_29727": 0.6935746669769287, "camel_29947": 0.6938222050666809, "camel_28838": 0.6940003037452698, "camel_45682": 0.6947500109672546, "camel_44765": 0.6950796246528625, "camel_45721": 0.6951447129249573, "camel_44762": 0.6957162618637085, "camel_28744": 0.6978353261947632, "camel_28137": 0.6994175314903259, "camel_29984": 0.7006151080131531, "camel_29388": 0.7007734179496765, "camel_45718": 0.7019411325454712, "camel_28736": 0.7027819156646729, "camel_45684": 0.7029126882553101, "camel_45688": 0.7030778527259827, "gsm_train_20944": 0.7068765759468079, "gsm_rft_21298": 0.7068765759468079, "camel_45690": 0.7083823084831238, "camel_45687": 0.7090543508529663, "camel_45931": 0.7094975709915161, "camel_45693": 0.7111567258834839, "gsm_rft_33863": 0.7112630605697632, "camel_45689": 0.7117785215377808, "gsm_rft_11471": 0.7132092714309692, "camel_28379": 0.716658890247345, "camel_45741": 0.7172544002532959, "camel_29373": 0.7178292870521545, "camel_44838": 0.7241560220718384, "camel_45697": 0.7256355881690979, "camel_45725": 0.7300406098365784, "camel_45701": 0.73956698179245, "camel_29704": 0.7405993342399597, "camel_45709": 0.7445893287658691, "camel_45698": 0.7500630617141724, "camel_45754": 0.7510606050491333}, "TheoremQA_xueguangma/dividend_discount_model_4.json": {"TheoremQA_xueguangma/dividend_discount_model_4.json": 0, "aqua_rat_21029": 0.6427720189094543, "aqua_rat_86864": 0.6429404616355896, "gsm_rft_20456": 0.6429873704910278, "aqua_rat_937": 0.6430628299713135, "camel_39796": 0.6431719064712524, "aqua_rat_46293": 0.6432061195373535, "gsm_rft_2115": 0.6433120965957642, "gsm_rft_34495": 0.6434006094932556, "aqua_rat_10990": 0.6435607671737671, "aqua_rat_58803": 0.6436525583267212, "aqua_rat_87163": 0.6438482999801636, "aqua_rat_33923": 0.6440581679344177, "aqua_rat_52773": 0.6443166136741638, "math_test_algebra_337": 0.6443279385566711, "aqua_rat_32321": 0.6443495154380798, "aqua_rat_75833": 0.644374430179596, "aqua_rat_80962": 0.6447385549545288, "gsm_rft_15208": 0.6447551250457764, "aqua_rat_68501": 0.6449074745178223, "aqua_rat_9512": 0.6450313925743103, "aqua_rat_30650": 0.6451146602630615, "aqua_rat_83740": 0.645336389541626, "camel_37747": 0.6457288861274719, "aqua_rat_52775": 0.6458606719970703, "gsm_rft_749": 0.6458917856216431, "gsm_rft_876": 0.6458917856216431, "gsm_train_6548": 0.6458917856216431, "aqua_rat_57433": 0.6458929777145386, "aqua_rat_43017": 0.6462397575378418, "aqua_rat_1364": 0.6462793350219727, "gsm_rft_252": 0.646377682685852, "gsm_train_17995": 0.6464506983757019, "aqua_rat_66501": 0.6465350389480591, "gsm_rft_25112": 0.6465614438056946, "aqua_rat_62528": 0.6466576457023621, "aqua_rat_11197": 0.6466689109802246, "aqua_rat_34308": 0.646717369556427, "aqua_rat_34822": 0.6468143463134766, "gsm_rft_6083": 0.6468944549560547, "aqua_rat_26449": 0.646981418132782, "aqua_rat_52815": 0.6470145583152771, "gsm_rft_21062": 0.6471505165100098, "aqua_rat_66912": 0.6471536755561829, "aqua_rat_3885": 0.6474784016609192, "aqua_rat_78741": 0.6475813984870911, "aqua_rat_56784": 0.6480581760406494, "camel_37746": 0.648108184337616, "aqua_rat_50048": 0.6481761932373047, "aqua_rat_32740": 0.6483548283576965, "aqua_rat_20083": 0.6483873724937439, "aqua_rat_40344": 0.6488701105117798, "aqua_rat_17504": 0.6490078568458557, "aqua_rat_23319": 0.6490989327430725, "aqua_rat_4236": 0.6491389274597168, "aqua_rat_53206": 0.6498253345489502, "aqua_rat_5939": 0.6498456597328186, "aqua_rat_3773": 0.6499457955360413, "gsm_rft_10252": 0.650026798248291, "aqua_rat_17859": 0.6502355337142944, "camel_45738": 0.6503887176513672, "aqua_rat_57943": 0.6506873965263367, "gsm_rft_22073": 0.6507277488708496, "gsm_train_14713": 0.6507900953292847, "gsm_rft_27770": 0.6508407592773438, "TheoremQA_xueguangma/put_call_parity_1.json": 0.6509366035461426, "gsm_rft_23795": 0.6509799361228943, "aqua_rat_72737": 0.6510090827941895, "aqua_rat_66026": 0.6510134935379028, "aqua_rat_75598": 0.6511366963386536, "gsm_rft_31378": 0.6512030959129333, "gsm_rft_30093": 0.6512613296508789, "gsm_rft_1668": 0.6513684391975403, "gsm_train_16212": 0.6513684391975403, "gsm_rft_32019": 0.6515178680419922, "aqua_rat_22679": 0.6517802476882935, "aqua_rat_85795": 0.6518281102180481, "gsm_rft_8880": 0.6521572470664978, "aqua_rat_20758": 0.6521653532981873, "aqua_rat_30995": 0.6531335711479187, "aqua_rat_62242": 0.6532478332519531, "gsm_rft_27170": 0.653387188911438, "gsm_train_1402": 0.653387188911438, "gsm_rft_5694": 0.653387188911438, "aqua_rat_80078": 0.6534282565116882, "aqua_rat_13817": 0.653547465801239, "aqua_rat_80953": 0.6541687846183777, "gsm_rft_17816": 0.6542840003967285, "aqua_rat_33294": 0.6543904542922974, "gsm_rft_8605": 0.6547571420669556, "math_test_algebra_1043": 0.6547773480415344, "gsm_train_374": 0.6548836827278137, "gsm_rft_20347": 0.6548836827278137, "gsm_train_18514": 0.6550480723381042, "aqua_rat_12799": 0.655327320098877, "gsm_rft_11850": 0.6554489135742188, "aqua_rat_27053": 0.6556177735328674, "gsm_rft_27287": 0.6557166576385498, "math_train_algebra_940": 0.6557469964027405, "aqua_rat_42852": 0.6557694673538208, "aqua_rat_14728": 0.6561200618743896, "aqua_rat_10007": 0.6570150256156921, "aqua_rat_8596": 0.657170832157135, "TheoremQA_xueguangma/present_value_1.json": 0.6572589874267578, "aqua_rat_8292": 0.6572868227958679, "aqua_rat_47176": 0.6578850746154785, "aqua_rat_52070": 0.658150315284729, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.6582212448120117, "aqua_rat_52474": 0.6582871079444885, "aqua_rat_56727": 0.6585351228713989, "aqua_rat_86432": 0.6586496233940125, "aqua_rat_45867": 0.6586920022964478, "aqua_rat_24626": 0.6587802171707153, "gsm_rft_24497": 0.6588811874389648, "aqua_rat_78349": 0.6589460968971252, "aqua_rat_73772": 0.6589550375938416, "aqua_rat_69526": 0.6593431234359741, "aqua_rat_27035": 0.659430980682373, "aqua_rat_3536": 0.6597608327865601, "aqua_rat_88687": 0.6598309874534607, "aqua_rat_57386": 0.6598533391952515, "aqua_rat_76890": 0.6598953604698181, "aqua_rat_6973": 0.6601042151451111, "aqua_rat_46315": 0.6604830622673035, "gsm_rft_24082": 0.6605075001716614, "aqua_rat_63477": 0.6605444550514221, "aqua_rat_79979": 0.6611140370368958, "gsm_rft_3720": 0.6612730622291565, "aqua_rat_54264": 0.6613655090332031, "aqua_rat_26339": 0.6620293855667114, "gsm_rft_32408": 0.6621308326721191, "aqua_rat_77486": 0.6632056832313538, "aqua_rat_44615": 0.6632391810417175, "aqua_rat_2713": 0.6636910438537598, "aqua_rat_7378": 0.6638641357421875, "aqua_rat_81348": 0.6638674736022949, "aqua_rat_10227": 0.6640902757644653, "aqua_rat_24347": 0.6648845076560974, "aqua_rat_69201": 0.6652649641036987, "aqua_rat_37337": 0.6655586361885071, "gsm_rft_26543": 0.6670753359794617, "aqua_rat_18969": 0.6672573685646057, "aqua_rat_74699": 0.6675522923469543, "aqua_rat_75134": 0.6686139702796936, "aqua_rat_59668": 0.6692348718643188, "aqua_rat_53421": 0.6692460775375366, "aqua_rat_67841": 0.6693583726882935, "aqua_rat_46623": 0.6693683862686157, "aqua_rat_64527": 0.669447124004364, "TheoremQA_xueguangma/forward_price_2.json": 0.669674277305603, "aqua_rat_72933": 0.6697012782096863, "aqua_rat_73532": 0.6705097556114197, "aqua_rat_45726": 0.670560896396637, "TheoremQA_xueguangma/spot_rate.json": 0.6706645488739014, "aqua_rat_83234": 0.6706970930099487, "aqua_rat_69571": 0.6709414124488831, "aqua_rat_76879": 0.6711826920509338, "aqua_rat_88960": 0.6712713241577148, "aqua_rat_69591": 0.6717170476913452, "aqua_rat_70856": 0.6721903085708618, "aqua_rat_37382": 0.6722145080566406, "aqua_rat_46607": 0.6722540259361267, "aqua_rat_3008": 0.6724333167076111, "aqua_rat_64664": 0.6729035377502441, "aqua_rat_63332": 0.672980785369873, "aqua_rat_27039": 0.6732394099235535, "aqua_rat_83774": 0.6733670234680176, "math_test_algebra_1611": 0.6735592484474182, "aqua_rat_56240": 0.6736432909965515, "aqua_rat_71897": 0.6745219826698303, "aqua_rat_28801": 0.6747559905052185, "aqua_rat_36204": 0.6748456954956055, "aqua_rat_59171": 0.6748599410057068, "aqua_rat_16849": 0.6751533150672913, "aqua_rat_67497": 0.6753367185592651, "aqua_rat_80382": 0.675682544708252, "aqua_rat_59298": 0.6768516302108765, "aqua_rat_20382": 0.6770683526992798, "aqua_rat_12664": 0.6773601174354553, "aqua_rat_15639": 0.6778757572174072, "aqua_rat_255": 0.6785694360733032, "aqua_rat_40840": 0.678641140460968, "aqua_rat_26820": 0.6792567372322083, "aqua_rat_87246": 0.6805823445320129, "aqua_rat_63119": 0.6806411743164062, "aqua_rat_55929": 0.6811867952346802, "aqua_rat_66298": 0.6842610239982605, "aqua_rat_19454": 0.6851304769515991, "aqua_rat_67283": 0.6854144930839539, "aqua_rat_87884": 0.6900919675827026, "aqua_rat_49749": 0.6902847290039062, "aqua_rat_79547": 0.6921244859695435, "aqua_rat_9965": 0.6922005414962769, "aqua_rat_70690": 0.6925341486930847, "aqua_rat_64914": 0.6932534575462341, "aqua_rat_33283": 0.7049959301948547, "aqua_rat_89004": 0.707672119140625, "TheoremQA_xueguangma/dividend_discount_model_1.json": 0.7356805205345154, "TheoremQA_xueguangma/dividend_discount_model_5.json": 0.7586950659751892, "TheoremQA_xueguangma/dividend_discount_model_2.json": 0.7596220374107361}, "TheoremQA_maxku/signalprocessing9-signalrep.json": {"camel_5246": 0.7548330426216125, "camel_5314": 0.7548702359199524, "camel_45748": 0.7553225159645081, "camel_44824": 0.7553606033325195, "camel_5170": 0.7554400563240051, "camel_45998": 0.7559133768081665, "camel_44530": 0.7559846639633179, "camel_5265": 0.7560805678367615, "camel_5264": 0.7562143206596375, "camel_44551": 0.7565221190452576, "camel_45670": 0.7566993236541748, "camel_45784": 0.7568648457527161, "camel_44475": 0.756973385810852, "camel_45763": 0.7572149634361267, "camel_5148": 0.7573535442352295, "camel_5213": 0.757379949092865, "camel_5128": 0.7574371695518494, "camel_5245": 0.7574653625488281, "camel_45693": 0.7575253844261169, "camel_44488": 0.7577120065689087, "camel_44484": 0.7579407691955566, "camel_5271": 0.7580322623252869, "camel_5203": 0.7583936452865601, "camel_29863": 0.758412778377533, "camel_45990": 0.7585681080818176, "camel_5192": 0.7588068842887878, "TheoremQA_maxku/signalprocessing10-nyquist.json": 0.7588202357292175, "camel_5252": 0.7592948079109192, "camel_45199": 0.7593300342559814, "camel_5198": 0.7593532204627991, "camel_5212": 0.7594580054283142, "camel_45799": 0.7596443295478821, "camel_5237": 0.7600579261779785, "camel_45142": 0.760139524936676, "camel_16256": 0.7602005004882812, "camel_29961": 0.7602525353431702, "camel_5165": 0.7602925300598145, "camel_44411": 0.7603186368942261, "camel_45810": 0.7606551647186279, "camel_5223": 0.7607206702232361, "camel_44838": 0.7610852122306824, "camel_29938": 0.7611574530601501, "camel_45689": 0.761318564414978, "camel_5235": 0.7614724040031433, "camel_45179": 0.7615066170692444, "camel_45923": 0.761584460735321, "camel_5069": 0.7618066072463989, "camel_45123": 0.7619921565055847, "camel_45385": 0.7620391845703125, "camel_5120": 0.7621470093727112, "camel_5275": 0.7625584602355957, "camel_5169": 0.7626034617424011, "camel_29988": 0.7626152038574219, "camel_45720": 0.762755274772644, "camel_44487": 0.762905478477478, "camel_45196": 0.7631998658180237, "camel_5106": 0.7632341384887695, "camel_5218": 0.7633578181266785, "camel_5222": 0.7637083530426025, "camel_5157": 0.7640529274940491, "camel_44426": 0.7641456127166748, "camel_45928": 0.7646892666816711, "TheoremQA_maxku/signalprocessing12-nyquist.json": 0.7647013664245605, "camel_44864": 0.7648554444313049, "camel_5121": 0.7652679085731506, "camel_44532": 0.7655008435249329, "camel_45725": 0.7655019760131836, "camel_5184": 0.7656132578849792, "camel_44621": 0.7657164335250854, "camel_44861": 0.7660187482833862, "camel_45744": 0.766538679599762, "camel_29948": 0.7666199207305908, "camel_5208": 0.767106294631958, "camel_45129": 0.7676147222518921, "camel_45754": 0.7678049802780151, "camel_44550": 0.7682662010192871, "camel_45198": 0.7688463926315308, "camel_5177": 0.7688747048377991, "camel_5228": 0.7690883874893188, "camel_5154": 0.7691214680671692, "camel_45676": 0.7692103385925293, "camel_45182": 0.769474446773529, "camel_16305": 0.770071268081665, "camel_45699": 0.7701002359390259, "camel_44462": 0.7702088952064514, "camel_45776": 0.7706577181816101, "camel_5272": 0.7707626223564148, "camel_29928": 0.7713577151298523, "camel_5152": 0.771380603313446, "camel_44471": 0.7718710899353027, "camel_44542": 0.7719571590423584, "camel_44400": 0.7720032930374146, "camel_44490": 0.7720388174057007, "camel_5164": 0.7721197009086609, "camel_5270": 0.772191047668457, "camel_45357": 0.7722014784812927, "camel_44448": 0.7723152041435242, "camel_5126": 0.7728381752967834, "camel_45680": 0.7731154561042786, "camel_45931": 0.7733392715454102, "camel_44516": 0.7734195590019226, "camel_5124": 0.7740789651870728, "camel_44486": 0.7743726968765259, "camel_5176": 0.7745344638824463, "camel_29973": 0.7747498750686646, "camel_44538": 0.774824857711792, "camel_45788": 0.7748856544494629, "camel_45789": 0.7751924395561218, "camel_45764": 0.7752506732940674, "camel_5133": 0.7753180861473083, "camel_5191": 0.7754881381988525, "camel_5173": 0.7759531140327454, "camel_45766": 0.7761489152908325, "camel_45288": 0.7769784927368164, "camel_45162": 0.7776930332183838, "camel_5215": 0.7783601880073547, "camel_45134": 0.7789613604545593, "camel_45379": 0.7791765928268433, "camel_45713": 0.7802557945251465, "camel_44517": 0.7803592681884766, "camel_43783": 0.7808055281639099, "camel_5187": 0.7813755869865417, "camel_44802": 0.7813894748687744, "camel_44533": 0.7821273803710938, "camel_44416": 0.7829631567001343, "camel_5147": 0.7830660939216614, "camel_45709": 0.7830790281295776, "camel_45839": 0.7832876443862915, "camel_29945": 0.7835057973861694, "camel_44544": 0.7838501334190369, "camel_45334": 0.7851588726043701, "camel_44554": 0.7855054140090942, "camel_44870": 0.7871288657188416, "camel_44849": 0.7881045341491699, "camel_44466": 0.7881072759628296, "camel_44531": 0.7894057035446167, "camel_44498": 0.7897153496742249, "camel_5153": 0.790120005607605, "camel_45400": 0.7905632257461548, "camel_44523": 0.7910764217376709, "camel_45790": 0.7916274070739746, "camel_44546": 0.7916293144226074, "camel_45796": 0.7922887206077576, "camel_45759": 0.793389081954956, "camel_45607": 0.7934339046478271, "camel_44512": 0.7938674688339233, "camel_44555": 0.794258177280426, "camel_44851": 0.7942672371864319, "camel_44526": 0.7947257161140442, "camel_45806": 0.7958828210830688, "camel_45815": 0.7961083650588989, "camel_44534": 0.7963223457336426, "camel_45155": 0.7963688373565674, "camel_45803": 0.7968153357505798, "camel_44839": 0.7973058223724365, "camel_45966": 0.7973438501358032, "camel_45996": 0.7974119186401367, "camel_45173": 0.797619640827179, "camel_44506": 0.797622799873352, "camel_45781": 0.7976673245429993, "camel_45792": 0.7979670763015747, "camel_44473": 0.7982068657875061, "camel_45988": 0.7983484268188477, "camel_44510": 0.7994780540466309, "camel_45729": 0.7995806336402893, "camel_45314": 0.8000839352607727, "camel_45615": 0.8001330494880676, "camel_45811": 0.8020002841949463, "camel_44865": 0.8028707504272461, "camel_44828": 0.8033737540245056, "camel_45791": 0.803557276725769, "camel_45166": 0.8039544820785522, "camel_44852": 0.8049633502960205, "camel_45782": 0.8057971000671387, "camel_45320": 0.8071966171264648, "camel_45130": 0.8072085976600647, "camel_45717": 0.8075085878372192, "camel_45700": 0.8076871633529663, "camel_45798": 0.8082929849624634, "camel_45308": 0.8090154528617859, "camel_44848": 0.8095448613166809, "camel_45171": 0.8102291226387024, "camel_44825": 0.8103805184364319, "camel_44504": 0.810541033744812, "camel_44420": 0.810600757598877, "camel_45743": 0.8113117814064026, "camel_45492": 0.8125351667404175, "camel_45821": 0.8131821155548096, "camel_44421": 0.8144344091415405, "camel_45176": 0.8160195350646973, "camel_45685": 0.8163305521011353, "camel_45765": 0.8178925514221191, "camel_44826": 0.8181020021438599, "camel_45681": 0.8198667764663696, "camel_45184": 0.8220797181129456, "camel_44818": 0.8239463567733765, "camel_45745": 0.8248580098152161, "camel_45146": 0.826171875, "camel_45137": 0.8264786005020142, "camel_44820": 0.8347636461257935}, "TheoremQA_jianyu_xu/Multinomial_1.json": {"camel_20310": 0, "camel_21808": 0, "camel_20853": 0, "camel_20844": 0, "camel_20304": 0, "camel_21761": 0, "camel_20856": 0, "camel_21405": 0, "camel_21360": 0, "camel_21110": 0, "camel_20812": 0, "camel_20609": 0, "camel_20867": 0, "camel_20818": 0, "camel_21219": 0, "camel_20698": 0, "camel_21567": 0, "camel_20598": 0, "camel_20248": 0, "camel_20823": 0, "camel_20930": 0, "camel_20301": 0, "camel_21400": 0, "camel_21386": 0, "camel_20309": 0, "camel_20272": 0, "camel_20414": 0, "camel_20849": 0, "camel_20302": 0, "camel_20863": 0, "camel_20312": 0, "camel_20499": 0, "camel_20578": 0, "camel_20602": 0, "camel_21253": 0, "camel_20256": 0, "camel_20583": 0, "camel_20577": 0, "camel_20611": 0, "camel_20570": 0, "camel_20514": 0, "camel_20262": 0, "camel_21215": 0, "camel_21261": 0, "camel_20571": 0, "camel_20623": 0, "camel_21379": 0, "camel_20656": 0, "camel_20813": 0, "camel_20805": 0, "camel_20946": 0, "camel_21050": 0, "camel_21039": 0, "camel_20637": 0, "camel_20802": 0, "camel_21202": 0, "math_test_counting_and_probability_216": 0.766394853591919, "aqua_rat_86831": 0.7664144039154053, "aqua_rat_77678": 0.7664394974708557, "aqua_rat_34762": 0.7665355801582336, "aqua_rat_49410": 0.7666436433792114, "aqua_rat_72708": 0.7666882872581482, "math_test_counting_and_probability_666": 0.7667106986045837, "aqua_rat_72660": 0.7667176723480225, "aqua_rat_24963": 0.7670344114303589, "aqua_rat_75188": 0.7670788764953613, "aqua_rat_34318": 0.7671166062355042, "aqua_rat_61965": 0.7674210667610168, "aqua_rat_5455": 0.7674906253814697, "aqua_rat_43584": 0.7675323486328125, "aqua_rat_84398": 0.7675594091415405, "aqua_rat_8627": 0.7676617503166199, "aqua_rat_84364": 0.7678502798080444, "math_train_counting_and_probability_445": 0.7679479718208313, "aqua_rat_33533": 0.7680196166038513, "aqua_rat_80108": 0.7680546045303345, "math_test_counting_and_probability_442": 0.7680920362472534, "aqua_rat_87252": 0.7681342959403992, "aqua_rat_84826": 0.7683092951774597, "aqua_rat_40683": 0.7683414816856384, "aqua_rat_43336": 0.7683663368225098, "aqua_rat_3279": 0.7683929204940796, "aqua_rat_25991": 0.7685157060623169, "aqua_rat_42412": 0.7687275409698486, "aqua_rat_21789": 0.7687373161315918, "aqua_rat_44716": 0.7687616348266602, "math_train_counting_and_probability_249": 0.7688882946968079, "aqua_rat_74248": 0.7690001130104065, "aqua_rat_25783": 0.7690239548683167, "aqua_rat_12795": 0.7691795825958252, "aqua_rat_74651": 0.769199550151825, "aqua_rat_13918": 0.7695260047912598, "aqua_rat_53622": 0.7695571780204773, "aqua_rat_44130": 0.7695990204811096, "aqua_rat_77406": 0.7696480751037598, "math_train_prealgebra_115": 0.7700203061103821, "aqua_rat_53707": 0.7700673937797546, "aqua_rat_53149": 0.7700928449630737, "aqua_rat_39115": 0.7701547741889954, "aqua_rat_73040": 0.7702168822288513, "aqua_rat_22531": 0.7706922888755798, "aqua_rat_21240": 0.7707116603851318, "math_test_counting_and_probability_935": 0.7709243297576904, "aqua_rat_8728": 0.7709720134735107, "aqua_rat_44268": 0.7710179090499878, "aqua_rat_89302": 0.7713207602500916, "aqua_rat_62995": 0.7714576721191406, "aqua_rat_65310": 0.7716196179389954, "aqua_rat_29513": 0.7716873288154602, "aqua_rat_32489": 0.7717332243919373, "aqua_rat_16780": 0.7719256281852722, "camel_38534": 0.7720107436180115, "aqua_rat_78656": 0.7721055746078491, "aqua_rat_19931": 0.7721220254898071, "aqua_rat_36385": 0.7724193930625916, "aqua_rat_29008": 0.7725400924682617, "aqua_rat_9231": 0.7725412845611572, "aqua_rat_77478": 0.7725500464439392, "aqua_rat_45483": 0.7727015018463135, "aqua_rat_77972": 0.7728321552276611, "aqua_rat_83158": 0.7728495001792908, "aqua_rat_74970": 0.7728554606437683, "aqua_rat_29319": 0.7731068134307861, "aqua_rat_27914": 0.7734075784683228, "aqua_rat_51384": 0.7734286785125732, "aqua_rat_35517": 0.7737085223197937, "aqua_rat_48430": 0.7737541794776917, "aqua_rat_82109": 0.7739489078521729, "aqua_rat_18129": 0.7739907503128052, "aqua_rat_87094": 0.7744101881980896, "aqua_rat_61326": 0.7744511365890503, "aqua_rat_69861": 0.7746856212615967, "aqua_rat_35395": 0.7747042179107666, "aqua_rat_37223": 0.7748648524284363, "aqua_rat_16320": 0.7756468057632446, "aqua_rat_22648": 0.7756813764572144, "aqua_rat_58193": 0.7758724093437195, "aqua_rat_42460": 0.7764921188354492, "aqua_rat_324": 0.7768015265464783, "aqua_rat_72582": 0.7769032716751099, "aqua_rat_19830": 0.7770310044288635, "aqua_rat_67159": 0.7772387862205505, "aqua_rat_44837": 0.7775753140449524, "aqua_rat_77698": 0.7775906920433044, "aqua_rat_87992": 0.7777703404426575, "math_train_counting_and_probability_961": 0.7790689468383789, "aqua_rat_15917": 0.7791363000869751, "aqua_rat_57985": 0.7806780338287354, "aqua_rat_22507": 0.7808667421340942, "camel_38493": 0.7811729311943054, "aqua_rat_83784": 0.7818996906280518, "aqua_rat_51723": 0.7819457650184631, "aqua_rat_62261": 0.7823299765586853, "aqua_rat_62699": 0.7825355529785156, "math_train_counting_and_probability_651": 0.7832396626472473, "aqua_rat_76714": 0.7833635210990906, "aqua_rat_23041": 0.7836249470710754, "math_train_counting_and_probability_617": 0.7837289571762085, "aqua_rat_34205": 0.7839343547821045, "aqua_rat_10102": 0.7848320603370667, "aqua_rat_39610": 0.7848337888717651, "aqua_rat_84159": 0.7858996391296387, "camel_38505": 0.7862967848777771, "aqua_rat_6365": 0.7866261005401611, "aqua_rat_32732": 0.7866690158843994, "aqua_rat_7248": 0.7873081564903259, "aqua_rat_11273": 0.7873216867446899, "aqua_rat_41861": 0.7882354259490967, "aqua_rat_62903": 0.7886785864830017, "aqua_rat_56015": 0.789650559425354, "aqua_rat_66841": 0.7899092435836792, "aqua_rat_60238": 0.7907831072807312, "aqua_rat_19436": 0.7915852665901184, "aqua_rat_21868": 0.7918983101844788, "aqua_rat_66118": 0.7924043536186218, "aqua_rat_54461": 0.7949775457382202, "aqua_rat_13369": 0.7989210486412048, "aqua_rat_2658": 0.8000890612602234, "aqua_rat_13585": 0.8006321787834167, "aqua_rat_70446": 0.8010880351066589, "aqua_rat_2480": 0.8018561005592346, "math_train_counting_and_probability_696": 0.8020194172859192, "aqua_rat_58757": 0.8022875785827637, "aqua_rat_50641": 0.803055465221405, "math_test_counting_and_probability_79": 0.8039684891700745, "aqua_rat_74550": 0.805422306060791, "aqua_rat_73402": 0.8057076334953308, "aqua_rat_18404": 0.8059260845184326, "aqua_rat_4294": 0.8071776628494263, "aqua_rat_575": 0.8079684972763062, "aqua_rat_18901": 0.8097026944160461, "aqua_rat_40108": 0.8100857138633728, "aqua_rat_60936": 0.810215175151825, "aqua_rat_61885": 0.8108047842979431, "aqua_rat_89113": 0.8141818046569824, "aqua_rat_73122": 0.8159107565879822, "aqua_rat_34678": 0.8161116242408752, "aqua_rat_16877": 0.8173088431358337, "aqua_rat_29651": 0.820708692073822, "aqua_rat_37185": 0.8265998959541321}, "TheoremQA_jianyu_xu/Cayley_3.json": {"camel_23129": 0, "camel_22426": 0, "camel_22379": 0, "camel_22433": 0, "camel_23932": 0, "camel_22887": 0, "camel_22378": 0, "camel_22421": 0, "camel_23427": 0, "camel_23986": 0, "camel_22430": 0, "camel_22469": 0, "camel_23342": 0, "camel_23190": 0, "camel_23148": 0, "camel_21084": 0, "camel_22807": 0, "camel_23999": 0, "camel_23968": 0, "camel_22419": 0, "camel_23183": 0, "camel_22573": 0, "camel_23404": 0, "camel_22471": 0, "camel_22478": 0, "camel_21044": 0, "camel_22413": 0, "camel_21817": 0, "camel_23971": 0, "camel_22417": 0, "camel_21091": 0, "camel_23394": 0, "camel_22373": 0, "camel_23941": 0, "camel_22575": 0, "camel_23136": 0, "camel_22912": 0, "camel_22462": 0, "camel_22405": 0, "camel_22451": 0, "camel_23168": 0, "camel_22439": 0, "camel_22477": 0, "camel_23199": 0, "camel_21063": 0, "camel_22415": 0, "camel_22434": 0, "camel_22472": 0, "camel_22452": 0, "camel_22401": 0, "camel_22386": 0, "camel_22448": 0, "camel_23170": 0, "camel_22442": 0, "camel_22338": 0, "camel_22425": 0, "camel_22352": 0, "camel_22400": 0, "camel_22333": 0, "camel_22328": 0, "camel_23125": 0, "camel_23157": 0, "camel_22476": 0, "camel_22466": 0, "camel_22843": 0, "camel_22902": 0, "camel_22418": 0, "camel_21064": 0, "camel_22456": 0, "camel_23386": 0, "camel_22447": 0, "camel_23988": 0, "camel_22437": 0, "camel_23975": 0, "camel_23951": 0, "camel_22450": 0, "camel_23965": 0, "camel_22441": 0, "camel_23378": 0, "camel_22393": 0, "camel_23175": 0, "camel_23364": 0, "camel_23137": 0, "camel_23187": 0, "camel_23145": 0, "camel_22458": 0, "camel_23162": 0, "camel_23147": 0, "camel_23195": 0, "camel_21100": 0, "camel_23166": 0, "camel_23191": 0, "camel_23193": 0, "camel_22454": 0, "camel_23165": 0, "camel_23124": 0, "camel_23167": 0, "camel_22444": 0, "camel_23154": 0, "camel_22863": 0, "camel_23141": 0, "camel_23393": 0, "camel_22407": 0, "camel_23188": 0, "camel_23363": 0, "camel_23423": 0, "camel_21083": 0, "camel_23150": 0, "camel_22443": 0, "camel_23372": 0, "camel_23180": 0, "camel_23132": 0, "camel_23237": 0, "camel_23198": 0, "camel_21072": 0, "camel_22838": 0, "camel_22937": 0, "camel_21107": 0, "camel_22464": 0, "camel_22445": 0, "camel_23431": 0, "camel_23181": 0, "camel_22823": 0, "camel_23169": 0, "camel_22853": 0, "camel_22879": 0, "camel_23400": 0, "camel_22404": 0, "camel_22867": 0, "camel_23182": 0, "camel_22801": 0, "camel_23358": 0, "camel_22808": 0, "camel_22473": 0, "camel_23128": 0, "camel_22816": 0, "camel_23177": 0, "camel_22805": 0, "camel_23425": 0, "camel_22825": 0, "camel_23172": 0, "camel_22422": 0, "camel_22411": 0, "camel_23138": 0, "camel_23131": 0, "camel_23944": 0, "camel_22812": 0, "camel_22453": 0, "camel_23155": 0, "camel_23993": 0, "camel_23158": 0, "camel_23934": 0, "camel_23391": 0, "camel_22424": 0, "camel_22862": 0, "camel_22412": 0, "camel_22849": 0, "camel_22423": 0, "camel_23161": 0, "camel_23149": 0, "camel_23174": 0, "camel_21804": 0, "camel_23430": 0, "camel_22334": 0, "camel_21052": 0, "camel_23173": 0, "camel_23135": 0, "camel_23144": 0, "camel_23424": 0, "camel_23156": 0, "camel_23159": 0, "camel_23163": 0, "camel_23123": 0, "camel_23122": 0, "camel_22824": 0, "camel_21102": 0, "camel_21098": 0, "camel_21057": 0, "camel_23403": 0, "camel_23176": 0, "camel_21764": 0, "camel_21067": 0, "camel_23189": 0, "camel_23126": 0, "camel_22866": 0, "camel_23151": 0, "camel_23196": 0, "camel_23179": 0, "camel_23382": 0, "camel_23432": 0, "camel_23164": 0, "aqua_rat_36545": 0.7351373434066772, "aqua_rat_28685": 0.7358513474464417, "TheoremQA_xinyi/dag_3.json": 0.7433668375015259, "aqua_rat_44831": 0.7452412843704224, "aqua_rat_76009": 0.7500274181365967, "aqua_rat_70645": 0.7574474215507507, "aqua_rat_40504": 0.7880019545555115, "aqua_rat_25794": 0.7887302041053772, "camel_19957": 0.7969288229942322}, "TheoremQA_wenhuchen/infinite_series_sum3.json": {"aqua_rat_35123": 0.6767879128456116, "camel_31176": 0.6767908930778503, "aqua_rat_31829": 0.6768549084663391, "camel_31999": 0.6770484447479248, "camel_31256": 0.6770564317703247, "aqua_rat_15158": 0.6771507263183594, "camel_30763": 0.677159309387207, "camel_30749": 0.6773582696914673, "camel_42249": 0.6773890256881714, "camel_37809": 0.6775218844413757, "camel_42766": 0.6775374412536621, "camel_30834": 0.6775633096694946, "camel_31950": 0.6778261065483093, "gsm_rft_2696": 0.6778261661529541, "camel_20542": 0.6778755187988281, "camel_37785": 0.6779667735099792, "aqua_rat_53870": 0.6781079769134521, "camel_28502": 0.6781932711601257, "camel_30360": 0.6781972050666809, "camel_37812": 0.67826247215271, "camel_31654": 0.6783967018127441, "math_train_algebra_553": 0.6784182190895081, "camel_42794": 0.6784490942955017, "aqua_rat_344": 0.6787963509559631, "aqua_rat_54656": 0.6788614988327026, "aqua_rat_24127": 0.6788834929466248, "camel_31976": 0.679003119468689, "math_test_algebra_1428": 0.679153323173523, "camel_30346": 0.6791821122169495, "aqua_rat_61662": 0.679460346698761, "camel_31202": 0.6795538663864136, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus2.json": 0.6796939373016357, "aqua_rat_53042": 0.6798644065856934, "aqua_rat_5634": 0.6799373030662537, "aqua_rat_35341": 0.6800189018249512, "camel_42676": 0.6801973581314087, "camel_30959": 0.6802724599838257, "aqua_rat_33225": 0.6804932355880737, "aqua_rat_59654": 0.6805442571640015, "camel_20486": 0.6805689334869385, "aqua_rat_11917": 0.6806812882423401, "camel_31238": 0.6809103488922119, "camel_37825": 0.6809370517730713, "camel_42756": 0.6812984943389893, "camel_42063": 0.6813064813613892, "math_test_algebra_511": 0.6813185214996338, "camel_37766": 0.6814355850219727, "aqua_rat_27259": 0.68161940574646, "camel_37798": 0.681953489780426, "aqua_rat_42934": 0.6820922493934631, "aqua_rat_77963": 0.6821148991584778, "camel_30858": 0.6821478605270386, "camel_30726": 0.682148277759552, "aqua_rat_19560": 0.6826429963111877, "aqua_rat_8747": 0.68268883228302, "camel_31505": 0.6827199459075928, "camel_31228": 0.6829143762588501, "camel_42010": 0.6829246282577515, "aqua_rat_25659": 0.6829835176467896, "camel_30936": 0.6830127239227295, "camel_42776": 0.6830419301986694, "camel_28549": 0.6830658316612244, "aqua_rat_15035": 0.6831800937652588, "camel_30865": 0.6834192276000977, "camel_20541": 0.6834419965744019, "camel_42732": 0.6835986971855164, "camel_44106": 0.6836005449295044, "camel_49079": 0.6836423873901367, "camel_42711": 0.6839432716369629, "aqua_rat_34521": 0.6845812201499939, "camel_30385": 0.6847931742668152, "camel_30948": 0.6848189830780029, "aqua_rat_31662": 0.6849412322044373, "camel_30742": 0.6851586103439331, "math_train_algebra_1589": 0.6853306293487549, "aqua_rat_49434": 0.6853809952735901, "camel_31356": 0.6856540441513062, "aqua_rat_9677": 0.6859208345413208, "camel_31974": 0.6859861016273499, "camel_30843": 0.6860338449478149, "camel_37788": 0.6860659718513489, "camel_30327": 0.6863689422607422, "camel_31236": 0.6865456700325012, "aqua_rat_59396": 0.6867327690124512, "camel_42755": 0.6867998242378235, "camel_31987": 0.6870314478874207, "camel_31074": 0.6870449781417847, "aqua_rat_9734": 0.6872501969337463, "aqua_rat_87778": 0.6873306632041931, "camel_37883": 0.6879266500473022, "math_train_algebra_2479": 0.6879425048828125, "camel_30809": 0.6879464387893677, "camel_42045": 0.6883093118667603, "camel_37760": 0.688345730304718, "camel_31279": 0.688676118850708, "camel_30353": 0.6887863278388977, "camel_21967": 0.688887357711792, "camel_42753": 0.6889005303382874, "camel_30939": 0.689189076423645, "aqua_rat_87911": 0.6898378729820251, "aqua_rat_87890": 0.6908264756202698, "aqua_rat_55051": 0.6918928027153015, "camel_30754": 0.6919926404953003, "camel_30330": 0.6920117139816284, "camel_31444": 0.6922522783279419, "aqua_rat_1271": 0.6923346519470215, "camel_37768": 0.6926937103271484, "aqua_rat_11720": 0.6927063465118408, "math_train_algebra_886": 0.69280606508255, "camel_42778": 0.6932475566864014, "camel_30371": 0.6932662725448608, "camel_31901": 0.6935116052627563, "camel_31323": 0.6936101317405701, "camel_37767": 0.6936615705490112, "camel_30765": 0.6937806606292725, "camel_30889": 0.6941014528274536, "camel_37827": 0.6944288015365601, "aqua_rat_30821": 0.6945281028747559, "aqua_rat_50166": 0.694678544998169, "camel_44158": 0.6948469877243042, "camel_37819": 0.6948627233505249, "camel_42777": 0.6956946849822998, "aqua_rat_23208": 0.6960446834564209, "camel_42659": 0.696433424949646, "camel_31241": 0.6965866088867188, "camel_31881": 0.6971428990364075, "camel_31584": 0.6979877352714539, "aqua_rat_75812": 0.6985148191452026, "camel_31580": 0.6987062692642212, "camel_44100": 0.6987271904945374, "camel_42013": 0.6997042894363403, "camel_31884": 0.7000429034233093, "camel_37764": 0.7000781893730164, "camel_30740": 0.7003269791603088, "aqua_rat_53748": 0.7003546357154846, "camel_31947": 0.7003751397132874, "aqua_rat_73910": 0.7010476589202881, "aqua_rat_82861": 0.7014196515083313, "aqua_rat_32985": 0.7023495435714722, "camel_30813": 0.7028554677963257, "aqua_rat_67612": 0.7032728791236877, "math_test_algebra_2477": 0.7041370272636414, "camel_30339": 0.7043444514274597, "camel_44121": 0.7047215700149536, "aqua_rat_69628": 0.7047452330589294, "aqua_rat_16186": 0.7055648565292358, "camel_20481": 0.7058465480804443, "camel_31702": 0.7064613103866577, "aqua_rat_83193": 0.7068586945533752, "camel_49109": 0.7072155475616455, "camel_30770": 0.7077248096466064, "camel_30354": 0.7077449560165405, "camel_20527": 0.7086585760116577, "aqua_rat_13223": 0.7087165117263794, "camel_30357": 0.7089419960975647, "camel_30887": 0.7090235948562622, "TheoremQA_wenhuchen/infinite_series_sum2.json": 0.7095003724098206, "math_test_algebra_1184": 0.7097028493881226, "camel_30338": 0.7101346254348755, "aqua_rat_69318": 0.7101702690124512, "camel_31973": 0.7104383111000061, "camel_30342": 0.7108176350593567, "camel_31842": 0.7117635011672974, "camel_37619": 0.7122674584388733, "camel_31858": 0.712421178817749, "camel_30688": 0.7133334279060364, "camel_42672": 0.7134889364242554, "camel_31089": 0.7139347195625305, "aqua_rat_36268": 0.7152606844902039, "camel_31452": 0.7154192328453064, "aqua_rat_48885": 0.7182751297950745, "camel_30409": 0.7192356586456299, "camel_42668": 0.72022545337677, "camel_42678": 0.7202434539794922, "camel_31863": 0.7208841443061829, "camel_30093": 0.7214670181274414, "camel_30341": 0.7218968868255615, "camel_31915": 0.7225654125213623, "camel_30345": 0.7228453159332275, "camel_30383": 0.7238523364067078, "camel_30392": 0.7258103489875793, "camel_31880": 0.7271944284439087, "aqua_rat_52544": 0.7288102507591248, "camel_30797": 0.7299780249595642, "camel_30759": 0.7305619120597839, "camel_30202": 0.7313538789749146, "camel_30440": 0.7320714592933655, "camel_30685": 0.7380068898200989, "camel_31056": 0.739310085773468, "camel_30372": 0.7403413653373718, "camel_31869": 0.7411259412765503, "camel_31984": 0.7414511442184448, "camel_30374": 0.7421292066574097, "camel_49051": 0.7439298033714294, "camel_30680": 0.7470645904541016, "camel_28309": 0.7525850534439087, "camel_31759": 0.7533644437789917, "camel_31057": 0.7626705765724182, "camel_31084": 0.76577228307724, "camel_31061": 0.7705066800117493}, "TheoremQA_maxku/cv-colorsci3-rgb.json": {"TheoremQA_maxku/cv-colorsci3-rgb.json": 0, "gsm_rft_9540": 0.6551975607872009, "gsm_train_12277": 0.6552148461341858, "gsm_rft_11304": 0.6552460193634033, "gsm_train_6230": 0.6552460193634033, "aqua_rat_52795": 0.6553568840026855, "aqua_rat_873": 0.6555315852165222, "gsm_rft_30981": 0.6555386185646057, "gsm_rft_23571": 0.6555638313293457, "gsm_train_18529": 0.6556404829025269, "aqua_rat_14977": 0.6558006405830383, "gsm_rft_31633": 0.6558691263198853, "gsm_rft_22436": 0.6560221314430237, "gsm_rft_34758": 0.6560525894165039, "gsm_rft_27313": 0.6561232209205627, "gsm_rft_18902": 0.656331479549408, "gsm_rft_31285": 0.6563355326652527, "gsm_train_26494": 0.6563355326652527, "gsm_train_30429": 0.6563912034034729, "gsm_rft_34808": 0.656414806842804, "aqua_rat_84727": 0.6564444303512573, "aqua_rat_81319": 0.6564812064170837, "gsm_rft_26902": 0.6565025448799133, "gsm_rft_3157": 0.6565437316894531, "gsm_rft_16493": 0.656570553779602, "aqua_rat_31354": 0.6568737030029297, "gsm_rft_13651": 0.6568955183029175, "aqua_rat_48380": 0.6569048166275024, "gsm_rft_21832": 0.6569309234619141, "gsm_rft_24217": 0.6570113897323608, "aqua_rat_47102": 0.6570132970809937, "gsm_rft_21610": 0.6571366786956787, "gsm_rft_29493": 0.6572467684745789, "gsm_train_17368": 0.6574763655662537, "gsm_rft_14059": 0.6574926972389221, "gsm_train_7197": 0.6574926972389221, "gsm_rft_35126": 0.6575047373771667, "aqua_rat_9514": 0.6575267314910889, "gsm_rft_1777": 0.6575339436531067, "aqua_rat_85027": 0.657583475112915, "aqua_rat_67095": 0.6576720476150513, "aqua_rat_72504": 0.6577728390693665, "gsm_rft_11457": 0.6579076051712036, "gsm_rft_35627": 0.6579973697662354, "gsm_rft_6828": 0.658072292804718, "gsm_rft_20039": 0.6582819223403931, "gsm_rft_33841": 0.6582889556884766, "gsm_rft_30349": 0.6584134697914124, "aqua_rat_40691": 0.6585202813148499, "aqua_rat_60510": 0.6589503288269043, "gsm_train_24856": 0.6589804887771606, "gsm_rft_29435": 0.6590560674667358, "gsm_train_27431": 0.6590778827667236, "gsm_rft_7102": 0.6591079235076904, "gsm_train_9280": 0.6592903137207031, "gsm_rft_18784": 0.6593002676963806, "gsm_rft_11414": 0.6594001650810242, "gsm_rft_11927": 0.6594001650810242, "aqua_rat_24874": 0.6595278978347778, "gsm_rft_25645": 0.6597935557365417, "gsm_rft_2890": 0.6599038243293762, "gsm_train_188": 0.6599038243293762, "gsm_rft_28893": 0.6600713133811951, "gsm_rft_31983": 0.6601766347885132, "gsm_rft_12241": 0.6604582071304321, "aqua_rat_23401": 0.6604738235473633, "gsm_rft_1690": 0.6604933142662048, "gsm_rft_32921": 0.6607492566108704, "gsm_rft_32215": 0.6608097553253174, "aqua_rat_55715": 0.6609663367271423, "aqua_rat_63570": 0.6610080599784851, "gsm_rft_9461": 0.6610308289527893, "gsm_rft_3958": 0.6612029671669006, "gsm_rft_16916": 0.6614499092102051, "gsm_rft_27243": 0.6615306735038757, "gsm_rft_6321": 0.6618040800094604, "gsm_rft_493": 0.661970853805542, "gsm_rft_25491": 0.6619778871536255, "gsm_rft_5985": 0.6620826125144958, "aqua_rat_8304": 0.6621392965316772, "aqua_rat_84570": 0.6622187495231628, "gsm_rft_29535": 0.6622623205184937, "aqua_rat_35251": 0.6624231338500977, "aqua_rat_87418": 0.6629876494407654, "gsm_rft_3024": 0.6632838249206543, "aqua_rat_71134": 0.6632932424545288, "gsm_rft_11441": 0.6633254289627075, "aqua_rat_1658": 0.6637377738952637, "aqua_rat_50736": 0.6637749075889587, "gsm_rft_32201": 0.6639723181724548, "gsm_train_6055": 0.6639723181724548, "aqua_rat_81549": 0.6640335917472839, "gsm_rft_3146": 0.6640588045120239, "gsm_rft_15386": 0.6642209887504578, "gsm_train_24910": 0.6643396615982056, "gsm_rft_10212": 0.6643716096878052, "gsm_rft_31436": 0.6644390821456909, "aqua_rat_86352": 0.6648193001747131, "aqua_rat_5518": 0.6648381352424622, "gsm_rft_23405": 0.6653057336807251, "gsm_train_19996": 0.6653057336807251, "aqua_rat_32305": 0.665433943271637, "gsm_rft_2972": 0.665463387966156, "gsm_rft_31898": 0.6655459403991699, "aqua_rat_28516": 0.6658853888511658, "aqua_rat_26619": 0.6659448742866516, "gsm_rft_11875": 0.6660494208335876, "gsm_rft_869": 0.6661901473999023, "aqua_rat_5531": 0.6662349104881287, "gsm_rft_7520": 0.6662798523902893, "aqua_rat_76249": 0.6663228273391724, "gsm_rft_15413": 0.6663708686828613, "aqua_rat_22938": 0.6665887832641602, "gsm_rft_18673": 0.6666275858879089, "gsm_rft_14882": 0.6668878197669983, "aqua_rat_68587": 0.6670297384262085, "aqua_rat_46415": 0.6675354242324829, "aqua_rat_83058": 0.6678615808486938, "gsm_rft_24921": 0.6678656935691833, "aqua_rat_16002": 0.6679054498672485, "aqua_rat_26308": 0.6680123805999756, "gsm_rft_3218": 0.6682763695716858, "gsm_train_33000": 0.6683098673820496, "gsm_rft_35008": 0.6683235168457031, "aqua_rat_17748": 0.668547511100769, "aqua_rat_34033": 0.6694421172142029, "gsm_rft_3211": 0.6695045232772827, "gsm_train_9788": 0.6695045232772827, "aqua_rat_42415": 0.6697468757629395, "aqua_rat_56838": 0.6699391007423401, "gsm_train_35224": 0.6700453758239746, "gsm_rft_10958": 0.6702464818954468, "gsm_rft_13588": 0.6702723503112793, "gsm_rft_3058": 0.6703921556472778, "aqua_rat_80729": 0.6703953146934509, "gsm_rft_7108": 0.6704211831092834, "gsm_rft_17183": 0.6704505681991577, "aqua_rat_20998": 0.670947253704071, "gsm_rft_25755": 0.6709960699081421, "gsm_rft_3862": 0.6713565587997437, "aqua_rat_63278": 0.671589195728302, "aqua_rat_32944": 0.6716741919517517, "aqua_rat_68434": 0.6719321012496948, "gsm_rft_23876": 0.6721804738044739, "gsm_train_7153": 0.6723020672798157, "gsm_rft_20904": 0.6723020672798157, "aqua_rat_37735": 0.6723241806030273, "gsm_rft_27483": 0.6724976897239685, "aqua_rat_17167": 0.672583818435669, "aqua_rat_86544": 0.6726754307746887, "gsm_rft_10422": 0.6728330850601196, "gsm_rft_6315": 0.6730628609657288, "aqua_rat_53426": 0.6730868816375732, "aqua_rat_10379": 0.6731284856796265, "aqua_rat_72223": 0.6739195585250854, "aqua_rat_27052": 0.6741661429405212, "aqua_rat_8265": 0.6742718815803528, "aqua_rat_24962": 0.674460768699646, "aqua_rat_50381": 0.6744615435600281, "gsm_rft_3420": 0.6751207709312439, "aqua_rat_39370": 0.6753972768783569, "aqua_rat_87371": 0.6754193305969238, "aqua_rat_31699": 0.6758490800857544, "aqua_rat_27770": 0.6760154366493225, "aqua_rat_82211": 0.6761345863342285, "aqua_rat_85147": 0.6766887903213501, "aqua_rat_78694": 0.6770356297492981, "aqua_rat_80060": 0.6773731112480164, "aqua_rat_85460": 0.6777104139328003, "aqua_rat_18455": 0.6778979301452637, "aqua_rat_73623": 0.6786975860595703, "aqua_rat_50616": 0.6788851022720337, "aqua_rat_21052": 0.6790856122970581, "gsm_train_18947": 0.679387092590332, "gsm_rft_29861": 0.679479718208313, "aqua_rat_80601": 0.6796509027481079, "gsm_rft_32041": 0.679785430431366, "aqua_rat_81163": 0.6839921474456787, "aqua_rat_35390": 0.6849064230918884, "TheoremQA_maxku/cv-colorsci4-hsi.json": 0.6859340667724609, "gsm_rft_27135": 0.6865013241767883, "gsm_train_32836": 0.686502993106842, "gsm_rft_35232": 0.6865792870521545, "aqua_rat_63612": 0.6866111159324646, "gsm_rft_16988": 0.6867687702178955, "aqua_rat_22474": 0.6887571215629578, "gsm_rft_10427": 0.6896686553955078, "aqua_rat_46648": 0.6919553875923157, "aqua_rat_2003": 0.6932979226112366, "aqua_rat_84280": 0.6945921182632446, "aqua_rat_4046": 0.6989778280258179, "aqua_rat_47454": 0.699195921421051, "aqua_rat_5931": 0.7016401886940002, "aqua_rat_24892": 0.703197181224823, "aqua_rat_18162": 0.7343431115150452, "aqua_rat_54992": 0.7349518537521362, "aqua_rat_63536": 0.7355291843414307, "aqua_rat_10760": 0.7390257716178894, "aqua_rat_87245": 0.7392008304595947, "aqua_rat_47586": 0.7399151921272278}, "TheoremQA_wenhuchen/trapezoidal_rule3.json": {"camel_6244": 0, "camel_40263": 0, "camel_40241": 0, "camel_7340": 0, "camel_6295": 0, "camel_7824": 0, "camel_40292": 0, "camel_7359": 0, "camel_7285": 0, "camel_7309": 0, "camel_7054": 0, "camel_7108": 0, "camel_7119": 0, "camel_7346": 0, "camel_7317": 0, "camel_7792": 0, "camel_6308": 0, "camel_6257": 0, "camel_6317": 0, "camel_6291": 0, "camel_7051": 0, "camel_7088": 0, "camel_40274": 0, "camel_7814": 0, "camel_7114": 0, "camel_40280": 0, "camel_40261": 0, "camel_7839": 0, "camel_7061": 0, "camel_40293": 0, "camel_7106": 0, "camel_7784": 0, "camel_6256": 0, "camel_7789": 0, "camel_7555": 0, "camel_7065": 0, "camel_7330": 0, "camel_6283": 0, "camel_6251": 0, "camel_6316": 0, "camel_6296": 0, "camel_7057": 0, "camel_6255": 0, "camel_7058": 0, "camel_7075": 0, "camel_7078": 0, "camel_7838": 0, "camel_7104": 0, "camel_7797": 0, "camel_7761": 0, "camel_7760": 0, "camel_7334": 0, "camel_7040": 0, "camel_7802": 0, "camel_7082": 0, "camel_7304": 0, "camel_7115": 0, "camel_7776": 0, "camel_7780": 0, "camel_40313": 0, "camel_7763": 0, "camel_7823": 0, "camel_7092": 0, "camel_7099": 0, "camel_40249": 0, "camel_7064": 0, "camel_7048": 0, "camel_7818": 0, "camel_40268": 0, "camel_7773": 0, "camel_7292": 0, "camel_7101": 0, "camel_6240": 0, "camel_7068": 0, "camel_7105": 0, "camel_6260": 0, "camel_6249": 0, "camel_7041": 0, "camel_7100": 0, "camel_6254": 0, "camel_6290": 0, "camel_6253": 0, "camel_6272": 0, "camel_6270": 0, "camel_7117": 0, "camel_7779": 0, "camel_6299": 0, "camel_6292": 0, "camel_7096": 0, "camel_6305": 0, "camel_7093": 0, "camel_7071": 0, "camel_7112": 0, "camel_6266": 0, "camel_7834": 0, "camel_7830": 0, "camel_6247": 0, "camel_7769": 0, "camel_7821": 0, "camel_7803": 0, "camel_7781": 0, "camel_6252": 0, "camel_7731": 0, "camel_7796": 0, "camel_7042": 0, "camel_7831": 0, "camel_7060": 0, "camel_7772": 0, "camel_7110": 0, "camel_7808": 0, "camel_6312": 0, "camel_6307": 0, "camel_7063": 0, "camel_6275": 0, "camel_7052": 0, "camel_7768": 0, "camel_7083": 0, "camel_7793": 0, "camel_7102": 0, "camel_7835": 0, "camel_7820": 0, "camel_7800": 0, "camel_6294": 0, "camel_7804": 0, "camel_7762": 0, "camel_6286": 0, "camel_7811": 0, "camel_7822": 0, "TheoremQA_wenhuchen/trapezoidal_rule3.json": 0, "camel_7798": 0, "camel_7107": 0, "camel_7767": 0, "camel_7043": 0, "camel_6315": 0, "camel_7081": 0, "camel_7801": 0, "camel_7787": 0, "camel_7832": 0, "camel_7113": 0, "camel_7829": 0, "camel_6304": 0, "camel_7817": 0, "camel_7778": 0, "camel_6293": 0, "camel_7076": 0, "camel_7764": 0, "camel_6313": 0, "camel_7785": 0, "camel_6273": 0, "camel_7836": 0, "camel_7771": 0, "camel_7819": 0, "camel_6310": 0, "camel_7825": 0, "camel_7085": 0, "camel_7791": 0, "camel_6282": 0, "camel_7815": 0, "camel_7089": 0, "camel_7812": 0, "camel_7046": 0, "camel_6285": 0, "camel_7050": 0, "camel_7087": 0, "camel_6250": 0, "camel_6280": 0, "camel_6306": 0, "camel_7837": 0, "camel_6265": 0, "camel_6318": 0, "camel_6311": 0, "camel_7770": 0, "camel_7786": 0, "camel_7805": 0, "camel_6298": 0, "camel_7783": 0, "camel_7775": 0, "camel_6288": 0, "camel_6264": 0, "camel_7826": 0, "camel_6262": 0, "camel_6269": 0, "camel_6243": 0, "camel_6261": 0, "camel_6297": 0, "camel_6276": 0, "camel_6314": 0, "camel_7816": 0, "camel_6284": 0, "camel_6301": 0, "camel_6245": 0, "camel_6242": 0, "camel_6274": 0, "camel_6263": 0, "camel_6241": 0, "camel_6302": 0, "camel_45941": 0.7244172096252441, "camel_49657": 0.7248296141624451, "TheoremQA_wenhuchen/trapezoidal_rule2.json": 0.7366169691085815, "camel_19895": 0.7523661255836487}, "TheoremQA_elainewan/math_calculus_3_8.json": {"camel_6856": 0, "camel_6632": 0, "camel_6858": 0, "camel_6844": 0, "camel_6879": 0, "camel_6848": 0, "camel_6809": 0, "camel_6805": 0, "camel_6852": 0, "camel_6867": 0, "camel_6834": 0, "camel_6803": 0, "camel_6836": 0, "camel_7053": 0, "camel_6837": 0, "camel_6863": 0, "camel_6874": 0, "camel_6861": 0, "camel_6822": 0, "camel_7883": 0, "camel_6801": 0, "camel_6854": 0, "camel_6802": 0, "camel_6832": 0, "camel_6851": 0, "camel_6840": 0, "camel_6865": 0, "camel_6811": 0, "camel_6820": 0, "camel_6831": 0, "camel_6877": 0, "camel_6855": 0, "camel_6857": 0, "camel_6876": 0, "camel_6808": 0, "camel_6819": 0, "camel_6646": 0, "camel_6833": 0, "camel_6817": 0, "camel_6816": 0, "camel_6839": 0, "camel_6824": 0, "camel_6830": 0, "TheoremQA_elainewan/math_calculus_3_8.json": 0, "camel_5965": 0.7491369247436523, "math_test_geometry_888": 0.7493734955787659, "aqua_rat_38896": 0.7498151063919067, "camel_5177": 0.7500938773155212, "camel_19687": 0.750180184841156, "camel_5055": 0.7502104043960571, "math_test_geometry_903": 0.7504433989524841, "camel_5976": 0.7504534125328064, "camel_4194": 0.750636100769043, "aqua_rat_45660": 0.7507831454277039, "camel_5007": 0.7511759996414185, "camel_5571": 0.7512741088867188, "camel_4841": 0.7513836622238159, "aqua_rat_6676": 0.7521352171897888, "aqua_rat_17798": 0.7522338032722473, "camel_4196": 0.7523406744003296, "camel_5970": 0.7525826692581177, "camel_19693": 0.7526339292526245, "camel_5094": 0.7529985308647156, "camel_47373": 0.7530162334442139, "camel_5043": 0.7531055212020874, "camel_46156": 0.7532395720481873, "camel_4132": 0.7532563209533691, "aqua_rat_42233": 0.7536337375640869, "camel_5172": 0.7538815140724182, "camel_4828": 0.7538944482803345, "camel_5963": 0.7539383769035339, "camel_4854": 0.7540265321731567, "camel_4209": 0.7540371417999268, "camel_5999": 0.754094123840332, "camel_5041": 0.7545731067657471, "camel_4287": 0.7548379898071289, "camel_19726": 0.7550626397132874, "camel_4227": 0.7553268074989319, "camel_4238": 0.7556217908859253, "camel_42131": 0.7559164762496948, "camel_4190": 0.7559958696365356, "camel_4212": 0.7560495734214783, "camel_5958": 0.7562126517295837, "camel_4986": 0.7562423944473267, "camel_5849": 0.7565479874610901, "camel_5024": 0.7565982937812805, "camel_19680": 0.7573457360267639, "camel_5936": 0.757479727268219, "camel_4229": 0.7579094767570496, "camel_5946": 0.7582215070724487, "camel_5311": 0.7585261464118958, "math_train_geometry_6026": 0.7591480016708374, "camel_5935": 0.7594019770622253, "camel_5117": 0.7597267031669617, "camel_30260": 0.7598817944526672, "camel_4230": 0.7598931193351746, "camel_4182": 0.7599861025810242, "camel_5189": 0.7602647542953491, "camel_4169": 0.7602970600128174, "TheoremQA_xinyi/newtons_laws_1.json": 0.7604150176048279, "aqua_rat_74869": 0.7605008482933044, "camel_4180": 0.7610571384429932, "camel_5344": 0.7613230347633362, "camel_4177": 0.76134192943573, "camel_4219": 0.7614405751228333, "camel_46101": 0.7620159983634949, "math_test_geometry_1081": 0.7622660994529724, "camel_28254": 0.7625579237937927, "aqua_rat_75605": 0.7631791830062866, "camel_4216": 0.7636116147041321, "camel_4217": 0.7638497948646545, "camel_4171": 0.7638726234436035, "camel_5977": 0.7640763521194458, "camel_19727": 0.7643587589263916, "camel_5165": 0.7645071148872375, "camel_5105": 0.7650454640388489, "camel_4239": 0.7651137113571167, "camel_5982": 0.7652686834335327, "camel_5092": 0.7653353810310364, "camel_4188": 0.7653379440307617, "camel_4214": 0.7653570175170898, "camel_5948": 0.7655889987945557, "camel_4204": 0.7662915587425232, "camel_4181": 0.7664896845817566, "camel_4234": 0.7666469216346741, "camel_5974": 0.7668354511260986, "camel_5990": 0.7669935822486877, "camel_5997": 0.7670583724975586, "camel_4222": 0.7671747207641602, "camel_4218": 0.7671843767166138, "camel_4199": 0.767254650592804, "camel_5988": 0.7672585844993591, "camel_5928": 0.7672712802886963, "camel_5566": 0.7673183679580688, "camel_5070": 0.7676044702529907, "camel_4162": 0.7686041593551636, "camel_5845": 0.7687029838562012, "camel_5093": 0.7689705491065979, "camel_5840": 0.768989622592926, "camel_19711": 0.7692173719406128, "camel_5941": 0.769440233707428, "camel_5034": 0.7699738144874573, "camel_5883": 0.7702000737190247, "camel_4862": 0.7705450654029846, "camel_19718": 0.770635187625885, "math_train_geometry_6087": 0.7718967795372009, "camel_5980": 0.7719621062278748, "camel_5181": 0.7721853852272034, "camel_5971": 0.7724465727806091, "camel_4208": 0.7729297280311584, "camel_4232": 0.772970974445343, "camel_4176": 0.7735618352890015, "camel_5940": 0.7737004160881042, "camel_5886": 0.7742422819137573, "camel_47290": 0.7745102643966675, "math_train_geometry_6109": 0.7750789523124695, "camel_5922": 0.7751280665397644, "camel_19706": 0.7753281593322754, "camel_19733": 0.7754544615745544, "camel_5967": 0.7758303284645081, "camel_4170": 0.776652991771698, "camel_5079": 0.7769322395324707, "camel_5188": 0.7771245241165161, "camel_4097": 0.7777898907661438, "aqua_rat_46219": 0.7783728837966919, "camel_5035": 0.7787911891937256, "camel_4200": 0.7793662548065186, "camel_19721": 0.7807131409645081, "camel_19717": 0.7808531522750854, "camel_5853": 0.7811878323554993, "camel_47347": 0.7813210487365723, "camel_4168": 0.7816316485404968, "camel_5373": 0.7828449010848999, "camel_4184": 0.7832459211349487, "camel_4179": 0.7839263677597046, "camel_43823": 0.7840444445610046, "camel_5178": 0.785168468952179, "camel_5037": 0.785375714302063, "camel_4201": 0.7855768203735352, "camel_4211": 0.7898252606391907, "camel_5014": 0.790719747543335, "camel_4175": 0.7909300923347473, "camel_5436": 0.792620837688446, "camel_19715": 0.7932981252670288, "camel_5899": 0.7960160970687866, "camel_19754": 0.7964679002761841, "camel_5029": 0.7991169691085815, "camel_19750": 0.7995686531066895, "camel_4969": 0.8004248142242432, "camel_4972": 0.8006343841552734, "camel_5059": 0.8014070391654968, "camel_5004": 0.8043071627616882, "camel_5057": 0.8067839741706848, "camel_4987": 0.814549446105957, "camel_5358": 0.8157510161399841, "camel_4999": 0.8163512349128723, "camel_4994": 0.8175238370895386, "camel_5114": 0.817725419998169, "camel_4993": 0.8201456069946289, "camel_5011": 0.8248622417449951}, "TheoremQA_jianyu_xu/Binomial_5.json": {"camel_21528": 0, "camel_21572": 0, "camel_20996": 0, "camel_20336": 0, "camel_20309": 0, "camel_20256": 0, "camel_21227": 0, "camel_21253": 0, "camel_20931": 0, "camel_20378": 0, "camel_20364": 0, "camel_20946": 0, "camel_20611": 0, "camel_20293": 0, "camel_20598": 0, "camel_20512": 0, "camel_20930": 0, "camel_20272": 0, "camel_20312": 0, "camel_21405": 0, "camel_21039": 0, "camel_21202": 0, "camel_21386": 0, "camel_21215": 0, "aqua_rat_74695": 0.7938482165336609, "aqua_rat_34476": 0.793986976146698, "aqua_rat_18452": 0.7939977645874023, "aqua_rat_81548": 0.7940020561218262, "aqua_rat_30355": 0.7941767573356628, "aqua_rat_54446": 0.7943713665008545, "aqua_rat_21291": 0.7948724031448364, "aqua_rat_3841": 0.7950347661972046, "aqua_rat_31360": 0.795431911945343, "aqua_rat_74905": 0.7955370545387268, "aqua_rat_86831": 0.7955673336982727, "aqua_rat_40137": 0.7956299781799316, "math_test_counting_and_probability_1033": 0.7956706285476685, "aqua_rat_54461": 0.7956887483596802, "aqua_rat_16863": 0.7959672808647156, "aqua_rat_24963": 0.7961088418960571, "aqua_rat_4191": 0.7961921095848083, "math_test_counting_and_probability_535": 0.7962660789489746, "aqua_rat_25293": 0.7962723970413208, "math_train_counting_and_probability_949": 0.796369194984436, "aqua_rat_6961": 0.796417772769928, "aqua_rat_5316": 0.7964273691177368, "aqua_rat_29732": 0.7964993715286255, "aqua_rat_75780": 0.7966359853744507, "aqua_rat_78830": 0.7966437935829163, "aqua_rat_74248": 0.7968614101409912, "aqua_rat_72660": 0.7968763113021851, "aqua_rat_59675": 0.7969034314155579, "aqua_rat_40108": 0.7969670295715332, "aqua_rat_89302": 0.7970291376113892, "aqua_rat_41506": 0.7974032759666443, "aqua_rat_60522": 0.7974442839622498, "aqua_rat_31872": 0.7974560856819153, "aqua_rat_61885": 0.7976048588752747, "aqua_rat_69282": 0.7976669073104858, "aqua_rat_8218": 0.7976888418197632, "aqua_rat_71649": 0.7977051138877869, "math_test_counting_and_probability_513": 0.7977468371391296, "aqua_rat_37301": 0.7977784276008606, "math_test_counting_and_probability_666": 0.7978078126907349, "aqua_rat_66240": 0.7978976368904114, "aqua_rat_63254": 0.7979218363761902, "aqua_rat_39411": 0.7980642914772034, "aqua_rat_10235": 0.7981356978416443, "aqua_rat_84736": 0.7981815338134766, "aqua_rat_35292": 0.7982372641563416, "aqua_rat_38314": 0.7983514666557312, "aqua_rat_28183": 0.7988014221191406, "aqua_rat_38694": 0.7988321781158447, "aqua_rat_29563": 0.7988500595092773, "math_train_counting_and_probability_683": 0.7990878820419312, "aqua_rat_16877": 0.7994808554649353, "camel_38493": 0.7994852066040039, "aqua_rat_61903": 0.7997419834136963, "aqua_rat_8519": 0.7998415231704712, "aqua_rat_87094": 0.8005410432815552, "math_test_counting_and_probability_442": 0.8006777763366699, "aqua_rat_55590": 0.8007224202156067, "aqua_rat_42445": 0.8007494211196899, "aqua_rat_60755": 0.8007822036743164, "aqua_rat_44130": 0.8008557558059692, "aqua_rat_67179": 0.8009876608848572, "aqua_rat_6755": 0.8010056614875793, "aqua_rat_27914": 0.8010307550430298, "aqua_rat_29651": 0.8010493516921997, "aqua_rat_80108": 0.8011929988861084, "aqua_rat_13243": 0.8013291358947754, "aqua_rat_50942": 0.8013426065444946, "aqua_rat_75767": 0.8013672828674316, "aqua_rat_9693": 0.8014955520629883, "aqua_rat_78732": 0.8018490672111511, "aqua_rat_58323": 0.8020491600036621, "aqua_rat_779": 0.8022137880325317, "aqua_rat_65642": 0.8022176027297974, "aqua_rat_85740": 0.8024525046348572, "aqua_rat_48676": 0.8026084899902344, "aqua_rat_84398": 0.8027841448783875, "aqua_rat_73365": 0.802970826625824, "aqua_rat_81265": 0.8029849529266357, "aqua_rat_13585": 0.8030085563659668, "aqua_rat_40812": 0.8034742474555969, "aqua_rat_37223": 0.8036814332008362, "aqua_rat_59702": 0.8036895394325256, "aqua_rat_51559": 0.8037106990814209, "aqua_rat_74505": 0.8039014935493469, "math_train_counting_and_probability_369": 0.8041437268257141, "aqua_rat_42155": 0.8043772578239441, "aqua_rat_88418": 0.8045104742050171, "math_test_counting_and_probability_79": 0.8045941591262817, "aqua_rat_37642": 0.8049833178520203, "aqua_rat_71578": 0.8050878047943115, "aqua_rat_37185": 0.8051969408988953, "aqua_rat_8402": 0.80547696352005, "aqua_rat_47648": 0.8056623935699463, "aqua_rat_82553": 0.8057027459144592, "aqua_rat_13903": 0.8059759140014648, "math_train_counting_and_probability_437": 0.8059791922569275, "camel_38541": 0.8059996962547302, "aqua_rat_27717": 0.8064765334129333, "aqua_rat_89113": 0.8066376447677612, "aqua_rat_18404": 0.8067633509635925, "aqua_rat_51384": 0.8068834543228149, "aqua_rat_12398": 0.8070993423461914, "aqua_rat_78074": 0.8073573112487793, "aqua_rat_76271": 0.8076304793357849, "aqua_rat_81997": 0.8077046871185303, "aqua_rat_8728": 0.8078092336654663, "math_train_counting_and_probability_539": 0.8078175783157349, "aqua_rat_2480": 0.809276282787323, "aqua_rat_74550": 0.8092988729476929, "aqua_rat_28538": 0.8097259402275085, "aqua_rat_72210": 0.8098013997077942, "aqua_rat_35044": 0.8098040819168091, "math_train_counting_and_probability_373": 0.8103151321411133, "aqua_rat_10290": 0.8105687499046326, "aqua_rat_25933": 0.8105870485305786, "aqua_rat_57246": 0.8108830451965332, "aqua_rat_43064": 0.8108856081962585, "aqua_rat_4294": 0.8110158443450928, "aqua_rat_57693": 0.8111721277236938, "aqua_rat_22507": 0.8115141987800598, "aqua_rat_38594": 0.8119451999664307, "math_train_counting_and_probability_445": 0.8123286962509155, "aqua_rat_50541": 0.8124164938926697, "aqua_rat_44716": 0.8126777410507202, "aqua_rat_30109": 0.81295245885849, "aqua_rat_73402": 0.8131791949272156, "aqua_rat_73601": 0.8132754564285278, "aqua_rat_24776": 0.8137457370758057, "aqua_rat_28657": 0.8140324354171753, "math_train_counting_and_probability_249": 0.8141235709190369, "aqua_rat_10102": 0.8143938183784485, "aqua_rat_79094": 0.81463223695755, "aqua_rat_86468": 0.8150744438171387, "aqua_rat_60936": 0.8152526021003723, "math_test_counting_and_probability_776": 0.815399706363678, "aqua_rat_82104": 0.8155063986778259, "math_train_counting_and_probability_696": 0.8155205249786377, "aqua_rat_71137": 0.8158454298973083, "aqua_rat_8673": 0.8159586191177368, "aqua_rat_66841": 0.8162650465965271, "aqua_rat_83206": 0.8163935542106628, "aqua_rat_34678": 0.8171322345733643, "aqua_rat_53149": 0.817225456237793, "aqua_rat_32732": 0.8173232674598694, "aqua_rat_49270": 0.8177253603935242, "aqua_rat_62903": 0.8180216550827026, "aqua_rat_35517": 0.8182098269462585, "math_test_counting_and_probability_216": 0.8186296224594116, "aqua_rat_73122": 0.8186861872673035, "aqua_rat_66465": 0.8187237977981567, "aqua_rat_68198": 0.818798303604126, "aqua_rat_82511": 0.8195961117744446, "aqua_rat_35395": 0.8199279308319092, "aqua_rat_24605": 0.8213697075843811, "aqua_rat_15917": 0.8231574892997742, "aqua_rat_70861": 0.8238658308982849, "aqua_rat_22214": 0.8240842819213867, "math_train_counting_and_probability_961": 0.8241153359413147, "aqua_rat_52707": 0.824141800403595, "aqua_rat_62645": 0.8242372870445251, "aqua_rat_89036": 0.8242670297622681, "aqua_rat_51723": 0.8243939876556396, "aqua_rat_74651": 0.8251072764396667, "aqua_rat_72708": 0.8259251117706299, "aqua_rat_33533": 0.8268524408340454, "aqua_rat_11347": 0.8271191716194153, "aqua_rat_62768": 0.8274022340774536, "aqua_rat_44882": 0.82767653465271, "aqua_rat_13918": 0.8285057544708252, "aqua_rat_23041": 0.8285709619522095, "aqua_rat_29513": 0.8287276029586792, "aqua_rat_84364": 0.8305782079696655, "aqua_rat_43584": 0.8315797448158264, "camel_38505": 0.8321835398674011, "aqua_rat_87992": 0.8383681178092957}, "TheoremQA_elainewan/econ_micro_7_2.json": {"camel_25356": 0, "camel_25902": 0, "camel_25291": 0, "camel_25321": 0, "camel_25341": 0, "camel_25201": 0, "camel_25620": 0, "camel_25501": 0, "camel_25170": 0, "camel_24332": 0, "camel_25785": 0, "camel_25229": 0, "camel_25139": 0, "camel_25238": 0, "camel_25145": 0, "camel_25177": 0, "camel_24476": 0, "camel_25262": 0, "camel_25903": 0, "camel_25268": 0, "camel_25188": 0, "camel_25127": 0, "camel_24368": 0, "camel_25292": 0, "camel_25155": 0, "camel_25140": 0, "camel_25162": 0, "camel_25849": 0, "camel_25294": 0, "camel_25190": 0, "camel_25169": 0, "camel_25131": 0, "camel_25349": 0, "camel_25136": 0, "camel_25257": 0, "camel_25249": 0, "camel_25168": 0, "camel_25237": 0, "camel_25278": 0, "camel_25212": 0, "camel_25335": 0, "camel_25911": 0, "camel_25693": 0, "camel_24331": 0, "camel_25258": 0, "camel_24422": 0, "camel_24463": 0, "camel_25225": 0, "camel_24467": 0, "camel_24462": 0, "camel_25332": 0, "camel_25976": 0, "camel_24273": 0, "camel_25272": 0, "camel_25488": 0, "camel_25282": 0, "camel_25204": 0, "camel_25589": 0, "camel_25299": 0, "camel_24349": 0, "camel_25271": 0, "camel_25958": 0, "camel_25129": 0, "camel_25287": 0, "camel_25156": 0, "camel_25124": 0, "camel_25184": 0, "camel_25253": 0, "camel_25251": 0, "camel_25197": 0, "camel_25125": 0, "camel_25219": 0, "camel_25240": 0, "camel_25318": 0, "camel_25270": 0, "camel_25160": 0, "camel_25805": 0, "camel_25279": 0, "camel_25137": 0, "camel_25135": 0, "camel_25357": 0, "camel_25148": 0, "camel_25275": 0, "TheoremQA_elainewan/econ_micro_7_2.json": 0, "camel_25314": 0, "camel_25230": 0, "camel_25172": 0, "camel_25244": 0, "camel_25152": 0, "camel_25334": 0, "camel_25189": 0, "camel_25165": 0, "camel_25276": 0, "camel_25214": 0, "camel_25243": 0, "camel_25221": 0, "camel_25226": 0, "camel_25176": 0, "camel_25207": 0, "camel_25812": 0, "camel_25274": 0, "camel_25496": 0, "camel_25247": 0, "camel_25241": 0, "camel_25090": 0, "camel_25198": 0, "camel_25208": 0, "camel_25322": 0, "camel_25121": 0, "camel_25892": 0, "camel_25316": 0, "camel_25265": 0, "camel_25181": 0, "camel_25263": 0, "camel_25302": 0, "camel_25256": 0, "camel_25159": 0, "camel_25146": 0, "camel_24401": 0, "camel_25171": 0, "camel_25147": 0, "camel_24443": 0, "camel_25157": 0, "camel_24418": 0, "camel_25688": 0, "camel_25239": 0, "camel_25227": 0, "camel_25126": 0, "camel_25224": 0, "camel_25305": 0, "camel_25185": 0, "camel_25863": 0, "camel_24316": 0, "camel_37751": 0.7021667957305908, "camel_38752": 0.7033507823944092, "camel_37723": 0.703417956829071, "camel_37730": 0.7037753462791443, "camel_37699": 0.7044142484664917, "camel_37721": 0.705590009689331, "camel_37683": 0.7062710523605347, "camel_37704": 0.7063663601875305, "camel_37692": 0.7066176533699036, "camel_38645": 0.7070639133453369, "camel_38689": 0.7075475454330444, "camel_39397": 0.7079307436943054, "camel_37722": 0.7085315585136414, "camel_37750": 0.7086906433105469, "camel_37687": 0.7087664008140564, "camel_38729": 0.709122359752655, "camel_37742": 0.7093716263771057, "camel_37710": 0.7095248699188232, "camel_38710": 0.7095339298248291, "camel_37685": 0.7098501324653625, "camel_37693": 0.7099689841270447, "camel_38707": 0.7102941274642944, "camel_37703": 0.7113280892372131, "camel_38678": 0.7114124894142151, "camel_38758": 0.7114506959915161, "camel_37684": 0.711553692817688, "camel_38694": 0.7116392850875854, "camel_38715": 0.712185263633728, "camel_10284": 0.7123281359672546, "camel_37696": 0.7123348712921143, "camel_38661": 0.7135098576545715, "camel_38705": 0.7142690420150757, "camel_37635": 0.714593231678009, "camel_37669": 0.719947338104248, "camel_37708": 0.719981849193573, "camel_38717": 0.7210416793823242, "camel_38648": 0.7212817072868347, "camel_38646": 0.7219063639640808, "camel_38643": 0.7227327227592468, "camel_37740": 0.7231922149658203, "camel_38699": 0.7233872413635254, "camel_10305": 0.7236311435699463, "camel_38714": 0.723639965057373, "camel_37682": 0.7237978577613831, "camel_37680": 0.7251128554344177, "camel_37749": 0.7252751588821411, "camel_37716": 0.7257243990898132, "camel_37651": 0.7264072299003601, "camel_37709": 0.72764652967453, "camel_38692": 0.7300884127616882, "camel_37745": 0.7319527268409729, "TheoremQA_elainewan/econ_micro_7.json": 0.7320156097412109, "camel_10514": 0.7322341799736023, "camel_38795": 0.7322685718536377, "camel_37697": 0.7331382632255554, "camel_37700": 0.7342258095741272, "camel_37741": 0.7347334027290344, "aqua_rat_41336": 0.7359769344329834, "camel_38693": 0.7371186017990112, "camel_37706": 0.7378711700439453, "camel_38666": 0.7435290217399597, "camel_37752": 0.7455170154571533, "camel_37744": 0.7509067058563232, "camel_37729": 0.7538642287254333, "camel_38662": 0.755469024181366, "camel_37701": 0.7627431750297546, "TheoremQA_elainewan/econ_micro_18.json": 0.7724958062171936}, "TheoremQA_xueguangma/effective_rates_1.json": {"TheoremQA_xueguangma/effective_rates_1.json": 0, "aqua_rat_18561": 0.7298225164413452, "aqua_rat_16080": 0.7300395965576172, "aqua_rat_16856": 0.7301419973373413, "aqua_rat_72412": 0.7301581501960754, "aqua_rat_6314": 0.7301854491233826, "aqua_rat_40489": 0.730706512928009, "aqua_rat_83656": 0.7314466834068298, "aqua_rat_58694": 0.7318847179412842, "aqua_rat_64995": 0.7322058081626892, "aqua_rat_34462": 0.7322289347648621, "aqua_rat_5844": 0.732394814491272, "aqua_rat_28406": 0.7329602837562561, "aqua_rat_75833": 0.7332725524902344, "aqua_rat_10585": 0.7332906723022461, "aqua_rat_33923": 0.7333818078041077, "aqua_rat_83740": 0.7335883378982544, "aqua_rat_64422": 0.7337785959243774, "aqua_rat_10990": 0.7340391874313354, "aqua_rat_86517": 0.7341885566711426, "TheoremQA_wenhuchen/compound_interest1.json": 0.734196662902832, "aqua_rat_1796": 0.7346286773681641, "aqua_rat_47773": 0.7348290085792542, "aqua_rat_13692": 0.7348616719245911, "aqua_rat_3773": 0.7363321185112, "aqua_rat_43680": 0.7364460229873657, "aqua_rat_58518": 0.7373594045639038, "aqua_rat_16693": 0.7376575469970703, "aqua_rat_87590": 0.7381882071495056, "aqua_rat_60064": 0.7382024526596069, "aqua_rat_79904": 0.7382283806800842, "aqua_rat_3402": 0.738375186920166, "math_train_algebra_957": 0.7385070323944092, "aqua_rat_34698": 0.7388269901275635, "aqua_rat_50447": 0.7390301823616028, "aqua_rat_1115": 0.7390855550765991, "aqua_rat_77602": 0.7398062944412231, "aqua_rat_21250": 0.739957332611084, "aqua_rat_47882": 0.7408849000930786, "math_train_algebra_2306": 0.7410491704940796, "aqua_rat_84357": 0.7410560250282288, "aqua_rat_87904": 0.741293728351593, "aqua_rat_49963": 0.7414821982383728, "math_test_algebra_594": 0.7417080998420715, "aqua_rat_20423": 0.7421723008155823, "aqua_rat_71142": 0.7424628734588623, "aqua_rat_44930": 0.7425798773765564, "aqua_rat_64215": 0.7436267137527466, "aqua_rat_56718": 0.7438634037971497, "math_train_algebra_369": 0.7440910339355469, "aqua_rat_7357": 0.7441228628158569, "aqua_rat_21814": 0.7441807985305786, "aqua_rat_60321": 0.7442129850387573, "aqua_rat_53914": 0.7442405223846436, "aqua_rat_72794": 0.7446608543395996, "aqua_rat_54028": 0.7447846531867981, "aqua_rat_68": 0.7450528740882874, "aqua_rat_29356": 0.7456216216087341, "aqua_rat_66371": 0.7457188963890076, "aqua_rat_71239": 0.7457664012908936, "aqua_rat_73739": 0.7458491325378418, "aqua_rat_82669": 0.7458521723747253, "gsm_rft_11620": 0.7458614110946655, "gsm_train_25622": 0.7461984753608704, "aqua_rat_62528": 0.7466683983802795, "gsm_rft_6559": 0.7466986179351807, "aqua_rat_38068": 0.7468694448471069, "aqua_rat_70031": 0.7468779683113098, "aqua_rat_48358": 0.7469019293785095, "aqua_rat_25723": 0.747283399105072, "aqua_rat_64976": 0.7480024695396423, "aqua_rat_47290": 0.7481804490089417, "aqua_rat_43060": 0.7483941316604614, "aqua_rat_28282": 0.7484641671180725, "aqua_rat_73390": 0.7486539483070374, "aqua_rat_48160": 0.7486861348152161, "aqua_rat_34082": 0.7487136721611023, "aqua_rat_37258": 0.7487139105796814, "aqua_rat_84646": 0.7488824725151062, "aqua_rat_29976": 0.7492180466651917, "aqua_rat_56852": 0.749224066734314, "aqua_rat_48494": 0.7494460940361023, "gsm_rft_5849": 0.7506589889526367, "aqua_rat_39049": 0.7507758140563965, "aqua_rat_6679": 0.7508377432823181, "aqua_rat_49908": 0.7509335279464722, "aqua_rat_12597": 0.7514215111732483, "aqua_rat_25162": 0.7520356178283691, "aqua_rat_2257": 0.7521207332611084, "aqua_rat_30717": 0.7524566054344177, "aqua_rat_34263": 0.7525073885917664, "aqua_rat_36240": 0.752611517906189, "aqua_rat_12533": 0.7526260614395142, "aqua_rat_66803": 0.7527520060539246, "aqua_rat_14876": 0.7530406713485718, "aqua_rat_5907": 0.7531622648239136, "aqua_rat_17404": 0.7533138990402222, "aqua_rat_72687": 0.7533767223358154, "aqua_rat_13239": 0.7537160515785217, "aqua_rat_24182": 0.7537279725074768, "aqua_rat_23277": 0.7538169026374817, "aqua_rat_49718": 0.7544757723808289, "math_train_algebra_1011": 0.7545307278633118, "math_test_algebra_2626": 0.7551603317260742, "aqua_rat_75817": 0.7557383179664612, "aqua_rat_34081": 0.7567781209945679, "aqua_rat_75047": 0.7569960355758667, "aqua_rat_8658": 0.757150411605835, "TheoremQA_xueguangma/effective_rates_2.json": 0.757307767868042, "aqua_rat_84309": 0.7573152780532837, "aqua_rat_33430": 0.7580795288085938, "aqua_rat_7674": 0.7582815885543823, "aqua_rat_68014": 0.7586318850517273, "aqua_rat_51796": 0.7588673233985901, "aqua_rat_88174": 0.7591357231140137, "aqua_rat_42017": 0.7602139711380005, "aqua_rat_56129": 0.7604027986526489, "aqua_rat_26976": 0.7607351541519165, "aqua_rat_2618": 0.7609490156173706, "aqua_rat_58298": 0.7615994215011597, "aqua_rat_28984": 0.7617948651313782, "aqua_rat_53431": 0.7624379396438599, "aqua_rat_63070": 0.7630572319030762, "aqua_rat_60493": 0.763074517250061, "aqua_rat_31334": 0.7631193399429321, "math_test_algebra_82": 0.7637929320335388, "aqua_rat_54481": 0.7640026807785034, "aqua_rat_735": 0.7654880881309509, "aqua_rat_17663": 0.7656540870666504, "math_test_algebra_608": 0.7656748294830322, "aqua_rat_83839": 0.7657948732376099, "aqua_rat_32852": 0.7660503387451172, "aqua_rat_78533": 0.7670026421546936, "aqua_rat_10582": 0.7684975266456604, "aqua_rat_6566": 0.7688375115394592, "aqua_rat_68693": 0.7692841291427612, "aqua_rat_26425": 0.7698342204093933, "aqua_rat_78121": 0.7724608182907104, "aqua_rat_6180": 0.7727364897727966, "aqua_rat_82806": 0.7728162407875061, "aqua_rat_79047": 0.7738183736801147, "aqua_rat_53568": 0.7741615772247314, "aqua_rat_53336": 0.7743568420410156, "aqua_rat_6415": 0.7744423151016235, "aqua_rat_21728": 0.774869441986084, "aqua_rat_69447": 0.7748757004737854, "math_test_algebra_311": 0.7749398946762085, "aqua_rat_63322": 0.7754113078117371, "aqua_rat_17751": 0.7755060791969299, "aqua_rat_86835": 0.7757294774055481, "aqua_rat_67076": 0.7762408256530762, "aqua_rat_14414": 0.7762600779533386, "aqua_rat_75046": 0.7764454483985901, "aqua_rat_50660": 0.7769536972045898, "aqua_rat_20488": 0.7771885991096497, "aqua_rat_30386": 0.7781016826629639, "aqua_rat_62727": 0.7790717482566833, "aqua_rat_87589": 0.779531717300415, "aqua_rat_40411": 0.779741108417511, "aqua_rat_38657": 0.781241774559021, "aqua_rat_15743": 0.7813453078269958, "aqua_rat_59829": 0.7847590446472168, "aqua_rat_869": 0.7849162817001343, "aqua_rat_69905": 0.7872003316879272, "aqua_rat_51100": 0.787214994430542, "aqua_rat_28883": 0.7879801392555237, "math_test_algebra_337": 0.7882134318351746, "aqua_rat_69547": 0.7883578538894653, "aqua_rat_46898": 0.7896627187728882, "aqua_rat_16448": 0.7907055616378784, "aqua_rat_54664": 0.7907165884971619, "aqua_rat_65964": 0.793265163898468, "math_train_algebra_667": 0.7934623956680298, "aqua_rat_10686": 0.79349684715271, "aqua_rat_88003": 0.794139564037323, "aqua_rat_57943": 0.7948693633079529, "aqua_rat_88415": 0.7951840162277222, "aqua_rat_19784": 0.7953618168830872, "aqua_rat_59": 0.7965644001960754, "aqua_rat_3687": 0.7977990508079529, "aqua_rat_32350": 0.7983173727989197, "aqua_rat_1549": 0.7983556389808655, "aqua_rat_42515": 0.7989238500595093, "aqua_rat_59892": 0.8000524044036865, "aqua_rat_15079": 0.8126850128173828, "aqua_rat_61400": 0.8156156539916992, "aqua_rat_38900": 0.8201146721839905, "math_train_algebra_767": 0.8210772275924683, "aqua_rat_24052": 0.8212278485298157, "aqua_rat_88758": 0.8227161169052124, "aqua_rat_64105": 0.8240171074867249, "aqua_rat_20758": 0.8359898924827576, "aqua_rat_72737": 0.8368537425994873, "aqua_rat_45867": 0.8369396924972534, "aqua_rat_36461": 0.8387588858604431, "aqua_rat_3885": 0.8413342833518982, "aqua_rat_46315": 0.8424514532089233, "aqua_rat_42949": 0.8455347418785095, "aqua_rat_21626": 0.8461620211601257, "aqua_rat_41963": 0.8535186648368835}, "TheoremQA_jianyu_xu/Multinomial_4.json": {"camel_20514": 0, "camel_20061": 0, "camel_20988": 0, "camel_20985": 0, "camel_20314": 0, "camel_20281": 0, "camel_20487": 0, "camel_20604": 0, "camel_20672": 0, "camel_20812": 0, "camel_20612": 0, "camel_20175": 0, "camel_20414": 0, "camel_20302": 0, "camel_21545": 0, "camel_20431": 0, "camel_20862": 0, "camel_20830": 0, "camel_20410": 0, "camel_20622": 0, "camel_20356": 0, "camel_20863": 0, "camel_20973": 0, "camel_20849": 0, "camel_20248": 0, "camel_20411": 0, "camel_20583": 0, "camel_21117": 0, "camel_20578": 0, "camel_20818": 0, "camel_20823": 0, "camel_20244": 0, "camel_20861": 0, "camel_20600": 0, "camel_20643": 0, "camel_21223": 0, "camel_20805": 0, "camel_20262": 0, "camel_20848": 0, "camel_20867": 0, "camel_20860": 0, "camel_20447": 0, "camel_20549": 0, "camel_20844": 0, "camel_20499": 0, "camel_20666": 0, "camel_20942": 0, "camel_20506": 0, "camel_20457": 0, "camel_21219": 0, "camel_20317": 0, "camel_20856": 0, "camel_20299": 0, "camel_20845": 0, "camel_20602": 0, "camel_21261": 0, "camel_20464": 0, "camel_20297": 0, "camel_20859": 0, "TheoremQA_jianyu_xu/Multinomial_4.json": 0, "camel_20813": 0, "aqua_rat_73019": 0.7647337317466736, "aqua_rat_55802": 0.7649872899055481, "aqua_rat_50507": 0.7652535438537598, "aqua_rat_79918": 0.7652661800384521, "math_train_counting_and_probability_29": 0.7653146386146545, "aqua_rat_57419": 0.7655236721038818, "math_test_prealgebra_2024": 0.7655648589134216, "aqua_rat_20874": 0.7656378746032715, "aqua_rat_17800": 0.7664538621902466, "aqua_rat_20685": 0.7664555311203003, "aqua_rat_12384": 0.7666812539100647, "aqua_rat_62590": 0.7666850686073303, "aqua_rat_33793": 0.7668207287788391, "math_train_counting_and_probability_890": 0.7668224573135376, "aqua_rat_11652": 0.7668340802192688, "aqua_rat_57130": 0.766946017742157, "aqua_rat_36980": 0.7669849991798401, "aqua_rat_35633": 0.7676787972450256, "aqua_rat_32025": 0.7678089141845703, "aqua_rat_7139": 0.7679275274276733, "aqua_rat_39115": 0.768059492111206, "aqua_rat_75309": 0.7681417465209961, "aqua_rat_48724": 0.7681763768196106, "aqua_rat_19231": 0.7683815956115723, "math_train_prealgebra_1740": 0.7690080404281616, "aqua_rat_58247": 0.7692306041717529, "aqua_rat_28496": 0.7693650722503662, "math_test_counting_and_probability_704": 0.7696213722229004, "aqua_rat_56615": 0.769784688949585, "aqua_rat_55249": 0.7699847221374512, "aqua_rat_29318": 0.7700597047805786, "aqua_rat_53190": 0.7701159119606018, "aqua_rat_77678": 0.7701604962348938, "aqua_rat_34778": 0.7702158689498901, "aqua_rat_27623": 0.7703366875648499, "math_train_counting_and_probability_24": 0.7704181671142578, "aqua_rat_66723": 0.7704293727874756, "aqua_rat_20594": 0.7707548141479492, "math_train_prealgebra_172": 0.7709686756134033, "aqua_rat_7373": 0.7711581587791443, "aqua_rat_10378": 0.7713362574577332, "aqua_rat_11242": 0.7713847756385803, "aqua_rat_44268": 0.7713956832885742, "aqua_rat_87031": 0.7715974450111389, "aqua_rat_32937": 0.7716549038887024, "aqua_rat_12472": 0.7718341946601868, "aqua_rat_19798": 0.7719801664352417, "aqua_rat_17735": 0.7725991606712341, "aqua_rat_64457": 0.773472011089325, "aqua_rat_32634": 0.7735279202461243, "aqua_rat_19653": 0.7737717628479004, "aqua_rat_84792": 0.7738274335861206, "aqua_rat_4386": 0.7738418579101562, "aqua_rat_50319": 0.7738568186759949, "aqua_rat_41684": 0.7739174962043762, "aqua_rat_36073": 0.7739350199699402, "aqua_rat_3295": 0.7741862535476685, "aqua_rat_45011": 0.774303674697876, "aqua_rat_21789": 0.7745290398597717, "aqua_rat_35638": 0.7745321989059448, "aqua_rat_55857": 0.7745660543441772, "aqua_rat_51773": 0.7746430039405823, "aqua_rat_88236": 0.7746933698654175, "aqua_rat_19931": 0.7750357985496521, "aqua_rat_38599": 0.7750502228736877, "math_train_prealgebra_1167": 0.775075376033783, "aqua_rat_34214": 0.7755149006843567, "aqua_rat_65809": 0.7755610346794128, "aqua_rat_48521": 0.7755815982818604, "aqua_rat_20068": 0.7755938172340393, "aqua_rat_8771": 0.7757425904273987, "aqua_rat_81021": 0.7759093046188354, "aqua_rat_69596": 0.7763410806655884, "aqua_rat_73283": 0.776461660861969, "aqua_rat_62840": 0.7766317129135132, "aqua_rat_25182": 0.7766373157501221, "aqua_rat_66082": 0.7766832113265991, "aqua_rat_28318": 0.7766973972320557, "aqua_rat_51148": 0.7768040895462036, "aqua_rat_58193": 0.7771629095077515, "aqua_rat_43226": 0.7771798372268677, "aqua_rat_7588": 0.7772272825241089, "math_train_counting_and_probability_5131": 0.7777770161628723, "aqua_rat_66661": 0.778207004070282, "aqua_rat_67953": 0.7786714434623718, "aqua_rat_35991": 0.7789708375930786, "aqua_rat_26451": 0.7791334986686707, "aqua_rat_72012": 0.7794830799102783, "aqua_rat_15466": 0.7796335220336914, "aqua_rat_31049": 0.7798005938529968, "aqua_rat_67588": 0.7798335552215576, "aqua_rat_21632": 0.7798830270767212, "aqua_rat_18863": 0.7800712585449219, "aqua_rat_61326": 0.7801448702812195, "aqua_rat_33488": 0.7801733613014221, "aqua_rat_35962": 0.7802104949951172, "aqua_rat_43755": 0.7803459763526917, "aqua_rat_67870": 0.7806347608566284, "aqua_rat_45147": 0.7809802889823914, "aqua_rat_85339": 0.7814557552337646, "aqua_rat_85194": 0.7830926775932312, "aqua_rat_4340": 0.7832074761390686, "aqua_rat_58870": 0.7837886214256287, "aqua_rat_46484": 0.7838703989982605, "math_test_prealgebra_1107": 0.7846289873123169, "aqua_rat_3311": 0.7846834659576416, "aqua_rat_15353": 0.7854939103126526, "aqua_rat_9005": 0.7856390476226807, "aqua_rat_6101": 0.7860732674598694, "aqua_rat_65284": 0.786443829536438, "aqua_rat_77275": 0.7883880734443665, "math_train_counting_and_probability_1032": 0.7887482047080994, "aqua_rat_45246": 0.7892357707023621, "aqua_rat_21240": 0.7904582619667053, "aqua_rat_30513": 0.7906402945518494, "aqua_rat_74024": 0.7916536927223206, "aqua_rat_16417": 0.7920128703117371, "aqua_rat_28709": 0.7922528982162476, "aqua_rat_34268": 0.7924146056175232, "TheoremQA_jianyu_xu/combination_and_permutation_1.json": 0.7926087975502014, "aqua_rat_8129": 0.7926998734474182, "aqua_rat_34136": 0.7927994132041931, "aqua_rat_15194": 0.792803168296814, "math_test_prealgebra_1204": 0.7929759621620178, "aqua_rat_77505": 0.7931482791900635, "aqua_rat_53262": 0.7937545776367188, "aqua_rat_33293": 0.794230580329895, "aqua_rat_4285": 0.7960618734359741, "aqua_rat_25098": 0.7961159944534302, "aqua_rat_45187": 0.796846330165863, "camel_38534": 0.7972497344017029, "aqua_rat_51420": 0.7974559664726257, "aqua_rat_41332": 0.7977043390274048, "aqua_rat_51800": 0.797747790813446, "aqua_rat_28710": 0.8001798391342163, "aqua_rat_9747": 0.8017826080322266, "aqua_rat_36159": 0.8025604486465454, "aqua_rat_16429": 0.8057892322540283, "aqua_rat_38573": 0.8087354898452759}, "TheoremQA_maxku/cv-colorsci1-rgb.json": {"TheoremQA_maxku/cv-colorsci1-rgb.json": 0, "gsm_train_21913": 0.6085832715034485, "camel_44748": 0.608634352684021, "aqua_rat_39833": 0.6086883544921875, "aqua_rat_55014": 0.608715832233429, "gsm_rft_23876": 0.6087642312049866, "gsm_rft_9687": 0.6087727546691895, "gsm_rft_9791": 0.6088585257530212, "aqua_rat_85203": 0.6088703274726868, "math_test_counting_and_probability_1084": 0.6090038418769836, "math_test_counting_and_probability_855": 0.609018862247467, "aqua_rat_61809": 0.6090362071990967, "aqua_rat_38167": 0.6092686653137207, "math_test_counting_and_probability_260": 0.6094821691513062, "gsm_rft_17939": 0.6095688939094543, "camel_21001": 0.609757125377655, "camel_21596": 0.6097761988639832, "gsm_rft_24925": 0.609890341758728, "gsm_train_27821": 0.609890341758728, "camel_20407": 0.6098959445953369, "gsm_train_35467": 0.6100113987922668, "aqua_rat_5030": 0.610210657119751, "gsm_rft_3218": 0.6103721261024475, "camel_37491": 0.6104976534843445, "aqua_rat_78547": 0.6105395555496216, "gsm_train_33000": 0.6105570197105408, "aqua_rat_78639": 0.6106591820716858, "aqua_rat_17718": 0.6107982397079468, "camel_26575": 0.6111354827880859, "aqua_rat_71393": 0.6111728549003601, "gsm_rft_25326": 0.6112107634544373, "TheoremQA_maxku/cv-imageprocessing6-histogram.json": 0.6113415956497192, "camel_20517": 0.6113423109054565, "aqua_rat_57267": 0.6113605499267578, "camel_31197": 0.6116238236427307, "math_test_number_theory_985": 0.6118292212486267, "gsm_rft_22256": 0.6118906736373901, "math_train_number_theory_7104": 0.6119451522827148, "math_test_number_theory_1104": 0.611993670463562, "camel_27551": 0.6120175719261169, "gsm_train_13923": 0.6121926307678223, "gsm_rft_26309": 0.6122236847877502, "aqua_rat_22474": 0.6122844219207764, "camel_37453": 0.6123077273368835, "camel_8875": 0.6124215126037598, "aqua_rat_43755": 0.6124287247657776, "camel_37198": 0.6124629974365234, "gsm_rft_34914": 0.6126375794410706, "aqua_rat_17959": 0.6126465797424316, "aqua_rat_4648": 0.6127226948738098, "gsm_rft_35008": 0.6129955649375916, "math_test_counting_and_probability_27": 0.613054096698761, "aqua_rat_50093": 0.6130639314651489, "math_test_number_theory_60": 0.613203763961792, "gsm_rft_33275": 0.6133261322975159, "gsm_train_27178": 0.6133261322975159, "aqua_rat_74428": 0.613744854927063, "aqua_rat_2640": 0.6138253211975098, "math_test_number_theory_383": 0.613943338394165, "gsm_rft_29435": 0.6143243312835693, "camel_31193": 0.6144307851791382, "camel_37493": 0.6145076751708984, "math_train_number_theory_502": 0.6145702004432678, "camel_37551": 0.6146873831748962, "gsm_rft_18784": 0.6149479746818542, "camel_21553": 0.6149988770484924, "aqua_rat_48521": 0.6152477860450745, "math_train_counting_and_probability_514": 0.615271270275116, "math_test_number_theory_161": 0.615347683429718, "aqua_rat_42331": 0.6153682470321655, "gsm_rft_8013": 0.6155381798744202, "aqua_rat_75875": 0.6155593991279602, "math_train_counting_and_probability_1111": 0.6156541705131531, "gsm_rft_4843": 0.6157687306404114, "camel_27951": 0.6157722473144531, "camel_20413": 0.6159840226173401, "aqua_rat_75580": 0.6162983775138855, "aqua_rat_82302": 0.6163577437400818, "camel_13809": 0.6165763735771179, "gsm_rft_31898": 0.616685688495636, "camel_21821": 0.6168586611747742, "math_train_counting_and_probability_890": 0.6168902516365051, "camel_26686": 0.6172123551368713, "camel_37443": 0.6172359585762024, "aqua_rat_25226": 0.617402970790863, "aqua_rat_58195": 0.6176869869232178, "math_train_counting_and_probability_674": 0.6177343726158142, "aqua_rat_57498": 0.6177425384521484, "camel_26464": 0.6178642511367798, "math_train_prealgebra_1672": 0.6179215312004089, "math_test_prealgebra_144": 0.6181171536445618, "camel_20501": 0.6181410551071167, "camel_49846": 0.6181783676147461, "gsm_rft_23472": 0.61837238073349, "aqua_rat_79834": 0.6184592843055725, "gsm_rft_31436": 0.6193395853042603, "camel_37504": 0.6193966269493103, "aqua_rat_5247": 0.6198660731315613, "camel_21233": 0.6204054355621338, "camel_13805": 0.6206669807434082, "camel_44798": 0.62080979347229, "camel_27537": 0.6211012005805969, "camel_37553": 0.621272623538971, "camel_36216": 0.6213428974151611, "camel_26591": 0.6216949820518494, "camel_26680": 0.6218730807304382, "camel_36363": 0.6221715211868286, "gsm_train_28486": 0.6222303509712219, "gsm_rft_34166": 0.6222303509712219, "gsm_rft_23738": 0.6223136782646179, "camel_26460": 0.6223859786987305, "aqua_rat_22028": 0.6227007508277893, "camel_26483": 0.6228910088539124, "camel_21760": 0.6231297254562378, "camel_21775": 0.6233137845993042, "math_train_number_theory_528": 0.6233389973640442, "math_train_number_theory_498": 0.6239029765129089, "camel_26590": 0.6241506338119507, "camel_21383": 0.6243451237678528, "camel_36220": 0.6246978640556335, "camel_21960": 0.6248282194137573, "math_test_number_theory_691": 0.6257016658782959, "camel_20425": 0.625884473323822, "gsm_rft_33841": 0.6258904933929443, "camel_26394": 0.6268773078918457, "camel_26434": 0.627327561378479, "aqua_rat_29934": 0.6274093985557556, "camel_26585": 0.627924382686615, "aqua_rat_57240": 0.6280524730682373, "camel_26692": 0.6281073093414307, "camel_13823": 0.6281141638755798, "aqua_rat_35675": 0.6288269758224487, "math_train_number_theory_455": 0.6289569735527039, "gsm_train_24856": 0.6297275424003601, "gsm_rft_11414": 0.6297783851623535, "gsm_rft_11927": 0.6297783851623535, "gsm_rft_18016": 0.6298800110816956, "math_train_prealgebra_426": 0.6298990249633789, "camel_27940": 0.6300379633903503, "gsm_rft_16775": 0.6301019191741943, "math_train_prealgebra_481": 0.6306049227714539, "camel_37508": 0.6307066679000854, "camel_13789": 0.6315852999687195, "camel_26565": 0.6320986747741699, "camel_13765": 0.6322217583656311, "camel_26609": 0.6328487992286682, "camel_36357": 0.6330405473709106, "gsm_rft_159": 0.6333277821540833, "gsm_train_15116": 0.6333277821540833, "gsm_rft_4658": 0.6333277821540833, "camel_37882": 0.6352282166481018, "math_train_prealgebra_1175": 0.6352896690368652, "camel_26631": 0.6357511878013611, "camel_27982": 0.6358928084373474, "camel_26623": 0.6361679434776306, "aqua_rat_57783": 0.636229932308197, "aqua_rat_13370": 0.6365881562232971, "math_test_number_theory_493": 0.637771487236023, "math_train_counting_and_probability_730": 0.6379294991493225, "camel_26637": 0.6379295587539673, "camel_27970": 0.6381222605705261, "camel_13838": 0.6381747126579285, "math_train_prealgebra_353": 0.6385977268218994, "camel_13820": 0.6386860609054565, "camel_36961": 0.6397647261619568, "aqua_rat_17743": 0.6398280262947083, "camel_13764": 0.6399694085121155, "camel_20128": 0.6401728391647339, "aqua_rat_36194": 0.6405385136604309, "camel_26437": 0.6407092213630676, "TheoremQA_maxku/cv-colorsci4-hsi.json": 0.6408817172050476, "camel_26610": 0.6426823139190674, "camel_13811": 0.6432295441627502, "aqua_rat_60099": 0.6444726586341858, "aqua_rat_19653": 0.6457231640815735, "camel_26538": 0.6459684371948242, "camel_26612": 0.6464909315109253, "camel_26601": 0.647022008895874, "aqua_rat_87221": 0.6475144624710083, "camel_26485": 0.6485488414764404, "camel_26570": 0.6488515138626099, "camel_27994": 0.649161159992218, "camel_26581": 0.6538569927215576, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.6556184887886047, "camel_13806": 0.655860960483551, "math_train_prealgebra_1167": 0.6586342453956604, "camel_26638": 0.6588770151138306, "aqua_rat_13625": 0.6593157052993774, "camel_13808": 0.6602931618690491, "camel_36864": 0.6606024503707886, "aqua_rat_13646": 0.6610199213027954, "camel_36754": 0.6620902419090271, "TheoremQA_maxku/cv-colorsci2-hsi.json": 0.6624632477760315, "camel_37501": 0.6650105714797974, "camel_26584": 0.6698288321495056, "TheoremQA_maxku/cv-imageprocessing10-digital-image.json": 0.6718133091926575, "camel_13791": 0.6740321516990662, "camel_36295": 0.6788152456283569, "TheoremQA_maxku/cv-colorsci3-rgb.json": 0.6939214468002319, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0.6996272802352905}, "TheoremQA_panlu/similarity3.json": {"camel_3254": 0, "math_train_geometry_1019": 0, "math_test_geometry_609": 0, "camel_3999": 0, "camel_3247": 0, "camel_3253": 0, "math_train_geometry_6004": 0, "camel_3236": 0, "camel_3272": 0, "camel_3237": 0, "camel_3202": 0, "camel_3219": 0, "camel_3226": 0, "math_train_geometry_694": 0, "camel_3222": 0, "camel_3261": 0, "camel_3951": 0, "camel_3243": 0, "camel_3233": 0, "camel_3220": 0, "camel_3218": 0, "camel_3234": 0, "camel_3221": 0, "camel_3223": 0, "camel_3258": 0, "camel_3260": 0, "camel_3266": 0, "camel_3257": 0, "camel_3235": 0, "camel_3227": 0, "camel_3207": 0, "camel_3208": 0, "math_train_geometry_783": 0, "camel_3269": 0, "camel_3275": 0, "camel_3270": 0, "camel_3263": 0, "camel_3238": 0, "camel_3228": 0, "camel_3268": 0, "camel_3250": 0, "camel_3256": 0, "camel_3274": 0, "camel_3241": 0, "camel_3214": 0, "camel_3206": 0, "camel_3224": 0, "camel_3229": 0, "camel_3239": 0, "camel_3262": 0, "math_train_geometry_350": 0, "camel_3249": 0, "camel_3245": 0, "camel_3211": 0, "camel_3217": 0, "math_train_geometry_809": 0, "camel_3212": 0, "camel_3209": 0, "camel_3276": 0, "camel_3216": 0, "math_test_geometry_634": 0, "camel_3259": 0, "camel_3201": 0, "camel_3204": 0, "camel_3246": 0, "camel_3225": 0, "camel_3248": 0, "camel_3264": 0, "camel_3203": 0, "camel_3205": 0, "camel_3200": 0, "camel_3267": 0, "camel_3265": 0, "camel_3273": 0, "camel_3240": 0, "camel_3244": 0, "camel_3213": 0, "camel_2745": 0, "TheoremQA_panlu/similarity3.json": 0, "camel_3251": 0, "math_train_geometry_804": 0, "math_train_geometry_636": 0, "math_train_geometry_272": 0, "aqua_rat_54286": 0.7535795569419861, "aqua_rat_59583": 0.7537087202072144, "gsm_rft_604": 0.7540451884269714, "aqua_rat_55057": 0.7543765902519226, "aqua_rat_19464": 0.7544207572937012, "gsm_train_33962": 0.7544516921043396, "gsm_rft_18078": 0.7550893425941467, "aqua_rat_30114": 0.7551555633544922, "camel_18713": 0.7552107572555542, "gsm_rft_23551": 0.7552393674850464, "aqua_rat_83024": 0.755305290222168, "aqua_rat_21994": 0.755502462387085, "aqua_rat_27097": 0.7558730840682983, "aqua_rat_79811": 0.7561562657356262, "camel_18718": 0.7562492489814758, "gsm_rft_22050": 0.7564181089401245, "aqua_rat_25559": 0.7570037245750427, "aqua_rat_86050": 0.7570739984512329, "gsm_rft_25274": 0.7579417824745178, "aqua_rat_52869": 0.7579879760742188, "camel_31971": 0.7583145499229431, "aqua_rat_18677": 0.7583158016204834, "aqua_rat_4980": 0.7585437893867493, "aqua_rat_73164": 0.7588485479354858, "aqua_rat_4550": 0.7590558528900146, "aqua_rat_61382": 0.7592533826828003, "aqua_rat_72505": 0.7599315643310547, "aqua_rat_86238": 0.7599355578422546, "aqua_rat_37605": 0.7599866390228271, "aqua_rat_9047": 0.7600199580192566, "aqua_rat_4930": 0.7600407600402832, "aqua_rat_49461": 0.760125994682312, "aqua_rat_73609": 0.7606961727142334, "aqua_rat_25987": 0.7607418298721313, "aqua_rat_64146": 0.7608268857002258, "aqua_rat_6742": 0.7610872387886047, "aqua_rat_3355": 0.7611080408096313, "aqua_rat_12240": 0.7611506581306458, "aqua_rat_80856": 0.761290967464447, "math_train_algebra_2114": 0.7618936896324158, "aqua_rat_55386": 0.7620695233345032, "aqua_rat_13030": 0.7623105645179749, "aqua_rat_64869": 0.7629555463790894, "aqua_rat_8389": 0.7633315324783325, "math_test_prealgebra_1171": 0.7634671330451965, "aqua_rat_23453": 0.7636281251907349, "aqua_rat_11699": 0.7636324763298035, "aqua_rat_35895": 0.7638832926750183, "aqua_rat_66222": 0.7639760375022888, "aqua_rat_71832": 0.7640960812568665, "aqua_rat_24553": 0.7641969323158264, "aqua_rat_27315": 0.7642859220504761, "aqua_rat_46418": 0.764400839805603, "math_test_prealgebra_1154": 0.7647576928138733, "aqua_rat_7850": 0.765616238117218, "aqua_rat_59687": 0.7657502889633179, "aqua_rat_22832": 0.7658213376998901, "aqua_rat_34355": 0.7659878134727478, "aqua_rat_3357": 0.7660245299339294, "aqua_rat_29964": 0.7662355303764343, "aqua_rat_45753": 0.7671342492103577, "aqua_rat_66614": 0.7673243880271912, "math_train_prealgebra_606": 0.767615020275116, "aqua_rat_57441": 0.7678876519203186, "aqua_rat_32": 0.7679574489593506, "aqua_rat_40794": 0.7682452201843262, "aqua_rat_53060": 0.768573522567749, "aqua_rat_12761": 0.7688415050506592, "aqua_rat_26850": 0.7689629197120667, "aqua_rat_72235": 0.7694278955459595, "aqua_rat_7675": 0.7696715593338013, "aqua_rat_16054": 0.7697589993476868, "aqua_rat_55847": 0.7697721719741821, "math_test_prealgebra_1390": 0.7713369131088257, "aqua_rat_27771": 0.7716586589813232, "aqua_rat_34877": 0.7718448042869568, "aqua_rat_35791": 0.7721865177154541, "aqua_rat_63847": 0.7724938988685608, "aqua_rat_57712": 0.7728521823883057, "aqua_rat_32335": 0.7730768322944641, "aqua_rat_74464": 0.7732548713684082, "aqua_rat_9313": 0.7732977271080017, "aqua_rat_26654": 0.773369312286377, "aqua_rat_10906": 0.7736425399780273, "aqua_rat_76843": 0.773987352848053, "aqua_rat_71442": 0.7740777730941772, "aqua_rat_47373": 0.7742798924446106, "aqua_rat_87552": 0.7743330597877502, "aqua_rat_21537": 0.7747784852981567, "math_train_prealgebra_959": 0.7754945755004883, "aqua_rat_36856": 0.7760364413261414, "aqua_rat_55178": 0.777853786945343, "aqua_rat_7937": 0.7782288193702698, "aqua_rat_44109": 0.778727650642395, "aqua_rat_87989": 0.7791034579277039, "aqua_rat_6459": 0.7791332602500916, "aqua_rat_41018": 0.7796967029571533, "aqua_rat_7196": 0.779883623123169, "aqua_rat_6553": 0.7802085876464844, "aqua_rat_85319": 0.7821599245071411, "aqua_rat_9227": 0.7825002670288086, "aqua_rat_88392": 0.7841166257858276, "aqua_rat_34112": 0.7849999070167542, "math_train_prealgebra_328": 0.7856207489967346, "aqua_rat_69445": 0.7861140966415405, "aqua_rat_73491": 0.7875957489013672, "aqua_rat_1569": 0.7885211706161499, "math_test_prealgebra_1586": 0.7887027263641357, "aqua_rat_32417": 0.7892521619796753, "aqua_rat_88191": 0.790500283241272, "aqua_rat_72722": 0.790861964225769, "aqua_rat_88892": 0.7938703298568726, "aqua_rat_60233": 0.7947986721992493, "aqua_rat_45935": 0.79500812292099, "math_train_prealgebra_1943": 0.8096621036529541, "aqua_rat_80634": 0.8099197149276733, "camel_18647": 0.8383157849311829}, "TheoremQA_maxku/cv-cnn1.json": {"TheoremQA_maxku/cv-cnn1.json": 0, "gsm_rft_16215": 0.6271101236343384, "gsm_rft_8980": 0.6272258162498474, "aqua_rat_41208": 0.6272338628768921, "gsm_train_7154": 0.6272715926170349, "gsm_rft_34240": 0.6273321509361267, "aqua_rat_13625": 0.6274007558822632, "camel_26703": 0.6275440454483032, "camel_31986": 0.6275660395622253, "camel_31557": 0.6276770234107971, "gsm_train_27703": 0.6278452277183533, "aqua_rat_8933": 0.6279744505882263, "gsm_rft_35551": 0.6279952526092529, "gsm_rft_27782": 0.6280332207679749, "gsm_rft_11599": 0.6281537413597107, "gsm_train_14165": 0.6281946301460266, "gsm_rft_6461": 0.6281946301460266, "gsm_rft_23869": 0.6282010674476624, "gsm_train_23699": 0.6282010674476624, "camel_44787": 0.6283307075500488, "gsm_rft_20195": 0.6283540725708008, "camel_31918": 0.6283661127090454, "aqua_rat_35779": 0.6283732056617737, "camel_30509": 0.6283736824989319, "gsm_train_25856": 0.6284383535385132, "gsm_rft_17186": 0.6287404298782349, "gsm_rft_21588": 0.6288219690322876, "camel_30876": 0.6288637518882751, "gsm_rft_12439": 0.6288908123970032, "camel_30510": 0.6290130615234375, "gsm_rft_29148": 0.6290190815925598, "gsm_rft_308": 0.6290595531463623, "aqua_rat_50843": 0.6291177868843079, "gsm_rft_15171": 0.6292632222175598, "gsm_rft_22799": 0.6294329166412354, "gsm_rft_14096": 0.6295824646949768, "camel_30524": 0.6295999884605408, "gsm_rft_18442": 0.6296252608299255, "gsm_train_18640": 0.6296252608299255, "gsm_rft_1660": 0.6296664476394653, "gsm_rft_1245": 0.6297346949577332, "gsm_rft_1995": 0.6298274397850037, "gsm_rft_11843": 0.629848837852478, "gsm_rft_22763": 0.6299006938934326, "camel_21475": 0.6299163103103638, "gsm_train_9463": 0.6299505233764648, "gsm_rft_25877": 0.6299693584442139, "gsm_rft_20820": 0.6299758553504944, "gsm_rft_19960": 0.6301617622375488, "gsm_rft_16817": 0.630175769329071, "gsm_rft_14603": 0.6302509903907776, "aqua_rat_57153": 0.6302611827850342, "gsm_rft_2528": 0.6303210854530334, "gsm_rft_18992": 0.6303572654724121, "camel_26692": 0.6306386590003967, "gsm_rft_33011": 0.6306604146957397, "gsm_rft_23591": 0.6309512853622437, "gsm_train_22690": 0.6309512853622437, "gsm_rft_24953": 0.6310803294181824, "camel_31846": 0.6311252117156982, "aqua_rat_84157": 0.6312146782875061, "gsm_rft_25278": 0.6312157511711121, "gsm_rft_31633": 0.631535530090332, "gsm_rft_16965": 0.6315933465957642, "gsm_train_18247": 0.6315933465957642, "camel_44732": 0.631628692150116, "camel_19981": 0.6316534280776978, "camel_26701": 0.6316671967506409, "gsm_rft_35627": 0.6320974230766296, "camel_31923": 0.6321150660514832, "gsm_rft_31285": 0.6321253180503845, "gsm_train_26494": 0.6321253180503845, "gsm_rft_33995": 0.6321254968643188, "gsm_rft_5920": 0.6321646571159363, "camel_21035": 0.6322634816169739, "gsm_rft_14622": 0.6324898600578308, "camel_31946": 0.6325071454048157, "gsm_rft_20755": 0.632621169090271, "gsm_rft_22546": 0.632621169090271, "gsm_rft_7620": 0.6326435804367065, "aqua_rat_57472": 0.6329430341720581, "aqua_rat_76281": 0.633185088634491, "gsm_rft_30022": 0.6332637667655945, "camel_30407": 0.6332740783691406, "gsm_rft_29321": 0.6334467530250549, "gsm_rft_32458": 0.6334467530250549, "gsm_rft_13895": 0.6335448026657104, "gsm_rft_25314": 0.6335744261741638, "gsm_rft_27675": 0.633664071559906, "gsm_rft_8508": 0.6338201761245728, "gsm_rft_4689": 0.6338201761245728, "gsm_train_19003": 0.6338201761245728, "math_test_prealgebra_1279": 0.6338231563568115, "gsm_rft_23120": 0.6340546607971191, "gsm_train_25779": 0.6344267129898071, "camel_30499": 0.6345065236091614, "gsm_rft_31275": 0.6347943544387817, "camel_31589": 0.6348162293434143, "gsm_rft_1103": 0.6350870728492737, "gsm_train_8683": 0.6350870728492737, "gsm_rft_23812": 0.6352238655090332, "TheoremQA_maxku/cv-imageprocessing6-histogram.json": 0.6352687478065491, "gsm_rft_31898": 0.6352987885475159, "gsm_rft_6053": 0.6353365182876587, "aqua_rat_13646": 0.6354177594184875, "gsm_train_16223": 0.6356636881828308, "gsm_rft_22391": 0.6357108354568481, "gsm_rft_23175": 0.6357250809669495, "gsm_rft_33146": 0.6357917785644531, "gsm_train_705": 0.6358441114425659, "gsm_rft_2925": 0.6358441114425659, "gsm_rft_10602": 0.6358441114425659, "math_train_counting_and_probability_177": 0.6358558535575867, "gsm_rft_4658": 0.6358941197395325, "gsm_train_15116": 0.6358941197395325, "gsm_rft_159": 0.6358941197395325, "gsm_rft_8546": 0.635918378829956, "math_train_prealgebra_481": 0.63603276014328, "gsm_rft_31436": 0.6360951662063599, "gsm_train_4155": 0.6366304755210876, "camel_17639": 0.6367021203041077, "aqua_rat_433": 0.6368019580841064, "camel_44766": 0.6371075510978699, "gsm_rft_32313": 0.63729327917099, "aqua_rat_11961": 0.6373504996299744, "camel_30556": 0.6373686790466309, "math_train_prealgebra_353": 0.6374697089195251, "camel_9043": 0.6375320553779602, "gsm_rft_27829": 0.6375641226768494, "camel_44723": 0.6375668048858643, "camel_20495": 0.6376582384109497, "gsm_train_29880": 0.6378281712532043, "gsm_rft_33076": 0.6378720998764038, "gsm_rft_6392": 0.6378720998764038, "gsm_rft_25665": 0.6380423903465271, "gsm_rft_9950": 0.6383838057518005, "gsm_rft_13006": 0.638469934463501, "gsm_rft_4268": 0.638551652431488, "gsm_rft_33771": 0.6386008858680725, "camel_26686": 0.6392202973365784, "math_train_counting_and_probability_669": 0.6393738985061646, "TheoremQA_maxku/cv-imageprocessing10-digital-image.json": 0.6397687196731567, "gsm_rft_8475": 0.6407014727592468, "gsm_rft_9475": 0.6409822702407837, "gsm_train_31313": 0.6411181688308716, "gsm_rft_3386": 0.6411181688308716, "gsm_rft_10080": 0.6416476964950562, "gsm_train_7585": 0.6416476964950562, "camel_17618": 0.642193078994751, "gsm_rft_17952": 0.6424766778945923, "camel_31864": 0.6425406336784363, "aqua_rat_34528": 0.6428595185279846, "gsm_rft_21580": 0.6435400247573853, "gsm_rft_10682": 0.643894374370575, "aqua_rat_56916": 0.6445155739784241, "gsm_rft_32270": 0.644895613193512, "gsm_train_27467": 0.6449554562568665, "gsm_rft_11457": 0.6457356214523315, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0.6459230780601501, "camel_44750": 0.6462298631668091, "aqua_rat_84180": 0.6467359066009521, "camel_17654": 0.6467885375022888, "camel_37553": 0.6470005512237549, "aqua_rat_60927": 0.647098183631897, "camel_44755": 0.6475278735160828, "gsm_rft_29593": 0.6483175754547119, "camel_17637": 0.6486045122146606, "gsm_rft_7696": 0.6492185592651367, "aqua_rat_85106": 0.6502125263214111, "camel_18719": 0.6503145098686218, "camel_44749": 0.6507879495620728, "aqua_rat_33509": 0.6513051986694336, "aqua_rat_44305": 0.6513083577156067, "aqua_rat_6548": 0.651449978351593, "aqua_rat_75509": 0.6517249345779419, "gsm_rft_12896": 0.6522157192230225, "gsm_train_10809": 0.6522157192230225, "aqua_rat_38167": 0.6530244946479797, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.654042661190033, "camel_36754": 0.6546275615692139, "camel_44748": 0.6552435755729675, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.6569976210594177, "camel_31997": 0.6578177213668823, "aqua_rat_27312": 0.6589782238006592, "aqua_rat_84808": 0.6594015955924988, "aqua_rat_39106": 0.6595427393913269, "camel_44790": 0.6599723100662231, "math_train_counting_and_probability_5109": 0.6633492708206177, "aqua_rat_5820": 0.6656364798545837, "aqua_rat_86075": 0.666718602180481, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.6699565649032593, "camel_44728": 0.6707308292388916, "aqua_rat_229": 0.6747301816940308, "gsm_rft_24803": 0.6765654683113098, "gsm_train_35467": 0.6783036589622498, "gsm_rft_8013": 0.6801285743713379, "camel_19952": 0.6810963749885559, "TheoremQA_maxku/cv-cnn4.json": 0.6833011507987976, "camel_44798": 0.6990976333618164, "camel_17674": 0.730947732925415}, "TheoremQA_wenhuchen/t_test3.json": {"camel_9429": 0, "camel_8800": 0, "camel_8017": 0, "camel_8292": 0, "camel_8293": 0, "camel_8278": 0, "camel_8068": 0, "camel_8640": 0, "camel_8058": 0, "camel_8271": 0, "camel_8317": 0, "camel_8079": 0, "camel_8967": 0, "camel_9885": 0, "camel_8259": 0, "camel_8291": 0, "camel_8314": 0, "camel_8009": 0, "camel_8056": 0, "camel_8318": 0, "camel_8660": 0, "camel_8277": 0, "camel_8885": 0, "camel_8004": 0, "camel_8668": 0, "camel_8606": 0, "camel_8267": 0, "camel_9232": 0, "camel_8711": 0, "camel_8060": 0, "camel_8294": 0, "camel_8263": 0, "camel_8246": 0, "camel_8845": 0, "camel_8071": 0, "camel_8895": 0, "camel_8290": 0, "camel_8300": 0, "camel_8877": 0, "camel_8695": 0, "camel_8255": 0, "camel_8241": 0, "camel_8649": 0, "camel_8304": 0, "camel_8680": 0, "camel_8289": 0, "camel_8301": 0, "camel_8706": 0, "camel_8934": 0, "camel_8248": 0, "camel_8682": 0, "camel_8688": 0, "camel_8874": 0, "camel_8273": 0, "camel_9223": 0, "camel_8251": 0, "camel_8287": 0, "camel_8282": 0, "camel_9216": 0, "camel_9389": 0, "camel_8667": 0, "camel_8920": 0, "camel_9971": 0, "camel_8670": 0, "camel_8270": 0, "camel_9863": 0, "camel_8298": 0, "camel_8258": 0, "camel_8857": 0, "camel_8817": 0, "camel_8814": 0, "camel_8831": 0, "camel_8587": 0, "camel_8647": 0, "camel_8297": 0, "camel_8871": 0, "camel_8665": 0, "camel_8676": 0, "camel_8286": 0, "camel_8836": 0, "camel_8805": 0, "camel_8802": 0, "camel_8842": 0, "camel_9242": 0, "camel_8654": 0, "camel_8661": 0, "camel_8030": 0, "camel_8849": 0, "camel_8245": 0, "camel_8872": 0, "camel_8873": 0, "camel_8837": 0, "camel_8261": 0, "camel_8851": 0, "camel_9410": 0, "TheoremQA_wenhuchen/t_test3.json": 0, "camel_8876": 0, "camel_8073": 0, "camel_8804": 0, "camel_8878": 0, "camel_8698": 0, "camel_8856": 0, "camel_8288": 0, "camel_8835": 0, "camel_8276": 0, "camel_8852": 0, "camel_8863": 0, "camel_8843": 0, "camel_8252": 0, "camel_8240": 0, "camel_8801": 0, "camel_8838": 0, "camel_8825": 0, "camel_8811": 0, "camel_8685": 0, "camel_8854": 0, "camel_8308": 0, "camel_8280": 0, "camel_8311": 0, "camel_8295": 0, "camel_9952": 0, "camel_8625": 0, "camel_8921": 0, "camel_8274": 0, "camel_8312": 0, "camel_8810": 0, "camel_8922": 0, "camel_8898": 0, "camel_8319": 0, "camel_8855": 0, "camel_9394": 0, "camel_9392": 0, "camel_8823": 0, "camel_8715": 0, "camel_8812": 0, "camel_8864": 0, "camel_8644": 0, "camel_8844": 0, "camel_8866": 0, "camel_8306": 0, "camel_8827": 0, "camel_8283": 0, "camel_8840": 0, "camel_8671": 0, "camel_8675": 0, "camel_8847": 0, "camel_8809": 0, "camel_8853": 0, "camel_8714": 0, "camel_8031": 0, "camel_8260": 0, "camel_8832": 0, "camel_8712": 0, "camel_8279": 0, "camel_9972": 0, "camel_8310": 0, "camel_8846": 0, "camel_8691": 0, "camel_8850": 0, "aqua_rat_77962": 0.7578819990158081, "gsm_rft_13521": 0.7583994269371033, "aqua_rat_74657": 0.7584867477416992, "aqua_rat_61463": 0.7584970593452454, "aqua_rat_29307": 0.7588499188423157, "aqua_rat_57972": 0.7593041658401489, "aqua_rat_53496": 0.759377121925354, "gsm_rft_3420": 0.7595546245574951, "aqua_rat_5525": 0.7599921822547913, "aqua_rat_22540": 0.7602874040603638, "aqua_rat_49899": 0.7606860995292664, "aqua_rat_74122": 0.7609156966209412, "aqua_rat_83416": 0.7609414458274841, "aqua_rat_19637": 0.7612518668174744, "aqua_rat_47539": 0.7616311311721802, "aqua_rat_43664": 0.7618032097816467, "aqua_rat_17334": 0.7618129849433899, "aqua_rat_32897": 0.7618728280067444, "aqua_rat_25412": 0.7633102536201477, "aqua_rat_44286": 0.7641337513923645, "gsm_rft_25670": 0.7643076777458191, "aqua_rat_53834": 0.764797031879425, "aqua_rat_52991": 0.764913022518158, "aqua_rat_13100": 0.764979898929596, "aqua_rat_26496": 0.7653132081031799, "aqua_rat_81541": 0.7657750844955444, "aqua_rat_33752": 0.7661253213882446, "aqua_rat_8459": 0.7663140296936035, "aqua_rat_8387": 0.76706862449646, "aqua_rat_81964": 0.7671427726745605, "aqua_rat_26096": 0.7679710984230042, "gsm_rft_22746": 0.7692738771438599, "gsm_rft_32557": 0.7692848443984985, "gsm_train_6762": 0.7692848443984985, "aqua_rat_63437": 0.7696806788444519, "aqua_rat_8925": 0.7727224826812744, "aqua_rat_26184": 0.7732084393501282, "camel_37940": 0.8151265382766724, "camel_37953": 0.815127968788147, "TheoremQA_wenhuchen/t_test1.json": 0.8266670107841492, "TheoremQA_wenhuchen/t_test2.json": 0.8514418005943298}, "TheoremQA_maxku/signalprocessing7-phaseshift.json": {"gsm_train_16343": 0.6666542291641235, "aqua_rat_37149": 0.6667835116386414, "gsm_rft_14155": 0.666789710521698, "aqua_rat_17632": 0.666803777217865, "aqua_rat_22639": 0.6668541431427002, "aqua_rat_77065": 0.6669830083847046, "aqua_rat_58763": 0.6670228242874146, "gsm_train_34617": 0.6670780777931213, "gsm_rft_8556": 0.6672883033752441, "gsm_rft_6748": 0.66745525598526, "gsm_rft_6303": 0.667477011680603, "gsm_rft_34546": 0.6674932837486267, "camel_39662": 0.6675038933753967, "aqua_rat_6431": 0.667586088180542, "aqua_rat_78710": 0.6677565574645996, "gsm_rft_13497": 0.6679186224937439, "aqua_rat_9346": 0.667930006980896, "gsm_rft_31227": 0.6679489016532898, "aqua_rat_13525": 0.6679511070251465, "gsm_train_29000": 0.6679673194885254, "gsm_rft_3672": 0.6679673194885254, "gsm_rft_33724": 0.6679700016975403, "aqua_rat_47970": 0.6680400371551514, "aqua_rat_58261": 0.6681102514266968, "gsm_rft_33075": 0.6681566834449768, "gsm_train_19844": 0.668354332447052, "gsm_rft_30193": 0.6683886647224426, "aqua_rat_38240": 0.6684175729751587, "aqua_rat_29068": 0.6684423089027405, "aqua_rat_24066": 0.6684543490409851, "gsm_rft_30037": 0.6685012578964233, "gsm_rft_12777": 0.6685144305229187, "aqua_rat_13506": 0.668552577495575, "gsm_rft_12244": 0.6685647368431091, "aqua_rat_39089": 0.668573796749115, "gsm_rft_16452": 0.6685798764228821, "gsm_rft_20873": 0.6685817241668701, "gsm_rft_34156": 0.6686192154884338, "aqua_rat_23767": 0.668644905090332, "aqua_rat_18701": 0.6688389182090759, "gsm_rft_34525": 0.6691249012947083, "gsm_rft_27609": 0.6691458821296692, "gsm_rft_18195": 0.6692340970039368, "aqua_rat_12451": 0.6692455410957336, "aqua_rat_77027": 0.6693716645240784, "gsm_rft_33875": 0.6694127321243286, "gsm_rft_33013": 0.6695451140403748, "gsm_rft_27987": 0.6695735454559326, "gsm_rft_33749": 0.6697110533714294, "gsm_rft_30318": 0.6698085069656372, "aqua_rat_38713": 0.6698914766311646, "aqua_rat_28251": 0.670011579990387, "gsm_rft_30683": 0.670045793056488, "gsm_train_8631": 0.6700695753097534, "aqua_rat_13282": 0.670189619064331, "aqua_rat_60485": 0.6702777743339539, "aqua_rat_48773": 0.6702857613563538, "aqua_rat_21336": 0.6703141331672668, "gsm_train_28366": 0.6704158782958984, "gsm_rft_21471": 0.6704158782958984, "aqua_rat_33164": 0.6706659197807312, "aqua_rat_55372": 0.670748233795166, "aqua_rat_88599": 0.6709529161453247, "aqua_rat_7739": 0.6710711717605591, "gsm_rft_30777": 0.6713485717773438, "gsm_rft_1898": 0.6713611483573914, "gsm_rft_2484": 0.6714717149734497, "gsm_train_15066": 0.6715929508209229, "gsm_rft_12096": 0.6716132164001465, "gsm_rft_21175": 0.6719138622283936, "aqua_rat_46532": 0.6720983386039734, "gsm_rft_17533": 0.6722182631492615, "gsm_rft_25625": 0.6722880005836487, "gsm_rft_9252": 0.6723236441612244, "aqua_rat_64411": 0.6724787354469299, "aqua_rat_40609": 0.6724870800971985, "aqua_rat_85445": 0.6726605892181396, "aqua_rat_22368": 0.6727352738380432, "gsm_rft_29590": 0.672743022441864, "gsm_rft_31756": 0.6727595329284668, "gsm_rft_3494": 0.6727787256240845, "gsm_rft_23806": 0.672902524471283, "gsm_rft_33243": 0.6730281710624695, "gsm_train_28946": 0.6730281710624695, "gsm_rft_30704": 0.6730281710624695, "gsm_rft_16323": 0.673149049282074, "gsm_rft_22292": 0.6733323335647583, "gsm_rft_30222": 0.6733736395835876, "aqua_rat_70646": 0.6734540462493896, "gsm_rft_30678": 0.6735203266143799, "aqua_rat_13865": 0.6735281348228455, "gsm_train_4036": 0.6735407114028931, "gsm_rft_26607": 0.6735724210739136, "gsm_train_33563": 0.6735724210739136, "gsm_rft_10606": 0.673575758934021, "gsm_rft_33601": 0.6737317442893982, "aqua_rat_10289": 0.6737506985664368, "aqua_rat_52279": 0.6737858653068542, "gsm_rft_32394": 0.6737993955612183, "gsm_train_16525": 0.6737993955612183, "gsm_rft_21714": 0.6738134622573853, "gsm_train_11962": 0.6738462448120117, "gsm_rft_15995": 0.6738462448120117, "gsm_rft_2757": 0.6745214462280273, "aqua_rat_36298": 0.674570620059967, "camel_39612": 0.6745888590812683, "gsm_rft_32000": 0.6751843094825745, "gsm_rft_25316": 0.6755006909370422, "aqua_rat_8641": 0.6755478382110596, "gsm_rft_4564": 0.6756996512413025, "aqua_rat_68007": 0.6759334802627563, "aqua_rat_4849": 0.6759868860244751, "gsm_train_32507": 0.6761266589164734, "gsm_rft_31408": 0.6761266589164734, "gsm_rft_4857": 0.676131546497345, "gsm_rft_12533": 0.6761336326599121, "gsm_rft_8901": 0.6763441562652588, "gsm_rft_194": 0.6764532923698425, "gsm_rft_15280": 0.6764541864395142, "gsm_rft_4810": 0.6765823364257812, "gsm_rft_33119": 0.6767367124557495, "gsm_rft_32943": 0.6767544746398926, "camel_21538": 0.6771588325500488, "TheoremQA_mingyin/stopping-time1.json": 0.6772462129592896, "aqua_rat_46482": 0.6780226230621338, "aqua_rat_19103": 0.6780542731285095, "gsm_rft_16096": 0.6780903935432434, "camel_39630": 0.6781222820281982, "gsm_rft_5095": 0.6782220602035522, "aqua_rat_56844": 0.6786156296730042, "gsm_rft_20259": 0.6787721514701843, "aqua_rat_39036": 0.678896427154541, "aqua_rat_62145": 0.6789734363555908, "aqua_rat_30853": 0.6793572902679443, "aqua_rat_55755": 0.6796778440475464, "gsm_rft_34909": 0.6802647113800049, "aqua_rat_53594": 0.6804683804512024, "aqua_rat_63857": 0.6807459592819214, "aqua_rat_24936": 0.6811442971229553, "gsm_rft_16210": 0.6811721324920654, "gsm_rft_31050": 0.6812061071395874, "gsm_rft_20390": 0.6813997626304626, "gsm_rft_22376": 0.6815304756164551, "aqua_rat_34189": 0.6817042827606201, "gsm_train_33933": 0.6817310452461243, "gsm_rft_25236": 0.6817310452461243, "gsm_rft_11916": 0.681780219078064, "gsm_rft_8423": 0.6819851398468018, "gsm_rft_6098": 0.682354211807251, "aqua_rat_62295": 0.6827722191810608, "aqua_rat_19140": 0.682899534702301, "gsm_rft_18699": 0.6838559508323669, "gsm_train_25536": 0.6838559508323669, "aqua_rat_83815": 0.6839282512664795, "gsm_rft_21477": 0.6842969059944153, "gsm_rft_32686": 0.6846414804458618, "aqua_rat_6661": 0.6849259734153748, "aqua_rat_46563": 0.6850873231887817, "aqua_rat_27395": 0.685299813747406, "aqua_rat_15711": 0.6857855916023254, "gsm_rft_7127": 0.6860256195068359, "gsm_rft_16105": 0.6864766478538513, "gsm_rft_11073": 0.686575710773468, "gsm_rft_26314": 0.6866666078567505, "gsm_train_34559": 0.6867838501930237, "gsm_rft_12248": 0.6868664622306824, "aqua_rat_72840": 0.6876179575920105, "aqua_rat_58094": 0.6878305077552795, "aqua_rat_51568": 0.6878514885902405, "gsm_rft_26024": 0.6883522272109985, "gsm_rft_5097": 0.6889451742172241, "aqua_rat_82468": 0.6891764998435974, "aqua_rat_24061": 0.6893118023872375, "gsm_rft_3279": 0.6898220181465149, "aqua_rat_5982": 0.6899393200874329, "gsm_rft_10411": 0.6901784539222717, "camel_39614": 0.6904149055480957, "aqua_rat_55368": 0.6904776096343994, "aqua_rat_28973": 0.6905649900436401, "gsm_rft_11262": 0.6906919479370117, "aqua_rat_82581": 0.6908083558082581, "aqua_rat_62536": 0.6919634938240051, "gsm_rft_33198": 0.6938092708587646, "gsm_rft_30221": 0.6949277520179749, "aqua_rat_68610": 0.6969041228294373, "aqua_rat_64383": 0.6978286504745483, "aqua_rat_48775": 0.6978493332862854, "aqua_rat_86211": 0.6978604793548584, "gsm_rft_27803": 0.6978968977928162, "gsm_train_9826": 0.6980627775192261, "aqua_rat_3469": 0.6990121006965637, "gsm_rft_14862": 0.6991396546363831, "aqua_rat_86315": 0.7065163850784302, "camel_39625": 0.7110381126403809, "aqua_rat_22859": 0.7122364640235901, "aqua_rat_60661": 0.7148580551147461, "aqua_rat_9358": 0.7167152166366577, "aqua_rat_34688": 0.7169308066368103, "camel_36286": 0.7221471667289734, "aqua_rat_33141": 0.7223047614097595}, "TheoremQA_xinyi/sum_product_algorithm.json": {"camel_23380": 0, "camel_23620": 0, "camel_22817": 0, "camel_23610": 0, "camel_23374": 0, "camel_23141": 0, "camel_23192": 0, "camel_23389": 0, "camel_22818": 0, "camel_22834": 0, "camel_22802": 0, "camel_22858": 0, "camel_21107": 0, "camel_22320": 0, "camel_22443": 0, "camel_23431": 0, "camel_23367": 0, "camel_22353": 0, "camel_23679": 0, "camel_23411": 0, "camel_23438": 0, "camel_23382": 0, "camel_22327": 0, "camel_22396": 0, "camel_22850": 0, "camel_21083": 0, "camel_23150": 0, "camel_22859": 0, "camel_22359": 0, "camel_23184": 0, "camel_22157": 0, "camel_22844": 0, "camel_23124": 0, "camel_22821": 0, "camel_23148": 0, "camel_21100": 0, "camel_23403": 0, "camel_23426": 0, "camel_22813": 0, "camel_23146": 0, "camel_22061": 0, "camel_22170": 0, "camel_22839": 0, "camel_23371": 0, "camel_23378": 0, "camel_22861": 0, "camel_22872": 0, "camel_23424": 0, "camel_22875": 0, "camel_22840": 0, "camel_22835": 0, "camel_23425": 0, "camel_23934": 0, "camel_23372": 0, "camel_22391": 0, "camel_23402": 0, "camel_23159": 0, "camel_22825": 0, "camel_23161": 0, "camel_22339": 0, "camel_23387": 0, "camel_22374": 0, "camel_23125": 0, "camel_23408": 0, "camel_22376": 0, "camel_22809": 0, "camel_22829": 0, "camel_23157": 0, "camel_23661": 0, "camel_23404": 0, "camel_23608": 0, "camel_22377": 0, "camel_23165": 0, "camel_23604": 0, "camel_22417": 0, "camel_23177": 0, "camel_22329": 0, "camel_23642": 0, "camel_23154": 0, "camel_23672": 0, "camel_22068": 0, "camel_22871": 0, "camel_23152": 0, "camel_23397": 0, "camel_23129": 0, "camel_21057": 0, "camel_22845": 0, "camel_22369": 0, "camel_22878": 0, "camel_23139": 0, "camel_23400": 0, "camel_22820": 0, "camel_23410": 0, "camel_22810": 0, "camel_22383": 0, "camel_23432": 0, "camel_22333": 0, "camel_22853": 0, "camel_22808": 0, "camel_23131": 0, "camel_22338": 0, "camel_22801": 0, "camel_22393": 0, "camel_22379": 0, "camel_22847": 0, "camel_22849": 0, "camel_22356": 0, "camel_22868": 0, "camel_22361": 0, "camel_22812": 0, "camel_22381": 0, "camel_22876": 0, "camel_22855": 0, "camel_22398": 0, "camel_22857": 0, "camel_22806": 0, "camel_23132": 0, "camel_22384": 0, "camel_23172": 0, "camel_22826": 0, "camel_23394": 0, "camel_22364": 0, "camel_23624": 0, "camel_22807": 0, "camel_22866": 0, "camel_22378": 0, "camel_22382": 0, "camel_22819": 0, "camel_23182": 0, "camel_22824": 0, "camel_22392": 0, "camel_22345": 0, "camel_22322": 0, "camel_22841": 0, "camel_22860": 0, "camel_22879": 0, "camel_23135": 0, "camel_23363": 0, "camel_23617": 0, "camel_22843": 0, "camel_23423": 0, "camel_23430": 0, "camel_23609": 0, "camel_22805": 0, "camel_22373": 0, "camel_23189": 0, "camel_22814": 0, "camel_22803": 0, "camel_22838": 0, "camel_22823": 0, "camel_22837": 0, "camel_22397": 0, "camel_22862": 0, "camel_22362": 0, "camel_22811": 0, "camel_22816": 0, "camel_23196": 0, "camel_22863": 0, "camel_23392": 0, "camel_22335": 0, "camel_22334": 0, "camel_23158": 0, "TheoremQA_xinyi/sum_product_algorithm.json": 0, "camel_22387": 0, "camel_21044": 0, "camel_22870": 0, "camel_22380": 0, "camel_22352": 0, "camel_23386": 0, "camel_22873": 0, "camel_23164": 0, "camel_22854": 0, "camel_22940": 0, "camel_23144": 0, "camel_22375": 0, "camel_22867": 0, "camel_22865": 0, "camel_23971": 0, "camel_22836": 0, "camel_23391": 0, "camel_22804": 0, "camel_23181": 0, "camel_22864": 0, "camel_22328": 0, "camel_23379": 0, "camel_23127": 0, "camel_22832": 0, "camel_22360": 0, "camel_23174": 0, "camel_23393": 0, "camel_23193": 0, "camel_23364": 0, "camel_22828": 0, "camel_18365": 0.6728687882423401, "camel_38561": 0.6773362755775452, "TheoremQA_maxku/graphtheory7-shortestpath.json": 0.6802111864089966, "camel_38586": 0.6882697939872742, "TheoremQA_xinyi/dag_3.json": 0.6921364068984985, "TheoremQA_maxku/ipnetwork21-ip-2.json": 0.6984086036682129, "TheoremQA_xinyi/dag_1.json": 0.7037729620933533}, "TheoremQA_jianyu_xu/Binomial_4.json": {"camel_20074": 0, "camel_21419": 0, "camel_21267": 0, "camel_21379": 0, "camel_20930": 0, "camel_20530": 0, "camel_20312": 0, "camel_21022": 0, "camel_20293": 0, "camel_20255": 0, "camel_20271": 0, "camel_20382": 0, "camel_20593": 0, "camel_21081": 0, "camel_21527": 0, "camel_21563": 0, "camel_20394": 0, "camel_21549": 0, "camel_20298": 0, "camel_21251": 0, "camel_21395": 0, "camel_21213": 0, "camel_20364": 0, "camel_21230": 0, "camel_21429": 0, "camel_21808": 0, "camel_21363": 0, "camel_20984": 0, "camel_20240": 0, "camel_20611": 0, "camel_20344": 0, "camel_21034": 0, "camel_21236": 0, "camel_21371": 0, "camel_20599": 0, "camel_20802": 0, "camel_21386": 0, "camel_21572": 0, "camel_20397": 0, "camel_20378": 0, "camel_20348": 0, "camel_20598": 0, "camel_21528": 0, "camel_21005": 0, "camel_21039": 0, "camel_20749": 0, "aqua_rat_6023": 0.8153937458992004, "aqua_rat_71649": 0.815420925617218, "aqua_rat_48671": 0.8155068159103394, "aqua_rat_11651": 0.8157645463943481, "aqua_rat_12697": 0.8160015344619751, "aqua_rat_14562": 0.8160257339477539, "math_train_counting_and_probability_447": 0.8161712288856506, "aqua_rat_72479": 0.8163245916366577, "aqua_rat_78830": 0.8163880109786987, "aqua_rat_67179": 0.8164038062095642, "aqua_rat_37162": 0.816620945930481, "aqua_rat_71578": 0.8166980147361755, "aqua_rat_64485": 0.8169245719909668, "aqua_rat_84736": 0.8171308040618896, "aqua_rat_81548": 0.8177216649055481, "aqua_rat_52832": 0.8180335760116577, "aqua_rat_29513": 0.8181140422821045, "math_train_counting_and_probability_444": 0.8181193470954895, "aqua_rat_15730": 0.8181948065757751, "aqua_rat_81265": 0.8182904124259949, "aqua_rat_61775": 0.8182997107505798, "aqua_rat_78074": 0.818329930305481, "aqua_rat_82553": 0.8190051317214966, "aqua_rat_73365": 0.8190107941627502, "aqua_rat_34245": 0.8191825747489929, "aqua_rat_63963": 0.8193069696426392, "aqua_rat_20113": 0.8194711208343506, "aqua_rat_37357": 0.8195440769195557, "aqua_rat_13414": 0.8197236061096191, "aqua_rat_60998": 0.8198625445365906, "aqua_rat_37479": 0.8200435638427734, "aqua_rat_74719": 0.8200500011444092, "math_train_counting_and_probability_226": 0.8201097846031189, "aqua_rat_27128": 0.8204345107078552, "aqua_rat_58309": 0.820734441280365, "aqua_rat_10394": 0.8209025263786316, "aqua_rat_34318": 0.8209075927734375, "aqua_rat_79193": 0.8211974501609802, "aqua_rat_42333": 0.8216205835342407, "aqua_rat_14884": 0.821679949760437, "aqua_rat_60755": 0.822029709815979, "aqua_rat_70526": 0.8220958113670349, "aqua_rat_20722": 0.8222962021827698, "math_train_counting_and_probability_753": 0.8224331140518188, "aqua_rat_37993": 0.8225122690200806, "math_train_counting_and_probability_249": 0.8225619792938232, "math_test_counting_and_probability_190": 0.8225709199905396, "math_test_counting_and_probability_80": 0.8227978944778442, "aqua_rat_56939": 0.8229662775993347, "aqua_rat_69384": 0.8233336806297302, "aqua_rat_66240": 0.8233994841575623, "aqua_rat_73601": 0.8237149715423584, "aqua_rat_86468": 0.8237884640693665, "aqua_rat_76271": 0.8238059282302856, "aqua_rat_78895": 0.8242412805557251, "aqua_rat_87094": 0.8244718909263611, "aqua_rat_43879": 0.8245364427566528, "aqua_rat_25933": 0.8247241973876953, "math_test_counting_and_probability_384": 0.8247861862182617, "aqua_rat_59702": 0.8248728513717651, "aqua_rat_30172": 0.824897050857544, "math_train_counting_and_probability_417": 0.8253685832023621, "aqua_rat_39411": 0.8254105448722839, "aqua_rat_58323": 0.825610339641571, "aqua_rat_57693": 0.8259711265563965, "aqua_rat_53467": 0.8259758949279785, "aqua_rat_42177": 0.8259832859039307, "aqua_rat_51559": 0.8261472582817078, "aqua_rat_83206": 0.826196551322937, "aqua_rat_85599": 0.8262512683868408, "aqua_rat_41506": 0.8263663053512573, "aqua_rat_5288": 0.8264040350914001, "aqua_rat_57246": 0.8265261054039001, "aqua_rat_9536": 0.8266562223434448, "aqua_rat_72210": 0.8267459869384766, "aqua_rat_24582": 0.8269253373146057, "aqua_rat_74651": 0.8270889520645142, "aqua_rat_15343": 0.8270928859710693, "aqua_rat_32212": 0.827382504940033, "aqua_rat_68946": 0.8275933861732483, "aqua_rat_16780": 0.8276975154876709, "aqua_rat_31768": 0.8279274702072144, "aqua_rat_27717": 0.8279877305030823, "aqua_rat_9182": 0.8281109929084778, "aqua_rat_68213": 0.828179657459259, "aqua_rat_34272": 0.8282506465911865, "math_train_counting_and_probability_445": 0.828616738319397, "aqua_rat_42155": 0.82871413230896, "aqua_rat_29257": 0.8287178874015808, "aqua_rat_8673": 0.82902592420578, "aqua_rat_24776": 0.8290905952453613, "math_train_counting_and_probability_437": 0.8292054533958435, "aqua_rat_72708": 0.8292768597602844, "aqua_rat_77361": 0.8292985558509827, "math_train_counting_and_probability_562": 0.8294836282730103, "aqua_rat_68198": 0.8298475742340088, "aqua_rat_19534": 0.8303564786911011, "aqua_rat_3870": 0.8303918242454529, "aqua_rat_38314": 0.8307370543479919, "aqua_rat_87775": 0.83074951171875, "math_test_counting_and_probability_107": 0.8308246731758118, "aqua_rat_9556": 0.8311321139335632, "aqua_rat_7086": 0.8311436772346497, "aqua_rat_25085": 0.8315455317497253, "aqua_rat_82511": 0.831581175327301, "aqua_rat_18760": 0.8316726088523865, "aqua_rat_14483": 0.8317984938621521, "aqua_rat_53149": 0.8318646550178528, "aqua_rat_33533": 0.8320896625518799, "aqua_rat_50043": 0.8321512937545776, "aqua_rat_22507": 0.8322969675064087, "aqua_rat_74949": 0.8324652314186096, "aqua_rat_14281": 0.8326732516288757, "aqua_rat_22077": 0.8328211903572083, "aqua_rat_53395": 0.8329026699066162, "aqua_rat_89064": 0.83302241563797, "aqua_rat_62645": 0.8332762718200684, "aqua_rat_89175": 0.8334895968437195, "aqua_rat_29967": 0.8335505127906799, "aqua_rat_85174": 0.8338013887405396, "aqua_rat_65642": 0.8339138031005859, "aqua_rat_35900": 0.8346685171127319, "aqua_rat_32732": 0.8352611064910889, "aqua_rat_13918": 0.8354809880256653, "camel_38505": 0.8356100916862488, "aqua_rat_78732": 0.8356414437294006, "aqua_rat_10102": 0.8357305526733398, "aqua_rat_42746": 0.8364203572273254, "aqua_rat_53921": 0.8366987109184265, "aqua_rat_44712": 0.8373866081237793, "aqua_rat_62903": 0.8379930853843689, "aqua_rat_81170": 0.8379990458488464, "aqua_rat_17487": 0.8384506702423096, "aqua_rat_66841": 0.8386294841766357, "math_train_counting_and_probability_929": 0.8394109606742859, "aqua_rat_30648": 0.8399495482444763, "aqua_rat_71336": 0.8419066071510315, "camel_38493": 0.8428083658218384, "TheoremQA_jianyu_xu/Multinomial_2.json": 0.8428149819374084, "aqua_rat_8436": 0.8432294130325317, "aqua_rat_41430": 0.8462764620780945, "aqua_rat_70803": 0.8491500616073608, "math_train_counting_and_probability_961": 0.8492144346237183, "math_train_counting_and_probability_236": 0.8503221869468689, "aqua_rat_30109": 0.8505728840827942, "aqua_rat_28538": 0.8522374033927917, "aqua_rat_81997": 0.8534932136535645, "aqua_rat_49270": 0.8550388813018799, "aqua_rat_15615": 0.855162501335144, "aqua_rat_52092": 0.8563618063926697, "aqua_rat_70861": 0.8609126806259155, "aqua_rat_64131": 0.8636572360992432, "aqua_rat_42445": 0.8641644716262817, "math_train_counting_and_probability_338": 0.8670511245727539}, "TheoremQA_maxku/fourier6-FT.json": {"camel_45931": 0, "camel_45701": 0, "camel_45736": 0, "camel_45693": 0, "camel_45725": 0, "camel_44838": 0, "camel_45698": 0, "camel_45754": 0, "camel_45709": 0, "camel_28722": 0.6267601847648621, "aqua_rat_31136": 0.6268227696418762, "camel_29491": 0.6268759369850159, "camel_28559": 0.627052366733551, "camel_28863": 0.6270555257797241, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.6271357536315918, "camel_29142": 0.6273425817489624, "camel_28439": 0.6273553967475891, "aqua_rat_85407": 0.6274501085281372, "gsm_rft_1787": 0.6275172829627991, "camel_30423": 0.6277828216552734, "camel_29899": 0.6278603076934814, "camel_29821": 0.6278693079948425, "camel_29925": 0.6279217004776001, "camel_28803": 0.6281986832618713, "camel_28746": 0.6283332109451294, "camel_29877": 0.6284176707267761, "camel_26483": 0.6284958720207214, "camel_29969": 0.6286218762397766, "camel_28528": 0.6288275122642517, "camel_29281": 0.628928005695343, "gsm_rft_6507": 0.6291229128837585, "camel_29374": 0.6293274760246277, "camel_28773": 0.6294848918914795, "camel_30939": 0.6295145153999329, "TheoremQA_maxku/signalprocessing19-period.json": 0.629676103591919, "camel_29830": 0.6297026872634888, "aqua_rat_23666": 0.6301997900009155, "camel_5303": 0.6305351257324219, "camel_29692": 0.6308426260948181, "camel_29355": 0.6311079263687134, "camel_29078": 0.6312058568000793, "camel_29845": 0.6315615773200989, "camel_28874": 0.6315930485725403, "gsm_rft_7314": 0.6322479844093323, "camel_28081": 0.6323033571243286, "camel_28397": 0.6323858499526978, "camel_28500": 0.6325494647026062, "aqua_rat_41243": 0.6325846910476685, "aqua_rat_54913": 0.632804274559021, "camel_28487": 0.6328164935112, "camel_29102": 0.6328760981559753, "camel_31323": 0.6332078576087952, "math_train_counting_and_probability_708": 0.6332617402076721, "aqua_rat_43133": 0.6334646344184875, "camel_31497": 0.6335501074790955, "aqua_rat_66272": 0.6336013078689575, "camel_28835": 0.6336487531661987, "camel_29708": 0.6337218880653381, "camel_29407": 0.633759081363678, "camel_29730": 0.6339629888534546, "camel_29948": 0.6341062784194946, "camel_28836": 0.6344409584999084, "camel_47819": 0.6344795227050781, "camel_30959": 0.6345537900924683, "aqua_rat_82251": 0.6348527073860168, "camel_28793": 0.6351513266563416, "camel_28802": 0.6352735757827759, "aqua_rat_31017": 0.6352891325950623, "gsm_rft_12368": 0.6356945633888245, "camel_26519": 0.6358403563499451, "camel_28511": 0.6358974575996399, "gsm_rft_31824": 0.6361349821090698, "gsm_train_34237": 0.6361349821090698, "aqua_rat_87692": 0.6363235116004944, "camel_28761": 0.636328935623169, "camel_28384": 0.6363933086395264, "aqua_rat_88322": 0.6365479230880737, "camel_26484": 0.636570155620575, "camel_36298": 0.6366633176803589, "gsm_rft_17859": 0.637068510055542, "math_train_number_theory_803": 0.6370696425437927, "gsm_train_6184": 0.6374869346618652, "aqua_rat_32099": 0.6375437378883362, "camel_28776": 0.6380015015602112, "gsm_rft_29423": 0.6381243467330933, "camel_29510": 0.6382412910461426, "gsm_rft_19613": 0.638455331325531, "camel_31174": 0.6388124227523804, "camel_28532": 0.6388383507728577, "camel_28382": 0.6388810276985168, "gsm_rft_11538": 0.6389498114585876, "gsm_train_23103": 0.6389498114585876, "gsm_rft_34026": 0.6389639377593994, "camel_28851": 0.6390330195426941, "camel_29184": 0.6390823125839233, "camel_29773": 0.6392034292221069, "camel_47766": 0.6393586993217468, "gsm_rft_14072": 0.6396248936653137, "camel_28502": 0.6400458812713623, "camel_28821": 0.6400978565216064, "camel_28348": 0.6403422355651855, "camel_29438": 0.6408953070640564, "camel_28946": 0.6411429643630981, "camel_28768": 0.641658365726471, "math_train_algebra_1978": 0.6418131589889526, "camel_28520": 0.6423859596252441, "camel_29298": 0.6426640748977661, "camel_28357": 0.642688512802124, "camel_29695": 0.6427500247955322, "aqua_rat_74037": 0.6428356766700745, "gsm_train_2018": 0.6433401107788086, "camel_28430": 0.6437135934829712, "gsm_rft_18389": 0.6438373327255249, "camel_47815": 0.6438412070274353, "camel_29684": 0.6438902616500854, "camel_30474": 0.644346296787262, "camel_28752": 0.6445215940475464, "camel_29364": 0.6445460319519043, "camel_28815": 0.6445493698120117, "camel_29816": 0.6446762084960938, "camel_29741": 0.6449417471885681, "camel_29971": 0.6449549198150635, "camel_29798": 0.6454408168792725, "camel_28492": 0.6460041999816895, "camel_28789": 0.6461706757545471, "camel_28795": 0.6472569704055786, "camel_29832": 0.6473033428192139, "gsm_rft_22956": 0.647626519203186, "camel_29752": 0.647675096988678, "camel_29429": 0.6478211879730225, "camel_28869": 0.6482244729995728, "camel_29121": 0.6493697762489319, "aqua_rat_83588": 0.6494057178497314, "camel_28791": 0.6497528553009033, "camel_28731": 0.6497640609741211, "camel_29947": 0.6498802900314331, "camel_28733": 0.6506001353263855, "camel_29371": 0.6506478190422058, "camel_28760": 0.6510587334632874, "camel_29719": 0.6510787606239319, "aqua_rat_38893": 0.6517986059188843, "aqua_rat_17846": 0.6520096063613892, "camel_29780": 0.6524979472160339, "camel_29373": 0.6531661152839661, "camel_28407": 0.6535888314247131, "camel_29681": 0.6542332172393799, "aqua_rat_87477": 0.6545825004577637, "aqua_rat_31483": 0.6545892357826233, "aqua_rat_63345": 0.6547548770904541, "camel_29388": 0.655093789100647, "camel_28779": 0.6551428437232971, "camel_29762": 0.6553962826728821, "camel_36290": 0.6571804881095886, "camel_29799": 0.6572297811508179, "gsm_rft_21298": 0.6578660011291504, "gsm_train_20944": 0.6578660011291504, "camel_28723": 0.6583812832832336, "aqua_rat_73496": 0.6584833264350891, "aqua_rat_14595": 0.6586490869522095, "camel_28787": 0.6593223810195923, "camel_29727": 0.6594235897064209, "camel_29790": 0.6597143411636353, "camel_28780": 0.6597380042076111, "camel_28737": 0.659808337688446, "camel_29370": 0.6598631143569946, "camel_28794": 0.6598899960517883, "camel_29836": 0.6599286794662476, "math_test_counting_and_probability_883": 0.6600309610366821, "camel_29734": 0.6604635119438171, "gsm_rft_11471": 0.6606100797653198, "camel_26505": 0.660635769367218, "gsm_rft_33863": 0.6609274744987488, "camel_29984": 0.6610662937164307, "camel_28751": 0.6623964309692383, "camel_29321": 0.6628369688987732, "aqua_rat_60208": 0.663102924823761, "camel_29810": 0.6639186143875122, "camel_28759": 0.6640086770057678, "aqua_rat_5850": 0.664260745048523, "camel_28740": 0.6671276092529297, "camel_47769": 0.6676782965660095, "camel_28838": 0.6679967641830444, "camel_28137": 0.6688981056213379, "camel_29467": 0.6700421571731567, "aqua_rat_31772": 0.6709257364273071, "camel_28404": 0.671681821346283, "camel_29704": 0.672122061252594, "camel_28753": 0.6728397607803345, "camel_29305": 0.6734380125999451, "camel_28736": 0.6746319532394409, "camel_29046": 0.6751070022583008, "camel_28379": 0.6751431822776794, "aqua_rat_73398": 0.6767017841339111, "camel_29060": 0.6775749921798706, "camel_28785": 0.677655041217804, "camel_28754": 0.6815916299819946, "camel_28765": 0.6863678097724915, "camel_28744": 0.6910321712493896, "camel_26497": 0.6935322880744934, "camel_26554": 0.6993402242660522}, "TheoremQA_xinyi/neural_networks.json": {"TheoremQA_xinyi/neural_networks.json": 0, "camel_29635": 0.6116374731063843, "camel_29596": 0.6117019057273865, "camel_29295": 0.6117613315582275, "camel_28803": 0.6118513941764832, "camel_29756": 0.6118563413619995, "camel_28434": 0.6119060516357422, "camel_29935": 0.6119914054870605, "camel_29613": 0.6120468378067017, "camel_29827": 0.6120853424072266, "camel_29243": 0.6121132373809814, "camel_29345": 0.6122484803199768, "camel_29299": 0.6122839450836182, "camel_28648": 0.6122905611991882, "camel_29832": 0.6123012900352478, "camel_29888": 0.6125198006629944, "camel_29085": 0.6125220656394958, "camel_29316": 0.6126627922058105, "camel_29755": 0.612801194190979, "camel_29949": 0.6128860116004944, "camel_28771": 0.6129003763198853, "camel_29918": 0.6129014492034912, "camel_29346": 0.612951934337616, "camel_29881": 0.6130533814430237, "camel_29310": 0.6131284832954407, "camel_29623": 0.613183319568634, "camel_29992": 0.6133323907852173, "camel_28830": 0.6134786009788513, "camel_29825": 0.6134797930717468, "camel_29790": 0.6134995222091675, "camel_18936": 0.613512396812439, "camel_29791": 0.6135717034339905, "camel_29759": 0.6138395071029663, "camel_28775": 0.6140760183334351, "camel_29971": 0.6142585873603821, "camel_28491": 0.6147593855857849, "camel_29997": 0.6149343848228455, "camel_29429": 0.6149423718452454, "camel_29568": 0.6150396466255188, "camel_29532": 0.6151374578475952, "camel_29658": 0.6151822805404663, "camel_18885": 0.6152386665344238, "camel_29708": 0.6152915358543396, "camel_29256": 0.6154000163078308, "camel_29959": 0.615442156791687, "camel_29649": 0.6155270338058472, "camel_28723": 0.6157049536705017, "camel_29975": 0.6158052682876587, "camel_28747": 0.6159135699272156, "camel_28145": 0.6160673499107361, "camel_29580": 0.6161796450614929, "camel_29740": 0.6162134408950806, "camel_29916": 0.6163267493247986, "camel_29563": 0.6164140105247498, "camel_29694": 0.6166553497314453, "camel_29374": 0.6166645288467407, "camel_28787": 0.6167402267456055, "camel_28780": 0.6167623996734619, "camel_29141": 0.6167899370193481, "camel_29650": 0.6169649362564087, "camel_29217": 0.6169784665107727, "camel_29278": 0.6170833110809326, "TheoremQA_elainewan/math_algebra_6.json": 0.6171355843544006, "camel_29491": 0.6171437501907349, "camel_29060": 0.6172818541526794, "camel_29739": 0.6172974705696106, "camel_28086": 0.6173582077026367, "camel_28384": 0.6174256801605225, "camel_29624": 0.6174637079238892, "camel_29305": 0.6174739003181458, "camel_29722": 0.6175310015678406, "camel_29612": 0.6175383925437927, "camel_29732": 0.6176976561546326, "camel_29799": 0.6178101301193237, "camel_29845": 0.6179479360580444, "camel_28848": 0.6180307269096375, "camel_29675": 0.6180613040924072, "camel_28465": 0.6181132793426514, "camel_29878": 0.618452250957489, "camel_28404": 0.6185503602027893, "camel_29604": 0.618590772151947, "camel_28773": 0.6187725067138672, "camel_28379": 0.6190454959869385, "camel_29987": 0.619051992893219, "camel_29730": 0.6190699934959412, "camel_29670": 0.6191700100898743, "camel_29907": 0.61921626329422, "camel_29823": 0.6192780137062073, "camel_28791": 0.6194542050361633, "camel_28801": 0.6194833517074585, "camel_29326": 0.6200160980224609, "camel_29697": 0.6200740337371826, "camel_29692": 0.6202367544174194, "camel_29151": 0.6202670335769653, "camel_29922": 0.6204042434692383, "camel_37551": 0.6206670999526978, "camel_29630": 0.6206691861152649, "camel_29802": 0.6208903193473816, "camel_29438": 0.6211293339729309, "camel_28479": 0.6215668320655823, "camel_29619": 0.6216124296188354, "camel_29920": 0.6216565370559692, "camel_29664": 0.6218796968460083, "camel_29341": 0.6219982504844666, "camel_29541": 0.6221126914024353, "camel_29787": 0.6222176551818848, "camel_9228": 0.6224962472915649, "camel_29894": 0.6226022243499756, "camel_29705": 0.622622013092041, "camel_29388": 0.6231728792190552, "camel_29978": 0.6231822371482849, "camel_29050": 0.6234477162361145, "camel_29686": 0.6237435936927795, "camel_29334": 0.6237466931343079, "camel_29232": 0.6241467595100403, "camel_28733": 0.6242088675498962, "camel_29275": 0.6242205500602722, "camel_29602": 0.6244115233421326, "camel_28794": 0.6247269511222839, "camel_36502": 0.6250467300415039, "camel_29691": 0.6251222491264343, "camel_29121": 0.6251777410507202, "camel_29350": 0.625225841999054, "camel_29340": 0.6252737045288086, "camel_29711": 0.6254174709320068, "camel_28805": 0.625477135181427, "camel_29549": 0.6259675621986389, "camel_29609": 0.6260040402412415, "camel_29052": 0.6260674595832825, "camel_29651": 0.6262835264205933, "camel_29734": 0.6262968182563782, "camel_29298": 0.6266323924064636, "camel_28869": 0.6269353628158569, "camel_29322": 0.6269568204879761, "camel_28520": 0.6269645690917969, "camel_29220": 0.6277426481246948, "camel_29088": 0.6278128623962402, "camel_29210": 0.6279212236404419, "camel_29704": 0.6279422044754028, "camel_29204": 0.6280694007873535, "camel_29343": 0.628140389919281, "camel_29700": 0.6282942891120911, "camel_36936": 0.6284493207931519, "camel_29370": 0.6284496188163757, "camel_28722": 0.6287364959716797, "camel_29235": 0.6288642287254333, "camel_29132": 0.6289230585098267, "camel_29249": 0.629145622253418, "camel_29255": 0.6293447017669678, "camel_17394": 0.629449725151062, "camel_29270": 0.6295055150985718, "camel_29162": 0.6297045946121216, "camel_29287": 0.6300567984580994, "camel_29234": 0.6300593018531799, "camel_29224": 0.6302070617675781, "camel_29321": 0.630284309387207, "camel_29215": 0.6310260891914368, "camel_29229": 0.6310583353042603, "camel_29693": 0.6310684680938721, "camel_29337": 0.6315001249313354, "camel_29752": 0.6320134401321411, "camel_29244": 0.6321391463279724, "camel_29301": 0.6322184205055237, "camel_29216": 0.6326219439506531, "camel_29407": 0.6329547166824341, "camel_29338": 0.6331120133399963, "camel_29716": 0.6333397626876831, "camel_29737": 0.6334006786346436, "camel_29753": 0.6334284543991089, "camel_29726": 0.6336808204650879, "camel_29271": 0.6338334083557129, "camel_29329": 0.6338616609573364, "camel_28754": 0.6339219212532043, "camel_29205": 0.6343533396720886, "camel_29277": 0.634614109992981, "camel_29684": 0.6346498727798462, "camel_29265": 0.6353484392166138, "camel_29327": 0.6364712119102478, "camel_29746": 0.6369010210037231, "camel_29228": 0.6378268003463745, "camel_29284": 0.6381407380104065, "camel_29279": 0.6382745504379272, "camel_29245": 0.6386051774024963, "camel_29328": 0.6390359997749329, "camel_29274": 0.6394429802894592, "camel_29222": 0.639702320098877, "camel_29257": 0.6411417126655579, "camel_29727": 0.6418415307998657, "camel_29288": 0.6419391632080078, "camel_29272": 0.643578052520752, "camel_29741": 0.6436457633972168, "camel_29721": 0.645121693611145, "camel_29682": 0.6453388333320618, "camel_29695": 0.6461119055747986, "camel_29227": 0.6465614438056946, "camel_29749": 0.6488469839096069, "camel_29251": 0.6514081954956055, "camel_29240": 0.6518932580947876, "camel_29276": 0.6556142568588257, "camel_29719": 0.6560221910476685}, "TheoremQA_xinyi/kernel_1.json": {"TheoremQA_xinyi/kernel_1.json": 0, "aqua_rat_5808": 0.6351050734519958, "camel_36456": 0.6353322863578796, "aqua_rat_73351": 0.6353468298912048, "camel_37910": 0.6353801488876343, "camel_37182": 0.6354068517684937, "camel_36827": 0.6354218125343323, "camel_8229": 0.635492742061615, "camel_9295": 0.6355822682380676, "camel_17618": 0.6356750726699829, "camel_9219": 0.6358216404914856, "camel_8227": 0.6358407735824585, "camel_9214": 0.6358596086502075, "camel_8175": 0.6359784007072449, "camel_9206": 0.6360459923744202, "camel_36858": 0.6361038684844971, "aqua_rat_84082": 0.6361477971076965, "camel_36595": 0.6361612677574158, "aqua_rat_33723": 0.636205792427063, "aqua_rat_39472": 0.6362252235412598, "camel_36422": 0.6362799406051636, "aqua_rat_96": 0.6364030241966248, "camel_8230": 0.6366023421287537, "camel_8972": 0.6366333961486816, "aqua_rat_60381": 0.636671781539917, "camel_9029": 0.6366739273071289, "aqua_rat_87883": 0.6368194818496704, "camel_40840": 0.6368592381477356, "camel_9153": 0.636958122253418, "camel_37902": 0.6369646191596985, "camel_8204": 0.6370142698287964, "camel_36458": 0.6371403932571411, "camel_8238": 0.6372230052947998, "camel_36938": 0.6372517347335815, "camel_8541": 0.6374163627624512, "aqua_rat_80024": 0.6374785900115967, "aqua_rat_10555": 0.6375309228897095, "camel_37839": 0.6376075744628906, "camel_9256": 0.6377996802330017, "camel_9248": 0.6378182172775269, "camel_36602": 0.6379326581954956, "camel_8549": 0.637947142124176, "camel_49882": 0.6379581093788147, "camel_8215": 0.6379587650299072, "camel_9916": 0.6379683017730713, "camel_9244": 0.6380559206008911, "camel_36848": 0.6380870938301086, "camel_9469": 0.6380900740623474, "camel_8512": 0.6380962133407593, "camel_9026": 0.6381232142448425, "camel_9233": 0.6381628513336182, "camel_36639": 0.6385558247566223, "camel_8553": 0.6386787295341492, "camel_8180": 0.6386846303939819, "camel_9151": 0.6386920809745789, "camel_9283": 0.6387012600898743, "aqua_rat_73650": 0.6387118101119995, "camel_41757": 0.638740062713623, "aqua_rat_49391": 0.6388071179389954, "camel_8569": 0.6388632655143738, "camel_8206": 0.6388810276985168, "camel_8604": 0.6389257311820984, "camel_9310": 0.6391637325286865, "camel_9259": 0.6396650671958923, "aqua_rat_25381": 0.6397274732589722, "camel_30455": 0.6398073434829712, "camel_8960": 0.6399520635604858, "camel_9277": 0.6401112675666809, "camel_9266": 0.640352189540863, "camel_36544": 0.6403618454933167, "camel_36766": 0.6403833031654358, "camel_9201": 0.6404281854629517, "aqua_rat_3450": 0.6407111883163452, "camel_37942": 0.6408448219299316, "aqua_rat_14465": 0.641014814376831, "camel_9022": 0.6411815881729126, "camel_8208": 0.6412876844406128, "aqua_rat_24481": 0.6414942145347595, "camel_8222": 0.6415867805480957, "aqua_rat_56237": 0.6419907212257385, "camel_9028": 0.6424095034599304, "camel_8239": 0.6424532532691956, "aqua_rat_54917": 0.6425113081932068, "camel_37923": 0.6426129937171936, "camel_8177": 0.6426255702972412, "camel_8481": 0.6426869034767151, "camel_8971": 0.642802357673645, "camel_9080": 0.6428414583206177, "camel_8196": 0.6428653597831726, "camel_8534": 0.6429010033607483, "camel_9043": 0.6429499983787537, "aqua_rat_27865": 0.6429867148399353, "camel_8485": 0.6431937217712402, "camel_8518": 0.6432396769523621, "camel_36441": 0.6433438658714294, "aqua_rat_10657": 0.6434884071350098, "camel_8494": 0.6436820030212402, "camel_8505": 0.6437614560127258, "camel_8483": 0.6438431739807129, "camel_9919": 0.6438957452774048, "camel_9202": 0.6439954042434692, "aqua_rat_80178": 0.6441015005111694, "camel_8978": 0.6441271901130676, "camel_9218": 0.644575297832489, "camel_37968": 0.6448934674263, "camel_9057": 0.6451742649078369, "camel_9096": 0.6451836228370667, "camel_37303": 0.6455281376838684, "camel_9213": 0.6455726623535156, "camel_37935": 0.645658016204834, "camel_36606": 0.6458033323287964, "aqua_rat_69142": 0.6461108922958374, "camel_9163": 0.6461625695228577, "camel_36869": 0.6462418437004089, "camel_9210": 0.6466236114501953, "camel_9017": 0.6466892957687378, "camel_5739": 0.6470642685890198, "camel_8209": 0.6472430229187012, "camel_9006": 0.6472636461257935, "camel_8533": 0.6474245190620422, "camel_9031": 0.6476215720176697, "camel_9276": 0.6476812362670898, "aqua_rat_87580": 0.6484575271606445, "camel_8559": 0.6486325860023499, "camel_8500": 0.649217426776886, "camel_9231": 0.6492320895195007, "camel_30478": 0.649452269077301, "camel_9216": 0.649996280670166, "camel_37719": 0.6500333547592163, "camel_9115": 0.6500867009162903, "camel_9275": 0.6502174735069275, "camel_8977": 0.6503549218177795, "camel_37101": 0.6503611207008362, "aqua_rat_47585": 0.6503989100456238, "camel_9001": 0.6505073308944702, "camel_8521": 0.650678813457489, "camel_9263": 0.6507925391197205, "camel_9209": 0.6516170501708984, "camel_8973": 0.6518399119377136, "camel_8548": 0.6519007086753845, "camel_8987": 0.6519430875778198, "camel_8514": 0.6521260142326355, "camel_9229": 0.6521298885345459, "camel_9230": 0.6521385908126831, "camel_9064": 0.6522876024246216, "camel_30458": 0.6523049473762512, "camel_8511": 0.6525844931602478, "camel_36875": 0.6526911854743958, "camel_8993": 0.6529426574707031, "camel_9034": 0.6530060172080994, "camel_9016": 0.6535975933074951, "camel_9267": 0.6537431478500366, "camel_8545": 0.6544013619422913, "camel_9018": 0.6545891761779785, "camel_9251": 0.6546076536178589, "camel_30413": 0.6546276211738586, "camel_9009": 0.654819130897522, "camel_9012": 0.6548938155174255, "camel_9260": 0.6559125781059265, "camel_9084": 0.6560875773429871, "camel_8174": 0.6564403772354126, "camel_9245": 0.6571853756904602, "camel_9030": 0.6582596302032471, "camel_9227": 0.6583315134048462, "camel_8225": 0.6589782238006592, "camel_8607": 0.6591527462005615, "camel_37989": 0.6595017910003662, "camel_36493": 0.6604675054550171, "camel_37997": 0.6607722640037537, "camel_8995": 0.6608110070228577, "camel_9205": 0.6615356206893921, "camel_9217": 0.6619482636451721, "camel_9246": 0.6641327738761902, "camel_9070": 0.6642251014709473, "camel_8176": 0.6642508506774902, "camel_8504": 0.66427081823349, "camel_9078": 0.6661235690116882, "camel_8536": 0.6664524078369141, "camel_9249": 0.6674461364746094, "camel_9208": 0.6675259470939636, "camel_8965": 0.6687226295471191, "camel_9113": 0.6688858866691589, "camel_8532": 0.6690495610237122, "camel_36502": 0.6707539558410645, "camel_36936": 0.6708366870880127, "camel_8999": 0.672836422920227, "camel_9211": 0.6732661128044128, "camel_9020": 0.6733061671257019, "camel_8528": 0.6766194701194763, "camel_8200": 0.6767837405204773, "camel_9004": 0.6770263910293579, "camel_9032": 0.679375410079956, "camel_9015": 0.6814510822296143, "camel_37926": 0.6817413568496704, "TheoremQA_elainewan/math_algebra_6.json": 0.6818650364875793, "camel_9025": 0.6819345951080322, "camel_37924": 0.6832348704338074, "camel_37934": 0.6918721795082092, "camel_8486": 0.6966491937637329, "camel_8963": 0.702264666557312}, "TheoremQA_wenhuchen/viterbi1.json": {"camel_9262": 0, "camel_8744": 0, "camel_9444": 0, "camel_9493": 0, "camel_8790": 0, "math_train_counting_and_probability_81": 0, "camel_8723": 0, "camel_8727": 0, "camel_8792": 0, "camel_9485": 0, "camel_9511": 0, "camel_9441": 0, "camel_9477": 0, "camel_9479": 0, "camel_9495": 0, "camel_9465": 0, "camel_9514": 0, "camel_9445": 0, "camel_9508": 0, "camel_9501": 0, "camel_9482": 0, "camel_9489": 0, "camel_9466": 0, "TheoremQA_wenhuchen/viterbi1.json": 0, "camel_9476": 0, "camel_9494": 0, "camel_9506": 0, "math_test_counting_and_probability_780": 0, "camel_9453": 0, "math_test_counting_and_probability_727": 0, "camel_9500": 0, "camel_9461": 0, "camel_9503": 0, "camel_9481": 0, "camel_8757": 0, "camel_9452": 0, "camel_8741": 0, "camel_9517": 0, "camel_9497": 0, "camel_9450": 0, "camel_9471": 0, "camel_9502": 0, "camel_9474": 0, "camel_9516": 0, "camel_8793": 0, "camel_9505": 0, "camel_8774": 0, "camel_9475": 0, "camel_9447": 0, "camel_9462": 0, "camel_9464": 0, "camel_9446": 0, "math_train_counting_and_probability_557": 0, "camel_9513": 0, "camel_9487": 0, "camel_9480": 0, "camel_9448": 0, "camel_9454": 0, "camel_9491": 0, "aqua_rat_47489": 0.7492083311080933, "aqua_rat_69606": 0.7496285438537598, "camel_11538": 0.7499718070030212, "aqua_rat_75721": 0.7499914169311523, "camel_24703": 0.7504239678382874, "camel_37977": 0.7504314184188843, "aqua_rat_82625": 0.7507036924362183, "camel_25515": 0.7509365081787109, "camel_24660": 0.750949501991272, "camel_24671": 0.7510644793510437, "camel_10648": 0.7512537837028503, "aqua_rat_56858": 0.7513608932495117, "aqua_rat_78183": 0.7513673901557922, "aqua_rat_16771": 0.7517735958099365, "camel_36523": 0.7519510984420776, "aqua_rat_65246": 0.7520439028739929, "camel_37992": 0.7520704865455627, "aqua_rat_61314": 0.7521392107009888, "aqua_rat_45407": 0.7522428035736084, "camel_37650": 0.7524716854095459, "camel_37890": 0.7524940371513367, "aqua_rat_689": 0.7525632381439209, "aqua_rat_50753": 0.7531120777130127, "camel_24388": 0.7531235814094543, "camel_24680": 0.753163754940033, "aqua_rat_34885": 0.7531691789627075, "camel_10888": 0.7531787157058716, "camel_24336": 0.7532598376274109, "camel_25396": 0.7532634139060974, "aqua_rat_30901": 0.753267228603363, "aqua_rat_86949": 0.7534047961235046, "aqua_rat_42090": 0.7535451650619507, "aqua_rat_80113": 0.7535467147827148, "camel_36358": 0.753571093082428, "aqua_rat_63248": 0.7536458969116211, "aqua_rat_61684": 0.7539030313491821, "camel_25372": 0.7540424466133118, "camel_10481": 0.754102349281311, "camel_10636": 0.7542386054992676, "camel_25407": 0.7544617652893066, "camel_25180": 0.7544875741004944, "camel_11631": 0.7545329332351685, "aqua_rat_79988": 0.7545592784881592, "camel_10604": 0.7546797394752502, "camel_24657": 0.7547270059585571, "aqua_rat_59064": 0.7550458908081055, "aqua_rat_15122": 0.7551892399787903, "aqua_rat_37772": 0.7552416324615479, "aqua_rat_41204": 0.7552459239959717, "aqua_rat_65962": 0.7555216550827026, "aqua_rat_76641": 0.7557468414306641, "aqua_rat_60327": 0.7559458017349243, "aqua_rat_46848": 0.7562308311462402, "camel_11901": 0.756328821182251, "camel_24370": 0.7563508749008179, "camel_25426": 0.7564317584037781, "aqua_rat_40444": 0.7564776539802551, "camel_25439": 0.7566969990730286, "aqua_rat_34949": 0.7569433450698853, "aqua_rat_39913": 0.7570134401321411, "camel_10914": 0.7571755051612854, "aqua_rat_8224": 0.7572140693664551, "camel_11584": 0.7572684288024902, "aqua_rat_44578": 0.7574059367179871, "camel_25433": 0.7575971484184265, "camel_25447": 0.7576503157615662, "aqua_rat_10224": 0.7582892775535583, "aqua_rat_63293": 0.7583518624305725, "aqua_rat_42825": 0.7586002349853516, "aqua_rat_51054": 0.7586184740066528, "camel_11314": 0.7586910724639893, "aqua_rat_47751": 0.7586985230445862, "aqua_rat_37698": 0.7588523030281067, "aqua_rat_50669": 0.758933424949646, "aqua_rat_50510": 0.7593024373054504, "aqua_rat_85293": 0.7595019936561584, "aqua_rat_50672": 0.7596831917762756, "camel_37849": 0.7612072825431824, "aqua_rat_3261": 0.761242687702179, "aqua_rat_6577": 0.761470377445221, "camel_25358": 0.7618181109428406, "camel_11156": 0.7618555426597595, "camel_11869": 0.7619598507881165, "aqua_rat_21944": 0.761968731880188, "camel_24711": 0.7624353170394897, "aqua_rat_80730": 0.762551486492157, "camel_24716": 0.76291424036026, "aqua_rat_81825": 0.7631309032440186, "aqua_rat_87308": 0.7638409733772278, "camel_37842": 0.7640813589096069, "aqua_rat_69941": 0.7643406391143799, "aqua_rat_50853": 0.7648630738258362, "camel_24710": 0.7650377154350281, "camel_37988": 0.7651628851890564, "aqua_rat_38490": 0.7654781341552734, "camel_37907": 0.7655854225158691, "camel_25361": 0.7658158540725708, "aqua_rat_75801": 0.7661239504814148, "camel_11739": 0.7662830948829651, "camel_36519": 0.766671895980835, "camel_37946": 0.7675803899765015, "camel_25410": 0.7675809264183044, "aqua_rat_71018": 0.7675929069519043, "camel_37859": 0.7681007981300354, "aqua_rat_14944": 0.7684974670410156, "camel_11619": 0.7690275311470032, "aqua_rat_73156": 0.7692378759384155, "camel_25303": 0.7700002193450928, "camel_25892": 0.7702276110649109, "camel_37912": 0.7703829407691956, "camel_25462": 0.7704699039459229, "aqua_rat_30573": 0.7705579996109009, "aqua_rat_84401": 0.7706036567687988, "camel_25420": 0.770795464515686, "camel_24714": 0.7710651159286499, "camel_25404": 0.7711668610572815, "camel_25517": 0.771504282951355, "aqua_rat_51142": 0.7715193629264832, "aqua_rat_6195": 0.7717133164405823, "aqua_rat_67820": 0.772110641002655, "camel_28142": 0.7727614045143127, "aqua_rat_86707": 0.7729975581169128, "camel_10622": 0.7733508348464966, "aqua_rat_87100": 0.7736783027648926, "camel_36384": 0.7739927768707275, "camel_10635": 0.7745452523231506, "camel_25471": 0.7750443816184998, "camel_25423": 0.7753535509109497, "aqua_rat_69505": 0.7753944993019104, "camel_25254": 0.7764525413513184, "aqua_rat_2646": 0.7768308520317078, "aqua_rat_86042": 0.7769860625267029, "camel_25494": 0.7775197625160217, "camel_25478": 0.7799428701400757, "aqua_rat_17728": 0.782261073589325, "camel_10639": 0.7848010063171387, "camel_11491": 0.7870820760726929, "camel_25438": 0.7876574397087097, "camel_25405": 0.7967977523803711, "camel_36276": 0.8018964529037476, "TheoremQA_wenhuchen/viterbi2.json": 0.824485719203949}, "TheoremQA_wenhuchen/kepler's_law3.json": {"TheoremQA_wenhuchen/kepler's_law3.json": 0, "aqua_rat_37440": 0.5848140120506287, "aqua_rat_50476": 0.5848219394683838, "gsm_rft_5947": 0.584912896156311, "aqua_rat_36121": 0.584998607635498, "camel_16283": 0.5850284099578857, "aqua_rat_65851": 0.5853418707847595, "aqua_rat_70945": 0.5853464603424072, "aqua_rat_919": 0.5854790806770325, "gsm_train_27598": 0.5855340957641602, "aqua_rat_32105": 0.5857170820236206, "gsm_rft_3843": 0.5858473181724548, "camel_36279": 0.5860271453857422, "camel_28823": 0.5861333012580872, "aqua_rat_59621": 0.5861846208572388, "aqua_rat_21246": 0.586202085018158, "gsm_rft_1803": 0.5864899754524231, "gsm_train_19006": 0.5867342352867126, "gsm_rft_8758": 0.5867530107498169, "gsm_rft_13204": 0.5867593288421631, "gsm_rft_23365": 0.5867841243743896, "gsm_rft_19203": 0.5868001580238342, "aqua_rat_65198": 0.5871098637580872, "gsm_rft_6393": 0.5871201753616333, "aqua_rat_64811": 0.5872483253479004, "gsm_rft_22872": 0.5872579216957092, "aqua_rat_11192": 0.5872765779495239, "camel_28861": 0.5873788595199585, "gsm_rft_3383": 0.5874515771865845, "gsm_rft_31188": 0.5874556303024292, "gsm_rft_8673": 0.5874971151351929, "aqua_rat_41482": 0.5877025127410889, "aqua_rat_73394": 0.5878095030784607, "camel_28812": 0.5879138112068176, "gsm_rft_11944": 0.5880058407783508, "camel_28736": 0.5882487893104553, "aqua_rat_11683": 0.5882760882377625, "gsm_train_19074": 0.5882796049118042, "gsm_rft_1559": 0.5882796049118042, "gsm_rft_22295": 0.5883156657218933, "gsm_rft_3603": 0.5884048938751221, "gsm_rft_13029": 0.5886186361312866, "gsm_rft_28416": 0.5887590050697327, "gsm_train_8335": 0.5887590050697327, "aqua_rat_58051": 0.5887619853019714, "gsm_rft_11759": 0.589241623878479, "gsm_rft_32994": 0.5892443060874939, "gsm_rft_14910": 0.5893244743347168, "gsm_rft_7861": 0.5893516540527344, "gsm_rft_22070": 0.5896335244178772, "gsm_train_14985": 0.5896335244178772, "gsm_rft_22904": 0.5896710157394409, "camel_24344": 0.5901715755462646, "gsm_rft_2271": 0.5902681946754456, "gsm_rft_19729": 0.5903291702270508, "gsm_rft_2575": 0.5904349088668823, "gsm_rft_870": 0.5904349088668823, "gsm_rft_28645": 0.5905531048774719, "gsm_rft_30836": 0.5905531048774719, "gsm_rft_28878": 0.5905531048774719, "gsm_train_31124": 0.5905531048774719, "gsm_train_31243": 0.590577244758606, "camel_29490": 0.5906316637992859, "aqua_rat_0": 0.5907939076423645, "gsm_rft_25197": 0.5909085273742676, "camel_29510": 0.5909202694892883, "gsm_rft_20918": 0.5910356640815735, "aqua_rat_62339": 0.5911911725997925, "gsm_rft_31116": 0.5915639996528625, "gsm_rft_22169": 0.5915728807449341, "gsm_train_21544": 0.5916867852210999, "gsm_rft_7812": 0.5917003750801086, "gsm_rft_18494": 0.5917275547981262, "gsm_rft_27918": 0.5917967557907104, "aqua_rat_73831": 0.5918463468551636, "camel_28860": 0.5920431017875671, "aqua_rat_26624": 0.5920653939247131, "camel_39446": 0.5922547578811646, "gsm_rft_13998": 0.5922829508781433, "gsm_train_7105": 0.5922829508781433, "aqua_rat_36957": 0.5923699140548706, "aqua_rat_81927": 0.5925706624984741, "gsm_rft_1589": 0.5926007628440857, "gsm_rft_57": 0.5929409265518188, "camel_39515": 0.5931029915809631, "gsm_rft_1925": 0.5931911468505859, "gsm_rft_23224": 0.5932449102401733, "gsm_rft_8950": 0.5936786532402039, "gsm_rft_2390": 0.5937269926071167, "aqua_rat_18752": 0.5939306616783142, "gsm_rft_6897": 0.5940907597541809, "camel_28869": 0.5941697359085083, "gsm_rft_8656": 0.5942298173904419, "camel_28832": 0.5942474603652954, "aqua_rat_87545": 0.5944816470146179, "aqua_rat_73953": 0.5945614576339722, "gsm_rft_24796": 0.5950067043304443, "aqua_rat_26179": 0.5951290130615234, "math_test_algebra_2631": 0.5956624746322632, "gsm_rft_34783": 0.5960270166397095, "aqua_rat_67295": 0.596113920211792, "aqua_rat_2995": 0.5962656736373901, "camel_28830": 0.5963746309280396, "gsm_rft_34630": 0.5963934063911438, "aqua_rat_24388": 0.5964099764823914, "aqua_rat_10204": 0.5969082117080688, "aqua_rat_79874": 0.5970310568809509, "aqua_rat_54005": 0.5974352359771729, "gsm_rft_26567": 0.5977299213409424, "math_train_algebra_2739": 0.5980061888694763, "gsm_rft_7556": 0.598357081413269, "aqua_rat_42233": 0.5984159708023071, "gsm_rft_18251": 0.5984285473823547, "gsm_rft_25684": 0.5985932946205139, "gsm_train_15621": 0.5992989540100098, "gsm_rft_24231": 0.5996715426445007, "camel_28815": 0.6001414060592651, "gsm_rft_34580": 0.601123034954071, "aqua_rat_50879": 0.6017926335334778, "aqua_rat_2020": 0.602323055267334, "gsm_rft_24978": 0.6025559902191162, "camel_28838": 0.6029990911483765, "aqua_rat_84368": 0.603111982345581, "gsm_train_15265": 0.6053295731544495, "gsm_rft_14302": 0.6053295731544495, "gsm_rft_5566": 0.6057565212249756, "gsm_rft_5789": 0.6063462495803833, "aqua_rat_76690": 0.6068007946014404, "gsm_train_21052": 0.606899619102478, "aqua_rat_80978": 0.6077579259872437, "gsm_rft_24790": 0.6077589392662048, "gsm_rft_25136": 0.6077589392662048, "gsm_train_18003": 0.6077589392662048, "gsm_rft_6386": 0.6079601645469666, "camel_28836": 0.6101183891296387, "aqua_rat_35471": 0.6103957891464233, "TheoremQA_panlu/gravitational_force2.json": 0.6107304692268372, "camel_28847": 0.6111416220664978, "aqua_rat_80089": 0.6123915314674377, "gsm_train_27098": 0.6134533286094666, "gsm_rft_7523": 0.6134533286094666, "gsm_rft_23617": 0.6134533286094666, "math_test_prealgebra_1873": 0.6140373945236206, "camel_39453": 0.6145457625389099, "aqua_rat_78220": 0.6149400472640991, "aqua_rat_47596": 0.615164577960968, "gsm_rft_11288": 0.6165505051612854, "gsm_train_29765": 0.6168867349624634, "gsm_rft_27862": 0.6168867349624634, "camel_5138": 0.6173263192176819, "gsm_rft_10897": 0.6173276305198669, "camel_29467": 0.6182411313056946, "camel_28532": 0.6189925074577332, "camel_17406": 0.6204093098640442, "camel_28537": 0.6216497421264648, "TheoremQA_panlu/gravitational_force1.json": 0.62409907579422, "aqua_rat_75922": 0.6278608441352844, "gsm_rft_10934": 0.628635823726654, "aqua_rat_2612": 0.6288653612136841, "gsm_rft_1431": 0.6290656924247742, "math_train_intermediate_algebra_1429": 0.631098747253418, "aqua_rat_18184": 0.6320739388465881, "gsm_rft_32685": 0.6320887804031372, "gsm_train_23496": 0.6321767568588257, "gsm_rft_35145": 0.6324874758720398, "aqua_rat_4869": 0.6384884715080261, "aqua_rat_67038": 0.6400790810585022, "gsm_rft_22533": 0.6415306329727173, "gsm_rft_10505": 0.6429446339607239, "gsm_train_29099": 0.6510105729103088, "gsm_rft_17764": 0.651136040687561, "camel_28137": 0.6514625549316406, "math_train_algebra_2156": 0.6563671827316284, "gsm_rft_22397": 0.6581395268440247, "aqua_rat_64905": 0.6584091782569885, "aqua_rat_67003": 0.6600260734558105, "aqua_rat_76036": 0.6650367975234985, "aqua_rat_6263": 0.6680608987808228, "gsm_rft_21861": 0.6689051389694214, "gsm_train_25944": 0.6689051389694214, "gsm_rft_14753": 0.6694644689559937, "camel_39513": 0.6695579886436462, "aqua_rat_76700": 0.6707919836044312, "aqua_rat_70741": 0.6731646060943604, "aqua_rat_36823": 0.6744228005409241, "aqua_rat_6249": 0.675735592842102, "aqua_rat_63716": 0.6759480834007263, "aqua_rat_43112": 0.6830437183380127, "TheoremQA_panlu/black_hole1.json": 0.6840266585350037, "aqua_rat_18805": 0.6868152618408203, "TheoremQA_wenhuchen/kepler's_law2.json": 0.6977991461753845, "aqua_rat_26489": 0.6984317898750305, "TheoremQA_panlu/energy_conservation1.json": 0.6986600756645203, "aqua_rat_11867": 0.7007223963737488, "aqua_rat_86642": 0.7053675651550293, "aqua_rat_88155": 0.7065716981887817, "aqua_rat_79015": 0.7083706855773926, "camel_29489": 0.738031804561615, "TheoremQA_wenhuchen/kepler's_law1.json": 0.7869072556495667, "camel_39449": 0.8439543843269348}, "TheoremQA_wenhuchen/L'H\u00f4pital_rule2.json": {"camel_7242": 0, "camel_7470": 0, "camel_7265": 0, "camel_7517": 0, "camel_7513": 0, "camel_7207": 0, "camel_7234": 0, "camel_7481": 0, "camel_7203": 0, "math_test_precalculus_893": 0, "camel_6632": 0, "camel_7270": 0, "camel_7225": 0, "camel_7486": 0, "camel_7210": 0, "camel_7200": 0, "camel_7231": 0, "camel_7243": 0, "camel_7487": 0, "camel_7220": 0, "camel_7268": 0, "camel_6825": 0, "camel_6564": 0, "camel_7477": 0, "TheoremQA_wenhuchen/L'H\u00f4pital_rule2.json": 0, "camel_7218": 0, "camel_7510": 0, "camel_7201": 0, "camel_7246": 0, "camel_6594": 0, "camel_7266": 0, "camel_7226": 0, "camel_7211": 0, "camel_7275": 0, "camel_7248": 0, "camel_7230": 0, "camel_7457": 0, "camel_7227": 0, "camel_7247": 0, "camel_7257": 0, "camel_7216": 0, "camel_7238": 0, "camel_7262": 0, "camel_7269": 0, "camel_7255": 0, "camel_7256": 0, "camel_7221": 0, "camel_7236": 0, "camel_7261": 0, "camel_7277": 0, "camel_7731": 0, "camel_7208": 0, "camel_7205": 0, "camel_7278": 0, "camel_7250": 0, "camel_7215": 0, "camel_7260": 0, "camel_7249": 0, "camel_7224": 0, "camel_7279": 0, "camel_7209": 0, "camel_7213": 0, "camel_7443": 0, "camel_7214": 0, "camel_7259": 0, "camel_7254": 0, "camel_7233": 0, "camel_7202": 0, "camel_7237": 0, "camel_6849": 0, "camel_7273": 0, "camel_7274": 0, "camel_7276": 0, "camel_7232": 0, "camel_7252": 0, "camel_7245": 0, "camel_7223": 0, "camel_7267": 0, "camel_7244": 0, "camel_7204": 0, "camel_7263": 0, "camel_31241": 0.6795627474784851, "camel_18922": 0.6799455285072327, "camel_31186": 0.6799857020378113, "camel_5043": 0.6800827980041504, "camel_5302": 0.6805095672607422, "aqua_rat_74869": 0.6806849837303162, "camel_5227": 0.6812296509742737, "camel_5198": 0.681256890296936, "camel_30914": 0.6813876628875732, "TheoremQA_elainewan/math_calculus_12.json": 0.6817266345024109, "camel_30890": 0.6819235682487488, "camel_31188": 0.682017982006073, "camel_28080": 0.6824577450752258, "camel_4965": 0.6825803518295288, "camel_19717": 0.6826968789100647, "camel_30903": 0.6833253502845764, "camel_5090": 0.683466374874115, "camel_19715": 0.6835036873817444, "camel_45174": 0.6836918592453003, "camel_31187": 0.6837215423583984, "camel_30668": 0.6837752461433411, "camel_30954": 0.6842699646949768, "camel_5065": 0.6849560737609863, "camel_30956": 0.6850301623344421, "camel_31316": 0.6856945753097534, "camel_4993": 0.6857052445411682, "camel_5344": 0.6857635378837585, "camel_30941": 0.6858610510826111, "camel_30942": 0.6863695979118347, "camel_5079": 0.6867885589599609, "camel_31294": 0.6867970824241638, "camel_30885": 0.6872020959854126, "camel_31175": 0.6873812079429626, "camel_30888": 0.6874487400054932, "camel_31339": 0.6875447630882263, "camel_5114": 0.6875724792480469, "camel_5181": 0.6876267194747925, "camel_5284": 0.6877024173736572, "camel_31173": 0.6877158284187317, "aqua_rat_75605": 0.6877659559249878, "camel_31104": 0.6878226399421692, "camel_5177": 0.687999427318573, "camel_19725": 0.6881121397018433, "camel_5092": 0.6881388425827026, "camel_18883": 0.6883532404899597, "gsm_rft_11031": 0.688478410243988, "camel_30909": 0.6885333061218262, "camel_40284": 0.6886507868766785, "camel_31142": 0.6888033151626587, "camel_31150": 0.6889013648033142, "camel_30931": 0.6890295147895813, "camel_5342": 0.6893427968025208, "camel_30921": 0.6896235942840576, "camel_31157": 0.690075695514679, "camel_39327": 0.6904736757278442, "gsm_rft_17551": 0.6906077861785889, "gsm_train_17819": 0.6906077861785889, "camel_30924": 0.6907304525375366, "gsm_rft_9344": 0.690980851650238, "gsm_rft_2452": 0.6912224888801575, "camel_18945": 0.6912993788719177, "camel_5303": 0.6917175650596619, "camel_18917": 0.6917781233787537, "aqua_rat_83913": 0.6919054985046387, "camel_16628": 0.6920249462127686, "camel_30881": 0.6921924352645874, "camel_18951": 0.6924244165420532, "camel_46120": 0.6937078833580017, "camel_18957": 0.6938096284866333, "camel_5057": 0.6939041018486023, "camel_30932": 0.6940505504608154, "camel_31147": 0.6941953301429749, "camel_19728": 0.6943026185035706, "camel_30883": 0.6948004961013794, "camel_45315": 0.6950967311859131, "camel_45293": 0.6958373785018921, "camel_5197": 0.6965649127960205, "camel_31174": 0.6970920562744141, "camel_5094": 0.6971872448921204, "camel_45310": 0.6971933245658875, "camel_45318": 0.6973026394844055, "camel_30899": 0.6976448893547058, "camel_5189": 0.6977598667144775, "camel_30920": 0.6983101963996887, "camel_31198": 0.6983308792114258, "camel_4986": 0.698415994644165, "camel_5070": 0.699028730392456, "camel_29060": 0.6992159485816956, "camel_5035": 0.6992547512054443, "camel_5029": 0.6994043588638306, "camel_30908": 0.7012749314308167, "camel_30917": 0.7015073895454407, "camel_31177": 0.7015649080276489, "camel_5165": 0.7016128301620483, "camel_30898": 0.701847493648529, "camel_47373": 0.7027210593223572, "camel_30944": 0.703713059425354, "camel_5093": 0.7039188742637634, "camel_45342": 0.7067363262176514, "camel_30953": 0.7071725130081177, "camel_30882": 0.7077532410621643, "camel_18783": 0.7088654637336731, "camel_5008": 0.709280252456665, "camel_18920": 0.7098251581192017, "camel_28086": 0.7099868059158325, "camel_30880": 0.71075838804245, "camel_18950": 0.7107802629470825, "camel_18919": 0.7115334868431091, "camel_5334": 0.7116938829421997, "camel_18882": 0.711696207523346, "camel_18940": 0.7148832678794861, "camel_30928": 0.7162594199180603, "camel_30919": 0.7224716544151306, "camel_18909": 0.7232407927513123, "camel_30904": 0.7260881662368774, "camel_39338": 0.7273281812667847, "camel_30907": 0.7274280786514282, "camel_39254": 0.7336203455924988, "camel_30945": 0.7394232749938965}, "TheoremQA_elainewan/math_calculus_2_6.json": {"camel_6817": 0, "camel_6239": 0, "camel_6801": 0, "camel_6844": 0, "camel_4813": 0.749782919883728, "camel_5526": 0.7498666048049927, "camel_4768": 0.7498723268508911, "camel_4761": 0.7498844265937805, "camel_4925": 0.7500142455101013, "camel_5055": 0.7501258850097656, "camel_4988": 0.7501401901245117, "camel_4743": 0.7501489520072937, "camel_4091": 0.7501932978630066, "camel_5549": 0.7502868175506592, "camel_4777": 0.7504851818084717, "camel_5013": 0.7505456805229187, "camel_4895": 0.7506969571113586, "camel_4552": 0.7508827447891235, "camel_4846": 0.7509992122650146, "camel_5577": 0.7510293126106262, "camel_4854": 0.7511274814605713, "camel_4096": 0.7511763572692871, "camel_5165": 0.7512120008468628, "camel_28086": 0.7513071298599243, "camel_5530": 0.7513224482536316, "camel_4804": 0.7513866424560547, "camel_4756": 0.7513887882232666, "camel_4955": 0.7516543865203857, "camel_5575": 0.751720666885376, "camel_4937": 0.7518622875213623, "camel_5554": 0.7523037791252136, "camel_4610": 0.7523362636566162, "camel_5576": 0.7524734735488892, "camel_4760": 0.7525693774223328, "camel_5539": 0.752668559551239, "camel_4749": 0.7528860569000244, "camel_5572": 0.7530282139778137, "camel_4783": 0.7530315518379211, "camel_4902": 0.7530393600463867, "camel_4801": 0.7533271908760071, "camel_5024": 0.7533658146858215, "camel_4898": 0.7535483241081238, "camel_5093": 0.7535685300827026, "camel_4878": 0.7537077069282532, "camel_4767": 0.7537481784820557, "camel_4765": 0.7538864016532898, "camel_4803": 0.7540821433067322, "camel_4742": 0.7541571259498596, "camel_4726": 0.7541714310646057, "camel_4739": 0.754204273223877, "camel_4785": 0.754306435585022, "camel_4786": 0.7547875046730042, "camel_4851": 0.7548853754997253, "camel_5591": 0.7551023364067078, "camel_4036": 0.7552204132080078, "camel_4931": 0.7553488612174988, "camel_5105": 0.7554947137832642, "camel_4754": 0.7555253505706787, "camel_5521": 0.7555968165397644, "camel_4792": 0.7556421160697937, "camel_4840": 0.7557271122932434, "camel_4920": 0.755843997001648, "camel_4764": 0.7558836340904236, "camel_5589": 0.7560256719589233, "camel_4914": 0.7560733556747437, "camel_5070": 0.7560737729072571, "camel_4773": 0.756136953830719, "camel_4919": 0.7561610341072083, "camel_4800": 0.7562446594238281, "camel_4909": 0.7562700510025024, "camel_4757": 0.7563245296478271, "camel_4900": 0.7564597725868225, "camel_4735": 0.7564642429351807, "camel_4901": 0.7570458650588989, "camel_4744": 0.7572665214538574, "camel_4823": 0.7572897672653198, "camel_4734": 0.7573472261428833, "camel_4763": 0.7574708461761475, "camel_4759": 0.7575729489326477, "camel_4787": 0.757809042930603, "camel_4921": 0.7579395771026611, "camel_4828": 0.757946789264679, "camel_4732": 0.7580943703651428, "camel_5027": 0.7581262588500977, "camel_4883": 0.7583069801330566, "camel_4897": 0.7583603858947754, "camel_4733": 0.7583944201469421, "camel_1874": 0.7585046291351318, "camel_4819": 0.7587890625, "camel_4963": 0.7588991522789001, "camel_4896": 0.7589092254638672, "camel_5079": 0.7589202523231506, "camel_5032": 0.7592099905014038, "camel_4741": 0.7592458128929138, "camel_5562": 0.759537935256958, "camel_4947": 0.7595812082290649, "camel_4751": 0.7597535848617554, "camel_4791": 0.7600187063217163, "camel_4752": 0.7605628967285156, "camel_4796": 0.7608608603477478, "camel_5551": 0.7609654664993286, "camel_5018": 0.7609726190567017, "camel_5899": 0.7614741325378418, "camel_4989": 0.7615659832954407, "camel_4805": 0.7616797089576721, "camel_4857": 0.761963427066803, "camel_4951": 0.7620532512664795, "camel_4903": 0.7623093128204346, "camel_4755": 0.7624408602714539, "camel_5188": 0.7624481320381165, "camel_4942": 0.7629985809326172, "camel_4747": 0.7631353139877319, "camel_5008": 0.7631356120109558, "camel_4729": 0.7632883787155151, "camel_5373": 0.7634387612342834, "camel_4728": 0.7635818123817444, "camel_4820": 0.7636979818344116, "camel_4886": 0.7638272643089294, "camel_4723": 0.7638543844223022, "camel_4956": 0.7639233469963074, "camel_4789": 0.7641203999519348, "camel_5358": 0.7644842863082886, "camel_4766": 0.7646917700767517, "camel_4724": 0.7649195790290833, "camel_4906": 0.7654327750205994, "camel_4793": 0.7654454112052917, "camel_4132": 0.7655550837516785, "camel_5021": 0.7658820152282715, "camel_4745": 0.7658975124359131, "camel_4788": 0.7665935754776001, "camel_5593": 0.7670771479606628, "camel_4797": 0.767316997051239, "camel_5029": 0.7679368257522583, "camel_5017": 0.768060028553009, "camel_4784": 0.768164336681366, "camel_4831": 0.7682587504386902, "camel_4876": 0.7685604095458984, "camel_4926": 0.7688078880310059, "camel_4950": 0.768842339515686, "camel_4762": 0.7688533067703247, "camel_5556": 0.7689224481582642, "camel_5523": 0.7690292000770569, "camel_4748": 0.7691119313240051, "camel_4776": 0.7692949175834656, "camel_5002": 0.7693849802017212, "camel_4978": 0.7694395780563354, "camel_5541": 0.7697718739509583, "camel_4790": 0.7699036598205566, "camel_4736": 0.7699592113494873, "camel_5524": 0.7700652480125427, "camel_4927": 0.7702298760414124, "camel_5012": 0.7707340121269226, "camel_4794": 0.770972728729248, "camel_4881": 0.7710009217262268, "camel_4753": 0.7710531949996948, "camel_4779": 0.7712120413780212, "camel_5536": 0.7713733315467834, "camel_5537": 0.771531343460083, "camel_4890": 0.7715815305709839, "camel_4016": 0.7717369198799133, "camel_4936": 0.7719821929931641, "camel_4928": 0.7720109224319458, "camel_4983": 0.7720366716384888, "camel_4889": 0.7721346020698547, "camel_4962": 0.7723345160484314, "camel_4905": 0.772360622882843, "camel_4891": 0.7733492851257324, "camel_4725": 0.7734396457672119, "camel_4721": 0.7735477685928345, "camel_4799": 0.7736999988555908, "camel_5561": 0.7740228772163391, "camel_5227": 0.7741955518722534, "camel_4952": 0.7744110822677612, "camel_4981": 0.7745399475097656, "camel_5334": 0.7746260166168213, "camel_4940": 0.7754124402999878, "camel_4730": 0.7755416631698608, "camel_4961": 0.7761424779891968, "camel_5092": 0.7768969535827637, "camel_4837": 0.7771316170692444, "camel_4780": 0.7771375179290771, "camel_4798": 0.7771558165550232, "camel_5571": 0.7773343920707703, "camel_4874": 0.7790558338165283, "camel_4991": 0.7793884873390198, "camel_5010": 0.7798570394515991, "camel_5007": 0.7817398309707642, "camel_5014": 0.7820742130279541, "camel_4974": 0.7835690975189209, "camel_5037": 0.7838959693908691, "camel_5057": 0.7850633859634399, "camel_5548": 0.785250186920166, "camel_4922": 0.7853438854217529, "camel_39489": 0.7855594158172607, "camel_4842": 0.786647617816925, "camel_4946": 0.7870998382568359, "camel_5034": 0.7949920892715454, "camel_5011": 0.7950606346130371, "camel_5114": 0.7966680526733398, "camel_5059": 0.8061940670013428}, "TheoremQA_xueguangma/future_value_1.json": {"TheoremQA_xueguangma/future_value_1.json": 0, "aqua_rat_47882": 0.7976206541061401, "aqua_rat_29433": 0.7977051734924316, "aqua_rat_58694": 0.7978646159172058, "aqua_rat_53504": 0.7980381846427917, "aqua_rat_50447": 0.798823893070221, "aqua_rat_21626": 0.7989069819450378, "aqua_rat_68636": 0.7994537949562073, "aqua_rat_24347": 0.799494743347168, "aqua_rat_69547": 0.8000102043151855, "aqua_rat_58126": 0.8002802729606628, "aqua_rat_34698": 0.8003189563751221, "aqua_rat_42949": 0.8004393577575684, "aqua_rat_31960": 0.8008521199226379, "aqua_rat_1115": 0.8008825778961182, "aqua_rat_42515": 0.8011276125907898, "aqua_rat_27270": 0.8013110756874084, "aqua_rat_78349": 0.8014327883720398, "aqua_rat_64976": 0.8014674186706543, "aqua_rat_65963": 0.8021716475486755, "aqua_rat_49718": 0.8022961616516113, "aqua_rat_39288": 0.8028109073638916, "math_test_algebra_1862": 0.8035722970962524, "aqua_rat_53421": 0.803614616394043, "aqua_rat_44549": 0.8036212921142578, "aqua_rat_69447": 0.8037106990814209, "aqua_rat_64664": 0.8037896752357483, "aqua_rat_37916": 0.8038573861122131, "aqua_rat_87884": 0.8039537072181702, "gsm_rft_7115": 0.8043338060379028, "gsm_train_9412": 0.8043338060379028, "aqua_rat_67698": 0.8044083714485168, "aqua_rat_38352": 0.8045102953910828, "aqua_rat_32851": 0.8045307397842407, "aqua_rat_13549": 0.8046400547027588, "aqua_rat_64914": 0.8047479391098022, "aqua_rat_76156": 0.8048844933509827, "aqua_rat_70690": 0.8050024509429932, "aqua_rat_75046": 0.805039644241333, "aqua_rat_53336": 0.805109977722168, "aqua_rat_86835": 0.8054358959197998, "aqua_rat_255": 0.8055365085601807, "aqua_rat_35907": 0.8057778477668762, "aqua_rat_51100": 0.8057833313941956, "aqua_rat_53568": 0.8060978055000305, "aqua_rat_42824": 0.8061145544052124, "aqua_rat_7674": 0.8064537644386292, "aqua_rat_18368": 0.8066536784172058, "aqua_rat_9965": 0.8068482279777527, "aqua_rat_44615": 0.8069357872009277, "aqua_rat_1549": 0.806942880153656, "aqua_rat_61757": 0.8071236610412598, "aqua_rat_69273": 0.8076126575469971, "aqua_rat_10686": 0.8078513741493225, "aqua_rat_33430": 0.8080514073371887, "math_train_algebra_1011": 0.808068573474884, "aqua_rat_59": 0.8081451058387756, "aqua_rat_10582": 0.808285117149353, "aqua_rat_17751": 0.8083263039588928, "math_test_algebra_311": 0.8086904883384705, "aqua_rat_63070": 0.8087586164474487, "aqua_rat_42017": 0.8089439272880554, "aqua_rat_54664": 0.8092978596687317, "aqua_rat_59892": 0.8097290396690369, "aqua_rat_3687": 0.8098605871200562, "aqua_rat_61585": 0.8099023699760437, "gsm_rft_23187": 0.8102895021438599, "gsm_rft_19035": 0.8102895021438599, "gsm_train_13256": 0.8104869723320007, "aqua_rat_6415": 0.8105326890945435, "aqua_rat_56852": 0.81059730052948, "aqua_rat_59668": 0.8112241625785828, "aqua_rat_26976": 0.8114019632339478, "aqua_rat_35380": 0.811485230922699, "aqua_rat_51796": 0.8125343322753906, "aqua_rat_67841": 0.8125731945037842, "aqua_rat_869": 0.8128215074539185, "gsm_train_30707": 0.8129208087921143, "aqua_rat_79979": 0.8129805326461792, "aqua_rat_72933": 0.8136550188064575, "aqua_rat_72687": 0.8137669563293457, "aqua_rat_63322": 0.8137742877006531, "aqua_rat_38071": 0.8138872981071472, "gsm_rft_20456": 0.8139063119888306, "gsm_rft_10656": 0.8139342069625854, "gsm_rft_22572": 0.8139486312866211, "aqua_rat_32350": 0.8141107559204102, "aqua_rat_2257": 0.8144189715385437, "aqua_rat_78121": 0.8144588470458984, "aqua_rat_65964": 0.8148898482322693, "math_train_algebra_2129": 0.814951479434967, "aqua_rat_32852": 0.8150675296783447, "aqua_rat_69526": 0.8153195381164551, "aqua_rat_37382": 0.8155508637428284, "aqua_rat_28520": 0.8155778646469116, "aqua_rat_61190": 0.8157490491867065, "math_test_algebra_82": 0.8158881664276123, "aqua_rat_58298": 0.816063642501831, "aqua_rat_24646": 0.8164379000663757, "aqua_rat_41963": 0.8166642189025879, "aqua_rat_88003": 0.8166894912719727, "aqua_rat_66298": 0.8169128894805908, "aqua_rat_7537": 0.8170633316040039, "aqua_rat_73739": 0.8171629905700684, "math_test_algebra_990": 0.8174905180931091, "gsm_rft_31902": 0.8175863027572632, "aqua_rat_87246": 0.8179888725280762, "aqua_rat_26339": 0.8183454275131226, "aqua_rat_83234": 0.8184105157852173, "aqua_rat_26582": 0.8185203075408936, "aqua_rat_66803": 0.8186419606208801, "aqua_rat_19784": 0.8186702132225037, "aqua_rat_88174": 0.8189379572868347, "aqua_rat_27039": 0.819242000579834, "aqua_rat_88415": 0.819243848323822, "gsm_rft_6559": 0.8193502426147461, "gsm_train_25622": 0.8193769454956055, "gsm_rft_11620": 0.8195444941520691, "aqua_rat_28662": 0.8195728659629822, "gsm_train_11462": 0.819740891456604, "gsm_rft_14102": 0.819740891456604, "aqua_rat_64092": 0.8199144005775452, "gsm_rft_6203": 0.8201739192008972, "aqua_rat_87589": 0.8204360008239746, "aqua_rat_84309": 0.8204795122146606, "aqua_rat_85193": 0.8207606673240662, "aqua_rat_86432": 0.8210557699203491, "gsm_rft_24137": 0.8211182951927185, "aqua_rat_78692": 0.8211840987205505, "aqua_rat_67076": 0.8215378522872925, "aqua_rat_88960": 0.8221057653427124, "gsm_rft_25658": 0.8234211802482605, "aqua_rat_53044": 0.824239194393158, "aqua_rat_64635": 0.8243266940116882, "aqua_rat_30386": 0.8246057033538818, "aqua_rat_3536": 0.8256931304931641, "gsm_rft_5849": 0.8257747292518616, "aqua_rat_7357": 0.8257983922958374, "aqua_rat_33006": 0.825980007648468, "aqua_rat_15337": 0.8260582685470581, "aqua_rat_83046": 0.8263553977012634, "aqua_rat_77744": 0.8267927169799805, "aqua_rat_37780": 0.827117919921875, "aqua_rat_27053": 0.8273394107818604, "aqua_rat_60321": 0.8273816108703613, "gsm_rft_12757": 0.8274741172790527, "gsm_rft_9871": 0.8274741172790527, "gsm_rft_3485": 0.8274741172790527, "gsm_train_6379": 0.8274741172790527, "math_train_algebra_1277": 0.8275317549705505, "gsm_rft_24617": 0.8278585076332092, "aqua_rat_32642": 0.8281399011611938, "math_test_algebra_2626": 0.8285139799118042, "aqua_rat_69339": 0.8292167782783508, "aqua_rat_62528": 0.8292504549026489, "math_test_algebra_337": 0.8300287127494812, "aqua_rat_41143": 0.8300346732139587, "aqua_rat_6657": 0.8305749297142029, "aqua_rat_16693": 0.8305752277374268, "aqua_rat_65985": 0.8306141495704651, "aqua_rat_66371": 0.8311141729354858, "aqua_rat_25325": 0.8319575190544128, "aqua_rat_32958": 0.8321248292922974, "gsm_rft_17331": 0.8328248858451843, "aqua_rat_59403": 0.8334534168243408, "aqua_rat_37258": 0.833556056022644, "aqua_rat_53302": 0.8338034749031067, "aqua_rat_47529": 0.8339158296585083, "aqua_rat_37580": 0.8346300721168518, "aqua_rat_22060": 0.8356509804725647, "aqua_rat_74003": 0.8358098268508911, "aqua_rat_13396": 0.8359136581420898, "gsm_rft_5669": 0.8360898494720459, "aqua_rat_9944": 0.8367407917976379, "aqua_rat_68014": 0.8373557925224304, "aqua_rat_83638": 0.8399299383163452, "aqua_rat_86234": 0.8409950137138367, "aqua_rat_43046": 0.8410629034042358, "aqua_rat_71239": 0.8413811922073364, "aqua_rat_39049": 0.842339038848877, "aqua_rat_79904": 0.8424238562583923, "math_train_algebra_667": 0.8441116213798523, "math_test_algebra_608": 0.8443238139152527, "math_train_algebra_707": 0.8444163799285889, "aqua_rat_29976": 0.8452445268630981, "aqua_rat_29321": 0.8482117652893066, "aqua_rat_28282": 0.8484480977058411, "aqua_rat_73390": 0.8494434356689453, "TheoremQA_wenhuchen/compound_interest1.json": 0.8525335192680359, "gsm_rft_9932": 0.8542110919952393, "gsm_rft_28176": 0.8545824885368347, "aqua_rat_21814": 0.8548070788383484, "gsm_train_26849": 0.8548589944839478, "gsm_rft_19092": 0.8548589944839478, "aqua_rat_25162": 0.855404257774353, "aqua_rat_20423": 0.8605968952178955, "math_train_algebra_957": 0.8610866069793701, "aqua_rat_12597": 0.8612506985664368, "math_train_algebra_369": 0.8731173276901245, "math_test_algebra_594": 0.8823251724243164}, "TheoremQA_jianyu_xu/pigeonhole_1.json": {"camel_21161": 0, "camel_21123": 0, "camel_21180": 0, "camel_21146": 0, "math_test_number_theory_612": 0, "camel_21175": 0, "camel_21193": 0, "camel_21145": 0, "camel_21186": 0, "camel_20577": 0, "camel_21173": 0, "camel_21176": 0, "camel_21163": 0, "camel_21143": 0, "camel_21252": 0, "camel_21170": 0, "camel_21137": 0, "camel_21798": 0, "camel_21168": 0, "camel_21120": 0, "camel_21040": 0, "camel_21196": 0, "camel_21158": 0, "camel_21188": 0, "camel_21172": 0, "camel_21147": 0, "camel_21132": 0, "camel_21160": 0, "camel_21185": 0, "camel_21169": 0, "camel_21141": 0, "camel_21174": 0, "camel_21190": 0, "camel_21154": 0, "camel_21126": 0, "camel_21198": 0, "camel_21372": 0, "camel_21165": 0, "camel_21055": 0, "camel_21121": 0, "camel_21162": 0, "camel_21177": 0, "camel_21159": 0, "camel_21128": 0, "camel_21835": 0, "camel_21183": 0, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0, "camel_23711": 0.6829314231872559, "aqua_rat_78805": 0.6829571723937988, "aqua_rat_15286": 0.6829590797424316, "aqua_rat_84502": 0.6831557750701904, "aqua_rat_38419": 0.6832493543624878, "aqua_rat_58655": 0.6834010481834412, "aqua_rat_55838": 0.6836457252502441, "aqua_rat_7648": 0.6837633848190308, "aqua_rat_37903": 0.6839351058006287, "aqua_rat_23573": 0.684173047542572, "aqua_rat_37188": 0.6846017241477966, "aqua_rat_63725": 0.684840202331543, "aqua_rat_65742": 0.6849350929260254, "aqua_rat_17162": 0.6850594282150269, "aqua_rat_56383": 0.6851637363433838, "aqua_rat_17717": 0.686180591583252, "aqua_rat_36058": 0.6862238049507141, "aqua_rat_51541": 0.6865206360816956, "aqua_rat_1131": 0.6867023706436157, "aqua_rat_52776": 0.6869320273399353, "aqua_rat_40097": 0.6870635151863098, "aqua_rat_80145": 0.6874437928199768, "aqua_rat_58635": 0.6876181364059448, "aqua_rat_88268": 0.6880861520767212, "aqua_rat_46632": 0.6882046461105347, "aqua_rat_30610": 0.6885730028152466, "aqua_rat_65383": 0.6888332366943359, "math_test_prealgebra_849": 0.6892088055610657, "aqua_rat_21205": 0.6892116665840149, "aqua_rat_73523": 0.6893547177314758, "aqua_rat_48816": 0.6897329092025757, "math_train_algebra_770": 0.6900507807731628, "aqua_rat_15511": 0.6902334690093994, "aqua_rat_42578": 0.6904653906822205, "aqua_rat_18128": 0.6910454630851746, "aqua_rat_22563": 0.6910533308982849, "aqua_rat_56889": 0.6913958191871643, "aqua_rat_26254": 0.6914052963256836, "aqua_rat_3736": 0.6917166709899902, "aqua_rat_50880": 0.6922661066055298, "aqua_rat_8519": 0.6924607753753662, "aqua_rat_9092": 0.6925889253616333, "aqua_rat_25877": 0.6927497386932373, "aqua_rat_257": 0.6928173303604126, "aqua_rat_52525": 0.692843496799469, "camel_11570": 0.6929285526275635, "aqua_rat_56307": 0.6933637261390686, "aqua_rat_61487": 0.693431556224823, "aqua_rat_7521": 0.6935963034629822, "aqua_rat_31046": 0.6936185956001282, "aqua_rat_74390": 0.6938958764076233, "aqua_rat_72179": 0.6939573884010315, "aqua_rat_76846": 0.6952295303344727, "aqua_rat_19096": 0.6954220533370972, "aqua_rat_45273": 0.6955320239067078, "aqua_rat_29842": 0.6964970827102661, "camel_36505": 0.6967013478279114, "aqua_rat_39765": 0.696916937828064, "aqua_rat_20344": 0.6970624923706055, "aqua_rat_20969": 0.6972519159317017, "aqua_rat_85357": 0.6975626945495605, "aqua_rat_64699": 0.6979190111160278, "aqua_rat_10287": 0.6981706619262695, "TheoremQA_jianyu_xu/Ramsey_3.json": 0.6983637809753418, "aqua_rat_68246": 0.6986895799636841, "aqua_rat_46126": 0.6990429759025574, "aqua_rat_10136": 0.7000124454498291, "aqua_rat_5662": 0.7002824544906616, "aqua_rat_41017": 0.7014026641845703, "math_train_algebra_2532": 0.7017234563827515, "aqua_rat_43005": 0.7018728256225586, "math_train_counting_and_probability_914": 0.7019158601760864, "aqua_rat_87746": 0.7022247910499573, "camel_36341": 0.7023645043373108, "TheoremQA_jianyu_xu/Ramsey_2.json": 0.7026735544204712, "aqua_rat_32157": 0.7033127546310425, "aqua_rat_60456": 0.7035799622535706, "aqua_rat_23636": 0.7037294507026672, "aqua_rat_25453": 0.7038958072662354, "aqua_rat_49256": 0.7043754458427429, "aqua_rat_52771": 0.7048938870429993, "aqua_rat_27921": 0.705405592918396, "aqua_rat_47084": 0.705579936504364, "aqua_rat_81420": 0.7060034275054932, "aqua_rat_83797": 0.7060587406158447, "aqua_rat_19090": 0.706249475479126, "aqua_rat_78018": 0.7064976096153259, "aqua_rat_31828": 0.7066301107406616, "aqua_rat_40277": 0.7068118453025818, "aqua_rat_56614": 0.7072107791900635, "aqua_rat_72312": 0.7075928449630737, "aqua_rat_53649": 0.7076049447059631, "aqua_rat_24238": 0.70766681432724, "aqua_rat_26962": 0.7089927196502686, "aqua_rat_29990": 0.7115378379821777, "aqua_rat_58088": 0.7118613123893738, "aqua_rat_70890": 0.7122436761856079, "aqua_rat_50073": 0.713094174861908, "math_test_counting_and_probability_987": 0.7138391733169556, "aqua_rat_65028": 0.7141867876052856, "aqua_rat_11601": 0.7152155637741089, "aqua_rat_49569": 0.7153505086898804, "aqua_rat_25103": 0.7159378528594971, "aqua_rat_5877": 0.7161024212837219, "camel_36391": 0.717031717300415, "aqua_rat_59053": 0.7173414826393127, "aqua_rat_75262": 0.7174619436264038, "aqua_rat_48010": 0.7192268967628479, "aqua_rat_80759": 0.7194610834121704, "aqua_rat_47694": 0.7222457528114319, "aqua_rat_15442": 0.7229061126708984, "aqua_rat_65264": 0.7234115600585938, "aqua_rat_15480": 0.7238932847976685, "aqua_rat_149": 0.7247347831726074, "aqua_rat_16788": 0.7253125905990601, "aqua_rat_37649": 0.7253580689430237, "aqua_rat_86710": 0.7265729904174805, "aqua_rat_17359": 0.7278441190719604, "aqua_rat_23524": 0.7286455631256104, "aqua_rat_66391": 0.7287748456001282, "aqua_rat_39271": 0.7291755676269531, "aqua_rat_20302": 0.7307421565055847, "aqua_rat_69238": 0.73164302110672, "aqua_rat_40065": 0.7320696711540222, "aqua_rat_20004": 0.7320735454559326, "aqua_rat_80435": 0.7325435876846313, "aqua_rat_73560": 0.7328994274139404, "aqua_rat_17862": 0.7334818840026855, "aqua_rat_48130": 0.7362844944000244, "aqua_rat_73303": 0.7364441752433777, "aqua_rat_83796": 0.7368792295455933, "aqua_rat_84086": 0.7372644543647766, "aqua_rat_38285": 0.7402855753898621, "aqua_rat_39047": 0.7406652569770813, "aqua_rat_33710": 0.7407483458518982, "aqua_rat_57502": 0.7412288188934326, "aqua_rat_34164": 0.7418277859687805, "aqua_rat_87294": 0.7422234416007996, "aqua_rat_67387": 0.7426250576972961, "aqua_rat_15630": 0.7427464127540588, "aqua_rat_48028": 0.7429391741752625, "aqua_rat_76356": 0.7438006401062012, "aqua_rat_22669": 0.7445887923240662, "aqua_rat_30710": 0.7448223233222961, "TheoremQA_jianyu_xu/pigeonhole_3.json": 0.7451429963111877, "aqua_rat_71213": 0.7463988661766052, "math_train_counting_and_probability_5123": 0.7503039240837097, "aqua_rat_14782": 0.7523382306098938, "aqua_rat_50597": 0.7691389322280884, "TheoremQA_jianyu_xu/pigeonhole_4.json": 0.7693759799003601, "aqua_rat_51045": 0.770014226436615, "aqua_rat_6686": 0.7754986882209778, "aqua_rat_6737": 0.7895268201828003}, "TheoremQA_jianyu_xu/Ramsey_3.json": {"camel_21197": 0, "camel_23829": 0, "camel_22175": 0, "camel_23726": 0, "camel_21128": 0, "camel_23754": 0, "camel_23746": 0, "camel_22215": 0, "camel_23766": 0, "camel_21116": 0, "camel_23689": 0, "camel_21140": 0, "camel_21126": 0, "camel_22206": 0, "camel_23721": 0, "camel_23764": 0, "camel_23776": 0, "camel_23827": 0, "camel_23788": 0, "camel_23816": 0, "camel_21065": 0, "camel_22165": 0, "camel_23722": 0, "camel_22161": 0, "camel_22120": 0, "camel_23825": 0, "camel_21797": 0, "camel_23733": 0, "camel_23743": 0, "camel_23696": 0, "camel_23742": 0, "camel_23789": 0, "camel_23691": 0, "camel_23694": 0, "camel_22220": 0, "camel_23771": 0, "camel_22212": 0, "camel_23727": 0, "camel_23718": 0, "camel_23731": 0, "camel_23680": 0, "camel_21133": 0, "camel_23790": 0, "camel_23808": 0, "camel_23703": 0, "camel_23685": 0, "camel_23701": 0, "camel_21192": 0, "camel_21171": 0, "camel_23795": 0, "camel_22238": 0, "camel_22164": 0, "camel_21181": 0, "camel_21169": 0, "camel_21784": 0, "camel_23818": 0, "camel_23699": 0, "camel_23702": 0, "camel_23714": 0, "camel_21144": 0, "camel_23729": 0, "camel_23755": 0, "camel_23724": 0, "camel_23710": 0, "camel_23748": 0, "camel_23756": 0, "camel_23707": 0, "camel_23704": 0, "camel_23698": 0, "camel_21167": 0, "camel_21196": 0, "camel_23712": 0, "camel_21055": 0, "camel_23828": 0, "camel_23775": 0, "camel_22207": 0, "camel_21189": 0, "camel_21183": 0, "camel_22202": 0, "camel_23734": 0, "camel_21184": 0, "camel_23713": 0, "camel_23747": 0, "camel_23758": 0, "camel_22230": 0, "camel_23705": 0, "camel_23723": 0, "camel_23683": 0, "camel_23798": 0, "camel_23717": 0, "camel_23759": 0, "camel_23720": 0, "camel_21195": 0, "camel_21139": 0, "camel_21124": 0, "camel_21170": 0, "camel_22211": 0, "camel_21173": 0, "camel_21151": 0, "camel_21163": 0, "camel_23715": 0, "camel_21121": 0, "camel_21174": 0, "camel_21136": 0, "camel_22177": 0, "camel_21164": 0, "camel_21145": 0, "camel_21179": 0, "camel_23686": 0, "camel_21162": 0, "camel_21149": 0, "camel_21122": 0, "camel_23725": 0, "camel_21178": 0, "camel_21131": 0, "camel_21134": 0, "camel_23730": 0, "camel_21153": 0, "camel_23740": 0, "TheoremQA_jianyu_xu/Ramsey_3.json": 0, "camel_23682": 0, "camel_21186": 0, "camel_21155": 0, "camel_23735": 0, "camel_23711": 0, "camel_21125": 0, "camel_21188": 0, "camel_23693": 0, "camel_21190": 0, "camel_21129": 0, "camel_21130": 0, "camel_23700": 0, "camel_21172": 0, "camel_21159": 0, "camel_23728": 0, "camel_21158": 0, "camel_21123": 0, "camel_21182": 0, "camel_21193": 0, "camel_23708": 0, "camel_21168": 0, "camel_23753": 0, "camel_21141": 0, "camel_23738": 0, "camel_21135": 0, "camel_23744": 0, "camel_21161": 0, "camel_22173": 0, "camel_21175": 0, "camel_23719": 0, "camel_21160": 0, "camel_22235": 0, "camel_21146": 0, "camel_21127": 0, "camel_21137": 0, "camel_23695": 0, "camel_21166": 0, "camel_23737": 0, "camel_21180": 0, "camel_23687": 0, "camel_21142": 0, "camel_21147": 0, "camel_21191": 0, "camel_21194": 0, "camel_23706": 0, "camel_23741": 0, "camel_23732": 0, "camel_21185": 0, "camel_23750": 0, "camel_21187": 0, "camel_23739": 0, "camel_21198": 0, "camel_23709": 0, "camel_23684": 0, "camel_23681": 0, "camel_21157": 0, "camel_23692": 0, "camel_21120": 0, "camel_23749": 0, "camel_21148": 0, "camel_23697": 0, "camel_23745": 0, "camel_23751": 0, "camel_21156": 0, "camel_21152": 0, "camel_21143": 0, "camel_23688": 0, "camel_21132": 0, "camel_23794": 0, "camel_21176": 0, "camel_23752": 0, "camel_23690": 0, "aqua_rat_38901": 0.7266061305999756, "math_test_counting_and_probability_987": 0.7422653436660767, "aqua_rat_83797": 0.7451475858688354, "TheoremQA_jianyu_xu/Ramsey_4.json": 0.7628417611122131, "TheoremQA_jianyu_xu/Ramsey_6.json": 0.764037549495697, "TheoremQA_jianyu_xu/Ramsey_5.json": 0.7655749320983887, "math_train_counting_and_probability_914": 0.7718830704689026, "TheoremQA_jianyu_xu/Ramsey_2.json": 0.8768895864486694}, "TheoremQA_wenhuchen/Poisson_process2.json": {"camel_11308": 0, "camel_9566": 0, "camel_10806": 0, "camel_11002": 0, "camel_10983": 0, "camel_11649": 0, "camel_8806": 0, "camel_11633": 0, "camel_10486": 0, "camel_10996": 0, "camel_9522": 0, "camel_10919": 0, "camel_11112": 0, "camel_11124": 0, "TheoremQA_wenhuchen/Poisson_process2.json": 0, "camel_11286": 0, "camel_11153": 0, "camel_10483": 0, "camel_9576": 0, "camel_11192": 0, "camel_8896": 0, "camel_10393": 0, "camel_10858": 0, "camel_11182": 0, "camel_11281": 0, "camel_10953": 0, "camel_11127": 0, "camel_10939": 0, "camel_11032": 0, "camel_10930": 0, "camel_11328": 0, "camel_11358": 0, "camel_10938": 0, "camel_10488": 0, "camel_11179": 0, "camel_10816": 0, "camel_10887": 0, "camel_10936": 0, "camel_9543": 0, "camel_8592": 0, "camel_11325": 0, "camel_9521": 0, "camel_11185": 0, "camel_11604": 0, "camel_9548": 0, "camel_11010": 0, "camel_11397": 0, "camel_9565": 0, "camel_8600": 0, "camel_8834": 0, "camel_11149": 0, "camel_9619": 0, "camel_11296": 0, "camel_10929": 0, "camel_10935": 0, "camel_9900": 0, "camel_10968": 0, "camel_10944": 0, "camel_11297": 0, "camel_10882": 0, "camel_11162": 0, "camel_10513": 0, "camel_10905": 0, "camel_11302": 0, "camel_11168": 0, "camel_10922": 0, "camel_9537": 0, "camel_10896": 0, "camel_9523": 0, "camel_11469": 0, "camel_10548": 0, "camel_10998": 0, "camel_9558": 0, "camel_11122": 0, "camel_10927": 0, "camel_9599": 0, "camel_9593": 0, "camel_11178": 0, "camel_10950": 0, "camel_10335": 0, "camel_11294": 0, "camel_9555": 0, "camel_11558": 0, "camel_10351": 0, "camel_10934": 0, "camel_8910": 0, "camel_9547": 0, "camel_11001": 0, "camel_11036": 0, "camel_11029": 0, "camel_9484": 0, "camel_11161": 0, "camel_9571": 0, "camel_10947": 0, "camel_9542": 0, "camel_9614": 0, "camel_9554": 0, "camel_11188": 0, "camel_11643": 0, "camel_9560": 0, "camel_10966": 0, "camel_10364": 0, "camel_11181": 0, "camel_10897": 0, "camel_9532": 0, "camel_10543": 0, "camel_9591": 0, "camel_11346": 0, "camel_11000": 0, "camel_10352": 0, "camel_9557": 0, "camel_10951": 0, "camel_10976": 0, "camel_10482": 0, "camel_10979": 0, "camel_11326": 0, "camel_10385": 0, "camel_11143": 0, "camel_9567": 0, "camel_10948": 0, "camel_9550": 0, "camel_10889": 0, "camel_10982": 0, "camel_9584": 0, "camel_11307": 0, "camel_9872": 0, "camel_10969": 0, "camel_10920": 0, "camel_11317": 0, "camel_11983": 0, "camel_10557": 0, "camel_10860": 0, "camel_11344": 0, "camel_8573": 0, "camel_9569": 0, "camel_11321": 0, "camel_11563": 0, "camel_10828": 0, "camel_17469": 0.5844776630401611, "aqua_rat_13384": 0.5852798223495483, "camel_38676": 0.5854955315589905, "camel_38715": 0.5864701867103577, "camel_38692": 0.5867665410041809, "aqua_rat_87228": 0.5874165296554565, "camel_38666": 0.5880140066146851, "camel_38661": 0.5884701609611511, "aqua_rat_39853": 0.5885757207870483, "gsm_rft_33863": 0.5891351699829102, "aqua_rat_67642": 0.5892485976219177, "aqua_rat_59951": 0.5894299745559692, "aqua_rat_43505": 0.5897798538208008, "aqua_rat_55278": 0.5901450514793396, "camel_38779": 0.5902732014656067, "camel_38649": 0.5911230444908142, "gsm_rft_21298": 0.5917337536811829, "gsm_train_20944": 0.5917337536811829, "camel_38698": 0.5918042659759521, "camel_45742": 0.5931938886642456, "camel_38740": 0.5937490463256836, "camel_38693": 0.5939009785652161, "camel_38696": 0.5940325260162354, "camel_17445": 0.5952582359313965, "aqua_rat_3027": 0.5956040024757385, "aqua_rat_9603": 0.5960547924041748, "camel_38654": 0.5960891246795654, "camel_38734": 0.596157431602478, "aqua_rat_10759": 0.5962166786193848, "camel_38651": 0.5968079566955566, "camel_38697": 0.5970711708068848, "camel_38646": 0.5976381897926331, "aqua_rat_42161": 0.5982843041419983, "camel_38687": 0.5983253121376038, "aqua_rat_17235": 0.5987793803215027, "camel_38682": 0.5990856289863586, "aqua_rat_41682": 0.5991693735122681, "aqua_rat_70783": 0.599399983882904, "gsm_rft_34988": 0.5999283790588379, "camel_38686": 0.599994957447052, "camel_38668": 0.6002591252326965, "aqua_rat_23428": 0.6005843281745911, "aqua_rat_40884": 0.6009894013404846, "camel_38643": 0.6033956408500671, "camel_29102": 0.6053162813186646, "gsm_rft_11471": 0.6060808300971985, "camel_38677": 0.6070516109466553, "camel_38705": 0.6072947382926941, "camel_38657": 0.6077162623405457, "camel_17545": 0.6092182993888855, "TheoremQA_wenhuchen/chebyshev1.json": 0.6133042573928833, "camel_38695": 0.6150447130203247, "aqua_rat_56490": 0.615246057510376, "camel_38691": 0.6161612868309021, "camel_38671": 0.6167590022087097, "camel_38645": 0.621660590171814, "camel_38659": 0.6219938397407532, "camel_38658": 0.6319828629493713, "camel_38660": 0.6340646147727966, "camel_38648": 0.6415862441062927, "camel_38674": 0.6442828178405762, "camel_38655": 0.6587881445884705}, "TheoremQA_wenhuchen/jensen2.json": {"TheoremQA_wenhuchen/jensen2.json": 0, "camel_4506": 0.7178553342819214, "camel_5774": 0.7181239724159241, "camel_5676": 0.7181483507156372, "camel_4532": 0.7184765934944153, "camel_5743": 0.718512773513794, "aqua_rat_70065": 0.7185392379760742, "camel_5632": 0.7190543413162231, "aqua_rat_21589": 0.7191392183303833, "camel_4435": 0.7192204594612122, "camel_18655": 0.7192298173904419, "camel_5755": 0.7192532420158386, "aqua_rat_25949": 0.7193447351455688, "camel_5657": 0.7194756865501404, "camel_4426": 0.7195377945899963, "camel_5741": 0.7195455431938171, "camel_46141": 0.7195865511894226, "camel_4556": 0.7196018099784851, "camel_5897": 0.7196497917175293, "camel_4547": 0.7197429537773132, "camel_5864": 0.7197708487510681, "camel_28842": 0.7199376821517944, "camel_5695": 0.7199423909187317, "camel_5727": 0.7199942469596863, "camel_5729": 0.7200329899787903, "camel_4511": 0.7201902270317078, "camel_4497": 0.7203052639961243, "camel_5698": 0.7209268808364868, "camel_5618": 0.7209470868110657, "camel_46110": 0.7209625840187073, "camel_5740": 0.7211183309555054, "camel_4530": 0.7211278080940247, "camel_19693": 0.7214623093605042, "camel_5674": 0.721487283706665, "camel_5644": 0.7216083407402039, "camel_4508": 0.7216448783874512, "camel_3947": 0.7220675349235535, "camel_5656": 0.7224504351615906, "camel_5719": 0.7225059866905212, "camel_4523": 0.7226149439811707, "camel_5726": 0.7227804660797119, "camel_5829": 0.7228764295578003, "camel_4490": 0.7229175567626953, "camel_5650": 0.7230789065361023, "camel_5701": 0.7231127023696899, "camel_5641": 0.723128080368042, "camel_5700": 0.7231972813606262, "camel_5638": 0.7232118844985962, "camel_5614": 0.7233123183250427, "camel_19687": 0.7233451008796692, "camel_5679": 0.7233981490135193, "camel_5820": 0.7234437465667725, "camel_5667": 0.723450779914856, "camel_5607": 0.7234752178192139, "camel_5627": 0.7235043048858643, "camel_19872": 0.7235260009765625, "camel_5699": 0.7235894203186035, "camel_4486": 0.7237183451652527, "camel_5721": 0.7237390875816345, "camel_5720": 0.7239118814468384, "camel_5808": 0.7243139743804932, "camel_5751": 0.7245581746101379, "camel_4520": 0.7245990037918091, "camel_5738": 0.7247021794319153, "camel_5707": 0.7250319123268127, "camel_18700": 0.7250809669494629, "camel_4538": 0.725191593170166, "camel_4482": 0.7252551317214966, "camel_5654": 0.7253331542015076, "camel_5642": 0.7253818511962891, "camel_5617": 0.7256029844284058, "camel_5655": 0.7257809638977051, "camel_5733": 0.7259396314620972, "camel_5764": 0.7259789109230042, "camel_4544": 0.7259995937347412, "camel_46130": 0.7261350154876709, "camel_5746": 0.7262792587280273, "camel_5686": 0.7262864112854004, "camel_4529": 0.7263251543045044, "camel_46131": 0.7263363599777222, "camel_5684": 0.7264482378959656, "camel_4499": 0.7266340851783752, "camel_19697": 0.7267653942108154, "camel_46099": 0.7267709970474243, "camel_5734": 0.7268117666244507, "camel_5664": 0.7268482446670532, "camel_5669": 0.7272911667823792, "camel_4488": 0.7273101210594177, "camel_4509": 0.7273251414299011, "camel_4543": 0.7274045944213867, "camel_5665": 0.7275534272193909, "camel_5709": 0.7275657057762146, "camel_5909": 0.7281873822212219, "camel_18713": 0.728205144405365, "camel_19869": 0.7282367944717407, "camel_5702": 0.7283239960670471, "camel_5811": 0.7285277247428894, "camel_4536": 0.7285835146903992, "camel_46084": 0.7286628484725952, "camel_4512": 0.7287773489952087, "camel_4537": 0.7288286089897156, "camel_5736": 0.7288811206817627, "camel_5630": 0.7290076613426208, "camel_5728": 0.7291520237922668, "camel_5600": 0.7291691899299622, "camel_5680": 0.72931307554245, "camel_5626": 0.7294591069221497, "camel_4534": 0.7295519113540649, "camel_5636": 0.7298210859298706, "camel_3983": 0.7300393581390381, "camel_4528": 0.7300799489021301, "camel_5634": 0.7301883101463318, "camel_46082": 0.730282187461853, "camel_5805": 0.7303497195243835, "camel_4510": 0.7307410836219788, "camel_5715": 0.7308159470558167, "camel_5848": 0.7324218153953552, "camel_5730": 0.7325673699378967, "camel_5708": 0.7325925230979919, "camel_5623": 0.732714831829071, "camel_5711": 0.7329248189926147, "camel_4541": 0.7329855561256409, "camel_19840": 0.7331066131591797, "camel_5706": 0.7332455515861511, "camel_5703": 0.7335273027420044, "camel_5716": 0.7337235808372498, "camel_46137": 0.734294056892395, "camel_4491": 0.734582781791687, "camel_5757": 0.7348060607910156, "camel_5894": 0.7348420023918152, "camel_5616": 0.7349916696548462, "camel_5658": 0.7352843880653381, "camel_4524": 0.7353106141090393, "camel_4683": 0.7354980707168579, "camel_5619": 0.7355082035064697, "camel_36766": 0.7356654405593872, "camel_5731": 0.7356998920440674, "camel_4535": 0.7357111573219299, "camel_5677": 0.73577880859375, "camel_5713": 0.7358144521713257, "camel_4487": 0.7359530925750732, "camel_4559": 0.736158013343811, "camel_5867": 0.7363312840461731, "camel_5687": 0.7364619374275208, "camel_46088": 0.7372053265571594, "camel_5670": 0.737316370010376, "camel_4459": 0.7373165488243103, "camel_5907": 0.7373219132423401, "camel_46111": 0.7373427748680115, "camel_5712": 0.7374763488769531, "camel_5912": 0.7377773523330688, "camel_4669": 0.7389105558395386, "camel_5602": 0.7390851974487305, "camel_4521": 0.7397287487983704, "aqua_rat_47647": 0.7399399876594543, "camel_4551": 0.740478515625, "camel_5682": 0.7412647604942322, "camel_4464": 0.7413397431373596, "camel_5861": 0.7416340708732605, "camel_5881": 0.7416941523551941, "camel_5609": 0.7417623996734619, "camel_5625": 0.7419262528419495, "camel_4527": 0.7419722080230713, "camel_5754": 0.7420069575309753, "camel_5633": 0.7422352433204651, "camel_5608": 0.7425985932350159, "camel_5749": 0.7442713379859924, "camel_5651": 0.7443666458129883, "camel_5737": 0.7443690299987793, "camel_5668": 0.7444862723350525, "camel_4516": 0.7452035546302795, "camel_4514": 0.7453427314758301, "camel_5647": 0.7456496357917786, "camel_5605": 0.74615478515625, "camel_4407": 0.7463858723640442, "camel_5629": 0.7464642524719238, "camel_5753": 0.7473613619804382, "camel_5723": 0.7475571036338806, "camel_5688": 0.747985303401947, "camel_5722": 0.7484949827194214, "camel_5710": 0.7488765716552734, "camel_5766": 0.7489016652107239, "camel_5747": 0.7494559288024902, "camel_5744": 0.7500239014625549, "camel_4518": 0.7500625848770142, "camel_5742": 0.7502489686012268, "camel_5643": 0.7503312230110168, "camel_5752": 0.7518382668495178, "camel_5904": 0.7522482872009277, "camel_46152": 0.7528531551361084, "camel_5622": 0.7531126141548157, "camel_5678": 0.7554454803466797, "camel_5601": 0.7565389275550842, "camel_4686": 0.756600558757782, "camel_5689": 0.7592877149581909, "camel_5681": 0.7617500424385071, "camel_5653": 0.7657414674758911, "camel_5868": 0.7657738924026489, "camel_5887": 0.7736019492149353, "camel_18649": 0.7965550422668457}, "TheoremQA_xueguangma/binomial_model_1.json": {"TheoremQA_xueguangma/binomial_model_1.json": 0, "camel_25279": 0.6385327577590942, "aqua_rat_46842": 0.6387764811515808, "camel_10554": 0.6388502717018127, "aqua_rat_27125": 0.6389288902282715, "camel_25291": 0.6389720439910889, "aqua_rat_20677": 0.6394502520561218, "camel_16941": 0.6397468447685242, "aqua_rat_80254": 0.6399814486503601, "camel_38659": 0.6400010585784912, "camel_10496": 0.6400566101074219, "camel_25253": 0.6401199102401733, "camel_25278": 0.6403806209564209, "camel_38666": 0.6407382488250732, "camel_25805": 0.640842854976654, "camel_25243": 0.6414808034896851, "aqua_rat_8296": 0.6415321230888367, "camel_9448": 0.6417280435562134, "aqua_rat_16890": 0.6418987512588501, "camel_38693": 0.6420038342475891, "camel_38660": 0.6420413255691528, "aqua_rat_300": 0.6420891880989075, "camel_29065": 0.64210045337677, "camel_37714": 0.642230212688446, "TheoremQA_elainewan/econ_micro_18.json": 0.6422608494758606, "aqua_rat_71720": 0.6425160765647888, "camel_38651": 0.6425849795341492, "aqua_rat_62052": 0.6426229476928711, "aqua_rat_2126": 0.6426821947097778, "camel_10489": 0.6426979899406433, "camel_9549": 0.6431041359901428, "camel_25287": 0.6432222723960876, "aqua_rat_82161": 0.6434274911880493, "aqua_rat_47112": 0.6435852646827698, "camel_25131": 0.6436406373977661, "camel_37696": 0.6436930894851685, "aqua_rat_13406": 0.6437017917633057, "aqua_rat_11169": 0.6438984870910645, "camel_24676": 0.6441179513931274, "aqua_rat_57018": 0.6442198157310486, "aqua_rat_79475": 0.6442926526069641, "camel_10537": 0.6444064378738403, "aqua_rat_6123": 0.6444444060325623, "camel_10503": 0.6444604396820068, "aqua_rat_46713": 0.6444913744926453, "camel_17484": 0.6445032954216003, "camel_29102": 0.6445449590682983, "aqua_rat_88397": 0.6448965668678284, "camel_37691": 0.6448970437049866, "camel_9495": 0.645214319229126, "camel_10546": 0.6454278826713562, "camel_38717": 0.6455347537994385, "aqua_rat_10293": 0.645626425743103, "camel_24715": 0.6457053422927856, "camel_11825": 0.6458467245101929, "aqua_rat_39322": 0.6463257670402527, "camel_10513": 0.6466808915138245, "gsm_rft_24227": 0.6467344760894775, "aqua_rat_34902": 0.6468147039413452, "camel_25136": 0.6468997597694397, "camel_10485": 0.647099494934082, "gsm_rft_32682": 0.6472799181938171, "TheoremQA_elainewan/econ_micro_7.json": 0.6474140882492065, "TheoremQA_xueguangma/geometric_brownian_motion.json": 0.6475337147712708, "camel_20483": 0.6476940512657166, "camel_37693": 0.6478445529937744, "aqua_rat_78125": 0.6479452252388, "camel_9557": 0.6480621695518494, "aqua_rat_27775": 0.6483129262924194, "aqua_rat_36141": 0.6483191251754761, "camel_10552": 0.6483820080757141, "aqua_rat_58170": 0.6484020948410034, "aqua_rat_40618": 0.6486064195632935, "camel_17518": 0.6488263607025146, "aqua_rat_17612": 0.64913409948349, "camel_37753": 0.649223804473877, "aqua_rat_82531": 0.6492536067962646, "aqua_rat_28096": 0.6495952606201172, "camel_25212": 0.6502452492713928, "gsm_rft_27168": 0.6506392359733582, "camel_10497": 0.6506627202033997, "aqua_rat_48727": 0.6507090330123901, "camel_10531": 0.6509286165237427, "aqua_rat_76293": 0.6509345769882202, "aqua_rat_66927": 0.6511437296867371, "gsm_rft_18604": 0.65155029296875, "aqua_rat_48279": 0.6520413160324097, "camel_38714": 0.6522752046585083, "camel_9576": 0.65262371301651, "aqua_rat_79363": 0.6527010202407837, "aqua_rat_32864": 0.6528773307800293, "gsm_rft_320": 0.653965175151825, "aqua_rat_5299": 0.6546528339385986, "gsm_train_23944": 0.6546671390533447, "aqua_rat_49267": 0.6553154587745667, "camel_10507": 0.6560001969337463, "aqua_rat_42740": 0.6560719013214111, "aqua_rat_61040": 0.6568320393562317, "aqua_rat_32328": 0.6572573184967041, "camel_10495": 0.6574617028236389, "aqua_rat_13263": 0.6576367020606995, "gsm_rft_19966": 0.6586208343505859, "aqua_rat_81598": 0.6587461829185486, "aqua_rat_54690": 0.6588630676269531, "camel_25125": 0.6590037941932678, "camel_17513": 0.659067690372467, "math_test_counting_and_probability_25780": 0.6591545939445496, "aqua_rat_87481": 0.6593798398971558, "aqua_rat_20527": 0.6598705649375916, "aqua_rat_21750": 0.661000669002533, "aqua_rat_68974": 0.6611292362213135, "camel_10536": 0.6619299054145813, "camel_25219": 0.6622155904769897, "camel_10500": 0.6623607873916626, "aqua_rat_19962": 0.6623821258544922, "camel_16942": 0.6632989048957825, "aqua_rat_68410": 0.6633033752441406, "aqua_rat_37786": 0.664991557598114, "camel_25239": 0.6658421754837036, "math_train_prealgebra_279": 0.6659175753593445, "camel_25255": 0.6664497256278992, "camel_10481": 0.6666336059570312, "aqua_rat_24355": 0.6668012738227844, "camel_10512": 0.6673052906990051, "camel_17469": 0.6673620939254761, "math_train_prealgebra_1884": 0.6676676869392395, "camel_10529": 0.6677801609039307, "camel_10493": 0.6685336232185364, "camel_10526": 0.6687034368515015, "aqua_rat_45706": 0.668765664100647, "camel_10559": 0.6690777540206909, "camel_10540": 0.6691650152206421, "aqua_rat_76433": 0.6696669459342957, "gsm_rft_10601": 0.6702308058738708, "camel_16925": 0.6712526679039001, "camel_20559": 0.6713481545448303, "camel_25270": 0.6714267730712891, "camel_10515": 0.6716452836990356, "camel_10520": 0.6726491451263428, "gsm_rft_26701": 0.6736247539520264, "aqua_rat_70338": 0.673660933971405, "camel_10548": 0.6743900179862976, "camel_10491": 0.6747606992721558, "aqua_rat_16431": 0.6751213669776917, "aqua_rat_41731": 0.677153468132019, "camel_38662": 0.6771971583366394, "aqua_rat_48354": 0.6779376268386841, "camel_10502": 0.6784149408340454, "aqua_rat_9579": 0.6784688234329224, "gsm_rft_24218": 0.6789920330047607, "gsm_train_17735": 0.6792795062065125, "camel_10522": 0.6796451807022095, "camel_10509": 0.6808681488037109, "aqua_rat_8397": 0.6808702945709229, "aqua_rat_18030": 0.6809694170951843, "camel_10534": 0.6823734641075134, "camel_10532": 0.6835057735443115, "aqua_rat_22889": 0.6841983795166016, "aqua_rat_6366": 0.6858377456665039, "camel_10494": 0.6864867806434631, "aqua_rat_4309": 0.6865705847740173, "aqua_rat_38058": 0.6874359846115112, "aqua_rat_4287": 0.6879661679267883, "aqua_rat_77492": 0.688474714756012, "aqua_rat_758": 0.6887857913970947, "aqua_rat_27489": 0.6898183226585388, "aqua_rat_85600": 0.6908883452415466, "camel_10482": 0.691540002822876, "aqua_rat_72903": 0.692798376083374, "camel_10557": 0.6937556266784668, "math_train_prealgebra_1338": 0.6948294639587402, "aqua_rat_45809": 0.694836437702179, "aqua_rat_10880": 0.6966850161552429, "camel_10511": 0.6981364488601685, "camel_10504": 0.7014790177345276, "camel_9461": 0.7017280459403992, "camel_10553": 0.7065595984458923, "camel_10544": 0.7067821621894836, "aqua_rat_86591": 0.7067967653274536, "camel_10530": 0.7072936296463013, "TheoremQA_xueguangma/binomial_model_2.json": 0.7101935148239136, "aqua_rat_34158": 0.7102252840995789, "aqua_rat_18878": 0.710891604423523, "aqua_rat_82406": 0.7128705382347107, "camel_10486": 0.713153600692749, "camel_10514": 0.7134246826171875, "camel_10535": 0.7138808369636536, "camel_10539": 0.7163223624229431, "aqua_rat_33669": 0.7185835242271423, "aqua_rat_32300": 0.722435474395752, "camel_10506": 0.7258288264274597, "camel_10558": 0.726776123046875, "camel_10543": 0.7287042140960693, "camel_10480": 0.7338050007820129, "camel_10523": 0.7406815886497498, "aqua_rat_75689": 0.7523295283317566, "camel_10542": 0.7548459768295288, "camel_10488": 0.7630334496498108, "camel_10555": 0.766078531742096, "camel_10492": 0.7733786106109619}, "TheoremQA_wenhuchen/newton2.json": {"camel_7695": 0, "camel_7755": 0, "TheoremQA_wenhuchen/newton2.json": 0, "camel_6576": 0, "camel_40598": 0, "camel_7777": 0, "camel_7774": 0, "aqua_rat_36076": 0.7377079725265503, "aqua_rat_42557": 0.7377243041992188, "camel_48056": 0.7377262115478516, "aqua_rat_53614": 0.7378714680671692, "aqua_rat_12032": 0.7379122376441956, "aqua_rat_18824": 0.7381546497344971, "camel_1629": 0.738254964351654, "aqua_rat_25092": 0.7382880449295044, "camel_49372": 0.7383881211280823, "camel_1758": 0.7384960055351257, "aqua_rat_27367": 0.7385198473930359, "aqua_rat_21462": 0.7385390996932983, "aqua_rat_84073": 0.7387089133262634, "camel_48297": 0.7387348413467407, "aqua_rat_57634": 0.7387954592704773, "camel_1729": 0.7391235828399658, "camel_432": 0.7391776442527771, "camel_48944": 0.739199161529541, "math_train_algebra_2830": 0.7393275499343872, "camel_28365": 0.739379346370697, "aqua_rat_46083": 0.7396758794784546, "camel_48623": 0.7396832704544067, "camel_1679": 0.7397218942642212, "camel_467": 0.7402294278144836, "camel_1710": 0.7403208613395691, "math_train_algebra_2029": 0.7404552102088928, "aqua_rat_69272": 0.7405025959014893, "camel_48131": 0.7408396601676941, "camel_28446": 0.7410829067230225, "camel_1754": 0.7411518692970276, "aqua_rat_48553": 0.7412346601486206, "camel_472": 0.741298258304596, "math_train_intermediate_algebra_1165": 0.7416173219680786, "camel_39125": 0.7417044043540955, "TheoremQA_wenhuchen/Descartes_Rule_of_Signs.json": 0.7420055866241455, "math_train_algebra_2244": 0.7421358823776245, "camel_48015": 0.7423030734062195, "aqua_rat_62268": 0.7424805760383606, "camel_1621": 0.7425366044044495, "math_train_intermediate_algebra_957": 0.7426844239234924, "camel_459": 0.7427501678466797, "aqua_rat_11873": 0.7429988980293274, "TheoremQA_elainewan/math_calculus_2_11.json": 0.7430087924003601, "camel_430": 0.7432449460029602, "camel_49437": 0.7432571053504944, "math_test_algebra_2098": 0.7433064579963684, "aqua_rat_70225": 0.7439283132553101, "camel_48106": 0.7440378665924072, "camel_1689": 0.7440937161445618, "aqua_rat_4632": 0.7444489002227783, "camel_1692": 0.7445246577262878, "camel_436": 0.7448655366897583, "math_train_algebra_2096": 0.7448791861534119, "aqua_rat_84753": 0.7449836134910583, "camel_1737": 0.745090901851654, "camel_48025": 0.7453760504722595, "aqua_rat_56076": 0.7454456090927124, "aqua_rat_6248": 0.745513379573822, "math_train_algebra_1618": 0.7457059621810913, "math_train_algebra_964": 0.7457784414291382, "aqua_rat_42392": 0.7460256218910217, "math_train_intermediate_algebra_12": 0.7460991144180298, "aqua_rat_51772": 0.7463744878768921, "camel_48045": 0.7464507818222046, "camel_49810": 0.7467154264450073, "camel_1668": 0.746779203414917, "camel_1718": 0.7468504309654236, "aqua_rat_50664": 0.7468860149383545, "camel_49656": 0.7472140192985535, "math_train_algebra_461": 0.7474213242530823, "camel_49258": 0.7476060390472412, "aqua_rat_56649": 0.7480697631835938, "camel_48076": 0.7481669783592224, "aqua_rat_28179": 0.748322069644928, "math_test_intermediate_algebra_951": 0.7483811378479004, "camel_49400": 0.7485153079032898, "camel_1684": 0.7486516237258911, "camel_1631": 0.7487517595291138, "camel_48068": 0.7489187121391296, "TheoremQA_xueguangma/intermediate_value_theorem.json": 0.7493860721588135, "aqua_rat_1683": 0.7494020462036133, "aqua_rat_16800": 0.7496387362480164, "math_test_algebra_2579": 0.7500279545783997, "camel_456": 0.7502406239509583, "camel_39306": 0.7502588033676147, "camel_1716": 0.7506466507911682, "camel_1747": 0.7508065104484558, "camel_1688": 0.7509391903877258, "camel_49039": 0.751205563545227, "camel_48007": 0.7513188123703003, "camel_1687": 0.7514273524284363, "camel_1700": 0.7521716356277466, "camel_1708": 0.7522466778755188, "camel_48121": 0.7522533535957336, "camel_48908": 0.7528712153434753, "camel_49845": 0.7535569667816162, "camel_1698": 0.7537843585014343, "math_test_algebra_2028": 0.7539368867874146, "camel_1703": 0.7540948987007141, "camel_48052": 0.7541444301605225, "aqua_rat_863": 0.7541768550872803, "math_train_intermediate_algebra_1515": 0.7545388340950012, "camel_48016": 0.754706621170044, "camel_48014": 0.7547104954719543, "aqua_rat_2920": 0.7552449703216553, "camel_1704": 0.7555957436561584, "camel_1685": 0.7560961842536926, "aqua_rat_32416": 0.7564002275466919, "camel_1638": 0.7564290165901184, "camel_1699": 0.7567431330680847, "camel_1666": 0.7575283646583557, "camel_403": 0.7578256726264954, "camel_49242": 0.7578685283660889, "math_train_algebra_1944": 0.7579946517944336, "camel_425": 0.7583524584770203, "aqua_rat_84969": 0.7583611607551575, "camel_1693": 0.758395791053772, "aqua_rat_36743": 0.7587435841560364, "math_test_algebra_704": 0.7590681910514832, "camel_48033": 0.7590951919555664, "aqua_rat_27289": 0.7592099905014038, "camel_49876": 0.759293258190155, "aqua_rat_45553": 0.7593555450439453, "TheoremQA_wenhuchen/Graffe's_root2.json": 0.7594950795173645, "camel_1682": 0.7598676085472107, "camel_48255": 0.760054349899292, "camel_48133": 0.7600567936897278, "camel_1709": 0.7601679563522339, "camel_1753": 0.7605214715003967, "camel_48120": 0.7616358995437622, "aqua_rat_69050": 0.761734127998352, "camel_1748": 0.7627545595169067, "camel_48569": 0.7627582550048828, "camel_1680": 0.7630521655082703, "camel_49225": 0.7630978226661682, "camel_48036": 0.7642538547515869, "camel_445": 0.7642693519592285, "camel_1724": 0.7644966244697571, "camel_1715": 0.7645444869995117, "aqua_rat_46099": 0.7650304436683655, "camel_49140": 0.7655221223831177, "camel_1738": 0.765954315662384, "camel_48096": 0.7669024467468262, "camel_1736": 0.7670143842697144, "camel_48005": 0.7677568197250366, "camel_49277": 0.769622266292572, "camel_1742": 0.7697029113769531, "camel_1730": 0.7703171968460083, "camel_1723": 0.7713974118232727, "camel_1728": 0.773466169834137, "aqua_rat_7450": 0.7739643454551697, "camel_1628": 0.7750028967857361, "camel_1660": 0.7751166820526123, "aqua_rat_16260": 0.7761362791061401, "aqua_rat_21304": 0.7769041061401367, "camel_1759": 0.7771126627922058, "aqua_rat_76599": 0.779996931552887, "camel_1705": 0.7801669239997864, "aqua_rat_51085": 0.7803442478179932, "camel_1744": 0.7811911106109619, "camel_1755": 0.7822437286376953, "camel_1695": 0.7828671336174011, "camel_28475": 0.783150851726532, "camel_1672": 0.7832995057106018, "camel_48888": 0.783732533454895, "camel_1717": 0.7839115858078003, "aqua_rat_17489": 0.7848528623580933, "camel_1707": 0.7858737707138062, "aqua_rat_30784": 0.7868155241012573, "camel_1745": 0.7870099544525146, "camel_1691": 0.7881256937980652, "camel_1706": 0.7885019779205322, "camel_1643": 0.791332483291626, "camel_1743": 0.7925070524215698, "camel_1614": 0.7933542132377625, "camel_1697": 0.7936207056045532, "camel_1751": 0.7948406338691711, "camel_1714": 0.7953439354896545, "camel_48000": 0.7957843542098999, "camel_1727": 0.7977025508880615, "camel_48965": 0.8004768490791321, "camel_1686": 0.8014737367630005, "camel_1735": 0.8029755353927612, "camel_1690": 0.8041508197784424, "camel_1712": 0.8052200675010681, "camel_48078": 0.8066173195838928, "camel_1732": 0.8090149164199829, "camel_1725": 0.8106478452682495, "camel_1746": 0.8143603205680847, "camel_48010": 0.815581202507019, "camel_1719": 0.8159455060958862, "camel_1713": 0.8171189427375793, "camel_1711": 0.8179538249969482}, "TheoremQA_elainewan/econ_micro_11.json": {"TheoremQA_elainewan/econ_micro_11.json": 0, "camel_38125": 0.7838398218154907, "camel_41771": 0.7838567495346069, "camel_41832": 0.7839617133140564, "camel_39867": 0.7840048670768738, "camel_40932": 0.7842165231704712, "camel_38313": 0.784263551235199, "camel_38319": 0.7844018936157227, "camel_38922": 0.78458172082901, "camel_39879": 0.7845834493637085, "camel_41972": 0.7847683429718018, "camel_40940": 0.7847759127616882, "camel_40653": 0.7848398089408875, "camel_40732": 0.7848926186561584, "camel_25187": 0.7848966717720032, "camel_38110": 0.7850715517997742, "camel_41615": 0.7857222557067871, "camel_39845": 0.7860532402992249, "camel_38613": 0.7861785888671875, "camel_39860": 0.7861917614936829, "camel_17532": 0.7862774133682251, "camel_41838": 0.7862807512283325, "camel_39300": 0.7863239645957947, "math_test_algebra_1095": 0.7864369750022888, "camel_38947": 0.7867471575737, "camel_21598": 0.7868324518203735, "camel_24893": 0.7871307134628296, "camel_39724": 0.7872070074081421, "camel_39870": 0.7877206802368164, "camel_38252": 0.7881000638008118, "camel_39048": 0.7883114814758301, "camel_38833": 0.7887375950813293, "camel_41170": 0.7890651226043701, "camel_25133": 0.7893591523170471, "camel_38032": 0.7893933057785034, "camel_40717": 0.7894128561019897, "camel_40810": 0.7894976735115051, "camel_38332": 0.7895053029060364, "camel_38866": 0.7895387411117554, "camel_38245": 0.7897466421127319, "camel_39858": 0.7899861931800842, "camel_38162": 0.7901945114135742, "camel_38398": 0.7903825640678406, "camel_39068": 0.7905027270317078, "camel_38968": 0.7906665802001953, "camel_7712": 0.7907261848449707, "camel_39055": 0.7908229231834412, "camel_39754": 0.7909063696861267, "camel_39895": 0.79152512550354, "camel_6973": 0.7916467189788818, "camel_38310": 0.792217493057251, "camel_38173": 0.7924319505691528, "camel_38047": 0.7927069664001465, "camel_38929": 0.7927254438400269, "camel_41651": 0.792905330657959, "camel_39919": 0.7932180762290955, "camel_39056": 0.7934707999229431, "camel_38091": 0.7935503721237183, "math_train_algebra_1669": 0.7939555048942566, "camel_38318": 0.7942796945571899, "camel_38856": 0.794420599937439, "camel_39340": 0.7945586442947388, "camel_40800": 0.7947907447814941, "camel_24544": 0.7949272394180298, "camel_39057": 0.7949910163879395, "camel_38824": 0.7950992584228516, "camel_38644": 0.7951862215995789, "camel_38729": 0.7952894568443298, "camel_38871": 0.7954361438751221, "camel_40890": 0.7954832911491394, "math_test_algebra_2543": 0.7955172061920166, "camel_38317": 0.795804500579834, "camel_39856": 0.7959968447685242, "camel_38281": 0.7960888743400574, "camel_24729": 0.7965113520622253, "camel_41749": 0.7968048453330994, "camel_39872": 0.7969005107879639, "camel_39843": 0.7969256043434143, "camel_40759": 0.7969571352005005, "camel_39854": 0.7975303530693054, "math_train_algebra_488": 0.7975378632545471, "camel_40697": 0.7975622415542603, "camel_39881": 0.7977697849273682, "camel_39857": 0.7980927228927612, "camel_39878": 0.798204779624939, "camel_39896": 0.7982605695724487, "camel_40916": 0.7984856367111206, "camel_41992": 0.7987082004547119, "camel_38131": 0.7991957068443298, "camel_38798": 0.7993828058242798, "camel_38180": 0.7994610667228699, "camel_40712": 0.7995103597640991, "camel_7017": 0.7995375394821167, "camel_41906": 0.7998680472373962, "camel_39902": 0.8000651001930237, "camel_39886": 0.8003971576690674, "camel_38195": 0.8007371425628662, "camel_7021": 0.8008618950843811, "camel_39914": 0.8010892868041992, "camel_39859": 0.8011825084686279, "aqua_rat_39466": 0.8012288808822632, "camel_38306": 0.8017789721488953, "camel_25161": 0.803178071975708, "camel_40901": 0.8035452961921692, "camel_41821": 0.8035831451416016, "camel_24556": 0.8042953610420227, "camel_39112": 0.8043148517608643, "camel_39880": 0.8045743107795715, "camel_40956": 0.8047649264335632, "camel_40933": 0.8054433465003967, "camel_39903": 0.8060376644134521, "camel_39866": 0.8066140413284302, "camel_41451": 0.8067657947540283, "camel_39552": 0.8070067763328552, "camel_24531": 0.8072834014892578, "camel_25178": 0.8075730800628662, "camel_39851": 0.8077154159545898, "camel_39106": 0.807824432849884, "camel_38828": 0.8081691265106201, "camel_41835": 0.8084684610366821, "camel_40942": 0.8085797429084778, "camel_6967": 0.8091304898262024, "camel_40947": 0.8094435930252075, "camel_39115": 0.8095428943634033, "camel_39842": 0.8102763295173645, "camel_40669": 0.81048583984375, "camel_39519": 0.8106238842010498, "camel_38224": 0.8108044266700745, "camel_38084": 0.8108564019203186, "camel_6193": 0.8109162449836731, "camel_37727": 0.811176061630249, "camel_40772": 0.8115430474281311, "camel_38874": 0.8122677206993103, "camel_40647": 0.8132084012031555, "camel_39868": 0.8140349984169006, "camel_39846": 0.814491331577301, "camel_25123": 0.8147968649864197, "math_test_algebra_812": 0.8148351311683655, "camel_39910": 0.8154175281524658, "camel_38439": 0.8160159587860107, "camel_38099": 0.8163678646087646, "camel_39084": 0.8167028427124023, "camel_6982": 0.817092776298523, "camel_24553": 0.8177833557128906, "camel_39894": 0.8184714913368225, "camel_41143": 0.8185416460037231, "camel_40661": 0.8187641501426697, "camel_39874": 0.8191381096839905, "camel_39852": 0.819241464138031, "camel_6228": 0.8192473649978638, "camel_39877": 0.8200270533561707, "camel_39888": 0.8205137848854065, "camel_40822": 0.820666491985321, "camel_38863": 0.8207863569259644, "camel_41898": 0.8209327459335327, "camel_39840": 0.821013331413269, "camel_38203": 0.8216705322265625, "camel_39887": 0.8217795491218567, "camel_37999": 0.8234277963638306, "camel_38628": 0.8248240351676941, "camel_24530": 0.8251621723175049, "camel_38155": 0.8260498046875, "camel_39464": 0.8262430429458618, "camel_39897": 0.8264685869216919, "camel_39884": 0.8267271518707275, "camel_38928": 0.8273776173591614, "camel_39893": 0.8274064064025879, "camel_39603": 0.8296235799789429, "camel_39890": 0.8300721049308777, "camel_39905": 0.8305065035820007, "camel_39909": 0.8305773735046387, "camel_38304": 0.8307966589927673, "camel_39853": 0.8310483694076538, "camel_39917": 0.8311227560043335, "camel_39093": 0.8319848775863647, "camel_6214": 0.8335501551628113, "camel_39114": 0.8335568308830261, "camel_40698": 0.8340114951133728, "camel_39094": 0.8345960974693298, "camel_39883": 0.8351461291313171, "camel_39119": 0.8356543779373169, "camel_40907": 0.8357531428337097, "camel_6185": 0.8364114761352539, "camel_38220": 0.8367184996604919, "camel_39873": 0.8379981517791748, "camel_39885": 0.838081419467926, "camel_41923": 0.8389451503753662, "camel_40704": 0.8394148945808411, "camel_39871": 0.8396990895271301, "camel_39388": 0.8401852250099182, "camel_39913": 0.8427074551582336, "camel_40682": 0.8444364666938782, "camel_39908": 0.8473057746887207, "camel_38205": 0.8486390113830566, "camel_40796": 0.8514494895935059, "camel_39502": 0.8529344201087952, "camel_38362": 0.8540120720863342, "camel_39861": 0.8540747761726379, "camel_38256": 0.8651478290557861, "camel_39332": 0.8726259469985962}, "TheoremQA_jianyu_xu/Catalan_1.json": {"camel_20783": 0, "camel_21970": 0, "camel_20721": 0, "camel_21955": 0, "camel_20392": 0, "camel_21950": 0, "camel_21993": 0, "camel_21999": 0, "camel_21978": 0, "camel_21987": 0, "camel_21958": 0, "camel_21963": 0, "camel_21943": 0, "camel_21953": 0, "camel_21941": 0, "camel_21985": 0, "camel_21935": 0, "camel_21986": 0, "camel_21979": 0, "camel_21934": 0, "camel_21959": 0, "camel_21974": 0, "camel_21925": 0, "camel_21951": 0, "camel_21920": 0, "camel_20734": 0, "camel_20744": 0, "camel_21922": 0, "camel_21981": 0, "camel_21996": 0, "camel_21988": 0, "camel_21994": 0, "camel_21271": 0, "camel_21035": 0, "aqua_rat_80651": 0.6380597352981567, "gsm_rft_16803": 0.638071596622467, "aqua_rat_75127": 0.6381916999816895, "aqua_rat_54343": 0.6382309794425964, "gsm_rft_14748": 0.6384575366973877, "camel_37605": 0.6385223865509033, "camel_22707": 0.6387075781822205, "aqua_rat_30701": 0.6388644576072693, "aqua_rat_693": 0.6389822959899902, "math_train_counting_and_probability_5011": 0.6390088796615601, "aqua_rat_4270": 0.6390215754508972, "gsm_rft_539": 0.6390247344970703, "gsm_train_12073": 0.6391919851303101, "gsm_rft_13579": 0.6391919851303101, "gsm_rft_15298": 0.6392506957054138, "aqua_rat_43833": 0.639263391494751, "aqua_rat_43678": 0.6392639875411987, "aqua_rat_48706": 0.6392667293548584, "aqua_rat_67046": 0.6393207311630249, "aqua_rat_5729": 0.6393915414810181, "gsm_rft_33250": 0.6396090388298035, "camel_37644": 0.6398124098777771, "math_test_counting_and_probability_279": 0.6399263143539429, "aqua_rat_7405": 0.6401836276054382, "aqua_rat_55472": 0.640213668346405, "aqua_rat_1237": 0.6402609348297119, "aqua_rat_36560": 0.6402626633644104, "aqua_rat_46577": 0.6408233642578125, "aqua_rat_73050": 0.6412185430526733, "aqua_rat_14820": 0.6416410803794861, "aqua_rat_86944": 0.6416849493980408, "aqua_rat_29631": 0.6420244574546814, "aqua_rat_60100": 0.6421288251876831, "aqua_rat_62064": 0.6421886682510376, "aqua_rat_55110": 0.6422510743141174, "aqua_rat_60691": 0.6423720121383667, "aqua_rat_14545": 0.6425662636756897, "aqua_rat_27359": 0.642568826675415, "aqua_rat_11240": 0.6429508328437805, "gsm_rft_5531": 0.6430469751358032, "camel_25601": 0.6430503129959106, "aqua_rat_3131": 0.6432149410247803, "gsm_rft_12953": 0.6436523199081421, "aqua_rat_15355": 0.6440647840499878, "gsm_rft_15866": 0.644110918045044, "gsm_train_18438": 0.644110918045044, "aqua_rat_67912": 0.6442078351974487, "camel_37625": 0.6444153189659119, "aqua_rat_14": 0.6444386839866638, "gsm_rft_31832": 0.6444724798202515, "aqua_rat_62566": 0.6445226073265076, "aqua_rat_75580": 0.6455343961715698, "aqua_rat_53907": 0.6457657217979431, "math_train_prealgebra_1415": 0.6458436250686646, "camel_37606": 0.6458826065063477, "aqua_rat_6437": 0.6461567878723145, "aqua_rat_81312": 0.6461923122406006, "aqua_rat_15612": 0.6462956666946411, "math_train_counting_and_probability_5044": 0.6464430093765259, "aqua_rat_35937": 0.6465920209884644, "aqua_rat_80580": 0.6470138430595398, "aqua_rat_88691": 0.6472052931785583, "aqua_rat_12408": 0.647493302822113, "camel_25649": 0.6480292677879333, "camel_24689": 0.6484193801879883, "math_test_counting_and_probability_652": 0.6487500667572021, "aqua_rat_46999": 0.6489552855491638, "aqua_rat_79317": 0.6490843892097473, "aqua_rat_52866": 0.6492542028427124, "camel_37632": 0.6495662927627563, "math_test_counting_and_probability_747": 0.6498250365257263, "math_test_counting_and_probability_894": 0.6498768925666809, "aqua_rat_68930": 0.6506792306900024, "aqua_rat_83470": 0.6507329344749451, "aqua_rat_73009": 0.6509845852851868, "camel_37615": 0.6511926054954529, "aqua_rat_31528": 0.651277482509613, "aqua_rat_2962": 0.6514552235603333, "aqua_rat_67804": 0.651911735534668, "aqua_rat_85987": 0.652485728263855, "camel_37642": 0.6529478430747986, "aqua_rat_44526": 0.6533684730529785, "aqua_rat_63487": 0.6535170078277588, "aqua_rat_31473": 0.6536864638328552, "TheoremQA_xinyi/dag_1.json": 0.6540181636810303, "aqua_rat_73045": 0.6541039943695068, "aqua_rat_24191": 0.6543266177177429, "aqua_rat_78357": 0.6543883681297302, "aqua_rat_60315": 0.6544039845466614, "aqua_rat_50640": 0.654492199420929, "aqua_rat_351": 0.6555623412132263, "camel_25608": 0.6559696793556213, "aqua_rat_24032": 0.655972421169281, "aqua_rat_3565": 0.6560668349266052, "aqua_rat_15856": 0.6582089066505432, "aqua_rat_46132": 0.6585654020309448, "aqua_rat_64700": 0.6589274406433105, "math_train_counting_and_probability_592": 0.6592311859130859, "aqua_rat_12332": 0.6603400111198425, "aqua_rat_77042": 0.6604161262512207, "camel_37649": 0.6614000797271729, "aqua_rat_35224": 0.6615616679191589, "aqua_rat_27920": 0.6620011925697327, "aqua_rat_48212": 0.6625856757164001, "aqua_rat_74406": 0.662706196308136, "aqua_rat_88984": 0.6644220948219299, "aqua_rat_44454": 0.6663224101066589, "aqua_rat_18981": 0.666326105594635, "gsm_train_7859": 0.6667004823684692, "aqua_rat_47964": 0.6668490767478943, "aqua_rat_61273": 0.6671732664108276, "gsm_rft_27762": 0.667201817035675, "gsm_rft_24665": 0.667201817035675, "aqua_rat_88126": 0.6675244569778442, "aqua_rat_50142": 0.667715311050415, "aqua_rat_25080": 0.667890191078186, "math_train_counting_and_probability_797": 0.6683266162872314, "aqua_rat_60535": 0.6683909296989441, "aqua_rat_36302": 0.6691595911979675, "aqua_rat_37133": 0.6696873307228088, "aqua_rat_33138": 0.6698348522186279, "math_train_counting_and_probability_5061": 0.6698379516601562, "aqua_rat_38718": 0.6699017882347107, "aqua_rat_3702": 0.6699387431144714, "aqua_rat_59572": 0.6700965762138367, "aqua_rat_75443": 0.6702343225479126, "aqua_rat_31476": 0.6703259348869324, "aqua_rat_26293": 0.6714997291564941, "aqua_rat_72007": 0.6722803711891174, "aqua_rat_69734": 0.672281801700592, "aqua_rat_52759": 0.6724381446838379, "aqua_rat_66165": 0.6727443337440491, "aqua_rat_46637": 0.6730968952178955, "aqua_rat_85332": 0.6735592484474182, "aqua_rat_38335": 0.6742956638336182, "math_train_counting_and_probability_5121": 0.6751118898391724, "aqua_rat_9837": 0.6759304404258728, "aqua_rat_37490": 0.6763167381286621, "aqua_rat_54560": 0.6776010990142822, "aqua_rat_39611": 0.6779778599739075, "aqua_rat_21233": 0.6779829859733582, "aqua_rat_28508": 0.6781882643699646, "aqua_rat_37678": 0.6798657774925232, "aqua_rat_39212": 0.6815823316574097, "aqua_rat_78291": 0.6823137998580933, "aqua_rat_88225": 0.682530403137207, "aqua_rat_26871": 0.6888813972473145, "aqua_rat_15155": 0.6889467239379883, "aqua_rat_22125": 0.6891191601753235, "aqua_rat_63325": 0.6922645568847656, "aqua_rat_53479": 0.6927524209022522, "aqua_rat_40713": 0.6971965432167053, "aqua_rat_84407": 0.6978646516799927, "aqua_rat_63918": 0.7019826769828796, "aqua_rat_13218": 0.7041189670562744, "aqua_rat_51470": 0.7056272029876709, "math_train_counting_and_probability_600": 0.7062847018241882, "aqua_rat_60481": 0.7119309902191162, "aqua_rat_51040": 0.7123936414718628, "math_train_prealgebra_446": 0.7159579396247864, "aqua_rat_75954": 0.7172179222106934, "aqua_rat_29122": 0.7195056676864624, "aqua_rat_3763": 0.7201483845710754, "aqua_rat_32304": 0.7211517095565796, "math_train_counting_and_probability_979": 0.7268291711807251, "math_train_counting_and_probability_757": 0.7397749423980713}, "TheoremQA_jianyu_xu/Binomial_3.json": {"camel_20930": 0, "camel_20246": 0, "camel_21419": 0, "camel_20998": 0, "camel_20269": 0, "camel_21526": 0, "camel_20915": 0, "camel_21480": 0, "camel_21421": 0, "camel_20874": 0, "camel_20546": 0, "camel_20256": 0, "camel_21426": 0, "camel_20002": 0, "camel_20260": 0, "camel_20287": 0, "camel_20022": 0, "TheoremQA_jianyu_xu/Binomial_3.json": 0, "aqua_rat_75234": 0.8476074934005737, "aqua_rat_43452": 0.8476088643074036, "aqua_rat_43541": 0.8476864695549011, "aqua_rat_27837": 0.847901463508606, "aqua_rat_9536": 0.8479201793670654, "aqua_rat_25443": 0.8484188318252563, "aqua_rat_85723": 0.8485074639320374, "aqua_rat_35044": 0.8485125303268433, "aqua_rat_33011": 0.8485918641090393, "aqua_rat_7035": 0.8486664295196533, "aqua_rat_58614": 0.8486775159835815, "aqua_rat_31666": 0.8487418293952942, "aqua_rat_49782": 0.8488442897796631, "aqua_rat_15099": 0.8489733338356018, "aqua_rat_50652": 0.8489915728569031, "aqua_rat_2090": 0.8490290641784668, "aqua_rat_25181": 0.8490579724311829, "aqua_rat_85740": 0.8490782976150513, "aqua_rat_7992": 0.8491023778915405, "aqua_rat_7237": 0.8493092060089111, "aqua_rat_29563": 0.849349856376648, "aqua_rat_85232": 0.8494386672973633, "aqua_rat_59675": 0.8494561314582825, "aqua_rat_86028": 0.8495180010795593, "aqua_rat_42231": 0.8497545719146729, "aqua_rat_76775": 0.8498179912567139, "aqua_rat_8707": 0.8499497175216675, "aqua_rat_25293": 0.849963366985321, "aqua_rat_24688": 0.8500404357910156, "TheoremQA_jianyu_xu/Binomial_5.json": 0.8500586748123169, "aqua_rat_41775": 0.8501089811325073, "aqua_rat_26058": 0.8501172065734863, "aqua_rat_52092": 0.8501256108283997, "aqua_rat_32295": 0.8501693606376648, "aqua_rat_28421": 0.8502370119094849, "aqua_rat_20243": 0.8502528071403503, "aqua_rat_2208": 0.8502625823020935, "aqua_rat_50689": 0.850267231464386, "math_train_counting_and_probability_437": 0.850283682346344, "aqua_rat_53852": 0.8503121733665466, "aqua_rat_29035": 0.8503320217132568, "aqua_rat_86575": 0.8505799174308777, "aqua_rat_19040": 0.8506546020507812, "aqua_rat_75739": 0.8506917357444763, "aqua_rat_16863": 0.8508197069168091, "aqua_rat_71071": 0.8508272171020508, "aqua_rat_75866": 0.8508520722389221, "aqua_rat_56907": 0.8509793281555176, "aqua_rat_41111": 0.8511038422584534, "aqua_rat_87471": 0.8512054681777954, "aqua_rat_52517": 0.8513341546058655, "math_train_counting_and_probability_562": 0.8513379096984863, "aqua_rat_83208": 0.8514404296875, "aqua_rat_59203": 0.8514423370361328, "aqua_rat_779": 0.8514857888221741, "aqua_rat_79401": 0.8516287207603455, "aqua_rat_28401": 0.8516747355461121, "aqua_rat_30726": 0.8519350290298462, "aqua_rat_50830": 0.8522456288337708, "aqua_rat_64919": 0.8522688746452332, "aqua_rat_72310": 0.852321982383728, "aqua_rat_81276": 0.85234135389328, "aqua_rat_88861": 0.8523532748222351, "aqua_rat_84736": 0.852380096912384, "aqua_rat_12838": 0.8524165153503418, "aqua_rat_13414": 0.8524917960166931, "aqua_rat_10665": 0.8525955677032471, "aqua_rat_2630": 0.8526961207389832, "aqua_rat_19956": 0.8528875708580017, "aqua_rat_8260": 0.853152871131897, "aqua_rat_58855": 0.8532992005348206, "aqua_rat_51198": 0.8533053398132324, "aqua_rat_22565": 0.8534597158432007, "aqua_rat_19345": 0.8539822697639465, "aqua_rat_47506": 0.8542352318763733, "aqua_rat_40846": 0.8542374968528748, "aqua_rat_46635": 0.8542802333831787, "aqua_rat_86045": 0.8543992638587952, "aqua_rat_82553": 0.8544583320617676, "aqua_rat_18452": 0.8545116782188416, "aqua_rat_77361": 0.8545821309089661, "aqua_rat_72538": 0.8545876741409302, "aqua_rat_1181": 0.8547934293746948, "aqua_rat_60350": 0.8549496531486511, "aqua_rat_81932": 0.8550229072570801, "aqua_rat_8218": 0.8551343083381653, "aqua_rat_51656": 0.8551515340805054, "aqua_rat_8760": 0.855310320854187, "aqua_rat_62773": 0.8553515672683716, "aqua_rat_25692": 0.8556341528892517, "aqua_rat_3853": 0.8559218645095825, "aqua_rat_51384": 0.8559361100196838, "aqua_rat_37561": 0.8561504483222961, "aqua_rat_54922": 0.8562350869178772, "aqua_rat_77458": 0.8562474250793457, "aqua_rat_11962": 0.8562653064727783, "aqua_rat_29054": 0.856295645236969, "aqua_rat_9589": 0.8564980030059814, "aqua_rat_42608": 0.856564462184906, "aqua_rat_67630": 0.856657862663269, "aqua_rat_75537": 0.856718122959137, "aqua_rat_38947": 0.8568574786186218, "aqua_rat_81390": 0.857133150100708, "aqua_rat_10280": 0.857288658618927, "aqua_rat_6878": 0.8575074672698975, "aqua_rat_3934": 0.8575546145439148, "aqua_rat_75780": 0.857699990272522, "aqua_rat_50290": 0.8581908941268921, "aqua_rat_69282": 0.8583158254623413, "aqua_rat_71181": 0.8583494424819946, "aqua_rat_67753": 0.8583795428276062, "aqua_rat_28153": 0.8584724068641663, "aqua_rat_71578": 0.8586391806602478, "aqua_rat_4069": 0.8588962554931641, "math_test_counting_and_probability_535": 0.859114408493042, "aqua_rat_82085": 0.8592177033424377, "aqua_rat_35078": 0.8601897358894348, "aqua_rat_42205": 0.8602131009101868, "aqua_rat_10456": 0.8608208894729614, "aqua_rat_60774": 0.8611524105072021, "aqua_rat_51723": 0.8616039156913757, "aqua_rat_23327": 0.8617303371429443, "aqua_rat_63254": 0.8620392680168152, "math_train_counting_and_probability_249": 0.8620793223381042, "aqua_rat_10119": 0.8620977997779846, "aqua_rat_28183": 0.8621302843093872, "aqua_rat_55590": 0.8622674942016602, "aqua_rat_7156": 0.8624531030654907, "aqua_rat_2653": 0.8626804947853088, "aqua_rat_9526": 0.8627360463142395, "aqua_rat_29018": 0.8628836274147034, "aqua_rat_35517": 0.862921416759491, "aqua_rat_28237": 0.8629971742630005, "aqua_rat_48220": 0.8630521297454834, "aqua_rat_72401": 0.8631499409675598, "aqua_rat_76349": 0.8632127046585083, "aqua_rat_40174": 0.8635257482528687, "aqua_rat_69481": 0.8638901710510254, "aqua_rat_35395": 0.8639301061630249, "aqua_rat_63415": 0.8640281558036804, "aqua_rat_67337": 0.8640284538269043, "aqua_rat_82087": 0.8641529083251953, "aqua_rat_30122": 0.8643583059310913, "aqua_rat_79851": 0.8643921613693237, "aqua_rat_29732": 0.8645344376564026, "aqua_rat_40137": 0.8645662665367126, "aqua_rat_75249": 0.8645886778831482, "aqua_rat_63209": 0.8654548525810242, "aqua_rat_61775": 0.8659688234329224, "aqua_rat_23041": 0.8664574027061462, "aqua_rat_31467": 0.8667618632316589, "aqua_rat_37993": 0.8668302893638611, "aqua_rat_23820": 0.8670579195022583, "aqua_rat_15917": 0.8672915697097778, "aqua_rat_32475": 0.8679866790771484, "aqua_rat_36512": 0.8680529594421387, "aqua_rat_81548": 0.8680732250213623, "aqua_rat_36115": 0.8685140013694763, "aqua_rat_14825": 0.8694135546684265, "aqua_rat_58309": 0.869592010974884, "aqua_rat_84957": 0.8704044818878174, "aqua_rat_63741": 0.8705222606658936, "aqua_rat_53467": 0.8706742525100708, "aqua_rat_80017": 0.8707513809204102, "aqua_rat_31360": 0.8713156580924988, "aqua_rat_8338": 0.8713669776916504, "aqua_rat_35015": 0.8718857169151306, "aqua_rat_75475": 0.8719061017036438, "aqua_rat_10394": 0.8723589181900024, "aqua_rat_65577": 0.8723681569099426, "aqua_rat_46850": 0.8725855350494385, "aqua_rat_59747": 0.8736996650695801, "aqua_rat_78014": 0.8738622665405273, "aqua_rat_15343": 0.8740120530128479, "aqua_rat_16762": 0.8757074475288391, "aqua_rat_74949": 0.875882089138031, "aqua_rat_22465": 0.8769845366477966, "aqua_rat_9713": 0.8774985074996948, "aqua_rat_8728": 0.8778767585754395, "aqua_rat_2112": 0.8818551898002625, "aqua_rat_5150": 0.8824999928474426, "aqua_rat_25421": 0.8832568526268005}, "TheoremQA_elainewan/econ_micro_18.json": {"camel_24259": 0, "camel_25329": 0, "camel_24418": 0, "camel_24706": 0, "camel_25146": 0, "camel_25446": 0, "camel_25229": 0, "camel_25620": 0, "camel_25232": 0, "camel_25360": 0, "camel_25268": 0, "camel_25307": 0, "camel_25501": 0, "camel_25356": 0, "camel_25201": 0, "camel_25272": 0, "camel_24273": 0, "camel_25892": 0, "camel_25234": 0, "camel_25275": 0, "camel_25338": 0, "camel_25281": 0, "camel_25302": 0, "camel_25155": 0, "camel_25316": 0, "camel_25513": 0, "camel_24369": 0, "camel_25209": 0, "camel_25177": 0, "camel_25337": 0, "camel_25213": 0, "camel_24401": 0, "camel_25137": 0, "camel_25171": 0, "camel_24354": 0, "camel_25117": 0, "camel_25391": 0, "camel_24422": 0, "camel_25902": 0, "camel_25183": 0, "camel_25325": 0, "camel_25323": 0, "camel_25305": 0, "camel_25274": 0, "camel_25958": 0, "camel_25349": 0, "camel_24316": 0, "camel_25359": 0, "camel_25911": 0, "camel_25341": 0, "camel_25237": 0, "camel_25157": 0, "camel_25135": 0, "camel_25263": 0, "camel_25131": 0, "camel_25204": 0, "camel_24291": 0, "camel_25246": 0, "camel_25240": 0, "camel_24331": 0, "camel_24649": 0, "camel_25169": 0, "camel_25139": 0, "camel_25193": 0, "camel_25294": 0, "camel_25300": 0, "camel_24415": 0, "camel_25129": 0, "camel_25345": 0, "camel_24343": 0, "camel_25330": 0, "camel_25693": 0, "camel_25258": 0, "camel_25273": 0, "camel_25243": 0, "camel_24707": 0, "camel_24644": 0, "camel_25314": 0, "camel_25165": 0, "camel_25318": 0, "camel_25805": 0, "camel_25226": 0, "camel_25265": 0, "camel_25332": 0, "camel_25343": 0, "camel_25208": 0, "camel_25168": 0, "camel_25160": 0, "camel_25140": 0, "camel_25152": 0, "camel_25207": 0, "camel_25688": 0, "camel_25299": 0, "camel_24476": 0, "camel_25216": 0, "camel_25227": 0, "camel_25238": 0, "camel_24462": 0, "camel_25244": 0, "camel_25125": 0, "camel_25124": 0, "camel_25136": 0, "camel_25198": 0, "camel_25321": 0, "camel_25863": 0, "camel_25249": 0, "camel_25247": 0, "camel_25181": 0, "camel_25184": 0, "camel_25241": 0, "camel_24443": 0, "camel_25159": 0, "camel_25175": 0, "camel_25239": 0, "camel_25214": 0, "camel_25367": 0, "camel_25172": 0, "camel_24349": 0, "camel_25334": 0, "camel_25189": 0, "camel_25212": 0, "camel_25251": 0, "camel_25257": 0, "camel_25147": 0, "camel_24355": 0, "camel_25121": 0, "camel_25221": 0, "camel_25357": 0, "camel_25224": 0, "camel_25291": 0, "camel_25043": 0, "camel_25270": 0, "camel_24708": 0, "camel_25279": 0, "camel_25256": 0, "camel_25176": 0, "camel_24386": 0, "camel_25496": 0, "camel_25253": 0, "camel_24368": 0, "camel_25156": 0, "camel_25278": 0, "camel_25219": 0, "camel_24715": 0, "camel_25287": 0, "camel_25335": 0, "camel_25292": 0, "camel_25127": 0, "camel_25322": 0, "camel_25197": 0, "camel_24463": 0, "camel_24467": 0, "camel_25231": 0, "camel_25230": 0, "camel_25225": 0, "camel_25185": 0, "camel_25282": 0, "TheoremQA_elainewan/econ_micro_18.json": 0, "camel_37708": 0.7733074426651001, "camel_37618": 0.7739487290382385, "aqua_rat_41336": 0.7748011350631714, "math_test_counting_and_probability_266": 0.776103675365448, "math_test_counting_and_probability_436": 0.7761796712875366, "camel_38758": 0.776824414730072, "camel_37714": 0.7784935832023621, "camel_37693": 0.7798699140548706, "camel_37685": 0.7813675999641418, "camel_37629": 0.7852547764778137, "camel_37682": 0.786232590675354, "camel_37635": 0.7887943983078003, "camel_37758": 0.7892638444900513, "camel_37703": 0.789507269859314, "camel_37744": 0.7913827300071716, "camel_39399": 0.7915996313095093, "camel_37740": 0.7916013598442078, "camel_37709": 0.7934582829475403, "camel_10305": 0.7940633296966553, "camel_38662": 0.8004356622695923, "camel_37684": 0.8030330538749695, "camel_37706": 0.8036362528800964, "camel_37697": 0.8050112724304199, "camel_37749": 0.8063110709190369, "camel_37750": 0.8067640066146851, "camel_37696": 0.8068925142288208, "camel_37756": 0.8084058165550232, "camel_37651": 0.809532880783081, "camel_37738": 0.8103365898132324, "camel_37752": 0.8141258358955383, "camel_37680": 0.8154012560844421, "camel_37745": 0.8160727024078369, "camel_37742": 0.8163513541221619, "camel_37700": 0.8170853853225708, "camel_37691": 0.8178728818893433, "camel_37741": 0.8179140090942383, "camel_37751": 0.8182341456413269, "camel_37669": 0.8207547068595886, "camel_37716": 0.8260958790779114, "camel_37729": 0.8263476490974426, "camel_39397": 0.8335766792297363, "camel_37701": 0.8519078493118286}, "TheoremQA_jianyu_xu/Multinomial_3.json": {"camel_20813": 0, "camel_20844": 0, "camel_21219": 0, "camel_20038": 0, "camel_20410": 0, "camel_20175": 0, "camel_20942": 0, "camel_20545": 0, "camel_20356": 0, "camel_20985": 0, "camel_20973": 0, "camel_20951": 0, "math_train_counting_and_probability_5081": 0.7903171181678772, "math_train_counting_and_probability_890": 0.7903331518173218, "aqua_rat_69484": 0.7903637290000916, "aqua_rat_87221": 0.7903846502304077, "aqua_rat_10199": 0.7904068231582642, "aqua_rat_75009": 0.7904433608055115, "aqua_rat_23851": 0.7905282378196716, "aqua_rat_4325": 0.7905455231666565, "aqua_rat_7596": 0.7905986309051514, "aqua_rat_85194": 0.7906137704849243, "aqua_rat_3845": 0.790704607963562, "aqua_rat_77566": 0.7911620140075684, "aqua_rat_3695": 0.7913388013839722, "aqua_rat_69806": 0.7913711667060852, "aqua_rat_66615": 0.7913779020309448, "aqua_rat_36909": 0.7914223670959473, "aqua_rat_13164": 0.791426956653595, "aqua_rat_75309": 0.791470468044281, "aqua_rat_29348": 0.7915143966674805, "aqua_rat_15196": 0.7915231585502625, "aqua_rat_56615": 0.7917359471321106, "aqua_rat_12911": 0.791795551776886, "aqua_rat_48327": 0.7918122410774231, "aqua_rat_16439": 0.7919373512268066, "aqua_rat_73428": 0.7919454574584961, "aqua_rat_13881": 0.7919718623161316, "aqua_rat_88638": 0.792079746723175, "aqua_rat_22727": 0.7921114563941956, "aqua_rat_78519": 0.792111873626709, "aqua_rat_48912": 0.7921919226646423, "math_train_counting_and_probability_379": 0.7924048900604248, "math_train_prealgebra_1167": 0.7924327254295349, "aqua_rat_86254": 0.7924503684043884, "aqua_rat_3295": 0.7924851179122925, "math_train_counting_and_probability_585": 0.7926544547080994, "aqua_rat_43628": 0.7928380370140076, "aqua_rat_57936": 0.7928763031959534, "aqua_rat_7726": 0.7929091453552246, "math_train_prealgebra_408": 0.7929439544677734, "aqua_rat_3368": 0.7931532263755798, "aqua_rat_68365": 0.7934491634368896, "math_test_prealgebra_2024": 0.7935603857040405, "aqua_rat_78144": 0.7935943007469177, "aqua_rat_55961": 0.793624997138977, "aqua_rat_79918": 0.7939040660858154, "aqua_rat_10824": 0.7940050959587097, "aqua_rat_5552": 0.7940846085548401, "aqua_rat_8694": 0.7943581342697144, "aqua_rat_7139": 0.7944586277008057, "aqua_rat_22458": 0.7947095036506653, "aqua_rat_60578": 0.7947446703910828, "aqua_rat_30725": 0.7947888374328613, "aqua_rat_32937": 0.7950395345687866, "aqua_rat_57767": 0.7950994372367859, "aqua_rat_57419": 0.7952263355255127, "aqua_rat_14321": 0.7954134941101074, "aqua_rat_26857": 0.7954314947128296, "math_test_counting_and_probability_704": 0.7954759001731873, "aqua_rat_8477": 0.7955432534217834, "aqua_rat_43512": 0.7955800890922546, "aqua_rat_19798": 0.7956920862197876, "aqua_rat_53190": 0.795726478099823, "aqua_rat_59175": 0.7957324981689453, "aqua_rat_38104": 0.7957949638366699, "aqua_rat_28496": 0.7958046197891235, "aqua_rat_67870": 0.7959104776382446, "aqua_rat_19714": 0.7959244847297668, "aqua_rat_13869": 0.7960212826728821, "math_train_prealgebra_172": 0.7960246205329895, "aqua_rat_66723": 0.7962382435798645, "math_train_counting_and_probability_29": 0.7962736487388611, "aqua_rat_40828": 0.7964154481887817, "aqua_rat_11652": 0.7965131998062134, "aqua_rat_17735": 0.7965166568756104, "aqua_rat_21240": 0.7966417670249939, "aqua_rat_11242": 0.7967461347579956, "aqua_rat_74391": 0.796978235244751, "aqua_rat_66920": 0.7976661920547485, "aqua_rat_20874": 0.797903299331665, "aqua_rat_55802": 0.7981547713279724, "aqua_rat_69444": 0.7985494136810303, "aqua_rat_26451": 0.7986081838607788, "aqua_rat_34214": 0.7986271977424622, "aqua_rat_20594": 0.7988210320472717, "aqua_rat_12384": 0.7991530299186707, "aqua_rat_15194": 0.7993944883346558, "aqua_rat_50507": 0.7994551658630371, "aqua_rat_81021": 0.7994982004165649, "aqua_rat_74024": 0.7996068000793457, "aqua_rat_20032": 0.7996142506599426, "aqua_rat_55249": 0.7997534871101379, "aqua_rat_19653": 0.8000114560127258, "aqua_rat_33293": 0.8001026511192322, "aqua_rat_8913": 0.8001822829246521, "aqua_rat_40323": 0.8003345727920532, "aqua_rat_35633": 0.8004679679870605, "aqua_rat_10378": 0.8005472421646118, "aqua_rat_16529": 0.8010897636413574, "aqua_rat_43755": 0.801179826259613, "math_train_counting_and_probability_691": 0.8011887669563293, "aqua_rat_72012": 0.8013310432434082, "aqua_rat_33793": 0.8013805150985718, "aqua_rat_6101": 0.8014736175537109, "aqua_rat_29318": 0.8015525937080383, "aqua_rat_41684": 0.8019041419029236, "aqua_rat_8627": 0.802172064781189, "aqua_rat_19231": 0.8022142052650452, "aqua_rat_88236": 0.8026232123374939, "aqua_rat_25098": 0.8027390241622925, "aqua_rat_34778": 0.8028972148895264, "TheoremQA_jianyu_xu/Multinomial_4.json": 0.8031401634216309, "aqua_rat_25182": 0.8032606244087219, "aqua_rat_50550": 0.8033610582351685, "aqua_rat_12472": 0.8033660054206848, "aqua_rat_4285": 0.8035899996757507, "aqua_rat_32025": 0.8037012815475464, "aqua_rat_67953": 0.803841769695282, "aqua_rat_51420": 0.8039206862449646, "aqua_rat_38599": 0.8040341734886169, "aqua_rat_59942": 0.8041930794715881, "aqua_rat_18729": 0.8044041991233826, "aqua_rat_49713": 0.8051983714103699, "aqua_rat_18788": 0.8052236437797546, "aqua_rat_22599": 0.8052463531494141, "aqua_rat_18863": 0.8052676320075989, "aqua_rat_50319": 0.8053514957427979, "aqua_rat_39440": 0.8058536648750305, "aqua_rat_27623": 0.8062512278556824, "aqua_rat_35638": 0.8064664006233215, "aqua_rat_64457": 0.8066005706787109, "aqua_rat_37766": 0.8066142201423645, "aqua_rat_28710": 0.8067655563354492, "aqua_rat_84792": 0.8068055510520935, "aqua_rat_85339": 0.8069640398025513, "aqua_rat_17800": 0.807168185710907, "aqua_rat_57130": 0.8073662519454956, "aqua_rat_51148": 0.8073874711990356, "aqua_rat_55857": 0.8074435591697693, "aqua_rat_65809": 0.8075679540634155, "aqua_rat_8771": 0.8078425526618958, "aqua_rat_20068": 0.8081361651420593, "aqua_rat_4386": 0.8091471791267395, "aqua_rat_62840": 0.809159517288208, "aqua_rat_28318": 0.809176504611969, "aqua_rat_32634": 0.8097881078720093, "aqua_rat_36073": 0.8100101947784424, "math_train_counting_and_probability_24": 0.8100318908691406, "aqua_rat_7588": 0.8105535507202148, "aqua_rat_73283": 0.8109511137008667, "aqua_rat_45011": 0.811028003692627, "aqua_rat_7373": 0.8115695118904114, "aqua_rat_51773": 0.8128392696380615, "aqua_rat_3311": 0.8131552338600159, "aqua_rat_33488": 0.8135935068130493, "aqua_rat_8129": 0.8136740326881409, "aqua_rat_46484": 0.8141562342643738, "aqua_rat_69596": 0.8157380819320679, "aqua_rat_77505": 0.8157427906990051, "aqua_rat_67588": 0.8161367774009705, "aqua_rat_53262": 0.8161689639091492, "aqua_rat_65284": 0.8162437081336975, "aqua_rat_66661": 0.8166119456291199, "aqua_rat_30513": 0.816612720489502, "aqua_rat_58870": 0.8166540265083313, "math_test_prealgebra_1107": 0.8169234991073608, "aqua_rat_51800": 0.8173640370368958, "aqua_rat_77275": 0.8177701830863953, "aqua_rat_28709": 0.8189579248428345, "aqua_rat_35991": 0.8190840482711792, "aqua_rat_15466": 0.8194790482521057, "aqua_rat_45147": 0.8200615048408508, "aqua_rat_15353": 0.8201857209205627, "math_test_prealgebra_1204": 0.8203824758529663, "aqua_rat_21632": 0.8206288814544678, "aqua_rat_45246": 0.8212635517120361, "aqua_rat_31049": 0.8219773769378662, "aqua_rat_9005": 0.8227866888046265, "aqua_rat_16417": 0.8235573768615723, "math_train_counting_and_probability_1032": 0.823898196220398, "aqua_rat_41332": 0.8242881894111633, "aqua_rat_4340": 0.8248003125190735, "aqua_rat_45187": 0.8259361386299133, "aqua_rat_34136": 0.8263810276985168, "aqua_rat_9747": 0.8268808126449585, "aqua_rat_36159": 0.8283013105392456, "aqua_rat_38573": 0.8287569284439087, "aqua_rat_34268": 0.8295657634735107, "aqua_rat_16429": 0.8357616662979126}, "TheoremQA_tonyxia/semiconductor2.json": {"TheoremQA_tonyxia/semiconductor2.json": 0, "camel_17812": 0.5776443481445312, "camel_44986": 0.5776655673980713, "camel_45120": 0.577697217464447, "camel_17769": 0.5785559415817261, "camel_45194": 0.5790610909461975, "camel_16563": 0.5790749192237854, "camel_45284": 0.5791692137718201, "camel_43827": 0.5793387293815613, "camel_16649": 0.5797994136810303, "camel_17805": 0.5799242258071899, "camel_16230": 0.5801581144332886, "camel_16662": 0.580164909362793, "camel_16190": 0.580227255821228, "camel_16231": 0.580371618270874, "camel_16719": 0.5804839134216309, "camel_16718": 0.5805281400680542, "camel_17287": 0.5812382102012634, "camel_16695": 0.5818784832954407, "camel_45012": 0.5820846557617188, "camel_45957": 0.5821413993835449, "camel_43965": 0.5823888182640076, "camel_16707": 0.5828177332878113, "camel_45922": 0.5829443335533142, "camel_45931": 0.5829658508300781, "camel_19920": 0.5830870270729065, "camel_16670": 0.5832175016403198, "camel_17818": 0.583682656288147, "camel_29123": 0.5839306116104126, "camel_16653": 0.5840200781822205, "camel_43944": 0.5842182040214539, "camel_16696": 0.5843169689178467, "camel_17787": 0.5844050645828247, "camel_16691": 0.5844758749008179, "camel_16665": 0.5849922895431519, "camel_16675": 0.5850730538368225, "camel_16656": 0.5854371786117554, "camel_16598": 0.5856108069419861, "camel_43964": 0.5857052803039551, "camel_45170": 0.5861215591430664, "camel_29892": 0.5865232348442078, "camel_29155": 0.5872165560722351, "camel_43979": 0.5875621438026428, "camel_17709": 0.587993860244751, "camel_16692": 0.5882257223129272, "camel_16616": 0.5883818864822388, "camel_45958": 0.5890874266624451, "camel_44765": 0.5891067981719971, "camel_16603": 0.5900446772575378, "camel_45033": 0.5901241898536682, "camel_16597": 0.5902636647224426, "camel_29173": 0.5903899669647217, "camel_43931": 0.5906590223312378, "camel_45148": 0.5907954573631287, "camel_16648": 0.5908716320991516, "camel_45144": 0.5911406874656677, "camel_45129": 0.5917367935180664, "camel_45932": 0.5921019315719604, "camel_16628": 0.5927958488464355, "camel_45141": 0.592807412147522, "camel_16579": 0.5928508639335632, "camel_43991": 0.5935110449790955, "camel_17811": 0.5940196514129639, "camel_29145": 0.5945709943771362, "camel_16702": 0.595035970211029, "camel_16209": 0.595212459564209, "camel_45159": 0.5955227017402649, "camel_45963": 0.5958651900291443, "camel_43998": 0.595872700214386, "camel_43987": 0.5962260365486145, "camel_45616": 0.5962541103363037, "camel_29844": 0.5968722701072693, "camel_43956": 0.5970407128334045, "camel_43922": 0.5974353551864624, "camel_16564": 0.5976746082305908, "camel_45983": 0.5990282297134399, "camel_43981": 0.5991228818893433, "camel_16608": 0.5991848707199097, "camel_45192": 0.5996730327606201, "camel_16645": 0.5999776124954224, "camel_43947": 0.6000102162361145, "camel_16658": 0.6001340746879578, "camel_16590": 0.6005086302757263, "camel_29154": 0.6005845069885254, "camel_45933": 0.6010836958885193, "camel_16650": 0.6010856628417969, "camel_16624": 0.6011331081390381, "camel_16641": 0.6018971800804138, "camel_45018": 0.6022285223007202, "camel_16562": 0.6025111079216003, "camel_45340": 0.602769672870636, "camel_43796": 0.6029779314994812, "camel_45657": 0.6037291884422302, "camel_16583": 0.6037848591804504, "camel_29184": 0.6037892699241638, "camel_16686": 0.603928804397583, "camel_29199": 0.6039462089538574, "camel_16679": 0.6043400764465332, "camel_45195": 0.6044602990150452, "camel_17807": 0.6045374870300293, "camel_17772": 0.6048365235328674, "camel_16716": 0.6049739718437195, "camel_45178": 0.6053096652030945, "camel_16588": 0.6053174138069153, "camel_29880": 0.6057324409484863, "camel_17798": 0.607524037361145, "camel_45964": 0.6078549027442932, "camel_16570": 0.6080296635627747, "camel_16589": 0.608173668384552, "camel_16626": 0.6084499359130859, "camel_45952": 0.6084756255149841, "camel_16673": 0.6087190508842468, "camel_45190": 0.6087676882743835, "camel_45302": 0.6095582842826843, "camel_16572": 0.6096042990684509, "camel_16560": 0.6097313165664673, "camel_16623": 0.6099096536636353, "camel_45295": 0.6102006435394287, "camel_16636": 0.6108667850494385, "camel_29915": 0.611243486404419, "camel_16651": 0.611473023891449, "camel_43792": 0.6117165088653564, "camel_16622": 0.6118568778038025, "camel_16618": 0.6121070981025696, "camel_45131": 0.612153172492981, "camel_16676": 0.6124573349952698, "camel_44967": 0.6126823425292969, "camel_29868": 0.6128255724906921, "camel_16615": 0.6137495636940002, "camel_16613": 0.6139665246009827, "camel_16713": 0.6140207648277283, "camel_16592": 0.6142253875732422, "camel_16666": 0.6144194006919861, "camel_16646": 0.614804208278656, "camel_45352": 0.6148308515548706, "camel_16637": 0.6156080365180969, "camel_16567": 0.6160064935684204, "camel_45169": 0.6162285208702087, "camel_16577": 0.6166386008262634, "camel_45149": 0.6175152659416199, "camel_16619": 0.6185806393623352, "camel_29886": 0.6189209222793579, "camel_16660": 0.6196494698524475, "camel_45155": 0.619899570941925, "camel_16677": 0.620215117931366, "camel_16605": 0.6203569173812866, "camel_16671": 0.6204620003700256, "camel_45136": 0.6215193867683411, "camel_16606": 0.62251216173172, "TheoremQA_panlu/wave_speed1.json": 0.6228392720222473, "camel_16632": 0.6232782602310181, "camel_43945": 0.6233870387077332, "camel_29914": 0.624091386795044, "camel_16587": 0.6248148083686829, "TheoremQA_tonyxia/statisticalphysics5.json": 0.6250598430633545, "camel_16565": 0.6251685619354248, "camel_16672": 0.626365602016449, "camel_16586": 0.6294301748275757, "camel_43782": 0.6305736303329468, "camel_16682": 0.630914568901062, "camel_16647": 0.6309667825698853, "camel_16699": 0.6314190626144409, "camel_45174": 0.6314609050750732, "camel_45074": 0.632313072681427, "TheoremQA_tonyxia/atom4.json": 0.6324423551559448, "camel_16621": 0.6327271461486816, "camel_16690": 0.633047878742218, "camel_16581": 0.6345018744468689, "camel_16596": 0.6348105669021606, "camel_45323": 0.6354804635047913, "camel_16657": 0.6363223791122437, "camel_16573": 0.6369508504867554, "camel_16602": 0.6378060579299927, "camel_16681": 0.6390904188156128, "camel_45199": 0.6408966183662415, "camel_16703": 0.6412933468818665, "camel_16634": 0.6442575454711914, "camel_17298": 0.6445643901824951, "camel_16712": 0.6446923017501831, "camel_16674": 0.6467825770378113, "camel_16575": 0.6474918127059937, "camel_16680": 0.6517461538314819, "camel_16571": 0.6529133915901184, "camel_45677": 0.6531356573104858, "camel_17288": 0.6532539129257202, "camel_45163": 0.6592708230018616, "camel_45140": 0.6632706522941589, "TheoremQA_panlu/wave_length1.json": 0.6645442843437195, "camel_45075": 0.6650068163871765, "camel_43779": 0.6657427549362183, "camel_45992": 0.6662372946739197, "math_test_algebra_578": 0.6753343939781189, "camel_45986": 0.6791146993637085, "camel_45999": 0.679302990436554, "camel_45956": 0.6835476160049438, "TheoremQA_tonyxia/photoelectric1.json": 0.683551549911499, "camel_45967": 0.6866481900215149, "TheoremQA_tonyxia/wave2.json": 0.6962935924530029, "camel_45935": 0.7105798125267029, "TheoremQA_tonyxia/semiconductor3.json": 0.8193801045417786}, "TheoremQA_xueguangma/present_value_2.json": {"TheoremQA_xueguangma/present_value_2.json": 0, "gsm_rft_31203": 0.6777942776679993, "gsm_rft_10641": 0.6779322624206543, "aqua_rat_83949": 0.6780428886413574, "gsm_rft_20110": 0.6780559420585632, "aqua_rat_57431": 0.6780951619148254, "gsm_train_4924": 0.6781828999519348, "gsm_rft_34181": 0.6784337162971497, "gsm_rft_25377": 0.6784994602203369, "aqua_rat_20878": 0.6786699891090393, "gsm_rft_24932": 0.6788231134414673, "gsm_rft_24735": 0.6788641214370728, "aqua_rat_67914": 0.6788917779922485, "gsm_rft_6618": 0.6791888475418091, "gsm_train_28388": 0.6792665719985962, "aqua_rat_16442": 0.6794824600219727, "aqua_rat_15337": 0.6795305609703064, "aqua_rat_14728": 0.6797918081283569, "aqua_rat_66917": 0.6803761720657349, "aqua_rat_74914": 0.6809360980987549, "aqua_rat_22632": 0.6813466548919678, "gsm_rft_3126": 0.6813951134681702, "gsm_rft_21062": 0.6814768314361572, "gsm_rft_34423": 0.6815094947814941, "gsm_rft_15046": 0.6817923784255981, "gsm_rft_31646": 0.6818011403083801, "aqua_rat_80303": 0.6819323301315308, "gsm_rft_35442": 0.6819364428520203, "gsm_rft_13670": 0.6819560527801514, "gsm_rft_25913": 0.6821177005767822, "gsm_train_34638": 0.6823229789733887, "gsm_rft_30946": 0.6826531887054443, "gsm_rft_6751": 0.6826813220977783, "gsm_rft_12584": 0.682997465133667, "aqua_rat_12418": 0.6830148696899414, "TheoremQA_xueguangma/future_value_1.json": 0.6831128597259521, "aqua_rat_41101": 0.683207094669342, "gsm_rft_13162": 0.6832368969917297, "gsm_train_28727": 0.6832420229911804, "gsm_train_34036": 0.6834068894386292, "aqua_rat_15749": 0.6836665272712708, "aqua_rat_26935": 0.6836674213409424, "gsm_rft_31288": 0.6840711832046509, "gsm_rft_7115": 0.6841251254081726, "gsm_train_9412": 0.6841251254081726, "aqua_rat_46525": 0.6841997504234314, "gsm_rft_35249": 0.6842584609985352, "aqua_rat_37392": 0.6843065023422241, "gsm_rft_33478": 0.6845341920852661, "gsm_train_13334": 0.6847414970397949, "gsm_rft_24690": 0.6847414970397949, "gsm_rft_20212": 0.6848291158676147, "gsm_rft_15946": 0.6848930716514587, "camel_45730": 0.6849764585494995, "gsm_rft_2778": 0.685160219669342, "gsm_rft_5014": 0.6852297782897949, "gsm_rft_9581": 0.6852710843086243, "aqua_rat_62371": 0.6852930188179016, "aqua_rat_73957": 0.6855902671813965, "gsm_rft_32019": 0.685723066329956, "aqua_rat_56922": 0.6858586072921753, "gsm_rft_31372": 0.685873806476593, "gsm_train_4730": 0.685873806476593, "gsm_rft_29082": 0.685958743095398, "aqua_rat_57864": 0.6859933733940125, "gsm_train_7824": 0.686826765537262, "gsm_rft_10732": 0.686826765537262, "gsm_train_8082": 0.686832845211029, "gsm_rft_4032": 0.686832845211029, "gsm_rft_34606": 0.6868892908096313, "gsm_rft_33513": 0.6871869564056396, "gsm_rft_20997": 0.6876358985900879, "gsm_train_16768": 0.6876358985900879, "gsm_rft_9014": 0.6876702904701233, "gsm_rft_32408": 0.6876938343048096, "gsm_rft_29054": 0.687706470489502, "aqua_rat_39841": 0.688011109828949, "gsm_rft_31657": 0.6880114078521729, "aqua_rat_4548": 0.6881415247917175, "gsm_train_17940": 0.6881418228149414, "gsm_rft_20077": 0.6885756254196167, "gsm_rft_17013": 0.6885756254196167, "gsm_rft_10656": 0.689065158367157, "aqua_rat_67074": 0.6891824007034302, "aqua_rat_87442": 0.6892128586769104, "gsm_rft_29226": 0.6895087361335754, "aqua_rat_78719": 0.6898055076599121, "gsm_rft_33659": 0.6898959875106812, "aqua_rat_23836": 0.6901348829269409, "gsm_rft_23260": 0.6904028654098511, "aqua_rat_58924": 0.6905581951141357, "gsm_rft_12600": 0.6906046867370605, "math_train_algebra_369": 0.6906789541244507, "gsm_rft_15334": 0.6909175515174866, "gsm_train_6037": 0.6909175515174866, "gsm_rft_12005": 0.6909267902374268, "aqua_rat_16258": 0.691114604473114, "aqua_rat_11544": 0.6911553740501404, "aqua_rat_39856": 0.6919662356376648, "gsm_rft_21730": 0.6922364234924316, "aqua_rat_23247": 0.6923965811729431, "gsm_rft_32767": 0.6925605535507202, "aqua_rat_611": 0.6930280923843384, "gsm_rft_24696": 0.6932333707809448, "gsm_rft_18143": 0.6932739615440369, "gsm_rft_7924": 0.6933383345603943, "gsm_rft_33781": 0.6935244202613831, "aqua_rat_16445": 0.6936395764350891, "gsm_rft_19766": 0.6937748193740845, "aqua_rat_60935": 0.69413822889328, "gsm_train_22362": 0.6944317817687988, "math_train_algebra_2507": 0.6945061087608337, "aqua_rat_56845": 0.6946383714675903, "gsm_train_2595": 0.694816529750824, "gsm_rft_35170": 0.6950342655181885, "aqua_rat_58629": 0.6952705979347229, "aqua_rat_36703": 0.6954572796821594, "aqua_rat_9530": 0.6958250999450684, "gsm_rft_11804": 0.6958621740341187, "gsm_rft_11628": 0.6959977746009827, "gsm_rft_7096": 0.696350634098053, "aqua_rat_70160": 0.696493923664093, "aqua_rat_42893": 0.6972991228103638, "gsm_rft_24249": 0.6983349323272705, "gsm_rft_22590": 0.6983957290649414, "gsm_rft_6422": 0.6984109282493591, "gsm_rft_34374": 0.6998346447944641, "camel_37735": 0.7002672553062439, "math_test_algebra_1862": 0.7011600136756897, "aqua_rat_71866": 0.7013593316078186, "gsm_rft_21130": 0.7023752927780151, "gsm_rft_19903": 0.7023752927780151, "gsm_train_12933": 0.7023752927780151, "gsm_rft_33006": 0.7028812170028687, "gsm_rft_14240": 0.7032681703567505, "gsm_train_21876": 0.703511655330658, "gsm_rft_15888": 0.703511655330658, "gsm_rft_18163": 0.7038789987564087, "aqua_rat_13348": 0.7040641903877258, "gsm_rft_20558": 0.7059928178787231, "math_test_algebra_1611": 0.7070004343986511, "gsm_rft_7026": 0.7071050405502319, "gsm_rft_33978": 0.7075635194778442, "gsm_train_34054": 0.7075635194778442, "gsm_train_24478": 0.708699107170105, "gsm_rft_9128": 0.7092320919036865, "gsm_rft_22041": 0.7092485427856445, "gsm_rft_28287": 0.7100788354873657, "TheoremQA_xueguangma/future_value_2.json": 0.7102485299110413, "gsm_rft_7891": 0.7102710604667664, "TheoremQA_xueguangma/dividend_discount_model_5.json": 0.713139533996582, "gsm_rft_17545": 0.7133176326751709, "aqua_rat_54684": 0.7142360806465149, "aqua_rat_37203": 0.7143604159355164, "aqua_rat_64484": 0.7150375843048096, "gsm_train_22552": 0.7152119278907776, "gsm_rft_25508": 0.7152119278907776, "aqua_rat_78427": 0.7159284949302673, "gsm_rft_3411": 0.7159603238105774, "gsm_rft_33880": 0.7159886360168457, "gsm_rft_8126": 0.7168044447898865, "aqua_rat_64523": 0.7174673676490784, "gsm_rft_1672": 0.7175168991088867, "gsm_train_3010": 0.7177285552024841, "gsm_rft_27542": 0.7181369662284851, "aqua_rat_26043": 0.7186627984046936, "aqua_rat_80269": 0.7190282344818115, "aqua_rat_29417": 0.7193385362625122, "gsm_rft_16062": 0.7194335460662842, "aqua_rat_24068": 0.7196677923202515, "gsm_rft_25231": 0.7199755311012268, "gsm_train_19719": 0.7199755311012268, "TheoremQA_xueguangma/forward_price_3.json": 0.719987690448761, "aqua_rat_85902": 0.7205201983451843, "aqua_rat_9857": 0.7214199304580688, "gsm_rft_30907": 0.7215911149978638, "aqua_rat_29154": 0.7223337292671204, "aqua_rat_30597": 0.7228022813796997, "aqua_rat_59587": 0.7231863141059875, "TheoremQA_xueguangma/spot_rate.json": 0.7233849763870239, "aqua_rat_57507": 0.7237461805343628, "aqua_rat_56436": 0.7247491478919983, "aqua_rat_67442": 0.7255331873893738, "aqua_rat_46883": 0.7261239886283875, "aqua_rat_88843": 0.7297964692115784, "aqua_rat_6475": 0.7330809235572815, "camel_37686": 0.7420920729637146, "aqua_rat_79856": 0.7444829344749451, "camel_45738": 0.745409369468689, "aqua_rat_36498": 0.7485427856445312, "aqua_rat_49352": 0.7514111995697021, "aqua_rat_45508": 0.7517569065093994, "aqua_rat_80676": 0.7564778327941895, "math_train_algebra_940": 0.7722300291061401, "TheoremQA_xueguangma/present_value_1.json": 0.775324285030365, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7775577902793884, "aqua_rat_31553": 0.7791752219200134, "TheoremQA_xueguangma/forward_price_2.json": 0.7894642353057861, "camel_37746": 0.7905040979385376, "camel_37747": 0.794227123260498}, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": {"camel_39954": 0, "camel_21663": 0, "camel_22069": 0, "camel_22247": 0, "camel_23982": 0, "camel_22332": 0, "camel_22395": 0, "camel_39977": 0, "camel_38596": 0, "camel_38569": 0, "camel_22859": 0, "camel_21671": 0, "camel_22831": 0, "camel_21642": 0, "camel_39932": 0, "camel_38614": 0, "camel_22003": 0, "camel_21665": 0, "camel_22875": 0, "camel_38621": 0, "camel_22301": 0, "camel_39974": 0, "camel_39952": 0, "camel_23953": 0, "camel_23957": 0, "camel_21613": 0, "camel_21605": 0, "camel_21650": 0, "camel_39939": 0, "camel_39935": 0, "camel_21668": 0, "camel_38637": 0, "camel_39955": 0, "camel_22041": 0, "camel_23936": 0, "camel_22346": 0, "camel_22296": 0, "camel_22024": 0, "camel_39979": 0, "camel_23929": 0, "camel_22290": 0, "camel_22037": 0, "camel_39987": 0, "camel_39980": 0, "camel_38512": 0, "camel_22276": 0, "camel_22931": 0, "camel_23967": 0, "camel_22340": 0, "camel_38599": 0, "camel_38573": 0, "camel_21623": 0, "camel_39959": 0, "camel_21653": 0, "camel_21628": 0, "camel_39950": 0, "camel_39998": 0, "camel_21672": 0, "camel_21615": 0, "camel_21678": 0, "camel_22046": 0, "camel_21674": 0, "camel_39986": 0, "camel_22248": 0, "camel_23973": 0, "camel_39988": 0, "camel_21639": 0, "camel_21602": 0, "camel_22057": 0, "camel_23947": 0, "camel_22052": 0, "camel_38560": 0, "camel_21646": 0, "camel_38639": 0, "camel_22874": 0, "camel_38564": 0, "camel_22285": 0, "camel_21632": 0, "camel_21640": 0, "camel_39961": 0, "camel_21606": 0, "camel_39925": 0, "camel_21624": 0, "camel_22240": 0, "camel_23970": 0, "camel_39920": 0, "camel_21670": 0, "camel_38489": 0, "camel_23991": 0, "camel_39999": 0, "camel_21636": 0, "camel_22367": 0, "camel_21600": 0, "camel_22368": 0, "camel_39963": 0, "camel_21619": 0, "camel_22000": 0, "camel_22350": 0, "camel_21662": 0, "camel_39976": 0, "camel_21655": 0, "camel_21645": 0, "camel_21620": 0, "camel_22344": 0, "camel_23961": 0, "camel_21644": 0, "camel_39989": 0, "camel_21647": 0, "camel_21654": 0, "camel_22043": 0, "camel_21611": 0, "camel_21617": 0, "camel_39929": 0, "camel_21614": 0, "camel_39965": 0, "camel_21666": 0, "camel_22818": 0, "camel_39983": 0, "camel_22390": 0, "camel_39942": 0, "camel_21608": 0, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": 0, "camel_21625": 0, "camel_21633": 0, "camel_39962": 0, "camel_39956": 0, "camel_39927": 0, "camel_21673": 0, "camel_39993": 0, "camel_21660": 0, "camel_38518": 0, "camel_39966": 0, "camel_38501": 0, "camel_39933": 0, "camel_21638": 0, "camel_39923": 0, "camel_23924": 0, "camel_38581": 0, "camel_21616": 0, "camel_21669": 0, "camel_22354": 0, "camel_39936": 0, "camel_21676": 0, "camel_21603": 0, "camel_23981": 0, "camel_39994": 0, "camel_21677": 0, "camel_22326": 0, "camel_22009": 0, "camel_38630": 0, "camel_39953": 0, "camel_39970": 0, "camel_39937": 0, "camel_22324": 0, "camel_21621": 0, "camel_21657": 0, "camel_39967": 0, "camel_21643": 0, "camel_23184": 0, "camel_39943": 0, "camel_38525": 0, "camel_21679": 0, "camel_38622": 0, "camel_21618": 0, "camel_39931": 0, "camel_21651": 0, "camel_22341": 0, "camel_22330": 0, "camel_22172": 0, "camel_21637": 0, "camel_39982": 0, "camel_21658": 0, "camel_22842": 0, "camel_21635": 0, "camel_39981": 0, "camel_22316": 0, "camel_39990": 0, "camel_21656": 0, "camel_21649": 0, "camel_21612": 0, "camel_39940": 0, "camel_21604": 0, "camel_22348": 0, "camel_22040": 0, "camel_39944": 0, "camel_21631": 0, "camel_23950": 0, "camel_21622": 0, "camel_21626": 0, "camel_39997": 0, "camel_22060": 0, "camel_39978": 0, "aqua_rat_49899": 0.8021805286407471, "aqua_rat_31336": 0.8021951913833618, "aqua_rat_26496": 0.8037154078483582, "aqua_rat_81964": 0.8132410049438477, "aqua_rat_17334": 0.8160503506660461, "aqua_rat_57972": 0.8174256682395935, "camel_9143": 0.8177030086517334, "aqua_rat_81541": 0.818790853023529}, "TheoremQA_wenhuchen/p_value2.json": {"camel_9834": 0, "camel_9568": 0, "camel_8017": 0, "camel_9528": 0, "camel_8034": 0, "camel_9531": 0, "camel_9529": 0, "camel_8737": 0, "camel_9559": 0, "camel_8735": 0, "camel_9578": 0, "camel_8768": 0, "camel_8784": 0, "camel_9563": 0, "camel_8045": 0, "camel_9561": 0, "camel_8732": 0, "TheoremQA_wenhuchen/p_value2.json": 0, "camel_9579": 0, "camel_9590": 0, "camel_9582": 0, "camel_9525": 0, "camel_9583": 0, "camel_8375": 0, "camel_9575": 0, "camel_9588": 0, "camel_9574": 0, "camel_8731": 0, "camel_9464": 0, "camel_8037": 0, "camel_9963": 0, "camel_9533": 0, "camel_9562": 0, "camel_9530": 0, "camel_9924": 0, "aqua_rat_5577": 0.7295098304748535, "camel_11948": 0.7296006083488464, "aqua_rat_86877": 0.7296177744865417, "aqua_rat_80380": 0.7297024130821228, "camel_10717": 0.7297243475914001, "camel_24679": 0.7300456762313843, "camel_11118": 0.7300674319267273, "camel_11488": 0.7301533818244934, "aqua_rat_38290": 0.7301783561706543, "camel_10360": 0.7302377223968506, "camel_11498": 0.7303014397621155, "camel_10926": 0.7303266525268555, "aqua_rat_61314": 0.7304072380065918, "camel_36361": 0.7306744456291199, "camel_10698": 0.7309519648551941, "aqua_rat_9180": 0.7311006188392639, "camel_37801": 0.7311630249023438, "camel_11479": 0.732124388217926, "camel_10793": 0.7321842908859253, "camel_11513": 0.7322109937667847, "aqua_rat_16030": 0.732472836971283, "camel_10253": 0.7333333492279053, "camel_10263": 0.7333877682685852, "aqua_rat_72672": 0.7334699630737305, "camel_10386": 0.7335318922996521, "aqua_rat_67067": 0.7337042093276978, "math_test_counting_and_probability_262": 0.7337710857391357, "camel_37814": 0.7338793873786926, "camel_11818": 0.7341134548187256, "aqua_rat_34192": 0.7341926097869873, "aqua_rat_3208": 0.7343300580978394, "camel_11308": 0.734396755695343, "aqua_rat_45407": 0.7344608306884766, "aqua_rat_86847": 0.7346974015235901, "aqua_rat_32868": 0.7347899675369263, "aqua_rat_43971": 0.735061526298523, "aqua_rat_75711": 0.7351426482200623, "aqua_rat_37618": 0.7352710962295532, "aqua_rat_33941": 0.735577404499054, "camel_37612": 0.735652506351471, "camel_11623": 0.7364507913589478, "camel_10008": 0.7373799681663513, "camel_11506": 0.7374752759933472, "camel_11515": 0.73762047290802, "camel_11436": 0.7386592030525208, "camel_11465": 0.7387311458587646, "aqua_rat_21586": 0.7388601899147034, "camel_10439": 0.738925039768219, "camel_11238": 0.7390772700309753, "aqua_rat_20022": 0.7394043803215027, "aqua_rat_42842": 0.7394224405288696, "aqua_rat_7098": 0.7395372986793518, "camel_37986": 0.7397199273109436, "camel_11499": 0.7397907376289368, "camel_11393": 0.7398348450660706, "camel_10327": 0.7400111556053162, "camel_10467": 0.7402132153511047, "camel_37802": 0.7402437925338745, "aqua_rat_80172": 0.7405766248703003, "aqua_rat_66217": 0.7410395741462708, "camel_25283": 0.7410405874252319, "camel_37783": 0.7410913705825806, "aqua_rat_56774": 0.7415056824684143, "camel_11786": 0.7417215704917908, "camel_11422": 0.741832435131073, "camel_25284": 0.7420265674591064, "camel_11713": 0.7421504855155945, "aqua_rat_42966": 0.7421882748603821, "aqua_rat_51388": 0.7426608204841614, "camel_11348": 0.7427412867546082, "camel_37631": 0.7427986860275269, "aqua_rat_30787": 0.7429602742195129, "aqua_rat_87022": 0.7430319786071777, "camel_10462": 0.743263304233551, "camel_11443": 0.7433790564537048, "camel_10703": 0.7437323927879333, "camel_10423": 0.7439544200897217, "camel_11423": 0.7440730929374695, "camel_11508": 0.744342029094696, "camel_24709": 0.7448011636734009, "camel_24659": 0.7451666593551636, "aqua_rat_71021": 0.7452170848846436, "aqua_rat_75648": 0.745521068572998, "camel_10682": 0.7456485033035278, "camel_10373": 0.7464413046836853, "camel_11462": 0.7472954988479614, "aqua_rat_88535": 0.7473254203796387, "camel_11489": 0.7483742833137512, "camel_39391": 0.7486417889595032, "aqua_rat_62298": 0.7486531138420105, "camel_10365": 0.7492409944534302, "camel_11457": 0.7494344711303711, "aqua_rat_8487": 0.7494826316833496, "camel_11495": 0.749907374382019, "aqua_rat_31129": 0.7500516176223755, "camel_11446": 0.7504423260688782, "camel_11493": 0.7505889534950256, "aqua_rat_43445": 0.751272439956665, "aqua_rat_4468": 0.7516672015190125, "camel_11796": 0.7524315714836121, "aqua_rat_62403": 0.7524586319923401, "camel_24677": 0.7525538206100464, "aqua_rat_32748": 0.753170371055603, "math_test_counting_and_probability_156": 0.7537028193473816, "camel_39408": 0.753821074962616, "camel_10657": 0.7538934946060181, "gsm_rft_3381": 0.7540784478187561, "gsm_rft_34226": 0.7542105913162231, "gsm_train_32701": 0.7542105913162231, "camel_24689": 0.7544922232627869, "camel_11453": 0.7545841932296753, "aqua_rat_75743": 0.7557164430618286, "aqua_rat_37936": 0.757902979850769, "camel_10301": 0.7582460045814514, "camel_37823": 0.759965181350708, "camel_24662": 0.7601211667060852, "camel_37830": 0.7603628635406494, "camel_11967": 0.7604141235351562, "camel_11619": 0.7608478665351868, "camel_10603": 0.7612623572349548, "camel_11531": 0.7612863779067993, "aqua_rat_5883": 0.7618191242218018, "math_train_counting_and_probability_995": 0.7630728483200073, "camel_24675": 0.7637659311294556, "camel_11558": 0.7643274068832397, "camel_24643": 0.7644972801208496, "camel_24685": 0.7657049894332886, "camel_24683": 0.7663445472717285, "camel_11925": 0.7667750120162964, "camel_11455": 0.7715391516685486, "aqua_rat_29721": 0.7722455859184265, "camel_11985": 0.7724239826202393, "aqua_rat_15170": 0.7726815938949585, "aqua_rat_31288": 0.7739673256874084, "camel_37762": 0.7753915786743164, "camel_39375": 0.7779156565666199, "camel_24654": 0.7780656218528748, "camel_37775": 0.7802982926368713, "aqua_rat_63187": 0.7813636660575867, "camel_10019": 0.7817935347557068, "math_train_counting_and_probability_550": 0.7826210856437683, "math_train_counting_and_probability_257": 0.7837153673171997, "camel_10432": 0.7839680314064026, "aqua_rat_64138": 0.7847548127174377, "camel_24693": 0.7876547574996948, "camel_11563": 0.7880582213401794, "camel_11539": 0.7883293628692627, "camel_10469": 0.7894827127456665, "TheoremQA_wenhuchen/p_value1.json": 0.7939417958259583, "camel_37799": 0.7964718341827393, "aqua_rat_42517": 0.7967829704284668, "camel_24640": 0.8007941246032715, "aqua_rat_2657": 0.8017111420631409, "aqua_rat_84637": 0.8043617606163025, "math_test_counting_and_probability_878": 0.8062010407447815, "aqua_rat_66708": 0.806273341178894, "camel_37875": 0.8071005344390869, "aqua_rat_5264": 0.808329701423645, "aqua_rat_32857": 0.809513509273529, "aqua_rat_45572": 0.8110189437866211, "math_train_counting_and_probability_97": 0.8155654072761536, "camel_10004": 0.8170416355133057, "aqua_rat_74523": 0.8190871477127075, "aqua_rat_36135": 0.8279585242271423, "camel_10006": 0.8291310667991638}, "TheoremQA_xueguangma/dividend_discount_model_1.json": {"TheoremQA_xueguangma/dividend_discount_model_1.json": 0, "aqua_rat_17685": 0.6792604327201843, "math_test_algebra_337": 0.6793405413627625, "camel_25250": 0.6794042587280273, "aqua_rat_86835": 0.6794198751449585, "aqua_rat_46293": 0.6794292330741882, "aqua_rat_69526": 0.6795056462287903, "gsm_rft_31203": 0.6795210242271423, "gsm_rft_34608": 0.6795362234115601, "gsm_rft_29688": 0.6796151399612427, "aqua_rat_52815": 0.6796222925186157, "aqua_rat_19740": 0.6797809600830078, "aqua_rat_53504": 0.6798455715179443, "aqua_rat_20739": 0.6798796653747559, "gsm_rft_2115": 0.6798862814903259, "aqua_rat_57433": 0.6800000667572021, "gsm_rft_27046": 0.6800207495689392, "aqua_rat_86432": 0.6800734400749207, "aqua_rat_38697": 0.6800829768180847, "aqua_rat_19454": 0.6802179217338562, "aqua_rat_76879": 0.6803165674209595, "aqua_rat_17532": 0.6803722381591797, "TheoremQA_xueguangma/forward_price_3.json": 0.680390477180481, "aqua_rat_18473": 0.6806957721710205, "aqua_rat_18969": 0.6807284355163574, "gsm_rft_26599": 0.6807605028152466, "gsm_train_26918": 0.6807605028152466, "aqua_rat_73323": 0.6809209585189819, "gsm_rft_24617": 0.6810137033462524, "gsm_rft_2016": 0.6810430288314819, "gsm_rft_5809": 0.6811015605926514, "aqua_rat_71288": 0.6811093091964722, "gsm_rft_31049": 0.6811633110046387, "gsm_rft_3769": 0.6811678409576416, "gsm_rft_31412": 0.6812090873718262, "gsm_train_25772": 0.681232213973999, "gsm_rft_13162": 0.6813592314720154, "gsm_train_14821": 0.6813620924949646, "aqua_rat_13471": 0.6813897490501404, "aqua_rat_47773": 0.6814156174659729, "gsm_rft_22277": 0.6814929246902466, "aqua_rat_10855": 0.6817700862884521, "aqua_rat_67794": 0.6819488406181335, "aqua_rat_4236": 0.6820382475852966, "aqua_rat_45836": 0.6820734143257141, "aqua_rat_46607": 0.6821293234825134, "aqua_rat_26339": 0.6821852922439575, "aqua_rat_17504": 0.6824169158935547, "aqua_rat_28151": 0.6825779676437378, "aqua_rat_44615": 0.6828594207763672, "aqua_rat_80299": 0.6829169988632202, "aqua_rat_3536": 0.682997465133667, "aqua_rat_67076": 0.6832858324050903, "aqua_rat_45867": 0.6833581328392029, "aqua_rat_63286": 0.6834409236907959, "aqua_rat_13817": 0.6838704347610474, "aqua_rat_79979": 0.6838988661766052, "aqua_rat_78121": 0.683943510055542, "aqua_rat_75451": 0.6839547753334045, "aqua_rat_13033": 0.684026837348938, "aqua_rat_83740": 0.6840333342552185, "aqua_rat_48279": 0.6840977072715759, "aqua_rat_46315": 0.6842595934867859, "aqua_rat_63322": 0.6843804121017456, "aqua_rat_85628": 0.684420645236969, "gsm_rft_15258": 0.6846670508384705, "aqua_rat_56718": 0.684795618057251, "aqua_rat_24347": 0.6848616600036621, "aqua_rat_47176": 0.6849340796470642, "gsm_train_28727": 0.6850424408912659, "gsm_rft_12584": 0.6850573420524597, "gsm_rft_10601": 0.6851307153701782, "aqua_rat_64922": 0.6851802468299866, "aqua_rat_30386": 0.6852496266365051, "aqua_rat_88687": 0.6853569746017456, "aqua_rat_15950": 0.6854414939880371, "aqua_rat_26820": 0.6855277419090271, "aqua_rat_42852": 0.6855958700180054, "gsm_rft_35249": 0.6856387257575989, "math_train_algebra_667": 0.6856905221939087, "aqua_rat_10990": 0.6857355237007141, "aqua_rat_49749": 0.6858580708503723, "gsm_rft_5012": 0.6861013174057007, "aqua_rat_75833": 0.6861542463302612, "aqua_rat_55929": 0.6863616108894348, "aqua_rat_33923": 0.6864269375801086, "aqua_rat_42796": 0.6865494251251221, "aqua_rat_67841": 0.6867494583129883, "aqua_rat_34230": 0.6870240569114685, "math_train_algebra_940": 0.6870706677436829, "aqua_rat_1115": 0.6870838403701782, "aqua_rat_88960": 0.6875246167182922, "gsm_rft_14407": 0.6875736117362976, "gsm_rft_14574": 0.687616765499115, "camel_39737": 0.6879506707191467, "gsm_rft_26721": 0.6881318092346191, "aqua_rat_69547": 0.6882411241531372, "aqua_rat_83774": 0.6888166069984436, "camel_37686": 0.6889012455940247, "camel_25151": 0.6890438795089722, "gsm_rft_32408": 0.6890876889228821, "gsm_rft_24218": 0.6891458630561829, "gsm_rft_19966": 0.6892611980438232, "aqua_rat_51100": 0.6893338561058044, "gsm_train_17735": 0.6894121170043945, "aqua_rat_27039": 0.6895131468772888, "aqua_rat_37709": 0.6897521615028381, "gsm_rft_33387": 0.6900104284286499, "gsm_rft_22572": 0.6901325583457947, "aqua_rat_33283": 0.6901864409446716, "aqua_rat_43017": 0.6903294920921326, "gsm_rft_19671": 0.6904903650283813, "gsm_rft_4489": 0.6904903650283813, "gsm_train_5087": 0.6904903650283813, "gsm_rft_17649": 0.690854012966156, "gsm_rft_34694": 0.6908622980117798, "aqua_rat_8292": 0.6909617185592651, "camel_37746": 0.69126957654953, "aqua_rat_62528": 0.6912717223167419, "gsm_rft_24082": 0.6913320422172546, "camel_38214": 0.691369891166687, "aqua_rat_24626": 0.6913859844207764, "aqua_rat_71424": 0.6914337873458862, "aqua_rat_52474": 0.69170743227005, "aqua_rat_72822": 0.6920186281204224, "gsm_rft_14766": 0.6929184794425964, "aqua_rat_33294": 0.6931810975074768, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.6934493780136108, "aqua_rat_11679": 0.6936007738113403, "aqua_rat_56784": 0.693658173084259, "gsm_rft_8605": 0.6937854290008545, "gsm_train_18514": 0.6941675543785095, "gsm_train_16035": 0.6941767930984497, "gsm_rft_23795": 0.6943953633308411, "aqua_rat_72933": 0.6945782899856567, "aqua_rat_81348": 0.6945925354957581, "gsm_rft_25960": 0.69462651014328, "aqua_rat_77486": 0.6948457956314087, "gsm_rft_6203": 0.6951318383216858, "gsm_rft_26701": 0.695165753364563, "aqua_rat_57386": 0.6953115463256836, "gsm_rft_29906": 0.6954628229141235, "aqua_rat_27035": 0.6957166790962219, "aqua_rat_53421": 0.6957789659500122, "gsm_rft_24137": 0.6961638927459717, "gsm_rft_24497": 0.696408748626709, "gsm_rft_32633": 0.6964554786682129, "gsm_train_30707": 0.6967678070068359, "aqua_rat_59668": 0.696927547454834, "gsm_rft_20456": 0.6971267461776733, "gsm_rft_34600": 0.6971887946128845, "gsm_rft_252": 0.6973655819892883, "aqua_rat_14728": 0.6974164247512817, "gsm_rft_24611": 0.6975012421607971, "aqua_rat_87246": 0.6975451707839966, "aqua_rat_83234": 0.6975892186164856, "aqua_rat_255": 0.698408842086792, "gsm_rft_11850": 0.6987586617469788, "gsm_rft_16966": 0.698806643486023, "TheoremQA_xueguangma/forward_price_2.json": 0.6988814473152161, "aqua_rat_3773": 0.6989611387252808, "aqua_rat_37382": 0.6989991664886475, "gsm_train_374": 0.6990072131156921, "gsm_rft_20347": 0.6990072131156921, "gsm_rft_17816": 0.699142336845398, "aqua_rat_32321": 0.6992520093917847, "aqua_rat_52197": 0.6994341015815735, "aqua_rat_15749": 0.7002056837081909, "aqua_rat_86309": 0.7003732323646545, "gsm_rft_26823": 0.7004508376121521, "aqua_rat_64664": 0.7005665302276611, "aqua_rat_89004": 0.700675368309021, "aqua_rat_57943": 0.7007502317428589, "aqua_rat_85762": 0.7009339928627014, "gsm_rft_26543": 0.7010286450386047, "camel_25255": 0.703263521194458, "aqua_rat_80962": 0.7033108472824097, "math_test_algebra_1611": 0.7051171660423279, "gsm_rft_28490": 0.7052263617515564, "gsm_rft_33804": 0.7059054374694824, "gsm_rft_10656": 0.7062827348709106, "aqua_rat_66298": 0.7063046097755432, "aqua_rat_87442": 0.7064759135246277, "aqua_rat_1364": 0.7067820429801941, "aqua_rat_87884": 0.7089568972587585, "aqua_rat_70690": 0.7090992331504822, "aqua_rat_9965": 0.7096809148788452, "aqua_rat_56922": 0.7100272178649902, "camel_37747": 0.7105442881584167, "aqua_rat_16258": 0.7110291719436646, "gsm_rft_5070": 0.7115638256072998, "aqua_rat_64914": 0.7117382884025574, "aqua_rat_23836": 0.712588369846344, "gsm_rft_7115": 0.7156285047531128, "gsm_train_9412": 0.7156285047531128, "TheoremQA_xueguangma/dividend_discount_model_2.json": 0.7196366190910339, "aqua_rat_7378": 0.7214428186416626, "gsm_rft_27287": 0.7309081554412842, "TheoremQA_xueguangma/dividend_discount_model_5.json": 0.7368389964103699, "TheoremQA_xueguangma/dividend_discount_model_4.json": 0.7501263618469238}, "TheoremQA_xinyi/rate_distortion_function_2.json": {"TheoremQA_xinyi/rate_distortion_function_2.json": 0, "TheoremQA_xinyi/kraft_inequality.json": 0.5634567737579346, "camel_28648": 0.563458263874054, "camel_25810": 0.5634761452674866, "camel_45819": 0.5634962916374207, "camel_25705": 0.5635073781013489, "camel_9152": 0.5637720227241516, "camel_22040": 0.5638572573661804, "camel_25838": 0.5639811754226685, "gsm_rft_5276": 0.5639963746070862, "gsm_train_13705": 0.5639963746070862, "camel_29346": 0.5640195608139038, "camel_29117": 0.564092755317688, "camel_29322": 0.5642558336257935, "gsm_rft_3717": 0.5642794370651245, "gsm_train_144": 0.5642794370651245, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0.5643174648284912, "aqua_rat_31535": 0.5643294453620911, "camel_41762": 0.5643332004547119, "camel_25761": 0.5643424987792969, "camel_41062": 0.564346969127655, "camel_38692": 0.5643614530563354, "camel_41486": 0.5643837451934814, "camel_41585": 0.5644158124923706, "aqua_rat_24133": 0.5645769834518433, "camel_29052": 0.5646780133247375, "camel_40973": 0.5647538900375366, "camel_36572": 0.5647901892662048, "camel_26505": 0.5648269653320312, "camel_38413": 0.5648477673530579, "camel_41742": 0.5648519992828369, "gsm_rft_23628": 0.5649322271347046, "camel_41320": 0.5649957060813904, "camel_41550": 0.5650355815887451, "camel_9146": 0.5651512145996094, "camel_41077": 0.565165102481842, "camel_29329": 0.5652039051055908, "camel_28797": 0.5652426481246948, "aqua_rat_25646": 0.5652614831924438, "camel_41963": 0.5652768015861511, "camel_29580": 0.5652804970741272, "camel_28344": 0.5652843117713928, "camel_25837": 0.5654445886611938, "camel_25782": 0.5657201409339905, "camel_41325": 0.5657526254653931, "camel_41103": 0.5657836198806763, "aqua_rat_5881": 0.5658060908317566, "aqua_rat_53724": 0.5659126043319702, "aqua_rat_4046": 0.5659142732620239, "camel_37719": 0.5660108923912048, "camel_29593": 0.5660698413848877, "camel_41088": 0.5662833452224731, "camel_41921": 0.5662908554077148, "camel_30223": 0.5663102269172668, "camel_40964": 0.5663278102874756, "camel_41005": 0.5663538575172424, "camel_41640": 0.5664524435997009, "camel_25554": 0.5664807558059692, "camel_39930": 0.5667235851287842, "camel_29734": 0.5670170187950134, "aqua_rat_76117": 0.5670772194862366, "camel_29341": 0.5672248005867004, "aqua_rat_14739": 0.5673605799674988, "camel_41076": 0.5674828886985779, "camel_25977": 0.5675457715988159, "camel_25452": 0.5675758719444275, "camel_9179": 0.5677541494369507, "camel_41247": 0.5680506825447083, "camel_9183": 0.5681204795837402, "aqua_rat_8926": 0.568294107913971, "gsm_rft_15239": 0.5682951807975769, "gsm_rft_33929": 0.5684946179389954, "camel_29759": 0.5685057640075684, "camel_25812": 0.5685386657714844, "aqua_rat_27865": 0.5687628388404846, "camel_41080": 0.5688880085945129, "camel_28661": 0.5691291093826294, "camel_41071": 0.5691889524459839, "camel_41740": 0.5692662000656128, "gsm_rft_21604": 0.5692920684814453, "gsm_train_1971": 0.5692920684814453, "camel_41114": 0.5694899559020996, "camel_9195": 0.5696040391921997, "aqua_rat_2322": 0.569647490978241, "camel_41700": 0.5697388648986816, "camel_15804": 0.5697394013404846, "camel_17545": 0.5698063969612122, "aqua_rat_38416": 0.569884181022644, "camel_40840": 0.5698887705802917, "camel_29719": 0.5699068903923035, "gsm_rft_22877": 0.5699329972267151, "camel_28117": 0.5700005292892456, "TheoremQA_maxku/ipnetwork5-mac.json": 0.5701688528060913, "camel_30413": 0.5702064037322998, "camel_25589": 0.5704218149185181, "aqua_rat_66093": 0.5705413818359375, "camel_36502": 0.5705550312995911, "camel_38613": 0.5705915093421936, "camel_29240": 0.5706716179847717, "camel_21916": 0.5708503723144531, "camel_29071": 0.5709165930747986, "camel_25785": 0.5709772109985352, "camel_41753": 0.571002185344696, "camel_29321": 0.5711009502410889, "camel_29541": 0.5713239312171936, "camel_40800": 0.5716274976730347, "camel_41735": 0.5717122554779053, "camel_39472": 0.5717805027961731, "camel_29302": 0.5721051096916199, "camel_41769": 0.572644829750061, "camel_41329": 0.572677731513977, "camel_41290": 0.5727301836013794, "camel_21909": 0.5728463530540466, "camel_9124": 0.5732046961784363, "camel_25833": 0.5734179019927979, "aqua_rat_72089": 0.5734481811523438, "camel_41691": 0.5735312104225159, "camel_39001": 0.5735339522361755, "camel_41694": 0.5739330649375916, "camel_29088": 0.5740317702293396, "camel_38813": 0.5747684240341187, "camel_25778": 0.5749543905258179, "camel_38565": 0.5749905109405518, "camel_38481": 0.5750529170036316, "camel_40914": 0.5750808715820312, "camel_15766": 0.5751494765281677, "camel_41813": 0.5751940608024597, "camel_29097": 0.5754755735397339, "camel_9151": 0.5754798650741577, "camel_41940": 0.5756206512451172, "camel_41981": 0.5758021473884583, "camel_37507": 0.5759116411209106, "camel_29082": 0.5762142539024353, "aqua_rat_85903": 0.5765014886856079, "camel_41302": 0.5766729116439819, "camel_40967": 0.5767747163772583, "camel_41288": 0.5771088600158691, "camel_38663": 0.5771377682685852, "gsm_rft_24984": 0.5773952007293701, "aqua_rat_73185": 0.5780959725379944, "camel_41086": 0.5782001614570618, "aqua_rat_53867": 0.5783095955848694, "camel_9173": 0.5786386728286743, "camel_9164": 0.57893306016922, "camel_38586": 0.5790116190910339, "camel_41986": 0.5792044997215271, "camel_41988": 0.5792912840843201, "camel_40948": 0.579433262348175, "camel_41098": 0.5798898339271545, "camel_9153": 0.5799379348754883, "camel_39340": 0.5799958109855652, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.5803106427192688, "TheoremQA_xinyi/distortion_rate_function_2.json": 0.5804200172424316, "camel_40819": 0.5808619856834412, "aqua_rat_27910": 0.5810344219207764, "camel_41991": 0.5810562968254089, "camel_17561": 0.5813383460044861, "camel_25823": 0.5817593336105347, "gsm_rft_13965": 0.5831655859947205, "gsm_train_30685": 0.5831655859947205, "camel_41293": 0.5832663774490356, "camel_15821": 0.5832914710044861, "camel_41284": 0.5833185315132141, "camel_25774": 0.5837003588676453, "camel_40982": 0.5837737917900085, "camel_41757": 0.5843313932418823, "camel_28384": 0.5843396782875061, "camel_41090": 0.5850287079811096, "camel_44732": 0.5853458046913147, "aqua_rat_10496": 0.5856629610061646, "aqua_rat_60195": 0.585707426071167, "TheoremQA_maxku/ipnetwork10-datatransmission.json": 0.5861921906471252, "camel_30407": 0.5862010717391968, "TheoremQA_maxku/cv-imageprocessing11-histogram.json": 0.5863972306251526, "camel_29078": 0.5870745182037354, "aqua_rat_87402": 0.5871548652648926, "camel_17586": 0.5873288512229919, "camel_45809": 0.5885199904441833, "TheoremQA_xinyi/binary_symmetric_channel_1.json": 0.5886158347129822, "camel_30474": 0.5889256000518799, "camel_39021": 0.5889442563056946, "camel_36493": 0.5911749601364136, "aqua_rat_52087": 0.5929097533226013, "TheoremQA_xinyi/data_processing.json": 0.5929263830184937, "aqua_rat_36286": 0.5959150791168213, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.5962913632392883, "camel_39482": 0.597429096698761, "camel_29042": 0.5983482599258423, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.6054438948631287, "TheoremQA_xinyi/expected_distortion.json": 0.6096948385238647, "TheoremQA_maxku/signalprocessing18-noisebark.json": 0.6118267178535461, "camel_45836": 0.6174588799476624, "TheoremQA_xinyi/rate_distortion_function_1.json": 0.6271452307701111, "TheoremQA_xinyi/fano_inequality.json": 0.6334446668624878, "TheoremQA_xinyi/distortion_rate_function_1.json": 0.6349853873252869, "TheoremQA_xinyi/concavity.json": 0.6387007236480713, "TheoremQA_xinyi/channel_capacity_1.json": 0.6405256986618042, "camel_44741": 0.6505112648010254, "camel_44798": 0.6518757939338684, "TheoremQA_xinyi/shannon_lower_bound.json": 0.6830401420593262}, "TheoremQA_wenhuchen/jensen1.json": {"math_test_precalculus_843": 0, "TheoremQA_wenhuchen/jensen1.json": 0, "camel_18700": 0.6761545538902283, "math_train_geometry_636": 0.676231324672699, "camel_4491": 0.6763970255851746, "camel_4437": 0.6765331029891968, "camel_4210": 0.6767511963844299, "camel_3947": 0.6767946481704712, "camel_39127": 0.6768103241920471, "camel_5608": 0.6770434379577637, "camel_6239": 0.6772081255912781, "camel_5668": 0.677315354347229, "aqua_rat_17326": 0.67732173204422, "camel_4508": 0.6774137616157532, "gsm_rft_35096": 0.6774589419364929, "camel_4414": 0.6775034666061401, "aqua_rat_25657": 0.6777544617652893, "TheoremQA_tonyxia/semiconductor5.json": 0.6778141856193542, "camel_5602": 0.6779402494430542, "camel_5625": 0.6780856251716614, "aqua_rat_3099": 0.6781124472618103, "camel_4488": 0.6782298684120178, "camel_4597": 0.6784841418266296, "camel_1779": 0.6785193085670471, "camel_4599": 0.6786370873451233, "camel_5647": 0.6788350939750671, "gsm_rft_8569": 0.6789432764053345, "camel_4527": 0.6791545748710632, "camel_5813": 0.6792119741439819, "aqua_rat_24553": 0.6796311736106873, "camel_5637": 0.6796565651893616, "camel_4454": 0.6798531413078308, "camel_5710": 0.6798901557922363, "camel_5893": 0.6802226901054382, "camel_5678": 0.6802976131439209, "camel_5601": 0.6803067326545715, "camel_4207": 0.6804210543632507, "camel_4534": 0.6804770231246948, "camel_5651": 0.680578887462616, "aqua_rat_10210": 0.6806583404541016, "aqua_rat_85168": 0.6807077527046204, "camel_4664": 0.6807787418365479, "camel_4463": 0.6808502078056335, "TheoremQA_wenhuchen/triangle2.json": 0.6809472441673279, "gsm_train_18703": 0.680992841720581, "gsm_rft_3456": 0.680992841720581, "gsm_rft_29143": 0.6810139417648315, "camel_4442": 0.6810261011123657, "camel_5635": 0.6811460852622986, "camel_4559": 0.681178629398346, "camel_5723": 0.6812868118286133, "camel_5605": 0.6814924478530884, "camel_4462": 0.6817518472671509, "camel_5861": 0.6821648478507996, "camel_4512": 0.6821812987327576, "camel_4487": 0.6822053790092468, "aqua_rat_84977": 0.6824060678482056, "camel_4648": 0.6824334859848022, "camel_19846": 0.6825358271598816, "camel_4521": 0.6825810670852661, "camel_5334": 0.6828652024269104, "camel_5629": 0.6833562254905701, "camel_4413": 0.683632493019104, "math_test_geometry_853": 0.6836788058280945, "math_test_prealgebra_1807": 0.6837409138679504, "camel_4681": 0.6839629411697388, "aqua_rat_52887": 0.684047281742096, "camel_4853": 0.6843463182449341, "aqua_rat_25559": 0.6844123005867004, "gsm_rft_34910": 0.6844689249992371, "camel_1818": 0.6845393776893616, "camel_19878": 0.6849310994148254, "camel_5622": 0.6850167512893677, "camel_5338": 0.6851300001144409, "aqua_rat_17304": 0.6851592659950256, "camel_4514": 0.68524169921875, "camel_5722": 0.6853166222572327, "aqua_rat_7637": 0.6855968236923218, "camel_4443": 0.6858552098274231, "camel_19869": 0.6859338283538818, "camel_19904": 0.6860477924346924, "camel_4516": 0.686315655708313, "camel_5805": 0.6863388419151306, "camel_29860": 0.6864873766899109, "gsm_train_2408": 0.6865732669830322, "camel_4652": 0.6867334246635437, "gsm_rft_19016": 0.6871921420097351, "camel_5744": 0.687249481678009, "camel_5643": 0.6873731017112732, "camel_4610": 0.6878294944763184, "camel_5749": 0.6879727244377136, "aqua_rat_7675": 0.6880143880844116, "aqua_rat_72505": 0.6887395977973938, "camel_3983": 0.6887564659118652, "aqua_rat_65114": 0.6889752149581909, "camel_19919": 0.6897782683372498, "camel_5688": 0.6901373267173767, "aqua_rat_79137": 0.6903523206710815, "camel_4524": 0.6903801560401917, "camel_5653": 0.690625786781311, "camel_19693": 0.6909268498420715, "camel_19889": 0.6911084651947021, "camel_4518": 0.6917361617088318, "camel_4311": 0.6917811632156372, "camel_4683": 0.6917937994003296, "gsm_rft_26751": 0.6923386454582214, "math_train_prealgebra_781": 0.6923391819000244, "aqua_rat_82184": 0.6925091743469238, "camel_19887": 0.6925376653671265, "camel_4450": 0.6925815343856812, "camel_4551": 0.6933276653289795, "camel_39489": 0.6933587789535522, "camel_4421": 0.6947492361068726, "camel_5663": 0.6951112747192383, "camel_5829": 0.695306658744812, "camel_4435": 0.6954518556594849, "camel_4465": 0.6956291794776917, "camel_5681": 0.6960475444793701, "camel_4708": 0.696063220500946, "camel_18655": 0.6964934468269348, "camel_5808": 0.6965097188949585, "camel_5904": 0.6970439553260803, "camel_4469": 0.6971984505653381, "camel_5632": 0.6977042555809021, "camel_4452": 0.6983455419540405, "camel_19872": 0.6984267830848694, "camel_4422": 0.6985998749732971, "camel_19881": 0.6990911960601807, "camel_4436": 0.6993295550346375, "camel_4669": 0.699374258518219, "camel_5287": 0.6995391845703125, "camel_4646": 0.6997218728065491, "camel_5689": 0.6997846364974976, "camel_4473": 0.700283944606781, "camel_4401": 0.7006344795227051, "camel_4701": 0.7007213830947876, "camel_4412": 0.7009915709495544, "camel_4464": 0.7011309862136841, "camel_4441": 0.7017373442649841, "camel_4449": 0.7021814584732056, "camel_19859": 0.7021970748901367, "camel_5811": 0.7028568387031555, "camel_4427": 0.703301727771759, "camel_5868": 0.7034041881561279, "camel_19868": 0.703777551651001, "camel_4477": 0.7038766145706177, "camel_4428": 0.7041670680046082, "camel_4400": 0.7042049765586853, "gsm_rft_17678": 0.704372227191925, "camel_4478": 0.7045015692710876, "camel_4468": 0.704744815826416, "camel_4453": 0.7048196792602539, "camel_4402": 0.7052324414253235, "camel_19871": 0.7056471109390259, "camel_4410": 0.7058500647544861, "camel_4408": 0.707258939743042, "camel_4433": 0.7083978652954102, "camel_4457": 0.7086420655250549, "camel_4459": 0.7086989879608154, "camel_4426": 0.7094976902008057, "camel_4697": 0.7096264958381653, "camel_18713": 0.710150957107544, "camel_4467": 0.7102071642875671, "camel_4419": 0.7104799747467041, "camel_4470": 0.7106775045394897, "camel_4455": 0.7114876508712769, "camel_4425": 0.7115231156349182, "camel_4471": 0.7117047905921936, "camel_5887": 0.7119287252426147, "camel_19879": 0.7119303345680237, "camel_5766": 0.712203860282898, "camel_4418": 0.7123087048530579, "camel_4404": 0.712759256362915, "camel_4458": 0.7135249972343445, "camel_28842": 0.7138625979423523, "camel_4407": 0.7141852378845215, "camel_4591": 0.7146848440170288, "camel_4444": 0.7157271504402161, "camel_4715": 0.7181428670883179, "camel_4460": 0.7183908820152283, "camel_4415": 0.7184233665466309, "camel_4431": 0.7184683084487915, "camel_4409": 0.7189050316810608, "camel_4429": 0.7191929817199707, "camel_4476": 0.7193447947502136, "camel_4667": 0.7198327779769897, "camel_4440": 0.7214875221252441, "camel_18649": 0.7216967344284058, "camel_4424": 0.7235572338104248, "camel_4456": 0.7237807512283325, "camel_4416": 0.7249496579170227, "camel_4686": 0.725443959236145, "camel_4438": 0.7263068556785583, "camel_4447": 0.7275766134262085, "camel_4475": 0.7288773059844971, "camel_4432": 0.7295928001403809, "camel_4434": 0.7308476567268372, "camel_4445": 0.7336575388908386, "camel_3937": 0.7345589399337769, "camel_4406": 0.7355024218559265}, "TheoremQA_maxku/signalprocessing14-Ztransform.json": {"TheoremQA_maxku/signalprocessing14-Ztransform.json": 0, "camel_29935": 0.6476367115974426, "camel_29392": 0.647710919380188, "camel_29944": 0.6478368043899536, "camel_28687": 0.6478424072265625, "camel_29374": 0.6478902101516724, "camel_29715": 0.6479398608207703, "camel_28456": 0.6479589939117432, "camel_29350": 0.6479814648628235, "camel_29700": 0.6480225324630737, "camel_30407": 0.6480634808540344, "camel_29256": 0.6480640769004822, "camel_29298": 0.6481401324272156, "camel_16825": 0.6482869386672974, "camel_29371": 0.6483789086341858, "camel_29678": 0.648428201675415, "camel_45518": 0.6484490036964417, "camel_28123": 0.6485257148742676, "camel_28156": 0.6485594511032104, "camel_29613": 0.6487059593200684, "camel_29657": 0.6488180160522461, "camel_29362": 0.6489403247833252, "camel_16894": 0.6490984559059143, "camel_16912": 0.6491192579269409, "camel_28465": 0.649185061454773, "camel_28676": 0.6492605805397034, "camel_29999": 0.6494093537330627, "camel_28344": 0.6496738791465759, "camel_29787": 0.6497429013252258, "camel_28385": 0.6498200297355652, "camel_29287": 0.6499629020690918, "camel_28668": 0.6501480340957642, "camel_29877": 0.6501628160476685, "camel_28138": 0.6502377986907959, "camel_29964": 0.6502673029899597, "camel_28084": 0.6503262519836426, "camel_29686": 0.6506243944168091, "camel_29691": 0.6507264375686646, "camel_29049": 0.6507385969161987, "camel_28116": 0.6510130763053894, "camel_28234": 0.651069700717926, "camel_29437": 0.6510936617851257, "camel_28787": 0.6515076160430908, "camel_28604": 0.651654064655304, "camel_29745": 0.6517317891120911, "camel_45836": 0.65199875831604, "camel_28099": 0.6520175933837891, "camel_29589": 0.6521216630935669, "camel_16905": 0.6522202491760254, "camel_29692": 0.6522611379623413, "camel_28145": 0.6525226831436157, "camel_29972": 0.6525891423225403, "camel_28468": 0.6526073813438416, "camel_29722": 0.6526129245758057, "camel_29241": 0.6526623368263245, "camel_28187": 0.6527082324028015, "camel_29407": 0.6527130603790283, "camel_29664": 0.6528747081756592, "camel_28883": 0.6529195308685303, "camel_29234": 0.6530551910400391, "camel_29071": 0.653584361076355, "camel_28718": 0.6536023616790771, "camel_29190": 0.6536229252815247, "camel_29710": 0.6536853313446045, "camel_28195": 0.6538184285163879, "camel_29346": 0.6538856029510498, "camel_29759": 0.653952419757843, "camel_28122": 0.6539987325668335, "camel_28802": 0.6540547609329224, "camel_28797": 0.6541841626167297, "camel_28502": 0.6542479991912842, "camel_29987": 0.6543574929237366, "camel_28163": 0.6543866395950317, "camel_29050": 0.6544919610023499, "camel_29667": 0.6546187996864319, "camel_29434": 0.6548677682876587, "camel_17561": 0.6550388932228088, "camel_29258": 0.6552082300186157, "camel_29741": 0.65549635887146, "gsm_rft_21298": 0.6554967164993286, "gsm_train_20944": 0.6554967164993286, "camel_28869": 0.6555307507514954, "camel_29322": 0.6559616327285767, "camel_29034": 0.6561070680618286, "camel_16996": 0.6564635634422302, "camel_29947": 0.656608521938324, "camel_29097": 0.6567652225494385, "camel_29249": 0.6567808985710144, "camel_29997": 0.6568236947059631, "camel_29108": 0.6569055318832397, "camel_29372": 0.6569893956184387, "camel_28520": 0.6570746302604675, "camel_28815": 0.6571152806282043, "camel_28404": 0.6572311520576477, "camel_29416": 0.6572493314743042, "camel_29687": 0.6575636267662048, "camel_29141": 0.6578701138496399, "camel_29265": 0.658003568649292, "camel_29132": 0.6580082774162292, "camel_29277": 0.6580437421798706, "camel_29755": 0.6581324934959412, "camel_28462": 0.6581587791442871, "camel_29971": 0.658164918422699, "camel_29121": 0.6582310199737549, "gsm_rft_33863": 0.6583442687988281, "camel_29230": 0.6590572595596313, "camel_29730": 0.6594913601875305, "camel_29721": 0.6595852375030518, "camel_29832": 0.659672737121582, "camel_29329": 0.6600049734115601, "camel_29705": 0.6600579023361206, "camel_29438": 0.6603229641914368, "camel_28178": 0.6604874730110168, "camel_28121": 0.6605188846588135, "camel_29682": 0.6607757806777954, "camel_29951": 0.6611098647117615, "camel_28754": 0.6611394882202148, "camel_29301": 0.6612570285797119, "camel_29044": 0.6614668965339661, "camel_29206": 0.6615201830863953, "camel_28789": 0.6617482900619507, "camel_28154": 0.6618367433547974, "camel_28379": 0.6619743704795837, "camel_29088": 0.6621588468551636, "camel_29232": 0.6622183322906494, "camel_29328": 0.6622836589813232, "camel_28821": 0.6624833345413208, "camel_29680": 0.662539005279541, "camel_17435": 0.6626203656196594, "camel_28227": 0.6628238558769226, "camel_28946": 0.6629496812820435, "camel_29244": 0.6632857322692871, "camel_29394": 0.6634736061096191, "camel_29992": 0.6637035012245178, "camel_30413": 0.6642511487007141, "camel_29220": 0.6643010973930359, "camel_29321": 0.6645998358726501, "camel_28081": 0.6647313833236694, "camel_28149": 0.6653485298156738, "TheoremQA_maxku/signalprocessing6-Ztransform.json": 0.6656689643859863, "camel_29257": 0.665752649307251, "camel_29215": 0.665940523147583, "gsm_rft_11471": 0.6660635471343994, "camel_28395": 0.6661828756332397, "camel_29255": 0.6669583320617676, "camel_29222": 0.6670262813568115, "camel_29163": 0.6673645377159119, "camel_29273": 0.6673867702484131, "camel_28407": 0.6676080822944641, "camel_28119": 0.6679444909095764, "camel_29080": 0.6681932210922241, "camel_28113": 0.6689570546150208, "camel_29217": 0.6691684722900391, "camel_29228": 0.6693833470344543, "camel_29216": 0.6698334813117981, "camel_29684": 0.6698437929153442, "camel_29204": 0.6700131297111511, "camel_29272": 0.6705987453460693, "camel_29373": 0.6715950965881348, "camel_29270": 0.6717197299003601, "camel_29681": 0.6722461581230164, "camel_29224": 0.6725149750709534, "camel_29727": 0.6727271676063538, "camel_29042": 0.6727861762046814, "camel_29271": 0.6732416749000549, "camel_29235": 0.6733457446098328, "camel_29275": 0.673924446105957, "camel_29122": 0.6740909814834595, "camel_29184": 0.6741390228271484, "camel_28384": 0.6741510033607483, "camel_29695": 0.6742237210273743, "camel_29245": 0.674673318862915, "camel_29638": 0.6761449575424194, "camel_28148": 0.676716685295105, "camel_29251": 0.6767329573631287, "camel_29276": 0.6771571040153503, "camel_29364": 0.6780485510826111, "camel_29752": 0.6785430908203125, "camel_29243": 0.6788411736488342, "camel_29749": 0.678888201713562, "camel_29693": 0.6789382100105286, "camel_29711": 0.680163562297821, "camel_29229": 0.680362343788147, "camel_29078": 0.6812661290168762, "TheoremQA_maxku/signalprocessing13-Ztransform.json": 0.6823002696037292, "camel_29278": 0.6840482950210571, "camel_29218": 0.6851561069488525, "camel_29178": 0.6857542991638184, "camel_29205": 0.6870591044425964, "camel_29704": 0.6876043677330017, "camel_29065": 0.6881635189056396, "camel_29708": 0.6910802721977234, "camel_29252": 0.69277423620224, "camel_29227": 0.6967342495918274, "camel_29240": 0.6974692344665527, "camel_29279": 0.6985474824905396, "camel_29429": 0.7022438645362854, "camel_29734": 0.7039338946342468, "camel_29719": 0.7192022800445557, "TheoremQA_maxku/signalprocessing4-Ztransform.json": 0.7193459868431091}, "TheoremQA_elainewan/math_calculus_11.json": {"TheoremQA_elainewan/math_calculus_11.json": 0, "gsm_rft_21684": 0.6934840083122253, "aqua_rat_1455": 0.693550169467926, "gsm_rft_7714": 0.6937229633331299, "aqua_rat_34414": 0.6937381625175476, "aqua_rat_80714": 0.6938004493713379, "aqua_rat_55227": 0.6938245296478271, "gsm_rft_24857": 0.6940644979476929, "gsm_train_3122": 0.6941362023353577, "aqua_rat_63497": 0.6942142248153687, "aqua_rat_81360": 0.6942277550697327, "gsm_rft_7166": 0.6943055391311646, "gsm_train_34670": 0.6943762898445129, "aqua_rat_73304": 0.6943957805633545, "aqua_rat_64511": 0.6944075226783752, "gsm_rft_18466": 0.6944311857223511, "camel_31459": 0.6945323348045349, "gsm_rft_20655": 0.6945381164550781, "gsm_rft_11840": 0.6945697069168091, "gsm_rft_28500": 0.6945723295211792, "gsm_rft_25971": 0.6945723295211792, "aqua_rat_13519": 0.6946170330047607, "gsm_rft_15666": 0.6946732997894287, "gsm_train_228": 0.6946732997894287, "gsm_rft_32430": 0.694782018661499, "aqua_rat_64153": 0.6947919130325317, "gsm_rft_33890": 0.6948002576828003, "aqua_rat_63694": 0.6948701739311218, "gsm_train_1691": 0.6948949694633484, "aqua_rat_68523": 0.6949588656425476, "aqua_rat_54398": 0.6951191425323486, "camel_36279": 0.6951259970664978, "math_train_algebra_2739": 0.6952423453330994, "aqua_rat_56111": 0.6954113245010376, "gsm_rft_1527": 0.6954771280288696, "aqua_rat_19975": 0.6955100297927856, "gsm_rft_3828": 0.695584237575531, "aqua_rat_6336": 0.6955872774124146, "aqua_rat_86102": 0.6957170367240906, "aqua_rat_79712": 0.6957972049713135, "aqua_rat_80614": 0.6958249807357788, "aqua_rat_38218": 0.695854127407074, "aqua_rat_16076": 0.695862889289856, "aqua_rat_39776": 0.6958674788475037, "gsm_train_29979": 0.6958972811698914, "gsm_rft_3160": 0.6958972811698914, "aqua_rat_35437": 0.6959299445152283, "gsm_rft_31414": 0.6959734559059143, "aqua_rat_50180": 0.6959822177886963, "gsm_rft_22295": 0.6959840059280396, "aqua_rat_36920": 0.6960275173187256, "gsm_rft_16042": 0.6960394382476807, "aqua_rat_11295": 0.6960687637329102, "aqua_rat_40737": 0.6960717439651489, "aqua_rat_73831": 0.6961482763290405, "gsm_rft_7089": 0.6961888670921326, "aqua_rat_82292": 0.696320652961731, "gsm_rft_31703": 0.6963297724723816, "gsm_rft_29345": 0.6963369250297546, "gsm_train_3954": 0.6963767409324646, "aqua_rat_73781": 0.6964343786239624, "gsm_rft_9784": 0.696438729763031, "gsm_rft_10734": 0.6964622139930725, "camel_37996": 0.6965739130973816, "aqua_rat_29957": 0.6966816186904907, "aqua_rat_45189": 0.6966844201087952, "aqua_rat_9735": 0.6972154378890991, "aqua_rat_13923": 0.6972570419311523, "gsm_rft_5315": 0.6972925662994385, "gsm_rft_9980": 0.6974020004272461, "aqua_rat_70956": 0.6974126100540161, "aqua_rat_15552": 0.6976111531257629, "aqua_rat_14923": 0.6976233124732971, "aqua_rat_47352": 0.697845458984375, "gsm_rft_15843": 0.6979057192802429, "gsm_train_25608": 0.6981990933418274, "aqua_rat_268": 0.6982154846191406, "gsm_rft_3112": 0.698248565196991, "aqua_rat_33076": 0.6982923150062561, "aqua_rat_63183": 0.6983717083930969, "gsm_rft_27637": 0.698392391204834, "aqua_rat_20429": 0.6984267830848694, "gsm_rft_19202": 0.6985592246055603, "aqua_rat_78647": 0.698611855506897, "aqua_rat_52511": 0.6986739635467529, "aqua_rat_1272": 0.6987208724021912, "aqua_rat_26644": 0.6988329887390137, "aqua_rat_40883": 0.6989530324935913, "aqua_rat_78987": 0.6989611983299255, "gsm_rft_20780": 0.6990354061126709, "aqua_rat_48688": 0.6991013884544373, "aqua_rat_63743": 0.6991564035415649, "aqua_rat_12508": 0.6992143392562866, "aqua_rat_42383": 0.6992496848106384, "aqua_rat_36976": 0.6992663741111755, "aqua_rat_88394": 0.6993764042854309, "aqua_rat_23177": 0.6993964910507202, "aqua_rat_61331": 0.6994539499282837, "aqua_rat_75264": 0.6995416879653931, "gsm_rft_33348": 0.6995732188224792, "gsm_train_15406": 0.6997170448303223, "aqua_rat_83930": 0.6997267603874207, "aqua_rat_59846": 0.6998134255409241, "gsm_train_34146": 0.6999267339706421, "aqua_rat_27940": 0.700003981590271, "gsm_rft_19941": 0.7001312375068665, "aqua_rat_28976": 0.7002040147781372, "aqua_rat_77996": 0.700269341468811, "aqua_rat_40634": 0.7002925276756287, "aqua_rat_26624": 0.7004966735839844, "aqua_rat_76557": 0.7005599737167358, "aqua_rat_13618": 0.7006129622459412, "aqua_rat_2852": 0.7006328105926514, "aqua_rat_12665": 0.700647234916687, "aqua_rat_4051": 0.7006568312644958, "aqua_rat_82043": 0.7008980512619019, "aqua_rat_3097": 0.7009578943252563, "aqua_rat_64492": 0.7011685371398926, "aqua_rat_27506": 0.7013958096504211, "aqua_rat_75239": 0.7014275193214417, "aqua_rat_57969": 0.7015401124954224, "aqua_rat_2131": 0.7015590667724609, "gsm_rft_24748": 0.7022535800933838, "gsm_rft_20228": 0.7022700309753418, "gsm_rft_3603": 0.702272355556488, "aqua_rat_72299": 0.7022851705551147, "aqua_rat_63267": 0.7023671269416809, "math_test_prealgebra_1778": 0.7024185061454773, "aqua_rat_83081": 0.7024368047714233, "gsm_rft_24098": 0.702469527721405, "gsm_rft_35561": 0.7027356624603271, "gsm_train_6893": 0.7027475833892822, "aqua_rat_15068": 0.7028563618659973, "aqua_rat_79211": 0.7029685378074646, "gsm_rft_15755": 0.7032386064529419, "aqua_rat_54718": 0.7034424543380737, "gsm_rft_17867": 0.703580379486084, "gsm_rft_27673": 0.7037709951400757, "aqua_rat_14942": 0.7040403485298157, "gsm_rft_57": 0.7046415209770203, "aqua_rat_39626": 0.7049605250358582, "gsm_rft_21076": 0.7050901651382446, "aqua_rat_73185": 0.7051668763160706, "aqua_rat_29678": 0.7053470015525818, "gsm_train_23047": 0.7053835988044739, "aqua_rat_2995": 0.7055014967918396, "aqua_rat_57461": 0.7059242725372314, "aqua_rat_5634": 0.7059658765792847, "gsm_train_31243": 0.7060372829437256, "aqua_rat_36782": 0.7068256735801697, "aqua_rat_53867": 0.7068499326705933, "aqua_rat_76643": 0.7068713307380676, "aqua_rat_11672": 0.7069079875946045, "aqua_rat_43462": 0.7069626450538635, "aqua_rat_50325": 0.7070727348327637, "aqua_rat_35485": 0.7074255347251892, "aqua_rat_10863": 0.7077223658561707, "aqua_rat_47365": 0.7079759240150452, "aqua_rat_39647": 0.7080488204956055, "gsm_rft_25325": 0.7083401679992676, "gsm_rft_7086": 0.7084209322929382, "aqua_rat_31829": 0.7088611721992493, "aqua_rat_10496": 0.7089239954948425, "gsm_rft_27918": 0.7089994549751282, "math_train_number_theory_7070": 0.7090495228767395, "gsm_train_34454": 0.7096431255340576, "gsm_rft_13166": 0.7097965478897095, "gsm_rft_759": 0.7097965478897095, "gsm_rft_27862": 0.7105920910835266, "gsm_train_29765": 0.7105920910835266, "gsm_rft_10897": 0.710645854473114, "TheoremQA_elainewan/math_calculus_2_10.json": 0.7107778191566467, "gsm_rft_14868": 0.711307168006897, "gsm_rft_11288": 0.7117241024971008, "gsm_train_21052": 0.7119609117507935, "aqua_rat_32037": 0.7127047181129456, "aqua_rat_53348": 0.7129002809524536, "gsm_rft_17385": 0.713059663772583, "gsm_rft_6386": 0.7131966352462769, "aqua_rat_69903": 0.7147364616394043, "aqua_rat_4578": 0.7154451608657837, "aqua_rat_8703": 0.7156944274902344, "aqua_rat_14328": 0.7157126665115356, "aqua_rat_84494": 0.7159773111343384, "aqua_rat_18977": 0.716119110584259, "aqua_rat_23682": 0.7163291573524475, "aqua_rat_9148": 0.7163780331611633, "gsm_rft_5566": 0.7166773080825806, "gsm_rft_14302": 0.7169058322906494, "gsm_train_15265": 0.7169058322906494, "aqua_rat_37668": 0.7175923585891724, "aqua_rat_65312": 0.7179670929908752, "gsm_rft_5789": 0.7181276082992554, "aqua_rat_71294": 0.7182861566543579, "aqua_rat_37483": 0.7183305025100708, "aqua_rat_42745": 0.7183673977851868, "aqua_rat_77082": 0.7190858125686646, "gsm_rft_13994": 0.7236924767494202, "aqua_rat_27858": 0.7238572835922241, "aqua_rat_11429": 0.7249177694320679}, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": {"TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0, "camel_9130": 0.6901584267616272, "camel_30740": 0.6902241706848145, "camel_28244": 0.6903787851333618, "camel_30455": 0.690440833568573, "camel_30750": 0.6906611919403076, "camel_19873": 0.6906969547271729, "camel_30781": 0.690727174282074, "camel_29305": 0.6907669305801392, "camel_28258": 0.6908075213432312, "aqua_rat_86374": 0.6909567713737488, "camel_30730": 0.6909933090209961, "aqua_rat_9335": 0.6912633776664734, "camel_18348": 0.691270649433136, "aqua_rat_47280": 0.6913140416145325, "camel_30777": 0.6914262771606445, "camel_47731": 0.6915267109870911, "aqua_rat_17107": 0.6916366815567017, "aqua_rat_59992": 0.6918821334838867, "camel_29323": 0.6918886303901672, "aqua_rat_12007": 0.6918947100639343, "camel_30215": 0.6922360062599182, "camel_30782": 0.6922821998596191, "aqua_rat_24561": 0.69228595495224, "math_test_counting_and_probability_731": 0.6924216747283936, "camel_30290": 0.6927303671836853, "aqua_rat_64423": 0.6928209066390991, "math_train_intermediate_algebra_1193": 0.6928395628929138, "camel_46152": 0.6930524706840515, "aqua_rat_11272": 0.6930550336837769, "math_test_intermediate_algebra_934": 0.693248450756073, "camel_30776": 0.693260908126831, "camel_28419": 0.6932886242866516, "camel_30264": 0.6933257579803467, "camel_30466": 0.693375289440155, "aqua_rat_61609": 0.6933765411376953, "camel_28361": 0.6934844851493835, "camel_30244": 0.6935259699821472, "camel_30265": 0.693567156791687, "aqua_rat_9508": 0.6936074495315552, "camel_30294": 0.6937354803085327, "math_train_intermediate_algebra_831": 0.6937618255615234, "aqua_rat_85395": 0.6937850713729858, "camel_9151": 0.6939533948898315, "aqua_rat_18327": 0.6940013766288757, "camel_30219": 0.6941075325012207, "camel_9760": 0.6941989660263062, "camel_28732": 0.6942872405052185, "camel_28243": 0.6944512724876404, "camel_48498": 0.694468080997467, "camel_28242": 0.6946040987968445, "camel_30738": 0.6946964859962463, "camel_47813": 0.6948598623275757, "camel_29320": 0.6948802471160889, "camel_28256": 0.6950803399085999, "camel_28459": 0.6953325867652893, "camel_30209": 0.6953557729721069, "aqua_rat_62326": 0.6953795552253723, "camel_42869": 0.6954203248023987, "camel_29339": 0.6954551339149475, "camel_30458": 0.6955739855766296, "camel_30272": 0.6956278681755066, "math_train_algebra_848": 0.6958094239234924, "camel_30729": 0.6958510279655457, "aqua_rat_12090": 0.6959587335586548, "math_train_prealgebra_1883": 0.695978581905365, "math_test_intermediate_algebra_1417": 0.696021318435669, "camel_46082": 0.6960313320159912, "camel_30319": 0.6961151361465454, "camel_30905": 0.696162760257721, "aqua_rat_6077": 0.6964702606201172, "camel_28286": 0.6964936256408691, "camel_30788": 0.6965595483779907, "camel_29321": 0.696669340133667, "camel_30208": 0.6968981623649597, "camel_42629": 0.6970660090446472, "camel_30753": 0.6970668435096741, "aqua_rat_2076": 0.6970918774604797, "aqua_rat_72434": 0.6971877813339233, "camel_28476": 0.6973417401313782, "camel_30764": 0.6977209448814392, "camel_30226": 0.6978561878204346, "aqua_rat_64490": 0.6982300877571106, "camel_30744": 0.6984847784042358, "camel_30183": 0.6985578536987305, "camel_30232": 0.6985706686973572, "camel_46110": 0.6985990405082703, "camel_30222": 0.6988028287887573, "aqua_rat_31052": 0.6988400816917419, "camel_42421": 0.6989260911941528, "camel_47706": 0.6989468932151794, "aqua_rat_66974": 0.6990274786949158, "camel_28372": 0.6992132067680359, "camel_15836": 0.6994788646697998, "camel_25549": 0.6995630264282227, "camel_47760": 0.6995773315429688, "math_test_geometry_507": 0.6997076869010925, "camel_18936": 0.6997389197349548, "camel_30250": 0.7000153660774231, "camel_30197": 0.7001771330833435, "camel_46145": 0.7002770900726318, "math_train_geometry_491": 0.700403094291687, "camel_47836": 0.7005181312561035, "aqua_rat_49279": 0.700637936592102, "camel_15830": 0.7007186412811279, "aqua_rat_4038": 0.7007908821105957, "camel_15764": 0.7008082866668701, "camel_30234": 0.7009369134902954, "aqua_rat_25540": 0.7015120983123779, "camel_28271": 0.7017290592193604, "camel_15770": 0.7017619609832764, "camel_30471": 0.7018016576766968, "camel_30163": 0.701970636844635, "camel_30182": 0.7020060420036316, "camel_30164": 0.7021741271018982, "camel_30216": 0.7023140788078308, "camel_30262": 0.7024276852607727, "camel_18906": 0.7024305462837219, "camel_28260": 0.7024568915367126, "aqua_rat_76216": 0.7024790644645691, "camel_28453": 0.7025353908538818, "camel_28278": 0.7026405334472656, "camel_30292": 0.7026751637458801, "camel_19716": 0.7027877569198608, "math_test_counting_and_probability_969": 0.7030575275421143, "camel_28433": 0.7031422257423401, "camel_42469": 0.7032355070114136, "camel_28282": 0.7034258246421814, "camel_30763": 0.7035952210426331, "camel_30169": 0.7036919593811035, "camel_30739": 0.704276442527771, "camel_30161": 0.7043483853340149, "math_train_geometry_6086": 0.7045220136642456, "aqua_rat_10411": 0.7046847343444824, "camel_18377": 0.7047204971313477, "camel_30211": 0.7048298716545105, "aqua_rat_33708": 0.7049077749252319, "camel_28252": 0.7051824331283569, "camel_39001": 0.7053715586662292, "camel_30793": 0.7058917284011841, "aqua_rat_38356": 0.7063745856285095, "camel_28265": 0.7064640522003174, "aqua_rat_14389": 0.7067154049873352, "camel_49899": 0.7068794965744019, "camel_28311": 0.7072045803070068, "aqua_rat_13841": 0.7075916528701782, "camel_30167": 0.7083069682121277, "aqua_rat_36627": 0.7083932161331177, "aqua_rat_85048": 0.7086367011070251, "aqua_rat_83185": 0.70876145362854, "camel_30293": 0.7091813683509827, "aqua_rat_71822": 0.709431529045105, "aqua_rat_71184": 0.709433376789093, "aqua_rat_88630": 0.7095871567726135, "aqua_rat_23501": 0.7100014686584473, "camel_18399": 0.7104488015174866, "camel_28249": 0.7106278538703918, "camel_15810": 0.7110812664031982, "camel_30221": 0.7112091183662415, "camel_15766": 0.7113698124885559, "camel_30465": 0.7115195393562317, "aqua_rat_888": 0.7126425504684448, "camel_9274": 0.7128504514694214, "aqua_rat_40381": 0.7128618955612183, "aqua_rat_32592": 0.7129243016242981, "aqua_rat_38400": 0.712958574295044, "camel_30408": 0.7134667038917542, "aqua_rat_77838": 0.7134899497032166, "camel_9134": 0.7136660814285278, "aqua_rat_43896": 0.7145048975944519, "camel_28384": 0.715074360370636, "camel_30224": 0.7159426808357239, "math_train_algebra_2169": 0.7160767316818237, "aqua_rat_24670": 0.7163600921630859, "aqua_rat_10932": 0.7164362668991089, "camel_30727": 0.717536985874176, "aqua_rat_47046": 0.7181307673454285, "camel_15832": 0.7183417677879333, "camel_28310": 0.7188201546669006, "camel_28439": 0.7197335362434387, "camel_28290": 0.720229983329773, "aqua_rat_7497": 0.721045732498169, "camel_9133": 0.7217190265655518, "aqua_rat_36704": 0.7218719124794006, "camel_28273": 0.7220481634140015, "aqua_rat_5254": 0.7221994400024414, "aqua_rat_417": 0.7224639654159546, "camel_28935": 0.7225255966186523, "camel_30259": 0.7225444912910461, "camel_30260": 0.7234742045402527, "aqua_rat_26062": 0.7244902849197388, "camel_30304": 0.7279554009437561, "camel_30217": 0.7286252975463867, "aqua_rat_24388": 0.7287284135818481, "math_train_geometry_671": 0.730697512626648, "camel_18380": 0.7341654896736145, "camel_15821": 0.7356246113777161, "aqua_rat_57399": 0.7368079423904419, "camel_30318": 0.7390661239624023, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.81291663646698}, "TheoremQA_elainewan/math_abstact_algebra_7.json": {"math_test_prealgebra_75": 0, "math_train_prealgebra_1248": 0, "math_train_prealgebra_18": 0, "math_train_prealgebra_1573": 0, "math_train_algebra_2532": 0, "math_test_prealgebra_1608": 0, "math_test_prealgebra_849": 0, "aqua_rat_49136": 0.6105939745903015, "aqua_rat_37248": 0.6106642484664917, "aqua_rat_66146": 0.6107622385025024, "aqua_rat_27921": 0.6107944250106812, "aqua_rat_7306": 0.6109455823898315, "aqua_rat_65310": 0.6117030382156372, "camel_21196": 0.611729621887207, "camel_21332": 0.6120262742042542, "aqua_rat_24657": 0.6121073961257935, "aqua_rat_33392": 0.612282395362854, "aops_2007_AIME_I_Problems/Problem_10": 0.6125169992446899, "camel_23312": 0.6125760078430176, "aqua_rat_48139": 0.6128613948822021, "camel_22138": 0.6129752993583679, "camel_20650": 0.6129967570304871, "gsm_rft_18774": 0.6131818890571594, "camel_34171": 0.6132200360298157, "aqua_rat_85822": 0.6133714318275452, "aqua_rat_64420": 0.6140238046646118, "aqua_rat_17902": 0.6142281293869019, "camel_20707": 0.6142356395721436, "aqua_rat_74606": 0.614350438117981, "aqua_rat_35259": 0.6152129769325256, "aqua_rat_15706": 0.6152603626251221, "aqua_rat_25912": 0.6153291463851929, "aqua_rat_19090": 0.6154426336288452, "aqua_rat_53796": 0.6156136393547058, "aqua_rat_10136": 0.6158620715141296, "aops_2017_AMC_10B_Problems/Problem_13": 0.6158797144889832, "math_test_counting_and_probability_852": 0.6159282922744751, "aqua_rat_21541": 0.6163830161094666, "math_test_number_theory_612": 0.6166572570800781, "aqua_rat_50880": 0.6170066595077515, "aqua_rat_25945": 0.6172701716423035, "camel_37147": 0.6174115538597107, "camel_23330": 0.6175204515457153, "aqua_rat_60178": 0.6179227232933044, "aqua_rat_39013": 0.6180779933929443, "aqua_rat_73819": 0.61822509765625, "gsm_rft_17248": 0.6186637282371521, "aqua_rat_15512": 0.6188065409660339, "aqua_rat_40277": 0.6189596056938171, "aqua_rat_89113": 0.6190491914749146, "camel_20680": 0.6190752983093262, "aqua_rat_25794": 0.6191952228546143, "camel_37253": 0.619272768497467, "gsm_rft_2045": 0.6200947761535645, "aqua_rat_21374": 0.6201534271240234, "gsm_rft_13977": 0.6205108165740967, "aqua_rat_84334": 0.6211220026016235, "aqua_rat_65264": 0.6212222576141357, "camel_23323": 0.621230959892273, "aqua_rat_59803": 0.6213117241859436, "camel_37456": 0.6213231682777405, "camel_21050": 0.6213642954826355, "camel_20714": 0.6217485070228577, "camel_21183": 0.6221541166305542, "aqua_rat_40504": 0.6223953366279602, "gsm_rft_2788": 0.6226574182510376, "math_train_counting_and_probability_149": 0.6227667331695557, "aqua_rat_43520": 0.6231232285499573, "camel_37242": 0.6231740713119507, "camel_20658": 0.6233672499656677, "aqua_rat_50047": 0.6241325736045837, "math_test_counting_and_probability_4": 0.6243153214454651, "aqua_rat_65383": 0.6244874000549316, "gsm_train_15213": 0.6245589852333069, "camel_20898": 0.6245825886726379, "gsm_rft_4225": 0.6251762509346008, "aqua_rat_83119": 0.6251952052116394, "aqua_rat_7001": 0.625523030757904, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0.6259607672691345, "aqua_rat_84502": 0.6259841322898865, "camel_37229": 0.6261398196220398, "math_train_counting_and_probability_959": 0.6265943646430969, "aqua_rat_80216": 0.6268046498298645, "math_train_counting_and_probability_70": 0.6269930005073547, "camel_34285": 0.626997172832489, "camel_21147": 0.6289466619491577, "camel_23292": 0.6292051672935486, "math_train_counting_and_probability_125": 0.6296032071113586, "gsm_rft_24858": 0.6299712657928467, "aqua_rat_21686": 0.6301926374435425, "camel_36978": 0.6305216550827026, "aqua_rat_37328": 0.6306976079940796, "aqua_rat_25103": 0.6307416558265686, "aqua_rat_37649": 0.6314698457717896, "math_test_counting_and_probability_987": 0.6315179467201233, "aqua_rat_15630": 0.631662905216217, "camel_20700": 0.6316947937011719, "camel_38524": 0.6318967342376709, "camel_21158": 0.6323301792144775, "math_test_counting_and_probability_294": 0.6326132416725159, "math_train_counting_and_probability_5113": 0.6326969861984253, "math_train_counting_and_probability_651": 0.6328647136688232, "camel_21568": 0.6332190036773682, "aqua_rat_84086": 0.6334587931632996, "camel_21055": 0.6335293650627136, "camel_21289": 0.6338748335838318, "aqua_rat_26932": 0.6339536905288696, "camel_21259": 0.6341147422790527, "aqua_rat_84328": 0.6345492005348206, "math_train_counting_and_probability_914": 0.6345722079277039, "aqua_rat_68250": 0.6345829367637634, "aqua_rat_4199": 0.634690523147583, "camel_20665": 0.6362146735191345, "aqua_rat_15869": 0.6362473964691162, "aqua_rat_39478": 0.6363915205001831, "camel_21154": 0.6366233825683594, "aqua_rat_22470": 0.6367157101631165, "math_train_counting_and_probability_98": 0.6368274688720703, "aqua_rat_51045": 0.6370533108711243, "camel_21120": 0.637345016002655, "camel_20540": 0.637874186038971, "math_train_counting_and_probability_5123": 0.6379163265228271, "aqua_rat_85357": 0.6382355690002441, "aqua_rat_50597": 0.6382758617401123, "aqua_rat_38419": 0.6388919353485107, "aqua_rat_48130": 0.6392650008201599, "aqua_rat_30610": 0.6395987868309021, "camel_20310": 0.6397567391395569, "aqua_rat_66391": 0.639986515045166, "aqua_rat_84877": 0.6411722302436829, "aqua_rat_31046": 0.6412286162376404, "camel_20841": 0.6418588757514954, "TheoremQA_jianyu_xu/pigeonhole_4.json": 0.641972005367279, "camel_21246": 0.6423656940460205, "camel_18056": 0.6424810290336609, "aqua_rat_36058": 0.6431406140327454, "camel_20695": 0.6433042883872986, "camel_21126": 0.6434406638145447, "aqua_rat_21205": 0.6440578699111938, "aqua_rat_42578": 0.6450937986373901, "aqua_rat_47936": 0.6452118158340454, "aqua_rat_73523": 0.6454481482505798, "camel_21835": 0.645501434803009, "aqua_rat_10371": 0.6459103226661682, "camel_21128": 0.645941972732544, "aqua_rat_6686": 0.6466515064239502, "camel_21174": 0.6469385027885437, "aqua_rat_60138": 0.6469402313232422, "camel_21225": 0.6479216814041138, "aqua_rat_62050": 0.6480078101158142, "aqua_rat_7922": 0.6487309336662292, "aqua_rat_17512": 0.6490868926048279, "aqua_rat_57502": 0.6495664119720459, "aqua_rat_37188": 0.6502965092658997, "aqua_rat_19178": 0.6507800817489624, "aqua_rat_56307": 0.6507876515388489, "aqua_rat_79259": 0.6519618630409241, "aqua_rat_60456": 0.6523051261901855, "aqua_rat_33304": 0.6542458534240723, "aqua_rat_79267": 0.6543843746185303, "aqua_rat_56889": 0.6545259356498718, "aqua_rat_22591": 0.6569743156433105, "aqua_rat_9092": 0.6573519110679626, "aqua_rat_80145": 0.65781170129776, "aqua_rat_6737": 0.6586176156997681, "aqua_rat_22563": 0.6588537096977234, "aqua_rat_46126": 0.6600651741027832, "aqua_rat_55838": 0.6605167984962463, "camel_37121": 0.6615757346153259, "aqua_rat_32446": 0.6616949439048767, "aqua_rat_30048": 0.6628548502922058, "camel_20596": 0.6628782153129578, "aqua_rat_52771": 0.6630604267120361, "camel_21798": 0.6634984612464905, "camel_21177": 0.6637406945228577, "aqua_rat_3736": 0.6637802124023438, "aqua_rat_7648": 0.6643883585929871, "TheoremQA_jianyu_xu/pigeonhole_3.json": 0.6647206544876099, "camel_21169": 0.6654794812202454, "math_train_counting_and_probability_633": 0.6655988097190857, "aqua_rat_39612": 0.6680199503898621, "camel_21360": 0.6681610941886902, "aqua_rat_80683": 0.668250322341919, "aqua_rat_17550": 0.6687719821929932, "aqua_rat_19096": 0.6690888404846191, "aqua_rat_79867": 0.6704961061477661, "camel_21252": 0.671962559223175, "aqua_rat_257": 0.672932505607605, "camel_21390": 0.6776236295700073, "aqua_rat_43005": 0.6776592135429382, "aqua_rat_76846": 0.6793770790100098, "camel_21165": 0.6809198260307312, "camel_37260": 0.6810669898986816, "camel_20614": 0.6819255948066711, "camel_21361": 0.6866839528083801, "aqua_rat_78522": 0.6879714131355286, "aqua_rat_5877": 0.6999234557151794, "camel_21040": 0.6999330520629883, "aqua_rat_39047": 0.7219662666320801, "camel_21372": 0.7222297191619873}, "TheoremQA_maxku/signalprocessing2-DB.json": {"TheoremQA_maxku/signalprocessing2-DB.json": 0, "gsm_rft_1576": 0.6561583280563354, "aqua_rat_37157": 0.6562525033950806, "aqua_rat_59885": 0.6563436985015869, "gsm_rft_17440": 0.6565819382667542, "gsm_rft_29222": 0.6565819382667542, "aqua_rat_2195": 0.6566071510314941, "aqua_rat_42817": 0.6566779613494873, "aqua_rat_26290": 0.6567177176475525, "gsm_rft_19435": 0.6567707061767578, "gsm_train_25711": 0.6568238735198975, "gsm_train_6133": 0.6568310856819153, "aqua_rat_13821": 0.6568558216094971, "gsm_rft_4808": 0.6569419503211975, "gsm_rft_22897": 0.6569851636886597, "gsm_rft_12677": 0.6569851636886597, "gsm_train_27476": 0.6569851636886597, "gsm_rft_23368": 0.6571255326271057, "gsm_rft_6894": 0.6573265194892883, "gsm_rft_2706": 0.6573424935340881, "gsm_rft_22602": 0.6573641300201416, "gsm_train_17402": 0.6573641300201416, "gsm_rft_22331": 0.6575376987457275, "aqua_rat_53118": 0.6575550436973572, "aqua_rat_4046": 0.6576045155525208, "gsm_rft_35381": 0.6577374339103699, "aqua_rat_36286": 0.6577405333518982, "gsm_rft_6908": 0.6578100919723511, "gsm_train_14055": 0.6578100919723511, "gsm_rft_23841": 0.6578100919723511, "gsm_train_4753": 0.6580377817153931, "gsm_rft_4164": 0.658122718334198, "gsm_rft_31710": 0.6581667065620422, "gsm_rft_14389": 0.6581733822822571, "aqua_rat_60986": 0.6581982970237732, "aqua_rat_63612": 0.6582074761390686, "gsm_rft_14019": 0.6582359075546265, "gsm_rft_13274": 0.658482015132904, "aqua_rat_47454": 0.6585333943367004, "gsm_rft_12308": 0.6585847735404968, "gsm_rft_4940": 0.6587525606155396, "aqua_rat_57461": 0.6587600708007812, "gsm_train_5581": 0.6588097214698792, "gsm_rft_8106": 0.6589635014533997, "gsm_train_10372": 0.6589635014533997, "aqua_rat_43685": 0.6589799523353577, "gsm_rft_7920": 0.6590197682380676, "gsm_rft_13924": 0.6590832471847534, "gsm_train_582": 0.6590832471847534, "aqua_rat_13846": 0.6591318249702454, "aqua_rat_53846": 0.6593403816223145, "gsm_train_29178": 0.6593589782714844, "gsm_rft_19214": 0.6595631241798401, "gsm_rft_34386": 0.6599843502044678, "aqua_rat_68943": 0.6599971652030945, "gsm_rft_28061": 0.6601472496986389, "gsm_train_30339": 0.6601489782333374, "gsm_train_34902": 0.6601628065109253, "gsm_rft_1196": 0.660167396068573, "gsm_rft_27723": 0.660232424736023, "gsm_rft_15795": 0.6602485179901123, "aqua_rat_36163": 0.6603282690048218, "gsm_rft_29667": 0.660416305065155, "gsm_train_9619": 0.6604436635971069, "aqua_rat_84836": 0.6605530381202698, "aqua_rat_54911": 0.6606012582778931, "aqua_rat_36251": 0.660631537437439, "aqua_rat_65183": 0.6607689261436462, "gsm_rft_15045": 0.6608055830001831, "gsm_train_18516": 0.6608140468597412, "gsm_rft_28497": 0.6608140468597412, "gsm_train_8512": 0.6608152985572815, "gsm_rft_10941": 0.6608152985572815, "gsm_rft_31387": 0.6608378887176514, "gsm_train_33171": 0.661171555519104, "gsm_rft_13049": 0.66124027967453, "gsm_rft_28086": 0.6613178849220276, "aqua_rat_65585": 0.6617859601974487, "aqua_rat_26529": 0.6618832945823669, "gsm_train_13655": 0.6618982553482056, "aqua_rat_76127": 0.6620486974716187, "gsm_rft_26010": 0.6620816588401794, "gsm_rft_19753": 0.66214919090271, "gsm_rft_20753": 0.66214919090271, "aqua_rat_44457": 0.6622061729431152, "aqua_rat_4051": 0.6623409390449524, "aqua_rat_3234": 0.662506639957428, "aqua_rat_7577": 0.6630232930183411, "gsm_train_17344": 0.6630952954292297, "gsm_rft_28757": 0.6631114482879639, "gsm_rft_9288": 0.6631996035575867, "gsm_rft_8504": 0.6633093357086182, "gsm_rft_16887": 0.6633111238479614, "gsm_rft_20187": 0.6633119583129883, "gsm_rft_34445": 0.663331151008606, "gsm_rft_33530": 0.6635519862174988, "gsm_rft_6549": 0.6636344790458679, "gsm_rft_2081": 0.6640483140945435, "gsm_rft_17550": 0.664139986038208, "gsm_train_19311": 0.664139986038208, "gsm_rft_16684": 0.6641773581504822, "gsm_train_17899": 0.6643056869506836, "gsm_rft_6960": 0.6643056869506836, "gsm_rft_10110": 0.6643917560577393, "gsm_rft_7726": 0.6644421815872192, "gsm_rft_32956": 0.6647790670394897, "aqua_rat_53207": 0.6648061275482178, "gsm_rft_16370": 0.6648321747779846, "gsm_rft_17300": 0.6648329496383667, "gsm_train_12926": 0.6648329496383667, "aqua_rat_23105": 0.6651734113693237, "aqua_rat_19719": 0.6654127836227417, "gsm_rft_11288": 0.6654979586601257, "gsm_rft_28611": 0.6655910611152649, "camel_45836": 0.6659170389175415, "gsm_rft_20209": 0.6659942865371704, "gsm_rft_3001": 0.6659942865371704, "gsm_train_22328": 0.6659942865371704, "gsm_rft_606": 0.6660937666893005, "gsm_rft_28173": 0.6661651134490967, "aqua_rat_66305": 0.6662005186080933, "gsm_rft_32521": 0.6667856574058533, "gsm_rft_32348": 0.6667856574058533, "gsm_train_19192": 0.6668457388877869, "aqua_rat_81450": 0.6673403978347778, "aqua_rat_29101": 0.6678757667541504, "gsm_rft_1000": 0.6680473685264587, "aqua_rat_60714": 0.6680911779403687, "gsm_rft_23817": 0.6682062149047852, "gsm_train_27300": 0.6682062149047852, "gsm_rft_21713": 0.6686712503433228, "gsm_train_22103": 0.669355034828186, "aqua_rat_21550": 0.6693747043609619, "gsm_rft_29698": 0.6695811152458191, "gsm_rft_21678": 0.6698212623596191, "gsm_rft_346": 0.6698874831199646, "gsm_train_6050": 0.6698874831199646, "gsm_rft_1359": 0.6701022386550903, "gsm_train_31455": 0.6702712178230286, "gsm_rft_27026": 0.6706171035766602, "gsm_train_34140": 0.6706171035766602, "gsm_rft_18468": 0.6706171035766602, "gsm_train_13418": 0.6706560254096985, "gsm_rft_3825": 0.6708638072013855, "aqua_rat_66162": 0.6709542870521545, "camel_45809": 0.6710092425346375, "gsm_rft_12975": 0.6710363030433655, "gsm_rft_5362": 0.6710363030433655, "gsm_rft_20150": 0.6711384654045105, "gsm_rft_22234": 0.6712086796760559, "aqua_rat_23127": 0.6719014644622803, "aqua_rat_8610": 0.6721802353858948, "gsm_rft_10897": 0.6727353930473328, "gsm_rft_25996": 0.6730097532272339, "aqua_rat_16469": 0.673291027545929, "gsm_rft_22822": 0.6733607649803162, "gsm_rft_3972": 0.6733768582344055, "gsm_rft_26587": 0.6738181710243225, "gsm_train_26081": 0.6738181710243225, "gsm_rft_27862": 0.6739490032196045, "gsm_train_29765": 0.6739490032196045, "gsm_rft_22363": 0.6743627190589905, "gsm_rft_28838": 0.6744362115859985, "camel_28122": 0.674788236618042, "gsm_rft_7862": 0.6750398278236389, "aqua_rat_6088": 0.675356388092041, "gsm_rft_28746": 0.6762068271636963, "gsm_train_23183": 0.6764357686042786, "gsm_rft_1939": 0.6768984198570251, "gsm_train_31158": 0.6768984198570251, "gsm_rft_35481": 0.6769265532493591, "gsm_rft_6261": 0.6786329746246338, "gsm_rft_8384": 0.6786329746246338, "gsm_rft_31953": 0.6786329746246338, "gsm_train_858": 0.6787152290344238, "gsm_rft_2592": 0.680634081363678, "aqua_rat_84169": 0.6808416843414307, "aqua_rat_53348": 0.681032121181488, "aqua_rat_77082": 0.6810590624809265, "gsm_train_31124": 0.6816049218177795, "gsm_rft_28645": 0.6816049218177795, "gsm_rft_30836": 0.6816049218177795, "gsm_rft_28878": 0.6816049218177795, "gsm_rft_2575": 0.6816865801811218, "gsm_rft_870": 0.6816865801811218, "gsm_rft_24796": 0.6820788383483887, "aqua_rat_32037": 0.6833065152168274, "gsm_rft_33471": 0.6851396560668945, "aqua_rat_59779": 0.6852537393569946, "aqua_rat_32984": 0.6899303793907166, "aqua_rat_59558": 0.6931853294372559, "aqua_rat_27769": 0.6933639049530029, "aqua_rat_73381": 0.6962665915489197, "aqua_rat_22426": 0.7039045691490173, "aqua_rat_82138": 0.7139898538589478, "aqua_rat_36347": 0.7177407741546631, "aqua_rat_69297": 0.7180769443511963, "aqua_rat_54325": 0.7195931077003479, "aqua_rat_61003": 0.7227340936660767, "TheoremQA_maxku/signalprocessing15-DB.json": 0.7369160652160645}, "TheoremQA_panlu/gravitational_force2.json": {"TheoremQA_panlu/gravitational_force2.json": 0, "gsm_train_14395": 0.6238004565238953, "gsm_rft_24421": 0.6239679455757141, "camel_7572": 0.6239793300628662, "camel_7960": 0.6245564818382263, "camel_7480": 0.6248133778572083, "aqua_rat_37440": 0.6254037618637085, "math_test_prealgebra_1873": 0.6255354881286621, "camel_28859": 0.6261175274848938, "aqua_rat_67003": 0.6262124180793762, "gsm_rft_20548": 0.6262798309326172, "gsm_rft_29319": 0.6263148188591003, "gsm_rft_13637": 0.6268519759178162, "gsm_train_9384": 0.6268519759178162, "camel_16554": 0.62701416015625, "camel_28879": 0.6271219849586487, "camel_28858": 0.6271599531173706, "camel_7974": 0.6275393962860107, "camel_7987": 0.6276378035545349, "camel_7541": 0.6278036236763, "camel_7962": 0.6278641819953918, "camel_28807": 0.628187358379364, "camel_7947": 0.6282914280891418, "gsm_rft_9473": 0.6283432245254517, "camel_28816": 0.6286580562591553, "gsm_rft_1170": 0.6287028789520264, "gsm_rft_16594": 0.6287850737571716, "gsm_train_14297": 0.6287850737571716, "camel_28852": 0.6288596987724304, "camel_47494": 0.6289297938346863, "camel_7993": 0.628961980342865, "aqua_rat_49275": 0.629188597202301, "camel_39446": 0.6294059157371521, "camel_39475": 0.629940390586853, "aqua_rat_19334": 0.6302255988121033, "camel_28813": 0.6302858591079712, "aqua_rat_6249": 0.6307567358016968, "aqua_rat_76700": 0.6307629346847534, "camel_39471": 0.6310341954231262, "camel_7920": 0.631198525428772, "aqua_rat_70741": 0.6314713954925537, "camel_28829": 0.6315507292747498, "camel_28841": 0.6318862438201904, "camel_7954": 0.6320839524269104, "gsm_train_13099": 0.6322709918022156, "gsm_rft_34703": 0.6322909593582153, "gsm_rft_9527": 0.6324689984321594, "camel_7966": 0.6326472163200378, "gsm_rft_35102": 0.632941722869873, "gsm_rft_23547": 0.6329799890518188, "camel_7999": 0.633061945438385, "gsm_rft_31297": 0.6331377625465393, "camel_7476": 0.6332131624221802, "gsm_rft_26363": 0.6333069205284119, "gsm_rft_26897": 0.6333135962486267, "camel_28875": 0.6336298584938049, "gsm_train_5772": 0.6336795687675476, "gsm_rft_13505": 0.6338016986846924, "camel_28823": 0.633824348449707, "camel_7478": 0.6341673731803894, "camel_7968": 0.6341854929924011, "gsm_rft_15576": 0.6347090601921082, "aqua_rat_5613": 0.6349962949752808, "camel_28532": 0.6363199949264526, "camel_39474": 0.6363873481750488, "camel_7945": 0.6364357471466064, "camel_28871": 0.6367400288581848, "gsm_rft_29554": 0.6369835138320923, "camel_16246": 0.6373205184936523, "camel_39462": 0.6376874446868896, "camel_28845": 0.6380749940872192, "camel_28808": 0.638198733329773, "camel_39491": 0.6383493542671204, "camel_7982": 0.6383810043334961, "aqua_rat_36823": 0.6384688019752502, "aqua_rat_63716": 0.6386410593986511, "camel_28854": 0.6386626362800598, "camel_28849": 0.6387782692909241, "camel_28806": 0.639121949672699, "camel_46180": 0.6391885876655579, "camel_28818": 0.6396207809448242, "aqua_rat_43112": 0.6401652693748474, "camel_5842": 0.6403195261955261, "camel_28809": 0.6404843330383301, "gsm_rft_35145": 0.642041027545929, "camel_46203": 0.6424083709716797, "camel_39308": 0.6425108909606934, "camel_28861": 0.6432106494903564, "aqua_rat_18805": 0.6434588432312012, "camel_28862": 0.6439837217330933, "camel_39517": 0.644970178604126, "camel_17542": 0.6452184915542603, "camel_28830": 0.6455316543579102, "TheoremQA_panlu/uniform_circular_motion1.json": 0.6460294127464294, "camel_7498": 0.6461929082870483, "camel_7998": 0.6461935639381409, "camel_28833": 0.6463425159454346, "camel_7934": 0.646446704864502, "camel_7922": 0.6469559669494629, "camel_28865": 0.6470363140106201, "camel_16247": 0.6477593779563904, "camel_7610": 0.6481561660766602, "camel_5138": 0.6484308838844299, "camel_4731": 0.6485326886177063, "camel_28822": 0.6493013501167297, "camel_28537": 0.6493386626243591, "camel_39511": 0.6495980024337769, "camel_7937": 0.6500771641731262, "camel_46190": 0.6501795649528503, "aqua_rat_86642": 0.6510246396064758, "camel_28860": 0.6513647437095642, "camel_28855": 0.6516558527946472, "camel_28832": 0.6524862051010132, "camel_39485": 0.6533403396606445, "gsm_rft_10505": 0.6536605954170227, "camel_28820": 0.653718888759613, "camel_28872": 0.6542080044746399, "aqua_rat_26489": 0.654411792755127, "camel_17565": 0.6544265747070312, "camel_7984": 0.6548783779144287, "camel_28826": 0.6555187106132507, "camel_28866": 0.6558499932289124, "aqua_rat_79015": 0.6562407612800598, "camel_5311": 0.6566044092178345, "camel_28867": 0.657028317451477, "gsm_rft_14306": 0.6571838855743408, "camel_7959": 0.6572155952453613, "gsm_rft_22533": 0.6573546528816223, "aqua_rat_88155": 0.6584662199020386, "camel_28831": 0.6591057181358337, "camel_28137": 0.6596113443374634, "camel_7928": 0.659674882888794, "gsm_rft_14979": 0.6600193977355957, "aqua_rat_11867": 0.6606801152229309, "camel_28022": 0.6607053875923157, "gsm_rft_18266": 0.6608932614326477, "gsm_train_553": 0.6608932614326477, "gsm_rft_10934": 0.6609832644462585, "camel_28853": 0.661698579788208, "gsm_rft_1431": 0.6622211933135986, "gsm_train_23496": 0.6623135805130005, "gsm_rft_32685": 0.66233229637146, "camel_39476": 0.6623610258102417, "camel_28868": 0.662952184677124, "camel_28856": 0.6631072759628296, "camel_39450": 0.663394033908844, "camel_7980": 0.6646163463592529, "camel_39452": 0.6651552319526672, "camel_28804": 0.6653656959533691, "gsm_rft_17764": 0.6661838889122009, "gsm_train_29099": 0.6668710708618164, "camel_29979": 0.6680206060409546, "camel_39469": 0.6687156558036804, "gsm_rft_22397": 0.6702996492385864, "camel_39460": 0.6706885099411011, "camel_28873": 0.6709877252578735, "camel_43563": 0.6726323366165161, "camel_28811": 0.6729658246040344, "camel_6246": 0.6734867095947266, "camel_7977": 0.6739977598190308, "aqua_rat_2612": 0.6748253703117371, "aqua_rat_75922": 0.6763743162155151, "aqua_rat_18184": 0.6764373183250427, "camel_17406": 0.6768351197242737, "camel_39467": 0.677130937576294, "TheoremQA_panlu/fluid_pressure1.json": 0.6781131029129028, "camel_28909": 0.6782164573669434, "aqua_rat_4869": 0.6815148591995239, "camel_39504": 0.6828679442405701, "camel_39461": 0.6847133040428162, "camel_7995": 0.6850476861000061, "TheoremQA_panlu/angular_frequency3.json": 0.6850769519805908, "math_test_algebra_518": 0.6859308481216431, "camel_7938": 0.6869495511054993, "aqua_rat_67038": 0.6871037483215332, "camel_28840": 0.6885546445846558, "camel_39479": 0.6887996792793274, "camel_39484": 0.6896184682846069, "camel_28068": 0.6924563646316528, "camel_39453": 0.6934146285057068, "camel_7944": 0.6939055323600769, "camel_28846": 0.6940777897834778, "camel_5857": 0.694865882396698, "TheoremQA_wenhuchen/Fluid_mechanics2.json": 0.6967581510543823, "TheoremQA_wenhuchen/kepler's_law3.json": 0.699476957321167, "camel_5001": 0.700348436832428, "camel_7552": 0.7020881772041321, "camel_39513": 0.7077990770339966, "camel_28847": 0.7114360332489014, "camel_39449": 0.7288691401481628, "camel_39488": 0.7325617074966431, "camel_39508": 0.7346429824829102, "camel_39447": 0.7360339760780334, "camel_39455": 0.7390145063400269, "TheoremQA_panlu/black_hole1.json": 0.7557919025421143, "camel_39515": 0.7707030773162842, "math_train_algebra_2156": 0.8374162912368774, "TheoremQA_panlu/energy_conservation1.json": 0.8474237322807312, "TheoremQA_panlu/gravitational_force1.json": 0.8504117131233215, "TheoremQA_wenhuchen/kepler's_law2.json": 0.8861171007156372}, "TheoremQA_wenhuchen/Liouville\u2019s_theorem2.json": {"camel_43191": 0, "camel_42547": 0, "camel_43211": 0, "camel_43152": 0, "camel_43252": 0, "camel_42422": 0, "camel_43413": 0, "camel_43010": 0, "camel_42972": 0, "camel_42437": 0, "camel_42486": 0, "camel_42438": 0, "camel_43104": 0, "camel_42528": 0, "camel_43408": 0, "camel_42504": 0, "camel_42888": 0, "camel_42520": 0, "camel_43761": 0, "camel_42053": 0, "camel_43911": 0, "camel_42596": 0, "camel_42441": 0, "camel_42551": 0, "camel_42614": 0, "camel_43036": 0, "camel_43227": 0, "camel_43140": 0, "camel_42420": 0, "TheoremQA_wenhuchen/Liouville\u2019s_theorem2.json": 0, "camel_42501": 0, "camel_42464": 0, "camel_42480": 0, "camel_43788": 0, "camel_42549": 0, "camel_42450": 0, "camel_42428": 0, "camel_42434": 0, "camel_42507": 0, "camel_43239": 0, "camel_42417": 0, "camel_43721": 0, "camel_43546": 0, "camel_42011": 0, "camel_42559": 0, "camel_42424": 0, "camel_42474": 0, "camel_42839": 0, "camel_43743": 0, "camel_43154": 0, "camel_42432": 0, "camel_43105": 0, "camel_42129": 0, "camel_43006": 0, "camel_42975": 0, "camel_42531": 0, "camel_42492": 0, "camel_42553": 0, "camel_43020": 0, "camel_43171": 0, "camel_42538": 0, "camel_43106": 0, "camel_43082": 0, "camel_42529": 0, "camel_43163": 0, "camel_42454": 0, "camel_42552": 0, "camel_42558": 0, "camel_43164": 0, "camel_43131": 0, "camel_42431": 0, "camel_42408": 0, "camel_42429": 0, "camel_42456": 0, "camel_42478": 0, "camel_42410": 0, "camel_42519": 0, "camel_43133": 0, "camel_42477": 0, "camel_42921": 0, "camel_42525": 0, "camel_42435": 0, "camel_42996": 0, "camel_42423": 0, "camel_43055": 0, "camel_42426": 0, "camel_43557": 0, "camel_42526": 0, "camel_42985": 0, "camel_42500": 0, "camel_43110": 0, "camel_42512": 0, "camel_42603": 0, "camel_43035": 0, "camel_42485": 0, "camel_43821": 0, "camel_42556": 0, "camel_42564": 0, "camel_42636": 0, "camel_42021": 0, "camel_49083": 0.6933623552322388, "camel_45183": 0.6938468813896179, "camel_30316": 0.6938586831092834, "camel_45496": 0.6939868927001953, "camel_30245": 0.6945114135742188, "camel_45693": 0.6946685314178467, "camel_45721": 0.6946848630905151, "camel_45748": 0.6947991847991943, "camel_45803": 0.6957538723945618, "camel_29899": 0.6959042549133301, "camel_44838": 0.6959859132766724, "camel_45772": 0.6962175965309143, "camel_17657": 0.6970686316490173, "camel_45754": 0.6972383856773376, "camel_45457": 0.6987965703010559, "camel_45407": 0.6992659568786621, "camel_48818": 0.6994410157203674, "camel_45924": 0.7001795768737793, "camel_45314": 0.700238823890686, "camel_17639": 0.7002589702606201, "camel_17269": 0.7005195617675781, "camel_45710": 0.7010037302970886, "camel_44784": 0.701099157333374, "camel_45722": 0.7015143632888794, "camel_44424": 0.7017777562141418, "camel_45725": 0.7017862796783447, "camel_17776": 0.701890230178833, "camel_45741": 0.7032315731048584, "camel_44799": 0.7034533023834229, "camel_45489": 0.7036837935447693, "camel_45518": 0.7044281363487244, "camel_44779": 0.7045872807502747, "camel_45688": 0.7050806283950806, "camel_45718": 0.705128014087677, "camel_30284": 0.7055566310882568, "camel_44721": 0.7058556079864502, "camel_44769": 0.7071489691734314, "camel_45299": 0.7082534432411194, "camel_45379": 0.7087841629981995, "camel_45762": 0.7088639140129089, "camel_45936": 0.7095534205436707, "camel_45315": 0.7096664905548096, "camel_44743": 0.7100929021835327, "camel_44742": 0.7113514542579651, "camel_44776": 0.7120952010154724, "camel_44764": 0.7128797173500061, "camel_45928": 0.7132697105407715, "camel_45834": 0.7133510112762451, "camel_45684": 0.713479220867157, "camel_44848": 0.7145584225654602, "camel_44778": 0.7155424356460571, "camel_44793": 0.7160615921020508, "camel_44774": 0.7160811424255371, "camel_44723": 0.7161181569099426, "camel_44748": 0.7166393399238586, "camel_44725": 0.7167209982872009, "camel_44797": 0.7169831991195679, "camel_45931": 0.7194667458534241, "TheoremQA_mingyin/liouville-theorem1.json": 0.7196170687675476, "camel_44767": 0.7214957475662231, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.722317099571228, "camel_44806": 0.7228792905807495, "camel_45709": 0.7256273627281189, "camel_44781": 0.7259759902954102, "camel_44729": 0.727531373500824, "camel_44746": 0.7286430597305298, "camel_44761": 0.7302664518356323, "camel_44794": 0.7307671308517456, "TheoremQA_wenhuchen/Liouville\u2019s_theorem1.json": 0.7307856678962708, "camel_44547": 0.730832040309906, "camel_44749": 0.7314581871032715, "camel_44752": 0.7339290976524353, "camel_44795": 0.7346655130386353, "camel_44777": 0.7348815202713013, "camel_44766": 0.7363250255584717, "camel_44785": 0.7365872263908386, "camel_44720": 0.7377307415008545, "camel_44722": 0.7378345131874084, "camel_44768": 0.7382848858833313, "camel_44773": 0.7396025657653809, "camel_44744": 0.7407721877098083, "camel_44750": 0.7441021203994751, "camel_44747": 0.7455956339836121, "camel_44787": 0.7458423376083374, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.7477231025695801, "camel_44775": 0.7479207515716553, "camel_44760": 0.747991681098938, "camel_44786": 0.7485430240631104, "camel_44788": 0.7498480081558228, "camel_44782": 0.7502713203430176, "camel_44735": 0.7538740038871765, "camel_44759": 0.7571933269500732, "camel_44728": 0.7582159042358398, "camel_44783": 0.7596569061279297, "camel_44798": 0.7598586678504944, "camel_44762": 0.7652245163917542, "camel_44757": 0.765515148639679, "camel_44727": 0.7721244692802429, "camel_44790": 0.7736178040504456, "camel_44772": 0.7739550471305847}, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus3.json": {"camel_7796": 0, "camel_7097": 0, "camel_7057": 0, "camel_7836": 0, "camel_7831": 0, "camel_7795": 0, "camel_7805": 0, "camel_7799": 0, "camel_7830": 0, "camel_7042": 0, "camel_7119": 0, "camel_7791": 0, "camel_7807": 0, "camel_7082": 0, "camel_7816": 0, "camel_7776": 0, "camel_7815": 0, "camel_7307": 0, "camel_6382": 0, "camel_7818": 0, "camel_7770": 0, "camel_7767": 0, "camel_7809": 0, "camel_7780": 0, "camel_7808": 0, "camel_7821": 0, "camel_7088": 0, "math_test_precalculus_320": 0, "camel_7298": 0, "camel_7284": 0, "camel_7820": 0, "camel_7281": 0, "camel_7814": 0, "camel_7314": 0, "camel_7783": 0, "camel_7761": 0, "camel_7802": 0, "camel_7321": 0, "camel_6286": 0, "camel_7062": 0, "camel_7333": 0, "camel_7798": 0, "camel_7357": 0, "camel_7040": 0, "camel_7810": 0, "camel_7305": 0, "camel_7760": 0, "camel_7772": 0, "camel_7293": 0, "camel_7764": 0, "camel_7771": 0, "camel_7562": 0, "camel_7813": 0, "camel_7834": 0, "camel_7763": 0, "camel_7239": 0, "math_test_precalculus_270": 0, "camel_7790": 0, "camel_6266": 0, "camel_7812": 0, "camel_7324": 0, "camel_7323": 0, "camel_7283": 0, "camel_7344": 0, "camel_7290": 0, "camel_6198": 0, "camel_7340": 0, "camel_7348": 0, "camel_7312": 0, "camel_7318": 0, "camel_7355": 0, "camel_7731": 0, "camel_7359": 0, "camel_7347": 0, "camel_7295": 0, "camel_7341": 0, "camel_7337": 0, "camel_7303": 0, "camel_7313": 0, "camel_7351": 0, "camel_7304": 0, "camel_7835": 0, "camel_7353": 0, "camel_7332": 0, "camel_7819": 0, "camel_7289": 0, "camel_7352": 0, "camel_7338": 0, "camel_7322": 0, "camel_7331": 0, "camel_7280": 0, "camel_7286": 0, "camel_7765": 0, "camel_7292": 0, "camel_7299": 0, "camel_7300": 0, "camel_7287": 0, "camel_7288": 0, "camel_7806": 0, "camel_7311": 0, "camel_7336": 0, "camel_7350": 0, "camel_7291": 0, "camel_7789": 0, "camel_7285": 0, "camel_7342": 0, "camel_7343": 0, "camel_7308": 0, "camel_7329": 0, "camel_7325": 0, "camel_7354": 0, "camel_7080": 0, "camel_7297": 0, "camel_7339": 0, "camel_7296": 0, "camel_7334": 0, "camel_7327": 0, "camel_7073": 0, "camel_7762": 0, "camel_7345": 0, "camel_7335": 0, "math_test_precalculus_1134": 0, "camel_7294": 0, "camel_7326": 0, "camel_7766": 0, "camel_7330": 0, "camel_7356": 0, "camel_7315": 0, "camel_7785": 0, "camel_7317": 0, "camel_6360": 0, "camel_7301": 0, "camel_7346": 0, "camel_7306": 0, "camel_7310": 0, "camel_7358": 0, "camel_7316": 0, "camel_7282": 0, "camel_7349": 0, "camel_7302": 0, "camel_7320": 0, "camel_7328": 0, "camel_7309": 0, "camel_7319": 0, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus3.json": 0, "camel_17537": 0.7072027325630188, "camel_30163": 0.7081323862075806, "camel_19747": 0.7082792520523071, "math_train_geometry_489": 0.7085222005844116, "camel_29192": 0.7085728049278259, "camel_28306": 0.7093291878700256, "camel_28247": 0.7094904780387878, "camel_30190": 0.7096473574638367, "camel_43488": 0.7101020216941833, "TheoremQA_xueguangma/fundamental_theorem_of_calculus.json": 0.7101076245307922, "camel_39254": 0.7101654410362244, "math_test_algebra_853": 0.7106431126594543, "camel_43449": 0.7111889123916626, "math_train_geometry_950": 0.7112315893173218, "camel_30171": 0.7120336890220642, "camel_28250": 0.7121597528457642, "math_train_geometry_6109": 0.7126673460006714, "camel_30162": 0.7146003842353821, "math_train_intermediate_algebra_549": 0.7146746516227722, "camel_28274": 0.7156230807304382, "camel_30238": 0.7157602906227112, "camel_30203": 0.7165387272834778, "camel_5470": 0.716649055480957, "camel_30303": 0.7169658541679382, "camel_19681": 0.7174584865570068, "math_train_prealgebra_1434": 0.7177035808563232, "camel_28313": 0.7182996273040771, "camel_46124": 0.719186007976532, "math_test_intermediate_algebra_1297": 0.7198908925056458, "camel_30319": 0.7230453491210938, "camel_19605": 0.7244458198547363, "camel_39327": 0.7259460091590881, "camel_43453": 0.7263045310974121, "camel_28263": 0.7271031141281128, "camel_28296": 0.727379322052002, "camel_17756": 0.7302204966545105, "aqua_rat_74869": 0.7307551503181458, "aqua_rat_75605": 0.7311847805976868, "camel_43463": 0.7314211130142212, "camel_43464": 0.733553409576416, "camel_43445": 0.734044075012207, "math_test_intermediate_algebra_864": 0.7354373335838318, "TheoremQA_wenhuchen/double_integral1.json": 0.7367093563079834, "camel_30210": 0.7370190620422363, "math_test_intermediate_algebra_1586": 0.7396031618118286, "camel_30175": 0.7434292435646057, "camel_49657": 0.7447522282600403, "camel_39338": 0.7467888593673706, "camel_19568": 0.7471245527267456, "camel_19633": 0.7528625726699829, "camel_28248": 0.7555137276649475, "camel_19617": 0.7629134654998779, "camel_19895": 0.7646105885505676, "camel_44347": 0.7751085758209229, "camel_19725": 0.794090211391449}, "TheoremQA_mingyin/convexity1.json": {"TheoremQA_mingyin/convexity1.json": 0, "camel_38175": 0, "camel_39266": 0, "camel_39237": 0, "camel_39223": 0, "camel_39001": 0, "camel_18255": 0.6528466939926147, "camel_19423": 0.6528667211532593, "camel_28258": 0.652877151966095, "camel_30182": 0.6529079675674438, "camel_28297": 0.6531299352645874, "camel_30180": 0.6531597375869751, "camel_30297": 0.6531654000282288, "camel_19741": 0.6532741785049438, "camel_28302": 0.6534852385520935, "math_test_counting_and_probability_385": 0.6536074876785278, "camel_31497": 0.6536723971366882, "camel_28264": 0.6536902189254761, "math_test_counting_and_probability_175": 0.6537923216819763, "camel_47813": 0.6537923812866211, "camel_30785": 0.6539755463600159, "camel_30726": 0.6542305946350098, "camel_30757": 0.6542357206344604, "camel_31637": 0.6542483568191528, "camel_47805": 0.6544406414031982, "camel_28308": 0.654522716999054, "camel_30765": 0.6545343399047852, "camel_30187": 0.6551356315612793, "camel_31516": 0.6551392674446106, "camel_28278": 0.6555324792861938, "camel_18034": 0.6558128595352173, "math_test_geometry_686": 0.6559814214706421, "camel_18704": 0.6560398936271667, "camel_31983": 0.6561367511749268, "camel_18682": 0.6561452150344849, "camel_30218": 0.6563200950622559, "camel_19867": 0.6565884947776794, "camel_30296": 0.6566136479377747, "aqua_rat_30772": 0.6568111777305603, "aqua_rat_72434": 0.6568285822868347, "camel_19771": 0.6572990417480469, "camel_40893": 0.6575252413749695, "camel_18690": 0.6575273275375366, "math_train_geometry_355": 0.6576743721961975, "camel_30779": 0.6577274799346924, "aqua_rat_57399": 0.6578770279884338, "camel_30242": 0.6584550738334656, "camel_30262": 0.6585372686386108, "aqua_rat_10325": 0.6585621237754822, "camel_19786": 0.6587289571762085, "camel_28276": 0.6588128805160522, "camel_28252": 0.6590044498443604, "camel_30243": 0.6592980027198792, "camel_40940": 0.6596163511276245, "camel_30773": 0.6598227024078369, "camel_19952": 0.6598508954048157, "camel_30730": 0.6598770618438721, "aqua_rat_29007": 0.6599316596984863, "camel_18376": 0.6599849462509155, "camel_30888": 0.6600313186645508, "aqua_rat_64709": 0.6600821614265442, "camel_30749": 0.6600852012634277, "camel_47780": 0.6601537466049194, "camel_18664": 0.6603493690490723, "camel_18662": 0.6605014801025391, "camel_30768": 0.6606763601303101, "aqua_rat_17380": 0.6606905460357666, "camel_19743": 0.6607035994529724, "aqua_rat_16643": 0.6608068346977234, "camel_30742": 0.660858690738678, "camel_30731": 0.6610147953033447, "camel_42431": 0.6610575914382935, "camel_18691": 0.6611536741256714, "camel_30743": 0.6613193154335022, "camel_30724": 0.6614161133766174, "camel_30799": 0.6615215539932251, "camel_18675": 0.661561906337738, "camel_18860": 0.6618123650550842, "camel_18693": 0.6621676683425903, "camel_18656": 0.6622361540794373, "camel_30316": 0.6622371077537537, "camel_30764": 0.6623641848564148, "camel_28260": 0.6625180840492249, "math_train_geometry_671": 0.6625593900680542, "camel_30197": 0.6626095175743103, "camel_30760": 0.6626303791999817, "camel_18687": 0.662781834602356, "camel_28301": 0.66292405128479, "camel_30248": 0.6629488468170166, "camel_49722": 0.6632028222084045, "camel_30206": 0.6633367538452148, "camel_19249": 0.6637811660766602, "camel_19716": 0.6639580726623535, "camel_30874": 0.6639737486839294, "camel_30761": 0.664145827293396, "camel_30744": 0.6641609072685242, "camel_19722": 0.6643242239952087, "camel_30783": 0.664325475692749, "camel_19768": 0.6649587750434875, "camel_19915": 0.6654025912284851, "camel_18208": 0.6663420796394348, "camel_30211": 0.6666349768638611, "camel_28292": 0.6666886806488037, "camel_28265": 0.6668822169303894, "camel_30274": 0.6671191453933716, "camel_30208": 0.6673339605331421, "camel_30194": 0.6674150228500366, "camel_30233": 0.6675312519073486, "camel_19723": 0.6681615710258484, "camel_18854": 0.6684073805809021, "camel_30167": 0.6685333847999573, "camel_47814": 0.6686744689941406, "math_test_geometry_772": 0.668682336807251, "camel_30212": 0.6688569784164429, "camel_18069": 0.668877363204956, "camel_30776": 0.6695044040679932, "camel_19248": 0.6699564456939697, "camel_30727": 0.6702288389205933, "camel_30183": 0.6702417135238647, "camel_30798": 0.6702561378479004, "camel_18710": 0.6702709197998047, "camel_28294": 0.6702733039855957, "camel_30794": 0.6705906391143799, "camel_30789": 0.6707292795181274, "camel_30769": 0.6707736849784851, "aqua_rat_62772": 0.6715332865715027, "camel_30219": 0.6716002821922302, "camel_18936": 0.6717457175254822, "camel_18678": 0.6719581484794617, "camel_18851": 0.6722623109817505, "aqua_rat_5243": 0.6724928021430969, "camel_30247": 0.6725829839706421, "camel_30232": 0.6728556752204895, "camel_18390": 0.6729311943054199, "camel_28282": 0.6733850240707397, "camel_18705": 0.6734911203384399, "camel_30741": 0.6736164689064026, "camel_30754": 0.6739501357078552, "camel_28269": 0.674272894859314, "camel_31985": 0.674626886844635, "camel_19701": 0.6746359467506409, "camel_30271": 0.6748095750808716, "camel_18869": 0.6748166084289551, "camel_31459": 0.6756165027618408, "TheoremQA_jianyu_xu/pigeonhole_2.json": 0.6760613322257996, "aqua_rat_18443": 0.6765811443328857, "camel_28273": 0.676784336566925, "camel_30725": 0.6771367788314819, "camel_18862": 0.6771695017814636, "camel_18703": 0.6773712635040283, "camel_18277": 0.6775964498519897, "aqua_rat_45831": 0.6777982115745544, "camel_18333": 0.6779928207397461, "camel_18366": 0.6781259775161743, "camel_46128": 0.6785297989845276, "camel_19946": 0.6795014142990112, "TheoremQA_xinyi/convex_hull.json": 0.6810086369514465, "camel_18362": 0.6813639998435974, "camel_30753": 0.6821364760398865, "camel_18706": 0.6823464035987854, "camel_19685": 0.6831982731819153, "camel_30791": 0.6832062005996704, "camel_30260": 0.6840065121650696, "camel_30746": 0.6844965219497681, "camel_43268": 0.6847347617149353, "camel_28249": 0.6855511665344238, "aqua_rat_11272": 0.6866250038146973, "camel_30231": 0.6869140863418579, "camel_18680": 0.6876678466796875, "camel_30795": 0.6878648400306702, "camel_30216": 0.6879917979240417, "camel_30161": 0.6889142394065857, "camel_30767": 0.6889910697937012, "camel_19825": 0.6896611452102661, "camel_30782": 0.6904370784759521, "camel_30750": 0.6905307173728943, "camel_30169": 0.6905797123908997, "camel_30720": 0.6916601061820984, "camel_30728": 0.6920735239982605, "camel_18355": 0.6948325634002686, "aqua_rat_78573": 0.6974560618400574, "camel_30796": 0.6980965733528137, "camel_18711": 0.6983726620674133, "camel_30318": 0.6987711787223816, "camel_30217": 0.7016904354095459, "camel_30259": 0.7017943263053894, "camel_30740": 0.7022379636764526, "camel_28310": 0.7034931182861328, "camel_28290": 0.7038943767547607, "camel_18360": 0.7064112424850464, "camel_30292": 0.7068278789520264, "camel_30304": 0.706829845905304, "camel_30225": 0.7081975340843201, "aqua_rat_68089": 0.7085323333740234, "camel_18399": 0.7120991349220276, "camel_18377": 0.7136179208755493, "camel_30224": 0.7214162945747375, "aqua_rat_16864": 0.7226021885871887, "camel_18383": 0.7390897870063782, "camel_18380": 0.7551020383834839}, "TheoremQA_tonyxia/maxplanar3.json": {"camel_22625": 0, "camel_22818": 0, "camel_22846": 0, "camel_22471": 0, "camel_22407": 0, "camel_23192": 0, "camel_22869": 0, "camel_22456": 0, "camel_23126": 0, "camel_21107": 0, "camel_23840": 0, "camel_22829": 0, "camel_22817": 0, "camel_22589": 0, "camel_22438": 0, "camel_22815": 0, "camel_21787": 0, "camel_22586": 0, "camel_23141": 0, "camel_21044": 0, "camel_22472": 0, "camel_22453": 0, "camel_23431": 0, "camel_22868": 0, "camel_22821": 0, "camel_21100": 0, "camel_22807": 0, "camel_22605": 0, "camel_23190": 0, "camel_22403": 0, "camel_23342": 0, "camel_22827": 0, "camel_22583": 0, "camel_22423": 0, "camel_22626": 0, "camel_23176": 0, "TheoremQA_tonyxia/maxplanar3.json": 0, "camel_23127": 0, "camel_22611": 0, "camel_22561": 0, "camel_23386": 0, "camel_23372": 0, "camel_23124": 0, "camel_22425": 0, "camel_22814": 0, "camel_23125": 0, "camel_23182": 0, "camel_22404": 0, "camel_22844": 0, "camel_23177": 0, "camel_22609": 0, "camel_22565": 0, "camel_22865": 0, "camel_23138": 0, "camel_22334": 0, "camel_22572": 0, "camel_22417": 0, "camel_22847": 0, "camel_22444": 0, "camel_22452": 0, "camel_23161": 0, "camel_23394": 0, "camel_23934": 0, "camel_22400": 0, "camel_22802": 0, "camel_23377": 0, "camel_22458": 0, "camel_23409": 0, "camel_22861": 0, "camel_23376": 0, "camel_22615": 0, "camel_22442": 0, "camel_22448": 0, "camel_22622": 0, "camel_23371": 0, "camel_23402": 0, "camel_22441": 0, "camel_23410": 0, "camel_22878": 0, "camel_21057": 0, "camel_22834": 0, "camel_23179": 0, "camel_23198": 0, "camel_22820": 0, "camel_22617": 0, "camel_23188": 0, "camel_23150": 0, "camel_23364": 0, "camel_23164": 0, "camel_22875": 0, "camel_22863": 0, "camel_23172": 0, "camel_21795": 0, "camel_22580": 0, "camel_23131": 0, "camel_22809": 0, "camel_22825": 0, "camel_22445": 0, "camel_22811": 0, "camel_22433": 0, "camel_23158": 0, "camel_22443": 0, "camel_22852": 0, "camel_22843": 0, "camel_22584": 0, "camel_23363": 0, "camel_23157": 0, "camel_22808": 0, "camel_23393": 0, "camel_22849": 0, "camel_22447": 0, "camel_22837": 0, "camel_22859": 0, "camel_22857": 0, "camel_23871": 0, "camel_22853": 0, "camel_23174": 0, "camel_22801": 0, "camel_23144": 0, "camel_22574": 0, "camel_23196": 0, "camel_22873": 0, "camel_22478": 0, "camel_22805": 0, "camel_22858": 0, "camel_23189": 0, "camel_21113": 0, "camel_23423": 0, "camel_23424": 0, "camel_23167": 0, "camel_22422": 0, "camel_22157": 0, "camel_23165": 0, "camel_22573": 0, "camel_22466": 0, "camel_23181": 0, "camel_21083": 0, "camel_22813": 0, "camel_22606": 0, "camel_22862": 0, "camel_22600": 0, "camel_22850": 0, "camel_22608": 0, "camel_22879": 0, "camel_23404": 0, "camel_22579": 0, "camel_22599": 0, "camel_22575": 0, "camel_22588": 0, "camel_22866": 0, "camel_22387": 0, "camel_23873": 0, "camel_23151": 0, "camel_22870": 0, "camel_22424": 0, "camel_22835": 0, "camel_23379": 0, "camel_23159": 0, "camel_23430": 0, "camel_22328": 0, "camel_22845": 0, "camel_22823": 0, "camel_21098": 0, "camel_23135": 0, "camel_23191": 0, "camel_22812": 0, "camel_23382": 0, "camel_23378": 0, "camel_22838": 0, "camel_22839": 0, "camel_23391": 0, "camel_21830": 0, "camel_23392": 0, "camel_22836": 0, "camel_22871": 0, "camel_22872": 0, "camel_22867": 0, "camel_22810": 0, "camel_22824": 0, "camel_22864": 0, "camel_23432": 0, "camel_22628": 0, "camel_22585": 0, "camel_23193": 0, "aqua_rat_54929": 0.7299044132232666, "camel_19249": 0.7308045625686646, "aqua_rat_28685": 0.7315683960914612, "camel_18680": 0.7339682579040527, "TheoremQA_tonyxia/maxplanar1.json": 0.7346516251564026, "camel_19812": 0.7379075288772583, "aqua_rat_44831": 0.7382094860076904, "camel_18699": 0.7430236339569092, "camel_18664": 0.7431133985519409, "aqua_rat_76009": 0.7444446682929993, "camel_18660": 0.7481210827827454, "aqua_rat_70645": 0.7493265867233276, "camel_18365": 0.7512810230255127, "aqua_rat_40504": 0.754666268825531, "aqua_rat_25794": 0.7547464966773987, "camel_19825": 0.764823317527771}, "TheoremQA_wenhuchen/series_convergen3.json": {"TheoremQA_wenhuchen/series_convergen3.json": 0, "camel_49110": 0.6047934889793396, "camel_20773": 0.6048324108123779, "camel_42289": 0.6048631072044373, "aqua_rat_47013": 0.6048949360847473, "aqua_rat_62262": 0.6051242351531982, "camel_28712": 0.6051316857337952, "camel_42341": 0.6051704287528992, "camel_37531": 0.6052976250648499, "camel_31969": 0.6053177714347839, "camel_37582": 0.6053788661956787, "camel_30948": 0.6054680943489075, "aqua_rat_50511": 0.6056062579154968, "camel_42269": 0.605904221534729, "aqua_rat_30979": 0.6062340140342712, "camel_30754": 0.6062900424003601, "aqua_rat_13532": 0.6063020825386047, "camel_20528": 0.6063573360443115, "aqua_rat_40916": 0.6063633561134338, "aqua_rat_47520": 0.6064077019691467, "camel_49105": 0.606523334980011, "aqua_rat_18545": 0.606651782989502, "aqua_rat_68877": 0.606791615486145, "aqua_rat_39048": 0.6072311401367188, "aqua_rat_5226": 0.6073693037033081, "camel_31066": 0.6073752045631409, "camel_37488": 0.6075865626335144, "camel_42871": 0.6078286170959473, "aqua_rat_78757": 0.6079127788543701, "aqua_rat_23857": 0.6080341935157776, "camel_44141": 0.6080942153930664, "aqua_rat_88648": 0.6081483960151672, "camel_30858": 0.6082533001899719, "camel_20717": 0.6084409952163696, "aqua_rat_57169": 0.6087000370025635, "aqua_rat_52920": 0.6087156534194946, "aqua_rat_52681": 0.6088510155677795, "camel_30342": 0.6089203953742981, "camel_31702": 0.6089439392089844, "aqua_rat_8379": 0.6093294024467468, "camel_20645": 0.60941481590271, "camel_37546": 0.6094799041748047, "aqua_rat_12020": 0.6095564961433411, "aqua_rat_57827": 0.6095631122589111, "aqua_rat_30022": 0.6098812818527222, "camel_42306": 0.610126256942749, "camel_31938": 0.6101789474487305, "aqua_rat_46276": 0.610183596611023, "camel_42271": 0.610296368598938, "camel_31584": 0.6105316281318665, "camel_42302": 0.6105729937553406, "camel_30765": 0.6105992197990417, "TheoremQA_wenhuchen/taylor_expansion2.json": 0.610838770866394, "aqua_rat_51974": 0.6108638644218445, "aqua_rat_73094": 0.6110358834266663, "math_train_algebra_457": 0.6110913157463074, "camel_30338": 0.6111953258514404, "camel_42536": 0.6115102767944336, "aqua_rat_20385": 0.6115795969963074, "aqua_rat_35123": 0.6118239164352417, "aqua_rat_60777": 0.6118853688240051, "camel_37583": 0.6119722127914429, "camel_42375": 0.6119897961616516, "camel_30740": 0.6120108366012573, "camel_30136": 0.6121278405189514, "camel_31947": 0.6124410033226013, "aqua_rat_1271": 0.6127758026123047, "aqua_rat_35538": 0.6128515601158142, "TheoremQA_elainewan/math_calculus_2_4.json": 0.6130111217498779, "camel_21967": 0.6132591366767883, "math_test_algebra_2477": 0.6132680773735046, "aqua_rat_19055": 0.6134324669837952, "camel_20641": 0.6136676669120789, "camel_42777": 0.6137306690216064, "camel_42244": 0.6138230562210083, "camel_49079": 0.6142132878303528, "camel_30345": 0.6144210696220398, "camel_42633": 0.6144405603408813, "math_train_algebra_1292": 0.6145886182785034, "camel_36477": 0.6145997047424316, "aqua_rat_67821": 0.614647388458252, "camel_36444": 0.614686131477356, "aqua_rat_260": 0.6150961518287659, "aqua_rat_3767": 0.6154206395149231, "camel_42882": 0.615553617477417, "camel_30440": 0.615554690361023, "camel_42844": 0.615598738193512, "camel_18917": 0.6156632900238037, "camel_30685": 0.6160091757774353, "camel_30680": 0.6160235404968262, "camel_31056": 0.6166769862174988, "camel_18096": 0.6168349981307983, "camel_31984": 0.6173102855682373, "camel_37559": 0.6173701286315918, "aqua_rat_7480": 0.6177165508270264, "camel_31089": 0.6177240014076233, "aqua_rat_54656": 0.6177536249160767, "camel_30409": 0.618269681930542, "camel_17379": 0.6188761591911316, "camel_42619": 0.6189160346984863, "camel_30341": 0.6189485788345337, "camel_31973": 0.6190266013145447, "aqua_rat_52544": 0.619239866733551, "camel_42762": 0.6193239092826843, "aqua_rat_19560": 0.6196091175079346, "camel_31505": 0.6196597218513489, "aqua_rat_9679": 0.6198948621749878, "camel_30392": 0.6200289130210876, "camel_37619": 0.6203563213348389, "aqua_rat_2902": 0.6204559803009033, "aqua_rat_9734": 0.6214760541915894, "camel_42249": 0.6216591596603394, "camel_31858": 0.6217525005340576, "camel_42668": 0.6219362616539001, "camel_30354": 0.6219930648803711, "aqua_rat_8747": 0.6224454045295715, "math_test_prealgebra_754": 0.6226165294647217, "aqua_rat_59407": 0.6228877305984497, "aqua_rat_6261": 0.6229596734046936, "camel_30797": 0.6239370703697205, "camel_30889": 0.625055193901062, "camel_31869": 0.6253958940505981, "camel_30759": 0.6254326701164246, "TheoremQA_wenhuchen/L'H\u00f4pital_rule1.json": 0.6254361867904663, "camel_20774": 0.6265281438827515, "camel_37502": 0.6266013383865356, "camel_31863": 0.6269065141677856, "camel_42672": 0.6270110607147217, "camel_42063": 0.6276944279670715, "camel_31452": 0.6279541850090027, "camel_37515": 0.6284549832344055, "camel_43304": 0.6287397742271423, "TheoremQA_elainewan/math_calculus_2_10.json": 0.6297500729560852, "aqua_rat_31892": 0.6299355626106262, "aqua_rat_35341": 0.629961371421814, "aqua_rat_53870": 0.6300832033157349, "camel_44100": 0.6302759647369385, "aqua_rat_50166": 0.6305627226829529, "camel_31444": 0.6311347484588623, "aqua_rat_64676": 0.6316421031951904, "camel_37590": 0.6316899061203003, "camel_30887": 0.6329200863838196, "camel_42497": 0.6330472826957703, "aqua_rat_83193": 0.6331097483634949, "camel_42613": 0.6333222389221191, "camel_42645": 0.6341221332550049, "camel_42778": 0.6342563033103943, "camel_42616": 0.6344015002250671, "camel_30770": 0.634718120098114, "TheoremQA_mingyin/borel-cantelli-lemma1.json": 0.634815514087677, "camel_37514": 0.6349805593490601, "camel_42623": 0.6349968910217285, "camel_44106": 0.6350910067558289, "TheoremQA_wenhuchen/infinite_series_sum2.json": 0.6353376507759094, "math_train_number_theory_7060": 0.6356078386306763, "camel_42258": 0.6357679963111877, "aqua_rat_53748": 0.635844886302948, "camel_20433": 0.6361218690872192, "camel_42711": 0.6368504762649536, "math_test_algebra_1184": 0.6374443173408508, "camel_18301": 0.6376984119415283, "camel_31987": 0.638034462928772, "TheoremQA_mingyin/Limit-of-sequence3.json": 0.6381702423095703, "camel_42676": 0.6383854150772095, "camel_42678": 0.6390443444252014, "aqua_rat_55051": 0.6413283348083496, "camel_30372": 0.6425556540489197, "camel_31057": 0.6426566243171692, "aqua_rat_61662": 0.6464007496833801, "camel_31084": 0.646403431892395, "aqua_rat_67612": 0.6487756967544556, "TheoremQA_xueguangma/maclaurin_series.json": 0.6493189334869385, "aqua_rat_59305": 0.6496965885162354, "camel_30374": 0.6502904295921326, "aqua_rat_82861": 0.6505313515663147, "aqua_rat_73910": 0.6507599949836731, "camel_44121": 0.6513808965682983, "aqua_rat_36268": 0.6523274183273315, "TheoremQA_wenhuchen/series_convergen2.json": 0.6526089310646057, "camel_30050": 0.6526341438293457, "aqua_rat_44150": 0.652934730052948, "camel_31061": 0.6532126069068909, "camel_42618": 0.6552596688270569, "camel_49109": 0.6559118032455444, "aqua_rat_13223": 0.6565947532653809, "camel_31880": 0.6579943299293518, "camel_42591": 0.6582330465316772, "camel_30202": 0.659107506275177, "aqua_rat_48885": 0.6600656509399414, "aqua_rat_69318": 0.660254180431366, "TheoremQA_mingyin/Limit-of-sequence2.json": 0.6632405519485474, "TheoremQA_wenhuchen/series_convergen1.json": 0.6654741168022156, "camel_28309": 0.6655054688453674, "aqua_rat_16186": 0.6657617092132568, "camel_31759": 0.6664900183677673, "aqua_rat_69628": 0.668904185295105, "camel_49051": 0.6717780828475952, "camel_42013": 0.676160991191864, "aqua_rat_59396": 0.6886792182922363, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus2.json": 0.7128912806510925}, "TheoremQA_jianyu_xu/Binomial_1.json": {"camel_20514": 0, "camel_21572": 0, "camel_20998": 0, "camel_20853": 0, "camel_21255": 0, "camel_21808": 0, "camel_21521": 0, "camel_20246": 0, "camel_20570": 0, "camel_20293": 0, "camel_21413": 0, "camel_20611": 0, "camel_20802": 0, "camel_20915": 0, "camel_20984": 0, "camel_21563": 0, "camel_20269": 0, "camel_20931": 0, "camel_20996": 0, "camel_21529": 0, "camel_20272": 0, "camel_20874": 0, "camel_20312": 0, "camel_20948": 0, "camel_20656": 0, "camel_20336": 0, "camel_20442": 0, "camel_21586": 0, "camel_20930": 0, "camel_20302": 0, "aqua_rat_39562": 0.7997372150421143, "aqua_rat_27948": 0.7997776865959167, "aqua_rat_575": 0.8000369668006897, "aqua_rat_37532": 0.8001588582992554, "aqua_rat_9713": 0.800359845161438, "aqua_rat_3235": 0.8006883263587952, "aqua_rat_29513": 0.8011059165000916, "aqua_rat_56939": 0.8011568188667297, "aqua_rat_62787": 0.8011937141418457, "aqua_rat_41506": 0.801300048828125, "aqua_rat_78953": 0.8014321327209473, "aqua_rat_83919": 0.8015034794807434, "aqua_rat_87775": 0.8017048239707947, "aqua_rat_78061": 0.801979124546051, "math_train_counting_and_probability_961": 0.8020489811897278, "aqua_rat_14195": 0.8020824790000916, "aqua_rat_27685": 0.802229642868042, "aqua_rat_14884": 0.8023485541343689, "aqua_rat_20142": 0.8023748397827148, "aqua_rat_42746": 0.802452564239502, "aqua_rat_58309": 0.8026465773582458, "aqua_rat_46685": 0.8032750487327576, "aqua_rat_16863": 0.8033663630485535, "aqua_rat_18901": 0.803536593914032, "aqua_rat_29732": 0.803757905960083, "aqua_rat_2193": 0.8039250373840332, "aqua_rat_82511": 0.804194450378418, "aqua_rat_13853": 0.8043076992034912, "aqua_rat_47989": 0.8044674396514893, "aqua_rat_34245": 0.8046162128448486, "aqua_rat_79193": 0.8046208024024963, "aqua_rat_7495": 0.8048836588859558, "aqua_rat_50043": 0.8050170540809631, "aqua_rat_811": 0.8050965666770935, "aqua_rat_42333": 0.8051052689552307, "aqua_rat_55206": 0.8051781058311462, "aqua_rat_80242": 0.8053046464920044, "aqua_rat_13609": 0.8058372139930725, "aqua_rat_79170": 0.8058483600616455, "aqua_rat_45168": 0.8058558702468872, "aqua_rat_15548": 0.8059218525886536, "aqua_rat_30648": 0.8062130212783813, "aqua_rat_48666": 0.8062383532524109, "aqua_rat_39411": 0.8064196705818176, "aqua_rat_60755": 0.8064454197883606, "aqua_rat_37185": 0.8065115213394165, "aqua_rat_73150": 0.8070876598358154, "aqua_rat_58044": 0.8071916699409485, "aqua_rat_41270": 0.8072232007980347, "aqua_rat_69384": 0.8075751066207886, "aqua_rat_64653": 0.8076474070549011, "math_train_counting_and_probability_122": 0.8077825903892517, "aqua_rat_32866": 0.8078601360321045, "aqua_rat_71071": 0.8080874681472778, "aqua_rat_50541": 0.808181881904602, "aqua_rat_44716": 0.8082619309425354, "aqua_rat_8468": 0.8086141347885132, "aqua_rat_84736": 0.8091405630111694, "aqua_rat_63012": 0.8098668456077576, "aqua_rat_76349": 0.8103756904602051, "aqua_rat_57049": 0.810599148273468, "aqua_rat_12398": 0.8107078671455383, "math_test_counting_and_probability_666": 0.8109777569770813, "aqua_rat_41621": 0.8110160827636719, "aqua_rat_30122": 0.8110921382904053, "aqua_rat_85599": 0.8115636110305786, "aqua_rat_20722": 0.8116806745529175, "aqua_rat_48676": 0.8117433786392212, "aqua_rat_53852": 0.8119867444038391, "aqua_rat_9536": 0.8120893239974976, "aqua_rat_73181": 0.8126705884933472, "camel_38493": 0.8126969337463379, "aqua_rat_73601": 0.813179612159729, "aqua_rat_81265": 0.8131874203681946, "math_train_counting_and_probability_373": 0.8131884932518005, "math_train_counting_and_probability_249": 0.8136123418807983, "aqua_rat_50942": 0.81388920545578, "aqua_rat_9693": 0.8139735460281372, "aqua_rat_41430": 0.8143635988235474, "aqua_rat_13243": 0.8149157166481018, "aqua_rat_42155": 0.8152071833610535, "math_test_counting_and_probability_776": 0.8154394030570984, "aqua_rat_49386": 0.815710723400116, "aqua_rat_72310": 0.8159345388412476, "aqua_rat_33613": 0.8161824941635132, "aqua_rat_34242": 0.8162630796432495, "aqua_rat_50830": 0.8165950775146484, "aqua_rat_57693": 0.8167141079902649, "aqua_rat_74695": 0.8170826435089111, "aqua_rat_19534": 0.8172923922538757, "aqua_rat_18452": 0.8180205225944519, "aqua_rat_42177": 0.8181946277618408, "aqua_rat_64894": 0.8182525634765625, "aqua_rat_35044": 0.81847083568573, "aqua_rat_19040": 0.818602442741394, "aqua_rat_81997": 0.8188735842704773, "aqua_rat_65642": 0.8188756108283997, "aqua_rat_80017": 0.8189201354980469, "aqua_rat_31467": 0.8189284205436707, "aqua_rat_18760": 0.8193821907043457, "aqua_rat_7156": 0.8194493055343628, "aqua_rat_75767": 0.8194917440414429, "aqua_rat_31360": 0.8196859359741211, "aqua_rat_40812": 0.8197494745254517, "aqua_rat_68198": 0.8197889924049377, "aqua_rat_69481": 0.8199477791786194, "aqua_rat_57246": 0.8202519416809082, "aqua_rat_72437": 0.8207914233207703, "camel_38505": 0.8208784461021423, "aqua_rat_60522": 0.821171224117279, "aqua_rat_26005": 0.8214079141616821, "aqua_rat_62645": 0.8217906355857849, "aqua_rat_62500": 0.8218079805374146, "aqua_rat_779": 0.822265625, "aqua_rat_67500": 0.822331428527832, "aqua_rat_49270": 0.8224267959594727, "aqua_rat_31872": 0.822864830493927, "aqua_rat_59675": 0.823176920413971, "aqua_rat_31768": 0.823215901851654, "aqua_rat_28183": 0.8232852816581726, "aqua_rat_63254": 0.823406457901001, "aqua_rat_75780": 0.8234618902206421, "aqua_rat_24963": 0.8237612843513489, "aqua_rat_78074": 0.8238561749458313, "aqua_rat_70526": 0.8238571286201477, "aqua_rat_78895": 0.8239057064056396, "aqua_rat_40137": 0.8240645527839661, "aqua_rat_35292": 0.824133574962616, "aqua_rat_88418": 0.824331521987915, "aqua_rat_47506": 0.8246296048164368, "math_test_counting_and_probability_216": 0.8247366547584534, "aqua_rat_47740": 0.8250163197517395, "aqua_rat_80108": 0.8250371813774109, "aqua_rat_10235": 0.825522780418396, "aqua_rat_52756": 0.8257132768630981, "aqua_rat_10993": 0.8257675170898438, "aqua_rat_7409": 0.8258528113365173, "aqua_rat_81548": 0.8262277245521545, "aqua_rat_23582": 0.8267654180526733, "aqua_rat_51384": 0.826997697353363, "aqua_rat_28538": 0.8271455764770508, "aqua_rat_37301": 0.8272275924682617, "aqua_rat_72660": 0.8278632760047913, "aqua_rat_86831": 0.8279398083686829, "aqua_rat_60892": 0.8284971117973328, "aqua_rat_8673": 0.8285518884658813, "aqua_rat_67179": 0.8287495374679565, "aqua_rat_55590": 0.8292290568351746, "aqua_rat_70861": 0.8294826745986938, "aqua_rat_13918": 0.8295046091079712, "aqua_rat_37223": 0.8297004103660583, "aqua_rat_89302": 0.8297159075737, "aqua_rat_72708": 0.8299014568328857, "aqua_rat_44130": 0.8300438523292542, "aqua_rat_33533": 0.8303347229957581, "aqua_rat_27914": 0.8306148052215576, "aqua_rat_83206": 0.830644965171814, "aqua_rat_42445": 0.8318455219268799, "aqua_rat_74651": 0.8326739072799683, "aqua_rat_15917": 0.8331175446510315, "aqua_rat_74248": 0.8332782983779907, "camel_38541": 0.8352534770965576, "aqua_rat_35395": 0.8355194330215454, "aqua_rat_58323": 0.8361160755157471, "aqua_rat_23041": 0.837986946105957, "aqua_rat_30109": 0.8397494554519653, "aqua_rat_53149": 0.8409299254417419, "aqua_rat_51723": 0.8409605026245117, "aqua_rat_35517": 0.8412332534790039, "aqua_rat_84398": 0.8452774286270142}, "TheoremQA_xueguangma/forward_rate_1.json": {"aqua_rat_21866": 0.7043895721435547, "aqua_rat_75610": 0.7044579386711121, "aqua_rat_10455": 0.7045541405677795, "aqua_rat_56852": 0.7046481966972351, "aqua_rat_32789": 0.7047179341316223, "aqua_rat_19004": 0.7048792243003845, "aqua_rat_26339": 0.7051605582237244, "aqua_rat_60424": 0.7053613662719727, "gsm_rft_25658": 0.705392599105835, "gsm_rft_24617": 0.7058789134025574, "aqua_rat_87017": 0.7058806419372559, "aqua_rat_41325": 0.7059387564659119, "math_train_algebra_369": 0.7061647176742554, "aqua_rat_53504": 0.7061861157417297, "aqua_rat_47059": 0.7064931988716125, "aqua_rat_58736": 0.7065181136131287, "aqua_rat_32851": 0.7066433429718018, "aqua_rat_11614": 0.7067930698394775, "aqua_rat_28282": 0.7070346474647522, "aqua_rat_79979": 0.7074624300003052, "aqua_rat_11610": 0.707673966884613, "aqua_rat_3536": 0.7077184319496155, "aqua_rat_735": 0.7078529596328735, "aqua_rat_52978": 0.7079119086265564, "aqua_rat_77602": 0.7079598903656006, "aqua_rat_30699": 0.7081355452537537, "aqua_rat_79047": 0.7082563638687134, "aqua_rat_24840": 0.7083824872970581, "aqua_rat_25723": 0.7084723114967346, "aqua_rat_33548": 0.708952784538269, "aqua_rat_86761": 0.7090545296669006, "aqua_rat_5308": 0.7094506025314331, "aqua_rat_40411": 0.7097787857055664, "aqua_rat_28150": 0.7100210785865784, "aqua_rat_59829": 0.7100419998168945, "aqua_rat_60181": 0.7100822925567627, "aqua_rat_59098": 0.7103546261787415, "aqua_rat_84309": 0.7104223370552063, "aqua_rat_44254": 0.7104615569114685, "aqua_rat_50660": 0.7105100154876709, "aqua_rat_48279": 0.7106433510780334, "aqua_rat_44191": 0.7106782793998718, "aqua_rat_255": 0.7106871604919434, "aqua_rat_33923": 0.7109066247940063, "aqua_rat_37258": 0.7114034295082092, "aqua_rat_84357": 0.7116328477859497, "aqua_rat_34698": 0.7116652727127075, "aqua_rat_87885": 0.7116721272468567, "aqua_rat_87904": 0.7116929888725281, "aqua_rat_64976": 0.7117880582809448, "aqua_rat_67841": 0.7119483947753906, "aqua_rat_4137": 0.7120122313499451, "aqua_rat_3275": 0.7121753692626953, "math_test_algebra_608": 0.7123354077339172, "aqua_rat_75833": 0.7125113010406494, "math_train_algebra_957": 0.7125240564346313, "aqua_rat_69273": 0.712550699710846, "aqua_rat_32891": 0.7125935554504395, "aqua_rat_10990": 0.7128135561943054, "aqua_rat_46898": 0.7130885124206543, "aqua_rat_66371": 0.7132148742675781, "aqua_rat_55010": 0.7132253646850586, "aqua_rat_26425": 0.7135738134384155, "aqua_rat_64125": 0.7140312790870667, "aqua_rat_43060": 0.7141150832176208, "aqua_rat_68014": 0.714269757270813, "aqua_rat_27039": 0.7144107818603516, "aqua_rat_21326": 0.7154330015182495, "aqua_rat_15471": 0.7156943082809448, "aqua_rat_28883": 0.7157573699951172, "aqua_rat_21250": 0.7159057259559631, "aqua_rat_1549": 0.7160041928291321, "aqua_rat_46158": 0.7163220047950745, "aqua_rat_71239": 0.7165229916572571, "aqua_rat_56548": 0.7167331576347351, "aqua_rat_73390": 0.7168923020362854, "aqua_rat_47773": 0.7169379591941833, "aqua_rat_87246": 0.7170525193214417, "aqua_rat_12533": 0.7176504731178284, "aqua_rat_88960": 0.7178787589073181, "aqua_rat_29134": 0.7178894281387329, "aqua_rat_57761": 0.718284547328949, "aqua_rat_29976": 0.7183122634887695, "aqua_rat_87884": 0.7187110781669617, "aqua_rat_16448": 0.7189539074897766, "aqua_rat_83740": 0.7190034985542297, "aqua_rat_45609": 0.7192452549934387, "aqua_rat_11824": 0.7193223834037781, "aqua_rat_64914": 0.7195262312889099, "aqua_rat_59892": 0.7198810577392578, "aqua_rat_86835": 0.7200403809547424, "aqua_rat_62727": 0.7200757265090942, "aqua_rat_32350": 0.7208860516548157, "aqua_rat_34082": 0.7214829325675964, "gsm_rft_10656": 0.7217369675636292, "aqua_rat_64215": 0.7217851877212524, "aqua_rat_66298": 0.7218061685562134, "aqua_rat_59": 0.7219709753990173, "aqua_rat_10686": 0.7222656607627869, "aqua_rat_869": 0.7222869396209717, "aqua_rat_68": 0.7224738597869873, "aqua_rat_51332": 0.7227024435997009, "aqua_rat_70690": 0.7228850722312927, "gsm_rft_7115": 0.7230416536331177, "gsm_train_9412": 0.7230416536331177, "aqua_rat_34159": 0.723209798336029, "aqua_rat_14728": 0.7232258319854736, "aqua_rat_69905": 0.7232877016067505, "aqua_rat_9965": 0.7235024571418762, "aqua_rat_20423": 0.7238320708274841, "aqua_rat_87589": 0.7239444255828857, "aqua_rat_10582": 0.7244125008583069, "math_test_algebra_337": 0.7245665192604065, "math_test_algebra_311": 0.7247585654258728, "aqua_rat_3773": 0.7255696654319763, "aqua_rat_21814": 0.7256478071212769, "aqua_rat_7826": 0.7258833646774292, "aqua_rat_39049": 0.726264476776123, "aqua_rat_88504": 0.7266783714294434, "aqua_rat_25162": 0.7267792224884033, "aqua_rat_5641": 0.7269262671470642, "aqua_rat_83656": 0.7272595763206482, "aqua_rat_65963": 0.7284718751907349, "aqua_rat_38068": 0.7285057902336121, "aqua_rat_76872": 0.7289175987243652, "aqua_rat_16693": 0.7291091084480286, "aqua_rat_54028": 0.729404866695404, "aqua_rat_68636": 0.7294543981552124, "aqua_rat_46552": 0.7298001050949097, "aqua_rat_42515": 0.7298012375831604, "aqua_rat_63322": 0.7301403880119324, "aqua_rat_37916": 0.7309738397598267, "aqua_rat_79904": 0.7311068177223206, "aqua_rat_33430": 0.7313637733459473, "gsm_rft_24137": 0.7313678860664368, "aqua_rat_63070": 0.7315237522125244, "aqua_rat_7674": 0.7317066192626953, "aqua_rat_14876": 0.7319818735122681, "aqua_rat_12597": 0.73232102394104, "aqua_rat_78121": 0.7323928475379944, "aqua_rat_20488": 0.7325149178504944, "aqua_rat_42017": 0.7337721586227417, "aqua_rat_60321": 0.7338286638259888, "aqua_rat_62174": 0.733963668346405, "aqua_rat_62528": 0.734818696975708, "aqua_rat_67076": 0.734972357749939, "aqua_rat_72794": 0.7354617118835449, "aqua_rat_7357": 0.7360184192657471, "aqua_rat_32852": 0.7361785769462585, "aqua_rat_54664": 0.7368021011352539, "aqua_rat_30386": 0.7385773658752441, "aqua_rat_36598": 0.7394343018531799, "aqua_rat_51796": 0.7395018935203552, "aqua_rat_72687": 0.7396700382232666, "aqua_rat_19784": 0.7402943968772888, "aqua_rat_65964": 0.7403059601783752, "aqua_rat_3687": 0.7405113577842712, "aqua_rat_32321": 0.7411236763000488, "aqua_rat_2257": 0.7411884665489197, "aqua_rat_88758": 0.7435347437858582, "math_train_algebra_767": 0.74357008934021, "aqua_rat_51100": 0.7442074418067932, "aqua_rat_11679": 0.74472576379776, "aqua_rat_69547": 0.7453545928001404, "aqua_rat_61400": 0.7454624772071838, "aqua_rat_88003": 0.7457093000411987, "aqua_rat_58298": 0.7466544508934021, "aqua_rat_38900": 0.7468510270118713, "aqua_rat_29356": 0.7469708919525146, "aqua_rat_26976": 0.7473347783088684, "aqua_rat_24052": 0.7475589513778687, "aqua_rat_73739": 0.7476530075073242, "aqua_rat_18368": 0.7481610178947449, "aqua_rat_82669": 0.7483378648757935, "aqua_rat_88415": 0.7489241361618042, "aqua_rat_86517": 0.7499827146530151, "aqua_rat_56718": 0.7500041127204895, "aqua_rat_70031": 0.750961184501648, "aqua_rat_88174": 0.7524980306625366, "aqua_rat_64105": 0.7525273561477661, "aqua_rat_15079": 0.7534665465354919, "math_train_algebra_667": 0.7554671168327332, "aqua_rat_1115": 0.7654121518135071, "aqua_rat_53336": 0.77245032787323, "aqua_rat_6415": 0.7742840051651001, "aqua_rat_57943": 0.7759188413619995, "aqua_rat_17751": 0.7763853669166565, "aqua_rat_69447": 0.7771230936050415, "aqua_rat_75046": 0.7793168425559998, "aqua_rat_42949": 0.7801799178123474, "aqua_rat_75047": 0.781674325466156, "aqua_rat_53568": 0.7820168733596802, "aqua_rat_21626": 0.7856369018554688, "aqua_rat_36461": 0.7863495349884033, "aqua_rat_20758": 0.7864640355110168, "aqua_rat_41963": 0.7885088920593262, "aqua_rat_3885": 0.7895001173019409, "aqua_rat_46315": 0.7907002568244934, "aqua_rat_45867": 0.7908251285552979, "aqua_rat_72737": 0.7938823699951172}, "TheoremQA_jianyu_xu/Binomial_6.json": {"camel_21033": 0, "camel_20611": 0, "camel_20930": 0, "camel_20448": 0, "camel_20931": 0, "camel_20903": 0, "camel_20619": 0, "camel_20915": 0, "camel_21253": 0, "camel_21418": 0, "camel_21419": 0, "camel_21216": 0, "camel_20266": 0, "camel_20312": 0, "camel_21572": 0, "camel_21386": 0, "camel_20407": 0, "camel_20453": 0, "camel_20336": 0, "camel_20718": 0, "camel_20984": 0, "camel_20477": 0, "camel_20656": 0, "camel_21434": 0, "camel_21413": 0, "camel_20853": 0, "camel_20274": 0, "camel_20914": 0, "camel_21563": 0, "camel_21521": 0, "camel_21227": 0, "camel_20708": 0, "camel_21247": 0, "camel_20677": 0, "camel_21034": 0, "camel_20996": 0, "camel_20716": 0, "camel_20973": 0, "camel_21267": 0, "aqua_rat_47506": 0.7800701856613159, "aqua_rat_8404": 0.7800737023353577, "aqua_rat_75780": 0.7801077365875244, "math_test_counting_and_probability_535": 0.7802332639694214, "aqua_rat_46881": 0.7803484797477722, "aqua_rat_86712": 0.7803598642349243, "aqua_rat_18452": 0.7804551124572754, "math_train_counting_and_probability_437": 0.7808699607849121, "aqua_rat_70861": 0.7809499502182007, "aqua_rat_77276": 0.7814004421234131, "camel_37003": 0.7814319133758545, "aqua_rat_9713": 0.7816899418830872, "aqua_rat_25656": 0.781787097454071, "math_train_counting_and_probability_445": 0.7817934155464172, "aqua_rat_83437": 0.781838595867157, "aqua_rat_49270": 0.7821624875068665, "aqua_rat_67709": 0.7823329567909241, "math_train_counting_and_probability_961": 0.7824243307113647, "aqua_rat_55099": 0.7826335430145264, "aqua_rat_15917": 0.7827162146568298, "aqua_rat_18760": 0.7827691435813904, "aqua_rat_18943": 0.782966136932373, "math_train_counting_and_probability_363": 0.7830175757408142, "aqua_rat_82553": 0.7833144664764404, "math_train_counting_and_probability_657": 0.7833656072616577, "aqua_rat_37642": 0.7833926677703857, "aqua_rat_35395": 0.78340083360672, "aqua_rat_35517": 0.7834251523017883, "aqua_rat_30109": 0.7836734652519226, "aqua_rat_50043": 0.7837586998939514, "aqua_rat_71150": 0.7837941646575928, "aqua_rat_35078": 0.7838351130485535, "aqua_rat_72537": 0.7840322852134705, "aqua_rat_23582": 0.7840335965156555, "aqua_rat_16294": 0.784086287021637, "aqua_rat_30648": 0.7845222353935242, "aqua_rat_85599": 0.7850915193557739, "aqua_rat_10164": 0.7851728200912476, "aqua_rat_67179": 0.7853800654411316, "aqua_rat_1152": 0.7854821085929871, "aqua_rat_1946": 0.7857372164726257, "camel_38545": 0.7860328555107117, "aqua_rat_1941": 0.7861024141311646, "aqua_rat_53921": 0.7863613367080688, "aqua_rat_9536": 0.7865525484085083, "aqua_rat_17370": 0.7866091728210449, "aqua_rat_19521": 0.7866198420524597, "aqua_rat_29035": 0.7868064641952515, "aqua_rat_51723": 0.7869998216629028, "aqua_rat_43512": 0.787143886089325, "aqua_rat_82087": 0.7872689962387085, "aqua_rat_29054": 0.7873302102088928, "aqua_rat_78074": 0.7875789999961853, "aqua_rat_55001": 0.7875916361808777, "aqua_rat_13903": 0.7877019643783569, "aqua_rat_41430": 0.787704348564148, "aqua_rat_7035": 0.7878354787826538, "math_train_counting_and_probability_249": 0.7879112362861633, "aqua_rat_62773": 0.7880197167396545, "camel_38539": 0.7881373167037964, "aqua_rat_49784": 0.7883610725402832, "aqua_rat_19369": 0.7885509133338928, "aqua_rat_42177": 0.7886830568313599, "aqua_rat_74901": 0.788854718208313, "aqua_rat_23041": 0.7889015674591064, "math_train_counting_and_probability_234": 0.7889605164527893, "aqua_rat_70434": 0.78914475440979, "aqua_rat_58323": 0.789154589176178, "aqua_rat_43422": 0.7894187569618225, "aqua_rat_38123": 0.7895245552062988, "aqua_rat_52714": 0.7896050810813904, "aqua_rat_49927": 0.7897046804428101, "aqua_rat_40601": 0.7898446917533875, "aqua_rat_78375": 0.7900538444519043, "aqua_rat_60238": 0.7901846766471863, "math_test_counting_and_probability_107": 0.7905154824256897, "aqua_rat_10378": 0.7905673384666443, "aqua_rat_7495": 0.7906779646873474, "aqua_rat_2946": 0.7908053398132324, "aqua_rat_70526": 0.7909332513809204, "aqua_rat_19534": 0.791357696056366, "aqua_rat_54461": 0.7915300726890564, "aqua_rat_43547": 0.7915607690811157, "camel_38493": 0.7915891408920288, "aqua_rat_16166": 0.7916291952133179, "aqua_rat_87465": 0.7916526198387146, "aqua_rat_75194": 0.7917083501815796, "aqua_rat_88095": 0.7917852401733398, "math_test_counting_and_probability_208": 0.7918468713760376, "aqua_rat_20594": 0.7920895218849182, "aqua_rat_29142": 0.7924309372901917, "aqua_rat_13991": 0.79250568151474, "aqua_rat_18356": 0.7925078272819519, "aqua_rat_78895": 0.7927715182304382, "aqua_rat_61876": 0.7932308316230774, "aqua_rat_86025": 0.7935952544212341, "aqua_rat_83206": 0.7936545610427856, "aqua_rat_65642": 0.7938054203987122, "aqua_rat_8673": 0.7941932082176208, "aqua_rat_9013": 0.7954207062721252, "aqua_rat_53622": 0.7954643368721008, "math_train_counting_and_probability_444": 0.7955277562141418, "aqua_rat_71598": 0.7956346869468689, "aqua_rat_36440": 0.7957866787910461, "aqua_rat_17502": 0.7959319949150085, "aqua_rat_31768": 0.7960887551307678, "aqua_rat_53149": 0.7964100241661072, "aqua_rat_15097": 0.7968271374702454, "aqua_rat_47613": 0.796971321105957, "TheoremQA_jianyu_xu/Multinomial_6.json": 0.7973037958145142, "aqua_rat_32683": 0.7976087927818298, "aqua_rat_85220": 0.7977653741836548, "aqua_rat_51656": 0.7978476881980896, "aqua_rat_59675": 0.798424482345581, "aqua_rat_44093": 0.7988126873970032, "aqua_rat_51352": 0.7989126443862915, "math_train_counting_and_probability_59": 0.7995963096618652, "aqua_rat_73732": 0.7998709082603455, "aqua_rat_26196": 0.8014585971832275, "aqua_rat_79204": 0.8018487095832825, "aqua_rat_87868": 0.8022135496139526, "math_train_counting_and_probability_753": 0.8033706545829773, "aqua_rat_42445": 0.8034531474113464, "aqua_rat_52825": 0.8034746646881104, "aqua_rat_56247": 0.804175853729248, "aqua_rat_3235": 0.8041931986808777, "math_train_counting_and_probability_5126": 0.8044516444206238, "aqua_rat_23594": 0.80477374792099, "aqua_rat_1550": 0.8048979043960571, "aqua_rat_78224": 0.8050399422645569, "aqua_rat_42412": 0.8055065274238586, "aqua_rat_74792": 0.805600106716156, "aqua_rat_9476": 0.805777907371521, "aqua_rat_63963": 0.8061904907226562, "aqua_rat_87252": 0.8068343997001648, "aqua_rat_55663": 0.8071203827857971, "aqua_rat_5455": 0.807333767414093, "aqua_rat_77730": 0.807599663734436, "aqua_rat_67694": 0.8084906935691833, "aqua_rat_16474": 0.8101593852043152, "aqua_rat_59556": 0.810711681842804, "aqua_rat_76251": 0.8107665181159973, "aqua_rat_17625": 0.8111459016799927, "aqua_rat_32212": 0.8119847774505615, "aqua_rat_8436": 0.8120872378349304, "aqua_rat_78061": 0.812839150428772, "math_test_counting_and_probability_68": 0.815216064453125, "aqua_rat_62725": 0.8152396082878113, "aqua_rat_42746": 0.8162215352058411, "aqua_rat_56064": 0.8182715773582458, "math_train_counting_and_probability_87": 0.8281065225601196, "math_train_counting_and_probability_429": 0.8309985399246216, "aqua_rat_10346": 0.8318802118301392, "aqua_rat_87690": 0.8325735926628113, "aqua_rat_48812": 0.8328298926353455, "aqua_rat_37852": 0.8329893946647644, "math_test_counting_and_probability_303": 0.8329942226409912, "math_test_counting_and_probability_595": 0.8333021998405457, "aqua_rat_71423": 0.8334688544273376, "math_test_counting_and_probability_389": 0.833803653717041, "math_train_counting_and_probability_246": 0.8620785474777222}, "TheoremQA_elainewan/math_algebra_4_3.json": {"camel_32511": 0, "camel_32510": 0, "TheoremQA_elainewan/math_algebra_4_3.json": 0, "camel_15684": 0.7016881704330444, "camel_21344": 0.7017132043838501, "camel_15674": 0.7017161250114441, "camel_14394": 0.7017354965209961, "camel_15613": 0.7019760608673096, "camel_15852": 0.7020667791366577, "camel_15718": 0.702125072479248, "camel_14731": 0.7021282315254211, "camel_15643": 0.7021798491477966, "camel_14553": 0.7022439241409302, "camel_15295": 0.7023284435272217, "camel_15618": 0.702420711517334, "camel_36893": 0.7024673223495483, "camel_23106": 0.7024877667427063, "camel_27490": 0.7025489807128906, "camel_14523": 0.7025564908981323, "camel_36936": 0.7026367783546448, "camel_26856": 0.7027938365936279, "camel_15630": 0.7028496265411377, "camel_14081": 0.7028723359107971, "camel_15928": 0.7030404210090637, "camel_15925": 0.7031072974205017, "camel_21340": 0.703127920627594, "camel_14905": 0.7032843232154846, "camel_49259": 0.7032904028892517, "camel_27664": 0.7033250331878662, "camel_27669": 0.7033771276473999, "camel_40008": 0.70347660779953, "camel_27480": 0.703479528427124, "camel_15649": 0.7037014961242676, "camel_27479": 0.7038493752479553, "camel_14913": 0.7038548588752747, "camel_27728": 0.7038650512695312, "camel_21280": 0.703946590423584, "camel_14939": 0.7039567828178406, "camel_49842": 0.7040648460388184, "camel_15661": 0.7040811777114868, "camel_27622": 0.7042286992073059, "camel_27601": 0.7044781446456909, "camel_23053": 0.7045205235481262, "camel_27647": 0.7045260667800903, "camel_15911": 0.7047416567802429, "camel_15628": 0.7048735022544861, "camel_26840": 0.7049418687820435, "camel_27446": 0.7049445509910583, "camel_15602": 0.704967737197876, "camel_15682": 0.7050145864486694, "camel_14889": 0.7050257921218872, "camel_14068": 0.7050303220748901, "camel_14932": 0.7051247358322144, "camel_27704": 0.7052589058876038, "camel_15608": 0.7053340077400208, "camel_15720": 0.7053546905517578, "camel_15851": 0.7055546641349792, "camel_15320": 0.7055860161781311, "camel_15697": 0.7057365775108337, "camel_15398": 0.7057953476905823, "camel_36929": 0.7058646082878113, "camel_15709": 0.7059984803199768, "camel_14730": 0.7060024738311768, "camel_15583": 0.7062391042709351, "camel_15625": 0.70624840259552, "camel_15388": 0.7062759399414062, "camel_15621": 0.7063018679618835, "camel_15287": 0.7063552141189575, "camel_15610": 0.706357479095459, "camel_15341": 0.70653235912323, "camel_27617": 0.7068037390708923, "camel_15329": 0.7069687843322754, "camel_15431": 0.7070914506912231, "camel_14039": 0.7072386741638184, "camel_27636": 0.7072595953941345, "camel_21328": 0.7072970271110535, "camel_27730": 0.7073403596878052, "camel_15651": 0.7074415683746338, "camel_15604": 0.7075054049491882, "camel_27018": 0.7076758742332458, "camel_27506": 0.7077738046646118, "camel_14901": 0.7077983617782593, "camel_15642": 0.7078285813331604, "camel_15739": 0.708217203617096, "camel_49885": 0.7089682817459106, "camel_15650": 0.7090162038803101, "camel_15694": 0.7091777920722961, "camel_14385": 0.7093454003334045, "camel_27691": 0.709353506565094, "camel_27695": 0.7097054123878479, "camel_26975": 0.709850549697876, "camel_15336": 0.7101097106933594, "camel_15752": 0.7102454304695129, "camel_27472": 0.7102577090263367, "camel_15748": 0.7103169560432434, "camel_27654": 0.7103343605995178, "camel_15702": 0.7104625105857849, "camel_27651": 0.7109854817390442, "camel_27398": 0.711063027381897, "camel_14556": 0.7111291289329529, "camel_14149": 0.7112386226654053, "camel_27696": 0.711453914642334, "camel_14908": 0.7115380167961121, "camel_15547": 0.7119537591934204, "camel_15657": 0.7122185826301575, "camel_27701": 0.7122303247451782, "camel_27621": 0.7123330235481262, "camel_14898": 0.7128124237060547, "camel_26963": 0.7128788828849792, "camel_49979": 0.7131093740463257, "camel_15582": 0.7134097218513489, "camel_27675": 0.7136528491973877, "camel_49212": 0.7137138247489929, "camel_27637": 0.7137272357940674, "camel_23523": 0.7137694954872131, "aqua_rat_33509": 0.7139427065849304, "camel_15659": 0.7143270373344421, "camel_15631": 0.714425265789032, "camel_37507": 0.7146250009536743, "camel_15727": 0.714792788028717, "camel_14158": 0.714897096157074, "camel_15323": 0.7151364684104919, "camel_15620": 0.7154944539070129, "camel_15734": 0.7155894637107849, "camel_15556": 0.7158247828483582, "camel_27678": 0.7158479690551758, "camel_15716": 0.7161674499511719, "camel_15307": 0.7162832617759705, "camel_21321": 0.7164904475212097, "camel_15721": 0.7166138291358948, "camel_15691": 0.7167291641235352, "camel_21319": 0.7168209552764893, "camel_15756": 0.716974675655365, "camel_27657": 0.7173013091087341, "camel_15394": 0.7176482677459717, "camel_15757": 0.7177376747131348, "camel_27469": 0.7178664207458496, "camel_27658": 0.7179859280586243, "camel_26864": 0.7180394530296326, "camel_27603": 0.7182237505912781, "camel_15759": 0.7182496190071106, "camel_15667": 0.7182570099830627, "camel_15730": 0.7183988094329834, "camel_15745": 0.718438446521759, "camel_15283": 0.7184625267982483, "camel_15707": 0.718740701675415, "camel_26778": 0.7187728881835938, "camel_15679": 0.7193877696990967, "camel_27644": 0.7193893790245056, "camel_15348": 0.7201317548751831, "camel_49959": 0.7202252149581909, "camel_27602": 0.7202517986297607, "camel_15696": 0.7203242182731628, "camel_14912": 0.7206435203552246, "camel_27670": 0.7206965088844299, "camel_15729": 0.7215037941932678, "camel_27656": 0.7216667532920837, "camel_15683": 0.7216755747795105, "camel_15590": 0.7217051982879639, "camel_15360": 0.7218494415283203, "camel_27460": 0.7218857407569885, "camel_27605": 0.7219558954238892, "camel_15619": 0.7220076322555542, "camel_15655": 0.7221260070800781, "TheoremQA_elainewan/math_algebra_3_5.json": 0.7223736047744751, "camel_49930": 0.7231520414352417, "camel_47707": 0.723410964012146, "camel_15803": 0.723484992980957, "camel_27641": 0.7237290740013123, "camel_15530": 0.72388756275177, "camel_15690": 0.7243287563323975, "camel_15751": 0.7247437834739685, "camel_21320": 0.7253036499023438, "camel_27712": 0.726288914680481, "camel_27026": 0.726421594619751, "camel_27611": 0.7290721535682678, "camel_14884": 0.7301048636436462, "camel_15717": 0.7301480174064636, "camel_27652": 0.7303475141525269, "camel_15624": 0.7304911017417908, "TheoremQA_elainewan/math_algebra_4.json": 0.7307451963424683, "camel_27628": 0.7324075102806091, "camel_27627": 0.7335215210914612, "camel_15687": 0.7337334156036377, "camel_15656": 0.7343479990959167, "camel_27672": 0.7354304194450378, "camel_27492": 0.7363501191139221, "TheoremQA_elainewan/math_algebra_6.json": 0.7371000051498413, "camel_15676": 0.7373969554901123, "camel_27634": 0.7376590371131897, "camel_27607": 0.7387149930000305, "camel_27639": 0.7392515540122986, "camel_27619": 0.7404518127441406, "camel_27648": 0.7414812445640564, "camel_21334": 0.7445520758628845, "camel_27667": 0.751037061214447, "TheoremQA_elainewan/math_algebra_2.json": 0.7542963027954102, "camel_15728": 0.7557995915412903, "camel_27449": 0.7592459917068481, "camel_27500": 0.7638564705848694}, "TheoremQA_maxku/fourier1-FS.json": {"camel_45356": 0, "camel_45158": 0, "camel_44526": 0, "camel_44991": 0, "camel_45320": 0, "camel_44564": 0, "camel_44352": 0, "camel_44866": 0, "camel_44335": 0, "camel_44665": 0, "camel_44338": 0, "camel_44503": 0, "camel_44195": 0, "camel_45121": 0, "camel_44448": 0, "camel_45079": 0, "camel_44264": 0, "camel_45758": 0, "camel_45615": 0, "camel_44650": 0, "camel_44862": 0, "camel_44089": 0, "camel_44322": 0, "camel_44406": 0, "camel_44803": 0, "camel_45143": 0, "camel_44681": 0, "camel_44117": 0, "camel_44331": 0, "camel_44342": 0, "camel_45552": 0, "camel_44584": 0, "camel_44374": 0, "camel_44082": 0, "camel_44676": 0, "camel_44040": 0, "camel_44533": 0, "camel_44477": 0, "camel_45081": 0, "camel_45571": 0, "camel_44362": 0, "camel_44160": 0, "camel_44667": 0, "camel_44127": 0, "camel_44124": 0, "camel_44928": 0, "camel_45052": 0, "camel_44092": 0, "camel_44925": 0, "camel_44927": 0, "camel_45911": 0, "camel_44877": 0, "camel_44155": 0, "camel_44326": 0, "camel_44325": 0, "camel_44914": 0, "camel_45773": 0, "camel_44411": 0, "camel_44442": 0, "camel_45227": 0, "camel_44399": 0, "camel_44379": 0, "camel_44566": 0, "camel_45965": 0, "camel_45103": 0, "camel_45680": 0, "camel_45353": 0, "camel_44427": 0, "camel_44002": 0, "camel_44466": 0, "camel_45711": 0, "camel_44420": 0, "camel_45564": 0, "camel_45729": 0, "camel_44943": 0, "camel_44691": 0, "camel_44824": 0, "camel_44802": 0, "camel_44276": 0, "camel_44504": 0, "camel_44384": 0, "camel_44323": 0, "camel_44204": 0, "camel_45632": 0, "camel_44447": 0, "camel_44176": 0, "camel_44490": 0, "camel_45203": 0, "camel_44621": 0, "camel_45822": 0, "camel_44088": 0, "camel_45275": 0, "camel_44674": 0, "camel_45165": 0, "camel_45610": 0, "camel_44021": 0, "camel_44579": 0, "camel_44468": 0, "camel_44560": 0, "camel_45914": 0, "camel_44457": 0, "camel_45585": 0, "camel_45236": 0, "camel_44499": 0, "camel_44022": 0, "camel_44874": 0, "camel_44465": 0, "camel_44227": 0, "camel_45998": 0, "camel_45896": 0, "camel_45224": 0, "camel_44955": 0, "camel_44923": 0, "camel_45919": 0, "camel_45748": 0, "camel_45855": 0, "TheoremQA_maxku/fourier1-FS.json": 0, "camel_45134": 0, "camel_44402": 0, "camel_45133": 0, "camel_45575": 0, "camel_45526": 0, "camel_45261": 0, "camel_44232": 0, "camel_45303": 0, "camel_45561": 0, "camel_44858": 0, "camel_44473": 0, "camel_45869": 0, "camel_44143": 0, "camel_44520": 0, "camel_45945": 0, "camel_45720": 0, "camel_44883": 0, "camel_45707": 0, "camel_44574": 0, "camel_44482": 0, "camel_44103": 0, "camel_44903": 0, "camel_44559": 0, "camel_44881": 0, "camel_45708": 0, "camel_45644": 0, "camel_44924": 0, "camel_45853": 0, "camel_44931": 0, "camel_45207": 0, "camel_44884": 0, "camel_45238": 0, "camel_44449": 0, "camel_44909": 0, "camel_44918": 0, "camel_45910": 0, "camel_45724": 0, "camel_44433": 0, "camel_45308": 0, "camel_44429": 0, "camel_44535": 0, "camel_44104": 0, "camel_44453": 0, "camel_45662": 0, "camel_44809": 0, "camel_44509": 0, "camel_45300": 0, "camel_44128": 0, "camel_45524": 0, "camel_45792": 0, "camel_44097": 0, "camel_44285": 0, "camel_44109": 0, "camel_44099": 0, "camel_44514": 0, "camel_45603": 0, "camel_45220": 0, "camel_45271": 0, "camel_44015": 0, "camel_44324": 0, "camel_44495": 0, "camel_44933": 0, "camel_45700": 0, "camel_45145": 0, "camel_45533": 0, "camel_44900": 0, "camel_45281": 0, "camel_44445": 0, "camel_43483": 0.8507938981056213, "camel_29842": 0.8543094396591187, "camel_43762": 0.8567594289779663, "camel_43469": 0.8583452105522156, "camel_43818": 0.8588678240776062, "camel_43582": 0.8598930239677429, "camel_43884": 0.8629222512245178, "camel_43814": 0.8642743229866028, "camel_43708": 0.8645647168159485, "camel_43729": 0.8666829466819763, "camel_43705": 0.8729029297828674, "camel_17830": 0.8842219710350037, "TheoremQA_maxku/fourier3-FT.json": 0.8935132026672363, "camel_43701": 0.9050313234329224, "camel_43720": 0.9115397930145264}, "TheoremQA_xueguangma/forward_price_3.json": {"TheoremQA_xueguangma/forward_price_3.json": 0, "gsm_rft_12784": 0.7094341516494751, "gsm_rft_8605": 0.7094712257385254, "gsm_rft_33006": 0.709659993648529, "aqua_rat_59668": 0.7097153663635254, "aqua_rat_20423": 0.7098532915115356, "gsm_train_18514": 0.7098996043205261, "aqua_rat_38785": 0.7100092768669128, "aqua_rat_53421": 0.7107602953910828, "aqua_rat_61400": 0.7107606530189514, "aqua_rat_79979": 0.7108418345451355, "aqua_rat_25162": 0.7108855843544006, "gsm_rft_12420": 0.7109357118606567, "aqua_rat_14728": 0.7110299468040466, "aqua_rat_34775": 0.7111440896987915, "aqua_rat_24347": 0.7111677527427673, "gsm_rft_13721": 0.7112360596656799, "aqua_rat_29170": 0.7114478349685669, "camel_45738": 0.7115364670753479, "aqua_rat_72933": 0.7116102576255798, "aqua_rat_30717": 0.7116994857788086, "gsm_rft_6751": 0.7118880152702332, "gsm_rft_32254": 0.7119913101196289, "aqua_rat_28282": 0.7124324440956116, "gsm_train_34638": 0.7124425172805786, "gsm_rft_22572": 0.7125498652458191, "gsm_rft_18143": 0.7128820419311523, "gsm_rft_12584": 0.7129568457603455, "aqua_rat_64664": 0.7131325602531433, "gsm_train_28727": 0.7131762504577637, "aqua_rat_15556": 0.713183581829071, "gsm_rft_24497": 0.7133102416992188, "aqua_rat_37382": 0.7133932709693909, "aqua_rat_38900": 0.7135522365570068, "aqua_rat_1115": 0.7135800123214722, "aqua_rat_3536": 0.7137500643730164, "aqua_rat_83740": 0.7137733697891235, "gsm_rft_35249": 0.7139437198638916, "aqua_rat_83234": 0.7140955924987793, "gsm_rft_7026": 0.7141359448432922, "gsm_rft_15334": 0.7141950726509094, "gsm_train_6037": 0.7141950726509094, "TheoremQA_xueguangma/present_value_1.json": 0.7143567800521851, "gsm_rft_33978": 0.7144196629524231, "gsm_train_34054": 0.7144196629524231, "aqua_rat_29976": 0.7144210934638977, "aqua_rat_18368": 0.7147129774093628, "aqua_rat_47773": 0.7147476673126221, "aqua_rat_62528": 0.7147641777992249, "aqua_rat_26022": 0.7148969173431396, "aqua_rat_88758": 0.7149744033813477, "aqua_rat_10990": 0.715121328830719, "math_test_algebra_608": 0.715627133846283, "aqua_rat_7537": 0.7157366871833801, "math_test_algebra_594": 0.7158532738685608, "aqua_rat_3687": 0.7159862518310547, "aqua_rat_15743": 0.716026246547699, "aqua_rat_32321": 0.7160812020301819, "aqua_rat_24052": 0.7161962985992432, "aqua_rat_36498": 0.716320812702179, "aqua_rat_75833": 0.7165185809135437, "aqua_rat_33923": 0.7165539264678955, "aqua_rat_80676": 0.7167113423347473, "aqua_rat_19784": 0.716788649559021, "aqua_rat_88415": 0.7170518040657043, "aqua_rat_21814": 0.7171453833580017, "aqua_rat_42733": 0.7171812653541565, "gsm_train_30707": 0.7175309658050537, "aqua_rat_21626": 0.7176148891448975, "gsm_rft_30907": 0.7176882028579712, "gsm_rft_315": 0.7178215384483337, "aqua_rat_77602": 0.7180795073509216, "gsm_rft_20456": 0.7181069254875183, "aqua_rat_34698": 0.7181335091590881, "aqua_rat_42949": 0.718207597732544, "gsm_rft_11804": 0.7186311483383179, "gsm_rft_31203": 0.7186671495437622, "aqua_rat_39049": 0.7187598347663879, "aqua_rat_15337": 0.7193137407302856, "aqua_rat_64105": 0.7195836305618286, "aqua_rat_88003": 0.7197936177253723, "gsm_rft_6203": 0.7198810577392578, "gsm_train_8817": 0.7199453115463257, "gsm_rft_32019": 0.7205446362495422, "aqua_rat_54684": 0.7205645442008972, "gsm_rft_20110": 0.7208675742149353, "aqua_rat_1549": 0.7208920121192932, "gsm_rft_2351": 0.7211459279060364, "aqua_rat_59892": 0.7213979363441467, "aqua_rat_43060": 0.7214099168777466, "aqua_rat_25723": 0.7215802669525146, "aqua_rat_45508": 0.7216221690177917, "aqua_rat_32350": 0.7217802405357361, "aqua_rat_57943": 0.7220146059989929, "aqua_rat_3402": 0.722295343875885, "gsm_rft_13162": 0.7223331928253174, "math_test_algebra_1611": 0.7223390936851501, "gsm_rft_6422": 0.7232125401496887, "gsm_rft_10656": 0.7237156629562378, "aqua_rat_10686": 0.7238162755966187, "aqua_rat_72794": 0.723829448223114, "aqua_rat_46898": 0.7239404320716858, "aqua_rat_88960": 0.7240217328071594, "gsm_rft_31288": 0.7240546941757202, "aqua_rat_16448": 0.724614679813385, "aqua_rat_64976": 0.724644660949707, "camel_37746": 0.7249579429626465, "aqua_rat_11679": 0.7252221703529358, "gsm_rft_7096": 0.7253195643424988, "aqua_rat_49352": 0.7256206274032593, "math_train_algebra_940": 0.7258989214897156, "gsm_rft_33659": 0.7259538769721985, "aqua_rat_28883": 0.7261990308761597, "aqua_rat_3773": 0.7263165712356567, "aqua_rat_59": 0.7265609502792358, "aqua_rat_67841": 0.726593017578125, "aqua_rat_56852": 0.7266704440116882, "aqua_rat_27039": 0.7269163727760315, "aqua_rat_41963": 0.7269996404647827, "gsm_rft_16062": 0.7270185947418213, "aqua_rat_86835": 0.7273256182670593, "aqua_rat_68014": 0.7273716926574707, "gsm_rft_23131": 0.7274668216705322, "gsm_rft_25231": 0.7274686098098755, "gsm_train_19719": 0.7274686098098755, "aqua_rat_48494": 0.7278088927268982, "TheoremQA_xueguangma/put_call_parity_1.json": 0.7280693650245667, "aqua_rat_36240": 0.7281007766723633, "gsm_rft_31720": 0.7282450199127197, "aqua_rat_73390": 0.7285218834877014, "math_train_algebra_369": 0.7292379140853882, "aqua_rat_69905": 0.7294113039970398, "aqua_rat_10582": 0.7295079231262207, "aqua_rat_63070": 0.7295557260513306, "aqua_rat_255": 0.7297202348709106, "aqua_rat_869": 0.7298155426979065, "aqua_rat_3885": 0.7302362322807312, "aqua_rat_40489": 0.7304422855377197, "aqua_rat_37258": 0.7304490208625793, "aqua_rat_70690": 0.7305405735969543, "aqua_rat_66298": 0.7306376695632935, "TheoremQA_xueguangma/spot_rate.json": 0.7306928038597107, "aqua_rat_42515": 0.7310158610343933, "aqua_rat_87246": 0.7311744689941406, "aqua_rat_9965": 0.7312295436859131, "aqua_rat_87884": 0.731234610080719, "aqua_rat_24068": 0.7316319942474365, "aqua_rat_33430": 0.7316951155662537, "aqua_rat_64914": 0.7318993806838989, "aqua_rat_67076": 0.731919527053833, "aqua_rat_32852": 0.7320058941841125, "aqua_rat_51100": 0.7320167422294617, "aqua_rat_735": 0.7322478294372559, "aqua_rat_30386": 0.7328270673751831, "aqua_rat_69547": 0.7333150506019592, "aqua_rat_45867": 0.7334876656532288, "aqua_rat_42017": 0.733894407749176, "aqua_rat_64422": 0.7339562177658081, "aqua_rat_71239": 0.7339895367622375, "aqua_rat_7674": 0.7340051531791687, "gsm_rft_26458": 0.7340359091758728, "aqua_rat_66371": 0.7341417670249939, "aqua_rat_36461": 0.7342750430107117, "aqua_rat_72737": 0.7344856858253479, "aqua_rat_40411": 0.7345234155654907, "aqua_rat_84309": 0.7345255613327026, "math_train_algebra_2507": 0.7346950173377991, "aqua_rat_49908": 0.7347092032432556, "aqua_rat_87589": 0.7357466220855713, "aqua_rat_79047": 0.7358360886573792, "aqua_rat_20758": 0.7364423274993896, "gsm_rft_3890": 0.7368530631065369, "aqua_rat_78121": 0.7371107339859009, "aqua_rat_78533": 0.737335205078125, "gsm_train_29580": 0.737879753112793, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7384064197540283, "aqua_rat_6679": 0.7385357618331909, "aqua_rat_15079": 0.7389659285545349, "aqua_rat_31553": 0.7391905784606934, "aqua_rat_63322": 0.7394121289253235, "TheoremQA_xueguangma/forward_price_1.json": 0.7403855323791504, "math_test_algebra_337": 0.740439772605896, "aqua_rat_62727": 0.7408846616744995, "aqua_rat_85902": 0.741413950920105, "aqua_rat_50660": 0.7417269945144653, "aqua_rat_46315": 0.7417899966239929, "math_test_algebra_2626": 0.7418662905693054, "aqua_rat_29154": 0.7422840595245361, "math_train_algebra_1658": 0.7428538203239441, "camel_37735": 0.7435833215713501, "math_test_algebra_1862": 0.7437087893486023, "aqua_rat_26425": 0.7439624667167664, "math_train_algebra_667": 0.747671365737915, "math_test_algebra_311": 0.7493332624435425, "gsm_rft_30946": 0.7519832253456116, "gsm_rft_19766": 0.7521848082542419, "gsm_rft_9014": 0.7522287368774414, "gsm_train_34036": 0.752617597579956, "gsm_rft_20212": 0.754550039768219, "TheoremQA_xueguangma/forward_price_2.json": 0.7807143926620483}, "TheoremQA_xueguangma/intermediate_value_theorem.json": {"camel_6985": 0, "camel_7676": 0, "camel_7273": 0, "camel_7257": 0, "camel_6417": 0, "camel_7682": 0, "camel_7277": 0, "camel_7714": 0, "camel_6424": 0, "camel_7120": 0, "camel_6466": 0, "camel_7030": 0, "camel_7177": 0, "camel_7163": 0, "camel_7029": 0, "camel_7027": 0, "camel_7013": 0, "camel_7003": 0, "camel_6420": 0, "camel_7037": 0, "camel_7024": 0, "camel_7144": 0, "camel_7021": 0, "camel_6440": 0, "camel_6984": 0, "camel_6972": 0, "camel_6411": 0, "camel_6975": 0, "camel_7135": 0, "camel_6986": 0, "camel_7194": 0, "camel_7214": 0, "camel_6966": 0, "camel_6989": 0, "camel_6974": 0, "camel_7272": 0, "camel_7020": 0, "camel_7124": 0, "camel_7128": 0, "camel_7007": 0, "camel_7174": 0, "camel_7161": 0, "camel_6981": 0, "camel_6448": 0, "camel_7251": 0, "camel_6976": 0, "camel_6967": 0, "camel_7016": 0, "camel_7019": 0, "camel_6437": 0, "camel_7173": 0, "camel_6518": 0, "camel_7160": 0, "camel_6979": 0, "camel_6987": 0, "camel_7149": 0, "camel_7205": 0, "camel_7038": 0, "camel_7026": 0, "camel_6449": 0, "camel_6407": 0, "camel_7268": 0, "camel_7178": 0, "camel_7234": 0, "camel_7032": 0, "camel_7011": 0, "camel_7159": 0, "camel_6970": 0, "camel_7035": 0, "camel_7138": 0, "camel_41857": 0.7071302533149719, "camel_40650": 0.7073155641555786, "gsm_rft_28321": 0.7073172926902771, "camel_40780": 0.7073813080787659, "camel_40776": 0.707643449306488, "camel_44659": 0.7077247500419617, "gsm_rft_17551": 0.7081251740455627, "gsm_train_17819": 0.7081251740455627, "camel_40781": 0.7086235284805298, "camel_1523": 0.7087498903274536, "gsm_rft_9344": 0.708806037902832, "gsm_rft_2452": 0.7089023590087891, "math_train_algebra_1536": 0.7089993953704834, "math_train_algebra_47": 0.7090756893157959, "camel_39311": 0.7094313502311707, "camel_1707": 0.7094372510910034, "camel_19412": 0.7095479369163513, "camel_469": 0.7096871137619019, "camel_41950": 0.7098978161811829, "camel_476": 0.7100018858909607, "camel_40754": 0.7100059986114502, "camel_38888": 0.710019052028656, "camel_39359": 0.7100854516029358, "camel_452": 0.710308849811554, "camel_1685": 0.7103347182273865, "math_test_algebra_892": 0.7103561758995056, "camel_1706": 0.7106444835662842, "gsm_rft_11031": 0.7108042240142822, "camel_40867": 0.7112149596214294, "gsm_rft_2784": 0.7113234400749207, "gsm_rft_368": 0.7113234400749207, "gsm_train_10122": 0.7113941311836243, "camel_40777": 0.7113962769508362, "camel_18765": 0.7116198539733887, "camel_1590": 0.7117131352424622, "camel_413": 0.7117925882339478, "camel_39319": 0.7118542790412903, "camel_40885": 0.7120305299758911, "camel_39310": 0.7120874524116516, "camel_1534": 0.7121546268463135, "camel_441": 0.7121666669845581, "camel_38193": 0.7121849656105042, "camel_40797": 0.7123395204544067, "camel_39441": 0.7123890519142151, "camel_39108": 0.7131963968276978, "camel_19483": 0.7132083773612976, "camel_465": 0.7134069800376892, "camel_39296": 0.7134312987327576, "camel_40752": 0.7134771347045898, "camel_38088": 0.7139418721199036, "camel_40785": 0.7140302658081055, "aqua_rat_47425": 0.7143810987472534, "camel_40729": 0.7144116163253784, "aqua_rat_52932": 0.7147747278213501, "camel_1544": 0.7152124047279358, "aqua_rat_48488": 0.7153098583221436, "camel_40736": 0.7153633832931519, "camel_38221": 0.7156171202659607, "camel_38109": 0.7160085439682007, "camel_39325": 0.7167293429374695, "camel_38909": 0.7168264389038086, "camel_18139": 0.7170014977455139, "camel_410": 0.7177453637123108, "TheoremQA_elainewan/math_calculus_12.json": 0.7177799940109253, "camel_427": 0.717831552028656, "aqua_rat_11436": 0.7180134057998657, "camel_40952": 0.7181668877601624, "camel_39457": 0.7181726694107056, "camel_40798": 0.7182765603065491, "camel_41853": 0.7182862758636475, "camel_40882": 0.7188952565193176, "aqua_rat_66786": 0.7189998030662537, "aqua_rat_44312": 0.7191146016120911, "camel_40779": 0.719550371170044, "camel_39355": 0.7196825742721558, "camel_41417": 0.7198110818862915, "aqua_rat_53929": 0.7199721932411194, "camel_39323": 0.7207902073860168, "camel_1527": 0.7212627530097961, "camel_39251": 0.7216475009918213, "camel_48965": 0.7217950820922852, "camel_40817": 0.7218279838562012, "camel_38197": 0.7225565314292908, "aqua_rat_57946": 0.722624659538269, "camel_5035": 0.7231277227401733, "camel_18915": 0.7239891290664673, "camel_39343": 0.7240590453147888, "camel_41967": 0.724094033241272, "camel_436": 0.7241247296333313, "camel_1750": 0.724916934967041, "camel_40929": 0.7252724170684814, "gsm_rft_5022": 0.7259211540222168, "gsm_train_14395": 0.7259211540222168, "gsm_rft_4611": 0.7259211540222168, "camel_40788": 0.7268661260604858, "aqua_rat_9643": 0.7270525693893433, "aqua_rat_68267": 0.7294646501541138, "camel_39486": 0.7295576333999634, "camel_19401": 0.7296425104141235, "camel_1759": 0.7302119135856628, "camel_40770": 0.7303204536437988, "math_test_intermediate_algebra_470": 0.7305206060409546, "TheoremQA_xueguangma/rolle_theorem.json": 0.7310187220573425, "camel_39448": 0.7313520908355713, "camel_39483": 0.7328447699546814, "camel_1731": 0.733431875705719, "camel_18923": 0.7342519164085388, "math_train_algebra_207": 0.73515784740448, "camel_40735": 0.7380738854408264, "math_train_intermediate_algebra_1821": 0.7381922006607056, "camel_1749": 0.7384293675422668, "camel_39312": 0.7385939955711365, "camel_19281": 0.7391483187675476, "camel_18732": 0.7392795085906982, "camel_1565": 0.7402625679969788, "camel_1733": 0.742171585559845, "camel_40945": 0.7430950999259949, "camel_5016": 0.7449941635131836, "camel_1748": 0.7467073202133179, "camel_28147": 0.7475122809410095, "camel_1744": 0.7480398416519165, "camel_18784": 0.7481991648674011, "camel_1757": 0.7482760548591614, "camel_39466": 0.7521203756332397, "aqua_rat_16683": 0.752456545829773, "camel_40760": 0.7547337412834167, "camel_1708": 0.7553238868713379, "camel_1702": 0.7563665509223938, "aqua_rat_11769": 0.7566512227058411, "camel_39357": 0.7586247324943542}, "TheoremQA_mingyin/Limit-of-sequence2.json": {"TheoremQA_mingyin/Limit-of-sequence2.json": 0, "camel_31759": 0.6280615925788879, "aqua_rat_55051": 0.628081202507019, "aqua_rat_14307": 0.6280869841575623, "gsm_train_28477": 0.6281163692474365, "camel_36444": 0.6283367872238159, "aqua_rat_10097": 0.6283637881278992, "camel_16804": 0.6284143924713135, "camel_30526": 0.6284239292144775, "gsm_rft_32289": 0.6284500360488892, "camel_16123": 0.6285046339035034, "camel_30374": 0.6285167932510376, "camel_40704": 0.628531277179718, "camel_16862": 0.6285927295684814, "aqua_rat_62135": 0.6287142038345337, "camel_17379": 0.6287975311279297, "math_test_counting_and_probability_974": 0.6288372278213501, "camel_42536": 0.6288512349128723, "camel_16806": 0.6288527846336365, "camel_28688": 0.6288588047027588, "aqua_rat_68262": 0.6288681030273438, "camel_40670": 0.6289380192756653, "camel_31048": 0.6290144920349121, "camel_30858": 0.6290431022644043, "gsm_train_11028": 0.6291403770446777, "camel_16131": 0.6291614174842834, "math_train_number_theory_7018": 0.6291628479957581, "aqua_rat_2286": 0.6291741728782654, "camel_20782": 0.6293230652809143, "camel_8361": 0.6293651461601257, "aqua_rat_18817": 0.6294196248054504, "aqua_rat_18530": 0.6294496059417725, "camel_37471": 0.6295897960662842, "camel_28705": 0.6296175718307495, "camel_29019": 0.6296230554580688, "aqua_rat_37587": 0.6297411322593689, "camel_31460": 0.6298204064369202, "math_test_counting_and_probability_930": 0.6298890113830566, "camel_37591": 0.6299107670783997, "camel_28710": 0.630033016204834, "gsm_rft_31268": 0.6301180124282837, "aqua_rat_4703": 0.63040691614151, "camel_37594": 0.6307293772697449, "aqua_rat_260": 0.6307499408721924, "aqua_rat_19055": 0.6308067440986633, "camel_31236": 0.630943238735199, "aqua_rat_12341": 0.6311084628105164, "camel_28663": 0.631195604801178, "aqua_rat_65330": 0.6313233375549316, "camel_31938": 0.6313896775245667, "aqua_rat_3314": 0.6315128803253174, "camel_20433": 0.6315352916717529, "camel_28671": 0.6315889954566956, "aqua_rat_41397": 0.6316894292831421, "aqua_rat_88648": 0.6318737864494324, "aqua_rat_66909": 0.6319358944892883, "math_train_number_theory_508": 0.6322057843208313, "camel_20774": 0.6322590708732605, "camel_29033": 0.6322678327560425, "camel_37547": 0.6323655247688293, "aqua_rat_82260": 0.6326673626899719, "camel_38527": 0.6327465772628784, "camel_28664": 0.6327727437019348, "aqua_rat_75738": 0.6328121423721313, "aqua_rat_9734": 0.632864773273468, "camel_30939": 0.6330248713493347, "aqua_rat_59192": 0.6331098675727844, "aqua_rat_2902": 0.6331774592399597, "gsm_train_27677": 0.633242666721344, "gsm_rft_34042": 0.633242666721344, "gsm_rft_4555": 0.633242666721344, "aqua_rat_44150": 0.6332718133926392, "aqua_rat_7869": 0.6334338784217834, "camel_31323": 0.6334753632545471, "aqua_rat_35021": 0.6336174011230469, "camel_42616": 0.6337993144989014, "camel_49109": 0.6338379383087158, "aqua_rat_62262": 0.6338728666305542, "aqua_rat_61662": 0.6339978575706482, "camel_31444": 0.6340126991271973, "camel_28718": 0.6340761780738831, "camel_11628": 0.634209156036377, "camel_28548": 0.6342207789421082, "aqua_rat_79822": 0.6344001293182373, "aqua_rat_69660": 0.6344298124313354, "TheoremQA_xueguangma/maclaurin_series.json": 0.6345242261886597, "aqua_rat_59989": 0.6345733404159546, "camel_28679": 0.6346327662467957, "camel_37581": 0.6346813440322876, "camel_42619": 0.6351626515388489, "TheoremQA_wenhuchen/L'H\u00f4pital_rule1.json": 0.6356324553489685, "camel_37590": 0.635784924030304, "aqua_rat_60031": 0.6358286142349243, "aqua_rat_34686": 0.636226236820221, "TheoremQA_jianyu_xu/derangement_1.json": 0.6363223195075989, "aqua_rat_82061": 0.6364288926124573, "aqua_rat_48983": 0.636560320854187, "camel_30959": 0.6366437077522278, "camel_42711": 0.6366546750068665, "camel_11562": 0.6366978883743286, "TheoremQA_elainewan/math_real_analysis_additional_3.json": 0.6367461681365967, "camel_8368": 0.6367485523223877, "camel_37519": 0.6368392705917358, "camel_18917": 0.6368586421012878, "camel_27736": 0.6369162797927856, "aqua_rat_65646": 0.6369954943656921, "camel_28696": 0.6381819844245911, "math_test_prealgebra_754": 0.6382330060005188, "camel_42497": 0.6383181214332581, "camel_42618": 0.6384361386299133, "camel_31131": 0.6385177373886108, "aqua_rat_73094": 0.6385537385940552, "camel_24549": 0.6388537287712097, "camel_31206": 0.6389134526252747, "math_train_counting_and_probability_1028": 0.6390393376350403, "camel_30843": 0.6390896439552307, "math_train_counting_and_probability_5036": 0.6391829252243042, "aqua_rat_60777": 0.6392604112625122, "camel_16112": 0.6394422054290771, "aqua_rat_88957": 0.6395566463470459, "aqua_rat_78344": 0.6397783160209656, "camel_30952": 0.6398801207542419, "camel_28712": 0.6398922204971313, "camel_12885": 0.6400871276855469, "aqua_rat_68443": 0.640144944190979, "aqua_rat_76182": 0.6401636004447937, "camel_11552": 0.6404531598091125, "camel_28521": 0.6405272483825684, "math_train_counting_and_probability_1066": 0.6406906247138977, "aqua_rat_73910": 0.6407039165496826, "camel_39482": 0.6407575011253357, "aqua_rat_80404": 0.6409622430801392, "camel_11271": 0.6409890651702881, "aqua_rat_57169": 0.6411863565444946, "aqua_rat_52920": 0.6416414976119995, "aqua_rat_47209": 0.6421849131584167, "aqua_rat_34963": 0.6426330208778381, "camel_30887": 0.6427100300788879, "aqua_rat_69960": 0.6427688598632812, "aqua_rat_61389": 0.6431547999382019, "aqua_rat_62672": 0.6432957053184509, "camel_30824": 0.6433820724487305, "camel_12945": 0.643413245677948, "aqua_rat_41810": 0.6440942883491516, "camel_28502": 0.6441690325737, "camel_16044": 0.6448325514793396, "camel_30202": 0.6448853015899658, "aqua_rat_67821": 0.6451542973518372, "gsm_rft_5709": 0.6451990008354187, "gsm_train_27638": 0.6451990008354187, "camel_26733": 0.6459746956825256, "TheoremQA_wenhuchen/series_convergen3.json": 0.6460206508636475, "aqua_rat_43837": 0.6461349129676819, "camel_29787": 0.6462299823760986, "camel_28668": 0.6466092467308044, "math_train_algebra_457": 0.6466802358627319, "aqua_rat_61431": 0.6468415856361389, "camel_31066": 0.6472771763801575, "camel_28309": 0.6475592255592346, "aqua_rat_40916": 0.647680401802063, "aqua_rat_82861": 0.648056149482727, "aqua_rat_37794": 0.6482393145561218, "camel_20491": 0.6484591364860535, "camel_37502": 0.6486737728118896, "camel_31987": 0.648806631565094, "gsm_rft_33399": 0.6495028734207153, "camel_28675": 0.6500688195228577, "camel_37559": 0.6503517031669617, "camel_28701": 0.650512158870697, "aqua_rat_6261": 0.6506200432777405, "aqua_rat_44801": 0.650629460811615, "aqua_rat_23857": 0.6506633162498474, "camel_27412": 0.6508312225341797, "camel_37546": 0.6510519981384277, "camel_37545": 0.651603639125824, "aqua_rat_30022": 0.6517792344093323, "aqua_rat_47013": 0.6518905758857727, "camel_42013": 0.6524182558059692, "aqua_rat_18545": 0.6525689959526062, "camel_42591": 0.6528676748275757, "camel_30770": 0.653020441532135, "aqua_rat_68547": 0.6541862487792969, "camel_18301": 0.6542515754699707, "aqua_rat_52681": 0.6543231010437012, "aqua_rat_13223": 0.6552161574363708, "camel_31880": 0.6556174159049988, "camel_30889": 0.6558908224105835, "math_train_number_theory_7060": 0.6571578979492188, "camel_49051": 0.6601843237876892, "aqua_rat_47520": 0.6602123975753784, "camel_26784": 0.6610994935035706, "aqua_rat_59396": 0.6624585390090942, "aqua_rat_16186": 0.6631239056587219, "aqua_rat_59305": 0.6634039878845215, "camel_11523": 0.6646744608879089, "aqua_rat_69628": 0.6672378182411194, "aqua_rat_59407": 0.6672978401184082, "camel_30050": 0.6788673400878906, "camel_37514": 0.6803785562515259, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus2.json": 0.7202853560447693}, "TheoremQA_elainewan/math_abstact_algebra_7_3.json": {"camel_33008": 0, "camel_33511": 0, "camel_33382": 0, "camel_32491": 0, "camel_33103": 0, "camel_33854": 0, "camel_32515": 0, "camel_33173": 0, "camel_33404": 0, "camel_33156": 0, "camel_33513": 0, "camel_32792": 0, "camel_32736": 0, "camel_32554": 0, "camel_33063": 0, "camel_33524": 0, "camel_32625": 0, "camel_32824": 0, "camel_33671": 0, "camel_33100": 0, "camel_33187": 0, "camel_33140": 0, "camel_32857": 0, "camel_32761": 0, "camel_33080": 0, "camel_32796": 0, "camel_33097": 0, "camel_33164": 0, "camel_32620": 0, "camel_33598": 0, "camel_32513": 0, "camel_33333": 0, "camel_33411": 0, "camel_32773": 0, "camel_32545": 0, "camel_33085": 0, "camel_33975": 0, "camel_33003": 0, "camel_33116": 0, "camel_32492": 0, "camel_33934": 0, "camel_32526": 0, "camel_32603": 0, "camel_33679": 0, "camel_33073": 0, "camel_33171": 0, "camel_33462": 0, "camel_33944": 0, "camel_33750": 0, "camel_32544": 0, "camel_33618": 0, "camel_32944": 0, "camel_32728": 0, "camel_33402": 0, "camel_33837": 0, "camel_32786": 0, "camel_32568": 0, "camel_32489": 0, "camel_32493": 0, "camel_32740": 0, "camel_32635": 0, "camel_32982": 0, "camel_32988": 0, "camel_33584": 0, "camel_33013": 0, "camel_32658": 0, "camel_32831": 0, "camel_32720": 0, "camel_32632": 0, "camel_33075": 0, "camel_32830": 0, "camel_33079": 0, "camel_32904": 0, "camel_33930": 0, "camel_32905": 0, "camel_33107": 0, "camel_32605": 0, "camel_32483": 0, "camel_32789": 0, "camel_33022": 0, "camel_32769": 0, "camel_32724": 0, "camel_32711": 0, "camel_32490": 0, "camel_33892": 0, "camel_32286": 0, "camel_32837": 0, "camel_32634": 0, "camel_33448": 0, "camel_33824": 0, "camel_32566": 0, "camel_33538": 0, "camel_32802": 0, "camel_33517": 0, "camel_32499": 0, "camel_32529": 0, "camel_32727": 0, "camel_33509": 0, "camel_33344": 0, "camel_33704": 0, "camel_33748": 0, "camel_33417": 0, "camel_32766": 0, "camel_33755": 0, "camel_32531": 0, "camel_32623": 0, "camel_32520": 0, "camel_32995": 0, "camel_32729": 0, "camel_33192": 0, "camel_33467": 0, "camel_33047": 0, "camel_33446": 0, "camel_32509": 0, "camel_32541": 0, "camel_33596": 0, "camel_33481": 0, "camel_32751": 0, "camel_32745": 0, "camel_32835": 0, "camel_33397": 0, "camel_33456": 0, "camel_32966": 0, "camel_33501": 0, "camel_32506": 0, "camel_33042": 0, "camel_33463": 0, "camel_33453": 0, "camel_33027": 0, "camel_33090": 0, "camel_33785": 0, "camel_33351": 0, "camel_33968": 0, "camel_32797": 0, "camel_32759": 0, "camel_33457": 0, "camel_33495": 0, "camel_33138": 0, "camel_32504": 0, "camel_32849": 0, "camel_33148": 0, "camel_32498": 0, "camel_32851": 0, "camel_33727": 0, "camel_33051": 0, "camel_33497": 0, "camel_32547": 0, "camel_32533": 0, "camel_33936": 0, "camel_32840": 0, "camel_32778": 0, "camel_33070": 0, "camel_32781": 0, "camel_33530": 0, "camel_32495": 0, "camel_32741": 0, "camel_32955": 0, "camel_32945": 0, "camel_32953": 0, "camel_33947": 0, "camel_33315": 0, "camel_32750": 0, "camel_33105": 0, "camel_32775": 0, "camel_33542": 0, "camel_33595": 0, "camel_33943": 0, "camel_33529": 0, "camel_33475": 0, "camel_33019": 0, "camel_32535": 0, "camel_33593": 0, "camel_33580": 0, "camel_32508": 0, "camel_32858": 0, "camel_33069": 0, "camel_32578": 0, "camel_33838": 0, "camel_33332": 0, "camel_32787": 0, "camel_33574": 0, "camel_33050": 0, "camel_33537": 0, "camel_32485": 0, "camel_33981": 0, "TheoremQA_elainewan/math_abstact_algebra_7_3.json": 0, "camel_32890": 0, "camel_33074": 0, "camel_33470": 0, "camel_33832": 0, "camel_33941": 0, "camel_32747": 0, "camel_33091": 0, "camel_33113": 0, "camel_33325": 0, "camel_32600": 0, "camel_33512": 0, "camel_32864": 0, "camel_33082": 0, "TheoremQA_elainewan/math_abstact_algebra_7_8.json": 0.818423330783844}, "TheoremQA_tonyxia/maxplanar1.json": {"camel_23199": 0, "camel_22835": 0, "camel_22565": 0, "camel_22595": 0, "camel_21787": 0, "camel_22447": 0, "camel_22605": 0, "camel_22450": 0, "camel_22393": 0, "camel_22387": 0, "camel_23128": 0, "camel_23386": 0, "camel_21113": 0, "camel_22458": 0, "camel_22379": 0, "camel_23389": 0, "camel_22469": 0, "camel_22608": 0, "camel_22864": 0, "camel_23408": 0, "camel_23377": 0, "camel_22424": 0, "camel_22437": 0, "camel_22564": 0, "camel_22478": 0, "camel_22466": 0, "camel_22448": 0, "camel_22412": 0, "camel_21795": 0, "camel_23392": 0, "camel_23146": 0, "camel_22471": 0, "camel_22334": 0, "camel_22827": 0, "camel_22425": 0, "camel_22413": 0, "camel_22837": 0, "camel_22464": 0, "camel_22441": 0, "camel_21830": 0, "camel_22843": 0, "camel_23156": 0, "camel_21044": 0, "camel_22600": 0, "camel_22352": 0, "camel_23182": 0, "camel_21091": 0, "camel_22417": 0, "camel_22573": 0, "camel_22338": 0, "camel_22456": 0, "camel_22561": 0, "camel_21107": 0, "camel_22472": 0, "camel_23141": 0, "camel_22588": 0, "camel_23124": 0, "camel_22444": 0, "camel_22373": 0, "camel_22563": 0, "camel_22443": 0, "camel_23934": 0, "camel_22632": 0, "camel_22454": 0, "camel_22445": 0, "camel_22572": 0, "camel_22442": 0, "TheoremQA_tonyxia/maxplanar1.json": 0, "camel_22328": 0, "camel_22604": 0, "camel_23171": 0, "camel_22625": 0, "camel_21052": 0, "camel_22581": 0, "camel_22398": 0, "camel_22415": 0, "camel_22422": 0, "camel_23364": 0, "camel_21054": 0, "camel_23170": 0, "camel_22585": 0, "camel_23183": 0, "camel_23193": 0, "camel_21067": 0, "camel_23403": 0, "camel_23147": 0, "camel_23125": 0, "camel_23172": 0, "camel_22452": 0, "camel_23176": 0, "camel_23195": 0, "camel_23151": 0, "camel_23149": 0, "camel_22838": 0, "camel_23132": 0, "camel_23188": 0, "camel_22473": 0, "camel_23181": 0, "camel_23363": 0, "camel_23159": 0, "camel_22453": 0, "camel_22812": 0, "camel_23425": 0, "camel_23131": 0, "camel_22586": 0, "camel_22853": 0, "camel_22866": 0, "camel_23150": 0, "camel_23404": 0, "camel_23391": 0, "camel_23394": 0, "camel_23155": 0, "camel_22606": 0, "camel_23174": 0, "camel_23400": 0, "camel_22824": 0, "camel_22411": 0, "camel_23177": 0, "camel_23424": 0, "camel_22825": 0, "camel_22439": 0, "camel_23158": 0, "camel_23372": 0, "camel_23198": 0, "camel_23402": 0, "camel_23135": 0, "camel_21083": 0, "camel_22599": 0, "camel_23871": 0, "camel_23189": 0, "camel_23154": 0, "camel_22580": 0, "camel_22333": 0, "camel_23167": 0, "camel_23157": 0, "camel_23169": 0, "camel_22434": 0, "camel_23423": 0, "camel_21098": 0, "camel_23376": 0, "camel_22584": 0, "camel_22808": 0, "camel_22418": 0, "camel_23431": 0, "camel_22383": 0, "camel_23393": 0, "camel_23136": 0, "camel_22823": 0, "camel_22912": 0, "camel_22575": 0, "camel_23148": 0, "camel_23190": 0, "camel_22579": 0, "camel_22863": 0, "camel_22805": 0, "camel_23430": 0, "camel_22862": 0, "camel_22407": 0, "camel_23180": 0, "camel_23165": 0, "camel_23138": 0, "camel_22628": 0, "camel_22801": 0, "camel_23187": 0, "camel_21102": 0, "camel_23175": 0, "camel_23161": 0, "camel_22574": 0, "camel_22157": 0, "camel_23173": 0, "camel_22849": 0, "camel_23122": 0, "camel_23168": 0, "camel_23137": 0, "camel_23144": 0, "camel_23123": 0, "camel_23145": 0, "camel_23191": 0, "camel_23166": 0, "camel_23162": 0, "camel_21057": 0, "camel_23378": 0, "camel_22867": 0, "camel_23163": 0, "camel_22879": 0, "camel_23126": 0, "camel_23196": 0, "camel_23179": 0, "camel_23432": 0, "camel_23382": 0, "camel_23164": 0, "camel_19812": 0.7569265365600586, "aqua_rat_54929": 0.7570245265960693, "aqua_rat_28685": 0.7617024779319763, "aqua_rat_44831": 0.7680644392967224, "camel_19957": 0.7714393734931946, "aqua_rat_76009": 0.7748526334762573, "aqua_rat_70645": 0.779046356678009, "aqua_rat_40504": 0.7865838408470154, "aqua_rat_25794": 0.7912499308586121}, "TheoremQA_jianyu_xu/Multinomial_6.json": {"camel_21418": 0, "camel_21203": 0, "camel_20285": 0, "camel_20302": 0, "camel_20598": 0, "camel_21526": 0, "camel_20293": 0, "camel_20442": 0, "camel_20356": 0, "camel_20022": 0, "camel_20611": 0, "camel_21564": 0, "camel_20449": 0, "camel_21039": 0, "camel_20619": 0, "camel_20931": 0, "camel_20260": 0, "camel_20813": 0, "camel_21247": 0, "camel_20274": 0, "camel_20298": 0, "camel_21005": 0, "camel_20406": 0, "camel_21253": 0, "camel_20998": 0, "camel_21572": 0, "camel_20930": 0, "camel_21419": 0, "camel_20336": 0, "camel_20256": 0, "camel_20283": 0, "camel_20552": 0, "camel_20915": 0, "camel_20453": 0, "camel_20410": 0, "camel_20246": 0, "camel_21528": 0, "camel_20698": 0, "camel_21034": 0, "camel_20269": 0, "camel_21267": 0, "camel_20397": 0, "camel_20984": 0, "camel_20414": 0, "camel_20309": 0, "TheoremQA_jianyu_xu/Multinomial_6.json": 0, "camel_20477": 0, "camel_21521": 0, "camel_20874": 0, "camel_20985": 0, "camel_21808": 0, "camel_20853": 0, "camel_21586": 0, "camel_21021": 0, "camel_21219": 0, "camel_21028": 0, "camel_20004": 0, "camel_20312": 0, "camel_20996": 0, "camel_20623": 0, "camel_21413": 0, "camel_20973": 0, "camel_20272": 0, "aqua_rat_31360": 0.8009464740753174, "aqua_rat_58309": 0.8011230230331421, "aqua_rat_10346": 0.801382839679718, "aqua_rat_16780": 0.8015645146369934, "aqua_rat_58044": 0.8015685081481934, "aqua_rat_32774": 0.8015738725662231, "math_train_counting_and_probability_562": 0.8016875386238098, "aqua_rat_53009": 0.8016961216926575, "aqua_rat_42445": 0.801751434803009, "aqua_rat_37185": 0.8018054962158203, "aqua_rat_80017": 0.801922619342804, "aqua_rat_55099": 0.8019432425498962, "aqua_rat_35044": 0.8020769357681274, "aqua_rat_44353": 0.8021203279495239, "aqua_rat_10394": 0.8023563623428345, "aqua_rat_84159": 0.8024300932884216, "aqua_rat_40812": 0.802539587020874, "aqua_rat_69384": 0.8025840520858765, "aqua_rat_74719": 0.8030871152877808, "aqua_rat_72437": 0.8031100630760193, "aqua_rat_28687": 0.8031675219535828, "aqua_rat_8728": 0.803331732749939, "aqua_rat_75780": 0.8033686280250549, "aqua_rat_77021": 0.8035193085670471, "aqua_rat_81548": 0.8035662174224854, "aqua_rat_73040": 0.8036429286003113, "math_train_counting_and_probability_696": 0.8039366602897644, "aqua_rat_84274": 0.8040306568145752, "aqua_rat_85599": 0.8041366934776306, "aqua_rat_71071": 0.8041422367095947, "math_train_counting_and_probability_122": 0.8041704893112183, "aqua_rat_58323": 0.8042834401130676, "aqua_rat_23594": 0.8042847514152527, "aqua_rat_74248": 0.8043538331985474, "aqua_rat_87868": 0.8043627738952637, "aqua_rat_74995": 0.8044151663780212, "aqua_rat_7035": 0.8044836521148682, "camel_38545": 0.804526150226593, "aqua_rat_80108": 0.8046483993530273, "aqua_rat_16294": 0.8046522736549377, "aqua_rat_72660": 0.8046691417694092, "aqua_rat_15343": 0.8047615885734558, "aqua_rat_38123": 0.8050857186317444, "aqua_rat_74695": 0.8051406145095825, "aqua_rat_67709": 0.8051876425743103, "aqua_rat_89302": 0.8052348494529724, "math_train_counting_and_probability_5126": 0.8053949475288391, "aqua_rat_51656": 0.8054022192955017, "aqua_rat_66330": 0.8056625723838806, "aqua_rat_87690": 0.8056919574737549, "aqua_rat_29348": 0.8056967258453369, "aqua_rat_71423": 0.8057742118835449, "math_train_counting_and_probability_437": 0.8059122562408447, "aqua_rat_24963": 0.8060426712036133, "aqua_rat_60522": 0.8060916066169739, "aqua_rat_77276": 0.8061200976371765, "math_train_counting_and_probability_249": 0.8061880469322205, "aqua_rat_57767": 0.8063990473747253, "aqua_rat_779": 0.8064531683921814, "aqua_rat_29035": 0.8064706325531006, "aqua_rat_29054": 0.8065015077590942, "aqua_rat_22458": 0.8065201044082642, "aqua_rat_47506": 0.8065370917320251, "aqua_rat_9536": 0.8066028356552124, "aqua_rat_84398": 0.8066450357437134, "aqua_rat_50830": 0.8067080974578857, "aqua_rat_12716": 0.8069167733192444, "aqua_rat_62500": 0.8070386052131653, "aqua_rat_87252": 0.8071451187133789, "aqua_rat_44130": 0.8071786761283875, "aqua_rat_53149": 0.8072009682655334, "aqua_rat_32489": 0.8072803616523743, "aqua_rat_17370": 0.8073471784591675, "aqua_rat_35078": 0.8075933456420898, "aqua_rat_74949": 0.8079237937927246, "aqua_rat_27914": 0.8080311417579651, "aqua_rat_8673": 0.8080675005912781, "aqua_rat_32212": 0.8081491589546204, "aqua_rat_83206": 0.8081641793251038, "aqua_rat_77361": 0.808596134185791, "aqua_rat_6365": 0.8086385130882263, "math_train_counting_and_probability_753": 0.8087778687477112, "aqua_rat_19534": 0.8091952204704285, "math_train_counting_and_probability_657": 0.8092650771141052, "math_train_counting_and_probability_445": 0.8094170689582825, "aqua_rat_28183": 0.8094737529754639, "aqua_rat_46365": 0.8094911575317383, "math_test_counting_and_probability_595": 0.8096520304679871, "aqua_rat_16474": 0.8099724650382996, "aqua_rat_52092": 0.8101018667221069, "aqua_rat_63254": 0.8101391196250916, "aqua_rat_74792": 0.8101577758789062, "aqua_rat_52067": 0.8103030323982239, "aqua_rat_37301": 0.8107526898384094, "aqua_rat_36385": 0.8107602596282959, "aqua_rat_61781": 0.8108294010162354, "aqua_rat_29732": 0.810846209526062, "aqua_rat_59675": 0.8108912110328674, "aqua_rat_86831": 0.8109204173088074, "aqua_rat_62725": 0.8109225630760193, "aqua_rat_26196": 0.8109771013259888, "aqua_rat_78835": 0.811113178730011, "aqua_rat_5455": 0.811231791973114, "aqua_rat_55590": 0.8113458156585693, "aqua_rat_12795": 0.811592698097229, "aqua_rat_40137": 0.8115969896316528, "aqua_rat_15917": 0.8116381168365479, "math_train_prealgebra_1975": 0.8116382956504822, "aqua_rat_8694": 0.8116915822029114, "aqua_rat_8436": 0.8117542266845703, "camel_38493": 0.8118500113487244, "aqua_rat_42412": 0.8118883967399597, "aqua_rat_52714": 0.8119090795516968, "aqua_rat_8627": 0.8119166493415833, "aqua_rat_52825": 0.8119523525238037, "aqua_rat_72582": 0.8127223253250122, "aqua_rat_23041": 0.8129222393035889, "aqua_rat_35517": 0.8131943941116333, "aqua_rat_74901": 0.8138330578804016, "aqua_rat_77730": 0.8139020204544067, "aqua_rat_22465": 0.8139076828956604, "aqua_rat_70526": 0.8143478631973267, "aqua_rat_51384": 0.8145122528076172, "aqua_rat_76251": 0.8162596821784973, "aqua_rat_7495": 0.8162989020347595, "aqua_rat_66615": 0.8170527219772339, "aqua_rat_35395": 0.8170633912086487, "aqua_rat_86063": 0.8178411722183228, "aqua_rat_82553": 0.8180593252182007, "aqua_rat_42746": 0.8184677362442017, "aqua_rat_3235": 0.8188844919204712, "aqua_rat_51723": 0.8205649256706238, "aqua_rat_39610": 0.8208109736442566, "aqua_rat_20594": 0.8219736218452454, "aqua_rat_34205": 0.822145402431488, "aqua_rat_43512": 0.824633002281189, "aqua_rat_10378": 0.8296149969100952}, "TheoremQA_wenhuchen/optics3.json": {"TheoremQA_wenhuchen/optics3.json": 0, "aqua_rat_28721": 0.6556649208068848, "aqua_rat_38989": 0.6556787490844727, "aqua_rat_9227": 0.6556965112686157, "aqua_rat_68085": 0.6557027101516724, "aqua_rat_48132": 0.6558382511138916, "aqua_rat_37409": 0.65584397315979, "aqua_rat_39223": 0.6559046506881714, "aqua_rat_2590": 0.6559125781059265, "aqua_rat_67318": 0.6560382843017578, "aqua_rat_86356": 0.6560385823249817, "aqua_rat_12925": 0.6561264991760254, "gsm_rft_15609": 0.6562392115592957, "aqua_rat_9229": 0.6562531590461731, "aqua_rat_62770": 0.6562796235084534, "gsm_train_11127": 0.656410276889801, "aqua_rat_47775": 0.6564285755157471, "aqua_rat_41216": 0.6564631462097168, "gsm_rft_27482": 0.6564704775810242, "gsm_rft_27712": 0.6564704775810242, "aqua_rat_81193": 0.6566686630249023, "aqua_rat_23067": 0.6567791104316711, "math_train_geometry_25569": 0.656787097454071, "gsm_rft_35072": 0.65688556432724, "aqua_rat_63605": 0.6570255160331726, "aqua_rat_21504": 0.6570680141448975, "aqua_rat_25149": 0.6571517586708069, "aqua_rat_35258": 0.6571767330169678, "aqua_rat_23667": 0.65733402967453, "aqua_rat_71114": 0.657340943813324, "aqua_rat_15317": 0.6573846936225891, "aqua_rat_86056": 0.6574258804321289, "aqua_rat_83862": 0.6574273705482483, "aqua_rat_79701": 0.6574347615242004, "aqua_rat_66216": 0.657508909702301, "aqua_rat_964": 0.6576111912727356, "math_train_prealgebra_1919": 0.6576274633407593, "math_test_geometry_105": 0.6578183770179749, "aqua_rat_52556": 0.6578315496444702, "aqua_rat_23202": 0.6578518152236938, "aqua_rat_64846": 0.6580706238746643, "aqua_rat_14896": 0.6581995487213135, "math_train_geometry_442": 0.6582309007644653, "aqua_rat_81188": 0.6583904027938843, "camel_19740": 0.65863037109375, "aqua_rat_34960": 0.6587365865707397, "aqua_rat_56786": 0.6588424444198608, "math_train_geometry_407": 0.6589908599853516, "gsm_train_14042": 0.6596429944038391, "gsm_rft_2688": 0.6596429944038391, "aqua_rat_19925": 0.6597245335578918, "gsm_rft_15250": 0.6599259972572327, "aqua_rat_86790": 0.6599653363227844, "aqua_rat_25668": 0.6599854230880737, "aqua_rat_29096": 0.6600691676139832, "aqua_rat_52063": 0.6601582765579224, "camel_6840": 0.6602073311805725, "aqua_rat_57177": 0.660484254360199, "aqua_rat_57888": 0.6604959964752197, "aqua_rat_29281": 0.6607465147972107, "aqua_rat_63946": 0.6607889533042908, "gsm_rft_15860": 0.66084223985672, "gsm_train_11193": 0.66084223985672, "gsm_rft_28669": 0.66084223985672, "math_train_prealgebra_1726": 0.6609216928482056, "camel_47698": 0.6614835262298584, "gsm_rft_20209": 0.6619881987571716, "gsm_rft_3001": 0.6619881987571716, "gsm_train_22328": 0.6619881987571716, "aqua_rat_36642": 0.6621598601341248, "math_train_prealgebra_725": 0.6622592210769653, "camel_47741": 0.6624172329902649, "aqua_rat_73119": 0.662503182888031, "aqua_rat_31980": 0.662787675857544, "aqua_rat_26179": 0.6630412936210632, "aqua_rat_81968": 0.6632207036018372, "aqua_rat_35477": 0.6636060476303101, "camel_4798": 0.6639088988304138, "gsm_rft_5305": 0.664459764957428, "gsm_train_22045": 0.664459764957428, "gsm_train_17974": 0.6646698713302612, "gsm_rft_4264": 0.6647396087646484, "gsm_rft_35606": 0.6647905707359314, "math_train_geometry_1101": 0.664860725402832, "aqua_rat_12010": 0.6650131344795227, "aqua_rat_6220": 0.6652447581291199, "aqua_rat_60403": 0.6653704643249512, "aqua_rat_61971": 0.6655821800231934, "aqua_rat_54504": 0.6656291484832764, "aqua_rat_84656": 0.6657596826553345, "aqua_rat_38758": 0.6658673286437988, "math_train_geometry_1022": 0.6663731336593628, "aqua_rat_30952": 0.6667109727859497, "aqua_rat_66191": 0.6668773889541626, "aqua_rat_61332": 0.6669263243675232, "aqua_rat_36249": 0.6669928431510925, "aqua_rat_20614": 0.6670892238616943, "aqua_rat_40900": 0.6671997904777527, "aqua_rat_43435": 0.6678388714790344, "aqua_rat_59988": 0.6679908633232117, "gsm_rft_23018": 0.6680821776390076, "gsm_train_14053": 0.6682255268096924, "gsm_rft_11828": 0.6682255268096924, "gsm_rft_8806": 0.6682255268096924, "aqua_rat_72645": 0.6682497262954712, "aqua_rat_52238": 0.6684247255325317, "aqua_rat_20582": 0.6684836745262146, "aqua_rat_83008": 0.6685885787010193, "aqua_rat_27170": 0.6686117053031921, "gsm_rft_33234": 0.6689454913139343, "gsm_train_21228": 0.6690781116485596, "gsm_rft_11235": 0.6690781116485596, "aqua_rat_79050": 0.669204592704773, "gsm_rft_9443": 0.6692492961883545, "aqua_rat_71816": 0.6692615151405334, "aqua_rat_74150": 0.6693546175956726, "gsm_rft_3570": 0.669619619846344, "aqua_rat_50400": 0.6696610450744629, "gsm_rft_34183": 0.669692873954773, "gsm_rft_12596": 0.6697295308113098, "aqua_rat_59927": 0.6697407960891724, "gsm_rft_15709": 0.6697558760643005, "camel_28143": 0.6698158383369446, "math_train_geometry_1": 0.6699124574661255, "math_train_geometry_804": 0.6699429750442505, "gsm_rft_8656": 0.6699478626251221, "aqua_rat_18034": 0.6703290939331055, "aqua_rat_22739": 0.6704749464988708, "aqua_rat_53114": 0.6705591082572937, "aqua_rat_18658": 0.6710425615310669, "aqua_rat_70527": 0.6711218357086182, "aqua_rat_20932": 0.6711836457252502, "aqua_rat_74461": 0.6713119149208069, "aqua_rat_6040": 0.6717175245285034, "aqua_rat_14967": 0.6717504262924194, "aqua_rat_3859": 0.6717764735221863, "aqua_rat_70483": 0.6720072031021118, "aqua_rat_10232": 0.6726413369178772, "gsm_rft_7428": 0.672774076461792, "aqua_rat_10339": 0.673618733882904, "aqua_rat_75450": 0.673760712146759, "aqua_rat_68661": 0.6743661761283875, "aqua_rat_70701": 0.6746543645858765, "math_test_prealgebra_2059": 0.6756166219711304, "aqua_rat_70812": 0.6766352653503418, "aqua_rat_25154": 0.676807701587677, "aqua_rat_70142": 0.6778982281684875, "aqua_rat_30371": 0.6798421144485474, "math_test_prealgebra_1904": 0.6805499196052551, "aqua_rat_68512": 0.6807743310928345, "aqua_rat_8162": 0.6808399558067322, "aqua_rat_28523": 0.6810697913169861, "aqua_rat_58996": 0.6814745664596558, "aqua_rat_24901": 0.6814817786216736, "aqua_rat_88321": 0.6819664835929871, "math_test_prealgebra_390": 0.6821029782295227, "math_test_prealgebra_583": 0.6821448802947998, "math_test_algebra_2160": 0.6824304461479187, "gsm_rft_8463": 0.682466983795166, "math_train_geometry_649": 0.6836764216423035, "gsm_rft_14765": 0.6838473081588745, "aqua_rat_41135": 0.6840500235557556, "aqua_rat_29187": 0.6842295527458191, "gsm_train_34815": 0.6850878596305847, "gsm_rft_28133": 0.6850878596305847, "aqua_rat_29369": 0.6851248145103455, "aqua_rat_33103": 0.6852740049362183, "aqua_rat_32781": 0.6870204210281372, "aqua_rat_33439": 0.687160313129425, "gsm_rft_11389": 0.6875709295272827, "aqua_rat_7754": 0.6882301568984985, "aqua_rat_66436": 0.6888982057571411, "gsm_rft_14244": 0.6890066862106323, "aqua_rat_72372": 0.6925638318061829, "camel_5527": 0.6930045485496521, "math_train_prealgebra_1701": 0.6950154304504395, "math_test_geometry_151": 0.6960098147392273, "aqua_rat_60805": 0.6977953314781189, "aqua_rat_46971": 0.7005012035369873, "aqua_rat_30186": 0.7020761966705322, "aqua_rat_83857": 0.7026677131652832, "aqua_rat_22618": 0.7030819058418274, "aqua_rat_83787": 0.7032319903373718, "aqua_rat_8530": 0.7036176919937134, "aqua_rat_25937": 0.7046657800674438, "aqua_rat_2228": 0.7062163949012756, "camel_49646": 0.7071061134338379, "aqua_rat_37605": 0.7078080177307129, "aqua_rat_12240": 0.7088770270347595, "aqua_rat_55057": 0.7089560031890869, "aqua_rat_18718": 0.7119536399841309, "aqua_rat_69962": 0.713767945766449, "gsm_rft_7733": 0.7172126770019531, "gsm_train_19077": 0.7179000377655029, "gsm_rft_17748": 0.7179000377655029, "camel_4737": 0.7195115685462952, "camel_4771": 0.7235825657844543, "camel_4808": 0.7346059679985046, "TheoremQA_wenhuchen/optics7.json": 0.7758011817932129, "TheoremQA_wenhuchen/optics2.json": 0.7787835001945496}, "TheoremQA_elainewan/math_algebra_7_2.json": {"camel_14459": 0, "camel_14402": 0, "camel_14542": 0, "camel_14551": 0, "camel_14504": 0, "camel_14534": 0, "camel_14467": 0, "camel_14452": 0, "camel_14545": 0, "camel_14441": 0, "camel_14501": 0, "camel_14506": 0, "camel_14521": 0, "camel_14507": 0, "camel_14487": 0, "camel_14417": 0, "camel_14449": 0, "camel_14529": 0, "camel_14536": 0, "camel_14498": 0, "TheoremQA_elainewan/math_algebra_7_2.json": 0, "camel_19973": 0.5995554327964783, "TheoremQA_elainewan/math_algebra_4_3.json": 0.5995928049087524, "camel_32635": 0.5996004343032837, "camel_23071": 0.5996331572532654, "camel_47805": 0.5997490286827087, "camel_36766": 0.5998255014419556, "camel_28786": 0.6001513004302979, "camel_19961": 0.6001744866371155, "TheoremQA_mingyin/compact-operator-theorem1.json": 0.6001940369606018, "camel_19993": 0.6002040505409241, "camel_29617": 0.600216805934906, "camel_29130": 0.6003121733665466, "camel_47789": 0.6003910303115845, "camel_47729": 0.600396990776062, "camel_47774": 0.6004429459571838, "camel_49853": 0.6005845069885254, "camel_47693": 0.6005887389183044, "camel_19982": 0.600818932056427, "camel_23533": 0.6008268594741821, "camel_47803": 0.600848913192749, "camel_29550": 0.6009752154350281, "camel_23527": 0.6011723279953003, "camel_47822": 0.6011842489242554, "TheoremQA_xinyi/channel_capacity_3.json": 0.6012705564498901, "camel_23573": 0.6014199256896973, "camel_49882": 0.6015776991844177, "camel_49856": 0.6016085743904114, "camel_29642": 0.6018576622009277, "camel_37452": 0.6018766760826111, "camel_19978": 0.6022068858146667, "camel_20970": 0.6022213101387024, "camel_19936": 0.6022786498069763, "camel_21012": 0.6023019552230835, "camel_26505": 0.6025213003158569, "camel_47763": 0.6025970578193665, "camel_47795": 0.602806031703949, "camel_29676": 0.602942168712616, "camel_49894": 0.6031447649002075, "camel_19935": 0.6033629775047302, "camel_29596": 0.6033712029457092, "camel_19714": 0.6034027934074402, "camel_29523": 0.6035622358322144, "camel_37318": 0.6044396162033081, "camel_32077": 0.6045135855674744, "camel_32526": 0.604532778263092, "camel_23536": 0.6046531796455383, "camel_47684": 0.6049071550369263, "camel_19933": 0.6049142479896545, "camel_49884": 0.6049757599830627, "camel_49896": 0.6049776673316956, "camel_23525": 0.605049729347229, "camel_19984": 0.6050624251365662, "camel_29630": 0.605279803276062, "camel_49888": 0.6054908633232117, "camel_47786": 0.6059741377830505, "camel_47732": 0.6062236428260803, "camel_23564": 0.6062961220741272, "camel_20960": 0.6063328981399536, "camel_23553": 0.6063632369041443, "camel_49861": 0.6065531373023987, "camel_29628": 0.6068239808082581, "camel_29327": 0.6068383455276489, "camel_9503": 0.6069638729095459, "camel_47773": 0.6069832444190979, "camel_20969": 0.6069987416267395, "camel_19928": 0.6071649193763733, "camel_23554": 0.6072328090667725, "camel_29321": 0.6072676181793213, "camel_30467": 0.6073703169822693, "camel_23569": 0.6073817014694214, "camel_47730": 0.6076768636703491, "camel_23597": 0.6079113483428955, "camel_29615": 0.6079639792442322, "camel_29186": 0.6081432700157166, "camel_19999": 0.6082010865211487, "camel_47817": 0.6084555983543396, "camel_29799": 0.6087072491645813, "camel_19985": 0.608932614326477, "camel_27398": 0.6089655756950378, "camel_27500": 0.6090118288993835, "camel_20964": 0.6090981960296631, "camel_47772": 0.6091071367263794, "camel_23114": 0.6094599366188049, "camel_19929": 0.6097195148468018, "camel_29661": 0.6098142266273499, "camel_23576": 0.6100785136222839, "camel_40126": 0.6101925373077393, "camel_21003": 0.6102810502052307, "camel_21349": 0.6103628873825073, "camel_49852": 0.6104113459587097, "camel_19998": 0.6106020212173462, "TheoremQA_elainewan/math_algebra_3_5.json": 0.6108131408691406, "camel_49850": 0.6108660101890564, "camel_47775": 0.6111235618591309, "camel_28747": 0.6119844317436218, "camel_21025": 0.6122000217437744, "camel_47771": 0.612318754196167, "camel_23530": 0.6124491095542908, "camel_23546": 0.6125540733337402, "camel_23067": 0.6133607625961304, "camel_29658": 0.6133831739425659, "camel_28412": 0.6135963201522827, "camel_49985": 0.6136902570724487, "camel_47827": 0.6144541501998901, "camel_47760": 0.6148509383201599, "camel_47764": 0.6150978207588196, "camel_47787": 0.6155750155448914, "camel_47756": 0.6155771017074585, "camel_19986": 0.6155880689620972, "camel_21016": 0.615768551826477, "camel_19989": 0.616802453994751, "camel_47724": 0.617047131061554, "camel_19977": 0.6173237562179565, "camel_23523": 0.6175180673599243, "camel_23575": 0.6175698637962341, "camel_49842": 0.6181068420410156, "camel_47800": 0.6186257004737854, "camel_47691": 0.6193145513534546, "camel_49881": 0.619714617729187, "camel_48834": 0.6200875043869019, "camel_32950": 0.6201271414756775, "camel_23543": 0.620663046836853, "camel_47755": 0.6208378076553345, "camel_47811": 0.6216588616371155, "camel_19983": 0.6217093467712402, "camel_47783": 0.6218731999397278, "camel_47781": 0.6220743656158447, "camel_49885": 0.6222860813140869, "camel_19938": 0.6223848462104797, "camel_47788": 0.6226502656936646, "camel_36756": 0.6238667368888855, "camel_23549": 0.6243171095848083, "camel_47784": 0.6248219609260559, "camel_19922": 0.6249292492866516, "camel_40112": 0.6258374452590942, "camel_19018": 0.6260671019554138, "camel_47713": 0.626594066619873, "camel_47799": 0.6274635195732117, "camel_49935": 0.6277896165847778, "camel_47793": 0.6280269622802734, "camel_47837": 0.628175675868988, "camel_49865": 0.6286067962646484, "camel_49891": 0.6286428570747375, "camel_23556": 0.6291123032569885, "camel_47826": 0.6297819018363953, "camel_47777": 0.6305691003799438, "camel_49909": 0.6311149001121521, "TheoremQA_elainewan/math_algebra_7.json": 0.6314384341239929, "camel_49866": 0.6319840550422668, "camel_40117": 0.6326515078544617, "camel_49887": 0.632749617099762, "TheoremQA_elainewan/math_algebra_6.json": 0.6331226825714111, "camel_47707": 0.6334872245788574, "TheoremQA_elainewan/math_algebra_4.json": 0.6339390277862549, "camel_49906": 0.635112464427948, "camel_36754": 0.6353940367698669, "camel_23542": 0.6357495784759521, "camel_47776": 0.6379799246788025, "camel_19944": 0.638430655002594, "camel_49883": 0.6386527419090271, "camel_23558": 0.6387019157409668, "camel_40110": 0.6389404535293579, "camel_47834": 0.6395429968833923, "camel_47810": 0.6403708457946777, "camel_40139": 0.6409719586372375, "TheoremQA_mingyin/cayley-theorem1.json": 0.6412176489830017, "camel_47801": 0.642487645149231, "camel_49900": 0.6429678201675415, "camel_47780": 0.6444252133369446, "camel_47838": 0.6481369733810425, "camel_47830": 0.6492201685905457, "camel_47828": 0.6505147218704224, "camel_19981": 0.6515502333641052, "camel_47761": 0.6576291918754578, "camel_40155": 0.6611664891242981, "camel_40119": 0.6616912484169006, "camel_19972": 0.6641814112663269, "camel_47814": 0.6663617491722107, "camel_49871": 0.6779412627220154}, "TheoremQA_mingyin/Limit-of-sequence3.json": {"TheoremQA_mingyin/Limit-of-sequence3.json": 0, "aqua_rat_67794": 0.6539576053619385, "aqua_rat_69455": 0.6539673805236816, "gsm_rft_34326": 0.6539767384529114, "aqua_rat_53042": 0.6541146636009216, "camel_30847": 0.6541905999183655, "aqua_rat_56337": 0.6542124152183533, "camel_37577": 0.6543744206428528, "aqua_rat_76697": 0.6544427871704102, "gsm_train_8464": 0.6544786095619202, "aqua_rat_70145": 0.6546151638031006, "gsm_rft_20038": 0.6546950340270996, "aqua_rat_344": 0.6546950340270996, "aqua_rat_30585": 0.654718816280365, "aqua_rat_10334": 0.654820442199707, "gsm_train_6685": 0.6548570990562439, "gsm_rft_2696": 0.6548624038696289, "aqua_rat_33515": 0.6550366878509521, "math_test_counting_and_probability_788": 0.6553659439086914, "aqua_rat_37074": 0.6554011702537537, "gsm_rft_24023": 0.6554480791091919, "aqua_rat_10066": 0.655547022819519, "aqua_rat_37275": 0.6556462645530701, "camel_31759": 0.6556826829910278, "aqua_rat_50530": 0.6558899879455566, "aqua_rat_36662": 0.6558908224105835, "math_train_algebra_24402": 0.655921459197998, "camel_31084": 0.6559820771217346, "aqua_rat_24127": 0.6561900973320007, "gsm_rft_19857": 0.6561955213546753, "aqua_rat_55848": 0.6562055349349976, "gsm_rft_33375": 0.6562593579292297, "aqua_rat_88395": 0.6563172340393066, "gsm_rft_31879": 0.6563265919685364, "aqua_rat_60848": 0.6565016508102417, "math_train_algebra_1877": 0.6565618515014648, "aqua_rat_21417": 0.6565940380096436, "aqua_rat_5221": 0.6566452383995056, "camel_30372": 0.6569020748138428, "aqua_rat_81406": 0.6569363474845886, "aqua_rat_69542": 0.6569398641586304, "aqua_rat_11729": 0.6569851636886597, "aqua_rat_66319": 0.6571274399757385, "aqua_rat_21597": 0.6571782231330872, "gsm_rft_5470": 0.6572378873825073, "aqua_rat_48885": 0.6572601199150085, "gsm_train_33618": 0.657710075378418, "gsm_rft_4619": 0.657710075378418, "math_train_algebra_1292": 0.6579135060310364, "camel_30865": 0.658017635345459, "gsm_train_5473": 0.6581353545188904, "aqua_rat_17328": 0.6582046747207642, "aqua_rat_56920": 0.6582620739936829, "aqua_rat_45": 0.6583017110824585, "aqua_rat_21640": 0.6584242582321167, "gsm_rft_16300": 0.6584506034851074, "gsm_rft_24521": 0.6585512161254883, "aqua_rat_8383": 0.6586769819259644, "aqua_rat_25051": 0.6586998701095581, "camel_30374": 0.6587401032447815, "gsm_rft_18583": 0.6588550806045532, "aqua_rat_34453": 0.6590121984481812, "aqua_rat_76253": 0.6590334177017212, "aqua_rat_63318": 0.6592462062835693, "gsm_train_29852": 0.6592639088630676, "gsm_rft_14194": 0.6592639088630676, "aqua_rat_54421": 0.6593227982521057, "gsm_rft_33461": 0.6593624949455261, "gsm_rft_30287": 0.6593624949455261, "gsm_train_30635": 0.6593624949455261, "camel_31973": 0.6593629121780396, "gsm_rft_18213": 0.6594747304916382, "camel_37529": 0.6595414876937866, "aqua_rat_70284": 0.6596559882164001, "aqua_rat_47509": 0.6600398421287537, "aqua_rat_16214": 0.6601444482803345, "camel_8607": 0.6602842807769775, "aqua_rat_53638": 0.6603490710258484, "aqua_rat_45141": 0.6603758335113525, "aqua_rat_68972": 0.6604350805282593, "gsm_train_5852": 0.6604651808738708, "aqua_rat_82082": 0.6605966091156006, "aqua_rat_9645": 0.6606395840644836, "aqua_rat_65452": 0.6607106924057007, "aqua_rat_36838": 0.6607475876808167, "camel_20541": 0.6607701182365417, "gsm_rft_9838": 0.6608871817588806, "aqua_rat_43274": 0.6608919501304626, "aqua_rat_74957": 0.6612395644187927, "camel_30858": 0.661662220954895, "aqua_rat_27432": 0.6616735458374023, "aqua_rat_37866": 0.6616913676261902, "aqua_rat_981": 0.6617029905319214, "camel_31863": 0.6620033383369446, "camel_30409": 0.6621298789978027, "aqua_rat_4875": 0.6622065901756287, "math_train_prealgebra_1815": 0.6622348427772522, "aqua_rat_37202": 0.6623507738113403, "aqua_rat_78042": 0.6624011397361755, "math_train_algebra_627": 0.6626623272895813, "math_train_algebra_1966": 0.6626746654510498, "camel_30770": 0.6628742814064026, "camel_30440": 0.6628889441490173, "math_train_algebra_881": 0.6631062626838684, "gsm_rft_30067": 0.6631109118461609, "gsm_rft_17172": 0.6631450057029724, "aqua_rat_75406": 0.6632256507873535, "gsm_train_3141": 0.6632434725761414, "gsm_rft_20603": 0.6632434725761414, "gsm_rft_1517": 0.6633225083351135, "gsm_rft_8154": 0.6633365154266357, "aqua_rat_46101": 0.6633947491645813, "gsm_rft_2825": 0.6634267568588257, "gsm_rft_6577": 0.6635181307792664, "aqua_rat_22511": 0.6635563969612122, "gsm_rft_31508": 0.6636894941329956, "aqua_rat_24028": 0.6638028025627136, "gsm_rft_8650": 0.6638599634170532, "camel_20542": 0.6640352010726929, "camel_37559": 0.6644978523254395, "gsm_train_29119": 0.6645262837409973, "gsm_rft_25490": 0.6645483374595642, "gsm_rft_30593": 0.6645483374595642, "gsm_train_28517": 0.6645483374595642, "gsm_rft_8568": 0.6645483374595642, "gsm_rft_31585": 0.6646685004234314, "gsm_rft_23410": 0.6647009253501892, "camel_31858": 0.664771318435669, "gsm_rft_35422": 0.6648236513137817, "gsm_rft_35572": 0.6648393869400024, "math_train_algebra_2250": 0.6651094555854797, "gsm_rft_8043": 0.6652932167053223, "math_train_intermediate_algebra_353": 0.6654287576675415, "gsm_rft_29504": 0.665441632270813, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus2.json": 0.6654937267303467, "aqua_rat_73502": 0.6655049324035645, "gsm_rft_34878": 0.6655228137969971, "math_test_algebra_1263": 0.665709376335144, "aqua_rat_46992": 0.6657381057739258, "camel_8613": 0.6657840013504028, "aqua_rat_31892": 0.6659995317459106, "gsm_train_27451": 0.6661587357521057, "gsm_rft_21385": 0.6661802530288696, "aqua_rat_62279": 0.6662196516990662, "aqua_rat_4435": 0.6662247180938721, "gsm_rft_17589": 0.6665764451026917, "gsm_rft_24785": 0.6666944622993469, "gsm_train_4543": 0.6669329404830933, "gsm_rft_2391": 0.6669329404830933, "aqua_rat_73910": 0.6669589877128601, "gsm_rft_15321": 0.6673359274864197, "camel_20527": 0.6674016118049622, "gsm_rft_25139": 0.6675108671188354, "aqua_rat_11234": 0.66783207654953, "math_train_algebra_1995": 0.6683627963066101, "aqua_rat_6250": 0.6683958768844604, "camel_30341": 0.6687510013580322, "aqua_rat_55051": 0.6689541339874268, "gsm_rft_32231": 0.6690914630889893, "camel_30050": 0.6691531538963318, "gsm_rft_18655": 0.6694542169570923, "gsm_rft_27342": 0.6700824499130249, "math_train_algebra_2479": 0.6702195405960083, "camel_37546": 0.6706094741821289, "math_test_algebra_2100": 0.6720972657203674, "aqua_rat_64676": 0.672304093837738, "camel_31987": 0.6725029349327087, "gsm_rft_24531": 0.6726416349411011, "math_test_algebra_1957": 0.6727434396743774, "aqua_rat_69628": 0.6730610728263855, "math_train_algebra_553": 0.6733823418617249, "math_test_algebra_901": 0.6738192439079285, "gsm_rft_31016": 0.6743084788322449, "camel_37591": 0.6746668219566345, "aqua_rat_35341": 0.6750972867012024, "aqua_rat_82861": 0.67562335729599, "camel_37567": 0.6757640838623047, "aqua_rat_53870": 0.676347017288208, "camel_37547": 0.6765190958976746, "camel_37594": 0.6774619221687317, "camel_20481": 0.6778935790061951, "camel_30740": 0.6778979897499084, "math_train_algebra_457": 0.6790480017662048, "math_test_algebra_2664": 0.6799343824386597, "aqua_rat_61662": 0.681205153465271, "aqua_rat_83193": 0.6828210949897766, "math_train_intermediate_algebra_454": 0.6830322742462158, "aqua_rat_1271": 0.6836140155792236, "gsm_rft_3078": 0.6836662888526917, "aqua_rat_13223": 0.6852937340736389, "gsm_train_29573": 0.6891130208969116, "gsm_rft_9427": 0.6891130208969116, "aqua_rat_16186": 0.6909591555595398, "math_test_algebra_1184": 0.6910608410835266, "aqua_rat_33076": 0.6982405185699463, "aqua_rat_88394": 0.6999598741531372, "aqua_rat_31829": 0.7005456686019897, "aqua_rat_3097": 0.7060932517051697, "aqua_rat_5634": 0.7108817100524902, "camel_28309": 0.7138649821281433}, "TheoremQA_maxku/graphtheory6-shortestpath.json": {"camel_39941": 0, "camel_38608": 0, "camel_22842": 0, "camel_21634": 0, "camel_21612": 0, "camel_22078": 0, "camel_22387": 0, "camel_22390": 0, "camel_22328": 0, "camel_39964": 0, "camel_22047": 0, "camel_22857": 0, "camel_21667": 0, "camel_22026": 0, "camel_22037": 0, "camel_23982": 0, "camel_22012": 0, "camel_22002": 0, "camel_22036": 0, "camel_22247": 0, "camel_38906": 0, "camel_23410": 0, "camel_22467": 0, "camel_39946": 0, "camel_39932": 0, "camel_22032": 0, "camel_21664": 0, "camel_22039": 0, "camel_23970": 0, "camel_23924": 0, "camel_22831": 0, "camel_22030": 0, "camel_22066": 0, "camel_39960": 0, "camel_22064": 0, "camel_21663": 0, "camel_22841": 0, "camel_22294": 0, "camel_21678": 0, "camel_38501": 0, "camel_22252": 0, "camel_22856": 0, "camel_22345": 0, "camel_21658": 0, "camel_23942": 0, "camel_23983": 0, "camel_23193": 0, "camel_22384": 0, "camel_23981": 0, "camel_22860": 0, "camel_23961": 0, "camel_23991": 0, "camel_38576": 0, "camel_23967": 0, "camel_22075": 0, "camel_21654": 0, "camel_22020": 0, "camel_22240": 0, "camel_23973": 0, "camel_22074": 0, "camel_38615": 0, "camel_23928": 0, "camel_38621": 0, "camel_38564": 0, "camel_22340": 0, "camel_38572": 0, "camel_22007": 0, "camel_22870": 0, "camel_22335": 0, "camel_22058": 0, "camel_22821": 0, "camel_22316": 0, "camel_22854": 0, "camel_22018": 0, "camel_22044": 0, "camel_22800": 0, "camel_22395": 0, "camel_22874": 0, "camel_22033": 0, "camel_22835": 0, "camel_38585": 0, "camel_22014": 0, "camel_39999": 0, "camel_22350": 0, "camel_22059": 0, "camel_22449": 0, "camel_22023": 0, "camel_22041": 0, "camel_22053": 0, "camel_22829": 0, "camel_22826": 0, "camel_22810": 0, "camel_22397": 0, "camel_22417": 0, "camel_22069": 0, "camel_22077": 0, "camel_23143": 0, "camel_22398": 0, "camel_22001": 0, "camel_22008": 0, "camel_39959": 0, "camel_22027": 0, "camel_22009": 0, "camel_22326": 0, "camel_22035": 0, "camel_23980": 0, "camel_23184": 0, "camel_22079": 0, "camel_38609": 0, "camel_22296": 0, "camel_22875": 0, "camel_22025": 0, "camel_22354": 0, "camel_22017": 0, "camel_38560": 0, "camel_22067": 0, "camel_22034": 0, "camel_22046": 0, "camel_22004": 0, "camel_22003": 0, "camel_22019": 0, "camel_22056": 0, "camel_22809": 0, "camel_22070": 0, "camel_22807": 0, "camel_22024": 0, "camel_23947": 0, "camel_22051": 0, "camel_22054": 0, "camel_22000": 0, "camel_22005": 0, "camel_38630": 0, "camel_21628": 0, "camel_22043": 0, "camel_22065": 0, "camel_22818": 0, "camel_21610": 0, "camel_22021": 0, "camel_39952": 0, "camel_22847": 0, "camel_23409": 0, "camel_39997": 0, "camel_23957": 0, "camel_22330": 0, "camel_22062": 0, "camel_38489": 0, "camel_22873": 0, "camel_39920": 0, "camel_38619": 0, "camel_22016": 0, "camel_22859": 0, "camel_39938": 0, "camel_22363": 0, "camel_22076": 0, "camel_22861": 0, "camel_22052": 0, "camel_39998": 0, "camel_22040": 0, "camel_22028": 0, "camel_38581": 0, "camel_22802": 0, "camel_22073": 0, "camel_22055": 0, "camel_22868": 0, "camel_22329": 0, "camel_22011": 0, "camel_22300": 0, "camel_22029": 0, "camel_22279": 0, "camel_39996": 0, "camel_39983": 0, "camel_22010": 0, "camel_22049": 0, "camel_22361": 0, "camel_39977": 0, "camel_22367": 0, "camel_22068": 0, "camel_22022": 0, "camel_22061": 0, "camel_22344": 0, "camel_22006": 0, "camel_22324": 0, "camel_22031": 0, "camel_21641": 0, "camel_23127": 0, "camel_22015": 0, "camel_23997": 0, "camel_22057": 0, "camel_22806": 0, "camel_22368": 0, "camel_22332": 0, "camel_22038": 0, "camel_39974": 0, "camel_22060": 0, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0, "camel_22071": 0, "camel_41246": 0.7726103067398071, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": 0.8204633593559265, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0.8278031945228577, "TheoremQA_maxku/graphtheory7-shortestpath.json": 0.83465975522995}, "TheoremQA_elainewan/math_calculus_2_7.json": {"camel_7205": 0, "camel_7272": 0, "TheoremQA_elainewan/math_calculus_2_7.json": 0, "camel_7251": 0, "camel_18334": 0.6256762146949768, "camel_29122": 0.6256997585296631, "camel_28604": 0.6257866024971008, "aqua_rat_29707": 0.6258893609046936, "camel_28150": 0.6260188221931458, "camel_28634": 0.6261030435562134, "aqua_rat_9211": 0.6264037489891052, "camel_1746": 0.6267005801200867, "camel_28309": 0.626716136932373, "aqua_rat_18406": 0.6267557144165039, "camel_18142": 0.6268031001091003, "camel_19483": 0.6268672943115234, "camel_25575": 0.6268841028213501, "camel_28395": 0.6272367238998413, "camel_25564": 0.6273190379142761, "camel_40957": 0.6273643374443054, "camel_25596": 0.6274681687355042, "camel_28086": 0.627477765083313, "camel_41684": 0.6276443004608154, "camel_25556": 0.6276510953903198, "camel_25530": 0.6276844143867493, "camel_17413": 0.6277067065238953, "camel_28295": 0.6279094815254211, "camel_40676": 0.6279453039169312, "camel_18146": 0.6281564235687256, "camel_42030": 0.6282375454902649, "camel_40781": 0.6282504200935364, "aqua_rat_50162": 0.6282846927642822, "aqua_rat_74410": 0.628348708152771, "aqua_rat_68943": 0.6284660696983337, "camel_18100": 0.6286128163337708, "camel_29058": 0.6287631988525391, "camel_18034": 0.6290648579597473, "camel_18317": 0.6291539669036865, "camel_39465": 0.6293467283248901, "camel_18136": 0.6294357180595398, "camel_25591": 0.6294716000556946, "camel_28609": 0.629523754119873, "camel_18098": 0.6295556426048279, "aqua_rat_41618": 0.6296166181564331, "camel_40647": 0.6296182870864868, "camel_18117": 0.6296723484992981, "camel_18074": 0.6298205852508545, "aqua_rat_69644": 0.6299028992652893, "camel_25550": 0.6300272941589355, "camel_39125": 0.6300342082977295, "camel_28606": 0.630315899848938, "aqua_rat_89266": 0.6304068565368652, "aqua_rat_31164": 0.6306192278862, "camel_18266": 0.6308299899101257, "camel_28511": 0.6309051513671875, "aqua_rat_40603": 0.6311519742012024, "camel_28776": 0.6312210559844971, "aqua_rat_83148": 0.6313101649284363, "camel_25599": 0.6319761276245117, "camel_30166": 0.6323173642158508, "camel_29097": 0.6323471069335938, "camel_28316": 0.6323763132095337, "camel_30217": 0.632413387298584, "aqua_rat_29953": 0.6324147582054138, "camel_25594": 0.6325739622116089, "aqua_rat_30425": 0.632601261138916, "aqua_rat_2082": 0.6326257586479187, "camel_18139": 0.6327491402626038, "camel_18094": 0.6327493190765381, "camel_25558": 0.633146345615387, "camel_31459": 0.6331787109375, "math_test_prealgebra_1243": 0.6332354545593262, "camel_19558": 0.6336531043052673, "camel_25573": 0.6337106227874756, "aqua_rat_12456": 0.633902907371521, "camel_25565": 0.6340177059173584, "aqua_rat_19340": 0.6341114044189453, "camel_18154": 0.6343395113945007, "camel_25548": 0.6344181895256042, "camel_17545": 0.6344946026802063, "camel_18275": 0.6345754861831665, "aqua_rat_8153": 0.634727418422699, "camel_18103": 0.6353396773338318, "camel_18244": 0.635382890701294, "camel_17385": 0.6354899406433105, "camel_18085": 0.6359618306159973, "aqua_rat_59695": 0.6361715197563171, "camel_25552": 0.6365283727645874, "camel_18156": 0.637144923210144, "camel_25595": 0.6375455856323242, "aqua_rat_79963": 0.6375609636306763, "math_test_algebra_2628": 0.6378101706504822, "camel_1528": 0.6379985809326172, "camel_18307": 0.6380776166915894, "camel_28433": 0.6381869316101074, "camel_30887": 0.6382465362548828, "camel_18081": 0.638451874256134, "camel_25578": 0.6384905576705933, "camel_25569": 0.6388697028160095, "camel_18246": 0.6390370726585388, "aqua_rat_71774": 0.6390830874443054, "aqua_rat_66644": 0.6390939950942993, "camel_18203": 0.6396228671073914, "camel_25590": 0.6400227546691895, "camel_28825": 0.6401812434196472, "camel_25568": 0.6405848860740662, "camel_18153": 0.6412280201911926, "camel_28216": 0.6413827538490295, "camel_18058": 0.6422524452209473, "camel_39357": 0.6425625681877136, "camel_18248": 0.6425807476043701, "camel_18300": 0.6428090929985046, "camel_28304": 0.6429643630981445, "camel_28810": 0.6432100534439087, "camel_18138": 0.6432671546936035, "camel_18399": 0.6433792114257812, "camel_25583": 0.6434352397918701, "camel_25589": 0.6435697674751282, "camel_28100": 0.6440306305885315, "TheoremQA_elainewan/math_calculus_2_10.json": 0.6442761421203613, "camel_25526": 0.6445987224578857, "camel_28177": 0.6450655460357666, "camel_18105": 0.6450697779655457, "camel_25561": 0.6452363729476929, "camel_18222": 0.6454042792320251, "camel_18120": 0.6454997062683105, "camel_18312": 0.6455965638160706, "camel_25545": 0.6456682682037354, "camel_18012": 0.6460951566696167, "camel_28842": 0.6462945342063904, "TheoremQA_xueguangma/rolle_theorem.json": 0.6463691592216492, "aqua_rat_38830": 0.6464753746986389, "TheoremQA_elainewan/math_real_analysis_additional_1.json": 0.6465886235237122, "camel_30318": 0.6466283798217773, "camel_18132": 0.6466944813728333, "camel_19813": 0.6467511057853699, "camel_25536": 0.647083044052124, "camel_25525": 0.6471989154815674, "camel_30916": 0.6476184725761414, "camel_18069": 0.6478002071380615, "camel_25534": 0.6483821272850037, "camel_28080": 0.6488650441169739, "camel_18088": 0.648888349533081, "camel_25560": 0.6490968465805054, "camel_18115": 0.6498484015464783, "camel_17416": 0.6506174802780151, "camel_28821": 0.6506468057632446, "camel_25524": 0.6510233879089355, "camel_18152": 0.6512483358383179, "camel_18945": 0.6512830853462219, "camel_18095": 0.651374101638794, "camel_40760": 0.6515496373176575, "camel_25579": 0.6520915627479553, "camel_25587": 0.6521516442298889, "camel_25559": 0.6526862978935242, "camel_25581": 0.6528493762016296, "camel_25551": 0.6534578800201416, "TheoremQA_elainewan/math_calculus_2_11.json": 0.6535244584083557, "camel_18083": 0.6540957093238831, "camel_18070": 0.6546565294265747, "camel_18127": 0.6547831892967224, "camel_25547": 0.6548126339912415, "camel_25574": 0.6555187702178955, "aqua_rat_80489": 0.6559668183326721, "camel_25544": 0.6567695736885071, "camel_18936": 0.6569341421127319, "TheoremQA_elainewan/math_real_analysis_additional_2.json": 0.6574757695198059, "camel_25577": 0.6577935218811035, "camel_18318": 0.6599739789962769, "camel_25523": 0.6602435111999512, "camel_25555": 0.6611579656600952, "camel_18272": 0.6611753106117249, "aqua_rat_11769": 0.6616682410240173, "camel_29080": 0.662749707698822, "camel_30926": 0.6630393266677856, "camel_25585": 0.6635589599609375, "aqua_rat_77759": 0.6637583374977112, "camel_18893": 0.6640617251396179, "camel_25597": 0.6651621460914612, "camel_25542": 0.6660038232803345, "camel_25933": 0.6671118140220642, "camel_25584": 0.6677066683769226, "camel_25522": 0.6679797172546387, "camel_18092": 0.6689375638961792, "TheoremQA_wenhuchen/L'H\u00f4pital_rule2.json": 0.6695471405982971, "camel_25533": 0.6695783734321594, "camel_25541": 0.6697558164596558, "camel_25528": 0.6699051260948181, "camel_25540": 0.6705324649810791, "camel_18302": 0.6707638502120972, "camel_25539": 0.6714723706245422, "camel_25538": 0.6723942756652832, "camel_18909": 0.676247239112854, "camel_18957": 0.6765354871749878, "aqua_rat_11272": 0.6768512725830078, "aqua_rat_49646": 0.6848478317260742, "camel_25572": 0.6850195527076721, "camel_18047": 0.6865501999855042, "camel_18122": 0.6883434653282166, "camel_18130": 0.7033022046089172}, "TheoremQA_panlu/wave_length1.json": {"camel_17772": 0, "camel_16266": 0, "camel_16583": 0, "camel_16579": 0, "camel_16589": 0, "camel_16283": 0, "camel_16563": 0, "camel_17347": 0, "camel_16569": 0, "camel_17288": 0, "camel_16617": 0, "camel_16619": 0, "camel_16597": 0, "camel_16606": 0, "camel_16561": 0, "camel_16621": 0, "camel_16588": 0, "camel_16565": 0, "camel_16622": 0, "camel_16598": 0, "camel_16613": 0, "camel_16627": 0, "camel_16624": 0, "camel_16572": 0, "camel_16616": 0, "camel_16562": 0, "camel_16573": 0, "camel_16632": 0, "camel_16634": 0, "camel_16587": 0, "camel_16637": 0, "camel_16560": 0, "camel_16564": 0, "camel_16577": 0, "camel_16609": 0, "camel_16605": 0, "camel_16568": 0, "camel_16603": 0, "camel_16628": 0, "camel_16571": 0, "camel_16567": 0, "camel_16618": 0, "camel_16570": 0, "TheoremQA_panlu/wave_length1.json": 0, "camel_16581": 0, "camel_17811": 0, "camel_16615": 0, "camel_17798": 0, "camel_16602": 0, "camel_16626": 0, "camel_16590": 0, "camel_16608": 0, "camel_16623": 0, "camel_16636": 0, "camel_16592": 0, "camel_17298": 0, "camel_16586": 0, "camel_16596": 0, "camel_16575": 0, "camel_45681": 0.6882666349411011, "gsm_rft_17385": 0.6887891292572021, "camel_5261": 0.6889715790748596, "camel_5096": 0.6890208125114441, "camel_5228": 0.6894145607948303, "camel_45191": 0.6894634366035461, "aqua_rat_23930": 0.6895698308944702, "aqua_rat_68514": 0.6897841691970825, "camel_5255": 0.6899656653404236, "camel_5167": 0.690217912197113, "camel_5048": 0.6903322339057922, "aqua_rat_7310": 0.6906804442405701, "TheoremQA_tonyxia/wave2.json": 0.6909483671188354, "camel_5089": 0.6911673545837402, "camel_45153": 0.6920492649078369, "aqua_rat_56296": 0.6920588612556458, "camel_45288": 0.692254364490509, "camel_5271": 0.6922877430915833, "camel_5143": 0.6929343342781067, "camel_5052": 0.6930640935897827, "camel_5068": 0.6933468580245972, "camel_5098": 0.693712592124939, "camel_45334": 0.6948224902153015, "camel_5079": 0.6950215101242065, "camel_5185": 0.6952475309371948, "camel_5276": 0.6967751979827881, "aqua_rat_8197": 0.6977877020835876, "camel_43827": 0.6980199217796326, "camel_45196": 0.6984796524047852, "camel_45135": 0.6985272169113159, "aqua_rat_16469": 0.6986691355705261, "camel_45999": 0.6993725299835205, "camel_5181": 0.6996897459030151, "camel_45144": 0.6997108459472656, "camel_45315": 0.7003247141838074, "camel_5178": 0.7007079720497131, "camel_5041": 0.7008081078529358, "camel_5078": 0.7008111476898193, "camel_44806": 0.7008359432220459, "camel_5029": 0.700846254825592, "camel_5234": 0.7010021805763245, "aqua_rat_35471": 0.7021544575691223, "camel_5133": 0.7021872401237488, "camel_5232": 0.7026320695877075, "camel_5136": 0.7031396627426147, "camel_5113": 0.7032277584075928, "camel_5043": 0.7036116719245911, "camel_45992": 0.7037164568901062, "camel_4965": 0.7038199305534363, "camel_5209": 0.7038915157318115, "camel_5237": 0.7048267722129822, "aqua_rat_76776": 0.7056058645248413, "camel_45357": 0.7057555913925171, "camel_5092": 0.706552267074585, "camel_45142": 0.7066740393638611, "camel_45194": 0.7072621583938599, "camel_5134": 0.7074478268623352, "camel_5158": 0.7077147960662842, "camel_43783": 0.7077631950378418, "camel_45299": 0.7079327702522278, "camel_5129": 0.7083837389945984, "camel_5172": 0.7089369297027588, "camel_29154": 0.7091423869132996, "aqua_rat_81926": 0.7093102335929871, "camel_45120": 0.709506630897522, "aqua_rat_25765": 0.7106505036354065, "aqua_rat_12260": 0.7120606303215027, "camel_45928": 0.713051974773407, "camel_5227": 0.7135075926780701, "camel_45148": 0.7137093544006348, "aqua_rat_69487": 0.7140600681304932, "camel_5272": 0.7143149971961975, "camel_5070": 0.7155709266662598, "camel_5055": 0.7156869173049927, "camel_45126": 0.71588134765625, "gsm_rft_2452": 0.7159444093704224, "camel_5198": 0.716016948223114, "aqua_rat_67486": 0.7162640690803528, "gsm_rft_9344": 0.7164314389228821, "gsm_rft_17551": 0.7165849208831787, "gsm_train_17819": 0.7165849208831787, "gsm_rft_11031": 0.7167033553123474, "camel_45314": 0.7172520756721497, "camel_45952": 0.7175788283348083, "camel_5094": 0.7177594304084778, "camel_45963": 0.7188805937767029, "camel_5093": 0.719107985496521, "aqua_rat_75111": 0.7199934124946594, "camel_5177": 0.7202187776565552, "camel_5008": 0.7208738327026367, "camel_45956": 0.721225917339325, "camel_5189": 0.7219499945640564, "camel_5157": 0.7228932976722717, "camel_45156": 0.722895622253418, "camel_5165": 0.7236195802688599, "aqua_rat_60081": 0.7245270013809204, "camel_45166": 0.725996732711792, "camel_43796": 0.7282447814941406, "aqua_rat_23035": 0.7304009199142456, "aqua_rat_63167": 0.7316796183586121, "camel_5235": 0.7324748635292053, "camel_45616": 0.7346553206443787, "camel_45931": 0.735447108745575, "camel_45657": 0.7358576059341431, "camel_5197": 0.7366798520088196, "camel_45302": 0.7391787171363831, "camel_5216": 0.7398917078971863, "aqua_rat_3234": 0.7410691380500793, "camel_45677": 0.7413737177848816, "camel_45192": 0.741500735282898, "aqua_rat_8610": 0.7425102591514587, "camel_45129": 0.7426773309707642, "aqua_rat_44457": 0.743622899055481, "camel_45284": 0.7442205548286438, "aqua_rat_66162": 0.745957612991333, "camel_43803": 0.748810887336731, "aqua_rat_23105": 0.7498266696929932, "camel_43779": 0.7501285672187805, "camel_45141": 0.7515857815742493, "camel_44765": 0.7537441253662109, "camel_45131": 0.7582820057868958, "camel_45159": 0.7668009996414185, "camel_45169": 0.768182098865509, "camel_45190": 0.7720442414283752, "camel_45149": 0.7724282741546631, "camel_45178": 0.7750101685523987, "camel_45340": 0.7770848870277405, "camel_45295": 0.7801841497421265, "camel_45352": 0.7830873727798462, "camel_43792": 0.7831557989120483, "camel_45195": 0.783917248249054, "camel_45136": 0.7875369191169739, "camel_45935": 0.7900463938713074, "camel_45174": 0.7935184240341187, "camel_45323": 0.8042841553688049, "camel_45155": 0.8055961728096008, "camel_45199": 0.8201481699943542, "TheoremQA_panlu/wave_speed1.json": 0.8227109909057617, "camel_43782": 0.823743999004364, "camel_45140": 0.8395008444786072, "camel_45163": 0.8522302508354187}, "TheoremQA_wenhuchen/Poisson_process3.json": {"camel_10367": 0, "camel_10957": 0, "camel_10904": 0, "camel_11394": 0, "camel_11286": 0, "camel_11149": 0, "camel_11624": 0, "camel_11186": 0, "camel_11105": 0, "camel_11629": 0, "camel_11342": 0, "camel_10361": 0, "camel_11841": 0, "camel_10520": 0, "camel_10397": 0, "camel_10278": 0, "camel_10812": 0, "camel_11665": 0, "camel_10720": 0, "camel_11983": 0, "camel_11007": 0, "camel_11660": 0, "camel_10918": 0, "camel_11130": 0, "camel_11328": 0, "camel_11183": 0, "camel_10977": 0, "camel_11294": 0, "camel_10983": 0, "camel_10853": 0, "camel_10871": 0, "camel_11238": 0, "camel_11420": 0, "camel_10982": 0, "camel_11163": 0, "camel_10953": 0, "camel_11002": 0, "camel_11412": 0, "camel_11633": 0, "camel_11308": 0, "camel_11563": 0, "camel_10927": 0, "camel_10947": 0, "camel_11289": 0, "camel_11029": 0, "camel_10327": 0, "camel_11649": 0, "camel_10903": 0, "camel_11127": 0, "camel_11059": 0, "camel_11071": 0, "camel_11092": 0, "camel_11032": 0, "camel_10958": 0, "camel_9361": 0, "camel_11178": 0, "camel_11281": 0, "camel_10807": 0, "camel_9437": 0, "camel_10320": 0, "camel_11164": 0, "camel_11347": 0, "camel_11658": 0, "camel_11196": 0, "camel_11322": 0, "camel_8731": 0, "camel_11026": 0, "camel_8737": 0, "camel_10976": 0, "camel_11173": 0, "camel_9565": 0, "camel_10359": 0, "camel_10920": 0, "camel_10816": 0, "camel_10872": 0, "camel_10612": 0, "camel_9415": 0, "camel_11866": 0, "camel_11046": 0, "camel_10606": 0, "camel_11010": 0, "camel_10980": 0, "camel_11386": 0, "camel_10926": 0, "camel_11072": 0, "camel_9416": 0, "camel_10557": 0, "camel_10935": 0, "camel_11112": 0, "camel_11122": 0, "camel_11036": 0, "camel_10874": 0, "camel_11185": 0, "camel_10996": 0, "camel_11643": 0, "camel_11161": 0, "camel_10979": 0, "camel_11182": 0, "camel_10335": 0, "camel_10889": 0, "camel_9365": 0, "camel_11332": 0, "camel_11179": 0, "camel_10974": 0, "camel_10919": 0, "camel_11189": 0, "camel_11066": 0, "camel_10897": 0, "camel_11188": 0, "camel_10839": 0, "camel_10939": 0, "camel_11282": 0, "camel_11335": 0, "camel_10364": 0, "camel_10352": 0, "camel_11325": 0, "camel_11604": 0, "camel_10369": 0, "camel_11014": 0, "camel_11293": 0, "camel_11067": 0, "camel_11031": 0, "camel_11397": 0, "camel_10966": 0, "camel_9395": 0, "camel_10486": 0, "camel_11140": 0, "camel_10833": 0, "camel_11143": 0, "camel_10887": 0, "camel_11864": 0, "camel_9412": 0, "camel_10882": 0, "camel_9522": 0, "camel_10813": 0, "camel_9364": 0, "camel_8383": 0, "camel_11027": 0, "camel_11081": 0, "camel_11605": 0, "camel_10890": 0, "camel_10948": 0, "camel_10350": 0, "camel_11000": 0, "camel_10969": 0, "TheoremQA_wenhuchen/Poisson_process3.json": 0, "camel_10998": 0, "camel_11306": 0, "camel_11003": 0, "camel_11650": 0, "camel_11655": 0, "camel_11181": 0, "camel_11023": 0, "camel_11926": 0, "camel_10950": 0, "camel_11326": 0, "camel_10385": 0, "camel_9398": 0, "camel_10951": 0, "camel_9484": 0, "camel_10806": 0, "camel_11310": 0, "camel_11349": 0, "camel_11001": 0, "camel_11192": 0, "camel_9424": 0, "camel_11121": 0, "camel_9383": 0, "camel_10929": 0, "camel_11153": 0, "camel_10936": 0, "camel_10908": 0, "camel_10828": 0, "aqua_rat_42090": 0.708717942237854, "aqua_rat_85797": 0.7115451693534851, "aqua_rat_9422": 0.7117832899093628, "aqua_rat_83772": 0.712631344795227, "aqua_rat_20677": 0.7130138874053955, "aqua_rat_42781": 0.7142745852470398, "aqua_rat_50346": 0.7144308686256409, "aqua_rat_34130": 0.7145771384239197, "aqua_rat_73072": 0.7175771594047546, "aqua_rat_23262": 0.7180634140968323, "camel_38734": 0.7204861044883728, "aqua_rat_58860": 0.7204897999763489, "aqua_rat_33164": 0.7316402196884155, "aqua_rat_22368": 0.7330239415168762, "aqua_rat_26702": 0.7391976714134216, "aqua_rat_35997": 0.740312397480011, "aqua_rat_34189": 0.743083655834198, "aqua_rat_4849": 0.748266875743866, "aqua_rat_66771": 0.7490576505661011, "aqua_rat_57702": 0.7554475665092468, "aqua_rat_45598": 0.761193573474884, "aqua_rat_37149": 0.7644641399383545, "aqua_rat_77065": 0.7654748558998108, "aqua_rat_5337": 0.7663900256156921, "aqua_rat_48773": 0.7710328102111816, "aqua_rat_60711": 0.7750956416130066, "aqua_rat_89088": 0.7806814312934875}, "TheoremQA_xinyi/dag_1.json": {"camel_23432": 0, "camel_23926": 0, "camel_23956": 0, "camel_23158": 0, "camel_23981": 0, "camel_21641": 0, "camel_22868": 0, "camel_23106": 0, "camel_22854": 0, "camel_22338": 0, "camel_22449": 0, "camel_23181": 0, "camel_23940": 0, "camel_22414": 0, "camel_23959": 0, "camel_22816": 0, "camel_22455": 0, "camel_22832": 0, "camel_22940": 0, "camel_23982": 0, "camel_23991": 0, "camel_23979": 0, "camel_22406": 0, "camel_23144": 0, "camel_23943": 0, "camel_21304": 0, "camel_23972": 0, "camel_22415": 0, "camel_22412": 0, "camel_23973": 0, "camel_23131": 0, "camel_22464": 0, "camel_23948": 0, "camel_23472": 0, "camel_23174": 0, "camel_22454": 0, "camel_22407": 0, "camel_22410": 0, "camel_22477": 0, "camel_22843": 0, "camel_23947": 0, "camel_22408": 0, "camel_22828": 0, "camel_22409": 0, "camel_22437": 0, "camel_22863": 0, "camel_22453": 0, "camel_22841": 0, "camel_23391": 0, "camel_22808": 0, "camel_22450": 0, "camel_22378": 0, "camel_22806": 0, "camel_22436": 0, "camel_23980": 0, "camel_22068": 0, "camel_23985": 0, "camel_23961": 0, "camel_23935": 0, "camel_23949": 0, "camel_23957": 0, "camel_22459": 0, "camel_22458": 0, "camel_23933": 0, "camel_22468": 0, "camel_22819": 0, "camel_22474": 0, "camel_21079": 0, "camel_22426": 0, "camel_23955": 0, "camel_23193": 0, "camel_23952": 0, "camel_23954": 0, "camel_23963": 0, "camel_23941": 0, "camel_22475": 0, "camel_22423": 0, "camel_23114": 0, "camel_23968": 0, "camel_22444": 0, "camel_22473": 0, "camel_21663": 0, "camel_22404": 0, "camel_21064": 0, "camel_22446": 0, "camel_22439": 0, "camel_22429": 0, "camel_23308": 0, "camel_21098": 0, "camel_22400": 0, "camel_23393": 0, "camel_22448": 0, "camel_22456": 0, "camel_22664": 0, "camel_23970": 0, "camel_22466": 0, "camel_22403": 0, "camel_22402": 0, "camel_22434": 0, "camel_22447": 0, "camel_23924": 0, "camel_22472": 0, "camel_21100": 0, "camel_22425": 0, "camel_22157": 0, "camel_22422": 0, "camel_22431": 0, "camel_22469": 0, "camel_23988": 0, "camel_23971": 0, "camel_23921": 0, "camel_23995": 0, "camel_22463": 0, "camel_23990": 0, "camel_22428": 0, "camel_22471": 0, "camel_22061": 0, "camel_22438": 0, "camel_22416": 0, "camel_23966": 0, "camel_22424": 0, "camel_23976": 0, "camel_23975": 0, "camel_23928": 0, "camel_23944": 0, "camel_22461": 0, "camel_23984": 0, "camel_22445": 0, "camel_22432": 0, "camel_23989": 0, "camel_22462": 0, "camel_22435": 0, "camel_23969": 0, "camel_22440": 0, "camel_22807": 0, "camel_23931": 0, "camel_22411": 0, "camel_23920": 0, "camel_23934": 0, "camel_22460": 0, "camel_22478": 0, "camel_23960": 0, "camel_22443": 0, "camel_22420": 0, "camel_22452": 0, "camel_22465": 0, "camel_22442": 0, "camel_23998": 0, "camel_22427": 0, "camel_23978": 0, "camel_22430": 0, "camel_23951": 0, "camel_22405": 0, "camel_23930": 0, "camel_22433": 0, "camel_23983": 0, "camel_22457": 0, "camel_23996": 0, "camel_22401": 0, "camel_22419": 0, "camel_22451": 0, "camel_23922": 0, "camel_23442": 0, "camel_23997": 0, "camel_22467": 0, "camel_23945": 0, "camel_23958": 0, "camel_23938": 0, "camel_23939": 0, "camel_22441": 0, "camel_22417": 0, "camel_23932": 0, "camel_23942": 0, "camel_23923": 0, "TheoremQA_xinyi/dag_1.json": 0, "camel_36542": 0.6921398043632507, "camel_38489": 0.6936826705932617, "aqua_rat_28715": 0.695397675037384, "camel_39977": 0.6969305276870728, "aqua_rat_54929": 0.6969874501228333, "aqua_rat_28685": 0.6973901391029358, "camel_36503": 0.6994656920433044, "camel_19249": 0.7000012397766113, "camel_39997": 0.7030348181724548, "aqua_rat_55983": 0.7033888101577759, "aqua_rat_44831": 0.7092899680137634, "aqua_rat_11272": 0.7096092700958252, "aqua_rat_48531": 0.7106024622917175, "aqua_rat_23372": 0.7120404839515686, "aqua_rat_25794": 0.7144197225570679, "camel_19979": 0.7155705094337463, "aqua_rat_76009": 0.7159942984580994, "aqua_rat_70645": 0.7170931100845337, "aqua_rat_40504": 0.7179489731788635, "camel_19973": 0.7345342040061951, "TheoremQA_xinyi/dag_3.json": 0.7377535700798035, "aqua_rat_67605": 0.7498014569282532, "aqua_rat_34441": 0.7501506209373474, "aqua_rat_41715": 0.7524885535240173, "aqua_rat_44391": 0.7535848021507263}, "TheoremQA_xueguangma/geometric_brownian_motion.json": {"TheoremQA_xueguangma/geometric_brownian_motion.json": 0, "camel_16790": 0.6486132144927979, "camel_16736": 0.6486355662345886, "camel_25251": 0.6486744284629822, "camel_17920": 0.6489067673683167, "camel_16728": 0.6490975022315979, "camel_16797": 0.6492651700973511, "camel_10520": 0.6493780612945557, "camel_16735": 0.6494218707084656, "camel_38702": 0.6495707035064697, "camel_25129": 0.6495773792266846, "camel_16725": 0.6497714519500732, "camel_16722": 0.6500160098075867, "camel_16796": 0.6503775715827942, "camel_16758": 0.6504071354866028, "camel_10548": 0.6504765748977661, "camel_38689": 0.6509767174720764, "camel_16761": 0.6516485214233398, "camel_16750": 0.6516823768615723, "camel_16739": 0.6522024273872375, "camel_17966": 0.6524754166603088, "camel_25168": 0.6524913907051086, "camel_25171": 0.6531436443328857, "camel_16772": 0.6537407636642456, "camel_25302": 0.6540866494178772, "camel_17986": 0.6541674137115479, "camel_16768": 0.6542652249336243, "camel_10523": 0.6543298363685608, "camel_17971": 0.6545352339744568, "camel_16784": 0.6546224355697632, "camel_16732": 0.6546877026557922, "TheoremQA_elainewan/econ_micro_18.json": 0.6549248695373535, "camel_16765": 0.6550132632255554, "camel_16773": 0.6552138328552246, "camel_25177": 0.6557723879814148, "camel_16744": 0.655783474445343, "camel_16793": 0.6558355689048767, "camel_25253": 0.6558566093444824, "camel_38651": 0.6561881303787231, "camel_38697": 0.6562003493309021, "camel_38715": 0.6563203930854797, "camel_17992": 0.6563369631767273, "camel_38649": 0.6567028760910034, "camel_17985": 0.6569349765777588, "camel_17928": 0.6571029424667358, "camel_38677": 0.6572282910346985, "camel_17949": 0.657830536365509, "camel_16775": 0.6583642363548279, "camel_17996": 0.6585030555725098, "camel_17951": 0.6591044664382935, "camel_38717": 0.6593267917633057, "camel_16792": 0.6593864560127258, "camel_10506": 0.6594477891921997, "camel_16774": 0.6596090197563171, "camel_25136": 0.6597261428833008, "camel_17978": 0.6601481437683105, "camel_17942": 0.6603533029556274, "camel_17970": 0.6605761051177979, "camel_17440": 0.6607272028923035, "camel_16751": 0.6616131663322449, "camel_38645": 0.6616794466972351, "camel_16734": 0.6616949439048767, "camel_38648": 0.661927342414856, "camel_16760": 0.6628130674362183, "TheoremQA_xueguangma/dividend_discount_model_4.json": 0.6631224751472473, "camel_17973": 0.6635749340057373, "camel_17932": 0.6637492775917053, "camel_16745": 0.6639300584793091, "camel_16752": 0.6647042632102966, "camel_16753": 0.6651739478111267, "camel_38660": 0.6655207276344299, "camel_17484": 0.6655466556549072, "camel_10480": 0.6664674282073975, "camel_17930": 0.6665027141571045, "camel_16776": 0.6665530204772949, "camel_16720": 0.666989803314209, "camel_16756": 0.6670594215393066, "camel_17977": 0.6671404838562012, "camel_17972": 0.6675522923469543, "camel_17969": 0.667940616607666, "camel_16786": 0.6683690547943115, "camel_16794": 0.6697723865509033, "camel_25224": 0.6700809001922607, "camel_17997": 0.6708979606628418, "camel_38659": 0.671131432056427, "camel_17515": 0.6721226572990417, "camel_10543": 0.67217618227005, "camel_17475": 0.6721988916397095, "camel_16788": 0.6722682118415833, "camel_16741": 0.6729639172554016, "camel_17959": 0.6730247735977173, "camel_17931": 0.673577070236206, "camel_16798": 0.673618495464325, "camel_16769": 0.6740514039993286, "camel_24831": 0.6742805242538452, "camel_16779": 0.6747527122497559, "TheoremQA_xueguangma/forward_price_2.json": 0.6752052307128906, "camel_16762": 0.6752457618713379, "camel_25184": 0.6752493381500244, "camel_10555": 0.6755303740501404, "camel_17948": 0.6756992936134338, "camel_17934": 0.6761585474014282, "camel_17518": 0.6768065690994263, "camel_17479": 0.6770164966583252, "TheoremQA_xueguangma/options_theory.json": 0.6771095991134644, "camel_10542": 0.6774654984474182, "TheoremQA_xueguangma/delta_gamma_approximation.json": 0.6774864792823792, "camel_38643": 0.678109884262085, "camel_16770": 0.6784369349479675, "camel_16727": 0.678488552570343, "camel_16799": 0.678501546382904, "camel_16759": 0.6795122623443604, "camel_16778": 0.6795242428779602, "camel_17980": 0.680272102355957, "camel_17944": 0.6803670525550842, "camel_16777": 0.6805846691131592, "camel_16782": 0.6807764768600464, "camel_17982": 0.6807835102081299, "camel_10557": 0.6809219121932983, "camel_38693": 0.6811463236808777, "camel_16787": 0.6817986965179443, "camel_17958": 0.683379590511322, "camel_10486": 0.6838625073432922, "camel_17981": 0.6842898726463318, "camel_17962": 0.6849526762962341, "camel_10482": 0.685052216053009, "camel_45730": 0.6855714917182922, "camel_17513": 0.6857097744941711, "camel_17945": 0.6878153085708618, "camel_17993": 0.6887302994728088, "camel_16733": 0.6893032193183899, "camel_17999": 0.6898691058158875, "camel_17994": 0.6902360916137695, "camel_38714": 0.6923028826713562, "camel_17988": 0.6935352683067322, "camel_17976": 0.6936448812484741, "camel_10558": 0.694007396697998, "TheoremQA_xueguangma/forward_price_1.json": 0.6941469311714172, "camel_17937": 0.6959992051124573, "camel_17979": 0.6960855722427368, "camel_16783": 0.6978136301040649, "camel_17955": 0.697907030582428, "camel_17946": 0.6982195377349854, "camel_10492": 0.6985418200492859, "camel_16738": 0.698830246925354, "camel_17957": 0.6993294358253479, "camel_17933": 0.7004879117012024, "camel_17968": 0.7005485892295837, "camel_17995": 0.7006511688232422, "camel_16748": 0.7007394433021545, "camel_17974": 0.703057050704956, "camel_10514": 0.704903244972229, "camel_17922": 0.7076267004013062, "camel_45695": 0.7082415819168091, "camel_16755": 0.7088334560394287, "camel_16785": 0.7090407609939575, "camel_10488": 0.7101081609725952, "camel_17967": 0.7104495167732239, "camel_16763": 0.7125551700592041, "camel_16789": 0.7148516774177551, "camel_17938": 0.7169857621192932, "camel_17990": 0.7172372341156006, "camel_17987": 0.7175474166870117, "camel_16795": 0.7186405658721924, "camel_16740": 0.7207339406013489, "camel_16754": 0.723547101020813, "camel_17469": 0.7236342430114746, "camel_17947": 0.723720908164978, "camel_16780": 0.7282618880271912, "camel_17960": 0.7283673286437988, "camel_17983": 0.7300050258636475, "camel_17950": 0.7308977842330933, "camel_16791": 0.7318981885910034, "TheoremQA_xueguangma/binomial_model_1.json": 0.7331503033638, "camel_17943": 0.7333194613456726, "camel_17927": 0.7389914393424988, "camel_17998": 0.7398461103439331, "camel_17952": 0.7404108643531799, "camel_17936": 0.744461715221405, "camel_17984": 0.7470265030860901, "camel_17991": 0.7503886818885803, "camel_17926": 0.751064658164978, "camel_17935": 0.7518060803413391, "camel_17929": 0.7541905045509338, "camel_17941": 0.7553693056106567, "camel_17954": 0.7574896812438965, "TheoremQA_xueguangma/binomial_model_2.json": 0.7575972080230713, "camel_17939": 0.7577860355377197, "camel_17964": 0.7593608498573303, "camel_17940": 0.7611579298973083, "TheoremQA_xueguangma/put_call_parity_1.json": 0.7620025873184204, "camel_17924": 0.7624659538269043, "camel_16747": 0.7633551359176636, "camel_17961": 0.7664176225662231, "camel_17921": 0.7703377604484558, "camel_17975": 0.7727451920509338, "camel_17965": 0.7752435207366943, "camel_17963": 0.7823822498321533, "camel_17989": 0.7919875979423523, "camel_17923": 0.7993784546852112}, "TheoremQA_xinyi/rate_distortion_function_1.json": {"TheoremQA_xinyi/rate_distortion_function_1.json": 0, "aqua_rat_66641": 0.6017484664916992, "camel_41037": 0.601781964302063, "camel_25029": 0.6018035411834717, "camel_17532": 0.6018533110618591, "camel_29667": 0.6018579602241516, "camel_17561": 0.6020311713218689, "camel_41020": 0.602063000202179, "camel_29755": 0.6020829081535339, "camel_39495": 0.6021106243133545, "camel_25956": 0.6021896600723267, "TheoremQA_xinyi/cramer_rao_lower_bound_2.json": 0.6022618412971497, "camel_40978": 0.6024374961853027, "camel_28689": 0.6024404764175415, "camel_38724": 0.6024726033210754, "camel_38798": 0.6027854681015015, "aqua_rat_7326": 0.6028376221656799, "aqua_rat_41295": 0.6029696464538574, "camel_39223": 0.603163480758667, "camel_17551": 0.6031845211982727, "camel_40676": 0.6033713817596436, "camel_29715": 0.6033884286880493, "camel_41312": 0.6034003496170044, "camel_28672": 0.6034425497055054, "camel_28427": 0.6036230325698853, "camel_28660": 0.6038115620613098, "camel_41031": 0.6039775013923645, "camel_18097": 0.6039828062057495, "camel_28643": 0.6040336489677429, "camel_29722": 0.6041409373283386, "camel_25061": 0.6042155623435974, "camel_38720": 0.6045374870300293, "TheoremQA_maxku/cv-imageprocessing11-histogram.json": 0.6046308875083923, "camel_28793": 0.6046566367149353, "camel_40717": 0.6047274470329285, "camel_39259": 0.6047493815422058, "camel_41001": 0.6047953963279724, "camel_25248": 0.6049225926399231, "camel_39237": 0.6049512028694153, "TheoremQA_xinyi/expected_waiting_time.json": 0.6050774455070496, "TheoremQA_mingyin/borel-cantelli-lemma1.json": 0.6051585674285889, "TheoremQA_elainewan/math_real_analysis_additional_3.json": 0.6052482724189758, "camel_29055": 0.6053341031074524, "camel_38762": 0.6053546071052551, "camel_29256": 0.6053546667098999, "camel_25174": 0.6054053902626038, "camel_28667": 0.6054094433784485, "camel_29341": 0.6054162383079529, "camel_29097": 0.6054340600967407, "camel_40996": 0.6055225133895874, "camel_28648": 0.6055554747581482, "aqua_rat_86877": 0.605586588382721, "aqua_rat_61146": 0.605636715888977, "camel_29593": 0.6056520342826843, "camel_29328": 0.605981171131134, "camel_31395": 0.60652756690979, "camel_41841": 0.6066591143608093, "camel_29083": 0.6067337393760681, "camel_42536": 0.6067755222320557, "camel_40889": 0.6067978143692017, "TheoremQA_mingyin/Lebesgue-measure1.json": 0.6068528294563293, "camel_40704": 0.6069008111953735, "camel_28706": 0.6070752143859863, "camel_28712": 0.607123076915741, "camel_28708": 0.6072436571121216, "camel_41288": 0.6072976589202881, "camel_38648": 0.6073903441429138, "camel_29783": 0.6075986623764038, "camel_38704": 0.6076661348342896, "camel_40914": 0.6076752543449402, "camel_39277": 0.6076880097389221, "camel_25187": 0.60769122838974, "camel_40670": 0.607749879360199, "camel_29322": 0.6077894568443298, "camel_28718": 0.6078674793243408, "camel_25107": 0.6080346703529358, "camel_38663": 0.608109712600708, "aqua_rat_5274": 0.6081381440162659, "TheoremQA_mingyin/complete-metric-space1.json": 0.6081880331039429, "camel_25078": 0.6082668304443359, "camel_41008": 0.6082835793495178, "camel_29818": 0.6083130240440369, "camel_29302": 0.6083322167396545, "camel_31761": 0.6084483861923218, "camel_26924": 0.6084786653518677, "camel_29795": 0.6085089445114136, "camel_28548": 0.6085188984870911, "camel_29078": 0.6085702776908875, "camel_31401": 0.6086134910583496, "camel_29301": 0.608806312084198, "camel_41021": 0.6089394688606262, "camel_41011": 0.6089728474617004, "camel_29082": 0.6091213822364807, "camel_29057": 0.609287440776825, "TheoremQA_xinyi/chi_square_test.json": 0.6093811988830566, "camel_25105": 0.6093835830688477, "camel_29335": 0.6094202995300293, "camel_41005": 0.6094428300857544, "camel_28703": 0.6094920635223389, "camel_31051": 0.6095231771469116, "camel_28681": 0.6095653772354126, "camel_25528": 0.6098154187202454, "camel_38965": 0.6098328828811646, "camel_28344": 0.6098473072052002, "math_train_precalculus_932": 0.6099951863288879, "camel_25161": 0.6104846000671387, "camel_28650": 0.6105985641479492, "camel_40713": 0.6108324527740479, "aqua_rat_42657": 0.6110574007034302, "camel_38527": 0.6112017035484314, "camel_17545": 0.6112544536590576, "camel_29329": 0.6113132238388062, "camel_40973": 0.6113417744636536, "camel_41700": 0.6119263172149658, "math_test_algebra_2628": 0.6120980381965637, "camel_29884": 0.6121947169303894, "math_train_intermediate_algebra_2086": 0.6123704314231873, "camel_28694": 0.6124008297920227, "aqua_rat_5583": 0.6124807596206665, "camel_29787": 0.6125425696372986, "camel_40984": 0.6125997304916382, "camel_28685": 0.6127129793167114, "camel_42704": 0.6128336191177368, "TheoremQA_xinyi/huffman_code_1.json": 0.6130421757698059, "camel_37581": 0.6131485104560852, "camel_28701": 0.6135839819908142, "aqua_rat_72155": 0.613722562789917, "camel_40647": 0.6137852668762207, "camel_29061": 0.6137989163398743, "camel_39217": 0.6138601899147034, "camel_29187": 0.6140000820159912, "camel_30179": 0.6142651438713074, "camel_25022": 0.6151115894317627, "camel_25589": 0.6157476305961609, "aqua_rat_24364": 0.6157806515693665, "TheoremQA_xinyi/huffman_code_3.json": 0.6159037947654724, "camel_29090": 0.6159582734107971, "camel_40994": 0.6161683201789856, "camel_40948": 0.6163157224655151, "math_test_precalculus_652": 0.6168372631072998, "math_test_precalculus_695": 0.6172182559967041, "camel_25090": 0.617275059223175, "camel_26540": 0.6174187660217285, "camel_28645": 0.6174341440200806, "camel_29109": 0.6178682446479797, "camel_41769": 0.6179589033126831, "camel_38734": 0.6181132793426514, "TheoremQA_xinyi/Concavity_of_second_law_of_thermodynamics.json": 0.6183832883834839, "camel_38692": 0.6184028387069702, "camel_29689": 0.6187735199928284, "aqua_rat_80404": 0.618848979473114, "camel_28117": 0.6189760565757751, "camel_30234": 0.61910080909729, "camel_29042": 0.6195728182792664, "camel_38649": 0.6196771860122681, "camel_24997": 0.6196931600570679, "camel_28474": 0.6201707720756531, "camel_25171": 0.620343804359436, "camel_37471": 0.6205417513847351, "camel_25145": 0.6208137273788452, "camel_44798": 0.621492862701416, "camel_44741": 0.6227028369903564, "camel_30050": 0.6233283877372742, "camel_28677": 0.624585747718811, "camel_39482": 0.6250972747802734, "camel_29040": 0.6255447864532471, "camel_30315": 0.6256688833236694, "camel_28675": 0.6257611513137817, "camel_38643": 0.6259859800338745, "camel_28109": 0.6270216703414917, "camel_25162": 0.6278892755508423, "camel_28668": 0.6281408667564392, "camel_31071": 0.6290233731269836, "camel_25115": 0.6320337057113647, "TheoremQA_xinyi/maximum_entropy_2.json": 0.6327069997787476, "camel_38642": 0.6353300213813782, "aqua_rat_49646": 0.6355799436569214, "camel_30166": 0.6366438269615173, "camel_28136": 0.6381815075874329, "aqua_rat_11117": 0.638610303401947, "camel_40964": 0.640116810798645, "camel_29099": 0.6431523561477661, "camel_25046": 0.6432971954345703, "camel_28640": 0.6433374285697937, "camel_28007": 0.6434967517852783, "camel_28642": 0.6440099477767944, "TheoremQA_xinyi/kraft_inequality.json": 0.6566345691680908, "TheoremQA_xinyi/data_processing.json": 0.6735153794288635, "TheoremQA_xinyi/distortion_rate_function_2.json": 0.6883679032325745, "TheoremQA_xinyi/expected_distortion.json": 0.6975966691970825, "TheoremQA_xinyi/markov_inequality.json": 0.6993054747581482, "TheoremQA_xinyi/maximum_entropy_1.json": 0.7219823598861694, "TheoremQA_xinyi/channel_capacity_1.json": 0.728524386882782, "TheoremQA_xinyi/binary_symmetric_channel_1.json": 0.7305347919464111, "TheoremQA_xinyi/concavity.json": 0.7363600134849548, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.7651044726371765, "TheoremQA_xinyi/distortion_rate_function_1.json": 0.7836790680885315, "TheoremQA_xinyi/fano_inequality.json": 0.8077398538589478, "TheoremQA_xinyi/shannon_lower_bound.json": 0.816932737827301, "TheoremQA_xinyi/rate_distortion_function_2.json": 0.8196493983268738}, "TheoremQA_xinyi/distortion_rate_function_2.json": {"TheoremQA_xinyi/distortion_rate_function_2.json": 0, "camel_17602": 0.6160656809806824, "camel_42471": 0.6160745024681091, "camel_43989": 0.6161060929298401, "TheoremQA_mingyin/borel-cantelli-lemma1.json": 0.6162171363830566, "camel_18763": 0.6163437366485596, "camel_43953": 0.6164923310279846, "camel_43864": 0.6166808605194092, "camel_46496": 0.6168281435966492, "math_test_algebra_35": 0.6169471740722656, "camel_43867": 0.616994321346283, "math_train_precalculus_1305": 0.6170057654380798, "camel_17677": 0.6170375943183899, "camel_19682": 0.6170637011528015, "camel_16689": 0.6171490550041199, "camel_46833": 0.6173628568649292, "camel_43466": 0.617427408695221, "math_train_algebra_379": 0.6174704432487488, "camel_18101": 0.6175103187561035, "camel_29795": 0.6176539659500122, "camel_29335": 0.6178955435752869, "camel_47231": 0.617943286895752, "math_train_counting_and_probability_751": 0.6179731488227844, "math_train_algebra_823": 0.6180247068405151, "camel_46979": 0.6181765794754028, "camel_42499": 0.6182089447975159, "math_train_precalculus_306": 0.6182640790939331, "camel_17781": 0.6184924840927124, "camel_43451": 0.6185212731361389, "math_train_intermediate_algebra_854": 0.618711531162262, "camel_47000": 0.618760883808136, "camel_17547": 0.6188632845878601, "camel_47056": 0.618890106678009, "math_train_intermediate_algebra_2086": 0.6188930869102478, "math_test_algebra_945": 0.6189220547676086, "math_train_intermediate_algebra_215": 0.618969202041626, "camel_19443": 0.6191611886024475, "camel_19696": 0.6194300651550293, "camel_49078": 0.6194443106651306, "math_train_precalculus_247": 0.6194459199905396, "camel_43997": 0.6195887923240662, "camel_19691": 0.6196686625480652, "camel_46779": 0.6197226047515869, "camel_46987": 0.6197653412818909, "camel_46853": 0.6198952198028564, "math_train_intermediate_algebra_603": 0.6200342178344727, "camel_19654": 0.620227038860321, "camel_29294": 0.6202578544616699, "camel_17474": 0.6202580332756042, "camel_17591": 0.620417058467865, "camel_46841": 0.6205062866210938, "camel_28644": 0.6205794811248779, "camel_17770": 0.6206138730049133, "camel_43849": 0.6207755208015442, "math_train_intermediate_algebra_1201": 0.6212127804756165, "camel_43775": 0.6212366223335266, "camel_47279": 0.6213154792785645, "camel_17679": 0.6213173866271973, "camel_17778": 0.6214156746864319, "camel_45073": 0.6215284466743469, "camel_47111": 0.6215397715568542, "math_train_intermediate_algebra_445": 0.6216095685958862, "camel_46605": 0.621914803981781, "camel_28675": 0.621981143951416, "math_train_algebra_2749": 0.6220422387123108, "camel_17514": 0.6220971345901489, "TheoremQA_mingyin/cauchy-integral-theorem1.json": 0.6221297383308411, "TheoremQA_mingyin/Lebesgue-measure4.json": 0.622209370136261, "math_test_algebra_1375": 0.6222106218338013, "math_train_intermediate_algebra_1027": 0.6223008632659912, "camel_43693": 0.6225298643112183, "math_train_precalculus_1141": 0.6227399110794067, "camel_45105": 0.6230043768882751, "camel_43885": 0.6230055689811707, "camel_17849": 0.6231755614280701, "math_train_algebra_1087": 0.6232902407646179, "camel_47890": 0.6233788728713989, "camel_17442": 0.6234450340270996, "camel_47132": 0.6237826943397522, "camel_17458": 0.6238736510276794, "camel_46984": 0.6239343881607056, "camel_46874": 0.6240790486335754, "camel_47331": 0.6242403984069824, "camel_18865": 0.6242774128913879, "camel_46153": 0.6245138049125671, "camel_47055": 0.6247826218605042, "math_train_intermediate_algebra_1367": 0.6250179409980774, "camel_43924": 0.6254646182060242, "camel_19667": 0.6256114840507507, "camel_17468": 0.6260374188423157, "camel_43950": 0.6261636018753052, "camel_18772": 0.6261816620826721, "math_test_algebra_480": 0.6262057423591614, "camel_18929": 0.626241147518158, "camel_47022": 0.6262468695640564, "camel_29261": 0.6263769268989563, "camel_46823": 0.6263955235481262, "camel_46818": 0.6270668506622314, "camel_42587": 0.6271399855613708, "camel_43915": 0.6272980570793152, "camel_18779": 0.627406120300293, "camel_18998": 0.6278152465820312, "camel_43946": 0.6279769539833069, "camel_47172": 0.6281898021697998, "camel_47704": 0.6283064484596252, "camel_47059": 0.628420352935791, "camel_43994": 0.6284209489822388, "math_train_counting_and_probability_629": 0.6290754675865173, "camel_43913": 0.6290968060493469, "camel_17572": 0.629124641418457, "camel_17519": 0.6291678547859192, "camel_48987": 0.6291786432266235, "camel_43503": 0.6291859149932861, "camel_46811": 0.629372775554657, "camel_17529": 0.6293930411338806, "math_train_precalculus_314": 0.6294891834259033, "camel_28652": 0.6295162439346313, "TheoremQA_wenhuchen/Lagrange's_multiplier2.json": 0.6296098232269287, "camel_18933": 0.6298598647117615, "camel_29304": 0.6298731565475464, "camel_29354": 0.6303438544273376, "camel_39031": 0.6306238770484924, "camel_38981": 0.63111412525177, "camel_45101": 0.6312708258628845, "camel_46819": 0.631477415561676, "camel_40431": 0.631573498249054, "camel_19679": 0.6319149732589722, "camel_43898": 0.6319959163665771, "camel_16654": 0.6321448683738708, "camel_18133": 0.6323161721229553, "camel_18107": 0.6325669288635254, "math_test_algebra_1362": 0.6326618194580078, "camel_17535": 0.6326660513877869, "camel_46983": 0.6326940655708313, "camel_47241": 0.6327781081199646, "math_test_algebra_733": 0.6333996653556824, "math_train_algebra_1350": 0.6335826516151428, "camel_43897": 0.6336535811424255, "camel_47016": 0.633746325969696, "camel_42573": 0.6348770260810852, "camel_19037": 0.6349886059761047, "camel_17462": 0.6355684399604797, "math_test_intermediate_algebra_1791": 0.6356908679008484, "camel_17690": 0.6360759735107422, "camel_46986": 0.6365709900856018, "camel_17541": 0.6369224786758423, "math_train_precalculus_916": 0.6370373368263245, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.6374719142913818, "camel_17464": 0.6379083395004272, "TheoremQA_xinyi/expected_waiting_time.json": 0.638179361820221, "camel_19638": 0.6382603645324707, "TheoremQA_xinyi/change_of_variable_linear.json": 0.6383072733879089, "camel_17568": 0.6383532881736755, "camel_18914": 0.6392638087272644, "camel_17592": 0.6412054300308228, "math_train_intermediate_algebra_241": 0.6417157649993896, "camel_17533": 0.6417396068572998, "camel_17573": 0.6419477462768555, "camel_47021": 0.6429722905158997, "math_train_intermediate_algebra_650": 0.6431963443756104, "camel_46992": 0.6434834599494934, "math_train_precalculus_210": 0.6443408727645874, "camel_17540": 0.6449643969535828, "camel_42465": 0.6452178359031677, "camel_42611": 0.6452999711036682, "math_train_intermediate_algebra_1190": 0.6456958651542664, "camel_19168": 0.6457645297050476, "camel_43943": 0.6473167538642883, "camel_43914": 0.6476879119873047, "TheoremQA_wenhuchen/Poisson_process2.json": 0.649379551410675, "camel_42588": 0.6500555276870728, "math_train_intermediate_algebra_821": 0.6506465673446655, "TheoremQA_mingyin/log-concave1.json": 0.6511626839637756, "camel_17567": 0.6546278595924377, "math_train_intermediate_algebra_750": 0.6575095057487488, "camel_19005": 0.6576395034790039, "camel_17579": 0.6577385067939758, "camel_17582": 0.6583536267280579, "TheoremQA_mingyin/complete-metric-space1.json": 0.6594008207321167, "camel_17575": 0.6653426289558411, "TheoremQA_mingyin/convexity1.json": 0.6669901609420776, "TheoremQA_mingyin/martingale2.json": 0.6781551837921143, "TheoremQA_xinyi/markov_inequality.json": 0.6790938973426819, "TheoremQA_xinyi/fisher_information_4.json": 0.6929711103439331, "TheoremQA_xinyi/chi_square_test.json": 0.7040275931358337, "TheoremQA_xinyi/cramer_rao_lower_bound_1.json": 0.7048262357711792, "TheoremQA_xinyi/cramer_rao_lower_bound_2.json": 0.7097821235656738, "TheoremQA_xinyi/fisher_information_3.json": 0.7143540382385254, "TheoremQA_xinyi/maximum_entropy_2.json": 0.7166160941123962, "TheoremQA_xinyi/maximum_entropy_1.json": 0.7173938155174255, "TheoremQA_xinyi/Concavity_of_second_law_of_thermodynamics.json": 0.7499842047691345, "TheoremQA_xinyi/data_processing.json": 0.7571430802345276, "TheoremQA_xinyi/expected_distortion.json": 0.766288697719574, "TheoremQA_xinyi/fano_inequality.json": 0.77018803358078, "TheoremQA_xinyi/shannon_lower_bound.json": 0.7861157655715942, "TheoremQA_xinyi/channel_capacity_1.json": 0.7963369488716125, "TheoremQA_xinyi/rate_distortion_function_1.json": 0.7980931997299194, "TheoremQA_xinyi/rate_distortion_function_2.json": 0.7986376881599426, "TheoremQA_xinyi/concavity.json": 0.8342925310134888, "TheoremQA_xinyi/distortion_rate_function_1.json": 0.9275603890419006}, "TheoremQA_maxku/graphtheory2-vertexcover.json": {"camel_23472": 0, "camel_23620": 0, "camel_23296": 0, "camel_22324": 0, "camel_23143": 0, "camel_23679": 0, "camel_22765": 0, "camel_22752": 0, "camel_22871": 0, "camel_22787": 0, "camel_22841": 0, "camel_22830": 0, "camel_23957": 0, "camel_22119": 0, "camel_22326": 0, "camel_23426": 0, "camel_23442": 0, "camel_22188": 0, "camel_22820": 0, "camel_22361": 0, "camel_23374": 0, "camel_22186": 0, "camel_22085": 0, "camel_23605": 0, "camel_22092": 0, "camel_22740": 0, "camel_22397": 0, "camel_22367": 0, "camel_22123": 0, "camel_22847": 0, "camel_23184": 0, "camel_22345": 0, "camel_22121": 0, "camel_22852": 0, "camel_21795": 0, "camel_22192": 0, "camel_22368": 0, "camel_23411": 0, "camel_22103": 0, "camel_22087": 0, "camel_22162": 0, "camel_22100": 0, "camel_22384": 0, "camel_22150": 0, "camel_22108": 0, "camel_22136": 0, "camel_22204": 0, "camel_23511": 0, "camel_23397": 0, "camel_23601": 0, "camel_21918": 0, "camel_22723": 0, "camel_23481": 0, "camel_22356": 0, "camel_22316": 0, "camel_23672": 0, "camel_22223": 0, "camel_23477": 0, "camel_22137": 0, "camel_22140": 0, "camel_22826": 0, "camel_22854": 0, "camel_22172": 0, "camel_22858": 0, "camel_22116": 0, "camel_22870": 0, "camel_23648": 0, "camel_22786": 0, "camel_22088": 0, "camel_22133": 0, "camel_22152": 0, "camel_23512": 0, "camel_22208": 0, "camel_23675": 0, "camel_22171": 0, "camel_22796": 0, "camel_22197": 0, "camel_23371": 0, "camel_22810": 0, "camel_22739": 0, "camel_22753": 0, "camel_22792": 0, "camel_22098": 0, "camel_22856": 0, "camel_23435": 0, "camel_22176": 0, "camel_22859": 0, "camel_22842": 0, "camel_22817": 0, "camel_22767": 0, "camel_22818": 0, "camel_23381": 0, "camel_22762": 0, "camel_22742": 0, "camel_22831": 0, "camel_22875": 0, "camel_23443": 0, "camel_22768": 0, "camel_22193": 0, "camel_22835": 0, "camel_22200": 0, "camel_22726": 0, "camel_22802": 0, "camel_22127": 0, "camel_23363": 0, "camel_22724": 0, "camel_22806": 0, "camel_23607": 0, "camel_22746": 0, "camel_22182": 0, "camel_22154": 0, "camel_22763": 0, "camel_22809": 0, "camel_22821": 0, "camel_22101": 0, "camel_22168": 0, "camel_22800": 0, "camel_22122": 0, "camel_23505": 0, "camel_22734": 0, "camel_22224": 0, "camel_22735": 0, "camel_22117": 0, "camel_23409": 0, "camel_22874": 0, "camel_22754": 0, "camel_22097": 0, "camel_22744": 0, "camel_22794": 0, "camel_22868": 0, "camel_22377": 0, "camel_22210": 0, "camel_23608": 0, "camel_22089": 0, "camel_22330": 0, "camel_22793": 0, "camel_22861": 0, "camel_22860": 0, "camel_22106": 0, "camel_22778": 0, "camel_22328": 0, "camel_23617": 0, "camel_22335": 0, "TheoremQA_maxku/graphtheory2-vertexcover.json": 0, "camel_22147": 0, "camel_22755": 0, "camel_22749": 0, "camel_22829": 0, "camel_22398": 0, "camel_22736": 0, "camel_22728": 0, "camel_22363": 0, "camel_23362": 0, "camel_23677": 0, "camel_22873": 0, "camel_22179": 0, "camel_22857": 0, "camel_23379": 0, "camel_22729": 0, "camel_22770": 0, "camel_22218": 0, "camel_22764": 0, "camel_22777": 0, "camel_23364": 0, "camel_23360": 0, "camel_22185": 0, "camel_22738": 0, "camel_22798": 0, "camel_23438": 0, "camel_22758": 0, "camel_22756": 0, "camel_22745": 0, "camel_22773": 0, "camel_22795": 0, "camel_22789": 0, "camel_22784": 0, "camel_22722": 0, "camel_22720": 0, "camel_23410": 0, "camel_22769": 0, "camel_22760": 0, "camel_22783": 0, "camel_22761": 0, "camel_22170": 0, "camel_22727": 0, "camel_22785": 0, "camel_22737": 0, "camel_22721": 0, "camel_22743": 0, "camel_22757": 0, "camel_22799": 0, "aqua_rat_76009": 0.7370408773422241, "camel_39977": 0.7370887994766235, "camel_39997": 0.7407799959182739, "camel_39941": 0.7411824464797974, "camel_38564": 0.7472172975540161, "TheoremQA_maxku/graphtheory4-vertexcover.json": 0.7671577334403992, "camel_38526": 0.7696823477745056, "TheoremQA_maxku/graphtheory5-vertexcover.json": 0.7768131494522095, "TheoremQA_maxku/graphtheory3-vertexcover.json": 0.7887827157974243}, "TheoremQA_maxku/cv-imageprocessing2-morphology.json": {"TheoremQA_maxku/cv-imageprocessing2-morphology.json": 0, "camel_19490": 0.5290254950523376, "camel_31196": 0.5290660858154297, "camel_36321": 0.5290708541870117, "camel_31864": 0.5290961265563965, "camel_36770": 0.5291513204574585, "camel_17840": 0.5291731953620911, "camel_17237": 0.5292194485664368, "camel_30928": 0.529231607913971, "aqua_rat_24388": 0.5292736887931824, "camel_31615": 0.5293055772781372, "camel_49325": 0.5293337106704712, "camel_19537": 0.5293489098548889, "camel_31090": 0.5293726921081543, "camel_31176": 0.5294458270072937, "camel_47799": 0.5294625759124756, "camel_32727": 0.5295339822769165, "camel_36557": 0.529704749584198, "camel_36414": 0.5297697186470032, "camel_31047": 0.5297975540161133, "camel_47599": 0.5297982096672058, "camel_30861": 0.5299602746963501, "camel_30834": 0.5300068855285645, "camel_18906": 0.5300700068473816, "camel_18959": 0.5301162600517273, "camel_19469": 0.5301237106323242, "camel_30912": 0.5301840901374817, "camel_40462": 0.530188798904419, "camel_36421": 0.5302664637565613, "camel_31647": 0.5303450226783752, "camel_39234": 0.5304591059684753, "camel_18884": 0.5304772853851318, "camel_36432": 0.5304891467094421, "camel_17525": 0.530523955821991, "camel_19375": 0.5305294990539551, "camel_47810": 0.5306896567344666, "camel_36481": 0.5307190418243408, "camel_30743": 0.531080961227417, "camel_47801": 0.5311875343322754, "TheoremQA_maxku/cv-cnn4.json": 0.5312467217445374, "camel_37860": 0.5312635898590088, "camel_31966": 0.5313840508460999, "camel_36429": 0.531387984752655, "camel_19401": 0.5313884019851685, "camel_31997": 0.5313907265663147, "camel_37507": 0.5315142869949341, "camel_31981": 0.5316623449325562, "camel_36452": 0.5317041873931885, "camel_36544": 0.5319114327430725, "camel_19567": 0.5319613814353943, "camel_30927": 0.5320547223091125, "aqua_rat_67452": 0.5321787595748901, "camel_31949": 0.53242427110672, "camel_30959": 0.5325037837028503, "camel_30950": 0.5325437784194946, "camel_31164": 0.5325533151626587, "camel_36425": 0.5327138304710388, "camel_31199": 0.5329264402389526, "camel_36490": 0.5330857038497925, "camel_36466": 0.5330912470817566, "camel_36195": 0.5331166386604309, "camel_47836": 0.5331376194953918, "camel_47405": 0.5331774950027466, "camel_30833": 0.5331991314888, "camel_49705": 0.5332236289978027, "camel_36412": 0.5333613157272339, "camel_29907": 0.5333716869354248, "camel_31168": 0.53342205286026, "camel_31639": 0.5335975885391235, "camel_44797": 0.533633828163147, "camel_36477": 0.5337198376655579, "camel_19488": 0.5337740778923035, "camel_31933": 0.5337923169136047, "camel_19558": 0.5338014960289001, "camel_31497": 0.5338437557220459, "camel_29908": 0.5339049696922302, "camel_40408": 0.5339247584342957, "camel_47725": 0.5339394211769104, "camel_40467": 0.5340312123298645, "camel_36396": 0.5342831611633301, "camel_17610": 0.5345305800437927, "camel_17730": 0.5346959829330444, "camel_37916": 0.5348215699195862, "camel_36410": 0.535148561000824, "camel_36473": 0.5356441140174866, "camel_36352": 0.5356855392456055, "camel_36465": 0.5357049703598022, "camel_17736": 0.5357969403266907, "camel_36476": 0.5360384583473206, "camel_30407": 0.5361013412475586, "camel_30284": 0.5361612439155579, "camel_31660": 0.536236584186554, "camel_17702": 0.5362728834152222, "camel_31946": 0.5365402102470398, "camel_36475": 0.5368545055389404, "camel_31179": 0.5370046496391296, "camel_36472": 0.5374855995178223, "camel_47700": 0.5375317335128784, "camel_36497": 0.5375610589981079, "camel_36713": 0.5376302599906921, "camel_31969": 0.537707507610321, "camel_47814": 0.5377970933914185, "camel_30843": 0.5378246307373047, "camel_36443": 0.5378482341766357, "camel_47682": 0.5379825234413147, "camel_36437": 0.5379915833473206, "camel_36439": 0.5380110740661621, "camel_18936": 0.5381754636764526, "camel_36413": 0.5384629368782043, "camel_31174": 0.5385464429855347, "camel_18910": 0.538688600063324, "TheoremQA_mingyin/Riesz-representation-theorem1.json": 0.5387546420097351, "camel_40712": 0.538936972618103, "camel_30770": 0.5389853119850159, "camel_36848": 0.5391908884048462, "camel_36400": 0.5393403768539429, "camel_30935": 0.5393517017364502, "camel_19584": 0.5395703315734863, "camel_30536": 0.5396502614021301, "camel_30826": 0.5399604439735413, "camel_36752": 0.5399859547615051, "camel_17800": 0.5400111079216003, "camel_47755": 0.5400372743606567, "camel_40671": 0.540219247341156, "camel_31745": 0.5402409434318542, "camel_36929": 0.5403206944465637, "camel_47766": 0.5403311252593994, "camel_36440": 0.5404388904571533, "camel_40703": 0.5405799746513367, "camel_19629": 0.5406901836395264, "camel_31929": 0.5407701134681702, "camel_19368": 0.5414224863052368, "camel_31459": 0.5414265394210815, "camel_17632": 0.5414555072784424, "camel_36406": 0.5415700674057007, "camel_19519": 0.5417223572731018, "camel_36404": 0.5419620871543884, "camel_17615": 0.5420706868171692, "camel_36683": 0.5423704981803894, "camel_36415": 0.5424354672431946, "camel_17757": 0.542659342288971, "camel_47760": 0.5426932573318481, "camel_36581": 0.5428382754325867, "camel_39278": 0.5430434942245483, "camel_17722": 0.5435267686843872, "camel_28384": 0.5436030626296997, "camel_30740": 0.543648898601532, "camel_36447": 0.5439633131027222, "camel_31718": 0.5441163182258606, "camel_36453": 0.5441790223121643, "camel_17629": 0.5445325374603271, "camel_36460": 0.5446269512176514, "camel_36335": 0.5450024604797363, "camel_19436": 0.5452442765235901, "camel_36463": 0.5457152128219604, "camel_36428": 0.5463266372680664, "camel_19423": 0.5465152263641357, "camel_31963": 0.5468242764472961, "camel_47786": 0.5475279688835144, "camel_36858": 0.5478152632713318, "camel_36775": 0.5479418039321899, "camel_36419": 0.5479826927185059, "camel_36830": 0.5480570793151855, "camel_47724": 0.5484936833381653, "camel_36777": 0.5486655831336975, "camel_36423": 0.548712432384491, "camel_36424": 0.5488004088401794, "camel_17641": 0.5500338673591614, "camel_36457": 0.5501046776771545, "camel_36418": 0.5507468581199646, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.5509354472160339, "camel_19531": 0.5511391162872314, "camel_17631": 0.5515437722206116, "camel_36435": 0.5516839623451233, "camel_36478": 0.5517570972442627, "camel_17692": 0.5529800057411194, "camel_36456": 0.5541431903839111, "camel_36441": 0.555760383605957, "camel_18908": 0.5562911629676819, "camel_17657": 0.5563680529594421, "camel_36422": 0.5565590262413025, "camel_17618": 0.5581917762756348, "camel_36451": 0.5588950514793396, "camel_36201": 0.5593872666358948, "camel_36502": 0.5599496960639954, "camel_36417": 0.5603389739990234, "camel_36938": 0.5609766840934753, "camel_18943": 0.5617940425872803, "camel_36458": 0.5622241497039795, "camel_19374": 0.5642457008361816, "camel_46120": 0.5674347281455994, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.569319486618042, "camel_47707": 0.570740282535553, "camel_36936": 0.5717910528182983, "camel_17621": 0.5810036063194275, "camel_17654": 0.5878703594207764, "camel_17637": 0.592388391494751, "camel_17674": 0.5964474678039551, "camel_17639": 0.6168968081474304, "TheoremQA_maxku/cv-imageprocessing1-morphology.json": 0.8912543058395386}, "TheoremQA_jianyu_xu/Ramsey_5.json": {"camel_23720": 0, "camel_21111": 0, "camel_23798": 0, "camel_22170": 0, "camel_22215": 0, "camel_21784": 0, "camel_22202": 0, "camel_23732": 0, "camel_23815": 0, "camel_22176": 0, "camel_22182": 0, "camel_23688": 0, "camel_23723": 0, "camel_23681": 0, "camel_23692": 0, "camel_23713": 0, "camel_23703": 0, "camel_21822": 0, "camel_21174": 0, "camel_21398": 0, "camel_21809": 0, "camel_23825": 0, "camel_23826": 0, "camel_23700": 0, "camel_23724": 0, "camel_23706": 0, "camel_23807": 0, "camel_23758": 0, "camel_23709": 0, "camel_23794": 0, "camel_23683": 0, "camel_23727": 0, "camel_23745": 0, "camel_21128": 0, "camel_21271": 0, "camel_23689": 0, "camel_21171": 0, "camel_21204": 0, "camel_21782": 0, "camel_23729": 0, "camel_21133": 0, "camel_23788": 0, "camel_21192": 0, "camel_21197": 0, "camel_23762": 0, "camel_22117": 0, "camel_21180": 0, "camel_23710": 0, "camel_21199": 0, "camel_23742": 0, "camel_23735": 0, "camel_21144": 0, "camel_23754": 0, "camel_20577": 0, "camel_21129": 0, "camel_23736": 0, "camel_23684": 0, "camel_23757": 0, "camel_23696": 0, "camel_21147": 0, "camel_23680": 0, "camel_23707": 0, "camel_23749": 0, "camel_23734": 0, "camel_23717": 0, "TheoremQA_jianyu_xu/Ramsey_5.json": 0, "camel_23739": 0, "camel_23751": 0, "camel_23722": 0, "camel_21167": 0, "camel_23697": 0, "camel_23699": 0, "camel_23752": 0, "camel_23690": 0, "camel_21183": 0, "camel_21191": 0, "camel_21139": 0, "camel_23704": 0, "camel_21157": 0, "camel_21151": 0, "camel_21127": 0, "camel_21163": 0, "camel_21135": 0, "camel_21175": 0, "camel_23701": 0, "camel_21161": 0, "camel_21179": 0, "camel_21170": 0, "camel_23737": 0, "camel_21130": 0, "camel_21182": 0, "camel_21143": 0, "camel_23719": 0, "camel_21121": 0, "camel_21125": 0, "camel_21124": 0, "camel_23816": 0, "camel_21173": 0, "camel_21184": 0, "camel_23755": 0, "camel_21162": 0, "camel_21196": 0, "camel_21153": 0, "camel_23731": 0, "camel_21145": 0, "camel_21187": 0, "camel_21164": 0, "camel_21158": 0, "camel_23682": 0, "camel_21120": 0, "camel_21194": 0, "camel_23714": 0, "camel_21807": 0, "camel_23695": 0, "camel_21198": 0, "camel_21156": 0, "camel_21159": 0, "camel_23693": 0, "camel_21185": 0, "camel_21142": 0, "camel_21122": 0, "camel_21188": 0, "camel_21134": 0, "camel_23711": 0, "camel_23796": 0, "camel_21193": 0, "camel_23685": 0, "camel_21131": 0, "camel_23747": 0, "camel_21141": 0, "camel_21152": 0, "camel_21136": 0, "camel_23744": 0, "camel_21132": 0, "camel_21126": 0, "camel_21172": 0, "camel_23705": 0, "camel_21146": 0, "camel_23753": 0, "camel_21123": 0, "camel_21166": 0, "camel_21154": 0, "camel_23750": 0, "camel_23741": 0, "camel_21168": 0, "camel_23748": 0, "camel_21149": 0, "camel_21208": 0, "camel_21181": 0, "camel_23715": 0, "camel_23721": 0, "camel_23759": 0, "camel_21148": 0, "camel_21169": 0, "camel_23686": 0, "camel_21189": 0, "camel_21155": 0, "camel_22120": 0, "camel_23712": 0, "camel_21178": 0, "camel_21160": 0, "camel_21137": 0, "camel_21190": 0, "camel_21195": 0, "camel_21428": 0, "camel_21176": 0, "camel_21186": 0, "camel_36368": 0.713538646697998, "aqua_rat_58088": 0.7136598825454712, "aqua_rat_31932": 0.7139577865600586, "math_test_prealgebra_1071": 0.7140364050865173, "aqua_rat_85357": 0.714256763458252, "math_train_counting_and_probability_817": 0.7144683003425598, "aqua_rat_76154": 0.7163504958152771, "math_test_counting_and_probability_686": 0.7166059017181396, "math_test_prealgebra_1306": 0.7173557877540588, "math_train_counting_and_probability_757": 0.7196165323257446, "math_test_counting_and_probability_987": 0.7226817607879639, "math_train_prealgebra_446": 0.7230257391929626, "aqua_rat_83797": 0.7240384817123413, "math_train_counting_and_probability_1110": 0.7241977453231812, "aqua_rat_38901": 0.7262093424797058, "aqua_rat_46132": 0.7268720865249634, "aqua_rat_50073": 0.7273263931274414, "math_train_counting_and_probability_914": 0.7279415726661682, "math_train_counting_and_probability_5119": 0.7297948002815247, "aqua_rat_51040": 0.7338941097259521, "aqua_rat_63918": 0.734193742275238, "TheoremQA_jianyu_xu/Ramsey_4.json": 0.737311840057373, "aqua_rat_60481": 0.7381008267402649, "aqua_rat_75954": 0.7394018173217773, "aqua_rat_84407": 0.7440932989120483, "math_test_counting_and_probability_763": 0.7454193830490112, "TheoremQA_jianyu_xu/Ramsey_3.json": 0.7460793256759644, "aqua_rat_47964": 0.7461524605751038, "aqua_rat_37692": 0.7473905086517334, "TheoremQA_jianyu_xu/Ramsey_6.json": 0.7504610419273376, "aqua_rat_46637": 0.7551748752593994, "TheoremQA_jianyu_xu/Ramsey_2.json": 0.7571732997894287, "aqua_rat_44859": 0.7581210732460022}, "TheoremQA_tonyxia/particle4.json": {"TheoremQA_tonyxia/particle4.json": 0, "gsm_rft_20337": 0.5422244668006897, "gsm_rft_21267": 0.5422244668006897, "gsm_train_12934": 0.5422244668006897, "gsm_rft_9527": 0.5426174998283386, "gsm_rft_9227": 0.5427396893501282, "gsm_rft_13654": 0.5428215861320496, "aqua_rat_8426": 0.5428451895713806, "camel_43964": 0.5428745150566101, "gsm_train_12152": 0.5429346561431885, "camel_29490": 0.5432146787643433, "gsm_rft_29147": 0.5433602929115295, "aqua_rat_69977": 0.5434440970420837, "gsm_train_10956": 0.5435264706611633, "gsm_rft_23284": 0.5435561537742615, "camel_17811": 0.5437433123588562, "camel_31983": 0.5437561869621277, "TheoremQA_panlu/energy_conservation1.json": 0.5439779758453369, "gsm_rft_17823": 0.5443686246871948, "gsm_rft_9980": 0.544467031955719, "gsm_rft_31387": 0.5446563363075256, "camel_29451": 0.5446923971176147, "camel_16699": 0.5448929071426392, "gsm_rft_12732": 0.5449298620223999, "gsm_train_9298": 0.5449298620223999, "gsm_rft_1734": 0.5449298620223999, "gsm_rft_16370": 0.5450422763824463, "gsm_rft_7319": 0.545157253742218, "gsm_train_7388": 0.545157253742218, "gsm_train_28955": 0.5453445911407471, "gsm_rft_30111": 0.5453445911407471, "math_test_algebra_578": 0.5454443693161011, "camel_29485": 0.5455012321472168, "TheoremQA_panlu/black_hole1.json": 0.5455231070518494, "camel_29498": 0.5455678105354309, "gsm_rft_881": 0.5455853343009949, "camel_16676": 0.5456022620201111, "camel_30858": 0.545763373374939, "camel_28804": 0.5458425879478455, "gsm_rft_12049": 0.5459110140800476, "gsm_rft_16725": 0.5460809469223022, "camel_45074": 0.5461653470993042, "gsm_rft_31476": 0.5462311506271362, "gsm_rft_10319": 0.5462665557861328, "gsm_rft_29667": 0.546294093132019, "gsm_train_23496": 0.5463423728942871, "gsm_rft_20023": 0.5463595986366272, "gsm_train_10506": 0.5464085936546326, "gsm_rft_15764": 0.5464192628860474, "camel_29454": 0.54645836353302, "gsm_rft_4474": 0.5465087294578552, "gsm_rft_1756": 0.5465441942214966, "gsm_train_9534": 0.5465441942214966, "gsm_rft_18266": 0.5465521812438965, "gsm_train_553": 0.5465521812438965, "camel_39446": 0.5466223955154419, "gsm_rft_681": 0.5467426776885986, "gsm_rft_24393": 0.5468140840530396, "gsm_train_34664": 0.5468140840530396, "gsm_rft_21334": 0.5468202829360962, "camel_43981": 0.5468780994415283, "gsm_rft_24784": 0.5470386147499084, "gsm_train_22355": 0.5470386147499084, "gsm_rft_5013": 0.5472617745399475, "camel_28809": 0.5474000573158264, "camel_28808": 0.5474613308906555, "camel_29505": 0.5474961400032043, "gsm_rft_35002": 0.5475132465362549, "gsm_rft_26630": 0.5476075410842896, "aqua_rat_41482": 0.5476084351539612, "gsm_rft_32685": 0.5477035641670227, "gsm_rft_10502": 0.5478193759918213, "gsm_rft_13342": 0.5483663082122803, "gsm_rft_25773": 0.5484397411346436, "gsm_rft_26010": 0.5485303401947021, "gsm_train_3314": 0.5485466718673706, "gsm_rft_18060": 0.5485466718673706, "TheoremQA_xinyi/work_energy_theorem.json": 0.5485879182815552, "gsm_rft_22295": 0.5487263202667236, "gsm_rft_30773": 0.5487354397773743, "gsm_rft_57": 0.5487604737281799, "gsm_rft_10110": 0.5487967729568481, "camel_16651": 0.5487970113754272, "gsm_train_10116": 0.5487979054450989, "camel_16660": 0.5490522980690002, "gsm_rft_5441": 0.549275815486908, "gsm_train_6133": 0.5493649840354919, "gsm_train_25711": 0.5494973659515381, "gsm_rft_19435": 0.5494974255561829, "gsm_rft_17440": 0.5496379733085632, "gsm_rft_29222": 0.5496379733085632, "gsm_rft_28497": 0.5497978925704956, "gsm_train_18516": 0.5497978925704956, "aqua_rat_57727": 0.549842119216919, "gsm_rft_29727": 0.5498443245887756, "gsm_rft_25020": 0.5501008033752441, "gsm_rft_32171": 0.5501008033752441, "gsm_rft_31299": 0.5501008033752441, "gsm_train_30351": 0.5501008033752441, "gsm_rft_35356": 0.5501142144203186, "camel_29501": 0.5501962304115295, "gsm_rft_12524": 0.5502886176109314, "gsm_rft_33530": 0.5503752827644348, "gsm_rft_26941": 0.550482988357544, "camel_5894": 0.550702691078186, "gsm_rft_2125": 0.5507375001907349, "gsm_rft_10726": 0.5508320927619934, "gsm_rft_9144": 0.5508977770805359, "gsm_train_30230": 0.5509634017944336, "gsm_rft_14979": 0.5510117411613464, "gsm_rft_5229": 0.5510817766189575, "camel_28856": 0.551180362701416, "camel_19981": 0.5513523817062378, "aqua_rat_73760": 0.5513641238212585, "math_train_prealgebra_1191": 0.5513972043991089, "camel_29440": 0.5517284274101257, "gsm_train_5240": 0.5517878532409668, "gsm_rft_5187": 0.5517878532409668, "gsm_rft_14892": 0.5517878532409668, "gsm_rft_18313": 0.551859974861145, "camel_5859": 0.5519057512283325, "camel_28812": 0.5519561171531677, "aqua_rat_54375": 0.5522307753562927, "camel_24382": 0.5528242588043213, "camel_29482": 0.5529948472976685, "gsm_rft_12805": 0.5530418753623962, "gsm_rft_32549": 0.5531657338142395, "gsm_train_8964": 0.5531657338142395, "gsm_rft_20286": 0.5533747673034668, "camel_28840": 0.5537257790565491, "gsm_rft_35619": 0.5539368987083435, "camel_28822": 0.554164469242096, "gsm_rft_30108": 0.5542007684707642, "gsm_rft_14306": 0.554381251335144, "aqua_rat_9493": 0.5544639229774475, "gsm_train_7370": 0.5547661781311035, "aqua_rat_11549": 0.5549496412277222, "gsm_rft_7211": 0.5558640360832214, "gsm_rft_1431": 0.5560877323150635, "gsm_rft_29129": 0.5561627149581909, "camel_43945": 0.5567503571510315, "camel_28866": 0.556946873664856, "gsm_rft_15416": 0.557377278804779, "camel_29487": 0.5578386187553406, "camel_39513": 0.5578677654266357, "gsm_rft_24421": 0.5582656264305115, "camel_43944": 0.5586318969726562, "gsm_train_2068": 0.5589619278907776, "gsm_rft_4583": 0.5589619278907776, "gsm_rft_31346": 0.5590680241584778, "camel_28873": 0.5597553253173828, "camel_16713": 0.5598695278167725, "camel_16647": 0.5600603222846985, "gsm_rft_16695": 0.5602286458015442, "gsm_rft_32160": 0.5603421926498413, "gsm_rft_42": 0.5605311393737793, "gsm_train_3705": 0.5605311393737793, "camel_24344": 0.5613752603530884, "gsm_train_31725": 0.5619319081306458, "gsm_rft_6656": 0.5619319081306458, "math_train_algebra_24942": 0.5623856782913208, "gsm_rft_22887": 0.5639851689338684, "camel_16646": 0.5646098256111145, "camel_16677": 0.5648194551467896, "TheoremQA_panlu/rigid-body3.json": 0.5648930072784424, "camel_28811": 0.5649750232696533, "camel_16663": 0.5675434470176697, "camel_29464": 0.5689002275466919, "camel_16690": 0.5696122050285339, "camel_16703": 0.5705894231796265, "camel_28847": 0.5711930394172668, "camel_43979": 0.5713794231414795, "TheoremQA_tonyxia/statisticalphysics5.json": 0.5716264247894287, "camel_29496": 0.5729424357414246, "camel_16671": 0.5736414790153503, "camel_45999": 0.5748599171638489, "camel_16673": 0.5760033130645752, "camel_16680": 0.5778754949569702, "TheoremQA_tonyxia/semiconductor2.json": 0.5787382125854492, "TheoremQA_tonyxia/atom4.json": 0.5793105959892273, "camel_16682": 0.5793886184692383, "TheoremQA_tonyxia/wave2.json": 0.5823944211006165, "gsm_rft_35145": 0.5832183361053467, "camel_16712": 0.5849270224571228, "camel_16681": 0.5889209508895874, "gsm_rft_22533": 0.589609682559967, "TheoremQA_tonyxia/semiconductor3.json": 0.5905132293701172, "camel_16674": 0.5937008857727051, "camel_29484": 0.5941981673240662, "TheoremQA_tonyxia/photoelectric1.json": 0.597749650478363, "gsm_rft_10505": 0.597974956035614, "gsm_train_29099": 0.5986589789390564, "gsm_rft_17764": 0.6005458235740662, "camel_28846": 0.600972592830658, "gsm_rft_22397": 0.6034758687019348, "TheoremQA_tonyxia/relativity3.json": 0.7052839398384094, "TheoremQA_tonyxia/nuclear3.json": 0.712086021900177, "TheoremQA_xinyi/momentum.json": 0.7189251780509949, "TheoremQA_tonyxia/particle5.json": 0.7255537509918213, "TheoremQA_tonyxia/particle6.json": 0.8603156805038452}, "TheoremQA_jianyu_xu/Binomial_2.json": {"camel_20672": 0, "camel_20261": 0, "camel_20175": 0, "camel_20038": 0, "camel_20356": 0, "camel_20290": 0, "aqua_rat_84198": 0.712232768535614, "aqua_rat_63874": 0.7123103141784668, "aqua_rat_29993": 0.7125812768936157, "aqua_rat_78940": 0.7126531600952148, "math_test_counting_and_probability_863": 0.7126731276512146, "aqua_rat_72503": 0.7127573490142822, "aqua_rat_12497": 0.7129104733467102, "math_train_counting_and_probability_1032": 0.7129502892494202, "aqua_rat_43161": 0.713168203830719, "aqua_rat_18686": 0.7132489085197449, "aqua_rat_3163": 0.7133061289787292, "aqua_rat_19626": 0.7134957909584045, "aqua_rat_19403": 0.7135385274887085, "aqua_rat_7959": 0.7135907411575317, "aqua_rat_70378": 0.7136129140853882, "aqua_rat_48451": 0.7138701677322388, "aqua_rat_73594": 0.7140425443649292, "aqua_rat_45708": 0.7141112089157104, "aqua_rat_16417": 0.7141768336296082, "aqua_rat_64936": 0.7142787575721741, "math_test_prealgebra_1750": 0.7144070267677307, "aqua_rat_7334": 0.7144119739532471, "aqua_rat_3068": 0.7145747542381287, "math_test_counting_and_probability_1007": 0.7149551510810852, "aqua_rat_82592": 0.7150365710258484, "aqua_rat_26912": 0.7151519656181335, "aqua_rat_4502": 0.7154277563095093, "aqua_rat_52140": 0.7155122756958008, "aqua_rat_87153": 0.715682327747345, "aqua_rat_11382": 0.7157291769981384, "aqua_rat_12345": 0.715800404548645, "aqua_rat_7455": 0.7159295678138733, "aqua_rat_27673": 0.7159850001335144, "aqua_rat_39612": 0.7163966298103333, "aqua_rat_40418": 0.7165147066116333, "aqua_rat_41995": 0.71659255027771, "aqua_rat_45187": 0.7166886925697327, "aqua_rat_17322": 0.7167510390281677, "aqua_rat_55612": 0.7167779803276062, "aqua_rat_9747": 0.7168996334075928, "aqua_rat_36159": 0.7172911763191223, "aqua_rat_19073": 0.717352032661438, "aqua_rat_73109": 0.7175517082214355, "aqua_rat_55663": 0.7176439762115479, "aqua_rat_24240": 0.7180168032646179, "aqua_rat_79348": 0.7184937596321106, "aqua_rat_64752": 0.7185216546058655, "aqua_rat_87194": 0.7186099290847778, "aqua_rat_14470": 0.7186311483383179, "math_train_counting_and_probability_1063": 0.7189075350761414, "aqua_rat_5740": 0.718939483165741, "aqua_rat_29264": 0.7189907431602478, "aqua_rat_6238": 0.7190627455711365, "aqua_rat_44481": 0.71909099817276, "aqua_rat_69596": 0.7192062139511108, "aqua_rat_72902": 0.7194022536277771, "aqua_rat_15961": 0.7196922898292542, "aqua_rat_32214": 0.719771146774292, "aqua_rat_62457": 0.7202727794647217, "aqua_rat_3300": 0.720287561416626, "aqua_rat_51352": 0.7204536199569702, "aqua_rat_60948": 0.7204653024673462, "aqua_rat_63938": 0.7204828858375549, "aqua_rat_80829": 0.7206602096557617, "aqua_rat_52425": 0.7207039594650269, "aqua_rat_89049": 0.7207414507865906, "aqua_rat_36722": 0.7207808494567871, "aqua_rat_33999": 0.7209065556526184, "aqua_rat_75975": 0.7209616303443909, "aqua_rat_6017": 0.7209789752960205, "aqua_rat_38553": 0.7210160493850708, "aqua_rat_12003": 0.7210758924484253, "aqua_rat_63387": 0.7212553024291992, "aqua_rat_66661": 0.7216277718544006, "aqua_rat_54905": 0.72169029712677, "aqua_rat_1550": 0.7218806743621826, "aqua_rat_48428": 0.7220056653022766, "aqua_rat_18666": 0.7220875024795532, "aqua_rat_2305": 0.7224956154823303, "aqua_rat_60707": 0.7226375937461853, "aqua_rat_35991": 0.7227218747138977, "aqua_rat_8636": 0.7227444052696228, "aqua_rat_16947": 0.7228107452392578, "aqua_rat_75690": 0.7228153347969055, "aqua_rat_28709": 0.722865641117096, "aqua_rat_14535": 0.722942054271698, "aqua_rat_4646": 0.7229588627815247, "aqua_rat_26124": 0.7230069041252136, "aqua_rat_62255": 0.7231466174125671, "aqua_rat_61648": 0.7231628894805908, "aqua_rat_932": 0.7232294678688049, "aqua_rat_66552": 0.723250687122345, "aqua_rat_7001": 0.7233552932739258, "aqua_rat_30725": 0.7237063646316528, "aqua_rat_57746": 0.7237620949745178, "aqua_rat_21632": 0.7237633466720581, "aqua_rat_77551": 0.7237803936004639, "aqua_rat_15466": 0.7239530086517334, "aqua_rat_41993": 0.7239587306976318, "aqua_rat_12425": 0.7240152359008789, "aqua_rat_42248": 0.7240478992462158, "aqua_rat_35796": 0.7241653203964233, "aqua_rat_47160": 0.7242461442947388, "aqua_rat_16873": 0.7244009971618652, "aqua_rat_37328": 0.7244080901145935, "aqua_rat_9967": 0.7245203256607056, "aqua_rat_9868": 0.7246785759925842, "aqua_rat_56247": 0.7247675657272339, "aqua_rat_80157": 0.7248355150222778, "aqua_rat_82385": 0.7248764634132385, "math_train_counting_and_probability_379": 0.7248879075050354, "aqua_rat_30088": 0.7248966097831726, "aqua_rat_75182": 0.7251177430152893, "aqua_rat_87433": 0.7251830101013184, "aqua_rat_17399": 0.7253279685974121, "aqua_rat_2281": 0.7253425717353821, "aqua_rat_86061": 0.7254829406738281, "aqua_rat_14704": 0.7258116006851196, "aqua_rat_25285": 0.7260076999664307, "aqua_rat_41332": 0.7265238165855408, "aqua_rat_17215": 0.7266174554824829, "aqua_rat_80880": 0.7269368767738342, "aqua_rat_45982": 0.7269774675369263, "aqua_rat_61403": 0.7271273732185364, "aqua_rat_33285": 0.7273908257484436, "aqua_rat_22365": 0.7275199294090271, "aqua_rat_31049": 0.7275874614715576, "aqua_rat_45147": 0.7276284098625183, "aqua_rat_46448": 0.7277224063873291, "aqua_rat_56123": 0.7279238700866699, "aqua_rat_65303": 0.7283616065979004, "aqua_rat_17550": 0.7284740209579468, "aqua_rat_30048": 0.7287110686302185, "aqua_rat_11004": 0.7287943363189697, "aqua_rat_79867": 0.7290086150169373, "aqua_rat_33841": 0.7290363311767578, "aqua_rat_12250": 0.729292631149292, "aqua_rat_46501": 0.7297669649124146, "aqua_rat_18810": 0.7298575043678284, "aqua_rat_26931": 0.7298763394355774, "aqua_rat_40903": 0.7305977940559387, "aqua_rat_76698": 0.730725884437561, "aqua_rat_57663": 0.7310255765914917, "aqua_rat_10159": 0.7313013076782227, "aqua_rat_36098": 0.7313275933265686, "aqua_rat_73969": 0.7316858768463135, "aqua_rat_69806": 0.7329413294792175, "aqua_rat_80683": 0.7330118417739868, "aqua_rat_31137": 0.7337725758552551, "aqua_rat_78850": 0.7343894839286804, "aqua_rat_77088": 0.7344644665718079, "aqua_rat_62723": 0.7344999313354492, "aqua_rat_65830": 0.7345413565635681, "aqua_rat_4340": 0.7347332239151001, "aqua_rat_15353": 0.7350813746452332, "aqua_rat_50978": 0.735251784324646, "aqua_rat_29935": 0.7365702390670776, "aqua_rat_67694": 0.7366963028907776, "aqua_rat_61793": 0.7374914288520813, "math_train_counting_and_probability_691": 0.7374929785728455, "aqua_rat_69444": 0.7377153635025024, "aqua_rat_34136": 0.7377661466598511, "aqua_rat_68557": 0.7383042573928833, "aqua_rat_83119": 0.7385370135307312, "math_train_counting_and_probability_29": 0.738750696182251, "aqua_rat_19831": 0.7389360666275024, "math_train_prealgebra_1740": 0.7391258478164673, "aqua_rat_3309": 0.7396533489227295, "aqua_rat_21916": 0.7401999831199646, "aqua_rat_51032": 0.7403929829597473, "aqua_rat_27137": 0.7411559224128723, "aqua_rat_20032": 0.7414031028747559, "aqua_rat_36909": 0.7416111826896667, "aqua_rat_53069": 0.7428391575813293, "aqua_rat_33635": 0.7434202432632446, "aqua_rat_15322": 0.7436968684196472, "aqua_rat_8913": 0.7437823414802551, "aqua_rat_14573": 0.744018018245697, "aqua_rat_38330": 0.7441434860229492, "aqua_rat_19798": 0.7463395595550537, "aqua_rat_16429": 0.7505541443824768, "aqua_rat_34268": 0.7512773871421814, "aqua_rat_57419": 0.7513636350631714, "aqua_rat_32332": 0.7528771758079529, "aqua_rat_77566": 0.754275918006897, "aqua_rat_17726": 0.7559592723846436, "aqua_rat_79806": 0.7716442942619324, "aqua_rat_37506": 0.7772343754768372, "aqua_rat_67588": 0.7786806225776672, "aqua_rat_3845": 0.7805655002593994, "aqua_rat_23851": 0.7818478345870972, "aqua_rat_32025": 0.7889648079872131, "aqua_rat_19231": 0.7920995354652405, "aqua_rat_59175": 0.7927252054214478}, "TheoremQA_jianyu_xu/Ramsey_6.json": {"camel_23829": 0, "camel_23746": 0, "camel_22161": 0, "camel_21793": 0, "camel_23782": 0, "camel_21131": 0, "camel_22238": 0, "camel_23691": 0, "camel_23807": 0, "camel_23736": 0, "camel_21133": 0, "camel_21792": 0, "camel_23825": 0, "camel_21171": 0, "camel_21195": 0, "camel_21160": 0, "camel_21103": 0, "camel_23414": 0, "camel_23771": 0, "camel_22959": 0, "camel_23795": 0, "camel_22927": 0, "camel_22928": 0, "camel_22164": 0, "camel_22094": 0, "camel_23689": 0, "camel_22917": 0, "camel_22128": 0, "camel_23818": 0, "camel_23694": 0, "camel_23708": 0, "camel_23730": 0, "camel_23743": 0, "camel_23764": 0, "camel_21781": 0, "camel_21158": 0, "camel_23763": 0, "camel_22202": 0, "camel_23828": 0, "camel_23776": 0, "camel_21174": 0, "camel_21182": 0, "camel_23758": 0, "camel_21116": 0, "camel_22120": 0, "camel_22934": 0, "camel_21170": 0, "camel_21121": 0, "camel_23784": 0, "camel_23798": 0, "camel_21185": 0, "camel_22203": 0, "camel_23418": 0, "camel_21774": 0, "camel_21130": 0, "camel_22207": 0, "camel_23773": 0, "camel_21106": 0, "camel_21168": 0, "camel_23780": 0, "camel_23725": 0, "camel_23738": 0, "camel_21152": 0, "camel_23721": 0, "camel_23756": 0, "camel_23728": 0, "camel_21143": 0, "camel_23699": 0, "camel_23715": 0, "camel_23722": 0, "camel_23775": 0, "camel_21173": 0, "camel_23816": 0, "camel_23733": 0, "camel_23744": 0, "camel_23827": 0, "camel_23799": 0, "camel_23726": 0, "camel_23696": 0, "camel_21144": 0, "camel_23712": 0, "camel_23766": 0, "camel_23687": 0, "camel_23732": 0, "camel_23747": 0, "camel_22905": 0, "camel_23692": 0, "camel_23739": 0, "camel_23713": 0, "camel_21125": 0, "camel_23681": 0, "camel_23707": 0, "camel_21124": 0, "camel_22955": 0, "camel_23741": 0, "TheoremQA_jianyu_xu/Ramsey_6.json": 0, "camel_21188": 0, "camel_21164": 0, "camel_21163": 0, "camel_22230": 0, "camel_21181": 0, "camel_21153": 0, "camel_21157": 0, "camel_21122": 0, "camel_23682": 0, "camel_23755": 0, "camel_21194": 0, "camel_23701": 0, "camel_21136": 0, "camel_23731": 0, "camel_23737": 0, "camel_23788": 0, "camel_21149": 0, "camel_21172": 0, "camel_21190": 0, "camel_22177": 0, "camel_23714": 0, "camel_21065": 0, "camel_21162": 0, "camel_21159": 0, "camel_21178": 0, "camel_23790": 0, "camel_21198": 0, "camel_23702": 0, "camel_21127": 0, "camel_21137": 0, "camel_23753": 0, "camel_21129": 0, "camel_21142": 0, "camel_21120": 0, "camel_21166": 0, "camel_23740": 0, "camel_23729": 0, "camel_21187": 0, "camel_21151": 0, "camel_23735": 0, "camel_23710": 0, "camel_23742": 0, "camel_21123": 0, "camel_23685": 0, "camel_23724": 0, "camel_23693": 0, "camel_21175": 0, "camel_23700": 0, "camel_21180": 0, "camel_23789": 0, "camel_23711": 0, "camel_21782": 0, "camel_21135": 0, "camel_23698": 0, "camel_21132": 0, "camel_23704": 0, "camel_21784": 0, "camel_23727": 0, "camel_21179": 0, "camel_21134": 0, "camel_21146": 0, "camel_22947": 0, "camel_23686": 0, "camel_23808": 0, "camel_21145": 0, "camel_23734": 0, "camel_23748": 0, "camel_23718": 0, "camel_21193": 0, "camel_23706": 0, "camel_21186": 0, "camel_23684": 0, "camel_23717": 0, "camel_23680": 0, "camel_23750": 0, "camel_23719": 0, "camel_21161": 0, "camel_23688": 0, "camel_21148": 0, "camel_23720": 0, "camel_23709": 0, "camel_23723": 0, "camel_21155": 0, "camel_23705": 0, "camel_23683": 0, "camel_23749": 0, "camel_23703": 0, "camel_23697": 0, "camel_23751": 0, "camel_23745": 0, "camel_21156": 0, "camel_23759": 0, "camel_21139": 0, "camel_21189": 0, "camel_21191": 0, "camel_21176": 0, "camel_23690": 0, "camel_23752": 0, "camel_23794": 0, "math_train_counting_and_probability_914": 0.8000677227973938, "TheoremQA_jianyu_xu/Ramsey_4.json": 0.8485843539237976, "TheoremQA_jianyu_xu/Ramsey_5.json": 0.852218747138977, "TheoremQA_jianyu_xu/Ramsey_3.json": 0.8611673712730408, "TheoremQA_jianyu_xu/Ramsey_2.json": 0.8620915412902832}, "TheoremQA_wenhuchen/series_convergen2.json": {"aqua_rat_51193": 0.7093698382377625, "camel_30366": 0.7093895077705383, "gsm_rft_2696": 0.7094355225563049, "camel_31949": 0.7095035910606384, "camel_31676": 0.7095059156417847, "camel_31872": 0.7095125317573547, "camel_31497": 0.7097436189651489, "camel_30050": 0.7099565267562866, "aqua_rat_34388": 0.7100086212158203, "camel_30720": 0.7100698351860046, "camel_31960": 0.7101005911827087, "camel_31516": 0.7102184295654297, "camel_31633": 0.7103267312049866, "camel_31919": 0.7104620337486267, "aqua_rat_75359": 0.7104763388633728, "camel_31614": 0.7105512022972107, "camel_30825": 0.7105840444564819, "camel_31992": 0.7107695937156677, "camel_31275": 0.7108278870582581, "camel_31989": 0.7108449339866638, "camel_31684": 0.7110071778297424, "camel_30866": 0.711046576499939, "camel_31987": 0.7110809683799744, "camel_31527": 0.7112377285957336, "camel_31637": 0.7112627625465393, "camel_30812": 0.711277961730957, "aqua_rat_19560": 0.7112857699394226, "camel_31920": 0.7113999128341675, "camel_30947": 0.7114818096160889, "camel_31931": 0.7115694284439087, "aqua_rat_77787": 0.7117205858230591, "camel_30504": 0.7117990255355835, "camel_31908": 0.7118074893951416, "camel_31584": 0.7118383049964905, "camel_37764": 0.7119389772415161, "math_test_algebra_1836": 0.7120205163955688, "camel_30957": 0.7120875716209412, "camel_30864": 0.7120979428291321, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus2.json": 0.7121440172195435, "camel_31228": 0.7123170495033264, "aqua_rat_54656": 0.7123299837112427, "camel_31745": 0.7123706936836243, "camel_30949": 0.7125376462936401, "camel_31740": 0.7125382423400879, "camel_30936": 0.7127896547317505, "camel_30862": 0.7128901481628418, "camel_31977": 0.7129679918289185, "camel_30946": 0.7130056619644165, "camel_31887": 0.7132425904273987, "camel_30328": 0.7133013606071472, "camel_30912": 0.7135199308395386, "camel_31921": 0.7135990262031555, "camel_31467": 0.7138661742210388, "aqua_rat_41669": 0.7140544056892395, "camel_31091": 0.7140777111053467, "camel_31990": 0.7141349911689758, "camel_31766": 0.7141655683517456, "camel_31962": 0.714275598526001, "aqua_rat_53748": 0.7142950892448425, "camel_31973": 0.7143455147743225, "camel_31718": 0.7143458724021912, "camel_30952": 0.714439332485199, "camel_30327": 0.7150464653968811, "camel_31190": 0.7150653600692749, "camel_30773": 0.7152376174926758, "aqua_rat_15035": 0.7153814435005188, "aqua_rat_1188": 0.7155409455299377, "camel_31356": 0.7156117558479309, "camel_31323": 0.7157402634620667, "aqua_rat_75361": 0.7159349918365479, "camel_31890": 0.7159656882286072, "camel_31948": 0.7159966230392456, "camel_31933": 0.7166656255722046, "camel_30339": 0.7168430089950562, "camel_31942": 0.7169402241706848, "camel_30934": 0.7169625163078308, "camel_31912": 0.7174824476242065, "camel_31918": 0.7174978852272034, "camel_31993": 0.7176340818405151, "aqua_rat_24346": 0.7177878022193909, "camel_30915": 0.7179649472236633, "aqua_rat_48885": 0.7179816961288452, "math_train_algebra_2272": 0.7179886102676392, "aqua_rat_50166": 0.7181853652000427, "camel_30534": 0.7185519933700562, "camel_31202": 0.7186962366104126, "aqua_rat_62741": 0.7187177538871765, "camel_30440": 0.7189768552780151, "math_test_algebra_1184": 0.7194225788116455, "camel_30527": 0.719451367855072, "camel_30834": 0.7195260524749756, "aqua_rat_36268": 0.7196736335754395, "aqua_rat_69318": 0.7197393774986267, "aqua_rat_30533": 0.7197525501251221, "camel_30749": 0.7201526165008545, "math_test_number_theory_373": 0.7201972007751465, "camel_30360": 0.7201979160308838, "camel_31975": 0.720329999923706, "camel_31645": 0.7207257151603699, "camel_30397": 0.7208183407783508, "camel_31958": 0.720884382724762, "camel_31946": 0.7208946943283081, "aqua_rat_9734": 0.7211500406265259, "camel_30093": 0.7214444875717163, "aqua_rat_12172": 0.7216711044311523, "camel_31848": 0.7218510508537292, "camel_30385": 0.721977174282074, "camel_30824": 0.7225790619850159, "camel_31864": 0.7227106094360352, "camel_31680": 0.722718358039856, "camel_30179": 0.722821831703186, "camel_31899": 0.7229037880897522, "aqua_rat_9255": 0.7232224941253662, "camel_30680": 0.7233930230140686, "aqua_rat_54426": 0.7234162092208862, "math_train_number_theory_7033": 0.7234848141670227, "camel_30874": 0.7238585352897644, "camel_30371": 0.7239627838134766, "camel_30485": 0.7239643335342407, "camel_30474": 0.7243369817733765, "camel_31452": 0.7244443893432617, "camel_30685": 0.724450945854187, "aqua_rat_67612": 0.724461019039154, "camel_31963": 0.7245790958404541, "camel_31994": 0.7249625325202942, "camel_31505": 0.7263497710227966, "camel_30409": 0.7263668775558472, "camel_30740": 0.7264487743377686, "camel_30927": 0.7266855835914612, "camel_30951": 0.7269590497016907, "camel_31863": 0.7276990413665771, "camel_31877": 0.727836549282074, "camel_30843": 0.727864682674408, "camel_31910": 0.7279513478279114, "camel_30346": 0.7282841801643372, "camel_30926": 0.7286789417266846, "camel_31241": 0.7286850810050964, "camel_31901": 0.7286964654922485, "camel_31936": 0.7290632724761963, "camel_30959": 0.729268491268158, "camel_31878": 0.7296481728553772, "math_train_number_theory_54": 0.7298111319541931, "camel_30942": 0.7299098968505859, "camel_30136": 0.7299531698226929, "camel_30921": 0.7301738262176514, "math_test_number_theory_1024": 0.7301883697509766, "camel_30754": 0.7305712699890137, "camel_31884": 0.7306057810783386, "camel_30858": 0.7308022379875183, "camel_31444": 0.7308077812194824, "camel_30396": 0.7312272191047668, "camel_31525": 0.7313632965087891, "camel_30325": 0.7318001389503479, "camel_31915": 0.7318587303161621, "camel_30939": 0.7320155501365662, "camel_31858": 0.7322326302528381, "camel_30383": 0.7325047254562378, "camel_30341": 0.7328206300735474, "camel_30342": 0.7328413724899292, "camel_31976": 0.732878565788269, "camel_31859": 0.7329943776130676, "aqua_rat_33897": 0.7341045141220093, "camel_30865": 0.7347455024719238, "camel_30353": 0.734931468963623, "camel_31869": 0.7350472211837769, "camel_31263": 0.735226035118103, "camel_30886": 0.7358211278915405, "camel_31968": 0.7368136048316956, "camel_31061": 0.7371281981468201, "camel_31881": 0.7373993992805481, "camel_30330": 0.7379569411277771, "aqua_rat_38959": 0.7382665872573853, "aqua_rat_57003": 0.7384640574455261, "camel_31057": 0.7387913465499878, "camel_31947": 0.7402490377426147, "camel_30338": 0.7403304576873779, "camel_30770": 0.740373432636261, "camel_30345": 0.7414031624794006, "camel_31842": 0.7421345710754395, "camel_30357": 0.7434733510017395, "camel_31984": 0.7449961304664612, "camel_30948": 0.7450705170631409, "camel_31974": 0.7458651661872864, "camel_30354": 0.7478664517402649, "camel_30374": 0.7488271594047546, "camel_31548": 0.7509291172027588, "camel_31880": 0.7513769268989563, "camel_30392": 0.7530323266983032, "aqua_rat_25391": 0.7557060122489929, "camel_31084": 0.76092529296875, "camel_30372": 0.7623032331466675, "aqua_rat_82861": 0.763933539390564, "aqua_rat_73910": 0.7657078504562378, "aqua_rat_69628": 0.7664816379547119, "aqua_rat_16186": 0.7679257392883301, "camel_30887": 0.7693443894386292, "camel_31759": 0.7693868279457092, "camel_28309": 0.7722602486610413, "aqua_rat_12993": 0.7728822231292725, "aqua_rat_13223": 0.7734863758087158}, "TheoremQA_xinyi/channel_capacity_3.json": {"TheoremQA_xinyi/channel_capacity_3.json": 0, "camel_41288": 0.5918458700180054, "camel_41244": 0.5919781923294067, "camel_21903": 0.5920143127441406, "aqua_rat_85903": 0.5921474695205688, "camel_25406": 0.5923388004302979, "camel_25363": 0.5923426151275635, "camel_41266": 0.5925453305244446, "camel_24368": 0.5926516056060791, "camel_25194": 0.5926589369773865, "camel_29132": 0.5928052067756653, "camel_41267": 0.5928264260292053, "camel_25445": 0.5928426384925842, "camel_28754": 0.5928719639778137, "camel_9476": 0.5930729508399963, "camel_25505": 0.5932211875915527, "camel_25435": 0.5932674407958984, "camel_29752": 0.5932722091674805, "camel_29327": 0.593311071395874, "camel_15832": 0.5934595465660095, "camel_37453": 0.5935086011886597, "camel_9485": 0.593670129776001, "camel_25408": 0.5937035083770752, "camel_41078": 0.5937547087669373, "camel_29302": 0.5937640070915222, "camel_21861": 0.5938631296157837, "camel_25447": 0.5938696265220642, "camel_39021": 0.5939494371414185, "camel_21848": 0.5939510464668274, "camel_41640": 0.5939984917640686, "camel_29052": 0.5941716432571411, "camel_26518": 0.5942842960357666, "camel_29279": 0.5943964123725891, "camel_26505": 0.5944297313690186, "camel_28384": 0.5944440364837646, "camel_29910": 0.5945236682891846, "camel_29097": 0.5945465564727783, "camel_9468": 0.5945565700531006, "camel_37500": 0.5948664546012878, "camel_23371": 0.5949674844741821, "camel_41256": 0.5951001644134521, "camel_22514": 0.5951225757598877, "camel_25419": 0.5953305959701538, "camel_25490": 0.5954099893569946, "camel_24658": 0.595446765422821, "camel_41250": 0.5954793691635132, "camel_21892": 0.5955792665481567, "camel_22542": 0.5957278609275818, "camel_21840": 0.5960848331451416, "camel_41076": 0.5962666869163513, "camel_41268": 0.5962832570075989, "camel_41213": 0.5964428782463074, "camel_38560": 0.5965855717658997, "camel_25479": 0.5966821312904358, "camel_41255": 0.5967225432395935, "camel_22531": 0.5967854261398315, "camel_25439": 0.5968754291534424, "TheoremQA_xinyi/rate_distortion_function_1.json": 0.5969380140304565, "camel_21906": 0.5973227620124817, "camel_41251": 0.5975043177604675, "camel_25902": 0.597566545009613, "camel_41232": 0.5976719260215759, "camel_25426": 0.5976735353469849, "camel_21856": 0.5977523922920227, "camel_37677": 0.5979241132736206, "camel_41220": 0.598029375076294, "camel_25917": 0.5980305075645447, "aqua_rat_6577": 0.5980336666107178, "camel_29321": 0.5981444716453552, "camel_40973": 0.5982251763343811, "camel_24442": 0.5986945629119873, "camel_15766": 0.5987500548362732, "camel_25427": 0.5988359451293945, "camel_22485": 0.5989431738853455, "camel_21877": 0.5989871621131897, "camel_25373": 0.5993603467941284, "camel_25486": 0.5994349718093872, "camel_41274": 0.5996571183204651, "gsm_rft_13965": 0.5997441411018372, "gsm_train_30685": 0.5997441411018372, "camel_39482": 0.5997724533081055, "camel_38700": 0.6000346541404724, "camel_29102": 0.6007267236709595, "camel_25870": 0.6008213758468628, "camel_25896": 0.6009562015533447, "camel_41226": 0.6010992527008057, "camel_29042": 0.6011586785316467, "camel_9451": 0.6011894941329956, "camel_38734": 0.6012064814567566, "aqua_rat_47751": 0.6012199521064758, "camel_25474": 0.6013370752334595, "camel_9489": 0.6014814972877502, "TheoremQA_maxku/ipnetwork7-lan.json": 0.60200035572052, "aqua_rat_60327": 0.6021809577941895, "camel_21895": 0.6022193431854248, "aqua_rat_52087": 0.6022216081619263, "camel_29240": 0.6022350788116455, "aqua_rat_27910": 0.6024136543273926, "aqua_rat_36286": 0.6026591062545776, "camel_25502": 0.6026686429977417, "aqua_rat_87402": 0.6028002500534058, "camel_30420": 0.6028048992156982, "camel_9508": 0.6028339862823486, "camel_23402": 0.6031739115715027, "aqua_rat_69941": 0.6034413576126099, "aqua_rat_80730": 0.6034722328186035, "aqua_rat_21944": 0.6036184430122375, "camel_24422": 0.6036476492881775, "TheoremQA_maxku/ipnetwork21-ip-2.json": 0.6039246916770935, "camel_25855": 0.6041236519813538, "camel_23379": 0.6041356921195984, "camel_41222": 0.604141354560852, "camel_37491": 0.6042485237121582, "camel_25489": 0.6043031215667725, "camel_21890": 0.6043908596038818, "camel_22520": 0.604418158531189, "camel_21898": 0.6046712398529053, "camel_41203": 0.6052672266960144, "camel_25849": 0.605888307094574, "aqua_rat_37698": 0.6063212752342224, "camel_21858": 0.6067109107971191, "aqua_rat_50510": 0.6069647669792175, "TheoremQA_maxku/ipnetwork4-mac.json": 0.606985867023468, "camel_21894": 0.6073005199432373, "camel_37713": 0.6074306964874268, "camel_40967": 0.6074782013893127, "camel_24444": 0.6075490713119507, "camel_39395": 0.6078760623931885, "camel_21850": 0.6079022884368896, "camel_9444": 0.6079520583152771, "aqua_rat_40444": 0.6080529689788818, "camel_41248": 0.6082687973976135, "camel_41254": 0.6084710955619812, "camel_22492": 0.6086504459381104, "camel_41270": 0.6088818311691284, "TheoremQA_xinyi/concavity.json": 0.6089678406715393, "camel_41223": 0.6094416379928589, "camel_21846": 0.6094653010368347, "camel_41221": 0.6104912161827087, "camel_9458": 0.6109536290168762, "camel_38699": 0.6111584901809692, "camel_41279": 0.6111881732940674, "camel_21864": 0.6112305521965027, "camel_22547": 0.6112515330314636, "camel_41212": 0.6112571358680725, "camel_41242": 0.6117852330207825, "camel_29078": 0.6122657656669617, "camel_41208": 0.6123430728912354, "camel_22498": 0.6123694777488708, "camel_36276": 0.6123975515365601, "camel_21909": 0.6127264499664307, "aqua_rat_87308": 0.6128466129302979, "camel_41207": 0.6134129762649536, "camel_41247": 0.6146706342697144, "camel_25399": 0.6160258054733276, "camel_22486": 0.6166063547134399, "camel_22557": 0.6168780326843262, "camel_30444": 0.6170585751533508, "camel_41237": 0.6182351112365723, "camel_25410": 0.6191552877426147, "camel_21918": 0.6194085478782654, "camel_9465": 0.6200296878814697, "camel_9500": 0.6213660836219788, "camel_9449": 0.6220974326133728, "camel_25512": 0.6229659914970398, "camel_21912": 0.623526394367218, "camel_9466": 0.6252161264419556, "camel_36493": 0.6260430216789246, "camel_22502": 0.6265066266059875, "camel_40982": 0.6265115141868591, "camel_9457": 0.6265841722488403, "camel_22524": 0.6295495629310608, "camel_9448": 0.6297464966773987, "camel_9446": 0.6309212446212769, "camel_38586": 0.6317018866539001, "camel_22536": 0.6329901218414307, "camel_9505": 0.6330893039703369, "camel_9453": 0.6331870555877686, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.6343233585357666, "TheoremQA_xinyi/data_processing.json": 0.6356057524681091, "camel_25498": 0.6359488368034363, "camel_9514": 0.638132631778717, "camel_9474": 0.6391010284423828, "camel_36765": 0.6393558979034424, "camel_21893": 0.6407756805419922, "camel_38692": 0.6417878866195679, "camel_22484": 0.6424413323402405, "camel_22490": 0.642769992351532, "camel_9501": 0.6450199484825134, "camel_22521": 0.6460443735122681, "camel_9462": 0.6480982899665833, "camel_22548": 0.6512395143508911, "camel_22539": 0.657407283782959, "TheoremQA_xinyi/rate_distortion_function_2.json": 0.65985107421875, "camel_9503": 0.6609820127487183, "TheoremQA_xinyi/fano_inequality.json": 0.6658123135566711, "TheoremQA_xinyi/channel_capacity_1.json": 0.666936993598938, "TheoremQA_xinyi/shannon_lower_bound.json": 0.6771497130393982, "TheoremQA_maxku/ipnetwork10-datatransmission.json": 0.6830721497535706, "TheoremQA_xinyi/binary_symmetric_channel_1.json": 0.7345391511917114}, "TheoremQA_xinyi/huffman_code_3.json": {"TheoremQA_xinyi/huffman_code_3.json": 0, "camel_25564": 0.6658088564872742, "gsm_rft_11853": 0.6658599376678467, "gsm_rft_7043": 0.6658802032470703, "aqua_rat_36324": 0.6660769581794739, "gsm_rft_502": 0.6661091446876526, "gsm_rft_14522": 0.6661592721939087, "gsm_train_16519": 0.6661831736564636, "aqua_rat_80435": 0.6663077473640442, "aqua_rat_43912": 0.6663148403167725, "math_train_algebra_2648": 0.6663273572921753, "camel_25577": 0.6663854122161865, "gsm_train_27952": 0.6664618253707886, "gsm_rft_30763": 0.6664618253707886, "camel_25524": 0.6666445136070251, "camel_30359": 0.666693389415741, "camel_25578": 0.667012631893158, "gsm_rft_11441": 0.6671921610832214, "aqua_rat_48028": 0.6673303246498108, "gsm_rft_1138": 0.6673416495323181, "gsm_rft_34728": 0.6674006581306458, "gsm_rft_31058": 0.6674118041992188, "aqua_rat_2861": 0.6674389839172363, "camel_37914": 0.6674900650978088, "camel_36542": 0.6676374077796936, "camel_25550": 0.6676777601242065, "camel_25597": 0.6676925420761108, "gsm_rft_33269": 0.6680035591125488, "aqua_rat_15442": 0.6681072115898132, "aqua_rat_40065": 0.6684327125549316, "gsm_rft_34209": 0.6684734225273132, "camel_25933": 0.6684989333152771, "camel_25587": 0.6685598492622375, "camel_36367": 0.668960690498352, "gsm_rft_9522": 0.6691681146621704, "camel_36369": 0.6692767143249512, "gsm_train_25110": 0.66950923204422, "gsm_rft_20001": 0.66950923204422, "gsm_rft_31867": 0.6695315837860107, "aqua_rat_39529": 0.6695723533630371, "aqua_rat_43232": 0.6696621179580688, "aqua_rat_50484": 0.6698439717292786, "camel_25974": 0.6698449850082397, "gsm_train_33783": 0.669928252696991, "gsm_rft_3455": 0.6700050830841064, "gsm_rft_23392": 0.6700173020362854, "camel_25590": 0.6700432896614075, "camel_36340": 0.6701311469078064, "gsm_rft_26718": 0.6701512336730957, "gsm_rft_1300": 0.6703510880470276, "gsm_rft_14968": 0.6708449721336365, "gsm_train_13395": 0.6708449721336365, "gsm_train_22616": 0.6709159016609192, "gsm_rft_15376": 0.6709159016609192, "gsm_rft_23533": 0.6709159016609192, "aqua_rat_53479": 0.6710182428359985, "gsm_train_17810": 0.6710984706878662, "gsm_rft_5873": 0.6710992455482483, "aqua_rat_59416": 0.6711782217025757, "aqua_rat_81690": 0.6711965799331665, "gsm_rft_10499": 0.6713789701461792, "gsm_train_21133": 0.6715927720069885, "gsm_rft_10145": 0.6716747283935547, "gsm_rft_35088": 0.6716955900192261, "gsm_rft_12276": 0.6717221140861511, "camel_36361": 0.6718348264694214, "gsm_rft_6957": 0.6718369722366333, "gsm_rft_25108": 0.6720483899116516, "gsm_train_29434": 0.6720576286315918, "gsm_rft_23632": 0.6722580790519714, "aqua_rat_49886": 0.6722802519798279, "gsm_rft_26929": 0.6723082065582275, "gsm_train_26864": 0.6723082065582275, "aqua_rat_56227": 0.6726264357566833, "camel_25579": 0.6727269887924194, "gsm_rft_26683": 0.6728259921073914, "gsm_rft_6901": 0.6728973984718323, "gsm_train_11866": 0.6728973984718323, "gsm_rft_27715": 0.6729722619056702, "gsm_rft_15633": 0.6729722619056702, "camel_25540": 0.6729881763458252, "aqua_rat_77208": 0.6732172966003418, "gsm_rft_1723": 0.6734259724617004, "gsm_rft_20550": 0.6735787391662598, "gsm_rft_9176": 0.6737110614776611, "gsm_train_26662": 0.6737306714057922, "gsm_train_10699": 0.6737431287765503, "gsm_rft_11027": 0.6737748384475708, "gsm_train_30442": 0.6739143133163452, "gsm_rft_32974": 0.6739143133163452, "camel_25526": 0.6739533543586731, "gsm_rft_989": 0.6740146279335022, "gsm_rft_5816": 0.6740730404853821, "camel_30378": 0.6741953492164612, "gsm_train_24629": 0.6742693185806274, "camel_25547": 0.6743500232696533, "aqua_rat_80404": 0.6746169328689575, "camel_25572": 0.6747833490371704, "camel_25959": 0.6748870611190796, "aqua_rat_6686": 0.6754840612411499, "camel_25588": 0.6757783889770508, "aqua_rat_49730": 0.6758944392204285, "gsm_rft_18324": 0.6762978434562683, "aqua_rat_60978": 0.6764962077140808, "gsm_rft_33628": 0.6765568256378174, "aqua_rat_88939": 0.6766260266304016, "aqua_rat_72504": 0.6768022179603577, "aqua_rat_64824": 0.6770960092544556, "aqua_rat_36836": 0.6771103739738464, "camel_25568": 0.6772237420082092, "aqua_rat_14820": 0.6773961782455444, "gsm_rft_14554": 0.6775288581848145, "aqua_rat_78708": 0.6780511140823364, "aqua_rat_80459": 0.6780521273612976, "aqua_rat_34283": 0.6782376766204834, "gsm_rft_23052": 0.6783797740936279, "gsm_rft_26152": 0.6786226630210876, "gsm_rft_3071": 0.678737223148346, "aqua_rat_55387": 0.6788679361343384, "aqua_rat_69333": 0.6790431141853333, "math_test_algebra_1836": 0.6796579957008362, "gsm_rft_21725": 0.6803978681564331, "aqua_rat_73229": 0.6804483532905579, "gsm_rft_29625": 0.6804599761962891, "gsm_rft_29691": 0.6804599761962891, "gsm_train_4344": 0.6804599761962891, "gsm_rft_3147": 0.6808568835258484, "math_test_counting_and_probability_936": 0.6810498237609863, "gsm_rft_10428": 0.6810539960861206, "gsm_rft_946": 0.6810702085494995, "gsm_train_25747": 0.6810702085494995, "gsm_rft_12251": 0.6811765432357788, "camel_25545": 0.6812185049057007, "aqua_rat_76734": 0.6812303066253662, "aqua_rat_17396": 0.6812609434127808, "gsm_rft_19125": 0.6813697814941406, "aqua_rat_73092": 0.6814742684364319, "camel_25563": 0.681512713432312, "gsm_rft_2237": 0.6815882325172424, "camel_25522": 0.6820370554924011, "aqua_rat_72895": 0.6820458173751831, "gsm_train_31332": 0.6821075677871704, "aqua_rat_81027": 0.6824495196342468, "gsm_rft_18413": 0.6837143898010254, "gsm_rft_4841": 0.6839323043823242, "camel_25534": 0.6842976212501526, "gsm_rft_25016": 0.6844059228897095, "aqua_rat_61191": 0.6850762963294983, "camel_25559": 0.6851354837417603, "gsm_rft_21502": 0.6870930194854736, "camel_25560": 0.6882639527320862, "aqua_rat_38718": 0.6889204978942871, "gsm_train_6986": 0.6891832947731018, "gsm_rft_25": 0.6891832947731018, "camel_36377": 0.6897676587104797, "gsm_rft_25388": 0.689897358417511, "gsm_rft_30314": 0.6942278742790222, "aqua_rat_15566": 0.694311261177063, "gsm_train_31076": 0.6952456831932068, "gsm_rft_16567": 0.6953871250152588, "aqua_rat_44526": 0.6977062225341797, "aqua_rat_80797": 0.6981205344200134, "aqua_rat_44182": 0.6992256045341492, "aqua_rat_76567": 0.6997075080871582, "gsm_rft_2111": 0.7023399472236633, "aqua_rat_62327": 0.7036129236221313, "camel_36343": 0.7038267254829407, "camel_37553": 0.7044885158538818, "aqua_rat_53187": 0.7048743367195129, "aqua_rat_69403": 0.7063819766044617, "camel_36341": 0.7065582275390625, "aqua_rat_31650": 0.7070826888084412, "aqua_rat_50929": 0.7079275250434875, "aqua_rat_3175": 0.708925724029541, "aqua_rat_25511": 0.70945143699646, "aqua_rat_52378": 0.7094801068305969, "aqua_rat_79822": 0.7102285623550415, "aqua_rat_4547": 0.7114794254302979, "aqua_rat_61568": 0.7124058604240417, "aqua_rat_28724": 0.7151451110839844, "aqua_rat_41713": 0.7154123187065125, "aqua_rat_48356": 0.7182013988494873, "aqua_rat_28998": 0.7200421690940857, "aqua_rat_67308": 0.7230910658836365, "camel_36395": 0.7334822416305542, "camel_37570": 0.7361921072006226, "camel_36360": 0.7453895807266235, "gsm_rft_6826": 0.752793550491333, "gsm_rft_32883": 0.7551275491714478, "gsm_rft_34828": 0.756777286529541, "gsm_rft_15172": 0.7583762407302856, "gsm_rft_15553": 0.7609764933586121, "gsm_rft_12684": 0.7624610662460327, "gsm_rft_19047": 0.7689726948738098, "gsm_train_29804": 0.7689726948738098, "aqua_rat_10491": 0.7803246378898621, "aqua_rat_20543": 0.7804442644119263, "aqua_rat_623": 0.8212944865226746, "aqua_rat_74410": 0.8276026844978333, "camel_37112": 0.8355928659439087}}