{"TheoremQA_elainewan/math_calculus_5_2.json": {"camel_7268": 0, "camel_7242": 0, "camel_6849": 0, "gsm_rft_12369": 0.7640867233276367, "gsm_rft_15004": 0.7640867233276367, "gsm_train_437": 0.7640867233276367, "aqua_rat_47425": 0.7640997171401978, "aqua_rat_56038": 0.7641541361808777, "aqua_rat_12499": 0.7643662095069885, "aqua_rat_20826": 0.7646114826202393, "aqua_rat_47596": 0.7647740840911865, "aqua_rat_57946": 0.764807403087616, "aqua_rat_17995": 0.7648678421974182, "gsm_rft_5015": 0.7650349736213684, "aqua_rat_79740": 0.7650495767593384, "aqua_rat_86925": 0.7651957273483276, "aqua_rat_63153": 0.7652699947357178, "gsm_rft_28418": 0.7653176188468933, "aqua_rat_23330": 0.7654958367347717, "aqua_rat_72549": 0.7655545473098755, "aqua_rat_24555": 0.7656925916671753, "aqua_rat_19975": 0.7657148241996765, "gsm_rft_9498": 0.765734851360321, "gsm_train_31608": 0.7657435536384583, "gsm_rft_5373": 0.765819251537323, "gsm_rft_5789": 0.7658321261405945, "gsm_rft_18615": 0.7660702466964722, "gsm_rft_8404": 0.7661932110786438, "aqua_rat_26780": 0.7664742469787598, "aqua_rat_69903": 0.766616702079773, "aqua_rat_41455": 0.7666367292404175, "camel_37936": 0.7666923403739929, "aqua_rat_59420": 0.7667636275291443, "aqua_rat_5239": 0.7668440937995911, "aqua_rat_18287": 0.7668534517288208, "gsm_rft_17396": 0.7669841051101685, "aqua_rat_56111": 0.7670125365257263, "aqua_rat_56755": 0.7670689821243286, "aqua_rat_35437": 0.7676219344139099, "gsm_rft_8748": 0.7676445245742798, "aqua_rat_71574": 0.7677373290061951, "aqua_rat_59734": 0.7677409052848816, "aqua_rat_11295": 0.7678811550140381, "aqua_rat_70956": 0.7679559588432312, "aqua_rat_71294": 0.7680427432060242, "aqua_rat_37668": 0.7683200240135193, "aqua_rat_15068": 0.7683817148208618, "gsm_rft_1640": 0.7684758305549622, "aqua_rat_31551": 0.7684859037399292, "aqua_rat_33646": 0.7686312794685364, "aqua_rat_63555": 0.7686586380004883, "aqua_rat_29678": 0.7686935663223267, "aqua_rat_11875": 0.7687031626701355, "gsm_rft_3828": 0.7687082290649414, "gsm_rft_30481": 0.7688778042793274, "gsm_train_17263": 0.7688778042793274, "aqua_rat_32270": 0.7688913345336914, "aqua_rat_35471": 0.7689301371574402, "aqua_rat_19333": 0.768959105014801, "aqua_rat_32487": 0.7691243886947632, "aqua_rat_21997": 0.7693832516670227, "aqua_rat_2700": 0.7696012258529663, "gsm_rft_14868": 0.7696166038513184, "aqua_rat_42745": 0.769675076007843, "gsm_rft_28257": 0.7702875733375549, "aqua_rat_12537": 0.7704043388366699, "aqua_rat_23682": 0.7704962491989136, "aqua_rat_23177": 0.7709001302719116, "aqua_rat_37157": 0.7709845304489136, "aqua_rat_18977": 0.7710176110267639, "aqua_rat_2195": 0.7710579037666321, "aqua_rat_15563": 0.7710666656494141, "aqua_rat_43462": 0.771202802658081, "aqua_rat_65312": 0.7713097333908081, "aqua_rat_59846": 0.7714143395423889, "aqua_rat_51397": 0.7714307308197021, "aqua_rat_50180": 0.7714815735816956, "aqua_rat_71177": 0.7715151309967041, "aqua_rat_70296": 0.7715879082679749, "aqua_rat_49730": 0.7721061110496521, "aqua_rat_8703": 0.7723374962806702, "aqua_rat_56788": 0.7728895545005798, "aqua_rat_42126": 0.7734413743019104, "aqua_rat_71661": 0.7736326456069946, "aqua_rat_58277": 0.7736414670944214, "aqua_rat_13846": 0.7736945152282715, "gsm_train_21024": 0.7736988663673401, "aqua_rat_59885": 0.7738369107246399, "aqua_rat_47365": 0.7738886475563049, "gsm_rft_3538": 0.7740090489387512, "gsm_rft_2034": 0.7740090489387512, "aqua_rat_84494": 0.7740176916122437, "aqua_rat_42376": 0.7740517854690552, "aqua_rat_11429": 0.7746573686599731, "aqua_rat_74848": 0.7754207253456116, "aqua_rat_59630": 0.7757194638252258, "aqua_rat_45012": 0.7758415341377258, "aqua_rat_30166": 0.7759232521057129, "aqua_rat_81885": 0.7761276364326477, "aqua_rat_9148": 0.7762375473976135, "aqua_rat_52096": 0.7765151858329773, "gsm_rft_21414": 0.7766197919845581, "aqua_rat_4578": 0.7766276597976685, "aqua_rat_34283": 0.7769473195075989, "aqua_rat_37483": 0.7771667242050171, "aqua_rat_17824": 0.7772682905197144, "aqua_rat_51555": 0.7774191498756409, "aqua_rat_11054": 0.7777318358421326, "aqua_rat_10823": 0.777782142162323, "math_train_algebra_52": 0.7778311967849731, "gsm_train_6956": 0.7782968878746033, "gsm_rft_13200": 0.7782968878746033, "gsm_rft_15918": 0.7782968878746033, "aqua_rat_88394": 0.7784557938575745, "gsm_rft_7089": 0.7789316177368164, "gsm_rft_18466": 0.7790636420249939, "gsm_train_1691": 0.7790636420249939, "aqua_rat_65926": 0.7791891694068909, "camel_37933": 0.779396116733551, "aqua_rat_62310": 0.7798368334770203, "aqua_rat_72895": 0.779898464679718, "aqua_rat_27858": 0.7803026437759399, "aqua_rat_14328": 0.7808752059936523, "gsm_rft_19748": 0.7819451689720154, "aqua_rat_4051": 0.7823720574378967, "aqua_rat_76127": 0.782880425453186, "aqua_rat_23008": 0.783182680606842, "aqua_rat_27506": 0.7837672829627991, "aqua_rat_57461": 0.7840006947517395, "aqua_rat_53348": 0.7841704487800598, "camel_39486": 0.7844535708427429, "gsm_rft_24752": 0.7844935655593872, "aqua_rat_14555": 0.7849111557006836, "gsm_train_31543": 0.785356879234314, "gsm_rft_4984": 0.785356879234314, "gsm_rft_34916": 0.785356879234314, "aqua_rat_33076": 0.7877112030982971, "aqua_rat_31829": 0.7881545424461365, "aqua_rat_77082": 0.7890232801437378, "gsm_rft_681": 0.7892100811004639, "aqua_rat_32037": 0.7892580032348633, "aqua_rat_3097": 0.7896730899810791, "aqua_rat_5634": 0.7909111380577087, "gsm_train_10435": 0.7913036346435547, "gsm_rft_6566": 0.7913036346435547, "gsm_rft_18802": 0.7923159599304199, "gsm_rft_22599": 0.7924371361732483, "aqua_rat_12508": 0.7933304905891418, "gsm_rft_24023": 0.7952660322189331, "gsm_rft_5403": 0.7959468960762024, "aqua_rat_56227": 0.7962039113044739, "math_test_algebra_1377": 0.7978507876396179, "gsm_rft_19857": 0.7988764643669128, "gsm_train_17211": 0.7995622158050537, "gsm_rft_20546": 0.7995622158050537, "gsm_rft_8207": 0.8000433444976807, "gsm_rft_28004": 0.8005656599998474, "gsm_train_6685": 0.8007672429084778, "gsm_rft_20038": 0.8010688424110413, "aqua_rat_49970": 0.8018048405647278, "gsm_rft_17167": 0.8027288317680359, "aqua_rat_55682": 0.8033319711685181, "gsm_rft_32876": 0.8036867380142212, "gsm_rft_13586": 0.803748369216919, "gsm_rft_17947": 0.8038873672485352, "gsm_train_29627": 0.8038873672485352, "gsm_rft_17465": 0.8038873672485352, "gsm_rft_5346": 0.8041865229606628, "aqua_rat_24388": 0.8042309880256653, "gsm_rft_8666": 0.8047319650650024, "aqua_rat_68920": 0.8048403859138489, "gsm_rft_960": 0.8058228492736816, "gsm_train_34643": 0.8069250583648682, "gsm_train_15179": 0.8072612881660461, "gsm_rft_469": 0.8072612881660461, "gsm_rft_3683": 0.807291567325592, "gsm_rft_34686": 0.8075678944587708, "math_test_algebra_981": 0.8075689673423767, "gsm_rft_18280": 0.8083401918411255, "gsm_rft_19572": 0.8084845542907715, "aqua_rat_74383": 0.8085233569145203, "aqua_rat_2718": 0.809037446975708, "aqua_rat_51871": 0.810085117816925, "gsm_rft_10674": 0.8115816116333008, "gsm_train_31883": 0.8123828768730164, "gsm_rft_34403": 0.8123828768730164, "aqua_rat_16497": 0.8124129176139832, "aqua_rat_15784": 0.812504231929779, "gsm_rft_29300": 0.8127795457839966, "gsm_rft_30558": 0.8130846619606018, "gsm_rft_5605": 0.8154934644699097, "aqua_rat_23237": 0.8159662485122681, "aqua_rat_1178": 0.8161724209785461, "gsm_rft_23499": 0.8167464733123779, "gsm_rft_20403": 0.8167943954467773, "gsm_rft_32594": 0.8191072940826416, "gsm_rft_13509": 0.8200068473815918, "gsm_train_31200": 0.8200068473815918, "gsm_train_179": 0.8208895325660706, "gsm_rft_9752": 0.8208895325660706}, "TheoremQA_jianyu_xu/pigeonhole_3.json": {"camel_20836": 0, "camel_20623": 0, "camel_20257": 0, "camel_20499": 0, "camel_20425": 0, "camel_21050": 0, "camel_20540": 0, "camel_20598": 0, "camel_21360": 0, "camel_20022": 0, "camel_21015": 0, "camel_21835": 0, "camel_20310": 0, "camel_20614": 0, "camel_21143": 0, "camel_20287": 0, "camel_21550": 0, "camel_21040": 0, "camel_21361": 0, "camel_20462": 0, "camel_21159": 0, "camel_20577": 0, "camel_21126": 0, "camel_20272": 0, "camel_21568": 0, "camel_20256": 0, "camel_20903": 0, "camel_21154": 0, "camel_20302": 0, "camel_21183": 0, "TheoremQA_jianyu_xu/pigeonhole_3.json": 0, "camel_21141": 0, "camel_21169": 0, "camel_21160": 0, "camel_21174": 0, "camel_21372": 0, "camel_21128": 0, "camel_20308": 0, "camel_20312": 0, "camel_21165": 0, "camel_21147": 0, "camel_21798": 0, "camel_21177": 0, "camel_21246": 0, "camel_21055": 0, "camel_20301": 0, "camel_21196": 0, "aqua_rat_1824": 0.779088020324707, "math_train_counting_and_probability_617": 0.7791654467582703, "aqua_rat_54042": 0.7793604135513306, "aqua_rat_74792": 0.7795326113700867, "aqua_rat_7648": 0.7797113060951233, "aqua_rat_59053": 0.7798164486885071, "aqua_rat_84274": 0.7799942493438721, "aqua_rat_65742": 0.7800276279449463, "aqua_rat_78805": 0.7802067399024963, "aqua_rat_10905": 0.7802067995071411, "math_train_counting_and_probability_676": 0.7802401781082153, "aqua_rat_38838": 0.780453085899353, "math_train_prealgebra_1917": 0.7804922461509705, "aqua_rat_61326": 0.7809485793113708, "aqua_rat_34864": 0.7810004353523254, "aqua_rat_4334": 0.7811932563781738, "aqua_rat_37188": 0.7813995480537415, "aqua_rat_83784": 0.7815614342689514, "aqua_rat_39612": 0.7818319201469421, "aqua_rat_33304": 0.7819594740867615, "math_test_counting_and_probability_86": 0.7821799516677856, "aqua_rat_55838": 0.7823024392127991, "math_train_counting_and_probability_696": 0.7824482321739197, "aqua_rat_15917": 0.7829936742782593, "aqua_rat_39271": 0.7830532193183899, "math_train_counting_and_probability_667": 0.7837805151939392, "aqua_rat_39390": 0.7843635678291321, "aqua_rat_50073": 0.7844166159629822, "aqua_rat_19502": 0.785072386264801, "aqua_rat_56307": 0.7851364016532898, "aqua_rat_83332": 0.7851778268814087, "aqua_rat_49784": 0.7853037118911743, "math_train_prealgebra_1975": 0.7854015827178955, "aqua_rat_29008": 0.7856001853942871, "aqua_rat_15706": 0.7859894633293152, "aqua_rat_4199": 0.7862948775291443, "aqua_rat_20004": 0.7863085269927979, "aqua_rat_26932": 0.7865185141563416, "aqua_rat_84502": 0.7866406440734863, "aqua_rat_51384": 0.7867461442947388, "aqua_rat_56956": 0.7867863774299622, "aqua_rat_210": 0.7868629693984985, "math_test_counting_and_probability_695": 0.7869943976402283, "aqua_rat_1152": 0.7870134711265564, "math_train_counting_and_probability_125": 0.7874611616134644, "aqua_rat_7483": 0.787667989730835, "aqua_rat_7521": 0.7887643575668335, "aqua_rat_9092": 0.7889411449432373, "math_train_counting_and_probability_531": 0.7890764474868774, "aqua_rat_81742": 0.7891988754272461, "aqua_rat_41411": 0.7895178198814392, "aqua_rat_87746": 0.7895599603652954, "aqua_rat_80145": 0.7901398539543152, "aqua_rat_23636": 0.7901567220687866, "aqua_rat_74651": 0.7902551293373108, "aqua_rat_21205": 0.7905169725418091, "aqua_rat_68198": 0.7905298471450806, "aqua_rat_48326": 0.7905447483062744, "aqua_rat_45273": 0.7905651926994324, "aqua_rat_76251": 0.7908118963241577, "aqua_rat_47768": 0.7910739779472351, "math_train_prealgebra_770": 0.791094183921814, "aqua_rat_73523": 0.7911162376403809, "aqua_rat_62645": 0.7912982702255249, "aqua_rat_43005": 0.7913360595703125, "aqua_rat_46435": 0.791367769241333, "aqua_rat_11601": 0.7915284037590027, "aqua_rat_17717": 0.791991114616394, "aqua_rat_20344": 0.7922614216804504, "camel_38538": 0.7924490571022034, "aqua_rat_33533": 0.7926041483879089, "aqua_rat_35121": 0.7927553057670593, "aqua_rat_29990": 0.7928189039230347, "camel_37121": 0.7932541370391846, "aqua_rat_72708": 0.7935329675674438, "aqua_rat_24238": 0.7937430143356323, "aqua_rat_5662": 0.7938463091850281, "aqua_rat_23041": 0.7938870787620544, "aqua_rat_42578": 0.7940044403076172, "math_train_counting_and_probability_5123": 0.794078528881073, "aqua_rat_13918": 0.7942867279052734, "camel_38541": 0.7950541377067566, "aqua_rat_22669": 0.7953593134880066, "aqua_rat_48010": 0.7954360842704773, "math_train_counting_and_probability_657": 0.7955428957939148, "aqua_rat_19499": 0.7962393760681152, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0.7963245511054993, "aqua_rat_74597": 0.7963889241218567, "aqua_rat_39047": 0.7963905930519104, "aqua_rat_30710": 0.7963958382606506, "aqua_rat_53649": 0.7966077923774719, "aqua_rat_74390": 0.7968369126319885, "aqua_rat_52771": 0.7968654632568359, "aqua_rat_73303": 0.7971072196960449, "aqua_rat_57095": 0.7977699637413025, "aqua_rat_76356": 0.7981703281402588, "aqua_rat_9477": 0.7985624670982361, "aqua_rat_56614": 0.79856938123703, "aqua_rat_27075": 0.7985789179801941, "aqua_rat_66892": 0.7986788153648376, "aqua_rat_83986": 0.7987315058708191, "aqua_rat_26254": 0.7989325523376465, "aqua_rat_86710": 0.7990613579750061, "aqua_rat_41017": 0.7992064356803894, "aqua_rat_31957": 0.7994987964630127, "camel_11529": 0.7996705770492554, "aqua_rat_19090": 0.7998895645141602, "aqua_rat_15511": 0.8000978827476501, "math_train_counting_and_probability_167": 0.8002375960350037, "aqua_rat_27921": 0.8003548979759216, "aqua_rat_19436": 0.8004738092422485, "aqua_rat_71213": 0.8006663918495178, "aqua_rat_19152": 0.8010859489440918, "aqua_rat_42905": 0.8014564514160156, "aqua_rat_85357": 0.8016736507415771, "aqua_rat_82439": 0.8017134666442871, "aqua_rat_40277": 0.8018268346786499, "aqua_rat_29620": 0.8018324375152588, "aqua_rat_52525": 0.8022303581237793, "aqua_rat_75262": 0.8025422096252441, "camel_12727": 0.802682638168335, "aqua_rat_31214": 0.8036440014839172, "aqua_rat_73173": 0.8036918044090271, "aqua_rat_32157": 0.8040115833282471, "aqua_rat_32047": 0.8041581511497498, "aqua_rat_38285": 0.8043109178543091, "aqua_rat_51541": 0.8048452138900757, "aqua_rat_46009": 0.8052144646644592, "math_test_counting_and_probability_341": 0.8058835864067078, "aqua_rat_61965": 0.8080511689186096, "aqua_rat_2817": 0.8093228936195374, "aqua_rat_34164": 0.8094395995140076, "aqua_rat_41911": 0.8096581101417542, "aqua_rat_65264": 0.8097406625747681, "math_train_algebra_2532": 0.809869647026062, "aqua_rat_65518": 0.8103722929954529, "aqua_rat_31828": 0.8105179071426392, "aqua_rat_5877": 0.812277615070343, "aqua_rat_56383": 0.8126211762428284, "aqua_rat_76846": 0.8136114478111267, "aqua_rat_72312": 0.8142159581184387, "aqua_rat_19096": 0.8153262138366699, "aqua_rat_57502": 0.8247085809707642, "aqua_rat_37649": 0.8256279230117798, "aqua_rat_49569": 0.8272033333778381, "aqua_rat_14782": 0.82811039686203, "aqua_rat_6737": 0.8287404179573059, "aqua_rat_51045": 0.8298485279083252, "aqua_rat_87294": 0.8316405415534973, "aqua_rat_48130": 0.831954836845398, "aqua_rat_50597": 0.8322653770446777, "aqua_rat_66391": 0.8365893959999084, "aqua_rat_33710": 0.8377512693405151}, "TheoremQA_jianyu_xu/pigeonhole_2.json": {"camel_21170": 0, "camel_21146": 0, "camel_21835": 0, "camel_21160": 0, "camel_21132": 0, "camel_21185": 0, "camel_21196": 0, "camel_21141": 0, "camel_21128": 0, "camel_21178": 0, "camel_21183": 0, "camel_21372": 0, "camel_21159": 0, "camel_21176": 0, "camel_21174": 0, "camel_21152": 0, "camel_21143": 0, "camel_21123": 0, "camel_21120": 0, "camel_20495": 0, "TheoremQA_jianyu_xu/pigeonhole_2.json": 0, "aqua_rat_43460": 0.7544810175895691, "aqua_rat_74606": 0.7547141313552856, "aqua_rat_257": 0.7548094987869263, "aqua_rat_25895": 0.7549426555633545, "aqua_rat_84463": 0.7549477219581604, "aqua_rat_71787": 0.7550029754638672, "aqua_rat_63165": 0.7550057768821716, "aqua_rat_75235": 0.7551300525665283, "aqua_rat_78131": 0.7552114725112915, "aqua_rat_60179": 0.7552225589752197, "aqua_rat_5254": 0.7553584575653076, "camel_22161": 0.7553627490997314, "aqua_rat_854": 0.7554558515548706, "aqua_rat_17762": 0.7555527687072754, "aqua_rat_10892": 0.7555568218231201, "aqua_rat_67911": 0.7556387782096863, "camel_19727": 0.7557279467582703, "aqua_rat_54515": 0.7558979988098145, "aqua_rat_84347": 0.7559285759925842, "aqua_rat_790": 0.7563098669052124, "aqua_rat_16864": 0.7565797567367554, "aqua_rat_4157": 0.7566287517547607, "aqua_rat_64918": 0.7568327188491821, "aqua_rat_34542": 0.7570557594299316, "math_test_counting_and_probability_175": 0.7571696639060974, "aqua_rat_26067": 0.7572816014289856, "aqua_rat_9006": 0.7575826644897461, "gsm_rft_17267": 0.7577237486839294, "aqua_rat_10932": 0.7577840089797974, "camel_38190": 0.7577874660491943, "aqua_rat_3292": 0.7577894330024719, "gsm_rft_22231": 0.7578968405723572, "aqua_rat_3298": 0.7579262256622314, "aqua_rat_7104": 0.7579598426818848, "gsm_train_9170": 0.7582140564918518, "aqua_rat_57393": 0.7582498788833618, "aqua_rat_83185": 0.7582712173461914, "aqua_rat_16513": 0.7582845091819763, "aqua_rat_11144": 0.7583523392677307, "math_train_prealgebra_538": 0.7585113048553467, "aqua_rat_79081": 0.7585854530334473, "aqua_rat_75623": 0.7585998177528381, "aqua_rat_85020": 0.7586230635643005, "aqua_rat_49324": 0.7587367296218872, "aqua_rat_25540": 0.7587915062904358, "aqua_rat_85080": 0.7588537931442261, "aqua_rat_82274": 0.75897216796875, "aqua_rat_77294": 0.7590803503990173, "aqua_rat_67812": 0.7594937682151794, "aqua_rat_61748": 0.7596526741981506, "aqua_rat_68089": 0.7597371935844421, "aqua_rat_7497": 0.7601035237312317, "camel_18380": 0.7603312730789185, "aqua_rat_71235": 0.76034015417099, "aqua_rat_26062": 0.7604064345359802, "aqua_rat_75043": 0.760420560836792, "camel_39143": 0.7609328031539917, "aqua_rat_9335": 0.7611897587776184, "aqua_rat_22647": 0.7612007260322571, "aqua_rat_37138": 0.761411726474762, "aqua_rat_78317": 0.7616352438926697, "camel_19722": 0.761680543422699, "aqua_rat_26206": 0.7617790699005127, "camel_30242": 0.7621809840202332, "aqua_rat_57399": 0.7621875405311584, "aqua_rat_60456": 0.7623117566108704, "aqua_rat_71780": 0.7623304128646851, "camel_19734": 0.7623386979103088, "aqua_rat_37170": 0.7624717354774475, "aqua_rat_59875": 0.762606143951416, "aqua_rat_81227": 0.7626280188560486, "aqua_rat_1204": 0.7631369829177856, "aqua_rat_85048": 0.7631725072860718, "aqua_rat_77973": 0.7634190917015076, "aqua_rat_14389": 0.7634502053260803, "aqua_rat_45720": 0.7643415927886963, "aqua_rat_84620": 0.7643765807151794, "aqua_rat_22251": 0.7644890546798706, "aqua_rat_9508": 0.7645055055618286, "math_test_prealgebra_994": 0.7647058367729187, "aqua_rat_55940": 0.7647456526756287, "camel_19743": 0.7651641368865967, "aqua_rat_36627": 0.765799343585968, "aqua_rat_47046": 0.7662524580955505, "aqua_rat_36780": 0.7662525177001953, "aqua_rat_65264": 0.7665736675262451, "aqua_rat_5243": 0.7669284343719482, "math_train_geometry_6177": 0.76706862449646, "aqua_rat_6286": 0.7671258449554443, "aqua_rat_14454": 0.767302393913269, "aqua_rat_17930": 0.7673231363296509, "aqua_rat_10296": 0.767464280128479, "aqua_rat_29707": 0.7675476670265198, "aqua_rat_36704": 0.7675949931144714, "aqua_rat_32592": 0.7676602602005005, "aqua_rat_23501": 0.7678203582763672, "aqua_rat_47936": 0.7679035663604736, "math_train_counting_and_probability_267": 0.7679666876792908, "aqua_rat_21116": 0.7680167555809021, "aqua_rat_24670": 0.7682846784591675, "aqua_rat_56566": 0.7682874798774719, "aqua_rat_86106": 0.7688498497009277, "aqua_rat_72434": 0.769026517868042, "aqua_rat_38400": 0.7692298293113708, "aqua_rat_69644": 0.7692556977272034, "aqua_rat_25415": 0.7692750692367554, "aqua_rat_66974": 0.7693056464195251, "aqua_rat_60482": 0.7694449424743652, "aqua_rat_40766": 0.7698807120323181, "aqua_rat_65230": 0.770329475402832, "aqua_rat_85328": 0.7704071998596191, "aqua_rat_888": 0.7705023884773254, "aqua_rat_83576": 0.7715610265731812, "aqua_rat_81015": 0.771883487701416, "aqua_rat_57604": 0.771996259689331, "aqua_rat_78573": 0.7722365260124207, "aqua_rat_8073": 0.7729792594909668, "math_train_prealgebra_628": 0.7737506031990051, "gsm_rft_19529": 0.7738109827041626, "gsm_rft_19280": 0.7747359275817871, "gsm_train_18364": 0.7747359275817871, "gsm_rft_3885": 0.7747359275817871, "math_train_geometry_937": 0.7750231623649597, "aqua_rat_72151": 0.7759706974029541, "aqua_rat_62436": 0.7759971022605896, "aqua_rat_34002": 0.7761291861534119, "aqua_rat_82465": 0.7762783765792847, "aqua_rat_60518": 0.7767939567565918, "aqua_rat_49984": 0.7769414782524109, "aqua_rat_46063": 0.7772361636161804, "aqua_rat_64536": 0.777303159236908, "aqua_rat_6823": 0.777318000793457, "aqua_rat_50696": 0.7789777517318726, "aqua_rat_53476": 0.7792302966117859, "camel_39138": 0.779893696308136, "aqua_rat_12125": 0.7800312042236328, "aqua_rat_22633": 0.7804965972900391, "aqua_rat_21726": 0.7811188101768494, "aqua_rat_12007": 0.7817177772521973, "aqua_rat_84517": 0.7827702164649963, "aqua_rat_55274": 0.784403920173645, "aqua_rat_11574": 0.785109281539917, "aqua_rat_72399": 0.7852970957756042, "aqua_rat_47821": 0.7874886393547058, "aqua_rat_75858": 0.7876700758934021, "aqua_rat_80509": 0.7880439162254333, "aqua_rat_43406": 0.7899727821350098, "aqua_rat_24561": 0.7903714776039124, "aqua_rat_72603": 0.7908300161361694, "aqua_rat_82156": 0.7910963892936707, "aqua_rat_87175": 0.7912432551383972, "aqua_rat_24221": 0.7914978265762329, "aqua_rat_47040": 0.7915957570075989, "aqua_rat_80058": 0.7918524146080017, "aqua_rat_25886": 0.7921606302261353, "aqua_rat_33903": 0.7921616435050964, "aqua_rat_70794": 0.7924294471740723, "aqua_rat_68227": 0.7928819060325623, "aqua_rat_41800": 0.7929533123970032, "aqua_rat_84154": 0.7939053773880005, "aqua_rat_16851": 0.7951352596282959, "aqua_rat_43043": 0.795143187046051, "aqua_rat_84046": 0.7952123880386353, "aqua_rat_76358": 0.7959342002868652, "aqua_rat_2381": 0.7975672483444214, "aqua_rat_39186": 0.7977270483970642, "aqua_rat_80228": 0.799054741859436, "aqua_rat_65765": 0.8021208047866821, "math_train_geometry_6226": 0.8047042489051819, "aqua_rat_45831": 0.8056929111480713, "aqua_rat_6164": 0.8057361245155334, "aqua_rat_36721": 0.8067783713340759, "aqua_rat_60553": 0.807707667350769, "aqua_rat_17380": 0.8126077651977539, "camel_19685": 0.8157601952552795, "aqua_rat_64709": 0.8191309571266174, "aqua_rat_10325": 0.8211534023284912, "aqua_rat_16643": 0.8267704248428345, "aqua_rat_29007": 0.8300824761390686}, "TheoremQA_maxku/cv-imageprocessing6-histogram.json": {"TheoremQA_maxku/cv-imageprocessing6-histogram.json": 0, "gsm_train_6930": 0.7464364171028137, "aqua_rat_62074": 0.7465183734893799, "gsm_rft_23162": 0.7465940713882446, "aqua_rat_50308": 0.7467532157897949, "camel_8704": 0.7467710375785828, "camel_9729": 0.7467776536941528, "aqua_rat_34614": 0.7467776536941528, "gsm_rft_11997": 0.7468163371086121, "gsm_train_6196": 0.7468163371086121, "aqua_rat_42552": 0.7468975782394409, "gsm_rft_6826": 0.7469149827957153, "gsm_rft_18736": 0.7469331622123718, "aqua_rat_60270": 0.7469844818115234, "aqua_rat_34864": 0.7470414638519287, "aqua_rat_76048": 0.747048020362854, "aqua_rat_71385": 0.7471539378166199, "camel_9684": 0.7471762299537659, "aqua_rat_36046": 0.747245728969574, "camel_9401": 0.7472478747367859, "aqua_rat_45273": 0.747307538986206, "aqua_rat_34482": 0.7473600506782532, "aqua_rat_88002": 0.7473692297935486, "aqua_rat_21738": 0.7474929094314575, "camel_9122": 0.7474972009658813, "aqua_rat_43637": 0.7474982142448425, "aqua_rat_7483": 0.747504472732544, "gsm_rft_18205": 0.7475462555885315, "camel_8861": 0.7475565671920776, "camel_8651": 0.7476586103439331, "aqua_rat_79202": 0.7477251887321472, "aqua_rat_78510": 0.7478426098823547, "gsm_rft_27739": 0.7479163408279419, "camel_9858": 0.7479954361915588, "aqua_rat_56896": 0.7480248808860779, "aqua_rat_12712": 0.748042106628418, "gsm_train_10575": 0.7480968236923218, "aqua_rat_46729": 0.7481248378753662, "gsm_rft_23552": 0.748140275478363, "aqua_rat_36044": 0.7483286261558533, "camel_9724": 0.7483396530151367, "aqua_rat_1970": 0.7483465671539307, "gsm_rft_14308": 0.7483930587768555, "aqua_rat_43002": 0.7484102249145508, "aqua_rat_61859": 0.748458206653595, "camel_9870": 0.7487099170684814, "aqua_rat_73720": 0.7487583756446838, "aqua_rat_22518": 0.7488694787025452, "aqua_rat_63790": 0.7489188313484192, "aqua_rat_52229": 0.7489262223243713, "aqua_rat_17679": 0.7489532828330994, "camel_8339": 0.7489600777626038, "gsm_rft_15553": 0.7490587830543518, "aqua_rat_39463": 0.7492092251777649, "aqua_rat_68069": 0.7492687106132507, "aqua_rat_29580": 0.7492706179618835, "camel_25563": 0.7492741346359253, "aqua_rat_26531": 0.749311089515686, "aqua_rat_51043": 0.7493970394134521, "gsm_rft_8728": 0.7493982911109924, "aqua_rat_34976": 0.749407172203064, "camel_9170": 0.7495473027229309, "aqua_rat_26203": 0.749624490737915, "gsm_train_28945": 0.7497671246528625, "aqua_rat_41359": 0.7499483227729797, "aqua_rat_22452": 0.7499789595603943, "aqua_rat_22669": 0.7499791383743286, "aqua_rat_45761": 0.7500202655792236, "aqua_rat_83506": 0.7501487731933594, "aqua_rat_42142": 0.7502754330635071, "aqua_rat_63725": 0.7502763271331787, "aqua_rat_76356": 0.7504202127456665, "camel_9701": 0.7504504919052124, "aqua_rat_43666": 0.7504609823226929, "aqua_rat_84504": 0.7506985664367676, "aqua_rat_12696": 0.7507129907608032, "aqua_rat_71213": 0.7507520914077759, "aqua_rat_82882": 0.7507567405700684, "camel_36572": 0.7508175373077393, "gsm_rft_15195": 0.7509215474128723, "gsm_rft_16107": 0.7509215474128723, "gsm_rft_6449": 0.7509334683418274, "gsm_train_14922": 0.7509334683418274, "aqua_rat_41652": 0.7509476542472839, "aqua_rat_56885": 0.7509639859199524, "aqua_rat_6693": 0.7510333061218262, "aqua_rat_21698": 0.7511614561080933, "aqua_rat_17660": 0.7512952089309692, "aqua_rat_66892": 0.751311182975769, "aqua_rat_85438": 0.75132817029953, "aqua_rat_42058": 0.7513333559036255, "aqua_rat_22476": 0.7514466047286987, "aqua_rat_38285": 0.7514720559120178, "aqua_rat_17881": 0.7517602443695068, "aqua_rat_40952": 0.7520410418510437, "aqua_rat_7164": 0.7520430684089661, "aqua_rat_18682": 0.7521396279335022, "aqua_rat_46784": 0.7521837949752808, "gsm_rft_21351": 0.7522633671760559, "aqua_rat_3071": 0.7527036070823669, "aqua_rat_49569": 0.7528006434440613, "aqua_rat_58894": 0.7528399229049683, "aqua_rat_8423": 0.7531354427337646, "camel_9890": 0.7532491683959961, "aqua_rat_9603": 0.7532737255096436, "camel_9866": 0.753324568271637, "camel_9893": 0.7534605264663696, "aqua_rat_73459": 0.7536693811416626, "gsm_rft_12684": 0.7536773085594177, "aqua_rat_50602": 0.7537838220596313, "aqua_rat_20540": 0.7537846565246582, "aqua_rat_61148": 0.7537857294082642, "aqua_rat_79065": 0.7538793683052063, "aqua_rat_22466": 0.7540639042854309, "aqua_rat_73658": 0.754095196723938, "aqua_rat_8919": 0.754130482673645, "aqua_rat_30710": 0.7541569471359253, "aqua_rat_70783": 0.7541666626930237, "aqua_rat_7131": 0.7542734146118164, "camel_9259": 0.754422664642334, "aqua_rat_45562": 0.754498302936554, "aqua_rat_73988": 0.7545322179794312, "aqua_rat_73303": 0.754680871963501, "aqua_rat_3676": 0.7547616958618164, "camel_8830": 0.7548043131828308, "aqua_rat_2292": 0.7548120021820068, "aqua_rat_14502": 0.7549293637275696, "aqua_rat_52525": 0.7549765110015869, "aqua_rat_40283": 0.7550568580627441, "aqua_rat_50597": 0.7551026344299316, "aqua_rat_51045": 0.7551397681236267, "gsm_train_17713": 0.7551743984222412, "aqua_rat_43907": 0.7552347779273987, "gsm_rft_26702": 0.7555396556854248, "aqua_rat_31869": 0.7555575370788574, "aqua_rat_80630": 0.7564173340797424, "aqua_rat_89103": 0.7569218873977661, "camel_9882": 0.756983757019043, "aqua_rat_24338": 0.757127583026886, "aqua_rat_2411": 0.7571883201599121, "aqua_rat_7528": 0.7572649717330933, "gsm_rft_30185": 0.7574228644371033, "gsm_rft_30865": 0.7574228644371033, "aqua_rat_16321": 0.7579913139343262, "aqua_rat_15357": 0.7581387162208557, "aqua_rat_42161": 0.7583528161048889, "aqua_rat_75165": 0.7584928274154663, "aqua_rat_35806": 0.7585980296134949, "camel_23643": 0.7586643695831299, "aqua_rat_14229": 0.7588030099868774, "aqua_rat_5269": 0.7588563561439514, "aqua_rat_1283": 0.7590699791908264, "camel_20866": 0.7590718269348145, "aqua_rat_23428": 0.7595241665840149, "gsm_train_29804": 0.7599208950996399, "gsm_rft_19047": 0.7599208950996399, "aqua_rat_34164": 0.760093092918396, "gsm_rft_26920": 0.760361909866333, "aqua_rat_69951": 0.7608338594436646, "gsm_rft_32075": 0.7611604928970337, "aqua_rat_41252": 0.7611915469169617, "aqua_rat_87205": 0.7614377737045288, "aqua_rat_39605": 0.7621387243270874, "camel_9875": 0.7624896764755249, "aqua_rat_58938": 0.7626140713691711, "aqua_rat_55552": 0.7629915475845337, "aqua_rat_68886": 0.7632379531860352, "aqua_rat_2668": 0.7634633779525757, "aqua_rat_34970": 0.7636289596557617, "aqua_rat_21495": 0.7642228007316589, "aqua_rat_89106": 0.764571487903595, "aqua_rat_57506": 0.7648387551307678, "camel_38559": 0.7649537920951843, "aqua_rat_61938": 0.7655520439147949, "aqua_rat_65742": 0.7656590938568115, "aqua_rat_71456": 0.7657864093780518, "aqua_rat_88781": 0.7669093012809753, "aqua_rat_76108": 0.7674153447151184, "aqua_rat_67774": 0.7674686312675476, "aqua_rat_48016": 0.768115222454071, "aqua_rat_30773": 0.7681916952133179, "camel_9865": 0.7688339948654175, "aqua_rat_63404": 0.7693266272544861, "aqua_rat_42905": 0.7696158289909363, "camel_8677": 0.7701128721237183, "aqua_rat_32703": 0.7724992036819458, "aqua_rat_83986": 0.7744227051734924, "aqua_rat_56383": 0.775516152381897, "aqua_rat_46009": 0.7768294811248779, "camel_9166": 0.7791167497634888, "aqua_rat_19152": 0.7796735167503357, "camel_38521": 0.7816476821899414, "camel_9127": 0.783758819103241, "camel_9911": 0.7864130735397339, "aqua_rat_14601": 0.7892098426818848, "aqua_rat_12478": 0.7919929027557373, "aqua_rat_56264": 0.7920964956283569, "aqua_rat_27645": 0.792998731136322, "aqua_rat_4058": 0.794367790222168, "aqua_rat_62272": 0.7962448596954346}, "TheoremQA_elainewan/math_algebra_1.json": {"camel_15726": 0, "camel_14565": 0, "camel_161": 0, "camel_15528": 0, "math_train_algebra_1005": 0, "camel_15186": 0, "aqua_rat_29457": 0.7468527555465698, "camel_25773": 0.7468751072883606, "aqua_rat_86183": 0.7469197511672974, "aqua_rat_8458": 0.7469333410263062, "camel_24615": 0.7471498250961304, "camel_24612": 0.7472259402275085, "camel_25790": 0.7472800016403198, "camel_40809": 0.7473016381263733, "aqua_rat_75828": 0.7473075985908508, "gsm_rft_6168": 0.7475441694259644, "gsm_rft_17734": 0.7475441694259644, "gsm_train_19634": 0.7475441694259644, "camel_38288": 0.7475699782371521, "aqua_rat_13983": 0.747584879398346, "camel_41943": 0.7475877404212952, "camel_38768": 0.7476779222488403, "camel_25686": 0.7476967573165894, "camel_25924": 0.7478634715080261, "camel_24574": 0.7478980422019958, "camel_25793": 0.7479038834571838, "camel_24178": 0.7479492425918579, "camel_41551": 0.7479773163795471, "camel_25719": 0.74798983335495, "camel_24572": 0.7480871677398682, "camel_25682": 0.7481789588928223, "aqua_rat_76590": 0.748212456703186, "camel_39706": 0.7482325434684753, "gsm_rft_15751": 0.748289167881012, "camel_24576": 0.7483004927635193, "camel_41734": 0.7483591437339783, "camel_38597": 0.7484079599380493, "camel_25651": 0.7484245300292969, "camel_38209": 0.7484697699546814, "aqua_rat_25163": 0.748596727848053, "camel_40968": 0.74861079454422, "camel_24226": 0.7486484050750732, "aqua_rat_17648": 0.7487620711326599, "camel_38322": 0.7487706542015076, "aqua_rat_16730": 0.7487722039222717, "gsm_rft_9243": 0.7490165829658508, "aqua_rat_45146": 0.7490388751029968, "camel_25718": 0.7491374015808105, "camel_24204": 0.7491593956947327, "camel_24177": 0.7491723895072937, "aqua_rat_66471": 0.7492329478263855, "aqua_rat_78979": 0.749255895614624, "camel_25702": 0.749296247959137, "aqua_rat_42213": 0.7493634819984436, "aqua_rat_53644": 0.7493889927864075, "camel_38069": 0.7494269609451294, "camel_24239": 0.7494783401489258, "camel_24206": 0.7495178580284119, "aqua_rat_20133": 0.7495637536048889, "aqua_rat_74421": 0.7495818734169006, "aqua_rat_2821": 0.7496042251586914, "camel_24568": 0.749614953994751, "aqua_rat_63692": 0.7496152520179749, "camel_25756": 0.7496519684791565, "camel_24212": 0.749754786491394, "camel_25959": 0.7498902082443237, "camel_41827": 0.7499631643295288, "camel_38180": 0.7500000596046448, "camel_24561": 0.7502346038818359, "camel_25685": 0.750335693359375, "camel_24610": 0.7504149675369263, "camel_41615": 0.750486433506012, "camel_24608": 0.7504957914352417, "camel_39724": 0.7505865693092346, "aqua_rat_14515": 0.7506288290023804, "gsm_rft_4894": 0.7507145404815674, "camel_25752": 0.7508331537246704, "camel_41645": 0.7510660886764526, "camel_25797": 0.7513066530227661, "camel_24636": 0.7514981031417847, "camel_24620": 0.7517333626747131, "camel_25459": 0.7518244385719299, "camel_21851": 0.7520529627799988, "camel_41690": 0.7523003816604614, "camel_24197": 0.7523496150970459, "camel_38838": 0.7523552775382996, "camel_38853": 0.7524535059928894, "camel_25650": 0.7525069713592529, "camel_24192": 0.7526312470436096, "camel_41875": 0.7527689337730408, "camel_41566": 0.7528724074363708, "camel_25707": 0.752906084060669, "camel_24638": 0.7529289722442627, "camel_24196": 0.7529618740081787, "camel_37707": 0.7529727816581726, "camel_25961": 0.7529884576797485, "camel_40598": 0.7532109022140503, "camel_25757": 0.7533087730407715, "camel_38828": 0.7533454895019531, "camel_24577": 0.753371000289917, "camel_25766": 0.7534424662590027, "camel_25720": 0.7534692883491516, "camel_25638": 0.7535348534584045, "camel_25737": 0.7535792589187622, "camel_25861": 0.7536253929138184, "camel_25998": 0.7536932826042175, "camel_24603": 0.7538131475448608, "camel_38398": 0.7541410326957703, "aqua_rat_40283": 0.7543168067932129, "camel_24583": 0.7544782757759094, "camel_24598": 0.754500150680542, "camel_25758": 0.7545859813690186, "camel_25973": 0.7546049356460571, "camel_25767": 0.7549163699150085, "camel_25681": 0.7550333142280579, "camel_25751": 0.7552664875984192, "camel_40724": 0.7556175589561462, "camel_24595": 0.7557103037834167, "camel_25834": 0.7560140490531921, "camel_24218": 0.756277322769165, "camel_24623": 0.7565903067588806, "camel_25969": 0.756784200668335, "camel_24600": 0.7569996118545532, "camel_25974": 0.7572847604751587, "camel_25835": 0.7573302388191223, "camel_24553": 0.7573319673538208, "camel_24187": 0.7573931813240051, "camel_25941": 0.7574983835220337, "camel_24208": 0.757521390914917, "camel_25796": 0.7577878832817078, "camel_25967": 0.7580240368843079, "camel_24617": 0.7581846117973328, "gsm_rft_6027": 0.7585301995277405, "camel_25716": 0.7586637735366821, "camel_39032": 0.7586817145347595, "aqua_rat_19094": 0.7587242722511292, "gsm_train_35156": 0.7587435245513916, "camel_24573": 0.7587947249412537, "camel_38925": 0.7588454484939575, "aqua_rat_17708": 0.758903443813324, "camel_25755": 0.7592958211898804, "camel_25818": 0.7596119046211243, "camel_25779": 0.7596379518508911, "camel_39714": 0.7598130702972412, "camel_25940": 0.7599924802780151, "aqua_rat_2910": 0.7599979043006897, "camel_25944": 0.7600070238113403, "camel_24417": 0.7600650191307068, "camel_25966": 0.7601111531257629, "camel_25736": 0.760141909122467, "camel_25821": 0.7602195143699646, "aqua_rat_53429": 0.76036536693573, "camel_21901": 0.7606510519981384, "camel_25931": 0.7610373497009277, "camel_24609": 0.7611443996429443, "camel_24618": 0.7613959908485413, "gsm_rft_11207": 0.7615448832511902, "camel_38060": 0.7615547180175781, "camel_24232": 0.7616196274757385, "aqua_rat_70349": 0.7618988752365112, "camel_25989": 0.761919379234314, "camel_25764": 0.7620303630828857, "camel_24607": 0.7620695233345032, "camel_24588": 0.7627535462379456, "aqua_rat_11545": 0.7629246115684509, "camel_25869": 0.7632240653038025, "camel_38613": 0.7636966705322266, "camel_24480": 0.7640206813812256, "camel_25817": 0.764404833316803, "camel_24616": 0.7649084329605103, "camel_40848": 0.7654293179512024, "camel_25708": 0.7654403448104858, "camel_25783": 0.7660245895385742, "camel_25696": 0.7663282752037048, "camel_24630": 0.7663418650627136, "camel_25642": 0.7664621472358704, "camel_38628": 0.7664861083030701, "camel_37728": 0.7666763067245483, "camel_24562": 0.7672290802001953, "camel_25680": 0.767270028591156, "camel_25746": 0.7672842144966125, "camel_25979": 0.7677943110466003, "camel_25739": 0.7683965563774109, "camel_25792": 0.7685491442680359, "camel_20418": 0.7689517736434937, "camel_25761": 0.7690290212631226, "camel_25691": 0.7693068385124207, "camel_24217": 0.7696470022201538, "camel_25692": 0.7707214951515198, "camel_25771": 0.7726050615310669, "camel_25809": 0.772905707359314, "camel_25712": 0.7730161547660828, "aqua_rat_25180": 0.7733343243598938, "camel_25705": 0.773497462272644, "camel_25646": 0.7746443152427673, "camel_37939": 0.775658905506134, "camel_24613": 0.7772666811943054, "camel_37930": 0.7783843278884888, "camel_24602": 0.7826877236366272, "camel_24625": 0.7902886271476746}, "TheoremQA_xinyi/rotation.json": {"TheoremQA_xinyi/rotation.json": 0, "aqua_rat_53348": 0.7471337914466858, "aqua_rat_52841": 0.7471928000450134, "aqua_rat_4051": 0.7474378347396851, "aqua_rat_9778": 0.747592031955719, "aqua_rat_18047": 0.7479312419891357, "aqua_rat_29648": 0.748241662979126, "aqua_rat_7620": 0.7483415603637695, "gsm_rft_14362": 0.7486172318458557, "gsm_rft_34879": 0.7486172318458557, "aqua_rat_53176": 0.7487676739692688, "aqua_rat_76910": 0.7489541172981262, "aqua_rat_76771": 0.7490035891532898, "aqua_rat_49190": 0.7491008043289185, "gsm_train_21935": 0.7491297721862793, "camel_4969": 0.749392569065094, "aqua_rat_32037": 0.7495619654655457, "aqua_rat_85151": 0.749801754951477, "aqua_rat_737": 0.7499676942825317, "aqua_rat_2726": 0.7500995397567749, "aqua_rat_35936": 0.7502280473709106, "math_test_algebra_1169": 0.7508252263069153, "aqua_rat_75863": 0.750965416431427, "aqua_rat_46492": 0.751022458076477, "aqua_rat_52446": 0.7511375546455383, "aqua_rat_51535": 0.7512145042419434, "aqua_rat_32296": 0.7512634992599487, "aqua_rat_85732": 0.751304030418396, "camel_4972": 0.7515715956687927, "aqua_rat_86805": 0.7515775561332703, "aqua_rat_61167": 0.7518940567970276, "aqua_rat_20336": 0.7521681189537048, "aqua_rat_83073": 0.7528036236763, "camel_5178": 0.7528144717216492, "aqua_rat_16963": 0.753175675868988, "aqua_rat_63010": 0.7533527612686157, "aqua_rat_83393": 0.7538701891899109, "aqua_rat_79577": 0.7545496225357056, "aqua_rat_35730": 0.7547905445098877, "camel_5011": 0.7549391984939575, "aqua_rat_43412": 0.7551424503326416, "math_test_prealgebra_1007": 0.7556076645851135, "math_train_algebra_2034": 0.7557112574577332, "camel_5358": 0.7577530741691589, "aqua_rat_69804": 0.7580539584159851, "aqua_rat_54451": 0.7581688165664673, "aqua_rat_8254": 0.7582119703292847, "aqua_rat_30947": 0.7582868933677673, "aqua_rat_84016": 0.7583507895469666, "aqua_rat_45645": 0.7583708167076111, "aqua_rat_76549": 0.7586303949356079, "aqua_rat_4788": 0.7589479088783264, "aqua_rat_241": 0.7591314315795898, "aqua_rat_8908": 0.7591716647148132, "aqua_rat_43793": 0.7596662640571594, "aqua_rat_27296": 0.759762167930603, "aqua_rat_343": 0.759765625, "aqua_rat_56684": 0.7600465416908264, "camel_4999": 0.7604280710220337, "aqua_rat_60136": 0.7608262896537781, "aqua_rat_20126": 0.7608509063720703, "aqua_rat_50972": 0.7612756490707397, "aqua_rat_83645": 0.7612834572792053, "camel_5035": 0.7613760232925415, "aqua_rat_40694": 0.7613762617111206, "aqua_rat_75694": 0.7616318464279175, "aqua_rat_59863": 0.7617499828338623, "aqua_rat_77927": 0.7620575428009033, "aqua_rat_38590": 0.762151300907135, "aqua_rat_85655": 0.7628096342086792, "aqua_rat_83508": 0.7628686428070068, "aqua_rat_44993": 0.763312041759491, "aqua_rat_29570": 0.763388991355896, "aqua_rat_8429": 0.763490617275238, "camel_5114": 0.7634984850883484, "aqua_rat_12432": 0.7639040946960449, "aqua_rat_61106": 0.7640386819839478, "aqua_rat_19041": 0.7640623450279236, "aqua_rat_74287": 0.7645127177238464, "aqua_rat_40672": 0.7645787596702576, "aqua_rat_59674": 0.7647340297698975, "aqua_rat_57495": 0.7650381326675415, "aqua_rat_73912": 0.7652486562728882, "aqua_rat_8986": 0.7657791376113892, "camel_4987": 0.7659868597984314, "aqua_rat_58488": 0.7661599516868591, "aqua_rat_46923": 0.7663218379020691, "aqua_rat_62625": 0.7664157152175903, "aqua_rat_42327": 0.7676005959510803, "aqua_rat_66742": 0.7679768204689026, "aqua_rat_43143": 0.7682057619094849, "aqua_rat_52041": 0.7692292332649231, "aqua_rat_68269": 0.7693796157836914, "aqua_rat_67556": 0.7699439525604248, "aqua_rat_47661": 0.7700618505477905, "aqua_rat_46912": 0.7702252864837646, "aqua_rat_85602": 0.770233690738678, "aqua_rat_39810": 0.7702996730804443, "aqua_rat_71139": 0.7704043388366699, "aqua_rat_61468": 0.7705177664756775, "aqua_rat_7567": 0.7711862921714783, "aqua_rat_64279": 0.7713944911956787, "aqua_rat_43369": 0.7716115117073059, "aqua_rat_25430": 0.7719500064849854, "aqua_rat_72406": 0.7721662521362305, "aqua_rat_69828": 0.7724736928939819, "aqua_rat_30978": 0.7724921107292175, "aqua_rat_79046": 0.7731948494911194, "math_train_geometry_613": 0.7735600471496582, "aqua_rat_55874": 0.7739064693450928, "aqua_rat_75769": 0.7742207050323486, "aqua_rat_87142": 0.7743736505508423, "aqua_rat_7934": 0.7747023105621338, "aqua_rat_71238": 0.7747246026992798, "aqua_rat_12137": 0.7748222351074219, "aqua_rat_18077": 0.7752086520195007, "aqua_rat_14801": 0.7754671573638916, "aqua_rat_79843": 0.7760823965072632, "aqua_rat_33984": 0.7761698365211487, "aqua_rat_34381": 0.7762669920921326, "aqua_rat_48820": 0.7763155102729797, "aqua_rat_8953": 0.7764145731925964, "aqua_rat_18920": 0.776500403881073, "aqua_rat_17586": 0.7778739333152771, "aqua_rat_74017": 0.7780791521072388, "aqua_rat_63049": 0.7781654000282288, "aqua_rat_17232": 0.7782125473022461, "aqua_rat_53605": 0.7784791588783264, "camel_5344": 0.7785086035728455, "math_test_prealgebra_1423": 0.7786025404930115, "aqua_rat_44946": 0.7786517143249512, "aqua_rat_28317": 0.7787543535232544, "aqua_rat_69552": 0.7788054943084717, "aqua_rat_17161": 0.7790327668190002, "aqua_rat_78529": 0.7794323563575745, "aqua_rat_19837": 0.7795462012290955, "aqua_rat_36048": 0.7800261378288269, "aqua_rat_55349": 0.7809082865715027, "aqua_rat_86326": 0.7810153365135193, "aqua_rat_57227": 0.7810575366020203, "aqua_rat_57087": 0.7810854315757751, "aqua_rat_77944": 0.7811043858528137, "aqua_rat_52253": 0.7814023494720459, "aqua_rat_46742": 0.7820907831192017, "aqua_rat_13503": 0.7822534441947937, "aqua_rat_60106": 0.7824349403381348, "TheoremQA_xinyi/newtons_laws_1.json": 0.783531129360199, "aqua_rat_71793": 0.7840161323547363, "aqua_rat_36499": 0.7841331958770752, "aqua_rat_25695": 0.784231960773468, "aqua_rat_73548": 0.7847842574119568, "aqua_rat_8248": 0.7848573923110962, "aqua_rat_26876": 0.7855632901191711, "aqua_rat_81253": 0.7860096096992493, "aqua_rat_6798": 0.786439061164856, "aqua_rat_20229": 0.7865508794784546, "aqua_rat_40488": 0.787487268447876, "aqua_rat_85184": 0.7877454161643982, "aqua_rat_2921": 0.7882726192474365, "aqua_rat_64696": 0.7883548140525818, "aqua_rat_67030": 0.7884007096290588, "aqua_rat_41201": 0.788551390171051, "aqua_rat_77772": 0.7891008853912354, "camel_5284": 0.7891454100608826, "aqua_rat_54163": 0.7893420457839966, "aqua_rat_79407": 0.7901073694229126, "aqua_rat_43663": 0.791198194026947, "aqua_rat_50800": 0.7913787364959717, "aqua_rat_37025": 0.7914970517158508, "aqua_rat_15993": 0.7922206521034241, "aqua_rat_75907": 0.7927375435829163, "aqua_rat_75408": 0.7929549813270569, "aqua_rat_18227": 0.7932690978050232, "aqua_rat_2038": 0.7938429117202759, "aqua_rat_5744": 0.7939856648445129, "aqua_rat_23015": 0.7954802513122559, "aqua_rat_70325": 0.7959254384040833, "aqua_rat_11110": 0.7963829040527344, "aqua_rat_86618": 0.7970064878463745, "aqua_rat_83499": 0.7975069284439087, "camel_5004": 0.8004319071769714, "aqua_rat_65204": 0.8026986718177795, "aqua_rat_54538": 0.8027773499488831, "aqua_rat_66318": 0.803374171257019, "aqua_rat_6305": 0.8039601445198059, "aqua_rat_51549": 0.804177463054657, "aqua_rat_34465": 0.8052554726600647, "aqua_rat_18441": 0.8052952289581299, "aqua_rat_43469": 0.80567467212677, "aqua_rat_81657": 0.8063313961029053, "aqua_rat_84659": 0.8067064881324768, "aqua_rat_4364": 0.8070741891860962, "aqua_rat_16632": 0.8070940375328064, "aqua_rat_43997": 0.8083480596542358, "aqua_rat_59830": 0.8110536336898804, "aqua_rat_84913": 0.8124849200248718, "aqua_rat_75022": 0.8137398362159729, "aqua_rat_8349": 0.8139685392379761, "aqua_rat_3802": 0.8161234855651855, "aqua_rat_65833": 0.8177608251571655}, "TheoremQA_wenhuchen/eigen_value1.json": {"camel_14492": 0, "camel_14434": 0, "camel_14489": 0, "camel_14513": 0, "camel_14445": 0, "camel_14525": 0, "camel_14499": 0, "camel_14431": 0, "camel_14498": 0, "camel_14454": 0, "camel_14542": 0, "camel_14400": 0, "camel_14517": 0, "camel_14535": 0, "camel_14448": 0, "camel_14507": 0, "camel_14501": 0, "camel_14551": 0, "camel_14458": 0, "camel_14554": 0, "camel_14418": 0, "camel_14548": 0, "camel_14532": 0, "camel_14483": 0, "camel_14484": 0, "camel_14552": 0, "camel_14420": 0, "camel_14494": 0, "camel_14503": 0, "camel_14425": 0, "camel_14436": 0, "camel_14456": 0, "camel_14414": 0, "camel_14462": 0, "camel_14475": 0, "camel_14512": 0, "camel_14546": 0, "camel_14515": 0, "camel_14432": 0, "camel_14529": 0, "camel_14556": 0, "camel_14463": 0, "camel_14476": 0, "camel_14557": 0, "camel_14509": 0, "camel_14550": 0, "camel_14533": 0, "camel_14453": 0, "camel_14455": 0, "camel_14419": 0, "camel_14518": 0, "camel_14538": 0, "camel_14537": 0, "camel_14516": 0, "camel_14541": 0, "camel_14474": 0, "camel_14508": 0, "camel_14536": 0, "camel_14469": 0, "camel_14506": 0, "camel_14460": 0, "camel_14472": 0, "camel_14406": 0, "camel_14521": 0, "camel_14408": 0, "camel_14544": 0, "camel_14417": 0, "camel_14428": 0, "camel_14430": 0, "camel_14446": 0, "camel_14429": 0, "camel_14504": 0, "camel_14452": 0, "camel_14534": 0, "camel_14426": 0, "camel_14412": 0, "camel_14470": 0, "camel_14450": 0, "camel_14539": 0, "camel_14459": 0, "camel_14439": 0, "camel_14401": 0, "camel_14545": 0, "camel_14510": 0, "camel_14477": 0, "camel_14422": 0, "camel_14402": 0, "camel_14461": 0, "camel_14438": 0, "camel_14413": 0, "camel_14424": 0, "camel_14486": 0, "camel_14441": 0, "camel_14403": 0, "camel_14466": 0, "camel_14427": 0, "camel_14549": 0, "camel_14449": 0, "camel_14435": 0, "camel_14543": 0, "camel_14410": 0, "camel_14421": 0, "camel_14443": 0, "camel_14437": 0, "camel_14447": 0, "camel_14493": 0, "camel_14405": 0, "camel_14468": 0, "camel_14423": 0, "camel_14473": 0, "camel_14520": 0, "camel_14457": 0, "camel_14440": 0, "camel_14526": 0, "camel_14487": 0, "camel_14407": 0, "camel_14464": 0, "camel_14409": 0, "camel_14471": 0, "camel_14523": 0, "camel_14451": 0, "camel_14404": 0, "camel_14479": 0, "camel_14411": 0, "camel_14531": 0, "camel_14558": 0, "camel_14442": 0, "camel_14415": 0, "camel_14465": 0, "camel_14530": 0, "camel_14444": 0, "TheoremQA_wenhuchen/eigen_value1.json": 0, "camel_14478": 0, "camel_14467": 0, "camel_40153": 0.7828255891799927, "camel_40131": 0.7844781279563904, "camel_28738": 0.7847778797149658, "camel_40108": 0.7852725386619568, "camel_40156": 0.7858463525772095, "camel_39003": 0.7860325574874878, "camel_40090": 0.7868510484695435, "camel_40134": 0.7875726819038391, "camel_40123": 0.787815511226654, "camel_9333": 0.7883384823799133, "camel_40102": 0.7885673642158508, "camel_40120": 0.7889174818992615, "camel_40100": 0.7889643311500549, "camel_40105": 0.7891238331794739, "camel_40103": 0.7933082580566406, "TheoremQA_wenhuchen/definite_matrix2.json": 0.7933534383773804, "camel_28786": 0.7935826182365417, "camel_28673": 0.7941710948944092, "camel_40144": 0.7943025231361389, "TheoremQA_wenhuchen/definite_matrix1.json": 0.7959105372428894, "camel_45480": 0.7959936261177063, "camel_40152": 0.7967402935028076, "camel_40137": 0.7997632622718811, "camel_40109": 0.8004041314125061, "camel_40125": 0.801983654499054, "camel_40092": 0.8023627400398254, "camel_40158": 0.8024164438247681, "camel_40145": 0.804131269454956, "camel_40114": 0.8047151565551758, "camel_40140": 0.8051145672798157, "camel_40082": 0.8051642179489136, "camel_40110": 0.8056644201278687, "camel_40089": 0.8058478832244873, "camel_40128": 0.8068217039108276, "camel_40081": 0.8073415160179138, "camel_40146": 0.807675302028656, "camel_40096": 0.8093023896217346, "camel_40118": 0.8115909099578857, "camel_40122": 0.8119633197784424, "camel_40143": 0.8120399713516235, "camel_40141": 0.8146334886550903, "camel_40106": 0.8152197003364563, "camel_40157": 0.8159084320068359, "camel_40117": 0.8160303831100464, "camel_40097": 0.8184854984283447, "camel_40155": 0.8195204138755798, "camel_40119": 0.820033073425293, "camel_40083": 0.8204063773155212, "camel_40115": 0.820717453956604, "camel_40130": 0.8210920095443726, "camel_40104": 0.8216052651405334, "camel_30479": 0.8228427767753601, "camel_40142": 0.8229045867919922, "camel_40116": 0.8256520628929138, "camel_40133": 0.8264368772506714, "camel_40154": 0.8275575041770935, "camel_40127": 0.8290652632713318, "camel_40094": 0.8291170597076416, "camel_40126": 0.8303589224815369, "camel_40135": 0.8323050737380981, "camel_40085": 0.8334774971008301, "camel_40136": 0.8350726962089539, "TheoremQA_elainewan/math_algebra_7.json": 0.8379261493682861, "camel_40139": 0.8413457274436951, "camel_40112": 0.8426454663276672, "camel_40101": 0.8474241495132446}, "TheoremQA_wenhuchen/definite_matrix1.json": {"camel_15729": 0, "camel_15329": 0, "camel_15178": 0, "camel_15832": 0, "camel_15717": 0, "camel_15125": 0, "camel_15705": 0, "camel_15682": 0, "camel_15707": 0, "camel_15687": 0, "camel_15803": 0, "camel_15690": 0, "camel_15360": 0, "camel_15342": 0, "camel_15826": 0, "camel_15683": 0, "camel_15165": 0, "camel_15727": 0, "camel_15679": 0, "camel_15716": 0, "camel_14506": 0, "camel_15051": 0, "TheoremQA_wenhuchen/definite_matrix1.json": 0, "camel_15194": 0, "camel_15134": 0, "camel_15752": 0, "camel_15168": 0, "camel_15169": 0, "camel_15123": 0, "camel_15121": 0, "camel_15162": 0, "camel_15721": 0, "camel_15748": 0, "camel_15130": 0, "camel_15728": 0, "camel_15187": 0, "camel_15308": 0, "camel_15145": 0, "camel_15656": 0, "camel_15697": 0, "camel_15193": 0, "camel_40094": 0.6829127669334412, "camel_9293": 0.6829360127449036, "camel_29571": 0.6829794049263, "camel_36766": 0.6829944252967834, "camel_36936": 0.6830049753189087, "camel_40114": 0.683275580406189, "camel_29450": 0.683379054069519, "camel_48338": 0.6834084391593933, "camel_9017": 0.6836085915565491, "camel_9329": 0.683697521686554, "camel_9310": 0.6837397813796997, "camel_36335": 0.6838997006416321, "camel_18740": 0.683948278427124, "camel_29602": 0.6840617656707764, "camel_29543": 0.6840996146202087, "camel_29534": 0.6843093037605286, "camel_38978": 0.6843334436416626, "camel_29508": 0.6843620538711548, "camel_29563": 0.684454619884491, "camel_29670": 0.6846010088920593, "camel_18724": 0.6846582293510437, "camel_29104": 0.6850330829620361, "camel_29650": 0.685402512550354, "camel_29612": 0.6854248642921448, "camel_39010": 0.6854297518730164, "camel_29625": 0.6855155825614929, "camel_29126": 0.6858105063438416, "camel_29443": 0.6858234405517578, "camel_29674": 0.6861215233802795, "camel_18771": 0.686166524887085, "camel_39362": 0.6862441301345825, "camel_9346": 0.6865030527114868, "camel_29485": 0.686730146408081, "camel_29656": 0.6867910623550415, "camel_18758": 0.6871414184570312, "camel_9325": 0.6871618032455444, "camel_40870": 0.6876002550125122, "camel_29649": 0.6877169609069824, "camel_18764": 0.6878471374511719, "camel_29137": 0.6878688335418701, "camel_29186": 0.6879474520683289, "TheoremQA_xinyi/kernel_2.json": 0.6884898543357849, "camel_29663": 0.6886263489723206, "camel_29605": 0.6888870596885681, "camel_36502": 0.689104437828064, "camel_18786": 0.6894668936729431, "camel_29501": 0.6897663474082947, "TheoremQA_elainewan/math_algebra_2.json": 0.6898449659347534, "camel_29265": 0.689887285232544, "camel_18787": 0.6900526285171509, "camel_40803": 0.6901484131813049, "camel_9305": 0.690159022808075, "camel_29556": 0.6902483105659485, "camel_48340": 0.6902967691421509, "camel_40940": 0.6904648542404175, "camel_18775": 0.6910979747772217, "camel_17522": 0.6911539435386658, "camel_39030": 0.6913386583328247, "camel_9296": 0.6914380788803101, "camel_29253": 0.6916359066963196, "camel_29540": 0.6918666958808899, "camel_8965": 0.692011833190918, "camel_29120": 0.6920846700668335, "camel_29566": 0.6921766996383667, "camel_9321": 0.6923065781593323, "camel_18959": 0.6928977966308594, "camel_29679": 0.6933519840240479, "camel_40119": 0.6947286128997803, "camel_38961": 0.6949265003204346, "camel_29130": 0.6950174570083618, "camel_40110": 0.6951420307159424, "camel_8988": 0.695179283618927, "camel_29629": 0.6953099966049194, "camel_9358": 0.695983350276947, "camel_18729": 0.696112871170044, "camel_39021": 0.6964399814605713, "camel_38976": 0.6967378258705139, "camel_29617": 0.6969939470291138, "camel_29158": 0.6970003247261047, "camel_40139": 0.6972998976707458, "camel_18738": 0.6973040103912354, "camel_18742": 0.6977190375328064, "camel_18723": 0.6977210640907288, "camel_39017": 0.6977639198303223, "camel_29622": 0.6980156898498535, "camel_39036": 0.6982466578483582, "camel_9339": 0.69869464635849, "camel_38973": 0.698925793170929, "camel_29616": 0.6991751790046692, "camel_29523": 0.6994537115097046, "camel_18759": 0.6995641589164734, "camel_29673": 0.6998330354690552, "camel_29458": 0.6999714970588684, "camel_29596": 0.7002546787261963, "camel_29568": 0.7004544138908386, "camel_29532": 0.7007948756217957, "camel_18789": 0.7012107372283936, "camel_29607": 0.7014634609222412, "camel_29630": 0.7017956972122192, "camel_29641": 0.7019556760787964, "camel_18773": 0.7029498219490051, "camel_29615": 0.7033101916313171, "camel_9299": 0.703553318977356, "camel_9359": 0.7049952745437622, "camel_29658": 0.7055168151855469, "camel_18780": 0.7058036923408508, "camel_29672": 0.7058335542678833, "camel_29642": 0.7060229778289795, "camel_38985": 0.7060945630073547, "camel_29661": 0.7063321471214294, "camel_40840": 0.7064412832260132, "camel_40117": 0.7069361209869385, "camel_18756": 0.7072824835777283, "camel_29570": 0.7075844407081604, "camel_29606": 0.7078129053115845, "camel_29676": 0.7100262641906738, "camel_40155": 0.7105608582496643, "camel_29669": 0.7109808325767517, "camel_29609": 0.7124339938163757, "camel_29655": 0.7130268812179565, "camel_40126": 0.7147930264472961, "camel_29628": 0.7153337001800537, "camel_39019": 0.7161410450935364, "camel_39008": 0.7179297208786011, "camel_40860": 0.7181933522224426, "camel_38982": 0.718225359916687, "camel_17569": 0.7187038064002991, "camel_39013": 0.7193211913108826, "camel_39001": 0.7193525433540344, "camel_38972": 0.7207938432693481, "camel_39018": 0.7222108244895935, "camel_39000": 0.7244846820831299, "camel_39004": 0.7262116074562073, "camel_39011": 0.7268289923667908, "camel_38990": 0.7317751049995422, "camel_38967": 0.7320933938026428, "camel_38974": 0.7385271787643433, "camel_39023": 0.7404080033302307, "camel_38991": 0.7405044436454773, "camel_38979": 0.7415409684181213, "camel_39012": 0.7424184679985046, "camel_38970": 0.7431203126907349, "camel_38984": 0.7438452243804932, "camel_38995": 0.7459123134613037, "camel_39029": 0.7466922402381897, "camel_38983": 0.7489017248153687, "camel_39038": 0.7516178488731384, "camel_39025": 0.7519654631614685, "camel_38992": 0.7605284452438354, "camel_38966": 0.7609038949012756, "camel_39009": 0.7612770795822144, "camel_38996": 0.7707662582397461, "camel_38963": 0.7712947130203247, "camel_38977": 0.7738977074623108, "camel_38964": 0.7782728672027588, "camel_39037": 0.7785084247589111, "camel_38980": 0.7795782089233398, "camel_38999": 0.7843334674835205, "TheoremQA_wenhuchen/definite_matrix2.json": 0.8096488118171692}, "TheoremQA_elainewan/math_algebra_1_2.json": {"math_train_intermediate_algebra_620": 0, "camel_433": 0, "camel_418": 0, "camel_1594": 0, "camel_1719": 0, "camel_468": 0, "camel_450": 0, "camel_445": 0, "camel_413": 0, "camel_1730": 0, "math_train_algebra_517": 0, "camel_1694": 0, "camel_1710": 0, "camel_453": 0, "camel_421": 0, "camel_474": 0, "camel_440": 0, "camel_456": 0, "camel_471": 0, "camel_1756": 0, "camel_464": 0, "math_train_algebra_47": 0, "camel_1723": 0, "camel_154": 0, "camel_454": 0, "camel_458": 0, "camel_420": 0, "camel_479": 0, "camel_156": 0, "camel_96": 0, "camel_461": 0, "camel_434": 0, "camel_1708": 0, "camel_1705": 0, "camel_408": 0, "camel_444": 0, "camel_430": 0, "camel_1747": 0, "camel_1755": 0, "camel_1693": 0, "camel_128": 0, "camel_1702": 0, "camel_401": 0, "camel_1686": 0, "camel_1746": 0, "camel_90": 0, "camel_1701": 0, "camel_141": 0, "camel_1725": 0, "camel_1733": 0, "camel_1690": 0, "camel_1743": 0, "camel_123": 0, "camel_80": 0, "camel_1707": 0, "camel_1714": 0, "camel_438": 0, "camel_443": 0, "camel_424": 0, "camel_435": 0, "camel_1711": 0, "camel_1715": 0, "camel_1744": 0, "camel_153": 0, "camel_436": 0, "camel_1704": 0, "camel_1741": 0, "camel_425": 0, "camel_1742": 0, "camel_403": 0, "camel_422": 0, "camel_95": 0, "camel_473": 0, "camel_452": 0, "camel_409": 0, "camel_1748": 0, "camel_465": 0, "math_test_algebra_704": 0, "camel_1712": 0, "camel_1695": 0, "camel_116": 0, "camel_467": 0, "camel_400": 0, "camel_1729": 0, "camel_449": 0, "camel_459": 0, "camel_1738": 0, "camel_99": 0, "camel_410": 0, "camel_135": 0, "camel_97": 0, "camel_437": 0, "camel_1691": 0, "camel_426": 0, "camel_1565": 0, "camel_469": 0, "camel_1751": 0, "camel_1757": 0, "camel_476": 0, "camel_159": 0, "camel_472": 0, "camel_1759": 0, "camel_478": 0, "camel_81": 0, "camel_457": 0, "camel_1706": 0, "camel_1713": 0, "camel_1732": 0, "camel_1727": 0, "camel_1745": 0, "camel_1717": 0, "camel_7765": 0.8250114321708679, "aqua_rat_32266": 0.8250919580459595, "camel_7774": 0.8251216411590576, "aqua_rat_12386": 0.8252219557762146, "camel_48120": 0.8260713219642639, "aqua_rat_23444": 0.8262940049171448, "aqua_rat_38583": 0.8264033794403076, "camel_6976": 0.8267691135406494, "aqua_rat_25092": 0.8269726634025574, "camel_39355": 0.8270119428634644, "aqua_rat_85635": 0.8273134231567383, "aqua_rat_50664": 0.8274036645889282, "aqua_rat_75993": 0.8276898264884949, "aqua_rat_2412": 0.827712893486023, "aqua_rat_33381": 0.8280990123748779, "aqua_rat_62627": 0.828432559967041, "aqua_rat_17105": 0.8284344673156738, "camel_49277": 0.8286910653114319, "camel_48107": 0.8288682699203491, "aqua_rat_55053": 0.8288747072219849, "aqua_rat_78902": 0.8290097713470459, "aqua_rat_21720": 0.8290503621101379, "aqua_rat_21992": 0.8291413187980652, "aqua_rat_72719": 0.8296024799346924, "aqua_rat_27410": 0.8300516605377197, "aqua_rat_48672": 0.8300898671150208, "aqua_rat_53614": 0.8304182291030884, "aqua_rat_965": 0.830799400806427, "camel_49140": 0.8309713006019592, "aqua_rat_23958": 0.8312299847602844, "camel_48121": 0.8314148783683777, "aqua_rat_79646": 0.8317890167236328, "camel_38088": 0.83213210105896, "aqua_rat_84753": 0.8325833678245544, "aqua_rat_13013": 0.8327466249465942, "aqua_rat_2696": 0.8327818512916565, "aqua_rat_18768": 0.8331210017204285, "aqua_rat_30784": 0.8335220217704773, "aqua_rat_3790": 0.8337875604629517, "aqua_rat_18824": 0.8341270685195923, "camel_48255": 0.8365827798843384, "camel_48965": 0.8367253541946411, "aqua_rat_29813": 0.8371886014938354, "aqua_rat_10935": 0.8373347520828247, "aqua_rat_17489": 0.837407648563385, "aqua_rat_40536": 0.83775794506073, "aqua_rat_70225": 0.8380657434463501, "camel_49845": 0.8383837342262268, "camel_48000": 0.8384827971458435, "aqua_rat_55187": 0.8396103382110596, "camel_49225": 0.8398064374923706, "aqua_rat_5517": 0.8399654626846313, "aqua_rat_44312": 0.8403800129890442, "aqua_rat_32853": 0.8406439423561096, "aqua_rat_48553": 0.8410598635673523, "camel_48096": 0.8427270650863647, "aqua_rat_46083": 0.8429948091506958, "camel_48010": 0.8432110548019409, "camel_39343": 0.8436280488967896, "aqua_rat_6248": 0.843887448310852, "aqua_rat_57286": 0.8445262312889099, "camel_49242": 0.8446220755577087, "aqua_rat_66786": 0.844825267791748, "aqua_rat_11436": 0.8460342288017273, "aqua_rat_53929": 0.846621572971344, "aqua_rat_52932": 0.8468584418296814, "aqua_rat_4632": 0.8475735783576965, "camel_5016": 0.848673403263092, "aqua_rat_46099": 0.8505401015281677, "aqua_rat_62268": 0.8517465591430664, "aqua_rat_21304": 0.8520103693008423, "camel_48888": 0.8525607585906982, "camel_48078": 0.8535643219947815, "aqua_rat_16683": 0.853956401348114, "aqua_rat_84969": 0.8559437394142151, "aqua_rat_32416": 0.8564738035202026, "aqua_rat_36743": 0.8570799231529236, "aqua_rat_69050": 0.8580900430679321, "aqua_rat_51085": 0.8608086109161377, "camel_6576": 0.8623442649841309, "aqua_rat_863": 0.8630411028862, "aqua_rat_45553": 0.8633214235305786, "aqua_rat_76599": 0.8635305166244507, "aqua_rat_7450": 0.8641772270202637, "aqua_rat_20174": 0.8685437440872192, "aqua_rat_66174": 0.8690041899681091, "aqua_rat_75546": 0.8704015016555786, "aqua_rat_28168": 0.8722874522209167, "aqua_rat_5411": 0.8735559582710266}, "TheoremQA_xueguangma/future_value_2.json": {"aqua_rat_14463": 0.789088249206543, "aqua_rat_60181": 0.7891222238540649, "aqua_rat_45060": 0.7891969680786133, "aqua_rat_22060": 0.789265513420105, "aqua_rat_32958": 0.7893059849739075, "aqua_rat_9529": 0.7893949151039124, "math_train_algebra_2484": 0.7894763946533203, "aqua_rat_35907": 0.7895498871803284, "aqua_rat_14998": 0.7896099090576172, "gsm_rft_11620": 0.78963303565979, "aqua_rat_82565": 0.7896747589111328, "aqua_rat_6703": 0.7899664044380188, "aqua_rat_65985": 0.790101170539856, "aqua_rat_40411": 0.7901092171669006, "aqua_rat_16448": 0.79012531042099, "aqua_rat_67292": 0.7901498675346375, "aqua_rat_77744": 0.7903096675872803, "aqua_rat_13549": 0.7903180122375488, "gsm_train_25622": 0.7903453707695007, "aqua_rat_86432": 0.7903913855552673, "aqua_rat_46898": 0.790443480014801, "aqua_rat_5231": 0.790496289730072, "aqua_rat_24351": 0.7906015515327454, "aqua_rat_39322": 0.7907657027244568, "aqua_rat_42017": 0.7907922267913818, "aqua_rat_7357": 0.7908939719200134, "aqua_rat_87884": 0.790918231010437, "aqua_rat_37580": 0.7910232543945312, "gsm_rft_22915": 0.791160523891449, "aqua_rat_74003": 0.791179895401001, "aqua_rat_64976": 0.791182279586792, "math_train_algebra_2129": 0.7911885976791382, "aqua_rat_84549": 0.7912372946739197, "aqua_rat_38785": 0.7912872433662415, "aqua_rat_6657": 0.7913605570793152, "aqua_rat_76156": 0.7914584279060364, "aqua_rat_48358": 0.791703462600708, "math_train_algebra_940": 0.7917657494544983, "aqua_rat_85193": 0.7918049097061157, "aqua_rat_19480": 0.7918115854263306, "math_test_algebra_990": 0.7918644547462463, "aqua_rat_6909": 0.792517900466919, "aqua_rat_20903": 0.7925313115119934, "aqua_rat_11771": 0.7927166223526001, "aqua_rat_43046": 0.7927173972129822, "math_train_algebra_2324": 0.7928408980369568, "aqua_rat_49963": 0.7928955554962158, "aqua_rat_62727": 0.7929336428642273, "aqua_rat_64092": 0.7930065393447876, "aqua_rat_71142": 0.7932219505310059, "aqua_rat_63070": 0.7932446002960205, "aqua_rat_78349": 0.79324871301651, "aqua_rat_43060": 0.7933147549629211, "aqua_rat_46552": 0.7934555411338806, "aqua_rat_63322": 0.7936140298843384, "aqua_rat_255": 0.7937460541725159, "aqua_rat_26582": 0.7938198447227478, "aqua_rat_33430": 0.7940964102745056, "aqua_rat_32582": 0.7941925525665283, "aqua_rat_28520": 0.7942277193069458, "aqua_rat_25325": 0.7942723631858826, "aqua_rat_56852": 0.7942864894866943, "aqua_rat_53302": 0.7945009469985962, "aqua_rat_78319": 0.7945219874382019, "aqua_rat_21010": 0.7945423126220703, "aqua_rat_61585": 0.794588029384613, "gsm_rft_5946": 0.7946642637252808, "aqua_rat_53504": 0.7946783304214478, "aqua_rat_60321": 0.7946814894676208, "aqua_rat_49718": 0.7947111129760742, "aqua_rat_17803": 0.7947483062744141, "aqua_rat_82152": 0.7947942614555359, "aqua_rat_79979": 0.7950578927993774, "aqua_rat_39288": 0.7951100468635559, "aqua_rat_47882": 0.7951396107673645, "aqua_rat_67841": 0.7957447171211243, "aqua_rat_60598": 0.7958863377571106, "gsm_rft_14102": 0.7959888577461243, "gsm_train_11462": 0.7959888577461243, "aqua_rat_52978": 0.7961841225624084, "aqua_rat_88174": 0.7961951494216919, "aqua_rat_27505": 0.7962700724601746, "aqua_rat_75047": 0.7962900400161743, "aqua_rat_72687": 0.7965075969696045, "aqua_rat_27053": 0.7966074347496033, "aqua_rat_3536": 0.7971426248550415, "aqua_rat_16693": 0.7972441911697388, "aqua_rat_79855": 0.797315239906311, "aqua_rat_66927": 0.797360897064209, "aqua_rat_64664": 0.7973967790603638, "math_train_algebra_667": 0.7974438071250916, "aqua_rat_88960": 0.7974458336830139, "aqua_rat_26770": 0.797553539276123, "aqua_rat_1115": 0.797588586807251, "aqua_rat_26976": 0.7976204752922058, "gsm_train_5941": 0.7977959513664246, "gsm_rft_7180": 0.7977959513664246, "aqua_rat_9965": 0.7978941202163696, "aqua_rat_13396": 0.7979046106338501, "aqua_rat_65963": 0.7979481816291809, "aqua_rat_70690": 0.7980401515960693, "aqua_rat_58298": 0.798058271408081, "aqua_rat_68636": 0.7981792688369751, "aqua_rat_51796": 0.7982087731361389, "math_test_algebra_1862": 0.7985519766807556, "gsm_rft_5849": 0.7985882759094238, "aqua_rat_18368": 0.7986529469490051, "aqua_rat_6679": 0.798917829990387, "aqua_rat_64635": 0.7989557981491089, "aqua_rat_31960": 0.7989832758903503, "aqua_rat_2257": 0.7989903092384338, "aqua_rat_79904": 0.7992172837257385, "aqua_rat_53421": 0.7995891571044922, "aqua_rat_49908": 0.7997135519981384, "gsm_rft_12217": 0.7999081015586853, "gsm_rft_5669": 0.7999690771102905, "aqua_rat_87589": 0.8000091910362244, "aqua_rat_32864": 0.8001146912574768, "aqua_rat_84309": 0.8003925085067749, "aqua_rat_32852": 0.8006686568260193, "aqua_rat_46888": 0.8008905649185181, "aqua_rat_56718": 0.8010578155517578, "aqua_rat_51100": 0.8012567162513733, "aqua_rat_30386": 0.8014571666717529, "aqua_rat_47773": 0.8014996647834778, "aqua_rat_27162": 0.8016692399978638, "aqua_rat_88746": 0.801772952079773, "aqua_rat_72794": 0.8019191026687622, "aqua_rat_87246": 0.8022212386131287, "aqua_rat_75737": 0.8023179173469543, "aqua_rat_61190": 0.8026611804962158, "aqua_rat_76956": 0.8026899695396423, "aqua_rat_48494": 0.8030527234077454, "aqua_rat_83234": 0.8032702207565308, "aqua_rat_72933": 0.8033896684646606, "aqua_rat_69526": 0.8034025430679321, "gsm_rft_25658": 0.8034173846244812, "aqua_rat_30717": 0.8034473061561584, "aqua_rat_26339": 0.8034541606903076, "aqua_rat_66298": 0.8034553527832031, "aqua_rat_10582": 0.8037765026092529, "aqua_rat_10990": 0.8037977814674377, "aqua_rat_39049": 0.8039343953132629, "aqua_rat_10904": 0.8040304780006409, "aqua_rat_48535": 0.804192841053009, "aqua_rat_50383": 0.8042793869972229, "aqua_rat_61757": 0.8044949769973755, "aqua_rat_59668": 0.8047765493392944, "aqua_rat_24646": 0.8048567771911621, "aqua_rat_59829": 0.8050232529640198, "aqua_rat_37382": 0.8051378726959229, "aqua_rat_21866": 0.8053061962127686, "aqua_rat_59299": 0.8055332899093628, "aqua_rat_75833": 0.8055989146232605, "aqua_rat_25162": 0.8057007789611816, "math_train_algebra_707": 0.8058362603187561, "aqua_rat_33923": 0.8058754205703735, "gsm_rft_17331": 0.8059847354888916, "aqua_rat_29976": 0.8069050312042236, "aqua_rat_37258": 0.8070681691169739, "math_test_algebra_608": 0.8071120977401733, "aqua_rat_869": 0.8071537613868713, "aqua_rat_735": 0.8073828220367432, "aqua_rat_78121": 0.8075210452079773, "aqua_rat_44615": 0.807695746421814, "gsm_rft_24617": 0.8080958724021912, "math_train_algebra_1277": 0.8081122040748596, "aqua_rat_83740": 0.8084986209869385, "aqua_rat_73739": 0.8089495301246643, "aqua_rat_86835": 0.8103496432304382, "aqua_rat_28282": 0.8106217980384827, "aqua_rat_12597": 0.8107811808586121, "math_test_algebra_1611": 0.8113861680030823, "aqua_rat_21814": 0.8133764863014221, "aqua_rat_70031": 0.8137140274047852, "aqua_rat_29356": 0.8142078518867493, "aqua_rat_68014": 0.8146255016326904, "aqua_rat_34332": 0.81498783826828, "aqua_rat_28662": 0.8160040974617004, "math_train_algebra_957": 0.8162618279457092, "aqua_rat_20423": 0.8167034983634949, "aqua_rat_67698": 0.8173254728317261, "aqua_rat_59403": 0.8192774653434753, "aqua_rat_66371": 0.8199844360351562, "aqua_rat_50447": 0.8201385736465454, "aqua_rat_71239": 0.8205123543739319, "aqua_rat_44549": 0.8212860822677612, "aqua_rat_73390": 0.821367084980011, "aqua_rat_33006": 0.8214754462242126, "aqua_rat_7537": 0.8215018510818481, "aqua_rat_15337": 0.8227052688598633, "aqua_rat_58694": 0.8228513598442078, "aqua_rat_86234": 0.8235780596733093, "gsm_train_26849": 0.8258123993873596, "gsm_rft_19092": 0.8258123993873596, "aqua_rat_29321": 0.8261663317680359, "gsm_rft_28176": 0.827542245388031, "gsm_rft_9932": 0.830360472202301, "math_train_algebra_369": 0.8355953693389893, "math_test_algebra_594": 0.8435300588607788}, "TheoremQA_wenhuchen/optics2.json": {"TheoremQA_wenhuchen/optics2.json": 0, "aqua_rat_40416": 0.7296631336212158, "camel_4792": 0.7298197746276855, "gsm_rft_20498": 0.7298266291618347, "camel_5521": 0.7298499941825867, "camel_4952": 0.7299615144729614, "aqua_rat_31980": 0.7302855253219604, "camel_4824": 0.7303532958030701, "camel_5027": 0.7304184436798096, "math_train_geometry_649": 0.7307252287864685, "gsm_rft_20209": 0.7308537364006042, "gsm_rft_3001": 0.7308537364006042, "gsm_train_22328": 0.7308537364006042, "camel_4828": 0.7310154438018799, "camel_5549": 0.7314332127571106, "camel_4992": 0.7314473390579224, "camel_4743": 0.731467604637146, "camel_4739": 0.7314730286598206, "aqua_rat_46971": 0.7315604090690613, "camel_4155": 0.7315783500671387, "camel_4736": 0.7317039966583252, "camel_4796": 0.7317284941673279, "aqua_rat_9142": 0.7317363023757935, "camel_4911": 0.7317801713943481, "camel_4840": 0.731813371181488, "camel_4726": 0.7320196628570557, "camel_4800": 0.7321696281433105, "camel_5584": 0.7323300838470459, "camel_4735": 0.7323591113090515, "camel_4923": 0.7323883771896362, "camel_4895": 0.7327637672424316, "camel_5538": 0.7328670024871826, "camel_5599": 0.7328715324401855, "camel_5586": 0.7329638600349426, "camel_5562": 0.7330020070075989, "camel_4946": 0.7330312132835388, "aqua_rat_40593": 0.7331110835075378, "gsm_rft_26992": 0.7331333160400391, "camel_4929": 0.7333446145057678, "camel_4871": 0.7334462404251099, "camel_4727": 0.7334994077682495, "aqua_rat_49952": 0.733570396900177, "camel_5576": 0.7335971593856812, "camel_6844": 0.7336154580116272, "camel_5540": 0.7336419224739075, "aqua_rat_83787": 0.7340943217277527, "aqua_rat_36912": 0.7345805764198303, "camel_4854": 0.7346025705337524, "camel_4825": 0.7346125841140747, "camel_4806": 0.7347890138626099, "camel_4811": 0.735066294670105, "aqua_rat_10339": 0.7350802421569824, "camel_5561": 0.7351423501968384, "camel_4819": 0.735197126865387, "camel_4869": 0.7352184653282166, "camel_4860": 0.735278844833374, "aqua_rat_66081": 0.7353982329368591, "aqua_rat_21504": 0.7354413270950317, "aqua_rat_20932": 0.7354524731636047, "camel_4797": 0.735759973526001, "camel_4953": 0.7359689474105835, "camel_5544": 0.7361181378364563, "camel_4884": 0.7363349199295044, "camel_4868": 0.7363691926002502, "camel_4906": 0.736400842666626, "aqua_rat_1600": 0.7366033792495728, "camel_4897": 0.7367005348205566, "aqua_rat_22739": 0.7368868589401245, "aqua_rat_31294": 0.7370238900184631, "gsm_rft_11389": 0.7373321652412415, "camel_4899": 0.7374628782272339, "camel_5012": 0.7374740839004517, "aqua_rat_72372": 0.7381623387336731, "aqua_rat_54985": 0.7383084893226624, "camel_4959": 0.7383578419685364, "aqua_rat_51750": 0.7384668588638306, "aqua_rat_43435": 0.7385134100914001, "camel_4803": 0.7386592030525208, "math_test_prealgebra_1108": 0.7391518950462341, "camel_4962": 0.7392041683197021, "camel_4740": 0.7392050623893738, "camel_4961": 0.7396230697631836, "camel_4755": 0.7397559881210327, "aqua_rat_44239": 0.7397997379302979, "aqua_rat_23369": 0.7399576306343079, "aqua_rat_81174": 0.7400442957878113, "aqua_rat_70142": 0.7400645017623901, "camel_4728": 0.740303099155426, "camel_4988": 0.7403063178062439, "aqua_rat_12010": 0.7403557300567627, "camel_5581": 0.7405088543891907, "aqua_rat_55752": 0.7407481074333191, "camel_4908": 0.7408838272094727, "camel_4794": 0.7408967614173889, "camel_4804": 0.7410430908203125, "aqua_rat_75200": 0.7411717176437378, "camel_4832": 0.741260826587677, "camel_4841": 0.7415921092033386, "camel_5105": 0.7420077323913574, "aqua_rat_71816": 0.7420200705528259, "camel_4888": 0.7420318126678467, "camel_4873": 0.7426226735115051, "camel_4767": 0.74263995885849, "camel_4955": 0.7427842617034912, "camel_4991": 0.7428715825080872, "aqua_rat_75450": 0.7428827881813049, "aqua_rat_85100": 0.7430590987205505, "aqua_rat_51744": 0.7430591583251953, "gsm_train_22045": 0.7430895566940308, "gsm_rft_5305": 0.7430895566940308, "aqua_rat_61332": 0.7431759238243103, "camel_4894": 0.7440248727798462, "camel_5000": 0.7443553805351257, "camel_4801": 0.7444595098495483, "camel_4844": 0.7444887161254883, "aqua_rat_80763": 0.7450414299964905, "camel_4845": 0.7451016306877136, "camel_4924": 0.7456070780754089, "camel_4891": 0.7456240057945251, "camel_4773": 0.7458895444869995, "camel_4867": 0.7459092140197754, "camel_4859": 0.7460389733314514, "math_test_prealgebra_583": 0.746482789516449, "camel_49646": 0.7473893761634827, "camel_4746": 0.7474960088729858, "camel_5032": 0.7479408383369446, "camel_4798": 0.7481546401977539, "camel_4932": 0.7483153343200684, "camel_4807": 0.7496386170387268, "camel_4760": 0.7496925592422485, "camel_4935": 0.7499926090240479, "camel_4837": 0.7502337694168091, "camel_4916": 0.7502506971359253, "camel_5287": 0.7503073811531067, "camel_4802": 0.7504101991653442, "camel_4780": 0.7504171133041382, "camel_5033": 0.7506429553031921, "camel_4106": 0.7514168620109558, "camel_4552": 0.7515033483505249, "camel_4721": 0.7515915632247925, "camel_4848": 0.7522199749946594, "camel_4724": 0.7523654699325562, "camel_4913": 0.7537946105003357, "camel_4920": 0.7539684772491455, "camel_5583": 0.7544243931770325, "camel_4857": 0.754738986492157, "camel_4866": 0.7548000812530518, "TheoremQA_wenhuchen/optics7.json": 0.7548186182975769, "camel_6840": 0.7548710107803345, "math_test_prealgebra_1904": 0.7550742626190186, "math_test_geometry_151": 0.7554879784584045, "camel_4781": 0.7565179467201233, "camel_5543": 0.7570571303367615, "camel_4893": 0.7576581835746765, "camel_4820": 0.7577370405197144, "camel_4846": 0.7589075565338135, "aqua_rat_33167": 0.7600581049919128, "camel_4813": 0.7605054974555969, "camel_4865": 0.7610819339752197, "camel_4827": 0.7617123126983643, "camel_4981": 0.7617658376693726, "camel_4853": 0.762902021408081, "aqua_rat_30186": 0.7629637122154236, "camel_4816": 0.7631065845489502, "camel_5563": 0.7631872892379761, "aqua_rat_63015": 0.7642496228218079, "camel_4831": 0.7645174264907837, "aqua_rat_32781": 0.764840304851532, "camel_4904": 0.7663663029670715, "camel_4874": 0.7670480012893677, "math_test_algebra_2160": 0.767507016658783, "camel_5587": 0.7698010206222534, "aqua_rat_30115": 0.7710102796554565, "aqua_rat_14967": 0.7711973190307617, "camel_5017": 0.77182537317276, "aqua_rat_2228": 0.7720368504524231, "aqua_rat_18718": 0.7725279331207275, "aqua_rat_60805": 0.7730413675308228, "math_train_prealgebra_1701": 0.7745892405509949, "aqua_rat_69962": 0.7754824757575989, "aqua_rat_86356": 0.7757028341293335, "camel_4980": 0.7757593989372253, "aqua_rat_18543": 0.7764679789543152, "aqua_rat_22618": 0.7784407734870911, "camel_4983": 0.7789112329483032, "aqua_rat_12240": 0.7789790630340576, "aqua_rat_83857": 0.7792749404907227, "camel_4737": 0.7812312245368958, "aqua_rat_25937": 0.7822431325912476, "aqua_rat_14896": 0.7855082154273987, "camel_5527": 0.7856526374816895, "aqua_rat_37605": 0.7875970602035522, "gsm_rft_7733": 0.7880866527557373, "aqua_rat_55057": 0.7881086468696594, "gsm_train_19077": 0.7885326743125916, "gsm_rft_17748": 0.7885326743125916, "aqua_rat_35477": 0.7888315916061401, "camel_4771": 0.7998258471488953, "aqua_rat_8530": 0.8043864965438843, "camel_4808": 0.8120870590209961}, "TheoremQA_wenhuchen/L'H\u00f4pital_rule1.json": {"camel_6107": 0, "camel_7021": 0, "camel_7755": 0, "TheoremQA_wenhuchen/L'H\u00f4pital_rule1.json": 0, "camel_6182": 0, "camel_6171": 0, "camel_6088": 0, "camel_16283": 0.7343462705612183, "camel_5333": 0.7343869209289551, "camel_19558": 0.7344241738319397, "camel_45818": 0.7344495058059692, "camel_45681": 0.7346392869949341, "camel_40945": 0.734663724899292, "camel_42261": 0.7346726059913635, "camel_45179": 0.7348002791404724, "camel_41216": 0.7348659038543701, "camel_5051": 0.7349047064781189, "camel_16623": 0.7349061965942383, "aqua_rat_26174": 0.7349119186401367, "camel_16164": 0.7349696755409241, "camel_29240": 0.7350020408630371, "camel_39321": 0.7350386381149292, "camel_45505": 0.735065221786499, "camel_45159": 0.7350685596466064, "camel_45449": 0.7351117134094238, "camel_42879": 0.7351344227790833, "camel_39486": 0.7351822853088379, "camel_44839": 0.7352125644683838, "camel_42301": 0.7352554202079773, "camel_29712": 0.7353147864341736, "camel_5103": 0.7353192567825317, "camel_5098": 0.7354453802108765, "camel_40781": 0.7354608178138733, "camel_42246": 0.7355519533157349, "camel_29046": 0.7355753183364868, "camel_29968": 0.7357336282730103, "camel_29732": 0.7357910871505737, "camel_42269": 0.7360953092575073, "camel_39254": 0.7360993027687073, "camel_16586": 0.736250638961792, "camel_39298": 0.7362961769104004, "camel_16249": 0.7364343404769897, "camel_16577": 0.7364473342895508, "camel_45146": 0.7365376949310303, "camel_36444": 0.7365497946739197, "camel_39327": 0.7366015315055847, "camel_39579": 0.7367080450057983, "camel_29753": 0.7368098497390747, "camel_5008": 0.7368770241737366, "camel_29437": 0.7369102835655212, "camel_29365": 0.7370387315750122, "camel_42591": 0.737050473690033, "camel_29373": 0.7371063232421875, "camel_42834": 0.7371662259101868, "camel_45494": 0.7372393012046814, "camel_28140": 0.7373147010803223, "camel_49051": 0.7374258041381836, "camel_5153": 0.7376147508621216, "camel_29995": 0.7377413511276245, "camel_45171": 0.7379429340362549, "camel_39134": 0.7379680275917053, "camel_29970": 0.7380080223083496, "camel_45191": 0.7381207346916199, "camel_29501": 0.7382173538208008, "camel_41997": 0.7383248209953308, "camel_39338": 0.7383478879928589, "camel_5080": 0.7385691404342651, "camel_29975": 0.7386898398399353, "camel_29638": 0.738736093044281, "camel_29379": 0.7388110756874084, "camel_17435": 0.7389402985572815, "camel_29417": 0.7392253875732422, "camel_29460": 0.7393620610237122, "camel_29992": 0.7394976019859314, "camel_44491": 0.7395889759063721, "camel_29973": 0.7396637201309204, "camel_42277": 0.7398353815078735, "camel_42313": 0.7398759722709656, "camel_45299": 0.7400212287902832, "camel_39125": 0.740025520324707, "camel_44347": 0.740083634853363, "camel_42844": 0.7402235269546509, "camel_31056": 0.7402961254119873, "camel_16598": 0.7403636574745178, "camel_45988": 0.7404009103775024, "camel_29959": 0.740409791469574, "camel_28137": 0.7405004501342773, "camel_16636": 0.7405422329902649, "camel_29383": 0.740593671798706, "camel_29378": 0.7406877875328064, "camel_45182": 0.7410509586334229, "camel_29735": 0.7411122918128967, "camel_45492": 0.7411346435546875, "aqua_rat_850": 0.7411882877349854, "camel_30319": 0.7412760853767395, "camel_29427": 0.7414727807044983, "camel_16626": 0.7414888739585876, "camel_45129": 0.7418472766876221, "camel_28666": 0.7419148683547974, "camel_45310": 0.7419757843017578, "camel_45518": 0.742019534111023, "camel_29998": 0.7422088980674744, "camel_29374": 0.7426309585571289, "camel_18917": 0.7427659630775452, "camel_29971": 0.7428256869316101, "camel_45447": 0.7428719997406006, "camel_40761": 0.7431626319885254, "camel_45314": 0.743342399597168, "camel_31206": 0.7435057163238525, "camel_16241": 0.7435417175292969, "camel_44694": 0.7437605261802673, "camel_29965": 0.7439055442810059, "camel_29983": 0.7441511750221252, "camel_45174": 0.7442473769187927, "camel_16616": 0.7442696690559387, "TheoremQA_elainewan/math_calculus_2_11.json": 0.7443893551826477, "camel_30889": 0.7444013357162476, "camel_29371": 0.7444058656692505, "camel_29986": 0.7444061636924744, "camel_29415": 0.7444528341293335, "aqua_rat_50085": 0.7444884777069092, "camel_29429": 0.7445864081382751, "camel_45120": 0.7446562051773071, "camel_29972": 0.7451118230819702, "camel_45156": 0.7451705932617188, "camel_16615": 0.7453600764274597, "camel_29426": 0.7454129457473755, "camel_28145": 0.7458887696266174, "camel_45312": 0.7460165023803711, "camel_45745": 0.7461144924163818, "camel_42315": 0.7464365363121033, "camel_29957": 0.7468189001083374, "camel_16256": 0.747715413570404, "camel_29360": 0.7477386593818665, "camel_29060": 0.7477577924728394, "camel_29922": 0.7480376958847046, "camel_29927": 0.7481439113616943, "camel_29364": 0.7481781840324402, "camel_17361": 0.7487103343009949, "camel_28147": 0.7487679123878479, "camel_29420": 0.7489191889762878, "camel_18951": 0.7494158148765564, "camel_29925": 0.7494229078292847, "camel_45969": 0.7495933175086975, "camel_42282": 0.7497310042381287, "camel_45293": 0.7498440742492676, "camel_45444": 0.7502668499946594, "aqua_rat_24364": 0.7504704594612122, "camel_45323": 0.7507752776145935, "camel_29955": 0.7513396143913269, "camel_29948": 0.7518324255943298, "camel_16588": 0.7518468499183655, "camel_29985": 0.7524964213371277, "camel_29198": 0.7530103325843811, "camel_29388": 0.7531737685203552, "camel_29438": 0.7541419267654419, "camel_29984": 0.7546833753585815, "camel_29403": 0.754813551902771, "camel_45142": 0.7550299763679504, "camel_29434": 0.7552171945571899, "camel_29422": 0.7554240822792053, "camel_29941": 0.755522608757019, "camel_36477": 0.7557393908500671, "camel_45169": 0.7558062672615051, "camel_29976": 0.7567911744117737, "camel_29398": 0.7568451166152954, "camel_28532": 0.7569894194602966, "camel_45196": 0.7580209970474243, "camel_16581": 0.7582224607467651, "camel_45949": 0.7601021528244019, "camel_29419": 0.7609456181526184, "camel_29936": 0.7610215544700623, "camel_28793": 0.762050986289978, "camel_29960": 0.7624564170837402, "camel_45170": 0.7633703351020813, "camel_29385": 0.7637285590171814, "camel_29977": 0.764001190662384, "camel_28080": 0.7645993828773499, "camel_45199": 0.7646185159683228, "camel_29389": 0.7658581137657166, "camel_29406": 0.7663491368293762, "camel_29416": 0.7669677734375, "camel_29860": 0.7671339511871338, "camel_29999": 0.7681039571762085, "camel_17390": 0.7690349221229553, "camel_29363": 0.7694177031517029, "camel_29950": 0.7697798013687134, "camel_45342": 0.7703572511672974, "camel_29969": 0.7706274390220642, "aqua_rat_49646": 0.7725778818130493, "camel_29435": 0.7726137638092041, "camel_28086": 0.7733675241470337, "camel_29381": 0.7741831541061401, "camel_29946": 0.7751436233520508, "camel_18301": 0.775231122970581, "aqua_rat_11117": 0.7757259011268616, "camel_29989": 0.777162492275238, "camel_29964": 0.7824472784996033, "camel_29943": 0.7831330299377441, "TheoremQA_elainewan/math_calculus_2_10.json": 0.793518602848053}, "TheoremQA_elainewan/math_calculus_2_11.json": {"camel_7688": 0, "camel_6449": 0, "camel_7020": 0, "camel_6978": 0, "camel_7025": 0, "camel_6463": 0, "camel_7036": 0, "camel_7029": 0, "camel_7714": 0, "camel_7720": 0, "camel_7028": 0, "camel_7013": 0, "camel_6974": 0, "camel_6986": 0, "camel_6218": 0, "camel_7003": 0, "camel_7016": 0, "camel_6962": 0, "camel_7024": 0, "camel_7272": 0, "camel_6971": 0, "camel_6967": 0, "camel_6985": 0, "camel_6988": 0, "camel_7008": 0, "camel_6987": 0, "camel_6979": 0, "camel_7032": 0, "camel_7755": 0, "camel_7019": 0, "camel_7031": 0, "camel_7021": 0, "camel_6961": 0, "camel_7686": 0, "camel_7033": 0, "camel_6415": 0, "TheoremQA_elainewan/math_calculus_2_11.json": 0, "camel_7005": 0, "camel_6309": 0, "camel_6964": 0, "camel_7011": 0, "camel_7012": 0, "camel_6166": 0, "camel_6165": 0, "camel_7035": 0, "camel_6990": 0, "camel_7731": 0, "camel_7030": 0, "camel_7007": 0, "camel_7695": 0, "camel_6966": 0, "camel_1746": 0.7574946880340576, "camel_5077": 0.7575839161872864, "camel_41954": 0.757646918296814, "camel_38932": 0.7577053904533386, "camel_39298": 0.7577939629554749, "aqua_rat_22581": 0.7578193545341492, "aqua_rat_7719": 0.757955014705658, "camel_38953": 0.7583419680595398, "camel_39310": 0.7583789825439453, "camel_39251": 0.7584865093231201, "camel_38958": 0.7585332989692688, "camel_39457": 0.7585726380348206, "camel_38941": 0.7587230205535889, "camel_38295": 0.7587314248085022, "camel_4256": 0.7587892413139343, "camel_38169": 0.7588531970977783, "aqua_rat_72162": 0.7589907646179199, "aqua_rat_66420": 0.7590212225914001, "camel_37999": 0.7592260837554932, "aqua_rat_48488": 0.7592847347259521, "camel_39218": 0.7593302726745605, "camel_38121": 0.7595821619033813, "camel_41093": 0.7596607804298401, "camel_39197": 0.7598770260810852, "camel_40945": 0.7599622011184692, "math_train_algebra_790": 0.7599682807922363, "camel_39124": 0.7601296901702881, "aqua_rat_24172": 0.7604169845581055, "camel_41170": 0.7604290246963501, "camel_1702": 0.760486364364624, "camel_476": 0.7605283856391907, "camel_38809": 0.7605965733528137, "camel_39358": 0.7606063485145569, "camel_41882": 0.760637640953064, "aqua_rat_59049": 0.7608274817466736, "camel_39355": 0.7608820796012878, "camel_40907": 0.7609313726425171, "camel_1796": 0.7610014081001282, "aqua_rat_13944": 0.7612521052360535, "aqua_rat_25092": 0.7613595128059387, "camel_39189": 0.7613797187805176, "camel_39359": 0.7614791393280029, "camel_39297": 0.7614876627922058, "camel_5065": 0.7615461945533752, "camel_5090": 0.7617411017417908, "camel_18928": 0.7618750929832458, "camel_39301": 0.7619664072990417, "camel_4968": 0.7619720101356506, "camel_40760": 0.7621480226516724, "camel_39098": 0.7621904611587524, "aqua_rat_67334": 0.762397289276123, "aqua_rat_20671": 0.7624111771583557, "camel_39067": 0.7624545097351074, "camel_4960": 0.762505292892456, "camel_5080": 0.7625194191932678, "camel_41216": 0.7629181146621704, "aqua_rat_76642": 0.762972891330719, "camel_5084": 0.7631140351295471, "camel_40734": 0.7631559371948242, "camel_39058": 0.7632743120193481, "camel_29860": 0.7634772062301636, "camel_39070": 0.7635332345962524, "aqua_rat_8453": 0.7636358141899109, "aqua_rat_2082": 0.7636827826499939, "camel_39055": 0.7638248801231384, "aqua_rat_64463": 0.7642738819122314, "camel_38950": 0.765022337436676, "camel_39248": 0.7650895118713379, "camel_5083": 0.7651150822639465, "camel_38182": 0.7652298212051392, "aqua_rat_41872": 0.7652575969696045, "camel_39590": 0.7652761340141296, "camel_41705": 0.7652993202209473, "camel_39323": 0.7653141617774963, "aqua_rat_5599": 0.7653588652610779, "camel_39106": 0.7653658390045166, "camel_4986": 0.7654263377189636, "camel_1748": 0.7654460668563843, "camel_41898": 0.7657839059829712, "camel_39343": 0.7660291790962219, "camel_39072": 0.766172468662262, "camel_5008": 0.7662324905395508, "camel_39050": 0.7663432955741882, "camel_39448": 0.7663687467575073, "aqua_rat_51356": 0.7664616107940674, "aqua_rat_87932": 0.766588568687439, "camel_39152": 0.7667977213859558, "aqua_rat_61677": 0.7669740915298462, "aqua_rat_13843": 0.7669985294342041, "camel_5006": 0.7672982215881348, "aqua_rat_53738": 0.7672983407974243, "aqua_rat_41331": 0.7674937844276428, "camel_5111": 0.7675111293792725, "aqua_rat_16683": 0.7676471471786499, "camel_39140": 0.7677018046379089, "camel_4996": 0.7679509520530701, "aqua_rat_49043": 0.7679736614227295, "aqua_rat_12233": 0.7679812908172607, "aqua_rat_9202": 0.7681653499603271, "camel_39598": 0.768246591091156, "camel_39486": 0.7683659195899963, "camel_38880": 0.7688661217689514, "aqua_rat_11769": 0.7689451575279236, "aqua_rat_84753": 0.7690820693969727, "camel_39579": 0.7691051363945007, "aqua_rat_19118": 0.7693197131156921, "camel_39466": 0.7698650360107422, "camel_1733": 0.7699390649795532, "aqua_rat_42657": 0.7705574631690979, "camel_39314": 0.7708561420440674, "camel_1708": 0.771133303642273, "camel_38109": 0.771304726600647, "camel_41821": 0.7713126540184021, "camel_41935": 0.7713210582733154, "aqua_rat_18768": 0.7716985940933228, "camel_40781": 0.7719008326530457, "camel_48965": 0.7721498012542725, "camel_39188": 0.7722495794296265, "camel_1528": 0.7723692655563354, "camel_39321": 0.7723861932754517, "aqua_rat_965": 0.7727418541908264, "camel_38892": 0.7732036709785461, "aqua_rat_22890": 0.7738169431686401, "aqua_rat_71292": 0.7740684151649475, "camel_29198": 0.7742285132408142, "camel_41967": 0.7748478055000305, "camel_39104": 0.7754361033439636, "aqua_rat_18406": 0.7755306363105774, "aqua_rat_42779": 0.7757467031478882, "aqua_rat_38830": 0.7758216857910156, "camel_41712": 0.7759748697280884, "camel_1744": 0.7763633131980896, "camel_39125": 0.7776490449905396, "aqua_rat_77759": 0.7780988812446594, "aqua_rat_40536": 0.7784228920936584, "camel_45969": 0.779013454914093, "aqua_rat_29538": 0.7801980972290039, "camel_41853": 0.7814953923225403, "camel_39085": 0.7830045819282532, "camel_5051": 0.7835469841957092, "camel_39108": 0.784084141254425, "aqua_rat_80489": 0.7841716408729553, "camel_28147": 0.7862724661827087, "camel_38938": 0.7874823808670044, "aqua_rat_49646": 0.788074254989624, "camel_28086": 0.788199782371521, "camel_39357": 0.7885966300964355, "camel_5066": 0.7903013825416565, "camel_41997": 0.7920084595680237}, "TheoremQA_elainewan/math_algebra_4.json": {"camel_15850": 0, "camel_15637": 0, "camel_14171": 0, "camel_15651": 0, "camel_14164": 0, "camel_14190": 0, "camel_15613": 0, "camel_15610": 0, "camel_14258": 0, "camel_15943": 0, "camel_15321": 0, "camel_14214": 0, "camel_14201": 0, "camel_14267": 0, "camel_15621": 0, "camel_15620": 0, "camel_15530": 0, "camel_15901": 0, "camel_15682": 0, "camel_15654": 0, "camel_15705": 0, "camel_14070": 0, "camel_15431": 0, "camel_15846": 0, "camel_15971": 0, "camel_15615": 0, "camel_15661": 0, "camel_15982": 0, "camel_15601": 0, "camel_14173": 0, "camel_14213": 0, "camel_14161": 0, "camel_15641": 0, "camel_15751": 0, "camel_14209": 0, "camel_15680": 0, "camel_15329": 0, "camel_14163": 0, "camel_14212": 0, "camel_15755": 0, "camel_15747": 0, "camel_14318": 0, "camel_15659": 0, "camel_15752": 0, "camel_15307": 0, "camel_14234": 0, "camel_14275": 0, "camel_14268": 0, "camel_15665": 0, "camel_15728": 0, "camel_14020": 0, "camel_15638": 0, "camel_15308": 0, "camel_14000": 0, "camel_15635": 0, "camel_15721": 0, "camel_14884": 0, "camel_14189": 0, "camel_15957": 0, "camel_15960": 0, "camel_14221": 0, "camel_14238": 0, "camel_14180": 0, "camel_14172": 0, "camel_14167": 0, "camel_14208": 0, "camel_14216": 0, "camel_15696": 0, "camel_14165": 0, "camel_15669": 0, "camel_15676": 0, "camel_15981": 0, "camel_14206": 0, "camel_15630": 0, "camel_14229": 0, "camel_15655": 0, "camel_14191": 0, "camel_15928": 0, "camel_15602": 0, "camel_15749": 0, "camel_14219": 0, "camel_15759": 0, "camel_15995": 0, "camel_15648": 0, "camel_15627": 0, "camel_15622": 0, "camel_14215": 0, "camel_15849": 0, "camel_14183": 0, "camel_15644": 0, "camel_15647": 0, "camel_15636": 0, "camel_14176": 0, "camel_14188": 0, "camel_15757": 0, "camel_14199": 0, "camel_14261": 0, "camel_15624": 0, "camel_15727": 0, "camel_14079": 0, "camel_14160": 0, "camel_15717": 0, "camel_14220": 0, "camel_15689": 0, "camel_14210": 0, "camel_14198": 0, "camel_15663": 0, "camel_14250": 0, "TheoremQA_elainewan/math_algebra_4.json": 0, "camel_15633": 0, "camel_15628": 0, "camel_15745": 0, "camel_14227": 0, "camel_15639": 0, "camel_15679": 0, "camel_15687": 0, "camel_15631": 0, "camel_15691": 0, "camel_15604": 0, "camel_15657": 0, "camel_14193": 0, "camel_14239": 0, "camel_14197": 0, "camel_14222": 0, "camel_15656": 0, "camel_14207": 0, "camel_14194": 0, "camel_15675": 0, "camel_14192": 0, "camel_14162": 0, "camel_15720": 0, "camel_15875": 0, "camel_14307": 0, "camel_15666": 0, "camel_14202": 0, "camel_14205": 0, "camel_15625": 0, "camel_15707": 0, "camel_14184": 0, "camel_14174": 0, "camel_15886": 0, "camel_14223": 0, "camel_14218": 0, "camel_14179": 0, "camel_14232": 0, "camel_15619": 0, "camel_15603": 0, "camel_14169": 0, "camel_14178": 0, "camel_14170": 0, "camel_14182": 0, "camel_15653": 0, "camel_14236": 0, "camel_14196": 0, "camel_14166": 0, "camel_15646": 0, "camel_14181": 0, "camel_14211": 0, "camel_14231": 0, "camel_14225": 0, "camel_14235": 0, "camel_14195": 0, "camel_14186": 0, "camel_14233": 0, "camel_14228": 0, "camel_14204": 0, "camel_14168": 0, "camel_15642": 0, "camel_14187": 0, "camel_14175": 0, "camel_14230": 0, "camel_14237": 0, "camel_14217": 0, "camel_14224": 0, "camel_14200": 0, "camel_14203": 0, "camel_21318": 0.7309973835945129, "camel_21310": 0.7311972379684448, "camel_21298": 0.7314558625221252, "camel_21306": 0.7314876914024353, "camel_21294": 0.7317391037940979, "camel_21284": 0.7319628000259399, "camel_49900": 0.7320845723152161, "camel_40031": 0.7323020696640015, "camel_21327": 0.7323079109191895, "camel_21319": 0.7324367165565491, "camel_21334": 0.7324506640434265, "camel_21329": 0.7325147986412048, "camel_21340": 0.7325417995452881, "camel_21322": 0.7337589263916016, "camel_27506": 0.7348437905311584, "camel_21359": 0.7355524897575378, "camel_21295": 0.7372859716415405, "camel_49871": 0.737673282623291, "TheoremQA_mingyin/gaussian-elimination1.json": 0.7391403913497925, "camel_21325": 0.7478131651878357, "camel_21320": 0.7481306195259094, "TheoremQA_elainewan/math_algebra_2.json": 0.749078094959259, "camel_21347": 0.7549756169319153, "TheoremQA_elainewan/math_algebra_3_5.json": 0.7818939685821533}, "TheoremQA_wenhuchen/optics7.json": {"TheoremQA_wenhuchen/optics7.json": 0, "gsm_rft_28321": 0.707504153251648, "gsm_rft_15409": 0.7075240612030029, "gsm_rft_2034": 0.7075258493423462, "gsm_rft_3538": 0.7075258493423462, "camel_17811": 0.7075636982917786, "gsm_rft_33234": 0.7076920866966248, "gsm_train_9179": 0.7078281044960022, "camel_6840": 0.7078644037246704, "aqua_rat_24388": 0.7078787088394165, "aqua_rat_7575": 0.7079377174377441, "camel_39251": 0.7079906463623047, "math_test_prealgebra_1904": 0.7080070376396179, "gsm_rft_14120": 0.7080793976783752, "gsm_rft_12209": 0.7081769108772278, "gsm_rft_9443": 0.708274245262146, "gsm_train_31894": 0.7082952260971069, "gsm_rft_2338": 0.7083765268325806, "camel_46280": 0.7085273265838623, "gsm_rft_18987": 0.7086361646652222, "camel_28096": 0.7086672186851501, "gsm_train_13763": 0.7088215947151184, "gsm_rft_21314": 0.7088215947151184, "aqua_rat_50302": 0.7088237404823303, "gsm_rft_7089": 0.7090033292770386, "gsm_rft_22305": 0.7090790867805481, "aqua_rat_74150": 0.7091493606567383, "aqua_rat_36411": 0.7092656493186951, "aqua_rat_77586": 0.709282636642456, "aqua_rat_35471": 0.7092978954315186, "camel_4972": 0.7095646262168884, "gsm_train_2661": 0.7096328735351562, "gsm_rft_3387": 0.7096328735351562, "aqua_rat_36249": 0.7097640037536621, "gsm_rft_16998": 0.7098365426063538, "gsm_rft_8748": 0.7099068760871887, "aqua_rat_28523": 0.7099990248680115, "aqua_rat_81631": 0.7100080847740173, "aqua_rat_8162": 0.7101076245307922, "gsm_train_21544": 0.7102148532867432, "aqua_rat_46971": 0.710364043712616, "aqua_rat_60297": 0.7104608416557312, "aqua_rat_33103": 0.7105283737182617, "gsm_rft_7812": 0.710537850856781, "aqua_rat_35903": 0.7105444073677063, "gsm_rft_4136": 0.7106728553771973, "gsm_train_21508": 0.7108363509178162, "aqua_rat_23008": 0.7109119892120361, "aqua_rat_20614": 0.7109436988830566, "gsm_rft_6897": 0.7110220193862915, "aqua_rat_70812": 0.7111971974372864, "gsm_rft_2105": 0.7112136483192444, "aqua_rat_23101": 0.7112266421318054, "gsm_rft_17325": 0.7113668918609619, "aqua_rat_9793": 0.711746871471405, "aqua_rat_24901": 0.7118987441062927, "camel_5344": 0.7120919823646545, "gsm_rft_5163": 0.7122026681900024, "camel_19754": 0.712448239326477, "camel_4994": 0.7127068638801575, "aqua_rat_88321": 0.7129296064376831, "aqua_rat_5999": 0.7130013108253479, "gsm_rft_32644": 0.7130258679389954, "aqua_rat_71395": 0.7136043310165405, "aqua_rat_25154": 0.7136553525924683, "aqua_rat_32925": 0.713671863079071, "gsm_rft_14868": 0.7139239311218262, "gsm_train_32410": 0.7139747738838196, "aqua_rat_33439": 0.7140053510665894, "aqua_rat_2228": 0.7140063047409058, "gsm_rft_2985": 0.7140181064605713, "aqua_rat_68735": 0.7140203714370728, "aqua_rat_49324": 0.714245080947876, "gsm_rft_15709": 0.7144964337348938, "aqua_rat_14555": 0.7145970463752747, "gsm_rft_25293": 0.7146759033203125, "aqua_rat_42212": 0.7148423790931702, "camel_19784": 0.7149312496185303, "camel_4999": 0.7149658203125, "aqua_rat_55756": 0.7152048945426941, "gsm_rft_20099": 0.7154356241226196, "aqua_rat_83787": 0.7157517075538635, "camel_4983": 0.7159171104431152, "aqua_rat_58122": 0.715931236743927, "camel_4737": 0.71593177318573, "gsm_rft_16470": 0.7159730195999146, "gsm_rft_14372": 0.7159730195999146, "gsm_train_19303": 0.7160592079162598, "aqua_rat_41724": 0.7160736322402954, "gsm_rft_3570": 0.7162129282951355, "aqua_rat_81968": 0.7164125442504883, "aqua_rat_20932": 0.7164162397384644, "gsm_train_18349": 0.7164922952651978, "camel_5017": 0.7166849970817566, "gsm_rft_29693": 0.7169301509857178, "aqua_rat_3331": 0.7169404029846191, "aqua_rat_37262": 0.7173005938529968, "aqua_rat_64556": 0.7173137068748474, "camel_4969": 0.7174121737480164, "aqua_rat_14285": 0.7174296379089355, "aqua_rat_71816": 0.717947781085968, "math_test_algebra_2160": 0.7180061340332031, "aqua_rat_21116": 0.7184276580810547, "aqua_rat_61332": 0.7184603214263916, "aqua_rat_56122": 0.7185253500938416, "gsm_train_2639": 0.7185564041137695, "gsm_rft_34396": 0.7185564041137695, "gsm_rft_22460": 0.7185668349266052, "gsm_train_25539": 0.7185668349266052, "aqua_rat_56566": 0.7186003923416138, "gsm_rft_27782": 0.7191765904426575, "aqua_rat_64993": 0.7192694544792175, "gsm_rft_14108": 0.7193747162818909, "math_train_prealgebra_1919": 0.7194344401359558, "gsm_rft_26574": 0.7194543480873108, "aqua_rat_38758": 0.719817578792572, "aqua_rat_54504": 0.7198436260223389, "aqua_rat_55747": 0.7200111746788025, "aqua_rat_76667": 0.7201042771339417, "aqua_rat_39210": 0.7203091382980347, "aqua_rat_12010": 0.7203476428985596, "aqua_rat_6220": 0.7206980586051941, "aqua_rat_25415": 0.7208372354507446, "gsm_rft_35201": 0.7208924889564514, "camel_19705": 0.721043586730957, "gsm_rft_11389": 0.7211016416549683, "aqua_rat_37688": 0.7211581468582153, "aqua_rat_60403": 0.7212053537368774, "aqua_rat_36642": 0.7213348746299744, "aqua_rat_1854": 0.721606433391571, "gsm_rft_35481": 0.7216955423355103, "gsm_rft_2430": 0.7220445871353149, "aqua_rat_37980": 0.7224218249320984, "aqua_rat_40416": 0.7224416732788086, "aqua_rat_17798": 0.7227821946144104, "aqua_rat_38896": 0.7231729030609131, "aqua_rat_17930": 0.7232383489608765, "camel_4987": 0.7235679030418396, "aqua_rat_49952": 0.7236035466194153, "gsm_train_31158": 0.7236261367797852, "gsm_rft_1939": 0.7236261367797852, "aqua_rat_51750": 0.7240359783172607, "camel_5527": 0.7243030071258545, "aqua_rat_18543": 0.7247408032417297, "aqua_rat_30572": 0.7249751687049866, "camel_4771": 0.7250200510025024, "aqua_rat_18718": 0.7251949310302734, "aqua_rat_23397": 0.7253693342208862, "aqua_rat_83857": 0.7254753708839417, "aqua_rat_31294": 0.7254976630210876, "gsm_rft_2452": 0.7256743311882019, "aqua_rat_43435": 0.7257125377655029, "aqua_rat_45660": 0.7259780168533325, "gsm_rft_9344": 0.7264769077301025, "gsm_rft_17551": 0.7264769077301025, "gsm_train_17819": 0.7264769077301025, "gsm_rft_11031": 0.7268667221069336, "gsm_rft_33471": 0.7268756031990051, "aqua_rat_22618": 0.727063775062561, "aqua_rat_65230": 0.7274086475372314, "camel_5287": 0.7278357744216919, "aqua_rat_53630": 0.7278918027877808, "TheoremQA_wenhuchen/optics3.json": 0.7279260158538818, "aqua_rat_81174": 0.7288306951522827, "aqua_rat_69962": 0.7289818525314331, "camel_28271": 0.7289950251579285, "aqua_rat_85100": 0.7290397882461548, "aqua_rat_14896": 0.7296692728996277, "math_train_prealgebra_1701": 0.7299896478652954, "camel_47373": 0.7304593324661255, "aqua_rat_60805": 0.7317549586296082, "aqua_rat_44239": 0.7321615219116211, "aqua_rat_6676": 0.7328711152076721, "aqua_rat_25937": 0.7329416275024414, "camel_4993": 0.733067512512207, "aqua_rat_86356": 0.7341408729553223, "aqua_rat_35477": 0.7355270981788635, "gsm_rft_3001": 0.7382795810699463, "gsm_train_22328": 0.7382795810699463, "gsm_rft_20209": 0.7382795810699463, "aqua_rat_8530": 0.7389285564422607, "gsm_rft_5305": 0.7401794195175171, "gsm_train_22045": 0.7401794195175171, "aqua_rat_30186": 0.7406871914863586, "aqua_rat_37605": 0.7418736219406128, "camel_4808": 0.7421693205833435, "aqua_rat_12240": 0.7424281239509583, "camel_19727": 0.743583619594574, "aqua_rat_55057": 0.7442187666893005, "camel_19713": 0.7536841034889221, "gsm_rft_7733": 0.7584401369094849, "gsm_rft_17748": 0.7586326599121094, "gsm_train_19077": 0.7586326599121094, "aqua_rat_59988": 0.7645646929740906, "aqua_rat_74461": 0.7646967172622681, "aqua_rat_27170": 0.7660267949104309, "aqua_rat_22739": 0.7697161436080933, "TheoremQA_wenhuchen/optics2.json": 0.7712007164955139, "aqua_rat_10339": 0.7716232538223267, "aqua_rat_70142": 0.7747341394424438}, "TheoremQA_elainewan/math_calculus_2_5.json": {"camel_7731": 0, "camel_6874": 0, "camel_6820": 0, "camel_6801": 0, "camel_7249": 0, "camel_7226": 0, "TheoremQA_elainewan/math_calculus_2_5.json": 0, "camel_7961": 0, "camel_6594": 0, "camel_6817": 0, "camel_6518": 0, "math_test_precalculus_893": 0, "camel_16280": 0.7540721297264099, "camel_5178": 0.7541088461875916, "camel_5425": 0.7542439699172974, "camel_4991": 0.7544843554496765, "camel_16242": 0.7545019388198853, "camel_29046": 0.7545505166053772, "camel_28802": 0.7545802593231201, "camel_5404": 0.7551432847976685, "camel_28804": 0.7552444338798523, "camel_5109": 0.7553320527076721, "camel_29860": 0.755601167678833, "camel_4983": 0.7556048035621643, "camel_28856": 0.7557080984115601, "camel_5104": 0.7557361721992493, "camel_28859": 0.7557762265205383, "camel_5139": 0.7558303475379944, "camel_28806": 0.7559347748756409, "camel_28830": 0.7559516429901123, "camel_16240": 0.7560980916023254, "camel_5338": 0.7563871741294861, "camel_5058": 0.7564367055892944, "camel_28909": 0.756456732749939, "camel_4988": 0.7566583156585693, "camel_4960": 0.7566611766815186, "camel_29989": 0.7566819787025452, "camel_28812": 0.7568316459655762, "camel_28858": 0.7575160264968872, "camel_40267": 0.7576424479484558, "camel_28800": 0.7576832175254822, "camel_39489": 0.7577459812164307, "camel_28826": 0.7578084468841553, "camel_5050": 0.757992684841156, "camel_4961": 0.7580316066741943, "camel_28873": 0.7580893039703369, "camel_28828": 0.7582815289497375, "camel_5290": 0.7589272856712341, "camel_28140": 0.7589371204376221, "camel_5005": 0.7595705986022949, "camel_5024": 0.7596240043640137, "camel_28864": 0.7597006559371948, "camel_16298": 0.7598881721496582, "camel_5303": 0.7599542140960693, "camel_28841": 0.7599623799324036, "aqua_rat_68267": 0.7602986693382263, "camel_4495": 0.7603396773338318, "camel_4967": 0.760556697845459, "camel_28852": 0.7605970501899719, "camel_5084": 0.7611011862754822, "aqua_rat_9643": 0.7615061402320862, "camel_28861": 0.7615962028503418, "camel_28844": 0.7617524266242981, "camel_28867": 0.7618019580841064, "camel_28022": 0.7619572877883911, "camel_5062": 0.761965811252594, "camel_5035": 0.7620345950126648, "aqua_rat_64993": 0.7622575163841248, "camel_5034": 0.7622657418251038, "camel_28145": 0.762317955493927, "camel_28847": 0.7626842260360718, "camel_44694": 0.7627871632575989, "camel_1874": 0.762821614742279, "TheoremQA_wenhuchen/Lagrange's_theorem.json": 0.762909471988678, "camel_5068": 0.7629434466362, "camel_39357": 0.7630705833435059, "camel_5007": 0.7631085515022278, "camel_4994": 0.7632227540016174, "camel_5115": 0.763467013835907, "camel_5295": 0.7635040283203125, "camel_16241": 0.7635794878005981, "camel_5314": 0.7642534971237183, "camel_5047": 0.764756977558136, "camel_28866": 0.7648189663887024, "camel_28862": 0.7652157545089722, "camel_28813": 0.765533983707428, "aqua_rat_38896": 0.7656118869781494, "camel_5078": 0.7658529281616211, "camel_5006": 0.7659136652946472, "camel_17435": 0.7662697434425354, "camel_28853": 0.7663025856018066, "camel_5113": 0.7664485573768616, "camel_28736": 0.7672367691993713, "camel_5063": 0.7673047780990601, "camel_28820": 0.7680105566978455, "camel_28836": 0.7681927680969238, "camel_28878": 0.7683525085449219, "camel_5077": 0.7688295841217041, "camel_28801": 0.7691019773483276, "aqua_rat_6676": 0.7691869139671326, "camel_5066": 0.769207775592804, "camel_29060": 0.7693555951118469, "camel_28823": 0.7697163820266724, "camel_5083": 0.7698918581008911, "aqua_rat_23397": 0.7698951959609985, "camel_28815": 0.7700095176696777, "camel_5138": 0.7702271342277527, "aqua_rat_45660": 0.7712582349777222, "camel_5089": 0.7715158462524414, "camel_5319": 0.7715639472007751, "camel_28816": 0.771611213684082, "camel_28814": 0.7721080780029297, "TheoremQA_elainewan/math_calculus_2_11.json": 0.7723395824432373, "aqua_rat_17798": 0.7725690603256226, "camel_39486": 0.7727600932121277, "TheoremQA_elainewan/math_calculus_12.json": 0.7729822993278503, "camel_28854": 0.7733230590820312, "camel_28832": 0.7736127972602844, "camel_5076": 0.7737022638320923, "camel_28809": 0.773797869682312, "camel_5111": 0.7739253044128418, "camel_28848": 0.7743603587150574, "camel_39327": 0.7744905948638916, "camel_5126": 0.7746294736862183, "aqua_rat_83913": 0.774734377861023, "aqua_rat_47425": 0.7751511335372925, "camel_5048": 0.7753262519836426, "camel_28824": 0.7756032943725586, "aqua_rat_28088": 0.7756534814834595, "camel_5358": 0.775986909866333, "camel_5103": 0.7764059901237488, "aqua_rat_57946": 0.7776520848274231, "aqua_rat_48488": 0.7777442932128906, "camel_5153": 0.777898371219635, "camel_28851": 0.7779224514961243, "camel_28805": 0.7780494093894958, "camel_5134": 0.7784196734428406, "camel_39338": 0.7785103917121887, "camel_28831": 0.7786139249801636, "camel_17406": 0.7786674499511719, "camel_28860": 0.7787871360778809, "camel_5307": 0.7791466116905212, "camel_17436": 0.7792816758155823, "camel_5342": 0.7795766592025757, "camel_29979": 0.7798207402229309, "camel_5098": 0.7802562713623047, "camel_5037": 0.7803394198417664, "camel_28147": 0.7805958986282349, "camel_28842": 0.7808835506439209, "aqua_rat_74869": 0.7810103297233582, "aqua_rat_75605": 0.7812246680259705, "camel_5057": 0.7813892364501953, "camel_17422": 0.7818681597709656, "camel_28869": 0.7819899320602417, "camel_5051": 0.7831514477729797, "camel_29198": 0.7835946083068848, "camel_5014": 0.7837041616439819, "camel_5011": 0.7837585210800171, "camel_28840": 0.7838260531425476, "camel_5356": 0.7842977046966553, "camel_5090": 0.7849636673927307, "camel_5334": 0.7866818904876709, "camel_5197": 0.7874431610107422, "camel_5185": 0.7880292534828186, "camel_28532": 0.7880603075027466, "camel_5331": 0.7900388836860657, "camel_5198": 0.7914857864379883, "camel_5227": 0.7915643453598022, "camel_5172": 0.7924512028694153, "camel_5357": 0.7936458587646484, "camel_5129": 0.7938321232795715, "camel_5114": 0.7945024967193604, "camel_5272": 0.7945793271064758, "camel_4965": 0.7984403371810913, "camel_5065": 0.7989398241043091, "camel_5180": 0.7989680171012878, "camel_5181": 0.7990430593490601, "camel_5079": 0.7992322444915771, "camel_5177": 0.8006446957588196, "camel_5117": 0.8014076352119446, "camel_5059": 0.80164635181427, "camel_5285": 0.8022476434707642, "camel_28137": 0.8036117553710938, "camel_5055": 0.805347204208374, "camel_5333": 0.8054521679878235, "camel_5189": 0.8057102560997009, "camel_5158": 0.8082005381584167, "camel_5188": 0.8108733892440796, "camel_5043": 0.811549723148346, "camel_28080": 0.8116984963417053, "camel_5094": 0.8135008811950684, "camel_5093": 0.8135616779327393, "camel_5092": 0.8150465488433838, "camel_5041": 0.8163546323776245, "camel_5008": 0.8164049386978149, "camel_28086": 0.8169621229171753, "camel_5165": 0.8179804682731628, "camel_5070": 0.818764865398407, "camel_5029": 0.8255560398101807, "camel_4986": 0.8363304734230042}, "TheoremQA_wenhuchen/gauss_lemma.json": {"camel_13503": 0, "camel_12577": 0, "camel_12634": 0, "camel_13919": 0, "camel_12565": 0, "camel_13255": 0, "camel_13541": 0, "camel_13275": 0, "camel_12596": 0, "camel_12832": 0, "camel_12872": 0, "camel_13555": 0, "camel_12137": 0, "camel_12566": 0, "camel_12183": 0, "camel_12167": 0, "camel_12630": 0, "camel_13455": 0, "camel_12824": 0, "camel_12846": 0, "camel_12875": 0, "camel_12568": 0, "camel_13224": 0, "camel_12625": 0, "camel_12595": 0, "camel_12232": 0, "camel_12619": 0, "camel_13522": 0, "camel_13527": 0, "camel_12593": 0, "camel_13584": 0, "camel_12914": 0, "camel_12617": 0, "camel_12618": 0, "camel_12622": 0, "camel_12636": 0, "camel_13582": 0, "camel_13575": 0, "camel_12834": 0, "camel_12858": 0, "camel_12847": 0, "camel_12833": 0, "camel_12813": 0, "camel_12869": 0, "camel_12857": 0, "camel_12865": 0, "camel_12859": 0, "camel_12830": 0, "camel_12805": 0, "camel_12815": 0, "camel_12807": 0, "camel_12819": 0, "camel_13661": 0, "camel_12828": 0, "camel_12854": 0, "camel_12818": 0, "camel_12862": 0, "camel_12820": 0, "camel_12849": 0, "camel_13552": 0, "camel_13201": 0, "camel_12808": 0, "camel_12874": 0, "camel_12877": 0, "camel_12569": 0, "camel_12868": 0, "camel_12590": 0, "camel_12880": 0, "camel_12804": 0, "camel_12133": 0, "camel_12827": 0, "camel_13471": 0, "camel_13465": 0, "camel_12866": 0, "camel_12599": 0, "camel_12194": 0, "camel_13252": 0, "TheoremQA_wenhuchen/gauss_lemma.json": 0, "camel_12573": 0, "camel_13521": 0, "camel_12817": 0, "camel_13249": 0, "camel_12563": 0, "camel_12816": 0, "camel_12806": 0, "camel_12814": 0, "camel_12839": 0, "camel_12825": 0, "camel_12860": 0, "camel_12864": 0, "camel_12831": 0, "camel_12878": 0, "camel_12844": 0, "camel_12851": 0, "camel_12838": 0, "camel_12842": 0, "camel_12850": 0, "camel_12836": 0, "camel_12801": 0, "camel_12873": 0, "camel_12823": 0, "camel_12840": 0, "camel_12835": 0, "camel_12802": 0, "camel_12822": 0, "camel_12843": 0, "camel_12856": 0, "camel_12870": 0, "camel_12812": 0, "camel_12811": 0, "camel_12810": 0, "camel_12848": 0, "camel_12879": 0, "camel_12861": 0, "camel_12855": 0, "camel_12837": 0, "camel_12867": 0, "camel_12852": 0, "camel_12821": 0, "camel_13636": 0, "camel_12841": 0, "camel_12803": 0, "camel_12853": 0, "camel_12826": 0, "camel_12863": 0, "camel_12876": 0, "camel_12871": 0, "camel_12800": 0, "camel_26016": 0.7390021085739136, "camel_26025": 0.7398162484169006, "camel_26393": 0.7399800419807434, "aqua_rat_79841": 0.7402056455612183, "camel_26333": 0.7403871417045593, "aqua_rat_86100": 0.7407517433166504, "camel_26061": 0.7409789562225342, "aqua_rat_62476": 0.7415896058082581, "camel_26019": 0.7416372895240784, "aqua_rat_56616": 0.7418693900108337, "aqua_rat_66334": 0.7421131134033203, "camel_26371": 0.7421964406967163, "camel_26329": 0.7422841787338257, "camel_26357": 0.7424042224884033, "camel_26348": 0.7424435019493103, "aqua_rat_32928": 0.742487907409668, "camel_26383": 0.7426149249076843, "aqua_rat_16577": 0.7426373958587646, "aqua_rat_65872": 0.7429426312446594, "aqua_rat_49604": 0.7430386543273926, "camel_26012": 0.7430484294891357, "aqua_rat_78908": 0.7439451217651367, "aqua_rat_43230": 0.7440598607063293, "aqua_rat_28349": 0.7453877925872803, "camel_26380": 0.7457771897315979, "aqua_rat_66605": 0.7464532852172852, "aqua_rat_64445": 0.7465150952339172, "camel_26351": 0.7466179728507996, "aqua_rat_65377": 0.7468708157539368, "camel_26350": 0.7471105456352234, "aqua_rat_29400": 0.7476398944854736, "camel_26071": 0.7496546506881714, "aqua_rat_11083": 0.7507272362709045, "aqua_rat_44214": 0.7513062357902527, "aqua_rat_74130": 0.7521497011184692, "math_train_number_theory_1100": 0.7525280714035034, "camel_26002": 0.752888560295105, "aqua_rat_77709": 0.753505527973175, "camel_26037": 0.755074143409729, "aqua_rat_6246": 0.7554102540016174, "camel_26326": 0.7563449740409851, "aqua_rat_72561": 0.757152259349823, "aqua_rat_10127": 0.7577358484268188, "aqua_rat_49868": 0.7582094073295593, "aqua_rat_27885": 0.7584613561630249, "aqua_rat_65036": 0.7585377097129822, "aqua_rat_29597": 0.7587852478027344, "aqua_rat_3156": 0.7592284083366394, "aqua_rat_37551": 0.7592421770095825, "math_test_number_theory_554": 0.7597349286079407, "aqua_rat_88443": 0.7615190148353577, "camel_37393": 0.7627348899841309, "aqua_rat_61608": 0.7657654285430908, "math_test_number_theory_1128": 0.7667370438575745, "camel_26051": 0.7678967714309692, "camel_26387": 0.7683184146881104, "aqua_rat_17168": 0.7699829936027527, "aqua_rat_24283": 0.773780345916748, "TheoremQA_wenhuchen/gauss_lemma2.json": 0.7771931290626526, "aqua_rat_15929": 0.7810933589935303, "aqua_rat_69927": 0.7849565148353577, "aqua_rat_22189": 0.7858361005783081, "aqua_rat_60360": 0.7875772714614868, "aqua_rat_9910": 0.7931821346282959, "aqua_rat_51863": 0.7934388518333435, "aqua_rat_28035": 0.7952845692634583, "aqua_rat_14060": 0.7956405282020569, "aqua_rat_61707": 0.7967673540115356, "aqua_rat_50295": 0.803366482257843, "aqua_rat_1010": 0.8034288883209229, "aqua_rat_75586": 0.8104190826416016, "aqua_rat_48398": 0.8153649568557739}, "TheoremQA_xueguangma/dividend_discount_model_2.json": {"TheoremQA_xueguangma/dividend_discount_model_2.json": 0, "aqua_rat_42740": 0.7757083773612976, "gsm_rft_35442": 0.7757139205932617, "gsm_rft_34495": 0.7757376432418823, "gsm_rft_17302": 0.7757612466812134, "aqua_rat_88011": 0.7757838368415833, "gsm_rft_11189": 0.7757948637008667, "aqua_rat_17612": 0.7759063243865967, "aqua_rat_86633": 0.7759667634963989, "aqua_rat_13817": 0.7759696841239929, "aqua_rat_66026": 0.7759755253791809, "gsm_rft_29683": 0.776032030582428, "gsm_rft_7079": 0.7760477662086487, "aqua_rat_66646": 0.7760713696479797, "gsm_rft_32819": 0.7762902975082397, "aqua_rat_16849": 0.776363730430603, "math_train_prealgebra_1338": 0.7765071988105774, "gsm_rft_21369": 0.7765393853187561, "aqua_rat_19454": 0.7765494585037231, "gsm_rft_33801": 0.7767185568809509, "aqua_rat_53674": 0.7767305374145508, "aqua_rat_48727": 0.7767444849014282, "aqua_rat_6366": 0.7767768502235413, "aqua_rat_51287": 0.7767834663391113, "camel_37746": 0.7769314646720886, "aqua_rat_36204": 0.7769989371299744, "aqua_rat_6469": 0.7770205736160278, "aqua_rat_10392": 0.7770451903343201, "gsm_rft_24611": 0.7771012783050537, "aqua_rat_54292": 0.7772209644317627, "aqua_rat_1447": 0.7772882580757141, "aqua_rat_52197": 0.7772896885871887, "gsm_rft_4462": 0.7773101329803467, "aqua_rat_26765": 0.777409553527832, "aqua_rat_68501": 0.7774645090103149, "gsm_rft_12542": 0.7775570154190063, "aqua_rat_37337": 0.7776066064834595, "gsm_rft_26182": 0.7776160836219788, "gsm_rft_5012": 0.7776484489440918, "gsm_rft_25913": 0.7776632905006409, "gsm_rft_28409": 0.7778128981590271, "aqua_rat_17859": 0.7779254913330078, "gsm_rft_5070": 0.7780507802963257, "gsm_rft_14506": 0.7780972719192505, "gsm_train_10049": 0.7780972719192505, "aqua_rat_64527": 0.7781188488006592, "gsm_train_34082": 0.778245210647583, "aqua_rat_39841": 0.7782953977584839, "aqua_rat_79704": 0.7783242464065552, "aqua_rat_88462": 0.7783300876617432, "aqua_rat_5299": 0.778478741645813, "gsm_rft_1626": 0.7785347700119019, "aqua_rat_86350": 0.7785775065422058, "aqua_rat_79547": 0.7786524295806885, "aqua_rat_79970": 0.7787603139877319, "aqua_rat_71690": 0.7789185643196106, "gsm_rft_31854": 0.7789332270622253, "aqua_rat_59939": 0.7789532542228699, "aqua_rat_12664": 0.7791658043861389, "aqua_rat_17504": 0.7791902422904968, "aqua_rat_89004": 0.7792685627937317, "aqua_rat_37392": 0.7794005870819092, "gsm_rft_23935": 0.779402494430542, "gsm_train_24637": 0.779402494430542, "gsm_rft_14407": 0.7795920968055725, "gsm_rft_6827": 0.7796291708946228, "gsm_train_19492": 0.7796291708946228, "aqua_rat_49968": 0.7796637415885925, "aqua_rat_61920": 0.7796646952629089, "aqua_rat_79286": 0.779670000076294, "aqua_rat_10022": 0.7797263860702515, "aqua_rat_71465": 0.7798949480056763, "aqua_rat_945": 0.7798981070518494, "gsm_rft_10252": 0.779945969581604, "aqua_rat_56727": 0.7799785137176514, "aqua_rat_1066": 0.7799897789955139, "aqua_rat_77614": 0.7800536155700684, "gsm_rft_30785": 0.7801209688186646, "aqua_rat_33801": 0.780160129070282, "gsm_rft_12600": 0.7801737189292908, "aqua_rat_87884": 0.7801939249038696, "math_test_algebra_1043": 0.7804304957389832, "gsm_rft_31372": 0.7804415225982666, "gsm_train_4730": 0.7804415225982666, "aqua_rat_86309": 0.7805148363113403, "gsm_rft_26823": 0.7805549502372742, "camel_25253": 0.7807554602622986, "aqua_rat_24048": 0.7807843089103699, "aqua_rat_40759": 0.780953049659729, "camel_37747": 0.7810152173042297, "gsm_rft_29226": 0.7810258865356445, "aqua_rat_7346": 0.7810537219047546, "aqua_rat_82399": 0.7811912298202515, "aqua_rat_55623": 0.7813180088996887, "aqua_rat_41782": 0.7813948392868042, "aqua_rat_16130": 0.7815781235694885, "aqua_rat_81598": 0.7816449403762817, "gsm_rft_27770": 0.7816706895828247, "gsm_train_14713": 0.7818534970283508, "aqua_rat_10227": 0.782135009765625, "aqua_rat_61026": 0.7823202013969421, "aqua_rat_9873": 0.7823665142059326, "gsm_rft_7803": 0.7824646234512329, "gsm_rft_6267": 0.7825546860694885, "gsm_rft_32019": 0.782842218875885, "aqua_rat_62036": 0.7828794121742249, "aqua_rat_27446": 0.7831097841262817, "aqua_rat_7307": 0.783349871635437, "gsm_rft_5391": 0.7833852171897888, "aqua_rat_2713": 0.7833924889564514, "aqua_rat_53171": 0.7834866046905518, "aqua_rat_56930": 0.7835226655006409, "aqua_rat_85560": 0.783694863319397, "gsm_rft_29292": 0.7838108539581299, "aqua_rat_80962": 0.7838269472122192, "aqua_rat_88687": 0.7839857339859009, "aqua_rat_42709": 0.7841430306434631, "aqua_rat_67487": 0.7843397855758667, "aqua_rat_27035": 0.7843572497367859, "aqua_rat_12799": 0.7846576571464539, "gsm_rft_17816": 0.7847903370857239, "aqua_rat_74699": 0.7848768830299377, "gsm_rft_28000": 0.7849467396736145, "gsm_rft_2946": 0.7851032614707947, "gsm_train_29223": 0.7851032614707947, "gsm_rft_35059": 0.7851587533950806, "gsm_train_22659": 0.7852752804756165, "gsm_rft_25984": 0.785366952419281, "aqua_rat_20555": 0.7854648232460022, "aqua_rat_77486": 0.7859373092651367, "gsm_rft_17441": 0.7859501838684082, "gsm_rft_13417": 0.7861483693122864, "aqua_rat_46607": 0.7862980365753174, "gsm_rft_17789": 0.7863068580627441, "gsm_train_21274": 0.7863068580627441, "gsm_rft_32168": 0.786417543888092, "gsm_rft_23795": 0.7866572737693787, "gsm_rft_26543": 0.7877252697944641, "gsm_rft_31049": 0.7877449989318848, "gsm_train_25772": 0.7879724502563477, "gsm_rft_13281": 0.7879921793937683, "aqua_rat_55929": 0.7880479097366333, "aqua_rat_11060": 0.7881753444671631, "aqua_rat_16627": 0.7883318066596985, "gsm_rft_31412": 0.7883639335632324, "aqua_rat_84363": 0.7884160280227661, "gsm_rft_15258": 0.7886425852775574, "aqua_rat_61547": 0.7890318632125854, "aqua_rat_73286": 0.7891901135444641, "gsm_rft_26213": 0.7891997694969177, "TheoremQA_xueguangma/spot_rate.json": 0.7895426154136658, "gsm_rft_20347": 0.7897147536277771, "gsm_train_374": 0.7897147536277771, "aqua_rat_47825": 0.7900899648666382, "aqua_rat_57109": 0.7903032302856445, "aqua_rat_14152": 0.7903090119361877, "aqua_rat_76011": 0.7911555767059326, "gsm_rft_11850": 0.7912026643753052, "gsm_rft_10842": 0.7914180755615234, "gsm_rft_31153": 0.7914656400680542, "gsm_train_27641": 0.7914656400680542, "gsm_rft_31288": 0.7916091084480286, "aqua_rat_34230": 0.791735827922821, "gsm_rft_13162": 0.792248010635376, "gsm_rft_31203": 0.7922854423522949, "aqua_rat_46713": 0.7923552989959717, "aqua_rat_42852": 0.7930393218994141, "aqua_rat_16605": 0.7939010858535767, "gsm_rft_6751": 0.7943645119667053, "gsm_train_34638": 0.7943645119667053, "aqua_rat_76879": 0.794899582862854, "aqua_rat_56922": 0.7953554391860962, "aqua_rat_8292": 0.795360267162323, "aqua_rat_25533": 0.79584139585495, "aqua_rat_37709": 0.796118438243866, "gsm_rft_3126": 0.7962074279785156, "aqua_rat_19962": 0.7970580458641052, "aqua_rat_15749": 0.7971559762954712, "aqua_rat_70338": 0.7973321676254272, "aqua_rat_17685": 0.7973838448524475, "aqua_rat_23836": 0.7979991436004639, "aqua_rat_64914": 0.7982842922210693, "aqua_rat_24355": 0.798505425453186, "aqua_rat_88770": 0.7986712455749512, "aqua_rat_87481": 0.7986827492713928, "aqua_rat_18140": 0.7988929748535156, "aqua_rat_76433": 0.7992891073226929, "aqua_rat_45706": 0.7998883128166199, "aqua_rat_24626": 0.7998883724212646, "aqua_rat_46293": 0.7999507784843445, "aqua_rat_33283": 0.8007277250289917, "aqua_rat_57386": 0.8015729188919067, "aqua_rat_52474": 0.8020091652870178, "aqua_rat_16258": 0.8043351173400879, "aqua_rat_87442": 0.8066860437393188, "aqua_rat_81348": 0.8145143389701843, "aqua_rat_46842": 0.819146990776062, "TheoremQA_xueguangma/dividend_discount_model_1.json": 0.8281599879264832, "TheoremQA_xueguangma/dividend_discount_model_5.json": 0.853122889995575, "TheoremQA_xueguangma/dividend_discount_model_4.json": 0.8545582890510559}, "TheoremQA_panlu/similarity2.json": {"math_train_geometry_809": 0, "TheoremQA_panlu/similarity2.json": 0, "math_train_geometry_350": 0, "math_train_geometry_636": 0, "math_train_geometry_272": 0, "math_train_geometry_804": 0, "gsm_rft_31644": 0.7704129219055176, "aqua_rat_50069": 0.7705904841423035, "aqua_rat_74307": 0.7708634734153748, "aqua_rat_43952": 0.7708836197853088, "aqua_rat_62034": 0.7709326148033142, "aqua_rat_69116": 0.77128666639328, "aqua_rat_26882": 0.7713848948478699, "aqua_rat_69100": 0.7717126607894897, "gsm_rft_34174": 0.7719197273254395, "aqua_rat_22052": 0.7719449400901794, "aqua_rat_19916": 0.7719884514808655, "aqua_rat_73351": 0.7720376253128052, "aqua_rat_52869": 0.7720487713813782, "aqua_rat_6422": 0.7721951007843018, "aqua_rat_35629": 0.7724632024765015, "aqua_rat_67264": 0.7725074887275696, "aqua_rat_29925": 0.7725209593772888, "gsm_rft_30111": 0.7726252675056458, "gsm_train_28955": 0.7726252675056458, "aqua_rat_40813": 0.772725522518158, "aqua_rat_13801": 0.772733747959137, "aqua_rat_82212": 0.7729524374008179, "aqua_rat_72440": 0.7730796337127686, "gsm_train_3857": 0.7732229232788086, "gsm_rft_7535": 0.7732229232788086, "aqua_rat_88865": 0.7732784152030945, "aqua_rat_50125": 0.7732980251312256, "aqua_rat_77434": 0.7734484672546387, "aqua_rat_70142": 0.7736498713493347, "gsm_train_18372": 0.7736712694168091, "gsm_rft_9977": 0.7736712694168091, "aqua_rat_75881": 0.7737593054771423, "aqua_rat_70363": 0.7740301489830017, "gsm_rft_16427": 0.7742341756820679, "aqua_rat_44878": 0.774309515953064, "aqua_rat_22739": 0.7743510007858276, "aqua_rat_19464": 0.7744961380958557, "aqua_rat_69590": 0.7745030522346497, "aqua_rat_10339": 0.7745854258537292, "aqua_rat_72799": 0.774744987487793, "aqua_rat_50119": 0.774874210357666, "aqua_rat_4102": 0.7749473452568054, "aqua_rat_51497": 0.7750679850578308, "aqua_rat_38464": 0.775139570236206, "aqua_rat_57871": 0.7752349972724915, "aqua_rat_84836": 0.7754148840904236, "aqua_rat_47444": 0.7754369974136353, "aqua_rat_31651": 0.7754882574081421, "camel_5527": 0.7754884958267212, "math_train_prealgebra_606": 0.7756047248840332, "gsm_rft_33234": 0.7757402062416077, "aqua_rat_32662": 0.7758018970489502, "aqua_rat_52952": 0.7760026454925537, "aqua_rat_74006": 0.7762658596038818, "aqua_rat_8530": 0.7763368487358093, "aqua_rat_22619": 0.7763897776603699, "camel_4808": 0.7765176296234131, "gsm_rft_2184": 0.7767729163169861, "gsm_train_8181": 0.7767729163169861, "aqua_rat_63192": 0.776805579662323, "aqua_rat_35895": 0.7768620848655701, "aqua_rat_5766": 0.7769678831100464, "aqua_rat_5037": 0.7769692540168762, "gsm_rft_15709": 0.7771686911582947, "gsm_rft_9443": 0.7773177027702332, "aqua_rat_11558": 0.7773351669311523, "camel_30449": 0.7773857116699219, "aqua_rat_62013": 0.7775822877883911, "aqua_rat_58348": 0.7775906920433044, "camel_4771": 0.7776175141334534, "aqua_rat_38897": 0.7778031229972839, "aqua_rat_66321": 0.7778379321098328, "aqua_rat_65465": 0.7778500318527222, "gsm_rft_34183": 0.7778600454330444, "aqua_rat_33898": 0.7778615355491638, "gsm_rft_11235": 0.7778986692428589, "gsm_train_21228": 0.7778986692428589, "aqua_rat_34376": 0.7779728770256042, "aqua_rat_74929": 0.7781441807746887, "aqua_rat_25939": 0.7785211801528931, "aqua_rat_73868": 0.7786912322044373, "aqua_rat_69391": 0.7787845134735107, "aqua_rat_67711": 0.7788458466529846, "aqua_rat_38118": 0.7788951396942139, "gsm_rft_4511": 0.7791480422019958, "aqua_rat_27170": 0.7792186737060547, "aqua_rat_82269": 0.7792593240737915, "aqua_rat_77512": 0.7793781161308289, "aqua_rat_12570": 0.7795022130012512, "aqua_rat_52168": 0.7796586155891418, "aqua_rat_34554": 0.7798526287078857, "gsm_rft_11838": 0.7801823019981384, "aqua_rat_28573": 0.7802311778068542, "gsm_train_3176": 0.7806611061096191, "aqua_rat_964": 0.7807261943817139, "aqua_rat_43529": 0.7809394598007202, "gsm_rft_28794": 0.7810773849487305, "aqua_rat_57216": 0.7811644673347473, "gsm_rft_3570": 0.7812341451644897, "aqua_rat_59295": 0.7812460064888, "gsm_rft_14077": 0.7814120650291443, "aqua_rat_47719": 0.7814139127731323, "aqua_rat_41306": 0.7814321517944336, "aqua_rat_37940": 0.7816548347473145, "aqua_rat_46418": 0.7819050550460815, "aqua_rat_50091": 0.7819381356239319, "aqua_rat_56697": 0.7820484042167664, "gsm_rft_881": 0.7821196913719177, "aqua_rat_13043": 0.782159686088562, "aqua_rat_47522": 0.7822138667106628, "aqua_rat_86892": 0.7824302315711975, "aqua_rat_73119": 0.7826323509216309, "aqua_rat_71832": 0.7829182147979736, "aqua_rat_86238": 0.7832216024398804, "aqua_rat_3357": 0.7833255529403687, "gsm_rft_16486": 0.7833473682403564, "aqua_rat_67621": 0.7843530178070068, "aqua_rat_71002": 0.7852016687393188, "gsm_rft_25319": 0.7854889631271362, "gsm_train_34102": 0.7854889631271362, "aqua_rat_82894": 0.785891056060791, "aqua_rat_13271": 0.7867288589477539, "aqua_rat_46305": 0.7867981195449829, "aqua_rat_60805": 0.7871909141540527, "aqua_rat_69379": 0.7872071266174316, "aqua_rat_80461": 0.7877466678619385, "aqua_rat_72117": 0.788199245929718, "aqua_rat_56338": 0.7889490723609924, "aqua_rat_54504": 0.7889724373817444, "aqua_rat_2228": 0.7889919877052307, "aqua_rat_53846": 0.7893965840339661, "aqua_rat_86615": 0.7894713282585144, "aqua_rat_32103": 0.7895677089691162, "aqua_rat_74046": 0.7903051972389221, "aqua_rat_4680": 0.7910167574882507, "aqua_rat_51453": 0.7911986708641052, "aqua_rat_38758": 0.7914291620254517, "aqua_rat_6915": 0.791466474533081, "aqua_rat_51469": 0.7918407320976257, "aqua_rat_71170": 0.7918548583984375, "aqua_rat_79604": 0.7921096682548523, "aqua_rat_18718": 0.7921988368034363, "aqua_rat_65291": 0.7926019430160522, "aqua_rat_81968": 0.793077290058136, "aqua_rat_69424": 0.7932023406028748, "aqua_rat_24805": 0.7939018607139587, "aqua_rat_36642": 0.7941138744354248, "aqua_rat_76238": 0.7941579818725586, "aqua_rat_2100": 0.7941647171974182, "aqua_rat_35180": 0.7942132949829102, "aqua_rat_47972": 0.7942513823509216, "aqua_rat_6220": 0.7945189476013184, "aqua_rat_69962": 0.7948809266090393, "aqua_rat_10513": 0.7956766486167908, "aqua_rat_4256": 0.7961536049842834, "aqua_rat_76943": 0.7963575124740601, "aqua_rat_60403": 0.7965685129165649, "aqua_rat_22618": 0.7965810894966125, "aqua_rat_52886": 0.7966403365135193, "aqua_rat_20703": 0.7967298030853271, "gsm_rft_20209": 0.7967870235443115, "gsm_train_22328": 0.7967870235443115, "gsm_rft_3001": 0.7967870235443115, "aqua_rat_83857": 0.7969196438789368, "aqua_rat_52689": 0.7997952699661255, "aqua_rat_38963": 0.7999418377876282, "aqua_rat_34219": 0.8005200028419495, "aqua_rat_9227": 0.8014387488365173, "camel_18647": 0.8029265999794006, "aqua_rat_51406": 0.8029525279998779, "aqua_rat_41026": 0.803865909576416, "aqua_rat_25937": 0.8040576577186584, "aqua_rat_44741": 0.8053070306777954, "math_train_prealgebra_1919": 0.8066660165786743, "camel_4737": 0.8067484498023987, "aqua_rat_51855": 0.8068483471870422, "aqua_rat_86522": 0.8068702816963196, "aqua_rat_48835": 0.8070661425590515, "aqua_rat_30186": 0.8079803586006165, "math_train_prealgebra_725": 0.8080183267593384, "aqua_rat_25578": 0.8086503148078918, "aqua_rat_40399": 0.809234082698822, "aqua_rat_55057": 0.8108950853347778, "aqua_rat_12240": 0.8115991950035095, "aqua_rat_54093": 0.8126888275146484, "aqua_rat_37605": 0.8150660991668701, "gsm_train_18349": 0.8164554834365845, "gsm_rft_14372": 0.8164724111557007, "gsm_rft_16470": 0.8164724111557007, "gsm_rft_30397": 0.829371452331543, "gsm_rft_26471": 0.829371452331543, "gsm_train_9974": 0.829371452331543, "gsm_rft_33960": 0.8305150270462036, "math_test_prealgebra_1586": 0.8449105620384216}, "TheoremQA_mingyin/stopping-time1.json": {"camel_11719": 0, "camel_11394": 0, "camel_10828": 0, "camel_11558": 0, "camel_9416": 0, "camel_10559": 0, "camel_9471": 0, "camel_10488": 0, "camel_9453": 0, "camel_9495": 0, "camel_10544": 0, "camel_9398": 0, "camel_9485": 0, "math_train_counting_and_probability_460": 0, "camel_10558": 0, "camel_10554": 0, "camel_9487": 0, "camel_9476": 0, "camel_9489": 0, "camel_10543": 0, "camel_10480": 0, "camel_10485": 0, "camel_9506": 0, "camel_9447": 0, "camel_11926": 0, "camel_10542": 0, "camel_9418": 0, "camel_10359": 0, "TheoremQA_mingyin/stopping-time1.json": 0, "camel_11869": 0, "camel_10520": 0, "camel_9466": 0, "math_test_counting_and_probability_25780": 0, "camel_9446": 0, "camel_9537": 0, "camel_9514": 0, "camel_10555": 0, "math_test_counting_and_probability_262": 0, "camel_9511": 0, "camel_10504": 0, "camel_10557": 0, "camel_9464": 0, "camel_11866": 0, "camel_10506": 0, "camel_38666": 0.6997507214546204, "camel_24250": 0.6999139189720154, "aqua_rat_60156": 0.6999580264091492, "camel_24644": 0.6999912261962891, "aqua_rat_34885": 0.6999971270561218, "aqua_rat_32510": 0.7000339031219482, "camel_37771": 0.7001945972442627, "aqua_rat_40988": 0.7002342939376831, "camel_38752": 0.7003498077392578, "aqua_rat_84011": 0.7003923654556274, "aqua_rat_64039": 0.7004148960113525, "aqua_rat_57702": 0.7007028460502625, "aqua_rat_24803": 0.7007032036781311, "aqua_rat_82625": 0.7007562518119812, "aqua_rat_19750": 0.7008327841758728, "camel_24688": 0.700870156288147, "aqua_rat_41336": 0.7009186744689941, "aqua_rat_1453": 0.701041042804718, "aqua_rat_12769": 0.7010622024536133, "camel_37669": 0.7010994553565979, "camel_36260": 0.7015455365180969, "aqua_rat_29275": 0.7016335129737854, "aqua_rat_88286": 0.7016589641571045, "aqua_rat_41052": 0.7016746997833252, "camel_24467": 0.7018063068389893, "aqua_rat_54761": 0.7019407749176025, "camel_21928": 0.7020153999328613, "aqua_rat_73072": 0.7020534873008728, "aqua_rat_57102": 0.7020537853240967, "camel_38645": 0.7020881175994873, "aqua_rat_59362": 0.7021684646606445, "camel_25678": 0.7022560238838196, "camel_39375": 0.7022576928138733, "camel_25489": 0.7024376392364502, "aqua_rat_46532": 0.7024405002593994, "aqua_rat_87651": 0.7025917768478394, "aqua_rat_34949": 0.7026293277740479, "aqua_rat_65593": 0.7027497291564941, "camel_38671": 0.7030481100082397, "camel_24669": 0.7030697464942932, "camel_38658": 0.7030858993530273, "aqua_rat_23464": 0.7030891180038452, "aqua_rat_43375": 0.7031451463699341, "aqua_rat_14944": 0.7032015919685364, "camel_36242": 0.7032920718193054, "camel_36361": 0.7033924460411072, "aqua_rat_86358": 0.703726589679718, "aqua_rat_4946": 0.7037631869316101, "aqua_rat_59064": 0.7039998769760132, "aqua_rat_65962": 0.7043423056602478, "aqua_rat_68610": 0.7044544219970703, "aqua_rat_85290": 0.7045952677726746, "aqua_rat_47000": 0.70464688539505, "camel_38674": 0.7046549916267395, "aqua_rat_88905": 0.7050498723983765, "camel_37732": 0.7051516771316528, "aqua_rat_22475": 0.7052902579307556, "aqua_rat_80959": 0.7053195238113403, "gsm_train_9826": 0.7056687474250793, "gsm_rft_14862": 0.7056687474250793, "camel_36368": 0.7058935761451721, "aqua_rat_30478": 0.7059273719787598, "camel_37713": 0.7060369849205017, "aqua_rat_6028": 0.706207275390625, "aqua_rat_83772": 0.7063507437705994, "gsm_rft_27803": 0.7066187262535095, "aqua_rat_66771": 0.7067797780036926, "camel_38657": 0.7070026993751526, "aqua_rat_3159": 0.7072667479515076, "aqua_rat_26702": 0.7073253989219666, "aqua_rat_5337": 0.7078579068183899, "camel_25543": 0.708258867263794, "camel_38646": 0.7084366679191589, "camel_24684": 0.7084997892379761, "aqua_rat_37149": 0.7086011171340942, "aqua_rat_41204": 0.708610475063324, "aqua_rat_13473": 0.7088611125946045, "camel_25447": 0.7089188694953918, "camel_25575": 0.7092087864875793, "aqua_rat_63857": 0.7092951536178589, "aqua_rat_45598": 0.7093930840492249, "camel_24676": 0.70939701795578, "camel_38682": 0.7095353603363037, "aqua_rat_35997": 0.7095481157302856, "aqua_rat_85797": 0.7095901966094971, "camel_38660": 0.7099176049232483, "camel_25568": 0.7099405527114868, "camel_24656": 0.7099549174308777, "camel_25620": 0.7099837064743042, "aqua_rat_58436": 0.7105182409286499, "aqua_rat_58101": 0.710781991481781, "aqua_rat_42825": 0.710964024066925, "camel_24641": 0.7112722396850586, "aqua_rat_37772": 0.7114492654800415, "camel_24653": 0.7115582227706909, "aqua_rat_20677": 0.7116532325744629, "aqua_rat_4849": 0.7117971181869507, "aqua_rat_62298": 0.7121226787567139, "aqua_rat_50672": 0.7125155925750732, "aqua_rat_10224": 0.7126551270484924, "aqua_rat_62145": 0.7129123210906982, "camel_38643": 0.7131010293960571, "camel_38677": 0.7134571075439453, "aqua_rat_61684": 0.714134931564331, "aqua_rat_33164": 0.7141876220703125, "aqua_rat_50853": 0.7143110632896423, "aqua_rat_48773": 0.714682936668396, "camel_24715": 0.7147924900054932, "camel_38695": 0.7150565981864929, "aqua_rat_44578": 0.7151555418968201, "aqua_rat_77065": 0.7153695225715637, "aqua_rat_49123": 0.7156169414520264, "aqua_rat_22368": 0.71584153175354, "camel_38694": 0.7158798575401306, "aqua_rat_38490": 0.7167754769325256, "aqua_rat_60711": 0.716853678226471, "camel_38651": 0.7174869775772095, "camel_24689": 0.7182074785232544, "aqua_rat_8224": 0.7182215452194214, "camel_36244": 0.7187143564224243, "camel_29102": 0.718957245349884, "camel_38705": 0.7190404534339905, "camel_38700": 0.7195800542831421, "camel_38659": 0.7198731303215027, "camel_37817": 0.7206724882125854, "aqua_rat_21194": 0.7207629084587097, "TheoremQA_wenhuchen/Poisson_process3.json": 0.7211072444915771, "aqua_rat_89088": 0.721264660358429, "aqua_rat_38029": 0.7219107747077942, "aqua_rat_31288": 0.7227397561073303, "camel_38648": 0.7231541872024536, "aqua_rat_25750": 0.7231845259666443, "camel_38711": 0.7233691811561584, "camel_38692": 0.723376989364624, "camel_38662": 0.7244166135787964, "aqua_rat_31903": 0.7244320511817932, "aqua_rat_14333": 0.7249972820281982, "camel_36276": 0.7254666090011597, "camel_37620": 0.725675106048584, "camel_36523": 0.7266762852668762, "camel_38715": 0.7269802689552307, "camel_24711": 0.7282375693321228, "aqua_rat_37057": 0.7291592955589294, "camel_38665": 0.7294216752052307, "aqua_rat_47751": 0.7310617566108704, "aqua_rat_6195": 0.731591522693634, "aqua_rat_69941": 0.7322289943695068, "aqua_rat_6577": 0.7323814630508423, "aqua_rat_60327": 0.733149528503418, "aqua_rat_37698": 0.7338359355926514, "aqua_rat_50510": 0.7347691059112549, "aqua_rat_80730": 0.7350820302963257, "aqua_rat_21944": 0.736195981502533, "aqua_rat_40444": 0.7386646866798401, "aqua_rat_87308": 0.7425296902656555, "aqua_rat_21336": 0.7477515935897827}, "TheoremQA_xinyi/maximum_entropy_2.json": {"camel_10905": 0, "camel_10896": 0, "camel_11344": 0, "camel_9365": 0, "camel_11397": 0, "camel_10922": 0, "camel_11190": 0, "camel_8751": 0, "camel_10330": 0, "camel_10705": 0, "camel_11302": 0, "camel_11983": 0, "camel_11210": 0, "camel_11336": 0, "camel_10810": 0, "camel_8770": 0, "camel_11457": 0, "camel_11307": 0, "camel_11340": 0, "camel_10493": 0, "camel_8781": 0, "camel_11317": 0, "camel_10694": 0, "camel_11168": 0, "camel_11563": 0, "camel_8771": 0, "camel_11122": 0, "camel_10935": 0, "camel_11003": 0, "camel_10943": 0, "camel_11841": 0, "camel_11192": 0, "camel_8769": 0, "camel_8750": 0, "camel_8759": 0, "camel_9398": 0, "camel_11334": 0, "camel_11346": 0, "camel_11693": 0, "camel_10955": 0, "camel_11218": 0, "camel_11256": 0, "camel_10938": 0, "camel_10557": 0, "camel_8361": 0, "camel_10690": 0, "camel_8782": 0, "camel_11178": 0, "camel_11342": 0, "camel_10958": 0, "camel_11130": 0, "camel_10320": 0, "camel_10907": 0, "camel_11046": 0, "camel_8344": 0, "camel_11306": 0, "camel_10375": 0, "camel_11285": 0, "camel_8789": 0, "camel_11153": 0, "camel_10889": 0, "camel_11036": 0, "camel_10904": 0, "camel_11875": 0, "camel_10984": 0, "camel_10853": 0, "camel_8749": 0, "camel_8387": 0, "camel_10486": 0, "camel_11001": 0, "camel_11420": 0, "camel_11000": 0, "camel_10352": 0, "camel_9521": 0, "camel_8383": 0, "camel_10897": 0, "camel_11067": 0, "camel_11810": 0, "camel_11536": 0, "camel_10911": 0, "camel_11228": 0, "camel_9448": 0, "camel_10494": 0, "camel_11149": 0, "camel_10697": 0, "camel_10666": 0, "camel_11539": 0, "camel_11029": 0, "camel_11057": 0, "camel_11804": 0, "camel_10974": 0, "camel_10996": 0, "camel_8351": 0, "camel_10976": 0, "camel_10816": 0, "camel_11182": 0, "camel_10806": 0, "camel_10920": 0, "camel_11185": 0, "camel_11355": 0, "camel_11027": 0, "camel_11294": 0, "camel_10939": 0, "camel_10364": 0, "camel_10393": 0, "camel_11669": 0, "camel_10998": 0, "camel_11332": 0, "camel_8368": 0, "camel_11325": 0, "camel_10595": 0, "camel_9522": 0, "camel_11617": 0, "camel_10867": 0, "camel_10813": 0, "camel_11127": 0, "camel_10334": 0, "camel_9484": 0, "camel_10979": 0, "camel_11328": 0, "camel_10947": 0, "camel_10870": 0, "camel_11161": 0, "camel_10868": 0, "camel_10351": 0, "camel_11412": 0, "camel_10950": 0, "camel_11558": 0, "camel_11282": 0, "camel_10832": 0, "camel_10800": 0, "camel_8730": 0, "camel_11296": 0, "camel_10808": 0, "camel_10858": 0, "camel_11124": 0, "camel_11323": 0, "camel_10341": 0, "camel_11143": 0, "camel_11322": 0, "camel_11247": 0, "camel_10957": 0, "camel_10371": 0, "camel_11281": 0, "camel_10887": 0, "camel_11365": 0, "camel_11297": 0, "camel_11649": 0, "camel_10919": 0, "camel_10953": 0, "camel_11196": 0, "camel_10966": 0, "camel_11002": 0, "camel_11014": 0, "camel_8747": 0, "camel_10355": 0, "camel_11188": 0, "camel_10941": 0, "camel_11208": 0, "camel_11181": 0, "camel_10930": 0, "camel_11628": 0, "camel_11665": 0, "camel_10895": 0, "camel_11643": 0, "camel_10927": 0, "camel_11154": 0, "camel_10929": 0, "camel_10982": 0, "camel_11605": 0, "camel_11321": 0, "camel_11335": 0, "camel_10918": 0, "camel_10380": 0, "camel_10923": 0, "camel_11189": 0, "camel_11173": 0, "camel_11186": 0, "camel_11633": 0, "camel_10936": 0, "camel_11174": 0, "camel_10944": 0, "camel_11031": 0, "camel_10934": 0, "TheoremQA_xinyi/maximum_entropy_2.json": 0, "camel_11604": 0, "camel_11469": 0, "camel_11293": 0, "camel_24997": 0.6877902746200562, "camel_25543": 0.6916009783744812, "camel_38660": 0.6943906545639038, "camel_38697": 0.6976442337036133, "camel_29080": 0.6985807418823242, "camel_20511": 0.6990857720375061, "camel_38666": 0.7016212940216064, "camel_38643": 0.7094741463661194, "camel_38649": 0.7142678499221802, "camel_38718": 0.7226653695106506, "TheoremQA_xinyi/maximum_entropy_1.json": 0.7276453375816345, "camel_38691": 0.7454390525817871}, "TheoremQA_maxku/signalprocessing11-nyquist.json": {"TheoremQA_maxku/signalprocessing11-nyquist.json": 0, "camel_44512": 0.7328670620918274, "camel_45755": 0.7329328060150146, "camel_45718": 0.7330065369606018, "camel_44490": 0.733328640460968, "camel_44531": 0.7337202429771423, "camel_45600": 0.7337321639060974, "camel_45835": 0.7341093420982361, "camel_44802": 0.7342615127563477, "camel_45771": 0.7344008684158325, "camel_45935": 0.734665036201477, "camel_44552": 0.7350137233734131, "camel_45182": 0.7353941798210144, "TheoremQA_maxku/signalprocessing19-period.json": 0.7355270385742188, "camel_45748": 0.7358385920524597, "camel_44521": 0.7361282706260681, "camel_45352": 0.7361485362052917, "camel_45308": 0.7364122271537781, "camel_45706": 0.7365183234214783, "camel_44442": 0.7367112040519714, "camel_44545": 0.7373424768447876, "camel_45743": 0.7375312447547913, "camel_44494": 0.7375878691673279, "camel_29166": 0.7378702163696289, "camel_45401": 0.7380032539367676, "camel_45949": 0.7381287217140198, "camel_45923": 0.7381932735443115, "camel_45151": 0.7382506132125854, "camel_45320": 0.7382962703704834, "camel_45712": 0.7388038039207458, "camel_45710": 0.7392193675041199, "camel_44864": 0.7401270270347595, "camel_44448": 0.7402690052986145, "camel_45830": 0.7410550713539124, "camel_45766": 0.7418087720870972, "camel_45169": 0.7418408989906311, "camel_45003": 0.7423614263534546, "camel_45654": 0.7425522804260254, "camel_44766": 0.7427929639816284, "camel_45772": 0.7436380386352539, "camel_45789": 0.7437288165092468, "camel_45805": 0.7437625527381897, "camel_44488": 0.743960976600647, "camel_44530": 0.7440091967582703, "camel_44421": 0.7441489100456238, "camel_45725": 0.7442453503608704, "camel_45727": 0.7442983388900757, "camel_45133": 0.7443444132804871, "camel_44550": 0.7443554997444153, "camel_45142": 0.7446662783622742, "camel_45818": 0.7447353601455688, "camel_45948": 0.746131956577301, "camel_45928": 0.7464887499809265, "camel_45996": 0.746527910232544, "camel_45137": 0.7468602061271667, "camel_45939": 0.7472320199012756, "camel_45717": 0.7475618124008179, "camel_44536": 0.747864842414856, "camel_44507": 0.7479881644248962, "camel_44758": 0.7487143874168396, "camel_44429": 0.7492347359657288, "camel_45693": 0.7493446469306946, "camel_45512": 0.7498784065246582, "camel_45690": 0.7498975992202759, "camel_44486": 0.7499284744262695, "camel_45682": 0.7505266666412354, "camel_44526": 0.7506650686264038, "camel_44543": 0.7510582208633423, "camel_45709": 0.7521354556083679, "camel_45815": 0.7524012923240662, "camel_45166": 0.7530375719070435, "camel_45744": 0.7530440092086792, "camel_45342": 0.7533212900161743, "camel_45811": 0.753458559513092, "camel_45786": 0.7535817623138428, "camel_45952": 0.7537928223609924, "camel_44818": 0.7543367743492126, "camel_45492": 0.7555192708969116, "camel_44528": 0.7555374503135681, "camel_44426": 0.7557791471481323, "camel_45782": 0.756085216999054, "camel_45644": 0.756203293800354, "camel_45170": 0.7564225792884827, "camel_45615": 0.7568235397338867, "camel_44517": 0.7576020956039429, "camel_45799": 0.757739245891571, "camel_44506": 0.7581624388694763, "camel_45775": 0.7582775354385376, "camel_44825": 0.7584109902381897, "camel_44061": 0.7585482597351074, "camel_45998": 0.7586031556129456, "camel_45809": 0.7594591975212097, "camel_45936": 0.7597701549530029, "camel_44538": 0.760507345199585, "camel_45812": 0.7605392932891846, "camel_45759": 0.7606179714202881, "camel_45988": 0.7608233690261841, "camel_45130": 0.7612042427062988, "camel_44500": 0.7612468600273132, "camel_44467": 0.7616349458694458, "camel_44462": 0.7619354128837585, "camel_45806": 0.7623609900474548, "camel_45685": 0.7626848220825195, "camel_44466": 0.7628664374351501, "camel_45184": 0.7631267309188843, "camel_45176": 0.7633216977119446, "camel_45680": 0.7634429335594177, "camel_44492": 0.7636457085609436, "camel_45797": 0.763809084892273, "camel_45729": 0.7641236186027527, "camel_44852": 0.764195442199707, "camel_45134": 0.7642451524734497, "camel_44826": 0.7645678520202637, "camel_45791": 0.7646303176879883, "camel_45803": 0.7648998498916626, "camel_45159": 0.7651734352111816, "camel_45788": 0.7652948498725891, "camel_44471": 0.7658030986785889, "camel_45129": 0.7658448815345764, "camel_45684": 0.7661550045013428, "camel_44475": 0.7665014863014221, "camel_45763": 0.7665285468101501, "camel_45162": 0.7675973773002625, "camel_45152": 0.7682978510856628, "camel_45681": 0.7683663964271545, "camel_45754": 0.7684882879257202, "camel_45784": 0.7685025930404663, "camel_44424": 0.7685185670852661, "camel_45314": 0.7689414024353027, "camel_45776": 0.76927649974823, "camel_45155": 0.7694297432899475, "camel_45790": 0.7695172429084778, "camel_44807": 0.7697595357894897, "camel_44544": 0.7698047757148743, "camel_45149": 0.7701733708381653, "camel_45798": 0.7705323696136475, "camel_45173": 0.7707675099372864, "camel_45821": 0.7710941433906555, "camel_44872": 0.7717152237892151, "camel_44473": 0.7717277407646179, "camel_44491": 0.7720227241516113, "camel_45713": 0.7721142172813416, "camel_45198": 0.7723914980888367, "camel_45606": 0.7727093696594238, "camel_45756": 0.7731665372848511, "camel_44523": 0.7733648419380188, "camel_45765": 0.773443341255188, "camel_44401": 0.7740410566329956, "camel_44460": 0.7745548486709595, "camel_44865": 0.7747687697410583, "camel_44861": 0.7751820683479309, "camel_44828": 0.7752206325531006, "camel_44416": 0.775510311126709, "camel_45966": 0.775582492351532, "camel_44851": 0.7758791446685791, "camel_44504": 0.7761979699134827, "camel_44439": 0.777086615562439, "camel_44848": 0.7775571346282959, "camel_44533": 0.7780736684799194, "camel_44846": 0.7787237167358398, "camel_45199": 0.7793662548065186, "camel_44839": 0.7794014811515808, "camel_44534": 0.7795528769493103, "camel_44537": 0.7800335884094238, "camel_45931": 0.7805008292198181, "camel_44447": 0.7835066914558411, "camel_45745": 0.7835291624069214, "camel_44487": 0.7859206199645996, "camel_44554": 0.7861858606338501, "camel_44516": 0.786782443523407, "camel_45604": 0.7879729866981506, "camel_45781": 0.7886214852333069, "camel_45700": 0.789793848991394, "camel_44849": 0.7908096313476562, "camel_44820": 0.7924014329910278, "camel_45792": 0.7926270365715027, "camel_45796": 0.7936712503433228, "camel_44420": 0.7941334247589111, "camel_45607": 0.7945056557655334, "camel_44838": 0.7946483492851257, "camel_44724": 0.7990428805351257, "camel_44498": 0.7997902035713196, "camel_44835": 0.8015670776367188, "camel_45146": 0.8051875233650208, "camel_45646": 0.809605062007904, "camel_44459": 0.809718906879425, "camel_45171": 0.8114162683486938, "camel_45676": 0.8131994605064392, "camel_45819": 0.816588282585144, "camel_44411": 0.8243408203125, "camel_45764": 0.8308154344558716, "camel_44873": 0.8476879000663757, "camel_44400": 0.8545872569084167, "camel_44860": 0.8635342121124268, "camel_45810": 0.8659923076629639, "TheoremQA_maxku/signalprocessing5-nyquist.json": 0.8676730990409851, "camel_45778": 0.8698360323905945, "camel_45807": 0.8839356303215027, "TheoremQA_maxku/signalprocessing10-nyquist.json": 0.8854541778564453, "TheoremQA_maxku/signalprocessing12-nyquist.json": 0.898665726184845}, "TheoremQA_maxku/cv-colorsci2-hsi.json": {"TheoremQA_maxku/cv-colorsci2-hsi.json": 0, "gsm_rft_10110": 0.630369246006012, "camel_41754": 0.6304107904434204, "aqua_rat_24258": 0.6304268836975098, "camel_44416": 0.6304559111595154, "camel_8523": 0.6304923892021179, "aqua_rat_28696": 0.6304963827133179, "camel_16581": 0.6305615901947021, "aqua_rat_1592": 0.6306694149971008, "camel_9150": 0.630711019039154, "camel_41746": 0.6307401061058044, "aqua_rat_7349": 0.6308002471923828, "gsm_rft_25914": 0.6309587359428406, "aqua_rat_49468": 0.6309774518013, "aqua_rat_9968": 0.6310555934906006, "camel_44839": 0.6310583353042603, "gsm_rft_28078": 0.6311371326446533, "camel_44401": 0.6311637759208679, "aqua_rat_24370": 0.6311758756637573, "aqua_rat_63615": 0.6312673091888428, "aqua_rat_28773": 0.6313559412956238, "gsm_train_4698": 0.6313812732696533, "camel_38481": 0.6313928961753845, "gsm_rft_26010": 0.6315194368362427, "aqua_rat_83310": 0.6315361261367798, "aqua_rat_73083": 0.6316109299659729, "aqua_rat_76198": 0.6317106485366821, "aqua_rat_53630": 0.6317738890647888, "aqua_rat_45999": 0.6317903399467468, "aqua_rat_46351": 0.6317911744117737, "aqua_rat_6253": 0.6318866014480591, "aqua_rat_77635": 0.6319440007209778, "camel_38813": 0.6320402026176453, "aqua_rat_85798": 0.6321409344673157, "camel_17238": 0.6322140693664551, "aqua_rat_42920": 0.6323109865188599, "camel_45159": 0.6323139071464539, "aqua_rat_37501": 0.6323463916778564, "aqua_rat_78840": 0.6325848698616028, "aqua_rat_49873": 0.6326441764831543, "camel_8867": 0.6326577663421631, "camel_41735": 0.6327364444732666, "aqua_rat_919": 0.6327983736991882, "camel_8234": 0.6329188346862793, "aqua_rat_8536": 0.6329472064971924, "gsm_rft_2184": 0.633010745048523, "gsm_train_8181": 0.633010745048523, "camel_43765": 0.6330438852310181, "camel_25549": 0.6331371665000916, "camel_16624": 0.6331605315208435, "aqua_rat_55448": 0.6332720518112183, "aqua_rat_14902": 0.6332767605781555, "aqua_rat_17160": 0.6333351135253906, "gsm_rft_1939": 0.6337120532989502, "gsm_train_31158": 0.6337120532989502, "camel_16608": 0.6337192058563232, "aqua_rat_29552": 0.6338076591491699, "aqua_rat_54734": 0.6339071989059448, "aqua_rat_77712": 0.6339470744132996, "aqua_rat_62882": 0.6339843273162842, "aqua_rat_54902": 0.6340226531028748, "aqua_rat_20810": 0.6341152191162109, "camel_8718": 0.6341223120689392, "camel_45616": 0.6341370940208435, "camel_45196": 0.6341489553451538, "camel_44548": 0.6343362331390381, "aqua_rat_24775": 0.6344899535179138, "camel_19844": 0.6345946788787842, "camel_41737": 0.6346116662025452, "gsm_rft_4511": 0.6346697807312012, "aqua_rat_79885": 0.6347775459289551, "camel_45611": 0.6348327994346619, "gsm_rft_17141": 0.6348681449890137, "camel_29451": 0.6348961591720581, "aqua_rat_7207": 0.634936511516571, "camel_18695": 0.6349916458129883, "gsm_train_1174": 0.6349943280220032, "gsm_rft_33186": 0.6349943280220032, "aqua_rat_19930": 0.6350745558738708, "aqua_rat_30572": 0.6351874470710754, "camel_8686": 0.635277271270752, "camel_45655": 0.6353116631507874, "camel_41723": 0.6353340744972229, "TheoremQA_tonyxia/semiconductor3.json": 0.635513961315155, "gsm_train_18516": 0.6356537342071533, "gsm_rft_28497": 0.6356537342071533, "camel_45737": 0.6357546448707581, "aqua_rat_35674": 0.6358834505081177, "camel_41704": 0.6359511613845825, "aqua_rat_3582": 0.636246383190155, "aqua_rat_757": 0.6363733410835266, "camel_41745": 0.636551022529602, "camel_41682": 0.6365751028060913, "aqua_rat_0": 0.6365783214569092, "aqua_rat_45234": 0.6367045044898987, "gsm_rft_35481": 0.6367854475975037, "camel_30264": 0.6370779871940613, "aqua_rat_32105": 0.6371455788612366, "aqua_rat_10714": 0.6372811198234558, "gsm_rft_33530": 0.6373199820518494, "aqua_rat_4235": 0.637461245059967, "aqua_rat_53680": 0.637480616569519, "aqua_rat_42167": 0.6375895142555237, "aqua_rat_83549": 0.6378278732299805, "camel_45818": 0.637832760810852, "aqua_rat_55747": 0.6378500461578369, "camel_45958": 0.6379076242446899, "camel_19873": 0.637946367263794, "gsm_rft_28624": 0.6379768252372742, "aqua_rat_35152": 0.6379803419113159, "aqua_rat_73394": 0.6380857229232788, "camel_45935": 0.6381330490112305, "aqua_rat_3306": 0.6382249593734741, "aqua_rat_63453": 0.6385485529899597, "TheoremQA_tonyxia/semiconductor2.json": 0.6387559771537781, "gsm_rft_20711": 0.6390178203582764, "aqua_rat_81243": 0.6390306353569031, "camel_41700": 0.6391037106513977, "gsm_rft_14572": 0.6393364071846008, "gsm_rft_33507": 0.6393364071846008, "gsm_rft_11166": 0.6393364071846008, "gsm_train_31881": 0.6393364071846008, "camel_8253": 0.6394026279449463, "TheoremQA_tonyxia/photoelectric1.json": 0.6396434307098389, "aqua_rat_17134": 0.639657199382782, "aqua_rat_33202": 0.6397897005081177, "aqua_rat_36121": 0.640052855014801, "aqua_rat_76667": 0.6400781869888306, "aqua_rat_10612": 0.6401069164276123, "camel_45033": 0.6401434540748596, "camel_45131": 0.6402425765991211, "aqua_rat_25321": 0.6403515338897705, "aqua_rat_37746": 0.6404232978820801, "camel_45931": 0.6404606699943542, "camel_45836": 0.6406134963035583, "aqua_rat_62930": 0.6406723856925964, "aqua_rat_22474": 0.6408864259719849, "camel_45750": 0.6408995985984802, "aqua_rat_79833": 0.6409424543380737, "camel_45960": 0.6410902738571167, "aqua_rat_56122": 0.6418898701667786, "camel_16164": 0.6418922543525696, "camel_45657": 0.6419278979301453, "aqua_rat_33534": 0.642056405544281, "aqua_rat_65851": 0.642212986946106, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0.642349123954773, "aqua_rat_85998": 0.6423975825309753, "aqua_rat_37912": 0.6427404880523682, "aqua_rat_82138": 0.6428125500679016, "camel_45700": 0.6431195139884949, "camel_41741": 0.6435105800628662, "TheoremQA_maxku/cv-imageprocessing6-histogram.json": 0.6435222625732422, "camel_41743": 0.6439415812492371, "camel_45323": 0.6441367268562317, "camel_17234": 0.6446126699447632, "camel_41750": 0.6448046565055847, "aqua_rat_2273": 0.6450206637382507, "aqua_rat_66988": 0.6450619101524353, "camel_9134": 0.6454280018806458, "camel_16214": 0.6456039547920227, "aqua_rat_74144": 0.646898090839386, "aqua_rat_69297": 0.646925687789917, "camel_45998": 0.6471981406211853, "camel_39021": 0.6472074389457703, "aqua_rat_87580": 0.6482369899749756, "camel_45651": 0.6489855051040649, "camel_44731": 0.6491948366165161, "camel_41720": 0.6501639485359192, "aqua_rat_81336": 0.6502498388290405, "camel_45314": 0.6503941416740417, "TheoremQA_maxku/signalprocessing2-DB.json": 0.6507522463798523, "camel_45809": 0.6509683132171631, "camel_45677": 0.6511596441268921, "aqua_rat_36347": 0.6526445746421814, "gsm_rft_33471": 0.6529273390769958, "camel_45334": 0.6546717286109924, "aqua_rat_54325": 0.6549062728881836, "aqua_rat_79294": 0.6549813151359558, "camel_45634": 0.6552170515060425, "camel_45181": 0.6556006669998169, "aqua_rat_80350": 0.6556216478347778, "camel_9133": 0.6561214923858643, "camel_28935": 0.6561745405197144, "aqua_rat_61003": 0.6562385559082031, "camel_44806": 0.656434953212738, "TheoremQA_maxku/cv-imageprocessing10-digital-image.json": 0.6571087837219238, "TheoremQA_maxku/cv-colorsci1-rgb.json": 0.6578306555747986, "camel_45637": 0.6595120429992676, "aqua_rat_42817": 0.6674134135246277, "aqua_rat_65183": 0.6712696552276611, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.6754176616668701, "camel_44543": 0.6797691583633423, "aqua_rat_31331": 0.6866049766540527, "aqua_rat_4231": 0.6869643330574036, "camel_44741": 0.6875339150428772, "aqua_rat_79408": 0.6902655959129333, "aqua_rat_48550": 0.691155195236206, "aqua_rat_18575": 0.6913461089134216, "TheoremQA_maxku/cv-colorsci4-hsi.json": 0.7599526047706604, "TheoremQA_maxku/cv-colorsci3-rgb.json": 0.7669754028320312}, "TheoremQA_jianyu_xu/Stirling_number_first_kind_5.json": {"camel_20523": 0, "camel_20377": 0, "camel_20967": 0, "camel_20468": 0, "camel_20309": 0, "camel_20808": 0, "camel_20611": 0, "camel_20540": 0, "camel_20627": 0, "camel_20988": 0, "camel_21049": 0, "camel_21042": 0, "camel_20392": 0, "camel_21228": 0, "camel_21200": 0, "camel_20787": 0, "camel_21039": 0, "camel_20572": 0, "camel_20638": 0, "camel_21269": 0, "camel_20398": 0, "camel_20255": 0, "camel_21138": 0, "camel_21028": 0, "camel_21085": 0, "camel_21431": 0, "camel_20244": 0, "camel_21266": 0, "camel_20339": 0, "aqua_rat_10539": 0.8108254671096802, "math_test_counting_and_probability_616": 0.8108567595481873, "aqua_rat_75260": 0.810929000377655, "aqua_rat_56902": 0.8109647035598755, "math_train_counting_and_probability_420": 0.8109805583953857, "aqua_rat_34248": 0.8110225200653076, "aqua_rat_34946": 0.8110634684562683, "aqua_rat_16653": 0.8112183213233948, "aqua_rat_77478": 0.8113055229187012, "aqua_rat_35816": 0.8115068674087524, "aqua_rat_26914": 0.8117579817771912, "aqua_rat_42815": 0.8117722868919373, "aqua_rat_36934": 0.8118129968643188, "aqua_rat_60555": 0.8118540644645691, "aqua_rat_31691": 0.8120298981666565, "math_test_counting_and_probability_1046": 0.8123505711555481, "aqua_rat_88292": 0.8123692274093628, "aqua_rat_72606": 0.8123883008956909, "aqua_rat_57838": 0.8124064207077026, "aqua_rat_41028": 0.8125740885734558, "aqua_rat_17041": 0.812646746635437, "aqua_rat_84091": 0.8129504323005676, "aqua_rat_36287": 0.8134907484054565, "aqua_rat_83838": 0.8135893940925598, "aqua_rat_8977": 0.8137180209159851, "aqua_rat_23141": 0.8137203454971313, "math_train_counting_and_probability_149": 0.8138108849525452, "aqua_rat_73132": 0.8138455152511597, "aqua_rat_42992": 0.8138629198074341, "math_test_counting_and_probability_103": 0.8139269948005676, "aqua_rat_65989": 0.8139685988426208, "aqua_rat_21315": 0.8139724135398865, "aqua_rat_9397": 0.8142396211624146, "aqua_rat_33427": 0.814322292804718, "math_test_counting_and_probability_508": 0.8143544793128967, "aqua_rat_55626": 0.8147001266479492, "aqua_rat_59919": 0.8148461580276489, "aqua_rat_47540": 0.8150039315223694, "aqua_rat_38586": 0.8152313232421875, "aqua_rat_9314": 0.8153232336044312, "aqua_rat_53826": 0.8153243064880371, "aqua_rat_14532": 0.8154112696647644, "aqua_rat_84159": 0.815481960773468, "aqua_rat_52342": 0.8154836893081665, "aqua_rat_24679": 0.8155778646469116, "aqua_rat_57287": 0.8156585693359375, "aqua_rat_31631": 0.815696656703949, "aqua_rat_30736": 0.8157170414924622, "aqua_rat_15706": 0.815742015838623, "aqua_rat_71277": 0.8157562613487244, "aqua_rat_53858": 0.8158359527587891, "aqua_rat_44084": 0.8159574866294861, "aqua_rat_30581": 0.816265881061554, "aqua_rat_83158": 0.8163793683052063, "aqua_rat_88068": 0.816475510597229, "aqua_rat_31826": 0.8165271282196045, "aqua_rat_78109": 0.8167974948883057, "aqua_rat_42973": 0.8169642090797424, "aqua_rat_40898": 0.8172022700309753, "aqua_rat_32829": 0.8172234296798706, "aqua_rat_75334": 0.8172895312309265, "aqua_rat_87694": 0.8173317909240723, "math_train_counting_and_probability_466": 0.8173622488975525, "math_train_counting_and_probability_756": 0.817413866519928, "TheoremQA_jianyu_xu/Multinomial_2.json": 0.8175501227378845, "aqua_rat_30941": 0.8177303075790405, "aqua_rat_34075": 0.8177581429481506, "aqua_rat_15112": 0.8180006742477417, "aqua_rat_58579": 0.8181410431861877, "aqua_rat_19322": 0.8181643486022949, "aqua_rat_83547": 0.8182457089424133, "aqua_rat_53699": 0.8183674812316895, "aqua_rat_34469": 0.8185185194015503, "aqua_rat_66532": 0.818523645401001, "aqua_rat_46786": 0.8186376690864563, "math_train_prealgebra_1075": 0.8186390995979309, "aqua_rat_49411": 0.8188695907592773, "aqua_rat_54367": 0.8188984990119934, "aqua_rat_32973": 0.8192026615142822, "aqua_rat_26378": 0.8194587230682373, "aqua_rat_13247": 0.8195080757141113, "aqua_rat_15403": 0.8196232914924622, "aqua_rat_62566": 0.819641649723053, "aqua_rat_53909": 0.8197117447853088, "aqua_rat_47326": 0.8201147317886353, "math_test_counting_and_probability_485": 0.8201799988746643, "aqua_rat_23721": 0.8202025890350342, "math_test_counting_and_probability_159": 0.8203833103179932, "aqua_rat_58987": 0.8204095959663391, "math_test_counting_and_probability_416": 0.8210931420326233, "aqua_rat_77867": 0.821447491645813, "aqua_rat_52067": 0.8215323686599731, "aqua_rat_65738": 0.8216398358345032, "aqua_rat_2473": 0.8220341801643372, "aqua_rat_68730": 0.8223270177841187, "aqua_rat_6563": 0.8223901987075806, "aqua_rat_30957": 0.8231539726257324, "aqua_rat_6212": 0.8237919211387634, "aqua_rat_70412": 0.8241946697235107, "aqua_rat_66827": 0.8244098424911499, "aqua_rat_71566": 0.8245716691017151, "aqua_rat_56829": 0.8247193694114685, "aqua_rat_67521": 0.8247626423835754, "aqua_rat_19604": 0.824770450592041, "math_test_counting_and_probability_748": 0.8248181343078613, "aqua_rat_36385": 0.8248960971832275, "aqua_rat_50479": 0.8252626061439514, "aqua_rat_19025": 0.8255335688591003, "aqua_rat_79349": 0.8255720734596252, "aqua_rat_9762": 0.8260071873664856, "aqua_rat_71410": 0.8260177969932556, "aqua_rat_5131": 0.8260255455970764, "aqua_rat_54776": 0.8266634941101074, "aqua_rat_15820": 0.8272333145141602, "aqua_rat_11490": 0.8272368907928467, "aqua_rat_76556": 0.8275269269943237, "aqua_rat_36803": 0.8277578949928284, "aqua_rat_30701": 0.8278778791427612, "aqua_rat_60744": 0.8279591202735901, "aqua_rat_12956": 0.8281346559524536, "aqua_rat_55263": 0.8281425833702087, "aqua_rat_75364": 0.8284366130828857, "aqua_rat_55783": 0.829135537147522, "aqua_rat_15927": 0.8295260071754456, "aqua_rat_65667": 0.82961106300354, "aqua_rat_16904": 0.8296289443969727, "aqua_rat_48706": 0.8297070264816284, "math_test_counting_and_probability_341": 0.8297158479690552, "aqua_rat_63513": 0.829821765422821, "aqua_rat_77763": 0.8298617005348206, "aqua_rat_79755": 0.8315756320953369, "aqua_rat_797": 0.8318524956703186, "aqua_rat_51466": 0.8318890333175659, "aqua_rat_34059": 0.8319016098976135, "aqua_rat_40108": 0.8322572708129883, "aqua_rat_7440": 0.8323984742164612, "math_train_counting_and_probability_22": 0.8330195546150208, "aqua_rat_64944": 0.8330496549606323, "aqua_rat_7248": 0.8331809043884277, "aqua_rat_13921": 0.8333721160888672, "aqua_rat_34628": 0.83371502161026, "aqua_rat_88490": 0.8338267207145691, "aqua_rat_74550": 0.8340084552764893, "aqua_rat_21868": 0.8340564966201782, "aqua_rat_18404": 0.8340572714805603, "aqua_rat_9085": 0.8345098495483398, "aqua_rat_56019": 0.8349078893661499, "aqua_rat_89113": 0.8350650668144226, "aqua_rat_22747": 0.8354666829109192, "aqua_rat_9727": 0.8356940150260925, "aqua_rat_16877": 0.8359856009483337, "aqua_rat_35588": 0.8360151648521423, "aqua_rat_4294": 0.8360794186592102, "aqua_rat_62238": 0.8360999822616577, "aqua_rat_61885": 0.8361731171607971, "aqua_rat_59912": 0.8362381458282471, "aqua_rat_43496": 0.8362890481948853, "aqua_rat_10096": 0.8376172780990601, "aqua_rat_29651": 0.8382349014282227, "aqua_rat_2480": 0.8382603526115417, "aqua_rat_26470": 0.8388679623603821, "aqua_rat_39088": 0.8390442132949829, "aqua_rat_73402": 0.8393402099609375, "aqua_rat_70081": 0.841631293296814, "aqua_rat_56498": 0.8435524106025696, "aqua_rat_34678": 0.8445104956626892, "aqua_rat_73122": 0.8452541828155518, "aqua_rat_13585": 0.8463577032089233, "aqua_rat_60936": 0.8470523953437805, "aqua_rat_68736": 0.8482723832130432, "aqua_rat_81367": 0.8489625453948975}, "TheoremQA_tonyxia/euler-graph3.json": {"camel_22907": 0, "camel_23881": 0, "camel_22619": 0, "camel_23850": 0, "camel_23896": 0, "camel_22932": 0, "camel_23902": 0, "camel_23906": 0, "camel_22638": 0, "camel_22601": 0, "camel_23915": 0, "camel_23865": 0, "camel_23913": 0, "camel_23880": 0, "camel_22636": 0, "camel_23890": 0, "camel_23872": 0, "camel_22593": 0, "camel_23899": 0, "camel_23843": 0, "camel_23845": 0, "camel_23918": 0, "camel_23894": 0, "camel_22564": 0, "camel_23911": 0, "camel_22563": 0, "camel_23887": 0, "camel_22632": 0, "camel_22574": 0, "camel_22621": 0, "camel_20780": 0, "camel_23857": 0, "camel_22588": 0, "camel_23904": 0, "camel_23864": 0, "camel_22578": 0, "camel_22634": 0, "camel_22600": 0, "camel_23874": 0, "camel_22560": 0, "camel_22572": 0, "camel_22625": 0, "camel_23856": 0, "camel_23908": 0, "camel_23852": 0, "camel_23907": 0, "camel_23891": 0, "camel_23868": 0, "camel_23912": 0, "camel_23888": 0, "camel_23869": 0, "camel_23847": 0, "camel_22631": 0, "camel_23884": 0, "camel_22607": 0, "camel_22897": 0, "camel_22603": 0, "camel_23873": 0, "camel_22577": 0, "camel_23849": 0, "camel_22562": 0, "camel_22580": 0, "camel_23900": 0, "camel_23877": 0, "camel_22630": 0, "camel_23841": 0, "camel_22561": 0, "camel_23876": 0, "camel_23910": 0, "camel_22605": 0, "camel_22614": 0, "camel_22637": 0, "camel_22610": 0, "camel_23871": 0, "camel_23863": 0, "camel_23870": 0, "camel_23844": 0, "camel_22589": 0, "camel_23859": 0, "camel_22604": 0, "camel_22581": 0, "camel_22586": 0, "camel_22594": 0, "camel_23889": 0, "camel_22635": 0, "camel_23842": 0, "camel_23879": 0, "camel_22595": 0, "camel_22575": 0, "camel_22598": 0, "camel_23866": 0, "camel_22606": 0, "camel_22599": 0, "camel_23878": 0, "camel_23848": 0, "camel_23919": 0, "camel_23901": 0, "camel_23875": 0, "camel_23840": 0, "camel_23916": 0, "camel_22565": 0, "camel_23917": 0, "TheoremQA_tonyxia/euler-graph3.json": 0, "camel_23846": 0, "camel_22584": 0, "camel_23862": 0, "camel_23903": 0, "camel_23909": 0, "camel_23893": 0, "camel_22609": 0, "camel_22568": 0, "camel_23867": 0, "camel_23905": 0, "camel_23861": 0, "camel_22616": 0, "camel_22569": 0, "camel_23898": 0, "camel_22567": 0, "camel_22624": 0, "camel_22587": 0, "camel_22591": 0, "camel_22622": 0, "camel_22623": 0, "camel_22592": 0, "camel_22626": 0, "camel_22639": 0, "camel_22576": 0, "camel_22617": 0, "math_test_geometry_188": 0.7137782573699951, "camel_18626": 0.7140188813209534, "camel_19970": 0.7140809297561646, "gsm_rft_22050": 0.7145764827728271, "camel_18693": 0.7161782383918762, "aqua_rat_57205": 0.7179279327392578, "camel_18624": 0.7194214463233948, "camel_18569": 0.7199023365974426, "aqua_rat_12891": 0.7208906412124634, "camel_18598": 0.7232186794281006, "camel_18656": 0.7234339118003845, "camel_18664": 0.7238538265228271, "gsm_rft_4437": 0.7245557904243469, "gsm_train_15934": 0.7245557904243469, "gsm_rft_25274": 0.7247291207313538, "aqua_rat_80197": 0.725409746170044, "aqua_rat_5243": 0.7257393002510071, "camel_18639": 0.7272292375564575, "aqua_rat_87384": 0.7277255058288574, "aqua_rat_50585": 0.7278175354003906, "camel_18692": 0.7278512716293335, "aqua_rat_37055": 0.7291193008422852, "math_train_geometry_821": 0.7305371761322021, "math_test_geometry_154": 0.7311989068984985, "camel_18636": 0.7317990064620972, "aqua_rat_15736": 0.7349404692649841, "gsm_rft_4179": 0.7363489270210266, "camel_18643": 0.7370899319648743, "aqua_rat_21290": 0.7372040748596191, "camel_18634": 0.739475429058075, "camel_18638": 0.7397486567497253, "math_test_geometry_217": 0.7404896020889282, "camel_18831": 0.743267834186554, "math_test_geometry_713": 0.7459000945091248, "math_train_geometry_758": 0.748894214630127, "math_test_counting_and_probability_385": 0.7512272000312805, "aqua_rat_49777": 0.7521694898605347, "camel_18715": 0.7531575560569763, "camel_18673": 0.7540211081504822, "aqua_rat_16933": 0.7550380825996399, "camel_19812": 0.7557276487350464, "camel_18675": 0.7573902010917664, "camel_18964": 0.7574357390403748, "math_train_geometry_6085": 0.7599559426307678, "camel_19723": 0.7606505155563354, "camel_18644": 0.763363242149353, "camel_18674": 0.7635146379470825, "aqua_rat_551": 0.7656946778297424, "camel_18688": 0.7659388184547424, "aqua_rat_72587": 0.7672712802886963, "camel_18662": 0.7694317698478699, "aqua_rat_23171": 0.7709593176841736, "math_train_prealgebra_519": 0.7738093137741089, "camel_18686": 0.7770317792892456, "camel_18711": 0.7778318524360657, "camel_18608": 0.7789180874824524, "camel_18717": 0.7789231538772583, "TheoremQA_tonyxia/maxplanar1.json": 0.7819648385047913, "camel_18659": 0.7821938991546631, "camel_18627": 0.7828293442726135, "camel_18652": 0.7878639698028564, "camel_19741": 0.7944448590278625, "camel_19888": 0.795500636100769, "TheoremQA_tonyxia/maxplanar3.json": 0.7987775802612305, "TheoremQA_tonyxia/euler-graph2.json": 0.8002285361289978, "camel_18701": 0.8003936409950256, "camel_18677": 0.8005346655845642, "camel_18672": 0.8010362386703491, "camel_18699": 0.8078306317329407, "camel_18658": 0.8148610591888428, "camel_18679": 0.8230212330818176, "math_train_geometry_6025": 0.8296273946762085}, "TheoremQA_xueguangma/forward_price_2.json": {"TheoremQA_xueguangma/forward_price_2.json": 0, "gsm_rft_23519": 0.7081440091133118, "aqua_rat_73739": 0.7081629037857056, "aqua_rat_39503": 0.7082149386405945, "gsm_rft_2033": 0.7082598805427551, "gsm_rft_11850": 0.708365797996521, "gsm_rft_31288": 0.7084774971008301, "aqua_rat_46883": 0.7085728645324707, "aqua_rat_3885": 0.7085868716239929, "gsm_rft_34919": 0.7086589932441711, "aqua_rat_18811": 0.7087063193321228, "gsm_rft_34866": 0.7088949680328369, "aqua_rat_55974": 0.7092089056968689, "gsm_rft_33801": 0.7092630863189697, "aqua_rat_23836": 0.7092768549919128, "gsm_rft_1289": 0.7093502879142761, "aqua_rat_1058": 0.7098725438117981, "aqua_rat_4548": 0.709891140460968, "gsm_rft_22041": 0.709902822971344, "gsm_train_24478": 0.709902822971344, "aqua_rat_60803": 0.7099223136901855, "aqua_rat_60935": 0.7099613547325134, "gsm_rft_29683": 0.7100088596343994, "aqua_rat_78719": 0.7103176712989807, "aqua_rat_46315": 0.7103291153907776, "camel_16789": 0.7103480696678162, "aqua_rat_45867": 0.7103900909423828, "aqua_rat_11679": 0.7104030847549438, "gsm_rft_6751": 0.7104711532592773, "gsm_train_34638": 0.7104711532592773, "aqua_rat_74914": 0.710635781288147, "gsm_rft_31646": 0.7106740474700928, "gsm_rft_33054": 0.7106903195381165, "gsm_rft_32819": 0.7107839584350586, "gsm_rft_17013": 0.7108474969863892, "gsm_rft_20077": 0.7108474969863892, "gsm_train_17940": 0.7108726501464844, "aqua_rat_37392": 0.7109411954879761, "aqua_rat_11544": 0.7112710475921631, "aqua_rat_15749": 0.7114158868789673, "aqua_rat_72737": 0.7114555239677429, "gsm_rft_1239": 0.7115170359611511, "aqua_rat_63067": 0.7115793824195862, "aqua_rat_65883": 0.7117164134979248, "aqua_rat_73408": 0.7117378115653992, "aqua_rat_16445": 0.7117480635643005, "gsm_rft_34374": 0.7119810581207275, "gsm_rft_20558": 0.7122385501861572, "gsm_train_21876": 0.7123723030090332, "gsm_rft_15888": 0.7123723030090332, "aqua_rat_611": 0.7125734090805054, "gsm_rft_33978": 0.7126242518424988, "gsm_train_34054": 0.7126242518424988, "aqua_rat_67442": 0.712717592716217, "gsm_rft_7079": 0.7127403616905212, "aqua_rat_37299": 0.7130060195922852, "gsm_rft_12005": 0.7130926847457886, "gsm_rft_14240": 0.7132031917572021, "aqua_rat_36461": 0.7132784128189087, "gsm_rft_25377": 0.7132838368415833, "aqua_rat_71911": 0.7135716080665588, "gsm_rft_3126": 0.7136610150337219, "gsm_rft_34423": 0.7137688398361206, "aqua_rat_9874": 0.7138715982437134, "gsm_rft_34181": 0.7138745188713074, "gsm_rft_7026": 0.7139066457748413, "aqua_rat_20758": 0.7143217921257019, "gsm_rft_6203": 0.7147316932678223, "TheoremQA_xueguangma/present_value_2.json": 0.7150169610977173, "gsm_rft_21062": 0.7151433229446411, "aqua_rat_88843": 0.715646505355835, "gsm_train_30707": 0.7156701683998108, "gsm_rft_22572": 0.716479480266571, "aqua_rat_16258": 0.7165400981903076, "aqua_rat_9530": 0.7166248559951782, "gsm_rft_28287": 0.7166669964790344, "gsm_rft_20456": 0.7167947292327881, "gsm_rft_32168": 0.7171351313591003, "aqua_rat_78570": 0.7172049283981323, "aqua_rat_37203": 0.7172496318817139, "gsm_rft_26543": 0.7173571586608887, "aqua_rat_42852": 0.7173720002174377, "aqua_rat_79047": 0.7173923254013062, "gsm_train_2595": 0.7174702882766724, "gsm_rft_9581": 0.7174981832504272, "aqua_rat_56436": 0.7175730466842651, "aqua_rat_6475": 0.7177175879478455, "gsm_rft_35170": 0.717726469039917, "aqua_rat_87442": 0.7181785702705383, "gsm_rft_11628": 0.7182059288024902, "gsm_rft_19903": 0.7183122038841248, "gsm_rft_21130": 0.7183122038841248, "gsm_train_12933": 0.7183122038841248, "aqua_rat_87484": 0.7192630171775818, "gsm_train_4924": 0.7197646498680115, "gsm_rft_10641": 0.7197646498680115, "gsm_rft_24735": 0.7198235988616943, "aqua_rat_56718": 0.7202180624008179, "aqua_rat_10200": 0.7202410697937012, "gsm_rft_15020": 0.7204871773719788, "gsm_rft_7891": 0.7205193042755127, "gsm_rft_24249": 0.7205926179885864, "gsm_rft_33006": 0.7207320332527161, "gsm_train_34036": 0.7212718725204468, "gsm_rft_30946": 0.7212718725204468, "gsm_rft_7924": 0.7213202714920044, "gsm_train_22362": 0.7213202714920044, "aqua_rat_30597": 0.7214184999465942, "math_train_algebra_940": 0.7214611172676086, "gsm_rft_32767": 0.7216142416000366, "gsm_rft_3173": 0.7216290235519409, "gsm_rft_287": 0.7216290235519409, "gsm_train_17061": 0.7216290235519409, "gsm_rft_20212": 0.7216302752494812, "aqua_rat_54684": 0.7221598029136658, "gsm_rft_18143": 0.722178041934967, "gsm_rft_19766": 0.7228641510009766, "aqua_rat_78193": 0.7230094075202942, "aqua_rat_45263": 0.7230275273323059, "aqua_rat_67914": 0.7232232093811035, "gsm_rft_15946": 0.7235944867134094, "aqua_rat_37463": 0.7236651182174683, "aqua_rat_74243": 0.7238818407058716, "aqua_rat_38648": 0.724058985710144, "aqua_rat_6634": 0.724233090877533, "gsm_rft_9014": 0.7242672443389893, "aqua_rat_15556": 0.7243698835372925, "aqua_rat_65797": 0.7245430946350098, "aqua_rat_26022": 0.7245838642120361, "gsm_rft_9128": 0.7246052026748657, "aqua_rat_16875": 0.7247324585914612, "aqua_rat_59199": 0.7249918580055237, "aqua_rat_57507": 0.7251672148704529, "aqua_rat_84779": 0.7256131172180176, "aqua_rat_50660": 0.7257086038589478, "aqua_rat_9033": 0.725867748260498, "aqua_rat_78533": 0.7259690761566162, "aqua_rat_47761": 0.7260345816612244, "aqua_rat_77609": 0.7263561487197876, "gsm_rft_33617": 0.7267122268676758, "gsm_rft_32019": 0.7268644571304321, "aqua_rat_40411": 0.7268965840339661, "aqua_rat_32321": 0.727314829826355, "aqua_rat_77105": 0.7274274230003357, "gsm_rft_8126": 0.7275952696800232, "aqua_rat_26425": 0.7277262806892395, "gsm_rft_30907": 0.727886438369751, "gsm_rft_33659": 0.7283234000205994, "aqua_rat_84306": 0.728839099407196, "gsm_rft_17545": 0.7291262149810791, "gsm_rft_25508": 0.7291924953460693, "gsm_train_22552": 0.7291924953460693, "aqua_rat_1115": 0.729248046875, "aqua_rat_45586": 0.7293028235435486, "gsm_rft_3411": 0.7294468283653259, "aqua_rat_26043": 0.7297807335853577, "gsm_rft_5014": 0.7303422689437866, "gsm_train_7824": 0.7303611636161804, "gsm_rft_10732": 0.7303611636161804, "gsm_rft_11804": 0.7310643196105957, "gsm_train_6037": 0.7311022877693176, "gsm_rft_15334": 0.7311022877693176, "gsm_rft_33880": 0.7314474582672119, "gsm_rft_23260": 0.7340227961540222, "gsm_rft_1672": 0.7342075109481812, "aqua_rat_56845": 0.734571635723114, "TheoremQA_xueguangma/present_value_1.json": 0.734731912612915, "gsm_rft_27542": 0.7348637580871582, "gsm_rft_7096": 0.7348841428756714, "gsm_train_3010": 0.7353011965751648, "aqua_rat_64523": 0.7364725470542908, "aqua_rat_70160": 0.7365236282348633, "gsm_rft_6422": 0.7376041412353516, "camel_37735": 0.7377921342849731, "gsm_rft_16062": 0.7389219999313354, "gsm_rft_25231": 0.7393391728401184, "gsm_train_19719": 0.7393391728401184, "aqua_rat_63735": 0.7395069599151611, "aqua_rat_84646": 0.7406303286552429, "aqua_rat_6283": 0.742293655872345, "aqua_rat_23277": 0.7449034452438354, "aqua_rat_80676": 0.7471893429756165, "aqua_rat_24182": 0.7475089430809021, "aqua_rat_48160": 0.7495868802070618, "aqua_rat_34081": 0.7496257424354553, "aqua_rat_49352": 0.7550103664398193, "aqua_rat_36498": 0.7570809721946716, "camel_16747": 0.7600441575050354, "aqua_rat_79856": 0.7640202045440674, "aqua_rat_29154": 0.7729604244232178, "aqua_rat_85902": 0.7740215063095093, "aqua_rat_31553": 0.7780143618583679, "TheoremQA_xueguangma/forward_price_3.json": 0.785787045955658, "camel_45738": 0.7882243394851685, "aqua_rat_45508": 0.7907293438911438, "camel_45730": 0.79681795835495, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.8024167418479919, "TheoremQA_xueguangma/put_call_parity_1.json": 0.8101513385772705, "TheoremQA_xueguangma/spot_rate.json": 0.8161751627922058, "TheoremQA_xueguangma/forward_price_1.json": 0.8302727341651917}, "TheoremQA_maxku/ipnetwork13-hammingdist.json": {"TheoremQA_maxku/ipnetwork13-hammingdist.json": 0, "aqua_rat_44305": 0.7191413044929504, "aqua_rat_22563": 0.7191841006278992, "aqua_rat_8833": 0.7192959189414978, "aqua_rat_15961": 0.719302773475647, "aqua_rat_48668": 0.7193369269371033, "aqua_rat_62699": 0.7194634079933167, "aqua_rat_1157": 0.7194915413856506, "aqua_rat_51171": 0.7195734977722168, "aqua_rat_62024": 0.7195926904678345, "aqua_rat_31336": 0.7196013331413269, "aqua_rat_85488": 0.7196184992790222, "camel_21992": 0.7196285128593445, "aqua_rat_45147": 0.719701886177063, "gsm_rft_14709": 0.7197578549385071, "gsm_rft_9771": 0.7197578549385071, "gsm_train_9366": 0.7197578549385071, "gsm_rft_6312": 0.7198306322097778, "aqua_rat_80982": 0.7198918461799622, "aqua_rat_8968": 0.7199004292488098, "aqua_rat_12317": 0.7199079990386963, "aqua_rat_81021": 0.7199167013168335, "camel_36368": 0.7199695706367493, "camel_20512": 0.7199885845184326, "aqua_rat_2817": 0.7199917435646057, "aqua_rat_27645": 0.7200178503990173, "gsm_rft_35121": 0.7200573682785034, "aqua_rat_19653": 0.7200605273246765, "aqua_rat_25982": 0.7200674414634705, "aqua_rat_82040": 0.7200831174850464, "aqua_rat_66818": 0.7200957536697388, "gsm_rft_28713": 0.7201287150382996, "aqua_rat_33938": 0.720145583152771, "aqua_rat_85171": 0.7201665043830872, "aqua_rat_29620": 0.720181941986084, "aqua_rat_82561": 0.7203266024589539, "gsm_rft_27370": 0.7203909754753113, "aqua_rat_2274": 0.7204208374023438, "aqua_rat_11380": 0.7204364538192749, "aqua_rat_39651": 0.7204641699790955, "aqua_rat_79736": 0.7205518484115601, "gsm_rft_33004": 0.7205880880355835, "aqua_rat_54809": 0.7206615209579468, "aqua_rat_85106": 0.720815896987915, "aqua_rat_63790": 0.7208917140960693, "aqua_rat_46576": 0.7209709286689758, "gsm_rft_34290": 0.7211588025093079, "aqua_rat_60138": 0.72121262550354, "aqua_rat_40353": 0.7212639451026917, "aqua_rat_72432": 0.7213095426559448, "aqua_rat_22893": 0.7214261293411255, "aqua_rat_34919": 0.7215136289596558, "gsm_rft_2703": 0.7215489149093628, "gsm_train_33096": 0.721820592880249, "aqua_rat_13646": 0.7219458818435669, "aqua_rat_40405": 0.722009539604187, "gsm_rft_1660": 0.7220137119293213, "math_train_counting_and_probability_769": 0.7221190929412842, "aqua_rat_1572": 0.7221982479095459, "math_train_prealgebra_947": 0.7222613096237183, "aqua_rat_31214": 0.7223612666130066, "gsm_rft_11616": 0.7224123477935791, "camel_40840": 0.7225059270858765, "gsm_rft_24906": 0.7225083708763123, "gsm_rft_14030": 0.7225147485733032, "gsm_rft_18340": 0.7225309610366821, "aqua_rat_9005": 0.7225384712219238, "camel_21550": 0.7225408554077148, "aqua_rat_47339": 0.7225496768951416, "aqua_rat_79267": 0.7226554751396179, "camel_19952": 0.7227978706359863, "aqua_rat_88152": 0.72283935546875, "math_test_counting_and_probability_260": 0.7228543162345886, "gsm_rft_14160": 0.7228787541389465, "gsm_rft_9540": 0.7230160236358643, "gsm_train_29739": 0.7230160236358643, "aqua_rat_4648": 0.7230523228645325, "aqua_rat_78788": 0.7232271432876587, "aqua_rat_15442": 0.7232859134674072, "aqua_rat_64478": 0.7233694791793823, "camel_19979": 0.7235499620437622, "gsm_rft_33587": 0.7236490845680237, "aqua_rat_17963": 0.7237913012504578, "aqua_rat_57099": 0.7238840460777283, "camel_21596": 0.7239062786102295, "aqua_rat_20616": 0.7240733504295349, "gsm_rft_32172": 0.7240893244743347, "camel_21376": 0.7242839336395264, "aqua_rat_5186": 0.7244579195976257, "aqua_rat_79259": 0.7247308492660522, "aqua_rat_34614": 0.7247494459152222, "camel_20866": 0.7249181270599365, "camel_20425": 0.7250308394432068, "camel_26421": 0.7251364588737488, "math_train_prealgebra_770": 0.7255402207374573, "gsm_rft_18527": 0.725553572177887, "gsm_rft_9537": 0.725553572177887, "aqua_rat_36194": 0.725657045841217, "gsm_rft_4684": 0.7257261872291565, "gsm_train_26111": 0.7257261872291565, "aqua_rat_53430": 0.7257446050643921, "aqua_rat_62188": 0.7258545160293579, "gsm_train_24148": 0.7259218692779541, "gsm_rft_29186": 0.7259218692779541, "aqua_rat_38681": 0.7259363532066345, "aqua_rat_32446": 0.7260663509368896, "aqua_rat_83587": 0.7261006236076355, "gsm_rft_31776": 0.7261303067207336, "gsm_rft_23571": 0.7262192368507385, "camel_36754": 0.7262599468231201, "aqua_rat_35474": 0.7263885736465454, "aqua_rat_63386": 0.7263938188552856, "aqua_rat_20302": 0.7265090346336365, "aqua_rat_35121": 0.727006733417511, "aqua_rat_22591": 0.7270615100860596, "gsm_rft_17248": 0.7271416187286377, "gsm_train_15213": 0.7271416187286377, "aqua_rat_78639": 0.7275046706199646, "aqua_rat_25509": 0.7275233864784241, "gsm_rft_33847": 0.7276047468185425, "camel_38593": 0.7278106212615967, "camel_21962": 0.7283905148506165, "aqua_rat_43800": 0.7284708023071289, "aqua_rat_5881": 0.728701114654541, "gsm_rft_13197": 0.7288278937339783, "aqua_rat_87221": 0.7293601036071777, "aqua_rat_15418": 0.7293602228164673, "camel_21761": 0.7295793890953064, "aqua_rat_39830": 0.7295864820480347, "aqua_rat_40153": 0.7295876145362854, "camel_37037": 0.7296043634414673, "aqua_rat_75572": 0.7302529811859131, "aqua_rat_73560": 0.7305580973625183, "aqua_rat_32047": 0.730587899684906, "gsm_train_6284": 0.7306324243545532, "gsm_rft_24858": 0.7306360602378845, "gsm_rft_21524": 0.730871319770813, "aqua_rat_28998": 0.7314139604568481, "math_test_prealgebra_144": 0.7315414547920227, "camel_36357": 0.7315554618835449, "aqua_rat_48028": 0.7315636873245239, "aqua_rat_76846": 0.7316069602966309, "camel_27506": 0.7318451404571533, "camel_20128": 0.7319814562797546, "aqua_rat_56096": 0.7323188185691833, "aqua_rat_77485": 0.7323344349861145, "aqua_rat_65518": 0.7327359318733215, "aqua_rat_24779": 0.7329708337783813, "gsm_rft_16932": 0.7329964637756348, "gsm_rft_14507": 0.7331511378288269, "camel_23285": 0.7333074808120728, "aqua_rat_88315": 0.7334052324295044, "aqua_rat_229": 0.7336559295654297, "aqua_rat_87185": 0.7337826490402222, "gsm_rft_27215": 0.7343419790267944, "aqua_rat_5877": 0.7346137762069702, "aqua_rat_41911": 0.7347295880317688, "gsm_rft_34047": 0.7349840998649597, "aqua_rat_60981": 0.7353493571281433, "gsm_rft_31518": 0.7354663014411926, "gsm_train_9652": 0.7357679009437561, "gsm_rft_13283": 0.7357786893844604, "aqua_rat_59505": 0.7359086275100708, "camel_38510": 0.7361318469047546, "aqua_rat_59096": 0.7363725900650024, "aqua_rat_83978": 0.7366898059844971, "aqua_rat_89317": 0.7368532419204712, "TheoremQA_maxku/cv-imageprocessing6-histogram.json": 0.7370110154151917, "aqua_rat_80397": 0.7376901507377625, "aqua_rat_65003": 0.7381841540336609, "aqua_rat_19743": 0.738487184047699, "camel_37444": 0.7389671206474304, "aqua_rat_6342": 0.7391327619552612, "aqua_rat_10179": 0.7397218942642212, "aqua_rat_19096": 0.7407646775245667, "gsm_rft_22430": 0.7412968873977661, "gsm_rft_21534": 0.7420997619628906, "gsm_train_34667": 0.7420997619628906, "aqua_rat_9869": 0.7434934377670288, "aqua_rat_73229": 0.7442629337310791, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.7454884648323059, "camel_38481": 0.7460001111030579, "aqua_rat_66731": 0.7472690939903259, "aqua_rat_13625": 0.747303307056427, "aqua_rat_56916": 0.7486037611961365, "aqua_rat_108": 0.7492768168449402, "camel_37553": 0.7493155002593994, "aqua_rat_85357": 0.7499552369117737, "aqua_rat_85697": 0.7505573630332947, "aqua_rat_1953": 0.7521981000900269, "aqua_rat_1879": 0.7542709708213806, "camel_37057": 0.7543946504592896, "aqua_rat_69333": 0.7544746398925781, "aqua_rat_72814": 0.7548118233680725, "aqua_rat_5625": 0.7553369998931885, "aqua_rat_34769": 0.7590919733047485, "gsm_train_35467": 0.759507954120636, "gsm_rft_24803": 0.759863018989563, "gsm_rft_8013": 0.7611015439033508, "TheoremQA_maxku/ipnetwork14-hammingdist.json": 0.819023847579956}, "TheoremQA_jianyu_xu/combination_1.json": {"camel_20948": 0, "camel_21182": 0, "camel_21015": 0, "camel_20512": 0, "camel_20336": 0, "camel_21822": 0, "camel_21215": 0, "camel_20002": 0, "camel_20308": 0, "camel_21198": 0, "camel_21167": 0, "camel_21152": 0, "camel_20580": 0, "camel_20312": 0, "camel_20540": 0, "camel_20378": 0, "camel_20931": 0, "camel_20256": 0, "camel_20930": 0, "camel_21568": 0, "camel_20293": 0, "camel_21000": 0, "TheoremQA_jianyu_xu/combination_1.json": 0, "camel_20525": 0, "camel_21530": 0, "camel_20121": 0, "camel_20287": 0, "camel_20046": 0, "aqua_rat_371": 0.8038277626037598, "aqua_rat_3870": 0.8038875460624695, "aqua_rat_13647": 0.8039187788963318, "aqua_rat_68198": 0.804057776927948, "aqua_rat_66711": 0.8042060136795044, "math_test_prealgebra_1764": 0.8043249845504761, "aqua_rat_89302": 0.804440438747406, "aqua_rat_55783": 0.804531991481781, "aqua_rat_84398": 0.8048591017723083, "aqua_rat_70861": 0.805066704750061, "aqua_rat_19502": 0.8051539659500122, "aqua_rat_69290": 0.8051920533180237, "aqua_rat_61693": 0.8053768873214722, "math_train_counting_and_probability_591": 0.8055326342582703, "aqua_rat_42333": 0.8055534362792969, "aqua_rat_72310": 0.8057745695114136, "aqua_rat_19500": 0.8057956695556641, "aqua_rat_3934": 0.8057974576950073, "aqua_rat_30109": 0.8059727549552917, "aqua_rat_8556": 0.8061502575874329, "aqua_rat_65642": 0.8062593340873718, "aqua_rat_23705": 0.806309163570404, "aqua_rat_39765": 0.8064565062522888, "aqua_rat_42177": 0.806622326374054, "aqua_rat_16861": 0.8067211508750916, "aqua_rat_75552": 0.8067398071289062, "aqua_rat_62645": 0.8068699836730957, "math_train_prealgebra_351": 0.8068723082542419, "math_test_prealgebra_1517": 0.8072862029075623, "aqua_rat_73601": 0.8079788684844971, "aqua_rat_13918": 0.8080757260322571, "math_train_counting_and_probability_122": 0.808347225189209, "math_test_prealgebra_305": 0.8088955879211426, "aqua_rat_65893": 0.8090568780899048, "aqua_rat_34272": 0.809161901473999, "aqua_rat_74651": 0.8091816902160645, "aqua_rat_58323": 0.8097174763679504, "aqua_rat_29967": 0.8099182844161987, "aqua_rat_58614": 0.8101314306259155, "aqua_rat_8021": 0.8101695775985718, "aqua_rat_42373": 0.8102197051048279, "aqua_rat_49053": 0.8102490305900574, "math_train_counting_and_probability_5093": 0.810253918170929, "aqua_rat_29732": 0.8102726340293884, "aqua_rat_21628": 0.8104406595230103, "aqua_rat_72708": 0.8105026483535767, "aqua_rat_35428": 0.810673713684082, "math_test_prealgebra_1997": 0.8106781244277954, "aqua_rat_33533": 0.8107777833938599, "aqua_rat_34607": 0.8108291625976562, "math_train_prealgebra_326": 0.8109341859817505, "aqua_rat_3700": 0.8111631274223328, "aqua_rat_58792": 0.8112205266952515, "aqua_rat_12398": 0.8114707469940186, "math_test_counting_and_probability_901": 0.811741828918457, "aqua_rat_18452": 0.8118966817855835, "math_test_counting_and_probability_575": 0.8119736909866333, "aqua_rat_13853": 0.8120735287666321, "aqua_rat_84277": 0.8122158646583557, "math_train_counting_and_probability_255": 0.8122190237045288, "math_test_counting_and_probability_993": 0.8122544288635254, "math_train_counting_and_probability_1110": 0.8122861981391907, "aqua_rat_78110": 0.8123281598091125, "aqua_rat_37223": 0.8123453855514526, "aqua_rat_83206": 0.812908411026001, "aqua_rat_60938": 0.8129305243492126, "aqua_rat_2510": 0.8133437037467957, "aqua_rat_84736": 0.814025342464447, "aqua_rat_48676": 0.814045250415802, "aqua_rat_20969": 0.8149363398551941, "aqua_rat_35121": 0.8151858448982239, "aqua_rat_28538": 0.8153693079948425, "aqua_rat_50686": 0.8154940009117126, "aqua_rat_57246": 0.8157610893249512, "aqua_rat_17617": 0.8159801363945007, "aqua_rat_62500": 0.8161876201629639, "aqua_rat_52325": 0.8166162371635437, "aqua_rat_967": 0.8168544769287109, "aqua_rat_66620": 0.8169689178466797, "aqua_rat_79193": 0.8170194029808044, "aqua_rat_19345": 0.8171435594558716, "aqua_rat_41506": 0.8175665736198425, "aqua_rat_50942": 0.8175841569900513, "aqua_rat_23818": 0.8178254961967468, "aqua_rat_67181": 0.8179124593734741, "aqua_rat_41111": 0.8181202411651611, "aqua_rat_50541": 0.8181454539299011, "aqua_rat_42231": 0.8183095455169678, "aqua_rat_43337": 0.8183563947677612, "aqua_rat_88698": 0.8184768557548523, "aqua_rat_27717": 0.818669319152832, "math_test_prealgebra_1132": 0.8188124895095825, "aqua_rat_70482": 0.8190391659736633, "aqua_rat_25103": 0.8191360831260681, "math_test_counting_and_probability_857": 0.8191388845443726, "math_train_counting_and_probability_531": 0.819159746170044, "aqua_rat_7992": 0.8192858695983887, "aqua_rat_8519": 0.81931072473526, "aqua_rat_73365": 0.8194664716720581, "aqua_rat_13414": 0.8194974660873413, "math_test_counting_and_probability_216": 0.8195040822029114, "aqua_rat_39388": 0.8195504546165466, "aqua_rat_10136": 0.8197910785675049, "aqua_rat_10665": 0.8199974894523621, "aqua_rat_60755": 0.8202404975891113, "aqua_rat_51559": 0.8203123211860657, "aqua_rat_88915": 0.8204395174980164, "aqua_rat_48816": 0.8207169771194458, "aqua_rat_83919": 0.8217464089393616, "aqua_rat_53149": 0.8217798471450806, "aqua_rat_24605": 0.8218069076538086, "aqua_rat_46685": 0.8219881057739258, "aqua_rat_49270": 0.8223366737365723, "math_test_counting_and_probability_341": 0.8223808407783508, "aqua_rat_73040": 0.8224466443061829, "aqua_rat_29306": 0.8226051330566406, "math_train_counting_and_probability_918": 0.8227023482322693, "math_train_counting_and_probability_373": 0.823173463344574, "aqua_rat_72210": 0.8236042261123657, "aqua_rat_8673": 0.8236272931098938, "aqua_rat_76271": 0.8237064480781555, "aqua_rat_47989": 0.8237413167953491, "aqua_rat_81997": 0.8238230347633362, "camel_38505": 0.8242521286010742, "aqua_rat_43064": 0.8248517513275146, "aqua_rat_78074": 0.8248909711837769, "aqua_rat_5686": 0.8252400159835815, "aqua_rat_52707": 0.8258705735206604, "aqua_rat_88418": 0.8259845972061157, "aqua_rat_43584": 0.827065646648407, "aqua_rat_59702": 0.8271946907043457, "aqua_rat_74695": 0.827279269695282, "math_test_counting_and_probability_776": 0.8279210925102234, "aqua_rat_11347": 0.8285883069038391, "aqua_rat_89036": 0.8290298581123352, "aqua_rat_10290": 0.8296968936920166, "aqua_rat_47648": 0.830512285232544, "aqua_rat_40812": 0.8315263986587524, "aqua_rat_84364": 0.831673264503479, "aqua_rat_82553": 0.831850528717041, "math_test_counting_and_probability_100": 0.8330816030502319, "aqua_rat_62768": 0.8333615064620972, "aqua_rat_25933": 0.8333688974380493, "aqua_rat_82104": 0.8349317908287048, "aqua_rat_15706": 0.835447371006012, "aqua_rat_74505": 0.835529088973999, "aqua_rat_28657": 0.8356037139892578, "aqua_rat_8402": 0.8377025127410889, "aqua_rat_22214": 0.837942898273468, "aqua_rat_29514": 0.838000476360321, "aqua_rat_44882": 0.8380534648895264, "math_train_counting_and_probability_910": 0.8387740254402161, "math_test_counting_and_probability_568": 0.8397140502929688, "aqua_rat_38694": 0.839751660823822, "aqua_rat_38594": 0.8397955894470215, "aqua_rat_37301": 0.8398699164390564, "aqua_rat_87992": 0.8401069045066833, "aqua_rat_71649": 0.8415859937667847, "aqua_rat_79094": 0.8418307900428772, "aqua_rat_66465": 0.8422760367393494, "aqua_rat_71137": 0.842368483543396, "aqua_rat_44716": 0.8427683711051941, "aqua_rat_72693": 0.8437472581863403, "aqua_rat_29513": 0.843916654586792, "aqua_rat_33834": 0.8444295525550842, "aqua_rat_75767": 0.8450644612312317, "aqua_rat_18439": 0.8629278540611267, "aqua_rat_53805": 0.863980770111084, "aqua_rat_57520": 0.8656764626502991, "aqua_rat_17402": 0.8666448593139648, "aqua_rat_75970": 0.8668786883354187, "aqua_rat_58707": 0.8792080879211426}, "TheoremQA_xinyi/linear_projection.json": {"camel_15777": 0, "camel_15061": 0, "camel_15849": 0, "camel_15157": 0, "camel_14898": 0, "camel_14547": 0, "camel_14195": 0, "camel_14908": 0, "camel_14420": 0, "camel_15750": 0, "camel_15624": 0, "camel_15083": 0, "camel_15591": 0, "camel_15812": 0, "camel_15425": 0, "camel_15127": 0, "camel_15093": 0, "camel_14228": 0, "camel_15655": 0, "camel_15760": 0, "camel_15807": 0, "camel_14507": 0, "camel_15398": 0, "camel_15397": 0, "camel_15705": 0, "camel_15586": 0, "camel_15057": 0, "camel_15420": 0, "camel_15378": 0, "camel_15072": 0, "camel_15796": 0, "camel_15645": 0, "camel_15199": 0, "camel_15803": 0, "camel_15360": 0, "camel_15656": 0, "camel_15822": 0, "camel_15619": 0, "camel_15752": 0, "camel_15792": 0, "camel_15650": 0, "camel_15794": 0, "camel_14912": 0, "camel_15704": 0, "camel_15768": 0, "camel_15134": 0, "camel_15051": 0, "camel_14542": 0, "camel_15728": 0, "camel_15427": 0, "camel_15056": 0, "camel_15643": 0, "camel_15721": 0, "camel_15547": 0, "camel_15365": 0, "camel_15043": 0, "camel_15108": 0, "camel_15837": 0, "camel_15089": 0, "camel_14894": 0, "camel_15717": 0, "camel_15713": 0, "camel_15730": 0, "camel_15748": 0, "camel_14179": 0, "TheoremQA_xinyi/linear_projection.json": 0, "camel_15697": 0, "camel_15838": 0, "camel_14453": 0, "camel_15676": 0, "camel_15074": 0, "camel_15555": 0, "camel_14214": 0, "camel_15683": 0, "camel_15816": 0, "camel_15806": 0, "camel_15727": 0, "camel_14156": 0, "camel_15818": 0, "camel_15826": 0, "camel_43481": 0.6601772904396057, "camel_19009": 0.6603444814682007, "camel_29499": 0.6605711579322815, "camel_40431": 0.6611015796661377, "math_train_precalculus_290": 0.6612028479576111, "camel_47348": 0.661352813243866, "math_train_precalculus_898": 0.6614052057266235, "TheoremQA_elainewan/math_algebra_2.json": 0.661411702632904, "TheoremQA_elainewan/math_algebra_4.json": 0.6614857316017151, "camel_47320": 0.6614962220191956, "math_test_precalculus_1032": 0.6616166830062866, "camel_18865": 0.6616603136062622, "math_train_precalculus_1020": 0.6617422699928284, "math_train_precalculus_1048": 0.6617658734321594, "camel_47749": 0.6618083119392395, "camel_45412": 0.6619032621383667, "math_train_precalculus_613": 0.661955714225769, "math_test_precalculus_802": 0.6622323989868164, "camel_29926": 0.6623555421829224, "camel_17522": 0.6623579859733582, "math_train_precalculus_1016": 0.6623756885528564, "math_test_precalculus_625": 0.6624034643173218, "math_train_precalculus_955": 0.6624467372894287, "TheoremQA_xinyi/kernel_1.json": 0.6624898314476013, "math_train_precalculus_18": 0.6626237034797668, "math_test_precalculus_945": 0.6626993417739868, "camel_40407": 0.6627240777015686, "camel_5877": 0.6627818942070007, "math_test_precalculus_1274": 0.6627864241600037, "camel_47797": 0.6628159880638123, "camel_27645": 0.6630790829658508, "math_train_precalculus_1010": 0.6630890369415283, "math_test_precalculus_504": 0.6632802486419678, "math_train_precalculus_11": 0.6633244752883911, "TheoremQA_mingyin/Sylveete-rank-inequality1.json": 0.6637080907821655, "math_train_precalculus_1263": 0.6637842655181885, "math_test_precalculus_1044": 0.6638001799583435, "camel_36766": 0.6639026999473572, "math_train_precalculus_152": 0.6640585064888, "math_train_precalculus_284": 0.6640704870223999, "camel_19443": 0.6644151210784912, "camel_47648": 0.6646000146865845, "camel_5863": 0.6647284626960754, "math_test_precalculus_102": 0.6651373505592346, "math_train_precalculus_559": 0.6651389002799988, "math_train_precalculus_171": 0.6651735901832581, "camel_43448": 0.6653797626495361, "math_train_precalculus_1089": 0.6655222773551941, "TheoremQA_elainewan/math_algebra_6.json": 0.6658262610435486, "math_test_precalculus_944": 0.6660023331642151, "camel_5911": 0.6661300659179688, "math_train_precalculus_457": 0.6661526560783386, "math_test_precalculus_184": 0.6672303676605225, "math_test_precalculus_752": 0.6674095988273621, "math_train_precalculus_835": 0.6674537062644958, "TheoremQA_mingyin/minimal-polynomial1.json": 0.6675999760627747, "math_train_precalculus_434": 0.6679759621620178, "math_test_precalculus_1227": 0.6682695150375366, "math_train_precalculus_95": 0.6684840321540833, "math_test_precalculus_968": 0.6685201525688171, "math_train_precalculus_64": 0.6687907576560974, "math_train_precalculus_510": 0.6690571904182434, "math_train_precalculus_200": 0.6696235537528992, "camel_19632": 0.6703171730041504, "math_test_precalculus_744": 0.6710086464881897, "math_test_precalculus_840": 0.6718064546585083, "math_train_precalculus_410": 0.6719265580177307, "camel_40410": 0.6722496747970581, "math_test_precalculus_763": 0.6725823283195496, "camel_9251": 0.6727058291435242, "camel_47742": 0.6727606654167175, "camel_40453": 0.672897458076477, "camel_40470": 0.6729415655136108, "math_test_precalculus_644": 0.6729649305343628, "math_test_precalculus_356": 0.673109769821167, "camel_29354": 0.6734761595726013, "camel_47293": 0.6736021637916565, "TheoremQA_elainewan/math_algebra_3_5.json": 0.6737830638885498, "math_test_precalculus_0": 0.6742423176765442, "math_test_precalculus_636": 0.6744440197944641, "math_test_precalculus_212": 0.6746946573257446, "math_train_precalculus_1106": 0.6750338077545166, "math_train_precalculus_86": 0.6759725213050842, "camel_17589": 0.6767411828041077, "camel_45838": 0.6770644783973694, "math_test_precalculus_383": 0.6773616671562195, "camel_29294": 0.6783146858215332, "math_train_precalculus_975": 0.6793610453605652, "math_train_precalculus_646": 0.6809507608413696, "camel_49885": 0.6812678575515747, "math_train_precalculus_822": 0.6814801692962646, "camel_40631": 0.681559145450592, "math_test_precalculus_254": 0.6821555495262146, "math_train_precalculus_645": 0.6828368306159973, "math_train_precalculus_179": 0.684632420539856, "camel_48226": 0.6846925616264343, "math_train_precalculus_358": 0.6848090887069702, "math_train_precalculus_271": 0.6855465769767761, "math_train_precalculus_163": 0.6863280534744263, "math_train_precalculus_306": 0.6863486766815186, "math_train_precalculus_338": 0.6865719556808472, "camel_19038": 0.6878989934921265, "math_train_precalculus_900": 0.6883786916732788, "TheoremQA_elainewan/math_algebra_4_3.json": 0.6886194944381714, "math_train_precalculus_404": 0.6899166107177734, "math_train_precalculus_727": 0.6912590265274048, "math_train_precalculus_498": 0.6918957233428955, "math_test_precalculus_755": 0.6928403973579407, "camel_47338": 0.693827211856842, "math_test_precalculus_266": 0.6980992555618286, "camel_43451": 0.6993876695632935, "TheoremQA_elainewan/math_algebra_5.json": 0.7046250700950623, "math_train_precalculus_583": 0.7162630558013916, "math_train_precalculus_1007": 0.7173138856887817, "math_train_precalculus_1213": 0.719602108001709, "math_test_precalculus_341": 0.7284653782844543, "TheoremQA_mingyin/gaussian-elimination2.json": 0.728475034236908, "math_test_precalculus_1218": 0.7312858700752258, "math_train_precalculus_87": 0.7367479205131531, "math_train_precalculus_368": 0.7563256621360779}, "TheoremQA_tonyxia/semiconductor1.json": {"TheoremQA_tonyxia/semiconductor1.json": 0, "gsm_rft_28497": 0.6214622259140015, "gsm_train_18516": 0.6214622259140015, "aqua_rat_64322": 0.6215135455131531, "camel_45012": 0.621553361415863, "camel_39482": 0.6216543316841125, "aqua_rat_71372": 0.6217365860939026, "gsm_rft_33530": 0.6218190789222717, "aqua_rat_56182": 0.6218597888946533, "camel_41009": 0.6220117807388306, "camel_41011": 0.6220744252204895, "aqua_rat_29552": 0.6222279071807861, "aqua_rat_24370": 0.622394323348999, "gsm_rft_34322": 0.6223952174186707, "aqua_rat_70296": 0.6224803328514099, "gsm_rft_13692": 0.6225945949554443, "aqua_rat_37501": 0.6226067543029785, "aqua_rat_6162": 0.6226211786270142, "aqua_rat_3331": 0.6226750016212463, "aqua_rat_65009": 0.6229981780052185, "gsm_rft_24094": 0.6230484247207642, "gsm_train_10381": 0.6230484247207642, "gsm_rft_3001": 0.6232330799102783, "gsm_rft_20209": 0.6232330799102783, "gsm_train_22328": 0.6232330799102783, "aqua_rat_2689": 0.6233619451522827, "aqua_rat_60297": 0.6235875487327576, "aqua_rat_12658": 0.6235946416854858, "camel_28081": 0.6235966086387634, "aqua_rat_71967": 0.6237092614173889, "gsm_rft_14007": 0.6237951517105103, "aqua_rat_63615": 0.623882532119751, "gsm_rft_5019": 0.6239551901817322, "gsm_rft_25914": 0.6240925788879395, "camel_16456": 0.6241161823272705, "aqua_rat_34594": 0.624609112739563, "aqua_rat_77682": 0.624988317489624, "aqua_rat_49292": 0.6252182126045227, "aqua_rat_36411": 0.6254886388778687, "math_test_algebra_1865": 0.6256923079490662, "aqua_rat_19705": 0.6258553266525269, "aqua_rat_81631": 0.6259525418281555, "aqua_rat_77586": 0.6260285377502441, "gsm_rft_11031": 0.6261316537857056, "camel_29204": 0.6261324286460876, "aqua_rat_9017": 0.6261343955993652, "camel_16555": 0.6262624859809875, "gsm_train_33930": 0.6264522075653076, "gsm_rft_4113": 0.6264522075653076, "gsm_rft_28078": 0.6265149712562561, "camel_16180": 0.6265576481819153, "gsm_train_4698": 0.6269570589065552, "camel_44982": 0.6270255446434021, "aqua_rat_5975": 0.6270416378974915, "aqua_rat_41407": 0.6273856163024902, "gsm_rft_1637": 0.627496063709259, "camel_44994": 0.6275771856307983, "TheoremQA_maxku/basic-electronics-2-1.json": 0.6277878284454346, "camel_43803": 0.6278303861618042, "camel_37984": 0.6279555559158325, "aqua_rat_48959": 0.6283811926841736, "camel_16166": 0.6287282705307007, "gsm_rft_35356": 0.6288129687309265, "gsm_train_10116": 0.6288129687309265, "camel_45174": 0.6289367079734802, "gsm_rft_28086": 0.6289579272270203, "gsm_rft_10726": 0.6291326880455017, "gsm_train_33171": 0.629187822341919, "aqua_rat_42126": 0.6294277906417847, "aqua_rat_32270": 0.6294452548027039, "camel_40443": 0.6296189427375793, "camel_16196": 0.6297231316566467, "camel_43809": 0.6297733783721924, "gsm_rft_2452": 0.6297998428344727, "gsm_rft_9344": 0.629827082157135, "gsm_rft_17551": 0.629827082157135, "gsm_train_17819": 0.629827082157135, "camel_17208": 0.6304449439048767, "camel_45967": 0.630445659160614, "aqua_rat_24258": 0.6306272745132446, "aqua_rat_12925": 0.630650520324707, "gsm_rft_13049": 0.6309137344360352, "aqua_rat_18977": 0.6312384605407715, "aqua_rat_52535": 0.6314378380775452, "gsm_rft_17754": 0.631475031375885, "aqua_rat_20090": 0.6316709518432617, "aqua_rat_40122": 0.6317140460014343, "camel_29275": 0.6318634748458862, "camel_28715": 0.6320211887359619, "camel_16201": 0.6320372223854065, "camel_44993": 0.6321004033088684, "aqua_rat_69903": 0.6326082944869995, "aqua_rat_73083": 0.6331784129142761, "aqua_rat_48599": 0.6335432529449463, "camel_45159": 0.6339715719223022, "camel_29279": 0.6341325044631958, "camel_16231": 0.6344717741012573, "camel_16214": 0.6346008777618408, "aqua_rat_52068": 0.634935736656189, "aqua_rat_28371": 0.6349562406539917, "gsm_rft_28838": 0.6349906325340271, "TheoremQA_panlu/molar_heat_capacity2.json": 0.6352605223655701, "camel_28151": 0.6353407502174377, "aqua_rat_37668": 0.6353957653045654, "gsm_rft_3972": 0.6354566216468811, "camel_16165": 0.6360939741134644, "aqua_rat_42745": 0.6361594200134277, "camel_16178": 0.6366233229637146, "camel_17811": 0.6370271444320679, "gsm_rft_2592": 0.6370542645454407, "camel_17240": 0.6374839544296265, "camel_45148": 0.6375859379768372, "camel_16344": 0.6376036405563354, "gsm_rft_1756": 0.6376568078994751, "gsm_train_9534": 0.6377226114273071, "gsm_rft_15764": 0.6377226114273071, "camel_17254": 0.6379114985466003, "camel_17561": 0.6379669308662415, "gsm_rft_15366": 0.63808673620224, "gsm_rft_9144": 0.6383033394813538, "gsm_train_30230": 0.6383033394813538, "gsm_rft_18313": 0.6384973526000977, "aqua_rat_28001": 0.6386553645133972, "camel_16199": 0.6386798620223999, "camel_16173": 0.6390026211738586, "camel_17341": 0.639075517654419, "camel_17213": 0.6394665241241455, "camel_16332": 0.6398423314094543, "camel_17211": 0.6399067640304565, "camel_37959": 0.6401335597038269, "gsm_rft_7862": 0.6402355432510376, "gsm_rft_17141": 0.6403232216835022, "gsm_train_23183": 0.6406819820404053, "aqua_rat_33683": 0.6408148407936096, "gsm_rft_28746": 0.6408692598342896, "gsm_train_1174": 0.6408712863922119, "gsm_rft_33186": 0.6408712863922119, "gsm_rft_22401": 0.6410086750984192, "camel_29252": 0.6411368250846863, "gsm_rft_19423": 0.6411892771720886, "gsm_train_15924": 0.6411892771720886, "gsm_rft_14462": 0.6411892771720886, "camel_29184": 0.641956627368927, "camel_17272": 0.642534613609314, "aqua_rat_5805": 0.6444416046142578, "camel_17267": 0.6452797651290894, "camel_16190": 0.6456671357154846, "gsm_rft_22822": 0.6459454894065857, "camel_45643": 0.6460399031639099, "camel_17252": 0.6462149620056152, "camel_17357": 0.6463863849639893, "gsm_rft_21326": 0.6473265886306763, "camel_17244": 0.647539496421814, "camel_45673": 0.6479507684707642, "camel_16169": 0.6482582688331604, "camel_45929": 0.6486319899559021, "camel_45925": 0.6503273248672485, "gsm_rft_6591": 0.6510308384895325, "gsm_train_4193": 0.6510308384895325, "aqua_rat_65096": 0.6522761583328247, "gsm_rft_21213": 0.6550738215446472, "gsm_train_10153": 0.6552180051803589, "gsm_rft_35104": 0.6554800868034363, "gsm_rft_23914": 0.6578074097633362, "TheoremQA_tonyxia/semiconductor2.json": 0.6586845517158508, "camel_45933": 0.6592649817466736, "TheoremQA_tonyxia/semiconductor3.json": 0.6617634892463684, "camel_37933": 0.6618829965591431, "camel_45033": 0.6631286144256592, "TheoremQA_panlu/linear_expansion1.json": 0.6633045673370361, "camel_17255": 0.66334068775177, "aqua_rat_30407": 0.6647920608520508, "aqua_rat_64101": 0.6652313470840454, "camel_45018": 0.6669652462005615, "aqua_rat_41829": 0.6672024130821228, "aqua_rat_33202": 0.6684158444404602, "camel_44972": 0.6687769293785095, "camel_19576": 0.6690155267715454, "aqua_rat_21090": 0.6701098084449768, "aqua_rat_28949": 0.6702091693878174, "aqua_rat_50074": 0.6723029017448425, "aqua_rat_21063": 0.6730167865753174, "aqua_rat_16995": 0.6758664846420288, "aqua_rat_8480": 0.6770943999290466, "camel_45016": 0.6771337985992432, "aqua_rat_55520": 0.679279088973999, "camel_16181": 0.6809337139129639, "aqua_rat_81880": 0.6825217008590698, "camel_17587": 0.6827080249786377, "camel_16160": 0.6835006475448608, "camel_17235": 0.6848565936088562, "camel_16217": 0.6873178482055664, "camel_44981": 0.6883400678634644, "camel_16209": 0.6913312673568726, "aqua_rat_76514": 0.6916671395301819, "camel_44967": 0.692087709903717, "camel_16179": 0.7112557291984558, "camel_17873": 0.7189416289329529, "camel_16175": 0.7246674299240112, "camel_16223": 0.7371733784675598}, "TheoremQA_maxku/signalprocessing15-DB.json": {"TheoremQA_maxku/signalprocessing15-DB.json": 0, "gsm_rft_12202": 0.637316882610321, "gsm_train_33385": 0.6374344229698181, "aqua_rat_5239": 0.6374934911727905, "aqua_rat_86249": 0.6375336050987244, "gsm_rft_26961": 0.6375641226768494, "gsm_rft_8537": 0.637620747089386, "aqua_rat_79408": 0.6376596093177795, "gsm_rft_2592": 0.6376635432243347, "gsm_rft_31297": 0.6377260684967041, "gsm_rft_24420": 0.6378639340400696, "gsm_train_29686": 0.6378639340400696, "aqua_rat_21997": 0.6378666758537292, "aqua_rat_73083": 0.6379392147064209, "camel_17586": 0.63797527551651, "camel_8536": 0.6379937529563904, "gsm_rft_8266": 0.6380599737167358, "gsm_rft_2576": 0.6380599737167358, "gsm_rft_15576": 0.6381078958511353, "camel_37959": 0.6381234526634216, "aqua_rat_56038": 0.6382004022598267, "aqua_rat_74144": 0.6382222175598145, "aqua_rat_21246": 0.6383627653121948, "aqua_rat_80350": 0.6383652687072754, "aqua_rat_28535": 0.63859623670578, "gsm_rft_13860": 0.6386129856109619, "gsm_rft_33299": 0.6387376189231873, "gsm_rft_33863": 0.6387597918510437, "aqua_rat_45657": 0.6388099789619446, "aqua_rat_75966": 0.6388139724731445, "gsm_rft_23547": 0.638923704624176, "gsm_train_13099": 0.638923704624176, "aqua_rat_79211": 0.6389489769935608, "gsm_rft_8810": 0.638978123664856, "gsm_rft_8436": 0.638978123664856, "gsm_rft_13386": 0.6389831900596619, "aqua_rat_24103": 0.6390751600265503, "aqua_rat_12240": 0.6391308903694153, "gsm_train_5776": 0.6391494870185852, "gsm_rft_89": 0.6391494870185852, "aqua_rat_58465": 0.6391902565956116, "aqua_rat_32270": 0.639289379119873, "gsm_train_4350": 0.63938969373703, "aqua_rat_70673": 0.6394513249397278, "aqua_rat_70296": 0.639485239982605, "gsm_rft_5789": 0.639500617980957, "gsm_rft_22976": 0.6395323872566223, "gsm_train_9254": 0.6395323872566223, "aqua_rat_61264": 0.6395393013954163, "camel_45984": 0.639599084854126, "camel_37980": 0.639714241027832, "gsm_rft_24796": 0.6397390961647034, "gsm_rft_13505": 0.6398094892501831, "gsm_rft_18466": 0.6398168206214905, "gsm_train_1691": 0.6398168206214905, "aqua_rat_30723": 0.6399167776107788, "gsm_train_21024": 0.6399334669113159, "gsm_rft_26885": 0.6399397850036621, "aqua_rat_18977": 0.6400118470191956, "gsm_rft_26897": 0.6400237083435059, "camel_45199": 0.6400871276855469, "gsm_rft_3538": 0.6401069164276123, "gsm_rft_2034": 0.6401069164276123, "gsm_rft_34703": 0.6401826739311218, "gsm_rft_7089": 0.6404125690460205, "aqua_rat_77996": 0.6404218673706055, "aqua_rat_23008": 0.6405128240585327, "aqua_rat_69903": 0.6405465006828308, "gsm_train_20944": 0.6405702233314514, "gsm_rft_21298": 0.6405702233314514, "gsm_rft_21213": 0.6405748724937439, "aqua_rat_41524": 0.6408050656318665, "aqua_rat_20090": 0.6409009099006653, "aqua_rat_15143": 0.6410427093505859, "gsm_rft_17141": 0.6411488056182861, "aqua_rat_50702": 0.6411558985710144, "aqua_rat_71294": 0.6411898732185364, "gsm_train_1174": 0.6412827968597412, "gsm_rft_33186": 0.6412827968597412, "aqua_rat_13162": 0.6412975192070007, "gsm_rft_6830": 0.6413706541061401, "camel_36593": 0.6414583325386047, "aqua_rat_47787": 0.6415217518806458, "camel_45174": 0.641525387763977, "aqua_rat_42745": 0.6415502429008484, "gsm_rft_6897": 0.6417235136032104, "aqua_rat_82697": 0.6420472860336304, "camel_37971": 0.6421298384666443, "gsm_train_10153": 0.6422786116600037, "gsm_train_21544": 0.6425246000289917, "gsm_rft_35104": 0.6426172256469727, "gsm_rft_28838": 0.6426811218261719, "aqua_rat_30186": 0.6428046822547913, "gsm_rft_7812": 0.6428547501564026, "gsm_rft_3972": 0.6430431604385376, "aqua_rat_65183": 0.6430652141571045, "gsm_rft_3001": 0.6432149410247803, "gsm_train_22328": 0.6432149410247803, "gsm_rft_20209": 0.6432149410247803, "aqua_rat_14765": 0.6433698534965515, "gsm_train_858": 0.6434478759765625, "gsm_rft_31953": 0.6436566114425659, "gsm_rft_8384": 0.6436566114425659, "gsm_rft_6261": 0.6436566114425659, "gsm_rft_7862": 0.6438420414924622, "gsm_train_21959": 0.6440045833587646, "gsm_rft_15660": 0.6440045833587646, "camel_38787": 0.6441066861152649, "gsm_rft_5069": 0.6443157196044922, "aqua_rat_47596": 0.6445006728172302, "gsm_rft_23421": 0.6452758312225342, "camel_28143": 0.6455110907554626, "camel_45802": 0.6455391645431519, "camel_45181": 0.6457834243774414, "gsm_train_23183": 0.6461204886436462, "aqua_rat_63167": 0.6461405754089355, "gsm_rft_2421": 0.64632648229599, "gsm_rft_22822": 0.6463399529457092, "gsm_rft_32849": 0.6463526487350464, "gsm_train_26360": 0.6463526487350464, "gsm_rft_28746": 0.647156834602356, "aqua_rat_36517": 0.6477491855621338, "aqua_rat_3234": 0.647973895072937, "gsm_rft_11471": 0.6487953066825867, "gsm_rft_6277": 0.6488867998123169, "aqua_rat_67357": 0.648917019367218, "gsm_train_24294": 0.6489307284355164, "camel_5287": 0.6489822268486023, "gsm_train_19337": 0.6489972472190857, "gsm_rft_10781": 0.6491075754165649, "gsm_rft_25894": 0.6496210098266602, "aqua_rat_53630": 0.6505902409553528, "gsm_rft_17396": 0.6507436037063599, "aqua_rat_37980": 0.6511814594268799, "aqua_rat_81926": 0.6512895226478577, "camel_39482": 0.6513998508453369, "camel_44491": 0.6514894962310791, "aqua_rat_6088": 0.6515032052993774, "aqua_rat_55747": 0.6516594886779785, "camel_44838": 0.6525753736495972, "aqua_rat_60081": 0.6527435183525085, "gsm_rft_26010": 0.6529794931411743, "aqua_rat_23035": 0.653093159198761, "aqua_rat_44457": 0.6531493067741394, "aqua_rat_76667": 0.6533079743385315, "aqua_rat_23105": 0.6537809371948242, "camel_37961": 0.6540378332138062, "aqua_rat_66162": 0.6540933847427368, "aqua_rat_23127": 0.6545565128326416, "aqua_rat_75099": 0.6551999449729919, "camel_45805": 0.6559232473373413, "aqua_rat_75111": 0.6560477018356323, "aqua_rat_8610": 0.6561447978019714, "gsm_rft_33530": 0.6562590599060059, "gsm_rft_28497": 0.65660160779953, "gsm_train_18516": 0.65660160779953, "aqua_rat_56122": 0.6567227840423584, "gsm_rft_10110": 0.657392680644989, "aqua_rat_67486": 0.6576366424560547, "aqua_rat_30572": 0.6578220129013062, "gsm_train_11581": 0.6585414409637451, "gsm_rft_28561": 0.6585414409637451, "gsm_rft_7433": 0.6585414409637451, "gsm_rft_7714": 0.6585415005683899, "aqua_rat_59779": 0.6588338017463684, "camel_28096": 0.6596123576164246, "camel_45159": 0.6596862077713013, "gsm_rft_15666": 0.6598806977272034, "gsm_train_228": 0.6601477861404419, "gsm_rft_7166": 0.6601477861404419, "aqua_rat_60714": 0.6604800820350647, "gsm_rft_1939": 0.6607229113578796, "gsm_train_31158": 0.6607229113578796, "aqua_rat_84169": 0.661409318447113, "aqua_rat_22426": 0.6616300344467163, "aqua_rat_66305": 0.6616755127906799, "aqua_rat_59558": 0.6620951294898987, "aqua_rat_27769": 0.6641287207603455, "aqua_rat_73381": 0.6654201149940491, "gsm_rft_35481": 0.6654890179634094, "aqua_rat_69297": 0.6656886339187622, "camel_45818": 0.6662099957466125, "camel_45834": 0.6665014624595642, "camel_17811": 0.6677094101905823, "aqua_rat_36347": 0.6712768077850342, "aqua_rat_32984": 0.6724377870559692, "gsm_rft_33471": 0.6736533045768738, "aqua_rat_54325": 0.6742797493934631, "aqua_rat_82138": 0.6752873063087463, "aqua_rat_61003": 0.6780687570571899, "camel_45819": 0.680334210395813, "camel_28122": 0.6841124296188354, "TheoremQA_maxku/signalprocessing18-noisebark.json": 0.6958016157150269, "camel_44806": 0.7071248888969421, "camel_45637": 0.7114583849906921, "camel_44543": 0.741784393787384, "camel_44741": 0.747448205947876, "camel_45836": 0.7917508482933044, "TheoremQA_maxku/signalprocessing2-DB.json": 0.7947549223899841, "camel_45809": 0.8503572940826416}, "TheoremQA_mingyin/Lebesgue-measure1.json": {"TheoremQA_mingyin/Lebesgue-measure1.json": 0, "camel_34517": 0.7252928614616394, "camel_30379": 0.725468099117279, "camel_37458": 0.7257973551750183, "math_train_counting_and_probability_259": 0.7258233428001404, "camel_30884": 0.7260154485702515, "aqua_rat_20715": 0.7263475060462952, "aqua_rat_71064": 0.7264964580535889, "gsm_rft_21038": 0.7270273566246033, "gsm_rft_22706": 0.7270273566246033, "gsm_train_20419": 0.7270273566246033, "aqua_rat_81382": 0.7270349860191345, "aqua_rat_33903": 0.7270588874816895, "aqua_rat_79145": 0.7272424697875977, "camel_31047": 0.7272822260856628, "camel_34487": 0.7273101806640625, "camel_30952": 0.7274115681648254, "aqua_rat_76356": 0.7275834083557129, "camel_37112": 0.7277097702026367, "camel_34538": 0.7279467582702637, "camel_38510": 0.7280544638633728, "aqua_rat_20491": 0.7281479835510254, "aqua_rat_15936": 0.7282253503799438, "aqua_rat_45273": 0.7282806634902954, "aqua_rat_62331": 0.7288421988487244, "camel_18671": 0.7288434505462646, "aqua_rat_40893": 0.7289144396781921, "gsm_rft_25428": 0.7289257049560547, "camel_30390": 0.7290458083152771, "camel_21753": 0.7291915416717529, "camel_30915": 0.7294171452522278, "camel_30932": 0.7295548319816589, "camel_21703": 0.7295598387718201, "camel_37027": 0.7297185063362122, "camel_30364": 0.730028510093689, "aqua_rat_23531": 0.7302011847496033, "camel_30399": 0.7302356958389282, "aqua_rat_11689": 0.7303411364555359, "camel_31190": 0.7306258678436279, "camel_30350": 0.7308627367019653, "camel_34516": 0.730972409248352, "camel_30340": 0.7310881018638611, "camel_30887": 0.7312123775482178, "camel_30937": 0.7312703728675842, "camel_30324": 0.7313485145568848, "aqua_rat_19896": 0.731422483921051, "aqua_rat_40065": 0.7314504981040955, "aqua_rat_17862": 0.7315438389778137, "aqua_rat_16788": 0.7315585017204285, "aqua_rat_34164": 0.7315897941589355, "aqua_rat_48464": 0.731630802154541, "gsm_rft_15632": 0.7318797707557678, "gsm_train_17342": 0.7318797707557678, "camel_37121": 0.7319800853729248, "aqua_rat_48668": 0.7320432066917419, "camel_30380": 0.7322845458984375, "camel_30384": 0.7324292659759521, "camel_34550": 0.7324680685997009, "aqua_rat_30189": 0.7325497269630432, "camel_21699": 0.7325790524482727, "aqua_rat_72530": 0.7325930595397949, "aqua_rat_83796": 0.7326868176460266, "aqua_rat_55514": 0.7326930165290833, "math_train_algebra_881": 0.7327182292938232, "aqua_rat_74996": 0.7327389121055603, "aqua_rat_17841": 0.7327924370765686, "camel_30942": 0.7329049110412598, "camel_34493": 0.7329409718513489, "aqua_rat_20848": 0.7329494953155518, "aqua_rat_79590": 0.7329991459846497, "camel_30895": 0.7330350875854492, "camel_30362": 0.7330420613288879, "gsm_rft_13556": 0.7330455183982849, "camel_21704": 0.7331858277320862, "gsm_rft_20084": 0.7332764267921448, "gsm_rft_27447": 0.7332764267921448, "TheoremQA_mingyin/cantor-set1.json": 0.7333185076713562, "gsm_train_10148": 0.7333327531814575, "gsm_rft_22281": 0.7333629131317139, "camel_34552": 0.7335817813873291, "aqua_rat_80435": 0.7336327433586121, "camel_21550": 0.7342590093612671, "camel_34553": 0.7343558669090271, "gsm_rft_8731": 0.7344175577163696, "camel_37089": 0.7344727516174316, "camel_30375": 0.7346106171607971, "camel_30333": 0.734734058380127, "aqua_rat_39494": 0.7347556948661804, "math_train_algebra_1877": 0.7348118424415588, "aqua_rat_71759": 0.7351255416870117, "camel_30888": 0.7352368831634521, "math_test_counting_and_probability_572": 0.7354472279548645, "camel_34534": 0.7354764342308044, "camel_37113": 0.7358819842338562, "aqua_rat_73720": 0.7358930706977844, "camel_21690": 0.7359446883201599, "aqua_rat_67911": 0.7360281944274902, "camel_31525": 0.7360634207725525, "aqua_rat_10033": 0.7361661791801453, "aqua_rat_60179": 0.7362385988235474, "aqua_rat_45489": 0.7365259528160095, "camel_30359": 0.7365285158157349, "camel_30374": 0.7367919683456421, "aqua_rat_58131": 0.7368127107620239, "aqua_rat_69320": 0.7369286417961121, "math_test_number_theory_1146": 0.7370025515556335, "aqua_rat_31193": 0.7370163202285767, "aqua_rat_17359": 0.7372565865516663, "camel_30885": 0.7375730276107788, "aqua_rat_74849": 0.7376192212104797, "aqua_rat_64918": 0.7377191185951233, "camel_34505": 0.7377651333808899, "aqua_rat_89288": 0.7377817034721375, "camel_34508": 0.7380544543266296, "camel_30948": 0.7382705211639404, "camel_21541": 0.7383098006248474, "camel_36990": 0.7383934855461121, "aqua_rat_65485": 0.738479495048523, "aqua_rat_69735": 0.738490879535675, "camel_30323": 0.7386839389801025, "aqua_rat_854": 0.7388792634010315, "aqua_rat_18682": 0.7389298677444458, "aqua_rat_72416": 0.7390828728675842, "camel_34506": 0.7390868663787842, "aqua_rat_149": 0.739177405834198, "camel_30921": 0.7392524480819702, "aqua_rat_62074": 0.7395328283309937, "camel_18240": 0.7395756840705872, "aqua_rat_8518": 0.740104079246521, "camel_30348": 0.7405095100402832, "aqua_rat_3298": 0.7407791018486023, "camel_37037": 0.7408254146575928, "aqua_rat_46784": 0.7409235239028931, "aqua_rat_15480": 0.7415242791175842, "aqua_rat_32331": 0.7415518760681152, "aqua_rat_67387": 0.7416694760322571, "aqua_rat_60766": 0.7417439818382263, "aqua_rat_35493": 0.7420295476913452, "aqua_rat_69238": 0.7423479557037354, "camel_36987": 0.7427714467048645, "camel_31842": 0.7430477142333984, "camel_30389": 0.7432071566581726, "aqua_rat_15442": 0.743281364440918, "camel_30386": 0.7433251738548279, "aqua_rat_1729": 0.7440856099128723, "camel_30341": 0.7449737787246704, "aqua_rat_4924": 0.7450473308563232, "aqua_rat_49020": 0.7458531260490417, "camel_30385": 0.7461957335472107, "camel_31759": 0.7462749481201172, "camel_30360": 0.7464492321014404, "aqua_rat_60963": 0.7475478053092957, "camel_34539": 0.7477402687072754, "math_test_prealgebra_931": 0.7478132843971252, "camel_30347": 0.7478519678115845, "camel_30335": 0.74785977602005, "camel_30342": 0.7481921315193176, "camel_30886": 0.7489150166511536, "camel_30352": 0.7489859461784363, "aqua_rat_23524": 0.7498988509178162, "aqua_rat_48028": 0.7499311566352844, "camel_30369": 0.7500091791152954, "camel_30398": 0.7503496408462524, "aqua_rat_73560": 0.7503769397735596, "camel_30351": 0.7516323924064636, "camel_30382": 0.7518337965011597, "aqua_rat_88955": 0.7528486251831055, "aqua_rat_220": 0.7534850835800171, "camel_30367": 0.7536522746086121, "camel_37020": 0.754722535610199, "aqua_rat_20302": 0.7549137473106384, "camel_30383": 0.7553410530090332, "camel_30387": 0.7594484090805054, "camel_30327": 0.7596814036369324, "camel_30343": 0.7604706883430481, "camel_30377": 0.7606513500213623, "camel_18056": 0.7626087665557861, "camel_30397": 0.7630149126052856, "camel_18193": 0.7637195587158203, "camel_30388": 0.7652460932731628, "camel_30321": 0.7666842937469482, "camel_30330": 0.7669050097465515, "camel_30334": 0.7711976170539856, "camel_30378": 0.7713742256164551, "camel_30371": 0.7740912437438965, "camel_30357": 0.7748485207557678, "camel_30396": 0.7757541537284851, "camel_30366": 0.7773691415786743, "camel_30320": 0.780825138092041, "camel_30372": 0.7828261256217957, "camel_30325": 0.7842157483100891, "camel_30368": 0.7863608002662659, "camel_30345": 0.7879561185836792, "camel_30392": 0.7880711555480957, "camel_30354": 0.7939553260803223, "camel_30328": 0.798742413520813, "camel_30353": 0.7999364137649536, "camel_30339": 0.8036404252052307, "camel_30346": 0.8148983716964722, "camel_30338": 0.8185759782791138}, "TheoremQA_mingyin/series2.json": {"math_test_precalculus_24169": 0, "TheoremQA_mingyin/series2.json": 0, "aqua_rat_44150": 0.6867286562919617, "math_train_intermediate_algebra_1154": 0.6868511438369751, "math_test_algebra_733": 0.6872221231460571, "camel_42285": 0.6873006820678711, "TheoremQA_wenhuchen/infinite_series_sum1.json": 0.6874955892562866, "camel_42746": 0.6875084638595581, "camel_30889": 0.6876294612884521, "camel_49105": 0.6877878308296204, "math_train_intermediate_algebra_316": 0.6879168152809143, "camel_42696": 0.6881262063980103, "camel_42759": 0.6882352232933044, "camel_42675": 0.6884855628013611, "camel_42803": 0.6888473033905029, "camel_42010": 0.6888903379440308, "camel_42748": 0.6893027424812317, "math_train_intermediate_algebra_532": 0.6894614696502686, "math_test_number_theory_1077": 0.6898189783096313, "camel_30327": 0.689842700958252, "camel_42686": 0.6900245547294617, "camel_42671": 0.6900988817214966, "camel_42774": 0.6901030540466309, "camel_42648": 0.6901827454566956, "camel_42744": 0.6901935935020447, "camel_42644": 0.6905398964881897, "camel_31842": 0.6908422708511353, "camel_42642": 0.6910912990570068, "camel_42661": 0.6914107799530029, "camel_30680": 0.6920413970947266, "camel_42653": 0.6923518776893616, "camel_42701": 0.6924310326576233, "aqua_rat_24093": 0.6926217079162598, "math_train_counting_and_probability_5026": 0.6927278637886047, "camel_42056": 0.6928638815879822, "camel_42667": 0.6929670572280884, "camel_31056": 0.6930598616600037, "camel_42727": 0.693403959274292, "camel_42702": 0.6934524774551392, "camel_42690": 0.6934807300567627, "camel_42681": 0.6937903165817261, "camel_42692": 0.6943386793136597, "camel_42767": 0.6943880915641785, "math_train_intermediate_algebra_1387": 0.6944280862808228, "math_train_intermediate_algebra_899": 0.6944356560707092, "camel_42684": 0.6947548389434814, "camel_42751": 0.6948745846748352, "camel_42752": 0.6951090693473816, "camel_30325": 0.6951805949211121, "math_train_algebra_58": 0.695311963558197, "camel_42032": 0.695587158203125, "camel_42680": 0.6958449482917786, "camel_42769": 0.6961296796798706, "math_train_algebra_652": 0.6961745023727417, "camel_44125": 0.6963569521903992, "camel_42034": 0.6967511773109436, "camel_42695": 0.69718337059021, "camel_42756": 0.6972988843917847, "camel_42709": 0.6975613832473755, "camel_49051": 0.6975626349449158, "camel_42660": 0.6976283192634583, "math_train_intermediate_algebra_824": 0.6978160738945007, "camel_42699": 0.6978882551193237, "math_train_intermediate_algebra_451": 0.6980007290840149, "aqua_rat_49434": 0.6983430981636047, "camel_42664": 0.6986638307571411, "camel_42704": 0.6987433433532715, "camel_42718": 0.6990503072738647, "camel_42782": 0.6991128921508789, "camel_42663": 0.6994206309318542, "camel_42665": 0.6995868682861328, "camel_18101": 0.6996278762817383, "camel_42674": 0.6999869346618652, "aqua_rat_31892": 0.700639545917511, "camel_30357": 0.7007101774215698, "camel_42735": 0.7010440826416016, "camel_42738": 0.7011146545410156, "camel_42052": 0.7012841105461121, "math_train_intermediate_algebra_1610": 0.701519250869751, "camel_42706": 0.7018495798110962, "camel_42707": 0.7018956542015076, "camel_42683": 0.7020418047904968, "camel_42647": 0.7027393579483032, "camel_30372": 0.7027639746665955, "aqua_rat_47530": 0.7028372287750244, "camel_42682": 0.7029680609703064, "camel_30346": 0.7029799222946167, "camel_42700": 0.7031567692756653, "camel_42754": 0.7034218907356262, "math_train_intermediate_algebra_1527": 0.7039259672164917, "aqua_rat_66695": 0.7039551138877869, "camel_31869": 0.7039961218833923, "camel_31880": 0.7047088146209717, "camel_42645": 0.7047890424728394, "aqua_rat_16203": 0.7052924633026123, "camel_49102": 0.7053496241569519, "camel_30353": 0.705394446849823, "camel_42777": 0.7056435942649841, "camel_42650": 0.7056681513786316, "aqua_rat_13532": 0.7058230042457581, "camel_42651": 0.7058748602867126, "camel_31089": 0.7059001922607422, "math_test_intermediate_algebra_1318": 0.7063887119293213, "aqua_rat_59396": 0.7064844965934753, "TheoremQA_mingyin/Lebesgue-measure4.json": 0.7072250247001648, "camel_42694": 0.7073512673377991, "math_test_intermediate_algebra_1600": 0.7074108719825745, "camel_44100": 0.7074758410453796, "camel_42715": 0.7076402902603149, "camel_42662": 0.7078347206115723, "camel_42669": 0.7082651257514954, "camel_44121": 0.7083576321601868, "camel_31759": 0.7084742188453674, "camel_30371": 0.7092304229736328, "camel_42677": 0.7095866799354553, "camel_42649": 0.7097057104110718, "math_test_intermediate_algebra_1451": 0.7097131609916687, "camel_42712": 0.709928572177887, "camel_42693": 0.7100761532783508, "camel_42714": 0.7110952734947205, "camel_42685": 0.7111726403236389, "camel_42698": 0.7114691734313965, "camel_42658": 0.7115707397460938, "camel_42717": 0.7120068669319153, "camel_30342": 0.7124468684196472, "camel_30383": 0.7131587266921997, "camel_30374": 0.7136470079421997, "camel_42666": 0.7138464450836182, "camel_42657": 0.7146007418632507, "camel_42640": 0.7146409749984741, "math_train_intermediate_algebra_1051": 0.7149305939674377, "camel_31061": 0.7155012488365173, "TheoremQA_mingyin/borel-cantelli-lemma1.json": 0.7155246734619141, "camel_42641": 0.7157542705535889, "camel_42719": 0.7167714238166809, "camel_49110": 0.7168739438056946, "camel_42705": 0.7177622318267822, "math_train_intermediate_algebra_464": 0.7178711295127869, "camel_42656": 0.7183736562728882, "aqua_rat_35538": 0.7188564538955688, "math_test_algebra_2477": 0.7191410660743713, "camel_42688": 0.7201906442642212, "camel_42689": 0.7202292680740356, "math_train_intermediate_algebra_670": 0.7206155061721802, "aqua_rat_19560": 0.7214049696922302, "camel_42673": 0.721682071685791, "aqua_rat_54656": 0.7218630313873291, "camel_42687": 0.7220445275306702, "camel_42708": 0.7229735851287842, "TheoremQA_wenhuchen/taylor_expansion2.json": 0.7230173349380493, "camel_30341": 0.7240904569625854, "camel_42646": 0.7243725061416626, "camel_42652": 0.7250521779060364, "camel_30338": 0.7258301377296448, "aqua_rat_67612": 0.7258545756340027, "camel_42679": 0.725877583026886, "TheoremQA_wenhuchen/series_convergen1.json": 0.7261205315589905, "camel_42676": 0.7261791825294495, "aqua_rat_36268": 0.7268296480178833, "math_train_intermediate_algebra_9003": 0.7272329330444336, "math_train_intermediate_algebra_1315": 0.7274274826049805, "camel_42713": 0.729202151298523, "camel_31057": 0.7293341755867004, "camel_30345": 0.7297994494438171, "aqua_rat_50166": 0.7298030257225037, "math_train_intermediate_algebra_1939": 0.7299894690513611, "TheoremQA_mingyin/Limit-of-sequence3.json": 0.7302164435386658, "aqua_rat_8747": 0.7316290736198425, "camel_30392": 0.7328063249588013, "camel_49044": 0.7330498695373535, "math_train_intermediate_algebra_445": 0.7330740094184875, "camel_31084": 0.7332624793052673, "aqua_rat_53748": 0.7336026430130005, "camel_18137": 0.7337837219238281, "camel_49079": 0.734163761138916, "camel_42703": 0.7355568408966064, "TheoremQA_wenhuchen/series_convergen2.json": 0.7366740107536316, "math_train_intermediate_algebra_1594": 0.7373585104942322, "aqua_rat_35123": 0.7390608787536621, "camel_42678": 0.7390609979629517, "aqua_rat_48885": 0.7411211729049683, "math_test_intermediate_algebra_2116": 0.7416073679924011, "camel_42670": 0.7419536113739014, "camel_30339": 0.7425065040588379, "camel_30354": 0.7434196472167969, "math_train_intermediate_algebra_1765": 0.7468220591545105, "aqua_rat_69318": 0.7478131651878357, "TheoremQA_wenhuchen/infinite_series_sum3.json": 0.7478660941123962, "camel_49109": 0.7483147978782654, "camel_44106": 0.7534530162811279, "math_train_intermediate_algebra_1581": 0.7614973783493042, "camel_30330": 0.7630128860473633, "math_train_intermediate_algebra_503": 0.7647024393081665, "camel_30202": 0.7655536532402039, "TheoremQA_wenhuchen/series_convergen3.json": 0.7701571583747864, "camel_30385": 0.7810258865356445, "camel_42643": 0.7815996408462524, "math_test_intermediate_algebra_1994": 0.7872762084007263, "TheoremQA_mingyin/Lebesgue-measure1.json": 0.7879890203475952, "TheoremQA_wenhuchen/infinite_series_sum2.json": 0.7907371520996094}, "TheoremQA_wenhuchen/ODE2.json": {"camel_7971": 0, "camel_7502": 0, "camel_7516": 0, "camel_16952": 0, "camel_7494": 0, "camel_7961": 0, "camel_7506": 0, "camel_7509": 0, "camel_7519": 0, "camel_16988": 0, "camel_7466": 0, "camel_7986": 0, "camel_16914": 0, "camel_7967": 0, "camel_7610": 0, "camel_7513": 0, "camel_7475": 0, "camel_7941": 0, "camel_16890": 0, "camel_7931": 0, "camel_17377": 0, "camel_7517": 0, "camel_17022": 0, "camel_16893": 0, "camel_7497": 0, "camel_17435": 0, "camel_7935": 0, "camel_16884": 0, "camel_16921": 0, "camel_7472": 0, "camel_7949": 0, "camel_17039": 0, "camel_17028": 0, "camel_17420": 0, "camel_17811": 0, "camel_16913": 0, "camel_16894": 0, "camel_7463": 0, "camel_16996": 0, "camel_7484": 0, "camel_7481": 0, "camel_7950": 0, "camel_7443": 0, "camel_16919": 0, "camel_16901": 0, "camel_7478": 0, "camel_7987": 0, "camel_17433": 0, "camel_16922": 0, "camel_16900": 0, "camel_7955": 0, "camel_7487": 0, "camel_17361": 0, "camel_7927": 0, "camel_7940": 0, "camel_17030": 0, "camel_7457": 0, "camel_7468": 0, "camel_39513": 0.7891502380371094, "camel_29400": 0.7891895174980164, "camel_28840": 0.789426326751709, "camel_28338": 0.7896669507026672, "camel_28906": 0.790287971496582, "camel_28821": 0.7907843589782715, "camel_28395": 0.7910088896751404, "camel_29974": 0.791522204875946, "camel_28796": 0.7916024923324585, "camel_28098": 0.7918000817298889, "camel_29597": 0.7920342683792114, "camel_29691": 0.7921509146690369, "camel_28785": 0.7923038005828857, "camel_28857": 0.7924882769584656, "camel_29950": 0.79250168800354, "camel_39469": 0.7926281690597534, "camel_39441": 0.7927864789962769, "camel_28853": 0.7934983372688293, "camel_28855": 0.7936232089996338, "camel_28045": 0.7938976287841797, "camel_29044": 0.7940632104873657, "camel_29362": 0.7947925925254822, "camel_39460": 0.7949684858322144, "camel_28733": 0.7949919104576111, "camel_40334": 0.7950354218482971, "camel_29398": 0.7950581312179565, "camel_28827": 0.7951450943946838, "camel_39446": 0.7953300476074219, "camel_28806": 0.7953537106513977, "camel_28842": 0.7958288788795471, "camel_29510": 0.7958588600158691, "camel_29374": 0.795861542224884, "camel_28824": 0.796107292175293, "camel_28064": 0.7962695956230164, "camel_28845": 0.7964460849761963, "camel_28399": 0.7966943383216858, "camel_28047": 0.7969345450401306, "camel_29396": 0.7970491647720337, "camel_28846": 0.7970655560493469, "camel_28379": 0.7973207831382751, "camel_28861": 0.7974321246147156, "camel_29443": 0.7977325916290283, "camel_29985": 0.7977590560913086, "camel_29395": 0.7977769374847412, "camel_28835": 0.7984579801559448, "camel_28789": 0.798676073551178, "camel_39473": 0.7987267374992371, "camel_29439": 0.7987689971923828, "camel_29967": 0.799047589302063, "camel_28825": 0.7992951273918152, "camel_29385": 0.799704372882843, "camel_39474": 0.8001466393470764, "camel_29411": 0.8003119230270386, "camel_39511": 0.8004301190376282, "camel_29437": 0.800553560256958, "camel_28862": 0.8008284568786621, "camel_29734": 0.8008617162704468, "camel_28813": 0.8010244965553284, "camel_29705": 0.8011641502380371, "camel_28867": 0.8012782335281372, "camel_28723": 0.8015252351760864, "camel_39479": 0.8016205430030823, "camel_28953": 0.8018136024475098, "camel_40249": 0.8024948835372925, "camel_29413": 0.8027554154396057, "camel_29997": 0.8028855323791504, "camel_28384": 0.8038704991340637, "camel_28057": 0.8041958212852478, "camel_28838": 0.8048670887947083, "camel_29925": 0.8050603866577148, "camel_28863": 0.8054486513137817, "camel_29432": 0.8062282204627991, "camel_28801": 0.8067006468772888, "camel_29486": 0.8070669174194336, "camel_28854": 0.8072432279586792, "camel_28332": 0.8073119521141052, "camel_28812": 0.8075199127197266, "camel_29391": 0.807830810546875, "camel_29576": 0.8079052567481995, "camel_28831": 0.8084025979042053, "camel_28823": 0.8084812760353088, "camel_29163": 0.8085529208183289, "camel_29430": 0.8092111349105835, "camel_28814": 0.8092770576477051, "camel_29178": 0.8094146847724915, "camel_29377": 0.8095597624778748, "camel_29392": 0.8103971481323242, "camel_29112": 0.8107976317405701, "camel_39503": 0.8108938932418823, "camel_29050": 0.8109025359153748, "camel_29992": 0.81133633852005, "camel_28787": 0.8118000626564026, "camel_28802": 0.8133746385574341, "camel_29528": 0.8138857483863831, "camel_28836": 0.8147514462471008, "camel_28780": 0.8148276209831238, "camel_28145": 0.8149029016494751, "camel_28878": 0.8152122497558594, "camel_29638": 0.8154962062835693, "camel_28088": 0.8156829476356506, "camel_28946": 0.8175973892211914, "camel_28816": 0.8183063864707947, "camel_28830": 0.8187744617462158, "camel_28133": 0.8192206025123596, "camel_28860": 0.8196025490760803, "camel_39510": 0.820558488368988, "camel_29364": 0.8212597370147705, "camel_39488": 0.8216329216957092, "camel_29388": 0.8220416903495789, "camel_28805": 0.822958767414093, "camel_28794": 0.8235275149345398, "camel_29991": 0.8244516849517822, "camel_28847": 0.8247961401939392, "camel_39517": 0.8268874287605286, "camel_29542": 0.8276111483573914, "camel_28848": 0.8284432888031006, "camel_28094": 0.8286211490631104, "camel_28394": 0.8289589881896973, "camel_29372": 0.8294689059257507, "camel_29979": 0.8296482563018799, "camel_29467": 0.8327560424804688, "camel_28022": 0.8328933119773865, "camel_28715": 0.8341596722602844, "camel_29429": 0.8352353572845459, "camel_29379": 0.8353796601295471, "camel_29438": 0.836122453212738, "camel_28826": 0.8362224102020264, "camel_39453": 0.8373015522956848, "camel_29972": 0.8384078145027161, "camel_28909": 0.8391110301017761, "camel_28832": 0.8406819105148315, "camel_28803": 0.8413233757019043, "camel_29426": 0.8418529033660889, "camel_29373": 0.8426684737205505, "camel_29491": 0.8439429402351379, "camel_28874": 0.8445506691932678, "camel_28068": 0.8476443290710449, "camel_28869": 0.849822998046875, "camel_28815": 0.8511802554130554, "camel_29387": 0.8593261241912842, "camel_28837": 0.8668707609176636, "camel_28024": 0.8676198124885559}, "TheoremQA_wenhuchen/Liouville\u2019s_theorem1.json": {"camel_43272": 0, "camel_42813": 0, "camel_43194": 0, "camel_43198": 0, "camel_42869": 0, "camel_42315": 0, "camel_42047": 0, "camel_42562": 0, "camel_42420": 0, "camel_42891": 0, "camel_42013": 0, "camel_42008": 0, "camel_42634": 0, "camel_42263": 0, "camel_42284": 0, "camel_43239": 0, "camel_42881": 0, "camel_43188": 0, "camel_43170": 0, "camel_43002": 0, "camel_42622": 0, "camel_43189": 0, "camel_42286": 0, "camel_42907": 0, "camel_42910": 0, "camel_42475": 0, "camel_42432": 0, "camel_42402": 0, "camel_42061": 0, "camel_42407": 0, "camel_42406": 0, "camel_42276": 0, "camel_42408": 0, "camel_42958": 0, "camel_42887": 0, "camel_43190": 0, "camel_43175": 0, "camel_43163": 0, "camel_42936": 0, "camel_43182": 0, "camel_43110": 0, "camel_42462": 0, "camel_42208": 0, "camel_42565": 0, "camel_43171": 0, "camel_42464": 0, "camel_42575": 0, "camel_42435": 0, "camel_42445": 0, "camel_42633": 0, "camel_42925": 0, "camel_42400": 0, "camel_42477": 0, "camel_43012": 0, "camel_42839": 0, "camel_42466": 0, "camel_43152": 0, "camel_43381": 0, "camel_42491": 0, "camel_43557": 0, "camel_42591": 0, "camel_43546": 0, "camel_42630": 0, "camel_42019": 0, "camel_42257": 0, "camel_42942": 0, "camel_42621": 0, "camel_42282": 0, "camel_42423": 0, "camel_42789": 0, "camel_42896": 0, "camel_42062": 0, "camel_42448": 0, "camel_43036": 0, "camel_42458": 0, "camel_42589": 0, "camel_42612": 0, "camel_43158": 0, "camel_43105": 0, "camel_42428": 0, "camel_42928": 0, "camel_42990": 0, "camel_43256": 0, "camel_42966": 0, "camel_43006": 0, "camel_42444": 0, "camel_42974": 0, "camel_42517": 0, "camel_42626": 0, "camel_42989": 0, "camel_42070": 0, "camel_43010": 0, "camel_42533": 0, "camel_43263": 0, "camel_42548": 0, "camel_42625": 0, "camel_42525": 0, "camel_42518": 0, "camel_42614": 0, "camel_42494": 0, "camel_42623": 0, "camel_42956": 0, "camel_42500": 0, "camel_43082": 0, "camel_42486": 0, "camel_42472": 0, "camel_42417": 0, "camel_42002": 0, "camel_42437": 0, "camel_42816": 0, "camel_42552": 0, "camel_42549": 0, "camel_42636": 0, "camel_42550": 0, "camel_43133": 0, "camel_42921": 0, "camel_42405": 0, "camel_43191": 0, "camel_42507": 0, "camel_42505": 0, "camel_42424": 0, "camel_42259": 0, "camel_42497": 0, "camel_42618": 0, "camel_42536": 0, "camel_43164": 0, "camel_42538": 0, "camel_42528": 0, "camel_42480": 0, "camel_42434": 0, "camel_42558": 0, "camel_42557": 0, "camel_43131": 0, "camel_42629": 0, "camel_42485": 0, "camel_42053": 0, "camel_42551": 0, "camel_42999": 0, "camel_42456": 0, "camel_42430": 0, "camel_42616": 0, "camel_42935": 0, "camel_42553": 0, "camel_42005": 0, "camel_42520": 0, "camel_42546": 0, "camel_42431": 0, "camel_42426": 0, "camel_42410": 0, "camel_43140": 0, "camel_42547": 0, "camel_42954": 0, "camel_42526": 0, "camel_43001": 0, "camel_42559": 0, "camel_42583": 0, "camel_42585": 0, "camel_43132": 0, "camel_42530": 0, "camel_42429": 0, "camel_42596": 0, "camel_42880": 0, "camel_42478": 0, "camel_42996": 0, "camel_42454": 0, "camel_43027": 0, "camel_42498": 0, "camel_42422": 0, "camel_42474": 0, "camel_42975": 0, "camel_42441": 0, "camel_42985": 0, "camel_42603": 0, "TheoremQA_wenhuchen/Liouville\u2019s_theorem1.json": 0, "camel_42529": 0, "camel_42512": 0, "camel_42615": 0, "camel_42007": 0, "camel_42488": 0, "camel_42508": 0, "camel_42522": 0, "camel_42613": 0, "camel_42519": 0, "camel_42582": 0, "camel_42539": 0, "camel_42074": 0, "camel_43035": 0, "camel_42888": 0, "camel_42412": 0, "camel_42021": 0, "camel_42531": 0, "camel_42501": 0, "camel_42504": 0, "camel_43020": 0, "camel_42492": 0, "camel_42564": 0, "camel_42556": 0, "camel_49083": 0.7724195718765259, "TheoremQA_wenhuchen/Liouville\u2019s_theorem2.json": 0.862910270690918, "TheoremQA_mingyin/liouville-theorem1.json": 0.8824775218963623}, "TheoremQA_elainewan/math_abstact_algebra_7_8.json": {"camel_33439": 0, "camel_33419": 0, "camel_32796": 0, "camel_33456": 0, "camel_33472": 0, "camel_32761": 0, "camel_33682": 0, "camel_33905": 0, "camel_33050": 0, "camel_33580": 0, "camel_32045": 0, "camel_32789": 0, "camel_32804": 0, "camel_33747": 0, "camel_33170": 0, "camel_33160": 0, "camel_32849": 0, "camel_33069": 0, "camel_33431": 0, "camel_32973": 0, "camel_32852": 0, "camel_33168": 0, "camel_32618": 0, "camel_32802": 0, "camel_33511": 0, "camel_32729": 0, "camel_33930": 0, "camel_32860": 0, "camel_32775": 0, "camel_32979": 0, "camel_32997": 0, "camel_32909": 0, "camel_33008": 0, "camel_33395": 0, "camel_32571": 0, "camel_33073": 0, "camel_33494": 0, "camel_33595": 0, "camel_33501": 0, "camel_33284": 0, "camel_33173": 0, "camel_33467": 0, "camel_33733": 0, "camel_32912": 0, "camel_32751": 0, "camel_32869": 0, "camel_33593": 0, "camel_32988": 0, "camel_32944": 0, "camel_32781": 0, "camel_32931": 0, "camel_33596": 0, "camel_33584": 0, "camel_33140": 0, "camel_33013": 0, "camel_32990": 0, "camel_33402": 0, "camel_33838": 0, "camel_32835": 0, "camel_33657": 0, "camel_33519": 0, "camel_32994": 0, "camel_33381": 0, "camel_33141": 0, "camel_32927": 0, "camel_33452": 0, "camel_32629": 0, "camel_33387": 0, "camel_32526": 0, "camel_33113": 0, "camel_33913": 0, "camel_33417": 0, "camel_33623": 0, "camel_32052": 0, "camel_33984": 0, "camel_33150": 0, "camel_33781": 0, "camel_32902": 0, "camel_32977": 0, "camel_32891": 0, "camel_33316": 0, "camel_32600": 0, "camel_33694": 0, "camel_32634": 0, "camel_33701": 0, "camel_33824": 0, "camel_32851": 0, "camel_33154": 0, "camel_33430": 0, "camel_33755": 0, "camel_32827": 0, "camel_33564": 0, "camel_32792": 0, "camel_33224": 0, "camel_33635": 0, "camel_32777": 0, "camel_33854": 0, "camel_33344": 0, "camel_32942": 0, "camel_33351": 0, "camel_33411": 0, "camel_33625": 0, "camel_33138": 0, "camel_33192": 0, "camel_33071": 0, "camel_33446": 0, "camel_32573": 0, "camel_32945": 0, "camel_33137": 0, "camel_32938": 0, "camel_33196": 0, "camel_32886": 0, "camel_32541": 0, "camel_32623": 0, "camel_33748": 0, "camel_32928": 0, "camel_33091": 0, "camel_32967": 0, "camel_32999": 0, "camel_32953": 0, "camel_32786": 0, "camel_32750": 0, "camel_33592": 0, "camel_32598": 0, "camel_33652": 0, "camel_33448": 0, "camel_32838": 0, "camel_33947": 0, "camel_33727": 0, "camel_32900": 0, "camel_33047": 0, "camel_33148": 0, "camel_33497": 0, "camel_33082": 0, "camel_33463": 0, "camel_33530": 0, "camel_33968": 0, "camel_33129": 0, "camel_33475": 0, "camel_33449": 0, "camel_33457": 0, "camel_32955": 0, "camel_33191": 0, "camel_33070": 0, "camel_33598": 0, "camel_33407": 0, "camel_32578": 0, "camel_33435": 0, "camel_33199": 0, "camel_32741": 0, "camel_32529": 0, "camel_32995": 0, "camel_33156": 0, "camel_33848": 0, "camel_33396": 0, "camel_33325": 0, "camel_33090": 0, "camel_32954": 0, "camel_33538": 0, "camel_33941": 0, "camel_33618": 0, "camel_33376": 0, "camel_33574": 0, "camel_33171": 0, "camel_33175": 0, "camel_33453": 0, "camel_32857": 0, "camel_33529": 0, "camel_33736": 0, "camel_32992": 0, "camel_32488": 0, "camel_33495": 0, "camel_32582": 0, "camel_32612": 0, "camel_33513": 0, "camel_32904": 0, "camel_33936": 0, "camel_33517": 0, "camel_33462": 0, "TheoremQA_elainewan/math_abstact_algebra_7_8.json": 0, "camel_33470": 0, "camel_33025": 0, "camel_33832": 0, "camel_32906": 0, "camel_33159": 0, "camel_33480": 0, "camel_33382": 0, "camel_32769": 0, "camel_33818": 0, "camel_33944": 0, "camel_33095": 0, "camel_32766": 0, "camel_33533": 0, "camel_33397": 0, "camel_32864": 0, "camel_32605": 0, "camel_32608": 0, "camel_33704": 0, "camel_32580": 0, "camel_33750": 0}, "TheoremQA_panlu/rigid-body3.json": {"TheoremQA_panlu/rigid-body3.json": 0, "camel_5188": 0.7377548813819885, "aqua_rat_63465": 0.7377616167068481, "aqua_rat_82115": 0.737865149974823, "gsm_rft_35619": 0.7378924489021301, "camel_28878": 0.7378954291343689, "aqua_rat_85422": 0.737909734249115, "aqua_rat_77944": 0.7379187941551208, "TheoremQA_xinyi/work_energy_theorem.json": 0.737949788570404, "camel_4986": 0.7379708290100098, "camel_7956": 0.7381466627120972, "camel_39475": 0.7381551861763, "TheoremQA_panlu/uniform_circular_motion1.json": 0.7383965849876404, "gsm_train_2068": 0.7384033203125, "gsm_rft_4583": 0.7384033203125, "aqua_rat_35471": 0.7385095953941345, "aqua_rat_52253": 0.738514244556427, "aqua_rat_86593": 0.7385833859443665, "gsm_rft_16695": 0.7386821508407593, "aqua_rat_17232": 0.738724946975708, "gsm_rft_24421": 0.7387354969978333, "aqua_rat_69828": 0.738750696182251, "camel_28806": 0.7388108372688293, "gsm_rft_15416": 0.7389538884162903, "aqua_rat_15993": 0.7390676140785217, "gsm_rft_15228": 0.7391532063484192, "gsm_rft_2622": 0.7393468022346497, "gsm_rft_30211": 0.7393468022346497, "gsm_train_21663": 0.7393468022346497, "aqua_rat_42233": 0.7393816113471985, "camel_28833": 0.739416241645813, "aqua_rat_48959": 0.7394320964813232, "aqua_rat_77586": 0.7394798398017883, "aqua_rat_25695": 0.7395430207252502, "aqua_rat_78987": 0.739622950553894, "aqua_rat_60106": 0.739726185798645, "aqua_rat_9793": 0.7397486567497253, "aqua_rat_38590": 0.7399784326553345, "gsm_rft_14868": 0.7400888800621033, "aqua_rat_71139": 0.7402223348617554, "camel_28860": 0.7402341961860657, "aqua_rat_81657": 0.7403078079223633, "aqua_rat_8349": 0.7405573725700378, "camel_39485": 0.7405762672424316, "camel_39446": 0.7406765222549438, "camel_16299": 0.7407504320144653, "aqua_rat_46971": 0.7410484552383423, "aqua_rat_6676": 0.7412549257278442, "aqua_rat_18805": 0.7412608861923218, "aqua_rat_3331": 0.7413431406021118, "camel_39514": 0.741406261920929, "aqua_rat_36249": 0.7415643930435181, "aqua_rat_23853": 0.7416329383850098, "camel_28836": 0.7416954040527344, "aqua_rat_27720": 0.7417088150978088, "camel_7946": 0.7417219877243042, "camel_7511": 0.7418796420097351, "gsm_rft_12209": 0.74213707447052, "camel_5093": 0.7422733902931213, "camel_5117": 0.7424595355987549, "aqua_rat_42126": 0.7424763441085815, "aqua_rat_33984": 0.7425307631492615, "gsm_rft_2338": 0.7425726056098938, "camel_24344": 0.7427283525466919, "aqua_rat_75022": 0.7430676817893982, "camel_5079": 0.7430766820907593, "camel_5057": 0.7431338429450989, "camel_28862": 0.7437742948532104, "aqua_rat_6188": 0.7439020276069641, "aqua_rat_85602": 0.7441454529762268, "aqua_rat_43369": 0.7444285750389099, "aqua_rat_25446": 0.7444496154785156, "gsm_rft_15250": 0.7444526553153992, "aqua_rat_6798": 0.7444756031036377, "gsm_rft_7812": 0.7447025179862976, "gsm_train_21544": 0.7448217272758484, "camel_5284": 0.7448301315307617, "aqua_rat_83787": 0.7449422478675842, "gsm_rft_6897": 0.7449425458908081, "camel_5311": 0.7451100945472717, "camel_28815": 0.7453956604003906, "camel_28826": 0.7454779148101807, "camel_39452": 0.7457813620567322, "gsm_rft_25293": 0.7460698485374451, "aqua_rat_68459": 0.7464393973350525, "camel_28801": 0.7465476393699646, "aqua_rat_20932": 0.7469443678855896, "aqua_rat_2038": 0.7471566796302795, "gsm_train_32410": 0.747218132019043, "aqua_rat_64165": 0.7473160028457642, "gsm_rft_2985": 0.7473827600479126, "camel_28852": 0.747501790523529, "aqua_rat_62416": 0.7475223541259766, "aqua_rat_61332": 0.7476098537445068, "gsm_rft_18987": 0.7476382851600647, "camel_28875": 0.747684121131897, "camel_28832": 0.7477757334709167, "aqua_rat_26677": 0.7477877140045166, "camel_28822": 0.7478830218315125, "camel_28853": 0.7479453682899475, "aqua_rat_51417": 0.7483473420143127, "gsm_rft_14362": 0.748691737651825, "gsm_rft_34879": 0.748691737651825, "gsm_rft_22295": 0.7488257884979248, "gsm_train_21935": 0.7489740252494812, "TheoremQA_panlu/uniform_circular_motion2.json": 0.7492472529411316, "aqua_rat_8908": 0.7493289709091187, "aqua_rat_71816": 0.7496145963668823, "aqua_rat_17586": 0.749779462814331, "camel_28804": 0.7499131560325623, "aqua_rat_60136": 0.7499474287033081, "math_test_prealgebra_1007": 0.7500830888748169, "aqua_rat_87974": 0.7502140402793884, "camel_16246": 0.7502933740615845, "camel_28845": 0.7503170371055603, "gsm_train_13121": 0.7504956722259521, "aqua_rat_72406": 0.7505049109458923, "camel_5358": 0.7506798505783081, "gsm_rft_35323": 0.7507025599479675, "aqua_rat_6700": 0.7507125735282898, "gsm_rft_32498": 0.7508970499038696, "gsm_rft_27200": 0.7511422038078308, "gsm_train_21885": 0.7512125372886658, "gsm_rft_28487": 0.7513034343719482, "aqua_rat_51549": 0.751497745513916, "aqua_rat_40694": 0.7516581416130066, "aqua_rat_29881": 0.7517855167388916, "camel_39479": 0.7518470883369446, "aqua_rat_75694": 0.7518510818481445, "gsm_rft_35201": 0.7518723607063293, "aqua_rat_59830": 0.7521146535873413, "gsm_rft_6173": 0.7522395849227905, "camel_4993": 0.7525216937065125, "aqua_rat_20126": 0.7531032562255859, "camel_28805": 0.753150224685669, "camel_28831": 0.7531992793083191, "gsm_rft_28558": 0.7534882426261902, "gsm_rft_19149": 0.754388153553009, "gsm_train_2173": 0.75443434715271, "gsm_rft_19699": 0.75443434715271, "gsm_rft_7695": 0.7544956803321838, "camel_28808": 0.7546880841255188, "aqua_rat_49023": 0.7547594904899597, "gsm_rft_32618": 0.7547765970230103, "gsm_train_34318": 0.7548466920852661, "gsm_rft_8772": 0.7548781633377075, "aqua_rat_43469": 0.7549964189529419, "aqua_rat_12010": 0.75504469871521, "gsm_rft_9980": 0.7551840543746948, "camel_28867": 0.7562466859817505, "gsm_rft_3828": 0.7564338445663452, "aqua_rat_29570": 0.7564486265182495, "aqua_rat_66570": 0.7568149566650391, "gsm_rft_11389": 0.7572594881057739, "camel_28856": 0.7580477595329285, "camel_28812": 0.758378803730011, "camel_5344": 0.7586931586265564, "camel_4994": 0.7587156295776367, "camel_28873": 0.758867621421814, "aqua_rat_43435": 0.7589472532272339, "gsm_rft_57": 0.7591272592544556, "camel_4969": 0.759518027305603, "camel_28868": 0.7598435878753662, "camel_29979": 0.7603011727333069, "aqua_rat_3802": 0.7611075639724731, "camel_17811": 0.7615615725517273, "camel_28866": 0.7621369957923889, "camel_5029": 0.762491762638092, "camel_28809": 0.7636710405349731, "camel_5001": 0.7644751667976379, "camel_28846": 0.7656510472297668, "camel_28137": 0.7663025259971619, "gsm_rft_10474": 0.7663312554359436, "gsm_rft_2034": 0.7665302753448486, "gsm_rft_3538": 0.7665302753448486, "aqua_rat_77082": 0.7668242454528809, "gsm_train_21024": 0.7669236660003662, "camel_39513": 0.7673519253730774, "camel_5011": 0.7678964734077454, "aqua_rat_53348": 0.7688590288162231, "camel_4999": 0.7699376344680786, "aqua_rat_32037": 0.7700406312942505, "camel_4979": 0.7701087594032288, "camel_4972": 0.7704300284385681, "camel_28872": 0.770613968372345, "aqua_rat_57461": 0.7707932591438293, "aqua_rat_65833": 0.7718790769577026, "camel_28816": 0.7723385095596313, "camel_28811": 0.7727379202842712, "camel_5114": 0.7728183269500732, "camel_28840": 0.7729097008705139, "aqua_rat_4051": 0.7737599015235901, "camel_28847": 0.7753608822822571, "camel_17406": 0.7753749489784241, "camel_28842": 0.7762691974639893, "camel_5035": 0.776597797870636, "camel_5178": 0.7796983122825623, "camel_4987": 0.7838190197944641, "camel_5004": 0.8010664582252502, "TheoremQA_xinyi/newtons_laws_1.json": 0.8095892071723938}, "TheoremQA_xinyi/cramer_rao_lower_bound_2.json": {"camel_8730": 0, "camel_8794": 0, "camel_8751": 0, "camel_8368": 0, "camel_8750": 0, "camel_8361": 0, "camel_9484": 0, "camel_8733": 0, "camel_8351": 0, "camel_9364": 0, "camel_8383": 0, "camel_9398": 0, "camel_8722": 0, "TheoremQA_xinyi/cramer_rao_lower_bound_2.json": 0, "camel_9527": 0, "camel_9365": 0, "camel_8755": 0, "camel_9415": 0, "camel_9522": 0, "camel_8753": 0, "camel_8771": 0, "camel_9412": 0, "camel_8773": 0, "camel_17086": 0.7050917744636536, "camel_10800": 0.705102801322937, "camel_17106": 0.7051160335540771, "camel_40647": 0.7051644325256348, "camel_29326": 0.7052077054977417, "camel_17033": 0.7052435278892517, "camel_11057": 0.7052885890007019, "camel_11335": 0.7053618431091309, "camel_29329": 0.7054291367530823, "camel_11604": 0.7055492401123047, "camel_10887": 0.7056792378425598, "camel_16026": 0.7058244943618774, "camel_16826": 0.7058677077293396, "camel_17107": 0.705893874168396, "camel_16937": 0.7059063911437988, "camel_11188": 0.7059197425842285, "camel_29726": 0.7059211730957031, "camel_29295": 0.7059711217880249, "camel_28675": 0.7061408758163452, "camel_17116": 0.70620197057724, "camel_11181": 0.7063009142875671, "camel_29496": 0.7064616680145264, "camel_10341": 0.7064660787582397, "camel_10966": 0.7065286636352539, "camel_17088": 0.7065296769142151, "camel_17195": 0.7065951824188232, "camel_17095": 0.7066249847412109, "camel_11332": 0.7066313028335571, "camel_16830": 0.7068651914596558, "camel_16142": 0.7068899273872375, "camel_38717": 0.7070145606994629, "camel_40761": 0.7070310711860657, "camel_17098": 0.707038402557373, "camel_16024": 0.707213819026947, "camel_10930": 0.7073168158531189, "camel_17369": 0.707438588142395, "camel_17073": 0.7074461579322815, "camel_10950": 0.7075790166854858, "camel_16028": 0.7076498866081238, "camel_17374": 0.7076780200004578, "camel_16140": 0.7077525854110718, "camel_11282": 0.7078676223754883, "camel_17056": 0.707870364189148, "camel_16103": 0.7079607248306274, "camel_16857": 0.7079742550849915, "aqua_rat_59804": 0.7080554366111755, "camel_17085": 0.7080910801887512, "camel_16844": 0.7081294059753418, "camel_16058": 0.7082750201225281, "camel_17067": 0.7083629369735718, "camel_17096": 0.708462655544281, "camel_16133": 0.7086796760559082, "camel_10998": 0.7089670896530151, "camel_10953": 0.709133505821228, "camel_11000": 0.7091749906539917, "camel_29033": 0.7091938853263855, "camel_28663": 0.7092229723930359, "camel_10929": 0.7093647122383118, "camel_10867": 0.7094716429710388, "camel_16032": 0.7097043395042419, "camel_10351": 0.7098853588104248, "camel_16804": 0.7101016044616699, "camel_16132": 0.710145890712738, "camel_16850": 0.7101464867591858, "camel_17007": 0.7102732062339783, "TheoremQA_wenhuchen/Poisson_process3.json": 0.7102817296981812, "camel_29343": 0.710378885269165, "camel_17045": 0.7104595303535461, "camel_11182": 0.7105485200881958, "camel_28642": 0.710570216178894, "camel_17078": 0.7105806469917297, "camel_16043": 0.710681676864624, "camel_10939": 0.710853099822998, "camel_17104": 0.7109667062759399, "camel_17083": 0.7110312581062317, "camel_16078": 0.7110328078269958, "camel_17118": 0.7111102938652039, "camel_25102": 0.7112056612968445, "camel_29335": 0.7112464904785156, "camel_16956": 0.7112573385238647, "camel_17075": 0.7112929224967957, "camel_16136": 0.7113237380981445, "camel_16108": 0.7113604545593262, "camel_16118": 0.7115623950958252, "camel_16119": 0.7116509079933167, "camel_10364": 0.7116871476173401, "camel_16052": 0.7116907238960266, "camel_11643": 0.7118520736694336, "camel_25107": 0.7118626236915588, "camel_16076": 0.7120690941810608, "camel_16050": 0.7120842933654785, "camel_17109": 0.71220463514328, "camel_10375": 0.712550938129425, "camel_16002": 0.7128792405128479, "camel_17184": 0.7133350372314453, "camel_16891": 0.7134357690811157, "camel_11294": 0.7135403156280518, "camel_17065": 0.7136000394821167, "camel_11649": 0.713678240776062, "camel_16049": 0.713750422000885, "camel_29080": 0.7137869596481323, "TheoremQA_xinyi/expected_distortion.json": 0.7138303518295288, "camel_10944": 0.7138321399688721, "camel_28691": 0.7141723036766052, "camel_17079": 0.7141919136047363, "camel_11355": 0.7142742872238159, "camel_16828": 0.714348554611206, "camel_17041": 0.7144084572792053, "camel_17108": 0.7144765257835388, "camel_11323": 0.7145645022392273, "camel_11412": 0.7145991325378418, "camel_17090": 0.7146263122558594, "camel_17070": 0.7146698236465454, "camel_16037": 0.7149171233177185, "camel_10380": 0.7151736617088318, "camel_16035": 0.7151864767074585, "camel_29294": 0.7152189016342163, "camel_17074": 0.7153022885322571, "camel_38643": 0.7154234647750854, "camel_28701": 0.7154256701469421, "camel_25161": 0.7154704332351685, "camel_16075": 0.7154859900474548, "camel_16126": 0.7159433960914612, "camel_16834": 0.7161083817481995, "camel_10979": 0.7161397933959961, "camel_17037": 0.7161936163902283, "camel_17094": 0.7162917852401733, "camel_10934": 0.716544508934021, "camel_10936": 0.7165767550468445, "camel_16067": 0.7168010473251343, "camel_10833": 0.7171603441238403, "camel_16079": 0.7173866033554077, "camel_16062": 0.7174858450889587, "camel_16045": 0.7175397872924805, "camel_16122": 0.7176614999771118, "camel_17097": 0.7177547812461853, "camel_11296": 0.7177621722221375, "camel_16054": 0.7178670167922974, "camel_16040": 0.7180889844894409, "camel_38650": 0.7181854248046875, "camel_17125": 0.7184234261512756, "camel_16813": 0.7184948325157166, "camel_10941": 0.7188169956207275, "camel_16072": 0.7190138697624207, "camel_17112": 0.7191221714019775, "camel_10895": 0.7192532420158386, "camel_17049": 0.7192533612251282, "camel_16902": 0.7198407649993896, "camel_16021": 0.7198876738548279, "camel_16840": 0.71996009349823, "camel_16862": 0.720698893070221, "camel_16063": 0.7207603454589844, "camel_16005": 0.7212399244308472, "camel_11365": 0.7212454676628113, "camel_16106": 0.7213398814201355, "camel_16036": 0.7215862274169922, "camel_16113": 0.7218061685562134, "camel_16003": 0.7225757241249084, "camel_16065": 0.7228177785873413, "camel_11281": 0.723067581653595, "camel_28974": 0.7230956554412842, "camel_16041": 0.7235819697380066, "camel_17068": 0.7252495288848877, "camel_16112": 0.7269611954689026, "camel_16149": 0.7269665002822876, "camel_16860": 0.7270154356956482, "camel_11161": 0.7277247905731201, "camel_17178": 0.7285987734794617, "camel_38649": 0.7297698259353638, "camel_16013": 0.7315207123756409, "camel_17062": 0.7326076626777649, "TheoremQA_xinyi/maximum_entropy_2.json": 0.7357480525970459, "camel_10352": 0.7376124262809753, "camel_16815": 0.7379185557365417, "camel_16033": 0.7548531293869019, "TheoremQA_xinyi/fisher_information_3.json": 0.7754016518592834, "TheoremQA_xinyi/cramer_rao_lower_bound_1.json": 0.7984153628349304}, "TheoremQA_elainewan/math_algebra_5.json": {"camel_15682": 0, "camel_15073": 0, "camel_15068": 0, "camel_15090": 0, "camel_15620": 0, "camel_15104": 0, "camel_15110": 0, "camel_15117": 0, "camel_15846": 0, "camel_15716": 0, "camel_15101": 0, "camel_15099": 0, "camel_15794": 0, "camel_15092": 0, "camel_15095": 0, "camel_15050": 0, "camel_14274": 0, "camel_15666": 0, "camel_15816": 0, "camel_15807": 0, "camel_15886": 0, "camel_15115": 0, "camel_15098": 0, "camel_15097": 0, "camel_15067": 0, "camel_15066": 0, "camel_15746": 0, "camel_15727": 0, "camel_15770": 0, "camel_15683": 0, "camel_15857": 0, "camel_15076": 0, "camel_15105": 0, "camel_15088": 0, "camel_15764": 0, "camel_15070": 0, "camel_15796": 0, "camel_15803": 0, "camel_14442": 0, "camel_15792": 0, "camel_15064": 0, "camel_15083": 0, "camel_15112": 0, "camel_15821": 0, "camel_15077": 0, "camel_15057": 0, "camel_15114": 0, "camel_15832": 0, "camel_15043": 0, "camel_15084": 0, "camel_15047": 0, "camel_15079": 0, "camel_14261": 0, "camel_15108": 0, "camel_15826": 0, "camel_15121": 0, "camel_15837": 0, "camel_15042": 0, "camel_15106": 0, "camel_15815": 0, "camel_15054": 0, "camel_15062": 0, "TheoremQA_elainewan/math_algebra_5.json": 0, "camel_15085": 0, "camel_15063": 0, "camel_15094": 0, "camel_15102": 0, "camel_15069": 0, "camel_15075": 0, "camel_15702": 0, "camel_15053": 0, "camel_15109": 0, "camel_15705": 0, "camel_15065": 0, "camel_15818": 0, "camel_15074": 0, "camel_15056": 0, "camel_15721": 0, "camel_15760": 0, "camel_15072": 0, "camel_15040": 0, "camel_15093": 0, "camel_14175": 0, "camel_15061": 0, "camel_15051": 0, "camel_9358": 0.7363592982292175, "camel_40117": 0.7363703846931458, "camel_40089": 0.7366733551025391, "camel_9344": 0.7367889881134033, "camel_9299": 0.736794114112854, "camel_9351": 0.7370234131813049, "camel_40097": 0.7371267080307007, "camel_40096": 0.737148642539978, "camel_9300": 0.7371882796287537, "camel_40111": 0.737260103225708, "camel_17674": 0.737328290939331, "camel_40120": 0.737384021282196, "camel_9317": 0.7373911142349243, "camel_47699": 0.7376106977462769, "camel_49146": 0.7376898527145386, "camel_9319": 0.7379295825958252, "camel_5902": 0.7382135987281799, "camel_40137": 0.7382383942604065, "camel_40145": 0.7383407354354858, "camel_9283": 0.7385493516921997, "camel_19739": 0.738616943359375, "camel_40840": 0.7389937043190002, "camel_5823": 0.7390350699424744, "camel_40141": 0.7396940588951111, "camel_9320": 0.7396997213363647, "camel_5683": 0.7397807836532593, "camel_5897": 0.7399486303329468, "camel_9359": 0.7401893734931946, "camel_49177": 0.7403892874717712, "camel_40108": 0.7408427000045776, "camel_40118": 0.7410091161727905, "camel_40122": 0.7415019869804382, "camel_40132": 0.7415482997894287, "camel_5895": 0.7430013418197632, "camel_5692": 0.7430201172828674, "camel_9330": 0.7432159781455994, "camel_5864": 0.7441319823265076, "camel_19686": 0.7444642186164856, "camel_40082": 0.744685709476471, "camel_5622": 0.7451429963111877, "camel_9310": 0.7458834052085876, "camel_5912": 0.7465531229972839, "camel_49173": 0.7468349933624268, "math_test_precalculus_1218": 0.7470381259918213, "camel_40116": 0.7470595836639404, "camel_9294": 0.7472374439239502, "camel_5896": 0.7473994493484497, "camel_40114": 0.7474344372749329, "TheoremQA_elainewan/math_algebra_3.json": 0.7476030588150024, "camel_40140": 0.7482338547706604, "camel_9296": 0.7483921647071838, "camel_9288": 0.7484212517738342, "camel_5705": 0.7487284541130066, "camel_5907": 0.7488054633140564, "camel_5901": 0.7488340139389038, "TheoremQA_elainewan/math_algebra_3_4.json": 0.7493922710418701, "camel_9329": 0.7499126195907593, "camel_5868": 0.7499356865882874, "camel_5875": 0.749961793422699, "camel_5906": 0.7500615119934082, "camel_9342": 0.750078558921814, "TheoremQA_elainewan/math_algebra_3_2.json": 0.7505421042442322, "camel_5867": 0.750565230846405, "camel_5664": 0.7512205243110657, "camel_49182": 0.7517150044441223, "camel_5913": 0.7518986463546753, "camel_8985": 0.7519897222518921, "camel_5915": 0.7520259618759155, "camel_5848": 0.7522017955780029, "camel_5704": 0.7529096007347107, "camel_19702": 0.7531090378761292, "camel_5872": 0.7532304525375366, "camel_49165": 0.7534615397453308, "camel_5887": 0.7536286115646362, "camel_49882": 0.7542421221733093, "camel_5843": 0.7542718052864075, "camel_5851": 0.7547236680984497, "camel_5904": 0.7554712891578674, "camel_5739": 0.756270170211792, "TheoremQA_elainewan/math_algebra_4.json": 0.757060706615448, "camel_5847": 0.757131040096283, "aqua_rat_67418": 0.7585399746894836, "camel_5876": 0.7596898674964905, "camel_49180": 0.760432243347168, "camel_49126": 0.7606003284454346, "camel_5889": 0.760947048664093, "camel_49121": 0.7617132067680359, "camel_5914": 0.761789083480835, "camel_49168": 0.7634092569351196, "camel_5892": 0.7655854821205139, "camel_5865": 0.7656240463256836, "camel_5881": 0.7664095163345337, "camel_40126": 0.7683340311050415, "camel_5916": 0.7684626579284668, "camel_5846": 0.7686198949813843, "camel_49851": 0.7687835693359375, "camel_5882": 0.7693681120872498, "camel_5858": 0.7714043855667114, "camel_5878": 0.7714749574661255, "camel_5888": 0.7737719416618347, "camel_5910": 0.7760725021362305, "camel_5879": 0.7778440117835999, "camel_5917": 0.7782888412475586, "camel_5898": 0.7783029675483704, "camel_5919": 0.7799339890480042, "camel_5863": 0.7802019119262695, "camel_5911": 0.7804151773452759, "camel_5877": 0.780692458152771, "camel_5903": 0.7816721200942993, "camel_5870": 0.7817166447639465, "camel_5859": 0.7824105024337769, "camel_5874": 0.7842327952384949, "camel_5869": 0.7864817976951599, "camel_5871": 0.7878631353378296, "camel_36766": 0.7934145927429199}, "TheoremQA_xueguangma/taylors_approximation_theorem.json": {"camel_7125": 0, "camel_7208": 0, "camel_6560": 0, "camel_7474": 0, "camel_7221": 0, "camel_6031": 0, "camel_7648": 0, "camel_7250": 0, "camel_7472": 0, "camel_7510": 0, "camel_6599": 0, "camel_7603": 0, "camel_7631": 0, "camel_6027": 0, "camel_7237": 0, "camel_7267": 0, "camel_7507": 0, "camel_6631": 0, "camel_7459": 0, "camel_7509": 0, "camel_7215": 0, "camel_7502": 0, "camel_7656": 0, "camel_6014": 0, "camel_7646": 0, "camel_6009": 0, "camel_6017": 0, "camel_6612": 0, "camel_7620": 0, "camel_7252": 0, "camel_7236": 0, "camel_7160": 0, "camel_6012": 0, "camel_7223": 0, "camel_7487": 0, "camel_7224": 0, "camel_7247": 0, "camel_6059": 0, "camel_6617": 0, "camel_7455": 0, "camel_7516": 0, "camel_6049": 0, "camel_7601": 0, "camel_7276": 0, "camel_7649": 0, "camel_7602": 0, "camel_6078": 0, "camel_7445": 0, "camel_7628": 0, "camel_7452": 0, "camel_6600": 0, "camel_7214": 0, "camel_6881": 0, "camel_6016": 0, "camel_7257": 0, "camel_6632": 0, "camel_6578": 0, "camel_6602": 0, "camel_6630": 0, "camel_6005": 0, "camel_6053": 0, "camel_6588": 0, "camel_6075": 0, "camel_6565": 0, "camel_6043": 0, "camel_7273": 0, "camel_6591": 0, "camel_7517": 0, "camel_7505": 0, "camel_7486": 0, "camel_6569": 0, "camel_6566": 0, "camel_7672": 0, "camel_7254": 0, "camel_6607": 0, "camel_6024": 0, "camel_7503": 0, "camel_7457": 0, "camel_6615": 0, "camel_6100": 0, "camel_6074": 0, "camel_7410": 0, "camel_6608": 0, "camel_7227": 0, "camel_7670": 0, "camel_6022": 0, "camel_7226": 0, "camel_6586": 0, "camel_7233": 0, "camel_6045": 0, "camel_7234": 0, "camel_7260": 0, "camel_6604": 0, "camel_7622": 0, "camel_7211": 0, "camel_7245": 0, "camel_7668": 0, "camel_6563": 0, "camel_7202": 0, "camel_7513": 0, "camel_7266": 0, "camel_7659": 0, "camel_7205": 0, "camel_6639": 0, "camel_7607": 0, "camel_7996": 0, "camel_6071": 0, "camel_6060": 0, "camel_7641": 0, "camel_6618": 0, "camel_7207": 0, "camel_6561": 0, "camel_7270": 0, "camel_7262": 0, "camel_7500": 0, "camel_6593": 0, "camel_7203": 0, "camel_6571": 0, "camel_7501": 0, "camel_6634": 0, "camel_7614": 0, "camel_7618": 0, "camel_7679": 0, "camel_6587": 0, "camel_6151": 0, "camel_7613": 0, "camel_6564": 0, "camel_6015": 0, "camel_7629": 0, "camel_6033": 0, "camel_6622": 0, "camel_6413": 0, "camel_6825": 0, "camel_6629": 0, "camel_6580": 0, "camel_6613": 0, "camel_6562": 0, "camel_6579": 0, "camel_6610": 0, "camel_6589": 0, "camel_6575": 0, "camel_6605": 0, "camel_7248": 0, "camel_6635": 0, "camel_7277": 0, "camel_6633": 0, "camel_6624": 0, "camel_7669": 0, "camel_7606": 0, "camel_7924": 0, "camel_6621": 0, "camel_6019": 0, "camel_6611": 0, "camel_6044": 0, "camel_6573": 0, "camel_7238": 0, "camel_6606": 0, "camel_6637": 0, "camel_6035": 0, "camel_6628": 0, "camel_6616": 0, "camel_7621": 0, "camel_6592": 0, "camel_6597": 0, "camel_6596": 0, "camel_6609": 0, "camel_7636": 0, "camel_6626": 0, "camel_6601": 0, "camel_6583": 0, "camel_6849": 0, "camel_6614": 0, "camel_6619": 0, "camel_6623": 0, "camel_6061": 0, "camel_6585": 0, "camel_6594": 0, "camel_6577": 0, "camel_40255": 0.7600138187408447, "camel_40302": 0.76003098487854, "camel_18891": 0.7600594758987427, "camel_40761": 0.7605583667755127, "camel_18920": 0.7641446590423584, "camel_28715": 0.7642021775245667, "camel_45318": 0.7642808556556702, "aqua_rat_12508": 0.7666689157485962, "camel_28086": 0.766874372959137, "TheoremQA_elainewan/math_calculus_2_4.json": 0.7678341269493103, "camel_5376": 0.767883837223053, "camel_18886": 0.7684758901596069, "camel_40240": 0.769241213798523, "camel_39486": 0.7702013254165649, "camel_5425": 0.7727113366127014, "camel_40267": 0.7730503082275391, "camel_18909": 0.7730836272239685, "camel_40258": 0.7751559019088745, "camel_18917": 0.7777976393699646, "TheoremQA_wenhuchen/L'H\u00f4pital_rule1.json": 0.7821310758590698, "camel_18951": 0.8007612228393555, "camel_18905": 0.8025678992271423}, "TheoremQA_maxku/signalprocessing5-nyquist.json": {"TheoremQA_maxku/signalprocessing5-nyquist.json": 0, "camel_44521": 0.6532720327377319, "gsm_rft_11985": 0.6535921692848206, "camel_44466": 0.6537008285522461, "gsm_rft_14307": 0.6539453864097595, "camel_45184": 0.6541546583175659, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.6545402407646179, "camel_45791": 0.6546867489814758, "camel_45988": 0.6549251675605774, "camel_44526": 0.6549383401870728, "camel_45806": 0.6551777720451355, "camel_45830": 0.6551861763000488, "camel_44729": 0.6552290916442871, "camel_44765": 0.6555228233337402, "gsm_train_24835": 0.6555260419845581, "camel_45176": 0.655597448348999, "gsm_rft_12264": 0.6556293964385986, "camel_44795": 0.6557950973510742, "gsm_rft_31265": 0.6560012698173523, "gsm_rft_12367": 0.656046986579895, "camel_44750": 0.6561020612716675, "camel_45771": 0.6564770340919495, "camel_44524": 0.656761646270752, "camel_44760": 0.656780481338501, "camel_45718": 0.6570346355438232, "camel_45687": 0.6571564674377441, "camel_45710": 0.6571924090385437, "camel_44775": 0.6572383642196655, "camel_44752": 0.6574092507362366, "camel_45821": 0.6576012969017029, "camel_45130": 0.657723605632782, "camel_44782": 0.6577911376953125, "camel_44442": 0.6578435897827148, "camel_45169": 0.6582068800926208, "camel_44826": 0.6583347320556641, "camel_45342": 0.6583428978919983, "camel_44473": 0.6585432291030884, "gsm_rft_19302": 0.6589265465736389, "camel_45129": 0.6594153642654419, "camel_45722": 0.6596136093139648, "camel_45637": 0.6598072052001953, "camel_45745": 0.6599169373512268, "camel_44788": 0.6599805951118469, "camel_44061": 0.6608375310897827, "camel_44852": 0.6609613299369812, "camel_45162": 0.6625828742980957, "camel_45133": 0.6628623604774475, "camel_45949": 0.6630666255950928, "camel_45700": 0.6634549498558044, "camel_45401": 0.6635911464691162, "camel_44552": 0.6636542677879333, "camel_44749": 0.6641322374343872, "camel_45788": 0.6641707420349121, "camel_44523": 0.6642898321151733, "camel_45798": 0.6643534302711487, "camel_44785": 0.6644077897071838, "camel_44772": 0.6645159721374512, "camel_44746": 0.6645225286483765, "camel_44486": 0.6648593544960022, "camel_45765": 0.6648815870285034, "camel_45998": 0.6650443077087402, "camel_44783": 0.6652741432189941, "camel_44865": 0.6653807163238525, "camel_45683": 0.6654090881347656, "camel_45948": 0.6656858325004578, "camel_44748": 0.6664187908172607, "camel_45792": 0.6664823889732361, "camel_45790": 0.6666812896728516, "camel_45314": 0.6677562594413757, "camel_44761": 0.6680420637130737, "camel_45615": 0.6683616638183594, "camel_45713": 0.6688076853752136, "camel_45654": 0.668975830078125, "camel_44500": 0.6692683100700378, "camel_45134": 0.669327437877655, "camel_45688": 0.6695538759231567, "camel_45173": 0.6695626974105835, "camel_45693": 0.6698571443557739, "camel_45772": 0.669903039932251, "camel_45966": 0.6700494289398193, "camel_45744": 0.6707929372787476, "camel_45155": 0.6708956360816956, "camel_45712": 0.6709133982658386, "camel_44528": 0.6711729168891907, "camel_44544": 0.6712768077850342, "camel_44533": 0.6713967323303223, "camel_45725": 0.6714531183242798, "camel_45706": 0.6718018054962158, "camel_45151": 0.672264814376831, "camel_44806": 0.6725812554359436, "camel_44504": 0.672782838344574, "gsm_rft_33863": 0.6736745834350586, "camel_45776": 0.6750766038894653, "camel_44475": 0.6754913926124573, "camel_44534": 0.6755680441856384, "camel_45600": 0.6758660674095154, "camel_45709": 0.6760888695716858, "camel_45775": 0.6763014793395996, "camel_44790": 0.6763548851013184, "camel_45784": 0.6764062643051147, "camel_45690": 0.676448404788971, "gsm_rft_11471": 0.6765766739845276, "camel_44426": 0.6766425967216492, "camel_45803": 0.677439272403717, "camel_44416": 0.6775935888290405, "camel_44507": 0.6782540082931519, "camel_44839": 0.6783053874969482, "camel_44828": 0.6783319115638733, "camel_44741": 0.678536057472229, "camel_45680": 0.6785854697227478, "camel_45512": 0.6800071001052856, "camel_44420": 0.6808794736862183, "camel_44851": 0.6811885833740234, "camel_45763": 0.6812554597854614, "camel_45727": 0.6822319030761719, "camel_44755": 0.6822686791419983, "camel_45152": 0.6828702688217163, "camel_44799": 0.6829074025154114, "camel_44536": 0.6829432249069214, "camel_45149": 0.6838881969451904, "camel_44554": 0.68421471118927, "camel_44732": 0.684403657913208, "camel_44471": 0.6844069957733154, "camel_45935": 0.6845449209213257, "camel_29166": 0.6848306059837341, "camel_44462": 0.6849109530448914, "camel_45606": 0.6854304075241089, "camel_45939": 0.6862773299217224, "camel_44728": 0.6863201856613159, "camel_45797": 0.6869436502456665, "camel_45754": 0.6880450248718262, "camel_45952": 0.6885996460914612, "gsm_train_20944": 0.6887144446372986, "gsm_rft_21298": 0.6887144446372986, "TheoremQA_maxku/signalprocessing19-period.json": 0.6888062953948975, "camel_45781": 0.6894336342811584, "camel_45198": 0.6895613670349121, "camel_45786": 0.6901674866676331, "camel_44516": 0.6904996633529663, "camel_44848": 0.691084086894989, "camel_44807": 0.691745936870575, "camel_44762": 0.6920127868652344, "camel_44846": 0.6925561428070068, "camel_44820": 0.6930921077728271, "camel_45818": 0.6957725882530212, "camel_44467": 0.6977711915969849, "camel_45756": 0.6978317499160767, "camel_45682": 0.6979193687438965, "camel_44498": 0.6984328627586365, "camel_44401": 0.6985090970993042, "camel_45684": 0.6987425088882446, "TheoremQA_maxku/signalprocessing18-noisebark.json": 0.6988438367843628, "camel_44861": 0.7004027962684631, "camel_44538": 0.7006279230117798, "camel_45199": 0.7013679146766663, "camel_45159": 0.7016720175743103, "camel_44487": 0.7020118832588196, "camel_45931": 0.7030458450317383, "camel_44798": 0.705685555934906, "camel_44543": 0.7059150338172913, "camel_44492": 0.7061174511909485, "camel_45936": 0.7064929008483887, "camel_44849": 0.7078295350074768, "camel_44439": 0.7098442316055298, "camel_45604": 0.7105556726455688, "camel_44766": 0.7121554613113403, "camel_44872": 0.7133809924125671, "camel_45836": 0.7146456837654114, "camel_45607": 0.7146530747413635, "camel_45146": 0.714765191078186, "camel_45171": 0.7147958874702454, "camel_44758": 0.7151756882667542, "camel_44491": 0.7159368395805359, "camel_45805": 0.7187126278877258, "camel_44537": 0.7189038395881653, "camel_45799": 0.719566285610199, "camel_44460": 0.7199442982673645, "camel_45812": 0.7199792265892029, "camel_44447": 0.7235838770866394, "camel_44424": 0.7367410659790039, "camel_45809": 0.7409337759017944, "camel_45796": 0.74516761302948, "camel_45676": 0.7454304695129395, "camel_44838": 0.7497329711914062, "camel_44411": 0.761881411075592, "camel_44835": 0.7669327855110168, "camel_44724": 0.7688969969749451, "camel_45764": 0.775854766368866, "camel_44459": 0.7759609818458557, "camel_45646": 0.7830274105072021, "camel_44873": 0.8050947189331055, "TheoremQA_maxku/signalprocessing10-nyquist.json": 0.8482427597045898, "camel_44400": 0.8502631187438965, "camel_45819": 0.8537375330924988, "TheoremQA_maxku/signalprocessing12-nyquist.json": 0.8555378913879395, "camel_45810": 0.8639132976531982, "TheoremQA_maxku/signalprocessing11-nyquist.json": 0.8724650144577026, "camel_44860": 0.8743349313735962, "camel_45807": 0.8746781945228577, "camel_45778": 0.9099703431129456}, "TheoremQA_xueguangma/spot_rate.json": {"TheoremQA_xueguangma/spot_rate.json": 0, "aqua_rat_52833": 0.6964408159255981, "aqua_rat_45586": 0.6964625716209412, "aqua_rat_17286": 0.696465015411377, "aqua_rat_48189": 0.6965963244438171, "aqua_rat_4833": 0.696797788143158, "aqua_rat_74914": 0.6968522071838379, "aqua_rat_10497": 0.6968993544578552, "gsm_rft_6422": 0.6969248056411743, "aqua_rat_80315": 0.6969872713088989, "aqua_rat_9530": 0.697033166885376, "aqua_rat_40718": 0.6970757246017456, "aqua_rat_5454": 0.6971986293792725, "aqua_rat_13348": 0.6973477602005005, "aqua_rat_6386": 0.6975971460342407, "aqua_rat_38648": 0.6977046728134155, "aqua_rat_74699": 0.6977138519287109, "aqua_rat_70745": 0.697895348072052, "aqua_rat_8732": 0.6980560421943665, "aqua_rat_38068": 0.6982178688049316, "aqua_rat_88687": 0.698229968547821, "aqua_rat_61597": 0.6983481049537659, "aqua_rat_46525": 0.6985263228416443, "aqua_rat_87484": 0.6985520720481873, "aqua_rat_74184": 0.6987639665603638, "aqua_rat_24542": 0.6988641023635864, "aqua_rat_57725": 0.6989729404449463, "aqua_rat_62371": 0.6993501782417297, "aqua_rat_67074": 0.6993513703346252, "aqua_rat_45487": 0.69936603307724, "aqua_rat_44830": 0.6998044848442078, "aqua_rat_46552": 0.699832022190094, "aqua_rat_65797": 0.6998975276947021, "aqua_rat_29356": 0.7000946998596191, "aqua_rat_44517": 0.7001779675483704, "aqua_rat_72850": 0.7003690004348755, "aqua_rat_76497": 0.7004222273826599, "aqua_rat_82832": 0.7004836797714233, "aqua_rat_6634": 0.7004886269569397, "aqua_rat_87442": 0.7005285024642944, "aqua_rat_83566": 0.7008569240570068, "camel_16789": 0.7009474635124207, "aqua_rat_611": 0.7010573744773865, "aqua_rat_65449": 0.7011681795120239, "aqua_rat_16258": 0.7014870643615723, "aqua_rat_63735": 0.7015981674194336, "aqua_rat_66654": 0.701622724533081, "aqua_rat_84755": 0.7021805644035339, "aqua_rat_75273": 0.7021921873092651, "aqua_rat_71866": 0.7024074792861938, "aqua_rat_42893": 0.702445387840271, "aqua_rat_23331": 0.7027924656867981, "aqua_rat_46533": 0.7028011083602905, "aqua_rat_23452": 0.7028346657752991, "TheoremQA_xueguangma/capital_asset_pricing_model.json": 0.7029092311859131, "aqua_rat_73183": 0.7029626965522766, "aqua_rat_16984": 0.7031142711639404, "aqua_rat_39856": 0.703251838684082, "aqua_rat_36703": 0.7034412622451782, "aqua_rat_63174": 0.7034652233123779, "aqua_rat_9857": 0.7034922242164612, "aqua_rat_83178": 0.7037066221237183, "aqua_rat_23247": 0.7039161920547485, "aqua_rat_20307": 0.7041058540344238, "aqua_rat_70447": 0.7042505145072937, "aqua_rat_53305": 0.7043070793151855, "aqua_rat_87486": 0.7044155597686768, "aqua_rat_80518": 0.7044617533683777, "aqua_rat_51753": 0.7045159935951233, "aqua_rat_78962": 0.7045237421989441, "aqua_rat_70031": 0.7045366764068604, "aqua_rat_36837": 0.7045475840568542, "aqua_rat_75132": 0.7046979665756226, "TheoremQA_xueguangma/dividend_discount_model_5.json": 0.7052111029624939, "aqua_rat_14235": 0.7053845524787903, "aqua_rat_48456": 0.7057811617851257, "aqua_rat_65316": 0.7059335112571716, "aqua_rat_50029": 0.70595782995224, "aqua_rat_76805": 0.7061687111854553, "aqua_rat_65768": 0.7062528729438782, "aqua_rat_27652": 0.7063153982162476, "aqua_rat_61724": 0.7064144015312195, "aqua_rat_38199": 0.7064728140830994, "aqua_rat_6283": 0.7066648602485657, "aqua_rat_54028": 0.7066964507102966, "aqua_rat_53180": 0.7068014144897461, "aqua_rat_27143": 0.7068437933921814, "aqua_rat_1440": 0.707182765007019, "aqua_rat_55287": 0.7074489593505859, "aqua_rat_69764": 0.707632839679718, "aqua_rat_17663": 0.7077869772911072, "aqua_rat_16875": 0.7078368663787842, "aqua_rat_34853": 0.7079071402549744, "aqua_rat_76597": 0.7079159617424011, "aqua_rat_84646": 0.7079262137413025, "aqua_rat_63067": 0.7080638408660889, "aqua_rat_31099": 0.7082134485244751, "aqua_rat_8298": 0.7082338333129883, "aqua_rat_37709": 0.708373486995697, "aqua_rat_72430": 0.7085381150245667, "aqua_rat_24247": 0.708640992641449, "aqua_rat_83846": 0.7086817622184753, "aqua_rat_28409": 0.7089791893959045, "aqua_rat_38204": 0.7091181874275208, "aqua_rat_40297": 0.7093115448951721, "aqua_rat_28984": 0.7094232439994812, "aqua_rat_3830": 0.7096464037895203, "aqua_rat_80837": 0.7096925973892212, "aqua_rat_9488": 0.7102500200271606, "aqua_rat_67442": 0.7104717493057251, "aqua_rat_36461": 0.711033284664154, "aqua_rat_73250": 0.7111154794692993, "aqua_rat_84306": 0.7115998268127441, "aqua_rat_46883": 0.7118568420410156, "aqua_rat_23277": 0.7124778628349304, "aqua_rat_3885": 0.7125067114830017, "aqua_rat_59587": 0.7125089764595032, "aqua_rat_76011": 0.7126979827880859, "aqua_rat_24182": 0.713034451007843, "aqua_rat_29417": 0.7131702899932861, "aqua_rat_61197": 0.7135750651359558, "aqua_rat_73739": 0.7137166261672974, "aqua_rat_55355": 0.713878870010376, "aqua_rat_47761": 0.7141171097755432, "aqua_rat_80511": 0.7142040133476257, "aqua_rat_79047": 0.7143039107322693, "aqua_rat_32568": 0.7156278491020203, "aqua_rat_50660": 0.7160879373550415, "aqua_rat_6475": 0.7165284752845764, "aqua_rat_10991": 0.7168623208999634, "aqua_rat_44264": 0.7175552248954773, "gsm_rft_16062": 0.7179682850837708, "aqua_rat_12055": 0.718275785446167, "gsm_rft_25231": 0.718443751335144, "gsm_train_19719": 0.718443751335144, "aqua_rat_12197": 0.7184840440750122, "aqua_rat_2632": 0.7187902927398682, "aqua_rat_54684": 0.7189491391181946, "aqua_rat_32397": 0.7190783619880676, "aqua_rat_34081": 0.719447135925293, "aqua_rat_83756": 0.7196621298789978, "aqua_rat_72737": 0.7196903228759766, "aqua_rat_78533": 0.7197060585021973, "aqua_rat_20758": 0.7202373147010803, "aqua_rat_1115": 0.720668375492096, "aqua_rat_37203": 0.7213562726974487, "aqua_rat_17583": 0.7214109301567078, "aqua_rat_56718": 0.7216249704360962, "aqua_rat_46315": 0.7218248844146729, "aqua_rat_54496": 0.7218477725982666, "aqua_rat_18261": 0.7219568490982056, "aqua_rat_64296": 0.7221369743347168, "aqua_rat_40411": 0.7223250865936279, "aqua_rat_26425": 0.7226688265800476, "aqua_rat_65425": 0.7231232523918152, "aqua_rat_13451": 0.7232510447502136, "aqua_rat_45867": 0.7236373424530029, "aqua_rat_77609": 0.7237701416015625, "TheoremQA_xueguangma/present_value_2.json": 0.7242909073829651, "aqua_rat_48160": 0.7246332168579102, "aqua_rat_89048": 0.7247377038002014, "aqua_rat_71911": 0.7247964143753052, "aqua_rat_70160": 0.7249597311019897, "aqua_rat_9874": 0.7252511382102966, "camel_37746": 0.7255071997642517, "math_train_algebra_940": 0.7255218029022217, "aqua_rat_78570": 0.7270455360412598, "camel_37735": 0.7271867990493774, "aqua_rat_79789": 0.7291539907455444, "aqua_rat_59199": 0.7294718623161316, "aqua_rat_56436": 0.7298234105110168, "aqua_rat_83671": 0.7309767007827759, "aqua_rat_30597": 0.7312403321266174, "aqua_rat_88843": 0.7319546937942505, "aqua_rat_64523": 0.7348646521568298, "aqua_rat_57507": 0.7367141842842102, "aqua_rat_18811": 0.7377204895019531, "TheoremQA_xueguangma/forward_rate_1.json": 0.7408210039138794, "camel_16747": 0.7408854961395264, "aqua_rat_36498": 0.740959107875824, "aqua_rat_77105": 0.7431215047836304, "aqua_rat_84779": 0.7451647520065308, "aqua_rat_56845": 0.7455180287361145, "aqua_rat_32321": 0.7455439567565918, "TheoremQA_xueguangma/present_value_1.json": 0.7465534806251526, "aqua_rat_26043": 0.7520279288291931, "aqua_rat_80676": 0.7532944679260254, "aqua_rat_49352": 0.7662985920906067, "aqua_rat_79856": 0.7668081521987915, "TheoremQA_xueguangma/forward_price_3.json": 0.7712021470069885, "TheoremQA_xueguangma/put_call_parity_1.json": 0.7752487659454346, "aqua_rat_31553": 0.7834166884422302, "aqua_rat_45508": 0.7882305979728699, "aqua_rat_29154": 0.8003509640693665, "aqua_rat_85902": 0.8032838106155396, "camel_45738": 0.803472101688385, "camel_45730": 0.8108217716217041, "TheoremQA_xueguangma/forward_price_1.json": 0.8152074813842773, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.8315332531929016, "TheoremQA_xueguangma/forward_price_2.json": 0.8574286699295044}, "TheoremQA_xueguangma/binomial_model_2.json": {"TheoremQA_xueguangma/binomial_model_2.json": 0, "camel_16782": 0.7423216700553894, "camel_24715": 0.7423616051673889, "camel_25225": 0.7424672245979309, "aqua_rat_13263": 0.7424896955490112, "camel_17936": 0.7429484128952026, "math_train_prealgebra_1338": 0.7429897785186768, "camel_17945": 0.7431022524833679, "camel_37699": 0.7431685328483582, "camel_25176": 0.743267297744751, "camel_10511": 0.7435886263847351, "camel_17976": 0.743767499923706, "camel_25513": 0.7438509464263916, "camel_17954": 0.7439867854118347, "camel_10536": 0.7440829873085022, "camel_38758": 0.7441604137420654, "camel_37669": 0.7442206144332886, "gsm_rft_10121": 0.7447273135185242, "camel_25367": 0.7447352409362793, "gsm_rft_23795": 0.7447431683540344, "camel_17999": 0.7448269724845886, "camel_38643": 0.7449427843093872, "gsm_rft_17302": 0.7450376749038696, "camel_10545": 0.7450897693634033, "camel_38689": 0.7451893091201782, "camel_10546": 0.7453310489654541, "camel_25359": 0.7454210519790649, "camel_17960": 0.7454723715782166, "camel_25292": 0.7454907298088074, "camel_25189": 0.745820164680481, "camel_38693": 0.7461491823196411, "camel_25291": 0.7463018894195557, "camel_17991": 0.7463919520378113, "aqua_rat_945": 0.7464058995246887, "gsm_rft_17816": 0.7464432120323181, "camel_37706": 0.7464610934257507, "camel_25152": 0.7470105886459351, "gsm_rft_14506": 0.7470538020133972, "gsm_train_10049": 0.7470538020133972, "gsm_rft_32682": 0.7471947073936462, "camel_9557": 0.7472485303878784, "aqua_rat_80962": 0.7472687363624573, "camel_16733": 0.7472981810569763, "camel_37723": 0.7474475502967834, "camel_24707": 0.7475295662879944, "camel_37730": 0.7475507855415344, "TheoremQA_xueguangma/forward_price_2.json": 0.747566819190979, "gsm_rft_31738": 0.7476539015769958, "camel_37749": 0.7477672696113586, "camel_25261": 0.7478030920028687, "camel_17950": 0.7478742003440857, "camel_17990": 0.7479999661445618, "camel_25168": 0.7482119798660278, "camel_17940": 0.7482666969299316, "camel_37758": 0.7482677698135376, "gsm_rft_11850": 0.7485123872756958, "TheoremQA_xueguangma/binomial_model_1.json": 0.7487483024597168, "aqua_rat_52197": 0.7487948536872864, "camel_25345": 0.7489292025566101, "gsm_rft_20347": 0.7489969730377197, "gsm_train_374": 0.7489969730377197, "camel_10529": 0.7490482330322266, "camel_38686": 0.749263346195221, "camel_37724": 0.7494362592697144, "camel_17929": 0.7495377659797668, "aqua_rat_73408": 0.7496111392974854, "camel_10481": 0.7498111724853516, "camel_25221": 0.749914288520813, "camel_25269": 0.7499966621398926, "aqua_rat_61026": 0.7500191926956177, "camel_17968": 0.7502626776695251, "camel_25337": 0.7502748370170593, "camel_17939": 0.7502896785736084, "aqua_rat_39503": 0.7503637671470642, "camel_25892": 0.7504037618637085, "camel_17957": 0.7504147887229919, "gsm_rft_26543": 0.7505175471305847, "camel_17926": 0.7505955100059509, "camel_25341": 0.7508766651153564, "camel_25958": 0.7509635090827942, "camel_37756": 0.7510515451431274, "camel_25332": 0.7510923743247986, "camel_17979": 0.75110924243927, "camel_25136": 0.7512227296829224, "camel_10495": 0.751315176486969, "camel_17955": 0.7513299584388733, "camel_10497": 0.7513490915298462, "camel_37750": 0.7515282034873962, "camel_10493": 0.7516595125198364, "camel_25287": 0.7516810894012451, "aqua_rat_67487": 0.7518352270126343, "camel_37696": 0.7524734735488892, "camel_38645": 0.7526136040687561, "aqua_rat_14152": 0.7526609897613525, "camel_38648": 0.7526683807373047, "camel_17975": 0.7527003288269043, "camel_16755": 0.7527104616165161, "camel_17941": 0.7527151107788086, "aqua_rat_22731": 0.7528488636016846, "camel_25299": 0.7530072927474976, "aqua_rat_86309": 0.7531645894050598, "camel_25220": 0.7534689903259277, "camel_38714": 0.7535910606384277, "camel_25305": 0.7537219524383545, "camel_25335": 0.754061222076416, "camel_25316": 0.7540886998176575, "camel_10526": 0.7542381882667542, "camel_10557": 0.7547914981842041, "camel_10551": 0.7551137804985046, "camel_10539": 0.7551888227462769, "camel_25282": 0.7553339004516602, "camel_38709": 0.7553364038467407, "camel_17937": 0.7554129362106323, "camel_37688": 0.755557119846344, "camel_25334": 0.7556438446044922, "camel_10531": 0.7559165358543396, "camel_37697": 0.756245493888855, "camel_10523": 0.7565935254096985, "camel_10502": 0.756811797618866, "camel_16783": 0.7570320963859558, "camel_10555": 0.7570947408676147, "camel_25296": 0.7571145296096802, "camel_17935": 0.7571642398834229, "camel_25279": 0.7574422359466553, "camel_10491": 0.7574737071990967, "camel_37757": 0.7574929594993591, "camel_24676": 0.7575564980506897, "camel_16785": 0.7577724456787109, "camel_25212": 0.7577829360961914, "aqua_rat_55181": 0.7579257488250732, "camel_37693": 0.7582946419715881, "camel_37691": 0.7585951685905457, "camel_25219": 0.7585964798927307, "camel_25224": 0.7587442994117737, "TheoremQA_xueguangma/forward_price_1.json": 0.7588576674461365, "camel_37682": 0.7588868141174316, "camel_25318": 0.7590421438217163, "camel_10537": 0.759453296661377, "camel_17994": 0.7596604228019714, "camel_25302": 0.7596663236618042, "camel_17921": 0.7597481608390808, "TheoremQA_elainewan/econ_micro_18.json": 0.7599731683731079, "camel_10540": 0.760456383228302, "camel_24684": 0.7605783343315125, "camel_39397": 0.7607657313346863, "camel_10553": 0.7608664035797119, "camel_10486": 0.761353611946106, "camel_45695": 0.7614659070968628, "camel_17998": 0.7615774869918823, "camel_37752": 0.7619466781616211, "camel_10543": 0.7619515061378479, "camel_17984": 0.7626911997795105, "camel_25239": 0.7631385326385498, "camel_25213": 0.7635263204574585, "camel_25253": 0.7639386653900146, "camel_25357": 0.7639681696891785, "camel_37742": 0.7644110918045044, "camel_10515": 0.7649859189987183, "camel_25268": 0.7650733590126038, "camel_37714": 0.7658722400665283, "camel_10482": 0.7665570378303528, "camel_17924": 0.7672551870346069, "camel_25188": 0.7675329446792603, "camel_17927": 0.7678665518760681, "camel_16748": 0.7679754495620728, "camel_10558": 0.7685444951057434, "camel_16795": 0.7690355181694031, "camel_16780": 0.7690416574478149, "camel_10504": 0.7691820859909058, "camel_37687": 0.7692051529884338, "camel_25244": 0.7695195078849792, "camel_25257": 0.7695470452308655, "camel_25227": 0.7726519703865051, "camel_10532": 0.7734352946281433, "camel_17989": 0.7736273407936096, "camel_25270": 0.7737250924110413, "camel_38662": 0.774736762046814, "camel_17965": 0.7760090231895447, "camel_16740": 0.7762720584869385, "camel_16763": 0.7766261696815491, "camel_17963": 0.7774213552474976, "camel_25241": 0.7776826024055481, "camel_10507": 0.7779621481895447, "camel_10492": 0.7782085537910461, "camel_10544": 0.7793771028518677, "camel_10480": 0.7836359739303589, "camel_25251": 0.7848978042602539, "camel_10542": 0.7852514982223511, "camel_16754": 0.7865926623344421, "camel_37729": 0.788175106048584, "camel_17961": 0.7897742390632629, "camel_16791": 0.7911098003387451, "TheoremQA_xueguangma/options_theory.json": 0.7913196086883545, "camel_10488": 0.7927506566047668, "camel_17923": 0.7955241799354553, "camel_16789": 0.7966574430465698, "camel_10506": 0.797376811504364, "camel_10514": 0.7977262735366821, "TheoremQA_xueguangma/put_call_parity_1.json": 0.8111743927001953, "camel_16747": 0.8209141492843628}, "TheoremQA_panlu/molar_heat_capacity2.json": {"TheoremQA_panlu/molar_heat_capacity2.json": 0, "aqua_rat_67815": 0.7316688299179077, "aqua_rat_5278": 0.7317144870758057, "aqua_rat_83672": 0.7317171692848206, "aqua_rat_54332": 0.7318046689033508, "gsm_rft_20831": 0.7318808436393738, "gsm_train_2974": 0.7318808436393738, "aqua_rat_11673": 0.7318946719169617, "gsm_rft_18000": 0.7319062948226929, "aqua_rat_82928": 0.7320560812950134, "gsm_rft_3495": 0.7321324348449707, "aqua_rat_316": 0.7321419715881348, "aqua_rat_52648": 0.732183039188385, "gsm_rft_20901": 0.73232501745224, "gsm_rft_20284": 0.7323502898216248, "aqua_rat_57091": 0.7323580980300903, "aqua_rat_33251": 0.732363760471344, "gsm_rft_10164": 0.7326808571815491, "aqua_rat_47102": 0.7328659296035767, "gsm_rft_8140": 0.7330076694488525, "aqua_rat_73743": 0.7332044243812561, "gsm_rft_21129": 0.733239471912384, "aqua_rat_70124": 0.7333235144615173, "aqua_rat_4920": 0.7334915995597839, "aqua_rat_64410": 0.7334938049316406, "aqua_rat_1215": 0.7335571050643921, "gsm_train_19861": 0.7335817217826843, "gsm_rft_13503": 0.7336049675941467, "gsm_rft_9900": 0.7336049675941467, "gsm_rft_29430": 0.7336833477020264, "aqua_rat_82016": 0.7336890697479248, "gsm_rft_7499": 0.7337068319320679, "aqua_rat_26009": 0.7338388562202454, "gsm_rft_8860": 0.7338505387306213, "gsm_rft_28262": 0.7338600158691406, "gsm_rft_32188": 0.7338600158691406, "aqua_rat_44307": 0.7338619828224182, "aqua_rat_52838": 0.7338715195655823, "aqua_rat_11960": 0.7339106798171997, "gsm_rft_5803": 0.7339436411857605, "gsm_rft_33297": 0.7339436411857605, "gsm_train_31498": 0.7339436411857605, "gsm_rft_31736": 0.7340693473815918, "aqua_rat_57483": 0.7340797185897827, "gsm_rft_7772": 0.7341213226318359, "gsm_train_11492": 0.7341213226318359, "aqua_rat_72520": 0.7341577410697937, "gsm_rft_11805": 0.7343488335609436, "gsm_rft_35136": 0.7344467639923096, "aqua_rat_3468": 0.7345617413520813, "aqua_rat_21256": 0.7346211075782776, "aqua_rat_29713": 0.7347580790519714, "gsm_rft_26279": 0.7347697019577026, "aqua_rat_59437": 0.7347956299781799, "aqua_rat_81791": 0.7348700165748596, "aqua_rat_54949": 0.7349689602851868, "gsm_rft_33310": 0.7349801063537598, "aqua_rat_21049": 0.7350805401802063, "gsm_rft_1727": 0.7351560592651367, "gsm_train_9590": 0.7351560592651367, "gsm_rft_26467": 0.7351731061935425, "gsm_rft_2300": 0.735268771648407, "gsm_train_22833": 0.7353546023368835, "aqua_rat_21162": 0.735392153263092, "aqua_rat_20793": 0.7354833483695984, "gsm_rft_3770": 0.735503613948822, "aqua_rat_14845": 0.7355958223342896, "gsm_rft_14132": 0.7356330752372742, "gsm_rft_2782": 0.7356375455856323, "aqua_rat_79178": 0.7356815338134766, "gsm_rft_23897": 0.735771894454956, "gsm_rft_27697": 0.7358721494674683, "aqua_rat_19482": 0.7358802556991577, "aqua_rat_82279": 0.7359575629234314, "gsm_rft_32869": 0.7360023856163025, "aqua_rat_49629": 0.7360373139381409, "aqua_rat_82137": 0.7360588908195496, "gsm_rft_31747": 0.7361981868743896, "gsm_rft_27655": 0.7362303137779236, "aqua_rat_40611": 0.7362593412399292, "gsm_rft_5194": 0.7363976240158081, "gsm_train_10873": 0.7363976240158081, "aqua_rat_80790": 0.7365993857383728, "gsm_rft_16954": 0.7368064522743225, "gsm_rft_5168": 0.7368433475494385, "gsm_rft_34517": 0.7371192574501038, "gsm_rft_6673": 0.7372073531150818, "gsm_rft_22822": 0.7372875809669495, "aqua_rat_13838": 0.7378625273704529, "aqua_rat_87353": 0.738044023513794, "gsm_rft_6660": 0.7380720973014832, "aqua_rat_57067": 0.7382067441940308, "gsm_rft_26375": 0.7383655309677124, "gsm_rft_10892": 0.7383754253387451, "gsm_rft_16020": 0.7384195327758789, "aqua_rat_22936": 0.7384305596351624, "aqua_rat_81955": 0.7387802600860596, "aqua_rat_43074": 0.7388740181922913, "gsm_rft_12678": 0.7390494346618652, "aqua_rat_55150": 0.7391495704650879, "gsm_rft_20649": 0.7391601204872131, "aqua_rat_54758": 0.7394413352012634, "gsm_train_13753": 0.7395732998847961, "gsm_rft_1404": 0.7395933866500854, "aqua_rat_41632": 0.7397664785385132, "aqua_rat_80952": 0.7398417592048645, "gsm_train_27798": 0.7399594187736511, "gsm_rft_28190": 0.7399594187736511, "aqua_rat_78348": 0.7399668097496033, "aqua_rat_6824": 0.7399730682373047, "gsm_rft_24776": 0.7400557994842529, "gsm_rft_2120": 0.7401188611984253, "gsm_rft_25765": 0.740152895450592, "gsm_rft_8985": 0.7402259707450867, "aqua_rat_12500": 0.740304172039032, "gsm_rft_19969": 0.7405070066452026, "gsm_train_26725": 0.7405070066452026, "gsm_rft_9894": 0.7405682802200317, "camel_45925": 0.7406262755393982, "gsm_rft_2844": 0.7413324117660522, "aqua_rat_53252": 0.7413935661315918, "aqua_rat_60497": 0.7414121627807617, "aqua_rat_55426": 0.7414365410804749, "gsm_rft_33340": 0.7415065169334412, "gsm_rft_24842": 0.7418298721313477, "gsm_rft_13663": 0.741870105266571, "gsm_rft_33719": 0.7420486211776733, "gsm_train_34452": 0.7421266436576843, "gsm_rft_34227": 0.7421266436576843, "aqua_rat_32205": 0.7425945401191711, "gsm_rft_30536": 0.7426939010620117, "gsm_rft_22912": 0.7426978349685669, "gsm_train_35436": 0.7429918050765991, "gsm_train_23489": 0.7430922389030457, "gsm_rft_24993": 0.7434267997741699, "gsm_rft_23476": 0.7435309290885925, "gsm_rft_27494": 0.7436062097549438, "gsm_rft_10144": 0.7436595559120178, "gsm_rft_31896": 0.7436655759811401, "gsm_rft_5908": 0.7439847588539124, "gsm_train_6141": 0.7439847588539124, "gsm_rft_25502": 0.7440638542175293, "gsm_train_13248": 0.7440964579582214, "gsm_rft_29159": 0.7442975640296936, "aqua_rat_80897": 0.7443735003471375, "gsm_rft_7694": 0.7444050312042236, "gsm_train_24555": 0.7450757622718811, "gsm_rft_12636": 0.7450757622718811, "aqua_rat_35656": 0.7452600598335266, "gsm_rft_13546": 0.7452664971351624, "gsm_train_8215": 0.7452664971351624, "gsm_rft_1891": 0.7452759742736816, "gsm_rft_26786": 0.7461795806884766, "aqua_rat_75205": 0.7462318539619446, "aqua_rat_20622": 0.7467433214187622, "gsm_rft_22576": 0.7479812502861023, "aqua_rat_63850": 0.7481586337089539, "camel_37933": 0.7492619156837463, "gsm_rft_25975": 0.7493783831596375, "gsm_rft_12582": 0.7494364380836487, "gsm_rft_11723": 0.750657320022583, "gsm_rft_26258": 0.7508997321128845, "aqua_rat_32250": 0.7523379921913147, "aqua_rat_72360": 0.7528009414672852, "gsm_train_15489": 0.7529922127723694, "camel_37984": 0.7530104517936707, "gsm_rft_34322": 0.7530117630958557, "gsm_rft_10620": 0.7534196972846985, "gsm_train_22817": 0.7536712288856506, "gsm_rft_21990": 0.7539931535720825, "gsm_rft_2604": 0.7540816068649292, "aqua_rat_29911": 0.754410445690155, "aqua_rat_4598": 0.7557523250579834, "gsm_rft_32487": 0.7558453679084778, "gsm_train_22269": 0.7558453679084778, "aqua_rat_79036": 0.7568895220756531, "aqua_rat_7859": 0.7573487758636475, "aqua_rat_8581": 0.7575309872627258, "gsm_rft_21326": 0.7581596374511719, "aqua_rat_73234": 0.7583200931549072, "aqua_rat_50560": 0.7616062760353088, "aqua_rat_26982": 0.7617148756980896, "gsm_rft_14007": 0.7617337107658386, "aqua_rat_38504": 0.7622938752174377, "aqua_rat_3199": 0.762405276298523, "aqua_rat_75763": 0.7636930346488953, "gsm_rft_15366": 0.7637448906898499, "gsm_rft_22401": 0.7643415331840515, "aqua_rat_47999": 0.7646298408508301, "aqua_rat_48607": 0.7651743292808533, "gsm_train_15924": 0.765326976776123, "gsm_rft_14462": 0.765326976776123, "gsm_rft_19423": 0.765326976776123, "camel_17587": 0.765485942363739, "gsm_rft_6591": 0.7672064900398254, "gsm_train_4193": 0.7672064900398254, "gsm_rft_21213": 0.770070493221283, "gsm_rft_35104": 0.7703596949577332, "gsm_train_10153": 0.7705092430114746, "gsm_rft_23914": 0.7763636708259583}, "TheoremQA_mingyin/cauchy-integral-theorem1.json": {"camel_42316": 0, "camel_42747": 0, "camel_42507": 0, "camel_43521": 0, "camel_42162": 0, "camel_43140": 0, "camel_42008": 0, "camel_42235": 0, "camel_42043": 0, "camel_42610": 0, "camel_42225": 0, "camel_42164": 0, "camel_42500": 0, "camel_42012": 0, "camel_43144": 0, "camel_42623": 0, "camel_42055": 0, "camel_43198": 0, "camel_43466": 0, "camel_42985": 0, "camel_42237": 0, "camel_42501": 0, "camel_42021": 0, "camel_42201": 0, "camel_42047": 0, "camel_42587": 0, "camel_43153": 0, "camel_42405": 0, "camel_42533": 0, "camel_42062": 0, "camel_42435": 0, "camel_43560": 0, "camel_42192": 0, "camel_42760": 0, "camel_43173": 0, "camel_42559": 0, "camel_43542": 0, "camel_42799": 0, "camel_42422": 0, "camel_42546": 0, "camel_43504": 0, "camel_42575": 0, "camel_42565": 0, "camel_42180": 0, "camel_42230": 0, "camel_42165": 0, "camel_42197": 0, "camel_43175": 0, "camel_43103": 0, "camel_42525": 0, "camel_42464": 0, "camel_43163": 0, "camel_42187": 0, "camel_42557": 0, "camel_43135": 0, "camel_42554": 0, "camel_43104": 0, "camel_43194": 0, "camel_42075": 0, "camel_43381": 0, "camel_42547": 0, "camel_42430": 0, "camel_43151": 0, "camel_42417": 0, "camel_42472": 0, "camel_42458": 0, "camel_42526": 0, "camel_42175": 0, "camel_42448": 0, "camel_43127": 0, "camel_42189": 0, "camel_43160": 0, "camel_43582": 0, "camel_43011": 0, "camel_42499": 0, "camel_42615": 0, "camel_43239": 0, "camel_43180": 0, "camel_42023": 0, "camel_42482": 0, "camel_43185": 0, "camel_43006": 0, "camel_42603": 0, "camel_42431": 0, "camel_43152": 0, "camel_42966": 0, "camel_42190": 0, "camel_42434": 0, "camel_43450": 0, "camel_42166": 0, "camel_42531": 0, "camel_43270": 0, "camel_42989": 0, "camel_42617": 0, "camel_42070": 0, "camel_42236": 0, "camel_42492": 0, "camel_42444": 0, "camel_43557": 0, "camel_43159": 0, "camel_42031": 0, "camel_42186": 0, "camel_42061": 0, "camel_43105": 0, "camel_42474": 0, "camel_42558": 0, "camel_42456": 0, "camel_42519": 0, "camel_43123": 0, "camel_42635": 0, "camel_42596": 0, "camel_42454": 0, "camel_42486": 0, "camel_43154": 0, "camel_42954": 0, "camel_42224": 0, "camel_42974": 0, "camel_43596": 0, "camel_43189": 0, "camel_42553": 0, "camel_43188": 0, "camel_42488": 0, "camel_43178": 0, "camel_42625": 0, "camel_43551": 0, "camel_42614": 0, "camel_43499": 0, "camel_42549": 0, "camel_42214": 0, "camel_42026": 0, "camel_42424": 0, "camel_42789": 0, "camel_43495": 0, "camel_43743": 0, "camel_43158": 0, "camel_42480": 0, "camel_42529": 0, "camel_43546": 0, "camel_42020": 0, "camel_42530": 0, "camel_42011": 0, "camel_43133": 0, "camel_42478": 0, "camel_43181": 0, "camel_42176": 0, "camel_42053": 0, "camel_42585": 0, "camel_43137": 0, "camel_43190": 0, "camel_42019": 0, "camel_42475": 0, "camel_42536": 0, "camel_42607": 0, "camel_42636": 0, "camel_42168": 0, "camel_42616": 0, "camel_42410": 0, "camel_42005": 0, "camel_42441": 0, "camel_42497": 0, "camel_42432": 0, "camel_42907": 0, "camel_43170": 0, "camel_43132": 0, "camel_43110": 0, "camel_42538": 0, "TheoremQA_mingyin/cauchy-integral-theorem1.json": 0, "camel_42007": 0, "camel_42552": 0, "camel_42494": 0, "camel_42518": 0, "camel_42626": 0, "camel_43191": 0, "camel_42429": 0, "camel_42002": 0, "camel_42881": 0, "camel_42477": 0, "camel_42498": 0, "camel_43263": 0, "camel_42412": 0, "camel_43164": 0, "camel_42073": 0, "camel_43001": 0, "camel_42504": 0, "camel_42078": 0, "camel_42051": 0, "camel_43501": 0, "camel_42223": 0, "camel_43131": 0, "camel_42556": 0, "camel_43478": 0, "camel_42211": 0, "camel_43171": 0, "camel_43020": 0, "camel_42564": 0, "camel_43035": 0, "camel_42208": 0, "TheoremQA_wenhuchen/Liouville\u2019s_theorem2.json": 0.7864993810653687, "TheoremQA_mingyin/liouville-theorem1.json": 0.7998656630516052, "TheoremQA_wenhuchen/Liouville\u2019s_theorem1.json": 0.8048847317695618}, "TheoremQA_wenhuchen/determinant2.json": {"camel_14107": 0, "camel_14123": 0, "camel_15676": 0, "camel_14131": 0, "camel_14710": 0, "camel_15417": 0, "camel_14872": 0, "camel_15656": 0, "camel_14860": 0, "camel_14121": 0, "camel_14104": 0, "camel_14826": 0, "camel_14081": 0, "camel_14913": 0, "camel_14911": 0, "camel_14912": 0, "camel_14675": 0, "camel_14891": 0, "camel_14087": 0, "camel_14098": 0, "camel_14892": 0, "camel_14933": 0, "camel_14918": 0, "camel_14924": 0, "camel_14927": 0, "camel_14141": 0, "camel_14903": 0, "camel_14811": 0, "camel_15281": 0, "camel_14947": 0, "camel_15650": 0, "camel_14116": 0, "camel_14112": 0, "camel_14719": 0, "camel_14103": 0, "camel_14109": 0, "camel_14679": 0, "camel_14711": 0, "camel_14716": 0, "camel_14699": 0, "camel_14692": 0, "camel_14650": 0, "camel_14681": 0, "camel_14814": 0, "camel_14955": 0, "camel_14937": 0, "camel_14707": 0, "camel_14691": 0, "camel_14672": 0, "camel_14697": 0, "camel_14660": 0, "camel_15655": 0, "camel_15618": 0, "camel_14715": 0, "camel_14686": 0, "camel_14659": 0, "camel_14084": 0, "camel_14654": 0, "camel_14662": 0, "camel_14644": 0, "camel_14642": 0, "camel_14690": 0, "camel_14647": 0, "camel_14646": 0, "camel_14674": 0, "camel_14667": 0, "camel_14703": 0, "camel_14685": 0, "camel_15748": 0, "camel_14714": 0, "camel_14657": 0, "camel_14663": 0, "camel_14705": 0, "camel_15583": 0, "camel_14698": 0, "camel_14669": 0, "camel_14138": 0, "camel_14142": 0, "camel_14120": 0, "camel_14695": 0, "camel_14683": 0, "camel_14668": 0, "camel_14673": 0, "camel_14092": 0, "camel_14670": 0, "camel_14665": 0, "camel_14661": 0, "camel_14095": 0, "camel_14694": 0, "TheoremQA_wenhuchen/determinant2.json": 0, "camel_14664": 0, "camel_14652": 0, "camel_14658": 0, "camel_14693": 0, "camel_14158": 0, "camel_14653": 0, "camel_14706": 0, "camel_14127": 0, "camel_14655": 0, "camel_14656": 0, "camel_14648": 0, "camel_14700": 0, "camel_14701": 0, "camel_14708": 0, "camel_14676": 0, "camel_14159": 0, "camel_14680": 0, "camel_14666": 0, "camel_14712": 0, "camel_14713": 0, "camel_14640": 0, "camel_14678": 0, "camel_14718": 0, "camel_14671": 0, "camel_14136": 0, "camel_14649": 0, "camel_14688": 0, "camel_14696": 0, "camel_14684": 0, "camel_14702": 0, "camel_14645": 0, "camel_14709": 0, "camel_14643": 0, "camel_14651": 0, "camel_14682": 0, "camel_14687": 0, "camel_14717": 0, "camel_14641": 0, "camel_21313": 0.7189884781837463, "camel_21323": 0.719025194644928, "camel_27619": 0.7202349901199341, "camel_21317": 0.7203684449195862, "camel_27449": 0.7206937670707703, "camel_21287": 0.7207556962966919, "camel_21345": 0.7211082577705383, "camel_21312": 0.721326470375061, "camel_21355": 0.7221397757530212, "camel_21280": 0.722719669342041, "camel_27678": 0.7227774262428284, "camel_27605": 0.7228173017501831, "camel_21306": 0.722881019115448, "camel_27628": 0.7228986024856567, "camel_21286": 0.7229670882225037, "camel_27644": 0.7244091033935547, "camel_21300": 0.7246875166893005, "camel_27500": 0.7248567342758179, "camel_26841": 0.7249451279640198, "camel_21333": 0.7249849438667297, "camel_27672": 0.7251497507095337, "camel_27669": 0.7251615524291992, "camel_21325": 0.7257009744644165, "camel_21334": 0.7257320284843445, "camel_21293": 0.7258761525154114, "camel_27658": 0.7270364165306091, "camel_21290": 0.7275708317756653, "camel_27637": 0.7279934883117676, "camel_21295": 0.7287612557411194, "camel_21344": 0.7291832566261292, "camel_21281": 0.7293658256530762, "camel_21305": 0.7296796441078186, "camel_21282": 0.7300143241882324, "camel_21310": 0.7300146818161011, "camel_21339": 0.730137288570404, "camel_21307": 0.7303663492202759, "camel_21315": 0.7306163311004639, "camel_21284": 0.7307158708572388, "camel_21341": 0.730961799621582, "camel_27648": 0.7321219444274902, "camel_21331": 0.7321606874465942, "camel_21309": 0.7331950664520264, "camel_21285": 0.733570396900177, "camel_21328": 0.7346537113189697, "camel_21329": 0.7347075939178467, "camel_27657": 0.7358338832855225, "camel_21359": 0.7359446287155151, "camel_21297": 0.7361519932746887, "camel_27627": 0.7363390326499939, "camel_21294": 0.7370182275772095, "camel_27617": 0.7372244000434875, "camel_21316": 0.7394529581069946, "camel_21311": 0.7405193448066711, "camel_21354": 0.7419595122337341, "camel_21319": 0.7419922351837158, "camel_21335": 0.743098258972168, "camel_21298": 0.7431665062904358, "camel_21322": 0.7432063221931458, "camel_27634": 0.7432293891906738, "camel_21326": 0.743346095085144, "TheoremQA_elainewan/math_algebra_2.json": 0.7441383600234985, "camel_21320": 0.7451432943344116, "camel_21347": 0.7451945543289185, "camel_21351": 0.7452538013458252, "camel_21318": 0.7453192472457886, "TheoremQA_elainewan/math_algebra_6_3.json": 0.7474350929260254, "camel_21340": 0.7478942275047302, "camel_21327": 0.7485337257385254, "camel_27603": 0.7493036985397339, "camel_27667": 0.7506188154220581, "camel_27639": 0.7590541839599609, "TheoremQA_wenhuchen/determinant1.json": 0.7737869024276733}, "TheoremQA_elainewan/math_abstact_algebra_7_5.json": {"math_test_prealgebra_660": 0, "math_train_prealgebra_1527": 0, "math_test_prealgebra_1218": 0, "aqua_rat_80221": 0.7116142511367798, "aqua_rat_2598": 0.711644172668457, "math_test_number_theory_257": 0.7117162346839905, "aqua_rat_31136": 0.7117987275123596, "aqua_rat_78326": 0.7118498682975769, "gsm_rft_32203": 0.7118942141532898, "aqua_rat_78298": 0.711929202079773, "aqua_rat_36528": 0.7119531035423279, "aqua_rat_43515": 0.712100088596344, "aqua_rat_81468": 0.7121115326881409, "aqua_rat_88723": 0.7121606469154358, "aqua_rat_76146": 0.7122594118118286, "aqua_rat_43692": 0.7122912406921387, "aqua_rat_16767": 0.7124478816986084, "aqua_rat_26493": 0.7125461101531982, "aqua_rat_586": 0.7126268744468689, "aqua_rat_58275": 0.7126872539520264, "aqua_rat_6222": 0.7127763032913208, "aqua_rat_68207": 0.712813138961792, "camel_12137": 0.7129462957382202, "aqua_rat_74214": 0.7130168080329895, "aqua_rat_69097": 0.7130904197692871, "aqua_rat_42507": 0.713305652141571, "aqua_rat_6563": 0.7134011387825012, "aqua_rat_71118": 0.7135159969329834, "math_train_number_theory_1026": 0.7135286927223206, "aqua_rat_76265": 0.71372389793396, "aqua_rat_29889": 0.71379154920578, "gsm_rft_14362": 0.7137970328330994, "gsm_rft_34879": 0.7137970328330994, "aqua_rat_54606": 0.7138081192970276, "aqua_rat_62784": 0.7138640284538269, "gsm_train_21935": 0.7140098214149475, "aqua_rat_14051": 0.7141892910003662, "aqua_rat_10968": 0.7143738865852356, "aqua_rat_53169": 0.7145723104476929, "aqua_rat_41114": 0.7146729826927185, "aqua_rat_11166": 0.7148832678794861, "aqua_rat_11641": 0.715080201625824, "aqua_rat_86953": 0.7151636481285095, "aqua_rat_49192": 0.715164065361023, "aqua_rat_58337": 0.7152517437934875, "aqua_rat_33804": 0.7153217196464539, "aqua_rat_23773": 0.7156022787094116, "aqua_rat_26482": 0.715628445148468, "math_test_counting_and_probability_829": 0.7156462669372559, "aqua_rat_19854": 0.7158529162406921, "aqua_rat_10055": 0.7159363031387329, "math_train_number_theory_379": 0.7159746289253235, "aqua_rat_78626": 0.716040313243866, "aqua_rat_14693": 0.7163055539131165, "aqua_rat_24462": 0.7164728045463562, "aqua_rat_46387": 0.7165305018424988, "math_test_counting_and_probability_1047": 0.7166167497634888, "aqua_rat_62041": 0.7166396379470825, "aqua_rat_52650": 0.7166727781295776, "aqua_rat_66547": 0.7167539596557617, "aqua_rat_49245": 0.7167596220970154, "aqua_rat_57544": 0.7169431447982788, "aqua_rat_36958": 0.7171021103858948, "aqua_rat_25833": 0.7171461582183838, "aqua_rat_47745": 0.71720951795578, "aqua_rat_31119": 0.7173274755477905, "aqua_rat_24078": 0.717444896697998, "aqua_rat_53443": 0.717475950717926, "aqua_rat_3474": 0.7175823450088501, "aqua_rat_22575": 0.7179325222969055, "aqua_rat_45588": 0.7181463837623596, "camel_12745": 0.7181603312492371, "aqua_rat_20868": 0.7181735634803772, "math_test_counting_and_probability_134": 0.7183892130851746, "aqua_rat_27629": 0.7184939384460449, "aqua_rat_34665": 0.7188137173652649, "aqua_rat_52611": 0.7188575863838196, "aqua_rat_2932": 0.7189935445785522, "aqua_rat_38915": 0.7190436720848083, "aqua_rat_19833": 0.7191752791404724, "aqua_rat_29670": 0.719257116317749, "aqua_rat_55994": 0.7197006344795227, "aqua_rat_29119": 0.7197452783584595, "aqua_rat_84091": 0.7199946641921997, "aqua_rat_55599": 0.7200751900672913, "aqua_rat_60525": 0.7203713655471802, "aqua_rat_51992": 0.720422625541687, "camel_12221": 0.7205459475517273, "aqua_rat_39391": 0.7210605144500732, "aqua_rat_75420": 0.7211651802062988, "aqua_rat_27925": 0.721566915512085, "aqua_rat_47785": 0.7217483520507812, "aqua_rat_10091": 0.7217814922332764, "aqua_rat_84513": 0.7219513058662415, "math_test_counting_and_probability_1046": 0.7219906449317932, "aqua_rat_78260": 0.722108781337738, "camel_12117": 0.7222052812576294, "aqua_rat_50821": 0.7222585678100586, "aqua_rat_37891": 0.7223130464553833, "aqua_rat_70953": 0.7224264740943909, "aqua_rat_42677": 0.7224507927894592, "camel_12572": 0.7226672768592834, "camel_20783": 0.7227790951728821, "aqua_rat_74851": 0.7229197025299072, "aqua_rat_42203": 0.7234155535697937, "aqua_rat_88322": 0.7238098978996277, "aqua_rat_49415": 0.7238582968711853, "aqua_rat_88982": 0.7242446541786194, "aqua_rat_55497": 0.7247897982597351, "aqua_rat_28493": 0.7248091697692871, "math_train_number_theory_973": 0.724909782409668, "aqua_rat_43230": 0.7249425649642944, "aqua_rat_81129": 0.7249725461006165, "aqua_rat_20845": 0.7250904440879822, "camel_12215": 0.7253230214118958, "aqua_rat_2191": 0.7253889441490173, "aqua_rat_69087": 0.72557532787323, "aqua_rat_4466": 0.7256130576133728, "aqua_rat_72280": 0.7257658839225769, "aqua_rat_52297": 0.7257956862449646, "aqua_rat_8772": 0.7260668873786926, "aqua_rat_25938": 0.7261081337928772, "math_test_counting_and_probability_41": 0.7262892127037048, "aqua_rat_34435": 0.7264154553413391, "math_test_number_theory_631": 0.7267107367515564, "aqua_rat_64428": 0.7268949151039124, "aqua_rat_38601": 0.7269279956817627, "aqua_rat_69959": 0.7270840406417847, "aqua_rat_32396": 0.7270996570587158, "math_train_counting_and_probability_113": 0.7276291251182556, "aqua_rat_50936": 0.7277016639709473, "aqua_rat_54689": 0.7279539704322815, "aqua_rat_57340": 0.7283352613449097, "aqua_rat_41458": 0.7285079956054688, "aqua_rat_69177": 0.7286874651908875, "aqua_rat_50097": 0.7287368178367615, "aqua_rat_26404": 0.7288033962249756, "aqua_rat_45576": 0.7289705276489258, "aqua_rat_81984": 0.7291348576545715, "aqua_rat_9296": 0.7292348146438599, "aqua_rat_67223": 0.7296421527862549, "aqua_rat_5175": 0.7297695875167847, "aqua_rat_273": 0.7299826741218567, "aqua_rat_2556": 0.7300065755844116, "aqua_rat_71050": 0.7303639054298401, "aqua_rat_12473": 0.7303919792175293, "aqua_rat_13165": 0.7307285666465759, "aqua_rat_65586": 0.7309640645980835, "aqua_rat_74864": 0.731517493724823, "aqua_rat_26661": 0.7321549654006958, "aqua_rat_42607": 0.7325260043144226, "aqua_rat_69582": 0.7332162261009216, "aqua_rat_85407": 0.7337781190872192, "aqua_rat_78908": 0.7344213724136353, "aqua_rat_64929": 0.7345858216285706, "aqua_rat_10766": 0.7347027659416199, "aqua_rat_45075": 0.7348793148994446, "aqua_rat_21313": 0.7349467873573303, "aqua_rat_21067": 0.7350082397460938, "aqua_rat_60011": 0.7355085611343384, "aqua_rat_34569": 0.7356097102165222, "aqua_rat_43874": 0.7356472015380859, "aqua_rat_68821": 0.736538290977478, "aqua_rat_2144": 0.7367615103721619, "aqua_rat_20828": 0.7367681860923767, "aqua_rat_29718": 0.7374483346939087, "aqua_rat_1227": 0.737919270992279, "aqua_rat_82251": 0.7381818890571594, "aqua_rat_1131": 0.7383511662483215, "aqua_rat_71250": 0.7384028434753418, "aqua_rat_66272": 0.7384873628616333, "aqua_rat_32099": 0.7392306923866272, "aqua_rat_78633": 0.7400286197662354, "aqua_rat_52187": 0.7402516007423401, "aqua_rat_87692": 0.7416800260543823, "aqua_rat_60879": 0.7428625226020813, "aqua_rat_31017": 0.7445982694625854, "math_test_counting_and_probability_883": 0.7446593642234802, "aqua_rat_23957": 0.7458609342575073, "math_train_number_theory_538": 0.7473478317260742, "math_test_counting_and_probability_789": 0.7485256791114807, "aqua_rat_49145": 0.7485769391059875, "aqua_rat_65101": 0.7504783272743225, "camel_21260": 0.7511451244354248, "aqua_rat_66503": 0.7528388500213623, "aqua_rat_74748": 0.7540432214736938, "aqua_rat_80212": 0.7551671266555786, "aqua_rat_12715": 0.7553089261054993, "aqua_rat_5492": 0.755577802658081, "aqua_rat_75190": 0.756320595741272, "aqua_rat_78156": 0.7570688128471375, "aqua_rat_80447": 0.7576403021812439, "math_test_number_theory_200": 0.7685762047767639, "math_train_number_theory_360": 0.7730622291564941, "math_train_number_theory_803": 0.7812573909759521, "aqua_rat_41243": 0.7931393980979919, "aqua_rat_74037": 0.7931692004203796, "aqua_rat_12612": 0.8012953400611877, "aqua_rat_41681": 0.8018844127655029, "aqua_rat_4189": 0.8195304870605469}, "TheoremQA_tonyxia/wave2.json": {"camel_16606": 0, "camel_16690": 0, "camel_16581": 0, "camel_17559": 0, "camel_17845": 0, "camel_16663": 0, "camel_16699": 0, "camel_16634": 0, "camel_16680": 0, "camel_16681": 0, "camel_16632": 0, "camel_17798": 0, "camel_16628": 0, "camel_16555": 0, "camel_16573": 0, "camel_16605": 0, "camel_16712": 0, "camel_16568": 0, "camel_16682": 0, "camel_16674": 0, "camel_16621": 0, "camel_16571": 0, "camel_16602": 0, "camel_17811": 0, "camel_16596": 0, "camel_16575": 0, "TheoremQA_tonyxia/wave2.json": 0, "aqua_rat_42854": 0.6777194142341614, "aqua_rat_56182": 0.6778253316879272, "aqua_rat_16975": 0.6779614686965942, "gsm_rft_22533": 0.6779763698577881, "aqua_rat_48987": 0.6779873371124268, "aqua_rat_42768": 0.6779927015304565, "aqua_rat_9493": 0.6780030131340027, "aqua_rat_61971": 0.6780101656913757, "aqua_rat_70077": 0.678011953830719, "gsm_rft_24978": 0.6780308485031128, "gsm_rft_18917": 0.6780619025230408, "gsm_rft_23718": 0.6780619025230408, "gsm_train_28914": 0.6780619025230408, "aqua_rat_70695": 0.6780825853347778, "camel_45323": 0.6781109571456909, "gsm_rft_34630": 0.6781345009803772, "gsm_rft_7166": 0.6781674027442932, "gsm_train_228": 0.6781674027442932, "aqua_rat_85557": 0.6782980561256409, "gsm_rft_870": 0.6783037185668945, "gsm_rft_2575": 0.6783037185668945, "aqua_rat_77599": 0.6783387660980225, "aqua_rat_71816": 0.6784746050834656, "TheoremQA_xinyi/momentum.json": 0.6785411834716797, "gsm_rft_2181": 0.6785529851913452, "aqua_rat_6188": 0.6786460876464844, "camel_7922": 0.6787897944450378, "aqua_rat_10794": 0.6787901520729065, "gsm_rft_21678": 0.6788561344146729, "camel_7981": 0.6788901090621948, "aqua_rat_13703": 0.6789263486862183, "aqua_rat_6674": 0.6789401769638062, "aqua_rat_67486": 0.6789442300796509, "aqua_rat_33689": 0.6789710521697998, "aqua_rat_66748": 0.6789915561676025, "camel_7977": 0.6790099740028381, "camel_37947": 0.679052472114563, "gsm_rft_28878": 0.6792483925819397, "gsm_train_31124": 0.6792483925819397, "gsm_rft_28645": 0.6792483925819397, "gsm_rft_30836": 0.6792483925819397, "gsm_rft_20767": 0.6793997287750244, "aqua_rat_76507": 0.6795397400856018, "aqua_rat_11192": 0.6796060800552368, "aqua_rat_56584": 0.6796778440475464, "gsm_train_2385": 0.6797109842300415, "aqua_rat_2740": 0.6797306537628174, "gsm_rft_29698": 0.6797804236412048, "gsm_train_13418": 0.6797804236412048, "aqua_rat_13443": 0.6798141002655029, "aqua_rat_3900": 0.6798218488693237, "aqua_rat_10048": 0.6799485087394714, "camel_7511": 0.6801047325134277, "aqua_rat_63167": 0.6805582642555237, "gsm_rft_3828": 0.6805601119995117, "camel_7440": 0.6808209419250488, "aqua_rat_57727": 0.6808617115020752, "aqua_rat_53936": 0.6808813214302063, "aqua_rat_11549": 0.6809673309326172, "camel_7945": 0.6810879707336426, "gsm_rft_7695": 0.6811351180076599, "camel_7951": 0.6811354756355286, "TheoremQA_tonyxia/particle6.json": 0.6812409162521362, "camel_7964": 0.6812493801116943, "aqua_rat_28523": 0.6814641356468201, "aqua_rat_3859": 0.6814839243888855, "aqua_rat_40832": 0.6815193891525269, "aqua_rat_25765": 0.6815865635871887, "aqua_rat_54375": 0.6816413402557373, "aqua_rat_73760": 0.6816903352737427, "aqua_rat_83787": 0.6817536354064941, "camel_24344": 0.682059645652771, "aqua_rat_41482": 0.6822192668914795, "aqua_rat_31689": 0.6823756694793701, "gsm_train_34146": 0.6824131608009338, "aqua_rat_48959": 0.6824764013290405, "aqua_rat_12925": 0.6826165914535522, "gsm_rft_19941": 0.6827557682991028, "gsm_rft_3112": 0.6830364465713501, "aqua_rat_74126": 0.6830635070800781, "gsm_train_34318": 0.6831189393997192, "aqua_rat_35471": 0.6831943392753601, "gsm_rft_9980": 0.6832009553909302, "gsm_rft_22887": 0.6832702159881592, "gsm_rft_19149": 0.6833011507987976, "gsm_rft_22440": 0.6833296418190002, "gsm_rft_6656": 0.6833361387252808, "gsm_train_31725": 0.6833361387252808, "TheoremQA_xinyi/work_energy_theorem.json": 0.6834429502487183, "aqua_rat_46971": 0.6836873292922974, "aqua_rat_23930": 0.6838747262954712, "gsm_rft_8772": 0.6839157938957214, "camel_28024": 0.6845277547836304, "camel_37936": 0.684870719909668, "TheoremQA_tonyxia/particle4.json": 0.6849006414413452, "aqua_rat_12499": 0.685067892074585, "camel_7499": 0.6852454543113708, "gsm_rft_10505": 0.6852753758430481, "gsm_train_2173": 0.6853443384170532, "gsm_rft_19699": 0.6853443384170532, "gsm_rft_11389": 0.6854665279388428, "aqua_rat_12010": 0.6855065226554871, "aqua_rat_60511": 0.6855337023735046, "aqua_rat_43435": 0.6856335401535034, "gsm_train_13121": 0.6857579350471497, "gsm_rft_32618": 0.6858857274055481, "gsm_rft_35323": 0.6859345436096191, "gsm_rft_27200": 0.6860973238945007, "aqua_rat_47596": 0.6861017346382141, "camel_7461": 0.6863363981246948, "camel_39446": 0.6864272952079773, "gsm_rft_22397": 0.6864707469940186, "camel_7975": 0.686818540096283, "gsm_rft_35145": 0.6869321465492249, "camel_4979": 0.6869417428970337, "TheoremQA_tonyxia/photoelectric1.json": 0.6869752407073975, "camel_7968": 0.6880003213882446, "camel_7976": 0.6881883144378662, "gsm_rft_24796": 0.6884437203407288, "aqua_rat_83619": 0.6886876225471497, "camel_7946": 0.6890767812728882, "camel_7925": 0.6891518235206604, "gsm_rft_17764": 0.6894556283950806, "gsm_train_29099": 0.6894556283950806, "aqua_rat_76776": 0.6895284056663513, "camel_29979": 0.6895336508750916, "gsm_rft_57": 0.6895946860313416, "camel_7974": 0.6896042227745056, "camel_28096": 0.6900818943977356, "camel_45169": 0.6905478835105896, "camel_7952": 0.6911008954048157, "gsm_rft_2271": 0.6915128827095032, "gsm_rft_11031": 0.6916080117225647, "camel_7991": 0.6917317509651184, "aqua_rat_75111": 0.691771388053894, "camel_37879": 0.6922591924667358, "gsm_rft_10474": 0.6927947402000427, "camel_45159": 0.6929708123207092, "aqua_rat_42126": 0.6939969658851624, "camel_45199": 0.6940776705741882, "camel_7984": 0.6941969990730286, "camel_7956": 0.6943290829658508, "camel_39514": 0.6948093771934509, "gsm_rft_7812": 0.695173978805542, "gsm_train_21544": 0.6952221393585205, "gsm_rft_2452": 0.69549161195755, "gsm_rft_6897": 0.6966596245765686, "gsm_rft_9344": 0.6967331767082214, "gsm_train_17819": 0.6967331767082214, "gsm_rft_17551": 0.6967331767082214, "camel_39485": 0.6968382596969604, "camel_7948": 0.6970036625862122, "aqua_rat_81926": 0.6973147392272949, "camel_28151": 0.6987796425819397, "math_test_algebra_2397": 0.7006621956825256, "TheoremQA_panlu/wave_speed1.json": 0.7025575041770935, "camel_45956": 0.7026609778404236, "camel_39452": 0.7043696045875549, "camel_45967": 0.7060375809669495, "gsm_train_21024": 0.7094512581825256, "gsm_rft_2034": 0.7095562815666199, "gsm_rft_3538": 0.7095562815666199, "camel_45075": 0.7115723490715027, "camel_28656": 0.7140386700630188, "camel_28715": 0.7164492607116699, "camel_39513": 0.7179241180419922, "TheoremQA_tonyxia/quantum3.json": 0.7210007905960083, "TheoremQA_tonyxia/semiconductor2.json": 0.7248128056526184, "camel_45935": 0.7289023399353027, "TheoremQA_tonyxia/semiconductor3.json": 0.7336033582687378, "camel_45174": 0.7343897223472595, "TheoremQA_panlu/wave_length1.json": 0.735805332660675, "camel_45999": 0.7415984272956848}, "TheoremQA_jianyu_xu/Ramsey_4.json": {"camel_21809": 0, "camel_21761": 0, "camel_23328": 0, "camel_23699": 0, "camel_21792": 0, "camel_23695": 0, "camel_21197": 0, "camel_21040": 0, "camel_21304": 0, "camel_21784": 0, "camel_21100": 0, "camel_21935": 0, "camel_23752": 0, "camel_21131": 0, "camel_21568": 0, "camel_21428": 0, "camel_20512": 0, "camel_21782": 0, "camel_21142": 0, "camel_21366": 0, "camel_21199": 0, "camel_23442": 0, "camel_21133": 0, "camel_21174": 0, "camel_21398": 0, "camel_20540": 0, "camel_21068": 0, "camel_23748": 0, "camel_23755": 0, "camel_23729": 0, "camel_21147": 0, "camel_21204": 0, "camel_21151": 0, "camel_21215": 0, "camel_23794": 0, "camel_21167": 0, "camel_21835": 0, "camel_23690": 0, "camel_21157": 0, "camel_21120": 0, "camel_21173": 0, "camel_21126": 0, "camel_21124": 0, "camel_21122": 0, "camel_21145": 0, "camel_21177": 0, "camel_21171": 0, "camel_21127": 0, "camel_21159": 0, "camel_21198": 0, "camel_21135": 0, "camel_21132": 0, "camel_21148": 0, "camel_21141": 0, "camel_21136": 0, "camel_21129": 0, "camel_23285": 0, "camel_21139": 0, "camel_21196": 0, "camel_21166": 0, "camel_21153": 0, "camel_21181": 0, "camel_21822": 0, "camel_22120": 0, "camel_21146": 0, "camel_21170": 0, "camel_21123": 0, "camel_21169": 0, "camel_21190": 0, "camel_21143": 0, "camel_21164": 0, "camel_21185": 0, "camel_21192": 0, "camel_21172": 0, "camel_21767": 0, "camel_21137": 0, "camel_21116": 0, "camel_21144": 0, "camel_21162": 0, "camel_21155": 0, "camel_21121": 0, "camel_21193": 0, "camel_21163": 0, "camel_23711": 0, "camel_23693": 0, "camel_21188": 0, "camel_21208": 0, "camel_23682": 0, "camel_21175": 0, "camel_21184": 0, "camel_23750": 0, "camel_21194": 0, "camel_23686": 0, "camel_21160": 0, "camel_21158": 0, "camel_21152": 0, "camel_21271": 0, "camel_21134": 0, "camel_20577": 0, "camel_21179": 0, "camel_23714": 0, "camel_21128": 0, "camel_21168": 0, "camel_21130": 0, "camel_21195": 0, "camel_23731": 0, "camel_21187": 0, "camel_23737": 0, "camel_21807": 0, "camel_21156": 0, "camel_21186": 0, "camel_21125": 0, "camel_21191": 0, "camel_21178": 0, "camel_21149": 0, "camel_21161": 0, "camel_21182": 0, "camel_21154": 0, "camel_21180": 0, "camel_21183": 0, "camel_21176": 0, "math_train_counting_and_probability_979": 0.7620210647583008, "aqua_rat_17902": 0.7621205449104309, "aqua_rat_54466": 0.762150764465332, "aqua_rat_55983": 0.7623286247253418, "camel_38505": 0.7627102732658386, "gsm_rft_6246": 0.7629398107528687, "aqua_rat_10500": 0.7630712985992432, "aqua_rat_53805": 0.7633711695671082, "aqua_rat_43337": 0.7643818855285645, "aqua_rat_13835": 0.7644156813621521, "math_train_prealgebra_733": 0.7645183801651001, "aqua_rat_86857": 0.7646062970161438, "aqua_rat_78389": 0.7648534178733826, "aqua_rat_34677": 0.7649257779121399, "aqua_rat_69290": 0.7651451230049133, "aqua_rat_76352": 0.7654671669006348, "math_train_prealgebra_351": 0.7657542824745178, "aqua_rat_74606": 0.7658149600028992, "aqua_rat_51040": 0.7662568688392639, "aqua_rat_53479": 0.7662668824195862, "camel_38538": 0.7664483189582825, "aqua_rat_87729": 0.767520546913147, "math_train_prealgebra_446": 0.7677440047264099, "aqua_rat_41875": 0.7681959867477417, "math_test_counting_and_probability_1081": 0.768858790397644, "math_train_prealgebra_815": 0.7690483927726746, "aqua_rat_52325": 0.7692197561264038, "math_train_counting_and_probability_757": 0.769406795501709, "aqua_rat_76846": 0.7698103189468384, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0.7700409889221191, "aqua_rat_8519": 0.7700804471969604, "aqua_rat_43090": 0.7706174254417419, "aqua_rat_19096": 0.7713003754615784, "math_test_prealgebra_1727": 0.7735989093780518, "aqua_rat_48816": 0.7740435004234314, "aqua_rat_63918": 0.774110734462738, "TheoremQA_jianyu_xu/Ramsey_3.json": 0.7746222019195557, "aqua_rat_17402": 0.7747782468795776, "aqua_rat_58883": 0.774940550327301, "math_train_counting_and_probability_600": 0.7753104567527771, "aqua_rat_18439": 0.7756969928741455, "aqua_rat_85357": 0.7757334113121033, "aqua_rat_39765": 0.7758978009223938, "aqua_rat_5877": 0.7761498093605042, "aqua_rat_57520": 0.7763150930404663, "aqua_rat_25103": 0.7763282060623169, "math_test_prealgebra_1764": 0.7767961025238037, "aqua_rat_10136": 0.7768132090568542, "aqua_rat_84086": 0.7769159078598022, "math_test_counting_and_probability_513": 0.7773852348327637, "aqua_rat_75970": 0.7776760458946228, "aqua_rat_75127": 0.77784264087677, "aqua_rat_12645": 0.7780330181121826, "math_test_counting_and_probability_763": 0.7783892154693604, "aqua_rat_83797": 0.7784003019332886, "aqua_rat_58707": 0.7794464230537415, "aqua_rat_20969": 0.7798541188240051, "math_test_counting_and_probability_341": 0.7816324234008789, "aqua_rat_86194": 0.7819186449050903, "aqua_rat_60481": 0.7820289731025696, "aqua_rat_53788": 0.7823854684829712, "aqua_rat_84407": 0.7826833724975586, "aqua_rat_47964": 0.7828543782234192, "aqua_rat_15706": 0.7831473350524902, "math_train_counting_and_probability_1110": 0.7832741141319275, "TheoremQA_jianyu_xu/Ramsey_2.json": 0.7834148406982422, "aqua_rat_75954": 0.788218080997467, "aqua_rat_46632": 0.7883052229881287, "aqua_rat_46132": 0.7887568473815918, "aqua_rat_46637": 0.7907609939575195, "math_test_prealgebra_1071": 0.7908212542533875, "math_test_prealgebra_1306": 0.7928658127784729, "aqua_rat_37692": 0.7935370802879333, "aqua_rat_31932": 0.7944114804267883, "aqua_rat_78805": 0.7971352934837341, "aqua_rat_50073": 0.8075444102287292, "aqua_rat_58088": 0.8087851405143738, "aqua_rat_44859": 0.8113785982131958, "aqua_rat_76154": 0.8125179409980774}, "TheoremQA_wenhuchen/determinant1.json": {"camel_14652": 0, "camel_14123": 0, "camel_14811": 0, "camel_14833": 0, "camel_14897": 0, "camel_14678": 0, "camel_14699": 0, "camel_14889": 0, "camel_14153": 0, "camel_14146": 0, "camel_14701": 0, "camel_14692": 0, "camel_14143": 0, "camel_14892": 0, "camel_14068": 0, "camel_15711": 0, "camel_14933": 0, "camel_14903": 0, "camel_15689": 0, "camel_14707": 0, "camel_14653": 0, "camel_14175": 0, "camel_14712": 0, "camel_14670": 0, "camel_14680": 0, "camel_15721": 0, "camel_15426": 0, "camel_14688": 0, "camel_14872": 0, "camel_14937": 0, "camel_15683": 0, "camel_14927": 0, "camel_15547": 0, "camel_14672": 0, "camel_14955": 0, "camel_14898": 0, "camel_14131": 0, "camel_14149": 0, "camel_15623": 0, "camel_14685": 0, "camel_14827": 0, "camel_14709": 0, "camel_14658": 0, "camel_14829": 0, "camel_14671": 0, "camel_15620": 0, "camel_14700": 0, "camel_14087": 0, "camel_14104": 0, "camel_14649": 0, "camel_14706": 0, "camel_14718": 0, "camel_14914": 0, "camel_15590": 0, "camel_14708": 0, "camel_14156": 0, "camel_14109": 0, "camel_15583": 0, "camel_14142": 0, "camel_14924": 0, "camel_14682": 0, "camel_15728": 0, "camel_14884": 0, "camel_14901": 0, "camel_14913": 0, "camel_15360": 0, "camel_15707": 0, "camel_15676": 0, "camel_14860": 0, "camel_14659": 0, "camel_14697": 0, "camel_14127": 0, "camel_14686": 0, "camel_14663": 0, "camel_14715": 0, "camel_14645": 0, "camel_14705": 0, "camel_14908": 0, "camel_15656": 0, "camel_14662": 0, "camel_14674": 0, "camel_14646": 0, "camel_15655": 0, "camel_14084": 0, "camel_14703": 0, "camel_14667": 0, "camel_14690": 0, "camel_14657": 0, "camel_15624": 0, "camel_14654": 0, "camel_14642": 0, "camel_14647": 0, "camel_15679": 0, "camel_14644": 0, "camel_14660": 0, "camel_15727": 0, "camel_15530": 0, "camel_14385": 0, "camel_14151": 0, "camel_15717": 0, "camel_15639": 0, "camel_15687": 0, "camel_14107": 0, "camel_14655": 0, "camel_14702": 0, "camel_14116": 0, "camel_15618": 0, "camel_14664": 0, "camel_14661": 0, "camel_15730": 0, "camel_14640": 0, "camel_14826": 0, "camel_14912": 0, "camel_14693": 0, "camel_14112": 0, "camel_14676": 0, "camel_14103": 0, "camel_14713": 0, "camel_15650": 0, "camel_14121": 0, "camel_14918": 0, "camel_14120": 0, "camel_14141": 0, "camel_14138": 0, "camel_14098": 0, "camel_14684": 0, "camel_14947": 0, "camel_14643": 0, "TheoremQA_wenhuchen/determinant1.json": 0, "camel_14666": 0, "camel_14696": 0, "camel_14651": 0, "camel_14092": 0, "camel_14095": 0, "camel_15748": 0, "camel_14158": 0, "camel_14159": 0, "camel_14717": 0, "camel_14687": 0, "camel_15619": 0, "camel_14136": 0, "camel_14641": 0, "camel_21355": 0.7182471752166748, "camel_21297": 0.7184483408927917, "camel_21300": 0.7193180918693542, "camel_21281": 0.7195891737937927, "camel_21331": 0.7197203636169434, "camel_21341": 0.7197912335395813, "camel_21312": 0.7200831770896912, "camel_21309": 0.7202020287513733, "camel_27607": 0.7204338312149048, "camel_21517": 0.720477819442749, "camel_26864": 0.7206708192825317, "camel_21306": 0.7208918929100037, "camel_21315": 0.7212706208229065, "camel_21354": 0.7213963866233826, "camel_21310": 0.7216899394989014, "camel_21325": 0.7219046950340271, "camel_21316": 0.7221156358718872, "camel_21290": 0.7221634387969971, "camel_27647": 0.7222071886062622, "camel_21344": 0.7224381566047668, "camel_21305": 0.7246429324150085, "camel_21320": 0.725159227848053, "camel_21286": 0.7257205843925476, "camel_21326": 0.7257868051528931, "camel_21284": 0.7259058952331543, "camel_27617": 0.7262065410614014, "camel_27670": 0.7267037034034729, "camel_27603": 0.7267122268676758, "camel_26823": 0.7267492413520813, "camel_27688": 0.7268988490104675, "camel_27658": 0.7276220917701721, "camel_21359": 0.7281937599182129, "camel_27619": 0.728415310382843, "camel_26841": 0.7286881804466248, "camel_21295": 0.7293356657028198, "camel_21351": 0.7293495535850525, "camel_21335": 0.7316579222679138, "camel_21334": 0.7317872047424316, "camel_21318": 0.7318045496940613, "camel_26858": 0.7319226861000061, "camel_21327": 0.734372079372406, "camel_27672": 0.7344010472297668, "camel_21319": 0.7347802519798279, "camel_21322": 0.7353150844573975, "camel_27657": 0.7353971004486084, "camel_21311": 0.7368329763412476, "camel_21347": 0.7370708584785461, "camel_21298": 0.7371061444282532, "camel_21340": 0.7391166687011719, "camel_27449": 0.7393776178359985, "camel_27500": 0.7402629256248474, "camel_27506": 0.7452992796897888, "camel_27648": 0.7493879199028015, "camel_27634": 0.7544971108436584, "camel_27667": 0.7600175142288208, "camel_27627": 0.7617670297622681, "camel_27639": 0.7655009627342224, "TheoremQA_elainewan/math_algebra_2.json": 0.7656707763671875}, "TheoremQA_wenhuchen/trapezoidal_rule2.json": {"camel_6983": 0, "camel_7268": 0, "gsm_rft_9234": 0.7604501247406006, "gsm_train_23437": 0.7604501247406006, "camel_8833": 0.7604625225067139, "camel_2542": 0.7604832053184509, "camel_2504": 0.7605695724487305, "aqua_rat_87977": 0.7606611251831055, "gsm_rft_19141": 0.760717511177063, "gsm_rft_19244": 0.760717511177063, "gsm_train_17909": 0.760717511177063, "gsm_rft_881": 0.7608652710914612, "aqua_rat_5634": 0.7609448432922363, "gsm_rft_22100": 0.7609524130821228, "gsm_train_20093": 0.7609524130821228, "math_train_prealgebra_320": 0.7609736323356628, "camel_2483": 0.7610231041908264, "gsm_rft_13006": 0.7611098885536194, "gsm_rft_24748": 0.7611356973648071, "aqua_rat_57738": 0.7611375451087952, "aqua_rat_82630": 0.7611563205718994, "gsm_train_27703": 0.7612991333007812, "camel_2539": 0.7613963484764099, "aqua_rat_27248": 0.7615666389465332, "camel_2522": 0.7616245150566101, "camel_2502": 0.7617479562759399, "aqua_rat_87036": 0.7617564797401428, "gsm_rft_1213": 0.7617838978767395, "gsm_train_17203": 0.7617838978767395, "gsm_rft_17966": 0.761825442314148, "gsm_rft_18739": 0.7618642449378967, "gsm_rft_18442": 0.7618892192840576, "gsm_train_18640": 0.7618892192840576, "aqua_rat_81336": 0.7619444727897644, "camel_2513": 0.7620065808296204, "camel_2534": 0.7620338201522827, "aqua_rat_71356": 0.7622259855270386, "gsm_rft_8337": 0.762256383895874, "aqua_rat_67621": 0.7622731924057007, "gsm_rft_25388": 0.7625376582145691, "aqua_rat_12750": 0.7625487446784973, "aqua_rat_3097": 0.762574315071106, "camel_2546": 0.7625772953033447, "aqua_rat_22466": 0.76259446144104, "camel_2549": 0.7626115679740906, "gsm_rft_33995": 0.7626321911811829, "gsm_rft_1640": 0.7626493573188782, "gsm_rft_11277": 0.7626540064811707, "camel_2559": 0.7627575993537903, "gsm_rft_14668": 0.7629352807998657, "gsm_train_4997": 0.7629352807998657, "camel_2510": 0.7630728483200073, "aqua_rat_40968": 0.7633907198905945, "camel_2493": 0.7634742856025696, "aqua_rat_57135": 0.7634773254394531, "gsm_rft_24768": 0.7634934782981873, "aqua_rat_54674": 0.763574481010437, "aqua_rat_40952": 0.7635862231254578, "gsm_rft_31476": 0.7636626362800598, "gsm_rft_33848": 0.763681948184967, "aqua_rat_46805": 0.763706624507904, "gsm_rft_5595": 0.7637102603912354, "camel_2503": 0.7639267444610596, "camel_2533": 0.7639570832252502, "aqua_rat_25321": 0.7639617323875427, "camel_2536": 0.7640154361724854, "gsm_rft_33800": 0.7640549540519714, "camel_39169": 0.7640594244003296, "gsm_train_31817": 0.7640940546989441, "aqua_rat_86892": 0.7642893195152283, "gsm_train_8683": 0.76444411277771, "aqua_rat_54918": 0.7644827365875244, "aqua_rat_76593": 0.7646052241325378, "gsm_rft_13895": 0.764679491519928, "camel_2492": 0.7647947072982788, "gsm_rft_1103": 0.764866828918457, "gsm_train_11153": 0.7650556564331055, "camel_2547": 0.765082061290741, "camel_2485": 0.7651016712188721, "aqua_rat_87387": 0.7651926279067993, "aqua_rat_37293": 0.7652286887168884, "camel_2557": 0.7652353644371033, "gsm_rft_5297": 0.76548171043396, "gsm_train_23531": 0.76548171043396, "gsm_rft_9467": 0.7654951810836792, "gsm_rft_6053": 0.7655138969421387, "gsm_rft_11210": 0.7655541300773621, "gsm_rft_6342": 0.7655541300773621, "aqua_rat_41306": 0.7655921578407288, "gsm_rft_30111": 0.7656246423721313, "gsm_train_28955": 0.7656246423721313, "gsm_rft_19111": 0.7656409740447998, "camel_2515": 0.7658425569534302, "gsm_rft_35098": 0.7659304738044739, "gsm_rft_12565": 0.7662280201911926, "gsm_train_9077": 0.7662280201911926, "aqua_rat_11328": 0.766460120677948, "aqua_rat_49939": 0.766474187374115, "gsm_rft_13342": 0.7665305137634277, "gsm_rft_27596": 0.7665467858314514, "gsm_rft_1164": 0.766610860824585, "camel_9911": 0.7666891813278198, "aqua_rat_64015": 0.7668514251708984, "camel_2545": 0.7670109272003174, "camel_2551": 0.7671087980270386, "gsm_rft_31676": 0.7672768831253052, "gsm_train_2303": 0.7674661874771118, "gsm_rft_1153": 0.7674661874771118, "gsm_train_3314": 0.7675065994262695, "gsm_rft_18060": 0.7675065994262695, "camel_2499": 0.7675309777259827, "gsm_rft_34505": 0.7680381536483765, "camel_25570": 0.7682985663414001, "gsm_train_12230": 0.7684376239776611, "gsm_rft_13994": 0.7685747742652893, "gsm_rft_11840": 0.7691558003425598, "gsm_rft_29042": 0.769461452960968, "gsm_rft_19620": 0.7694904208183289, "gsm_rft_27782": 0.769609272480011, "math_train_prealgebra_234": 0.7697681188583374, "aqua_rat_26579": 0.769923210144043, "gsm_rft_34951": 0.770339846611023, "gsm_rft_23196": 0.7704192399978638, "gsm_train_1557": 0.7704588770866394, "gsm_train_16009": 0.7704892158508301, "gsm_rft_25361": 0.7704892158508301, "gsm_rft_11107": 0.7705637812614441, "gsm_rft_7198": 0.7707746028900146, "camel_2496": 0.7708038091659546, "gsm_rft_8362": 0.7709646224975586, "gsm_rft_24811": 0.771185040473938, "gsm_rft_11802": 0.7711873650550842, "gsm_rft_2329": 0.7717617750167847, "gsm_rft_7754": 0.7719665765762329, "gsm_rft_30904": 0.7723543047904968, "gsm_train_19303": 0.7739605903625488, "gsm_rft_29693": 0.7740546464920044, "aqua_rat_32273": 0.7741690874099731, "gsm_rft_19697": 0.7741860747337341, "aqua_rat_4376": 0.7742072939872742, "math_train_algebra_2250": 0.7742741703987122, "gsm_train_21508": 0.7744796276092529, "gsm_rft_20099": 0.7745693325996399, "gsm_rft_2105": 0.7746384143829346, "gsm_rft_5163": 0.7746501564979553, "gsm_rft_32515": 0.7749590277671814, "gsm_train_18502": 0.7750848531723022, "gsm_rft_17965": 0.7750848531723022, "gsm_rft_24307": 0.7754563689231873, "gsm_rft_14014": 0.7754563689231873, "gsm_train_23574": 0.7754563689231873, "gsm_rft_18087": 0.7754899859428406, "gsm_train_16316": 0.7754899859428406, "gsm_train_30034": 0.7755706310272217, "gsm_rft_11392": 0.7756856083869934, "gsm_rft_2359": 0.7759421467781067, "aqua_rat_9157": 0.7759429216384888, "gsm_rft_14270": 0.7762049436569214, "gsm_rft_13043": 0.7762437462806702, "gsm_rft_29601": 0.7762437462806702, "math_test_prealgebra_1108": 0.7766070365905762, "gsm_rft_26539": 0.7766361236572266, "gsm_train_35065": 0.7772541642189026, "aqua_rat_7395": 0.7773670554161072, "gsm_rft_27714": 0.7777950167655945, "gsm_rft_9176": 0.7784295082092285, "gsm_rft_17822": 0.778504490852356, "gsm_train_34233": 0.778504490852356, "aqua_rat_33076": 0.7792180776596069, "gsm_rft_22976": 0.7798424363136292, "gsm_train_9254": 0.7798424363136292, "gsm_rft_26885": 0.7799532413482666, "aqua_rat_31829": 0.7805593609809875, "aqua_rat_31646": 0.7807415723800659, "gsm_rft_16237": 0.7809160351753235, "camel_39190": 0.7816314697265625, "gsm_rft_30314": 0.7821210622787476, "gsm_rft_459": 0.782394528388977, "gsm_rft_21346": 0.782394528388977, "gsm_train_18047": 0.782394528388977, "math_test_prealgebra_1365": 0.7826846241950989, "gsm_rft_16567": 0.7828460931777954, "gsm_rft_2111": 0.7833414673805237, "gsm_train_31076": 0.7834311723709106, "gsm_rft_10281": 0.7853296399116516, "aqua_rat_39753": 0.7858374714851379, "gsm_rft_28906": 0.7859508991241455, "gsm_rft_20964": 0.7862325310707092, "gsm_rft_20498": 0.7867399454116821, "gsm_rft_27772": 0.7882848381996155, "gsm_rft_9807": 0.7887928485870361, "gsm_train_35547": 0.789093017578125, "gsm_rft_27927": 0.7892049551010132, "gsm_rft_6218": 0.7898741960525513, "gsm_rft_4841": 0.7900146842002869, "gsm_rft_2358": 0.7902805209159851, "gsm_train_1555": 0.7902805209159851, "gsm_rft_13368": 0.7913031578063965, "gsm_rft_32158": 0.7914597988128662, "gsm_rft_21502": 0.7945989966392517}, "TheoremQA_xinyi/huffman_code_1.json": {"TheoremQA_xinyi/huffman_code_1.json": 0, "camel_27291": 0.6799110174179077, "aqua_rat_11482": 0.6799334287643433, "math_test_counting_and_probability_27": 0.6799529790878296, "aqua_rat_50286": 0.6799576282501221, "camel_27343": 0.6800800561904907, "camel_13785": 0.680387556552887, "camel_26434": 0.6804676055908203, "aqua_rat_79033": 0.6804689168930054, "aqua_rat_8477": 0.6806022524833679, "camel_27331": 0.6806241273880005, "camel_26799": 0.6806769967079163, "camel_26404": 0.6807458996772766, "aqua_rat_21182": 0.6807945966720581, "aqua_rat_52711": 0.6808134317398071, "aqua_rat_11382": 0.6808305382728577, "aqua_rat_70621": 0.680847704410553, "camel_27940": 0.6809649467468262, "aqua_rat_70441": 0.6811437010765076, "camel_27418": 0.6811828017234802, "camel_26447": 0.6814103126525879, "aqua_rat_77566": 0.6814292669296265, "camel_26410": 0.6814579963684082, "camel_26407": 0.6814600229263306, "camel_27310": 0.6815243363380432, "camel_26456": 0.6815439462661743, "aqua_rat_88152": 0.6816002130508423, "camel_27427": 0.6816260814666748, "aqua_rat_86040": 0.6818100810050964, "aqua_rat_79806": 0.6818317174911499, "camel_27308": 0.6818441152572632, "aqua_rat_29934": 0.6819099187850952, "aqua_rat_17550": 0.6819531321525574, "camel_27424": 0.6821643710136414, "camel_26502": 0.6821942925453186, "camel_13805": 0.6823533177375793, "aqua_rat_88778": 0.6823949813842773, "aqua_rat_79867": 0.6824714541435242, "aqua_rat_81021": 0.682748019695282, "aqua_rat_21183": 0.6827772259712219, "camel_27337": 0.6828479766845703, "aqua_rat_55739": 0.6829257011413574, "camel_26770": 0.6829358339309692, "aqua_rat_4518": 0.6830087900161743, "aqua_rat_40323": 0.6830988526344299, "aqua_rat_15961": 0.6831598281860352, "camel_13813": 0.6831985116004944, "aqua_rat_73449": 0.6833676695823669, "math_train_counting_and_probability_769": 0.6833909153938293, "TheoremQA_maxku/ipnetwork13-hammingdist.json": 0.683398425579071, "aqua_rat_87185": 0.6834127306938171, "aqua_rat_37328": 0.6834273934364319, "aqua_rat_41276": 0.6835499405860901, "math_test_counting_and_probability_1007": 0.6836400628089905, "aqua_rat_60575": 0.6838205456733704, "camel_26405": 0.6841408610343933, "aqua_rat_6017": 0.6844392418861389, "aqua_rat_17963": 0.6844800114631653, "aqua_rat_53420": 0.6847109198570251, "camel_27994": 0.684751570224762, "camel_27334": 0.6848562955856323, "math_train_prealgebra_426": 0.6848893165588379, "camel_13801": 0.6849204897880554, "camel_27925": 0.684964656829834, "aqua_rat_10179": 0.6850360035896301, "aqua_rat_8833": 0.6852710247039795, "camel_27350": 0.6853020787239075, "aqua_rat_88939": 0.6853070259094238, "camel_27982": 0.6853933334350586, "camel_36357": 0.685549795627594, "aqua_rat_79863": 0.6855628490447998, "aqua_rat_47339": 0.685604989528656, "camel_26442": 0.6856122612953186, "camel_27353": 0.685695469379425, "aqua_rat_19231": 0.6859817504882812, "aqua_rat_10824": 0.6860613822937012, "aqua_rat_10199": 0.6861294507980347, "aqua_rat_28815": 0.6861721277236938, "aqua_rat_68315": 0.6861737966537476, "camel_37882": 0.6861746311187744, "camel_13795": 0.6863399147987366, "camel_26463": 0.6864063739776611, "aqua_rat_954": 0.6865552067756653, "gsm_rft_9798": 0.6870133876800537, "camel_27303": 0.6870821118354797, "aqua_rat_19311": 0.6873474717140198, "aqua_rat_74669": 0.6874474883079529, "aqua_rat_39955": 0.6876323819160461, "aqua_rat_7449": 0.6877207159996033, "camel_27409": 0.6879302263259888, "camel_13818": 0.6879909038543701, "aqua_rat_53262": 0.6884269714355469, "aqua_rat_48838": 0.6884548664093018, "aqua_rat_24779": 0.6884776949882507, "aqua_rat_14732": 0.6885120868682861, "camel_26443": 0.6885770559310913, "camel_26500": 0.6886909008026123, "camel_26436": 0.6888108253479004, "camel_26518": 0.689069926738739, "camel_26485": 0.6891461610794067, "camel_26452": 0.6891485452651978, "camel_13808": 0.6892045140266418, "aqua_rat_63905": 0.6894631385803223, "aqua_rat_17007": 0.6896531581878662, "aqua_rat_15725": 0.689966082572937, "aqua_rat_24634": 0.6902759075164795, "aqua_rat_49708": 0.6903923749923706, "aqua_rat_85171": 0.6906071901321411, "aqua_rat_59175": 0.690669059753418, "camel_13802": 0.6908053159713745, "aqua_rat_54809": 0.6909044981002808, "camel_26745": 0.6910024285316467, "camel_26541": 0.6912965774536133, "aqua_rat_38681": 0.6913507580757141, "aqua_rat_77219": 0.6913647055625916, "TheoremQA_maxku/ipnetwork14-hammingdist.json": 0.6914181113243103, "camel_27938": 0.69146329164505, "camel_26453": 0.6916223764419556, "aqua_rat_7001": 0.6916384696960449, "aqua_rat_13318": 0.691889762878418, "camel_27420": 0.6919068098068237, "camel_26516": 0.6919757723808289, "camel_27381": 0.6920765042304993, "camel_26470": 0.6921629905700684, "aqua_rat_73041": 0.6922368407249451, "aqua_rat_3845": 0.6923466920852661, "camel_26427": 0.6924959421157837, "aqua_rat_85697": 0.6925691366195679, "camel_13809": 0.6927036643028259, "camel_13791": 0.6928168535232544, "aqua_rat_33082": 0.6929056644439697, "aqua_rat_2960": 0.6929329633712769, "camel_26549": 0.6929739713668823, "aqua_rat_53711": 0.6930232644081116, "camel_27316": 0.6931422352790833, "aqua_rat_21454": 0.6934957504272461, "aqua_rat_34195": 0.693626344203949, "camel_37553": 0.6936519145965576, "aqua_rat_19137": 0.6937955617904663, "camel_26460": 0.6942161321640015, "camel_37500": 0.6942305564880371, "camel_27326": 0.6949150562286377, "camel_27288": 0.6950767636299133, "aqua_rat_3522": 0.6955410838127136, "aqua_rat_108": 0.6955702304840088, "camel_13823": 0.6958496570587158, "math_test_prealgebra_1511": 0.6963092088699341, "aqua_rat_54964": 0.696337103843689, "camel_26534": 0.6965155601501465, "math_train_counting_and_probability_428": 0.696533203125, "aqua_rat_31049": 0.6966915130615234, "camel_27393": 0.6980474591255188, "camel_27298": 0.6983721256256104, "aqua_rat_83119": 0.6986499428749084, "camel_26545": 0.6990252733230591, "aqua_rat_23851": 0.6996326446533203, "aqua_rat_1879": 0.7001659870147705, "aqua_rat_9869": 0.700750470161438, "aqua_rat_43755": 0.7013777494430542, "gsm_train_2795": 0.7029452919960022, "gsm_rft_6414": 0.7029452919960022, "gsm_rft_4133": 0.7029452919960022, "aqua_rat_67588": 0.7030301690101624, "aqua_rat_47622": 0.7033949494361877, "camel_13806": 0.7035746574401855, "math_train_number_theory_492": 0.704955518245697, "aqua_rat_13873": 0.7054398655891418, "camel_26772": 0.7055785059928894, "aqua_rat_31336": 0.7060574293136597, "aqua_rat_57240": 0.7074440717697144, "aqua_rat_4340": 0.707561731338501, "camel_27294": 0.7079674005508423, "aqua_rat_32025": 0.7080404162406921, "camel_13764": 0.708627462387085, "aqua_rat_78639": 0.7095130085945129, "aqua_rat_39830": 0.7096255421638489, "aqua_rat_1953": 0.7098211646080017, "camel_27426": 0.7099519371986389, "aqua_rat_17743": 0.7100701332092285, "camel_27281": 0.7100968360900879, "aqua_rat_19653": 0.7101343870162964, "camel_27355": 0.7101362943649292, "aqua_rat_87221": 0.7103946805000305, "aqua_rat_34268": 0.7104810476303101, "camel_27321": 0.7107991576194763, "aqua_rat_72814": 0.712155818939209, "aqua_rat_33959": 0.7125771641731262, "aqua_rat_63386": 0.7127761840820312, "aqua_rat_5625": 0.7129102945327759, "camel_27357": 0.7130119800567627, "aqua_rat_60244": 0.7130147218704224, "camel_26421": 0.7138494849205017, "aqua_rat_45147": 0.7155216932296753, "aqua_rat_53686": 0.7162289619445801, "camel_27931": 0.7175777554512024, "aqua_rat_36194": 0.7177848815917969, "camel_13838": 0.7380551099777222, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.7549066543579102, "TheoremQA_xinyi/huffman_code_2.json": 0.7766942977905273, "TheoremQA_xinyi/kraft_inequality.json": 0.7835333347320557}, "TheoremQA_wenhuchen/ODE3.json": {"camel_7228": 0, "camel_7983": 0, "camel_7455": 0, "camel_7519": 0, "camel_7495": 0, "camel_7453": 0, "camel_7969": 0, "camel_7469": 0, "camel_7459": 0, "camel_6849": 0, "camel_7920": 0, "camel_6594": 0, "camel_7941": 0, "camel_7456": 0, "camel_7510": 0, "camel_7979": 0, "camel_7931": 0, "camel_7504": 0, "camel_7449": 0, "camel_7445": 0, "camel_7669": 0, "camel_7276": 0, "camel_7629": 0, "camel_7511": 0, "camel_7509": 0, "camel_7506": 0, "camel_7253": 0, "camel_7457": 0, "camel_17436": 0, "camel_7516": 0, "camel_7481": 0, "camel_7946": 0, "camel_6518": 0, "camel_7957": 0, "camel_7936": 0, "camel_7488": 0, "camel_7486": 0, "camel_7446": 0, "camel_7482": 0, "camel_7990": 0, "camel_7447": 0, "camel_17422": 0, "camel_7501": 0, "camel_7472": 0, "camel_7502": 0, "camel_7971": 0, "camel_7466": 0, "camel_7517": 0, "camel_7961": 0, "camel_7949": 0, "camel_7962": 0, "camel_7986": 0, "camel_7487": 0, "camel_7967": 0, "camel_7497": 0, "camel_7494": 0, "camel_7478": 0, "camel_7503": 0, "camel_7955": 0, "camel_17811": 0, "camel_7484": 0, "camel_7450": 0, "camel_7940": 0, "camel_7475": 0, "camel_7950": 0, "camel_17406": 0, "camel_7610": 0, "camel_7513": 0, "camel_7467": 0, "camel_7463": 0, "camel_7443": 0, "camel_7970": 0, "camel_7987": 0, "camel_17361": 0, "camel_7927": 0, "camel_7935": 0, "camel_7468": 0, "camel_28811": 0.7688942551612854, "aqua_rat_53348": 0.7691248655319214, "aqua_rat_57461": 0.769185483455658, "aqua_rat_32037": 0.7696870565414429, "camel_40249": 0.769814670085907, "gsm_rft_3538": 0.7698927521705627, "gsm_rft_2034": 0.7698927521705627, "gsm_train_21024": 0.769948422908783, "camel_39480": 0.7700200080871582, "camel_5172": 0.77009516954422, "camel_28802": 0.771198034286499, "camel_28859": 0.7717627882957458, "aqua_rat_4051": 0.7718194127082825, "camel_29950": 0.7720488905906677, "camel_29385": 0.7721813917160034, "camel_39469": 0.7724836468696594, "camel_28532": 0.7725120782852173, "camel_39471": 0.7732136845588684, "camel_28812": 0.7736119627952576, "camel_5227": 0.773673951625824, "camel_29060": 0.7739539742469788, "camel_29388": 0.7739608883857727, "camel_29387": 0.7742682099342346, "camel_28804": 0.7745362520217896, "camel_29972": 0.7755748629570007, "camel_5011": 0.775676429271698, "camel_28855": 0.7757749557495117, "camel_39509": 0.7760280966758728, "camel_39475": 0.7767863869667053, "camel_28086": 0.7772111892700195, "camel_39488": 0.7772345542907715, "camel_28841": 0.7773203253746033, "camel_5165": 0.7773365378379822, "camel_29372": 0.7774003744125366, "camel_29373": 0.7787105441093445, "camel_28858": 0.7789019346237183, "camel_28809": 0.7789674401283264, "camel_39308": 0.7793339490890503, "camel_28827": 0.7794650793075562, "camel_5035": 0.7797208428382874, "camel_28822": 0.7798467874526978, "camel_39513": 0.7809252142906189, "camel_28780": 0.7812229990959167, "camel_28846": 0.7812405228614807, "TheoremQA_elainewan/math_calculus_3_6.json": 0.7817847728729248, "camel_28145": 0.7817882895469666, "camel_29438": 0.782112717628479, "camel_5070": 0.7821199893951416, "camel_5094": 0.7822591066360474, "camel_28844": 0.7824231386184692, "camel_5008": 0.7824768424034119, "camel_28866": 0.782699465751648, "camel_28873": 0.7834135293960571, "camel_39441": 0.7837506532669067, "camel_39457": 0.7841207981109619, "camel_29379": 0.7845464944839478, "camel_28876": 0.7845789194107056, "camel_39454": 0.7849160432815552, "camel_39474": 0.7852337956428528, "camel_28801": 0.7855473756790161, "camel_28836": 0.78603595495224, "camel_28080": 0.786202609539032, "camel_28794": 0.7870150208473206, "camel_39446": 0.7873486280441284, "camel_28816": 0.7882336974143982, "camel_29467": 0.7882888317108154, "camel_5092": 0.7885857820510864, "camel_5311": 0.788735568523407, "camel_29426": 0.7893636226654053, "camel_39511": 0.7893815636634827, "camel_5079": 0.7894233465194702, "camel_39510": 0.7902287244796753, "camel_5114": 0.7911737561225891, "camel_5117": 0.7912399768829346, "camel_28854": 0.7912481427192688, "camel_28803": 0.791333794593811, "camel_39468": 0.7917953133583069, "camel_5093": 0.792451024055481, "camel_39460": 0.7929756045341492, "camel_39486": 0.7931287884712219, "camel_39479": 0.7938624024391174, "camel_28840": 0.7939611673355103, "camel_28715": 0.7939614057540894, "camel_39505": 0.7940612435340881, "camel_28874": 0.7941781282424927, "camel_28851": 0.7945705056190491, "camel_28824": 0.7950950860977173, "camel_39453": 0.7953919768333435, "camel_28853": 0.7954515814781189, "camel_39503": 0.7959698438644409, "camel_28830": 0.7960289716720581, "camel_5029": 0.7963652014732361, "camel_28806": 0.7964408993721008, "camel_39473": 0.7970348596572876, "camel_4986": 0.7973772287368774, "camel_28878": 0.797671914100647, "camel_28861": 0.7978132367134094, "TheoremQA_elainewan/math_calculus_12.json": 0.7984158396720886, "camel_28837": 0.799450695514679, "camel_28815": 0.7994790077209473, "camel_28842": 0.800644040107727, "camel_28814": 0.801893413066864, "camel_28852": 0.802550733089447, "camel_28847": 0.8027746677398682, "camel_28813": 0.8029651045799255, "camel_28137": 0.8031277656555176, "camel_28845": 0.8048332333564758, "camel_28823": 0.8052128553390503, "camel_39517": 0.8055567741394043, "camel_28068": 0.8082870244979858, "camel_28867": 0.8089467883110046, "camel_28826": 0.8094016313552856, "camel_28831": 0.8104866147041321, "camel_28805": 0.8106497526168823, "camel_28832": 0.8107971549034119, "camel_28848": 0.810981035232544, "camel_28860": 0.8117696642875671, "camel_28909": 0.8120479583740234, "camel_28869": 0.8121243119239807, "camel_28022": 0.8134518265724182, "camel_28862": 0.8136969804763794, "camel_28024": 0.822590172290802, "camel_29979": 0.8253732323646545}, "TheoremQA_maxku/ipnetwork4-mac.json": {"camel_11880": 0.8161778450012207, "camel_37652": 0.8162182569503784, "aqua_rat_77396": 0.8164157271385193, "camel_10705": 0.8164374232292175, "camel_10386": 0.8164809942245483, "camel_11133": 0.8165906071662903, "camel_11951": 0.8166418075561523, "aqua_rat_88905": 0.8166667819023132, "camel_8731": 0.8166983723640442, "aqua_rat_23058": 0.8167179822921753, "camel_11499": 0.816825270652771, "camel_11416": 0.8168575763702393, "camel_10801": 0.8168590068817139, "camel_10999": 0.8169217705726624, "aqua_rat_70748": 0.8169669508934021, "camel_10955": 0.8170103430747986, "camel_25913": 0.8171105980873108, "camel_11588": 0.8171311616897583, "aqua_rat_38490": 0.817180871963501, "aqua_rat_70905": 0.8173221349716187, "camel_10910": 0.8173325657844543, "camel_11360": 0.817375659942627, "camel_11713": 0.8173860311508179, "aqua_rat_50672": 0.8174927234649658, "aqua_rat_55374": 0.8175194263458252, "camel_11683": 0.8175315260887146, "camel_11576": 0.8177433609962463, "aqua_rat_50317": 0.817909300327301, "camel_11126": 0.8180086016654968, "camel_11158": 0.8181133270263672, "camel_8375": 0.8181396722793579, "camel_11341": 0.8182063698768616, "camel_10467": 0.8182370066642761, "aqua_rat_17559": 0.8182496428489685, "camel_11419": 0.8182910680770874, "camel_11318": 0.8183329105377197, "camel_10374": 0.8183870911598206, "camel_11527": 0.8184436559677124, "camel_11909": 0.818536102771759, "camel_10694": 0.8185765147209167, "camel_11433": 0.8186862468719482, "camel_11967": 0.8186985850334167, "camel_11072": 0.8189020752906799, "camel_10657": 0.8189436793327332, "camel_11845": 0.8189890384674072, "gsm_rft_32682": 0.8190499544143677, "camel_11043": 0.8190715312957764, "camel_11094": 0.8191169500350952, "aqua_rat_44158": 0.8191482424736023, "camel_11860": 0.8191940188407898, "camel_10937": 0.8192908763885498, "camel_11348": 0.8193349242210388, "camel_11786": 0.8194193840026855, "camel_11199": 0.819571852684021, "camel_10903": 0.8196138143539429, "camel_11142": 0.8196424841880798, "camel_10848": 0.8197594285011292, "aqua_rat_8224": 0.8197608590126038, "camel_10878": 0.819835364818573, "aqua_rat_74679": 0.8198409676551819, "aqua_rat_67820": 0.8200106620788574, "camel_11357": 0.8201947808265686, "camel_11857": 0.8202027082443237, "aqua_rat_63581": 0.8203636407852173, "camel_11677": 0.8203697800636292, "camel_11852": 0.8203914761543274, "camel_25283": 0.82039874792099, "camel_25895": 0.8204149603843689, "camel_9905": 0.8204383254051208, "camel_8333": 0.8205496072769165, "camel_11107": 0.820558488368988, "aqua_rat_63221": 0.8206407427787781, "camel_10952": 0.8206535577774048, "aqua_rat_45977": 0.8206743597984314, "camel_11660": 0.8209178447723389, "camel_11138": 0.8209502100944519, "camel_11438": 0.8211453557014465, "camel_11871": 0.8211511969566345, "camel_11163": 0.8213207125663757, "camel_10872": 0.821330189704895, "camel_25891": 0.8214113712310791, "camel_11876": 0.8214313983917236, "camel_11118": 0.8214378952980042, "camel_11883": 0.8215479254722595, "camel_11085": 0.8215790390968323, "camel_11092": 0.8215980529785156, "camel_11797": 0.8217207789421082, "camel_11461": 0.8218668699264526, "camel_10876": 0.8221080899238586, "camel_9485": 0.8221933841705322, "camel_11827": 0.8222920894622803, "camel_11172": 0.822297215461731, "camel_11394": 0.8223903179168701, "camel_10361": 0.822462797164917, "camel_11339": 0.8228507041931152, "camel_11563": 0.8228746652603149, "camel_11108": 0.8229578137397766, "camel_11726": 0.822978675365448, "camel_8737": 0.8230457305908203, "camel_10855": 0.8231954574584961, "camel_25887": 0.8232857584953308, "camel_11694": 0.8235276341438293, "camel_11159": 0.8235423564910889, "camel_11423": 0.8236128091812134, "camel_11135": 0.8237555623054504, "camel_11559": 0.8237556219100952, "camel_10327": 0.8239354491233826, "aqua_rat_14944": 0.8240475654602051, "camel_11508": 0.8241039514541626, "camel_9476": 0.8242511749267578, "aqua_rat_80543": 0.824783980846405, "camel_11658": 0.8248034119606018, "camel_11861": 0.8248431086540222, "aqua_rat_21939": 0.824885904788971, "camel_10812": 0.8251413106918335, "camel_11465": 0.8251945972442627, "camel_10880": 0.8252385258674622, "camel_11167": 0.8252687454223633, "camel_8353": 0.8253666758537292, "camel_10632": 0.8253870606422424, "camel_11635": 0.8256927132606506, "aqua_rat_46839": 0.8260351419448853, "aqua_rat_67279": 0.8262051343917847, "camel_10803": 0.8263775110244751, "camel_11361": 0.8264018893241882, "camel_11702": 0.826445996761322, "camel_11175": 0.8267149925231934, "camel_11698": 0.8267366290092468, "camel_11600": 0.8268802165985107, "camel_11356": 0.8272690773010254, "camel_11900": 0.8273524045944214, "camel_11238": 0.8275889158248901, "camel_37781": 0.8277068734169006, "aqua_rat_20632": 0.8277522921562195, "camel_11327": 0.828035295009613, "camel_11942": 0.8281473517417908, "camel_36523": 0.828203558921814, "camel_37612": 0.8283047676086426, "camel_11885": 0.8283771276473999, "aqua_rat_38029": 0.8284129500389099, "camel_11822": 0.828563928604126, "aqua_rat_79964": 0.8287391662597656, "aqua_rat_71604": 0.8288199305534363, "gsm_train_18030": 0.8295825719833374, "camel_10926": 0.8300583362579346, "camel_10365": 0.8300749659538269, "camel_11796": 0.8300848007202148, "aqua_rat_74224": 0.8302956223487854, "camel_37886": 0.8307864665985107, "aqua_rat_88015": 0.8316147327423096, "camel_11874": 0.8317553997039795, "gsm_rft_34671": 0.8319436311721802, "gsm_rft_25950": 0.8319436311721802, "camel_11436": 0.8319726586341858, "camel_10335": 0.8321049213409424, "camel_11988": 0.8322662711143494, "camel_11872": 0.8325083255767822, "camel_11650": 0.8326275944709778, "camel_11907": 0.8326568603515625, "aqua_rat_86209": 0.8328913450241089, "camel_11422": 0.8328971862792969, "camel_8784": 0.8329823613166809, "camel_11470": 0.8330879211425781, "camel_10839": 0.8337295651435852, "camel_9456": 0.8342615365982056, "camel_11870": 0.8346394896507263, "camel_11316": 0.8351966738700867, "aqua_rat_37698": 0.8352155089378357, "camel_11818": 0.835644543170929, "camel_11064": 0.8357412219047546, "camel_11320": 0.8366191387176514, "aqua_rat_64039": 0.8366327881813049, "camel_11308": 0.8368752002716064, "camel_11539": 0.8372405767440796, "camel_11756": 0.8379063010215759, "camel_11558": 0.8382846713066101, "aqua_rat_69941": 0.8390330672264099, "camel_10568": 0.839247465133667, "aqua_rat_87308": 0.8395847678184509, "camel_11864": 0.8396422266960144, "camel_11774": 0.8401203751564026, "camel_11741": 0.8405366539955139, "camel_11853": 0.8409152030944824, "aqua_rat_47751": 0.8409773111343384, "camel_11456": 0.841249406337738, "aqua_rat_40444": 0.8414596319198608, "aqua_rat_60327": 0.8416550755500793, "aqua_rat_6577": 0.8420547246932983, "aqua_rat_80730": 0.8421127796173096, "aqua_rat_50510": 0.8426395058631897, "aqua_rat_21944": 0.8427293300628662, "aqua_rat_62298": 0.843497633934021, "camel_11548": 0.8480345010757446, "camel_9464": 0.8482696413993835, "camel_11898": 0.8507360219955444, "camel_11875": 0.8535341620445251, "camel_11866": 0.8575940728187561, "camel_11719": 0.8580000996589661, "camel_11903": 0.8607039451599121, "camel_11946": 0.8627722859382629}, "TheoremQA_maxku/graphtheory5-vertexcover.json": {"camel_21057": 0, "camel_23174": 0, "camel_22857": 0, "camel_23435": 0, "camel_21182": 0, "camel_23182": 0, "camel_22754": 0, "camel_23404": 0, "camel_22218": 0, "camel_21144": 0, "camel_23144": 0, "camel_22861": 0, "camel_23192": 0, "camel_22829": 0, "camel_22800": 0, "camel_22040": 0, "camel_22755": 0, "camel_23797": 0, "camel_22168": 0, "camel_22847": 0, "camel_22863": 0, "camel_21044": 0, "camel_22356": 0, "camel_22300": 0, "camel_22223": 0, "camel_22765": 0, "camel_22216": 0, "camel_22224": 0, "camel_21197": 0, "camel_23372": 0, "camel_22347": 0, "camel_21158": 0, "camel_22749": 0, "camel_22872": 0, "camel_23414": 0, "camel_23360": 0, "camel_22770": 0, "camel_23190": 0, "camel_22393": 0, "camel_22722": 0, "camel_22835": 0, "camel_23134": 0, "camel_21678": 0, "camel_23141": 0, "camel_23389": 0, "camel_21190": 0, "camel_23146": 0, "camel_22396": 0, "camel_21162": 0, "camel_21784": 0, "camel_23430": 0, "camel_22780": 0, "camel_21376": 0, "camel_21195": 0, "camel_23381": 0, "TheoremQA_maxku/graphtheory5-vertexcover.json": 0, "camel_21157": 0, "camel_23362": 0, "camel_21135": 0, "camel_22384": 0, "camel_22791": 0, "camel_22398": 0, "camel_22742": 0, "camel_23395": 0, "camel_23306": 0, "camel_22188": 0, "camel_22191": 0, "camel_23158": 0, "camel_22867": 0, "camel_23379": 0, "camel_22785": 0, "camel_22789": 0, "camel_23438": 0, "camel_23369": 0, "camel_22809": 0, "camel_23367": 0, "camel_22873": 0, "camel_22721": 0, "camel_21083": 0, "camel_22737": 0, "camel_22859": 0, "camel_22753": 0, "camel_22767": 0, "camel_23409": 0, "camel_22734": 0, "camel_22768": 0, "camel_22763": 0, "camel_21179": 0, "camel_21132": 0, "camel_22778": 0, "camel_22397": 0, "camel_21188": 0, "camel_22875": 0, "camel_23393": 0, "camel_22179": 0, "camel_21194": 0, "camel_21193": 0, "camel_23400": 0, "camel_22870": 0, "camel_22752": 0, "camel_21161": 0, "camel_22740": 0, "camel_22729": 0, "camel_23363": 0, "camel_22726": 0, "camel_21173": 0, "camel_21186": 0, "camel_23977": 0, "camel_22117": 0, "camel_22329": 0, "camel_22761": 0, "camel_21187": 0, "camel_22756": 0, "camel_22792": 0, "camel_22363": 0, "camel_22377": 0, "camel_22335": 0, "camel_22793": 0, "camel_23397": 0, "camel_23427": 0, "camel_23285": 0, "camel_22808": 0, "camel_21123": 0, "camel_21172": 0, "camel_21122": 0, "camel_21129": 0, "camel_22176": 0, "camel_21130": 0, "camel_22744": 0, "camel_20734": 0, "camel_23374": 0, "camel_22724": 0, "camel_22818": 0, "camel_21170": 0, "camel_22758": 0, "camel_22182": 0, "camel_23424": 0, "camel_22215": 0, "camel_21116": 0, "camel_22728": 0, "camel_21185": 0, "camel_21145": 0, "camel_22738": 0, "camel_22294": 0, "camel_23432": 0, "camel_22746": 0, "camel_22769": 0, "camel_22210": 0, "camel_22810": 0, "camel_22204": 0, "camel_22784": 0, "camel_22760": 0, "camel_22743": 0, "camel_21152": 0, "camel_22773": 0, "camel_22783": 0, "camel_22745": 0, "camel_21198": 0, "camel_22720": 0, "camel_22757": 0, "camel_21180": 0, "camel_22795": 0, "camel_22185": 0, "camel_23410": 0, "camel_22777": 0, "camel_22727": 0, "camel_21133": 0, "camel_22799": 0, "camel_21176": 0, "camel_23364": 0, "camel_22170": 0, "camel_38586": 0.7587785720825195, "aqua_rat_40504": 0.7599570155143738, "camel_36503": 0.7608224153518677, "aqua_rat_28685": 0.7616111040115356, "camel_38489": 0.7618921995162964, "camel_38564": 0.7625828385353088, "camel_39928": 0.7633082270622253, "aqua_rat_25794": 0.7657303810119629, "TheoremQA_maxku/graphtheory2-vertexcover.json": 0.765780508518219, "camel_38561": 0.7664742469787598, "aqua_rat_44895": 0.7675440311431885, "aqua_rat_77006": 0.7677780389785767, "TheoremQA_maxku/graphtheory3-vertexcover.json": 0.7679033279418945, "aqua_rat_64683": 0.768002986907959, "camel_38572": 0.7696166634559631, "aqua_rat_7562": 0.7708592414855957, "aqua_rat_10797": 0.7708613276481628, "camel_38609": 0.7710865139961243, "aqua_rat_76903": 0.7714017033576965, "camel_38906": 0.7726026177406311, "camel_38526": 0.7766432762145996, "aqua_rat_83797": 0.7780949473381042, "aqua_rat_70645": 0.7789134383201599, "aqua_rat_76009": 0.7792682647705078, "gsm_rft_32172": 0.7819049954414368, "gsm_rft_4684": 0.7835161089897156, "gsm_train_26111": 0.7835161089897156, "aqua_rat_44831": 0.7849728465080261, "aqua_rat_54929": 0.7858121991157532}, "TheoremQA_xueguangma/dividend_discount_model_5.json": {"TheoremQA_xueguangma/dividend_discount_model_5.json": 0, "gsm_rft_26723": 0.7089344263076782, "gsm_train_35438": 0.7089344263076782, "gsm_rft_14276": 0.708962619304657, "gsm_rft_20906": 0.7089831829071045, "gsm_train_14445": 0.7089831829071045, "aqua_rat_20008": 0.7090476751327515, "gsm_rft_25984": 0.7090510725975037, "gsm_rft_27287": 0.7090597152709961, "gsm_rft_27319": 0.709094762802124, "aqua_rat_66298": 0.7090994119644165, "aqua_rat_7307": 0.7091489434242249, "gsm_rft_25210": 0.7093337774276733, "gsm_rft_20457": 0.7093906402587891, "gsm_train_19765": 0.7093906402587891, "aqua_rat_255": 0.7094211578369141, "aqua_rat_55623": 0.7098085880279541, "aqua_rat_80382": 0.7098740339279175, "aqua_rat_6366": 0.7100095748901367, "camel_24814": 0.7100205421447754, "gsm_rft_11189": 0.7100884318351746, "gsm_rft_22277": 0.7101012468338013, "aqua_rat_11679": 0.7101088762283325, "gsm_rft_17057": 0.7101858854293823, "gsm_rft_34497": 0.7103261947631836, "gsm_rft_26705": 0.7103261947631836, "aqua_rat_45726": 0.7103672027587891, "gsm_rft_32917": 0.7103927731513977, "aqua_rat_78741": 0.7104046940803528, "gsm_rft_30093": 0.7104578018188477, "gsm_rft_29688": 0.7104759812355042, "aqua_rat_69026": 0.7105210423469543, "aqua_rat_80175": 0.7106029987335205, "gsm_rft_19467": 0.7107628583908081, "gsm_rft_26182": 0.7107682824134827, "gsm_rft_14506": 0.710773766040802, "gsm_train_10049": 0.710773766040802, "gsm_rft_26599": 0.711202085018158, "gsm_train_26918": 0.711202085018158, "aqua_rat_88958": 0.7112212181091309, "aqua_rat_4236": 0.7114159464836121, "TheoremQA_xueguangma/capital_asset_pricing_model.json": 0.7114275097846985, "aqua_rat_35953": 0.7114502787590027, "aqua_rat_52833": 0.7115759253501892, "camel_10506": 0.7118012309074402, "aqua_rat_16605": 0.7118228673934937, "gsm_rft_19340": 0.7118498086929321, "gsm_rft_32019": 0.7119503617286682, "gsm_rft_252": 0.7119728326797485, "aqua_rat_72156": 0.7120736241340637, "gsm_train_17697": 0.7122372388839722, "gsm_rft_470": 0.7122372388839722, "aqua_rat_34230": 0.7123035788536072, "aqua_rat_69591": 0.7123095393180847, "aqua_rat_22679": 0.712371826171875, "aqua_rat_86828": 0.7124496698379517, "aqua_rat_62036": 0.7125487923622131, "gsm_rft_4368": 0.7126010656356812, "gsm_rft_5012": 0.7126576900482178, "TheoremQA_xueguangma/present_value_1.json": 0.7126622796058655, "aqua_rat_798": 0.7129706740379333, "gsm_rft_27770": 0.7131522297859192, "gsm_train_14713": 0.713234007358551, "aqua_rat_56240": 0.7132928371429443, "gsm_rft_8874": 0.7134805917739868, "gsm_train_18102": 0.7134805917739868, "gsm_rft_16966": 0.7135751247406006, "gsm_rft_10252": 0.713702917098999, "aqua_rat_47176": 0.7137647867202759, "aqua_rat_36913": 0.7138193845748901, "aqua_rat_71465": 0.7139474749565125, "gsm_rft_21165": 0.7139589786529541, "TheoremQA_xueguangma/earnings_multiplier_3.json": 0.7140336036682129, "gsm_train_14812": 0.7140554785728455, "aqua_rat_26449": 0.7141214609146118, "gsm_rft_29637": 0.7146743535995483, "aqua_rat_27446": 0.7147108912467957, "gsm_rft_29906": 0.7147185802459717, "gsm_train_16035": 0.7147185802459717, "gsm_rft_5809": 0.7147421836853027, "camel_24831": 0.7148586511611938, "aqua_rat_63332": 0.7149239778518677, "gsm_rft_34694": 0.7149950265884399, "gsm_train_14821": 0.7149978876113892, "gsm_rft_34608": 0.7149993181228638, "gsm_rft_30785": 0.7151034474372864, "gsm_rft_3769": 0.7151854038238525, "aqua_rat_48354": 0.7152774930000305, "aqua_rat_45227": 0.7153237462043762, "aqua_rat_23319": 0.7154512405395508, "aqua_rat_9579": 0.7155402302742004, "aqua_rat_70690": 0.7155558466911316, "gsm_rft_33054": 0.7158566117286682, "aqua_rat_73408": 0.7161781787872314, "aqua_rat_9965": 0.716187059879303, "gsm_rft_32819": 0.7162158489227295, "gsm_rft_1289": 0.7162840366363525, "gsm_rft_29683": 0.7165318727493286, "aqua_rat_56922": 0.7166520357131958, "aqua_rat_59171": 0.716695249080658, "gsm_rft_29910": 0.7167476415634155, "aqua_rat_75134": 0.7167544960975647, "aqua_rat_23836": 0.7168047428131104, "aqua_rat_69571": 0.7168265581130981, "aqua_rat_87246": 0.7169085144996643, "aqua_rat_71897": 0.7169776558876038, "gsm_rft_6266": 0.7171080112457275, "gsm_rft_23395": 0.7171486020088196, "gsm_train_14708": 0.7171486020088196, "aqua_rat_4287": 0.7172515392303467, "aqua_rat_15749": 0.7174587249755859, "aqua_rat_16627": 0.717476487159729, "aqua_rat_48285": 0.7175738215446472, "aqua_rat_13817": 0.7175971269607544, "gsm_train_16212": 0.7176780104637146, "gsm_rft_31378": 0.7176780104637146, "gsm_rft_1668": 0.7176780104637146, "aqua_rat_16849": 0.7179920077323914, "math_test_algebra_1043": 0.7181535363197327, "gsm_rft_7079": 0.718753457069397, "gsm_rft_5070": 0.7189882397651672, "gsm_rft_17816": 0.7191812992095947, "aqua_rat_14738": 0.7191874980926514, "aqua_rat_46623": 0.7193184494972229, "aqua_rat_37709": 0.7197954654693604, "aqua_rat_59298": 0.7202287912368774, "aqua_rat_40840": 0.7208088636398315, "gsm_rft_8605": 0.7208889722824097, "aqua_rat_16258": 0.7208905816078186, "gsm_rft_23795": 0.7209184169769287, "aqua_rat_87884": 0.7209509611129761, "aqua_rat_73772": 0.721206545829773, "gsm_rft_35059": 0.7212685346603394, "aqua_rat_73532": 0.7213025093078613, "aqua_rat_77492": 0.7213854789733887, "aqua_rat_76011": 0.7213918566703796, "aqua_rat_27035": 0.7215034365653992, "gsm_rft_24497": 0.7217427492141724, "gsm_rft_11850": 0.7219695448875427, "gsm_rft_28000": 0.7220932841300964, "gsm_train_22659": 0.7221865057945251, "aqua_rat_18140": 0.7224152088165283, "gsm_rft_20347": 0.7232919931411743, "gsm_train_374": 0.7232919931411743, "aqua_rat_17685": 0.7233440279960632, "gsm_train_18514": 0.7233684062957764, "aqua_rat_64527": 0.7235159873962402, "aqua_rat_42852": 0.7238771319389343, "gsm_rft_26543": 0.7239940166473389, "aqua_rat_63119": 0.7241670489311218, "aqua_rat_67497": 0.7242723703384399, "aqua_rat_26820": 0.7243996262550354, "aqua_rat_89004": 0.7247986793518066, "aqua_rat_55181": 0.7251229882240295, "gsm_rft_15258": 0.7251548767089844, "aqua_rat_19454": 0.7251843214035034, "gsm_train_25772": 0.7253409028053284, "aqua_rat_46293": 0.7253454327583313, "gsm_rft_31049": 0.7254080772399902, "aqua_rat_12799": 0.7255643010139465, "camel_37746": 0.7258651852607727, "aqua_rat_87442": 0.7266106009483337, "gsm_rft_31412": 0.7266858816146851, "aqua_rat_758": 0.7271386384963989, "aqua_rat_37337": 0.7272071838378906, "aqua_rat_76890": 0.7273727655410767, "aqua_rat_6973": 0.7278299331665039, "aqua_rat_61026": 0.7279186844825745, "aqua_rat_74699": 0.728599488735199, "aqua_rat_55929": 0.7288516759872437, "aqua_rat_88687": 0.7289037704467773, "aqua_rat_77486": 0.7294819951057434, "math_train_prealgebra_1338": 0.7295905351638794, "aqua_rat_945": 0.7300690412521362, "aqua_rat_27489": 0.7301480174064636, "aqua_rat_46713": 0.7306010723114014, "aqua_rat_67487": 0.7316668629646301, "aqua_rat_36204": 0.731850802898407, "aqua_rat_46842": 0.7341415882110596, "aqua_rat_88770": 0.7346492409706116, "aqua_rat_87163": 0.735569179058075, "aqua_rat_79547": 0.7365261316299438, "aqua_rat_64914": 0.7374303936958313, "aqua_rat_14152": 0.7387850880622864, "aqua_rat_8292": 0.7419884204864502, "aqua_rat_76879": 0.7420980930328369, "aqua_rat_85762": 0.7421911954879761, "aqua_rat_12664": 0.7429781556129456, "aqua_rat_1364": 0.7437172532081604, "aqua_rat_52197": 0.7445675730705261, "aqua_rat_24626": 0.7460207343101501, "aqua_rat_57386": 0.7469930648803711, "aqua_rat_52474": 0.7476259469985962, "aqua_rat_86309": 0.7498885989189148, "aqua_rat_80962": 0.7547896504402161, "aqua_rat_33283": 0.7579045295715332, "aqua_rat_81348": 0.7655099034309387, "TheoremQA_xueguangma/dividend_discount_model_1.json": 0.7788589000701904, "TheoremQA_xueguangma/dividend_discount_model_2.json": 0.8128107786178589, "TheoremQA_xueguangma/dividend_discount_model_4.json": 0.8799125552177429}, "TheoremQA_maxku/ipnetwork5-mac.json": {"TheoremQA_maxku/ipnetwork5-mac.json": 0, "aqua_rat_80959": 0.6818947792053223, "aqua_rat_30853": 0.6819671392440796, "aqua_rat_22847": 0.6820169687271118, "gsm_train_31074": 0.682077944278717, "gsm_rft_12264": 0.6820895671844482, "gsm_rft_26444": 0.6823417544364929, "aqua_rat_63857": 0.6823825240135193, "aqua_rat_3469": 0.6824530363082886, "gsm_rft_26882": 0.6825100779533386, "gsm_train_24835": 0.6825124025344849, "aqua_rat_28998": 0.682568371295929, "gsm_rft_29846": 0.6826250553131104, "gsm_train_28936": 0.6827287077903748, "aqua_rat_70646": 0.6828001141548157, "gsm_rft_14075": 0.6828148365020752, "gsm_rft_22760": 0.6829774975776672, "aqua_rat_28523": 0.6830930709838867, "gsm_rft_34524": 0.6831128597259521, "gsm_rft_12876": 0.683135449886322, "gsm_train_13336": 0.6831637620925903, "gsm_train_1148": 0.6832449436187744, "gsm_rft_33903": 0.6833990812301636, "camel_24382": 0.6834055781364441, "gsm_rft_11046": 0.683456540107727, "gsm_rft_8122": 0.683456540107727, "aqua_rat_8641": 0.683632493019104, "aqua_rat_29047": 0.6836544871330261, "gsm_rft_30095": 0.6836709976196289, "gsm_rft_32650": 0.6838577389717102, "camel_21876": 0.6838611960411072, "gsm_rft_34218": 0.6839129328727722, "gsm_rft_2939": 0.6839131116867065, "aqua_rat_2785": 0.6839410662651062, "gsm_train_15442": 0.6841217279434204, "aqua_rat_68610": 0.6841232180595398, "camel_21570": 0.6841511726379395, "gsm_rft_22831": 0.6841740608215332, "aqua_rat_36417": 0.6841887831687927, "gsm_rft_29106": 0.6842614412307739, "gsm_rft_7873": 0.6842614412307739, "gsm_train_27792": 0.6842614412307739, "gsm_rft_16849": 0.6842642426490784, "camel_39614": 0.6842732429504395, "gsm_rft_12367": 0.6844078898429871, "gsm_rft_34991": 0.6845176815986633, "aqua_rat_19942": 0.6845875978469849, "gsm_rft_15903": 0.6846047043800354, "gsm_rft_3162": 0.6851271986961365, "aqua_rat_82570": 0.6853598952293396, "gsm_rft_12292": 0.6855500936508179, "gsm_train_8629": 0.6855500936508179, "aqua_rat_8926": 0.6856657266616821, "gsm_rft_31265": 0.6856895685195923, "aqua_rat_2322": 0.6857286095619202, "aqua_rat_46532": 0.6857666373252869, "gsm_rft_21362": 0.685967743396759, "aqua_rat_1264": 0.6861322522163391, "gsm_rft_28181": 0.6862155795097351, "gsm_rft_25357": 0.6862654685974121, "aqua_rat_38672": 0.6863915920257568, "gsm_rft_1637": 0.686432957649231, "gsm_rft_25261": 0.6864386796951294, "gsm_rft_24117": 0.6865336894989014, "camel_11288": 0.6865973472595215, "camel_36307": 0.6868051886558533, "gsm_rft_11998": 0.6869134306907654, "gsm_train_9087": 0.6869134306907654, "gsm_rft_25250": 0.687232255935669, "gsm_rft_33208": 0.6873279809951782, "aqua_rat_38416": 0.6873355507850647, "camel_22486": 0.6874405741691589, "gsm_rft_12023": 0.6874586343765259, "gsm_train_17890": 0.6874710321426392, "gsm_rft_14796": 0.6874710321426392, "gsm_rft_16634": 0.6874710321426392, "gsm_rft_7432": 0.68771892786026, "gsm_train_7489": 0.68771892786026, "gsm_rft_6981": 0.6879589557647705, "gsm_rft_11215": 0.6880953907966614, "gsm_rft_11813": 0.6881163716316223, "aqua_rat_9358": 0.688234806060791, "aqua_rat_66093": 0.6883484721183777, "math_test_prealgebra_2073": 0.6883710622787476, "camel_39644": 0.6884476542472839, "aqua_rat_33141": 0.6885038614273071, "gsm_rft_20885": 0.6885996460914612, "gsm_train_29291": 0.6885996460914612, "aqua_rat_19344": 0.6887527704238892, "gsm_rft_9162": 0.6887814998626709, "gsm_rft_4189": 0.6887820959091187, "aqua_rat_52745": 0.6888247132301331, "gsm_rft_7449": 0.6891725659370422, "aqua_rat_53526": 0.6892795562744141, "gsm_rft_24412": 0.6901581883430481, "gsm_rft_18202": 0.6902149319648743, "aqua_rat_12162": 0.6903174519538879, "gsm_rft_5063": 0.6903881430625916, "aqua_rat_27243": 0.6904646158218384, "aqua_rat_72089": 0.6905158162117004, "aqua_rat_50137": 0.6907638311386108, "gsm_rft_23742": 0.6907767057418823, "gsm_rft_30989": 0.69082111120224, "gsm_train_20496": 0.69082111120224, "gsm_rft_12027": 0.6911234855651855, "camel_39659": 0.6917411088943481, "gsm_rft_22092": 0.6923251152038574, "gsm_rft_35526": 0.6924918293952942, "gsm_train_27526": 0.6924918293952942, "gsm_rft_23587": 0.6924918293952942, "gsm_rft_12328": 0.6925672888755798, "gsm_train_9826": 0.6926514506340027, "gsm_rft_14862": 0.6926514506340027, "camel_21911": 0.6927989721298218, "gsm_rft_27803": 0.6928561925888062, "gsm_rft_13595": 0.6930646300315857, "gsm_rft_33571": 0.6932470798492432, "gsm_rft_10321": 0.6934438943862915, "aqua_rat_34688": 0.6936957240104675, "gsm_rft_20159": 0.6938579082489014, "gsm_rft_2717": 0.6940092444419861, "gsm_rft_25150": 0.6940560340881348, "gsm_train_6878": 0.6940560340881348, "gsm_rft_1963": 0.6945691704750061, "gsm_rft_16326": 0.6949065327644348, "gsm_rft_2801": 0.6953495740890503, "gsm_rft_14788": 0.6954332590103149, "math_train_number_theory_7070": 0.6954810619354248, "aqua_rat_54520": 0.6956531405448914, "camel_26540": 0.6964297890663147, "gsm_rft_12105": 0.6969220042228699, "gsm_rft_17389": 0.6972060799598694, "gsm_rft_4746": 0.6972644925117493, "gsm_rft_25272": 0.697356641292572, "camel_24344": 0.6974546909332275, "gsm_rft_21828": 0.6975193619728088, "gsm_rft_2474": 0.6981357336044312, "aqua_rat_22859": 0.6982095241546631, "gsm_rft_17687": 0.6982741355895996, "gsm_train_15184": 0.6982741355895996, "gsm_rft_33753": 0.6986516118049622, "math_test_counting_and_probability_747": 0.6987704038619995, "gsm_rft_28756": 0.6989545226097107, "gsm_rft_13859": 0.6990063190460205, "gsm_rft_20353": 0.6991065144538879, "aqua_rat_60661": 0.6993277072906494, "gsm_rft_26670": 0.6993736624717712, "aqua_rat_60020": 0.6998185515403748, "gsm_rft_32533": 0.6999078989028931, "gsm_rft_2606": 0.6999850869178772, "gsm_rft_23218": 0.7000598907470703, "camel_21835": 0.7003485560417175, "gsm_rft_6098": 0.7005921006202698, "gsm_rft_25368": 0.701335608959198, "gsm_rft_23745": 0.7015174031257629, "gsm_train_33933": 0.7016991972923279, "gsm_rft_25236": 0.7016991972923279, "gsm_rft_20390": 0.7016991972923279, "gsm_train_15441": 0.7017043828964233, "gsm_rft_9514": 0.7017043828964233, "gsm_rft_4866": 0.7018135190010071, "gsm_rft_12713": 0.7021356225013733, "aqua_rat_53438": 0.7023321986198425, "gsm_train_31599": 0.7027198076248169, "gsm_rft_7226": 0.7029141783714294, "gsm_rft_1807": 0.7031043171882629, "gsm_train_19829": 0.7041517496109009, "gsm_rft_3729": 0.7043002247810364, "gsm_rft_14307": 0.705349862575531, "gsm_rft_11073": 0.7059425711631775, "gsm_train_4199": 0.7067355513572693, "gsm_rft_229": 0.7067355513572693, "gsm_rft_9272": 0.7067355513572693, "gsm_rft_6860": 0.7067822813987732, "gsm_rft_11985": 0.7119866013526917, "gsm_rft_33863": 0.7120766639709473, "gsm_rft_21298": 0.712155282497406, "gsm_train_20944": 0.712155282497406, "aqua_rat_73185": 0.712239146232605, "camel_45159": 0.712352454662323, "gsm_rft_11471": 0.7123619914054871, "gsm_rft_16361": 0.7129168510437012, "aqua_rat_52087": 0.7129503488540649, "camel_21053": 0.7131497859954834, "aqua_rat_78286": 0.7136964797973633, "aqua_rat_53867": 0.7139855623245239, "aqua_rat_10496": 0.7142678499221802, "gsm_rft_19302": 0.7147465944290161, "aqua_rat_60195": 0.7148143649101257, "camel_39395": 0.7158132791519165, "aqua_rat_9712": 0.7164408564567566, "camel_45778": 0.7172790765762329, "aqua_rat_87402": 0.7186561226844788, "aqua_rat_85903": 0.7264676690101624, "aqua_rat_36286": 0.7274327874183655, "aqua_rat_27910": 0.7274448871612549, "TheoremQA_maxku/ipnetwork10-datatransmission.json": 0.7359836101531982, "camel_45819": 0.7386376261711121, "aqua_rat_81119": 0.7397132515907288, "TheoremQA_maxku/ipnetwork7-lan.json": 0.7849265933036804}, "TheoremQA_wenhuchen/optics8.json": {"TheoremQA_wenhuchen/optics8.json": 0, "gsm_rft_12659": 0.6774487495422363, "gsm_rft_10474": 0.677462100982666, "gsm_rft_2430": 0.6774712204933167, "gsm_train_24294": 0.6775751113891602, "aqua_rat_35477": 0.6775921583175659, "gsm_rft_35145": 0.6776276230812073, "aqua_rat_11549": 0.6776357889175415, "camel_5007": 0.6778648495674133, "aqua_rat_26529": 0.6779136657714844, "camel_4988": 0.6779924035072327, "gsm_rft_10897": 0.6780102849006653, "gsm_rft_6277": 0.6780511140823364, "gsm_rft_22580": 0.6780751347541809, "aqua_rat_73760": 0.6780797243118286, "aqua_rat_21504": 0.678104817867279, "camel_37936": 0.6781349778175354, "aqua_rat_29101": 0.6781416535377502, "gsm_rft_9980": 0.678167998790741, "gsm_rft_17396": 0.6782256364822388, "camel_39440": 0.6782275438308716, "gsm_rft_35073": 0.6782976388931274, "gsm_rft_6830": 0.6783088445663452, "gsm_rft_27862": 0.678370475769043, "gsm_train_29765": 0.678370475769043, "gsm_rft_10781": 0.678478479385376, "aqua_rat_14555": 0.6785474419593811, "aqua_rat_6709": 0.6786150932312012, "aqua_rat_62339": 0.6787250638008118, "gsm_rft_25934": 0.6788081526756287, "gsm_rft_57": 0.6791563034057617, "aqua_rat_41482": 0.6793311238288879, "aqua_rat_67295": 0.6793624758720398, "aqua_rat_85422": 0.6795875430107117, "gsm_rft_15860": 0.6796954274177551, "gsm_rft_28669": 0.6796954274177551, "gsm_train_11193": 0.6796954274177551, "aqua_rat_25668": 0.6797586679458618, "gsm_rft_14868": 0.6797939538955688, "aqua_rat_85313": 0.679802656173706, "aqua_rat_25765": 0.6798373460769653, "gsm_rft_32387": 0.6798717975616455, "gsm_rft_22440": 0.6799654960632324, "gsm_train_14042": 0.680071234703064, "gsm_rft_2688": 0.680071234703064, "camel_45159": 0.6801649332046509, "camel_37879": 0.6801865100860596, "gsm_rft_22448": 0.6804317235946655, "gsm_rft_19149": 0.680452287197113, "aqua_rat_54096": 0.6804615259170532, "gsm_rft_18251": 0.6805124878883362, "aqua_rat_86447": 0.6805746555328369, "aqua_rat_12658": 0.6805790066719055, "gsm_rft_18492": 0.6806696653366089, "gsm_train_34318": 0.6806732416152954, "gsm_rft_21333": 0.6807807683944702, "aqua_rat_49292": 0.6808544993400574, "camel_4820": 0.6809958815574646, "camel_24344": 0.6810487508773804, "gsm_rft_14765": 0.6810892820358276, "camel_4980": 0.6811292767524719, "gsm_rft_2338": 0.6811630129814148, "gsm_rft_3186": 0.6812127828598022, "aqua_rat_6162": 0.6812204122543335, "aqua_rat_82879": 0.6812885403633118, "gsm_rft_24796": 0.6813732385635376, "gsm_rft_9498": 0.6813880801200867, "gsm_rft_7714": 0.6814326643943787, "aqua_rat_37409": 0.6815481185913086, "aqua_rat_31980": 0.681553065776825, "aqua_rat_74654": 0.6816638112068176, "aqua_rat_22741": 0.681709349155426, "aqua_rat_9906": 0.6819309592247009, "aqua_rat_68512": 0.6819698810577393, "aqua_rat_86056": 0.6820411682128906, "camel_4767": 0.6820685267448425, "aqua_rat_56182": 0.6821344494819641, "aqua_rat_10794": 0.6822483539581299, "gsm_rft_14244": 0.6824109554290771, "gsm_train_34815": 0.6824109554290771, "gsm_train_5301": 0.6824123859405518, "gsm_train_29099": 0.6824541687965393, "gsm_rft_17764": 0.6824541687965393, "gsm_rft_11101": 0.6826849579811096, "gsm_rft_2601": 0.6826849579811096, "aqua_rat_88321": 0.6826929450035095, "aqua_rat_5108": 0.6827322840690613, "gsm_rft_28133": 0.6828829646110535, "aqua_rat_16469": 0.6829231381416321, "gsm_rft_8772": 0.6831720471382141, "aqua_rat_56584": 0.6833378672599792, "gsm_rft_15666": 0.6833966374397278, "gsm_train_228": 0.6834793090820312, "gsm_rft_7166": 0.6834793090820312, "aqua_rat_16975": 0.6837170720100403, "aqua_rat_48959": 0.6837193965911865, "aqua_rat_8162": 0.6837248802185059, "gsm_rft_29698": 0.6838306784629822, "gsm_train_13418": 0.6838306784629822, "gsm_rft_8463": 0.684092104434967, "gsm_rft_35481": 0.6844038963317871, "gsm_rft_21678": 0.6845517754554749, "aqua_rat_33103": 0.6849644780158997, "gsm_rft_366": 0.6850572824478149, "aqua_rat_36411": 0.6851780414581299, "aqua_rat_33439": 0.6852717995643616, "aqua_rat_61971": 0.6854581832885742, "aqua_rat_42126": 0.6855025887489319, "aqua_rat_9793": 0.6855642199516296, "aqua_rat_14896": 0.685585081577301, "aqua_rat_24901": 0.6855937838554382, "aqua_rat_13443": 0.685700535774231, "aqua_rat_23008": 0.6857338547706604, "gsm_train_31158": 0.6857684254646301, "gsm_rft_1939": 0.6857684254646301, "gsm_train_13214": 0.6857837438583374, "gsm_train_6956": 0.6858096122741699, "gsm_rft_15918": 0.6858096122741699, "gsm_rft_13200": 0.6858096122741699, "gsm_train_32410": 0.6859020590782166, "gsm_rft_12596": 0.6859274506568909, "aqua_rat_12925": 0.6861628890037537, "aqua_rat_12257": 0.6861652731895447, "aqua_rat_81631": 0.6863502860069275, "camel_39513": 0.6863613128662109, "camel_4979": 0.6864408254623413, "gsm_rft_33471": 0.6865040063858032, "camel_45970": 0.6865057945251465, "gsm_rft_2985": 0.6871064305305481, "aqua_rat_3331": 0.6871442794799805, "aqua_rat_47596": 0.6871620416641235, "TheoremQA_tonyxia/semiconductor5.json": 0.6871623992919922, "aqua_rat_46971": 0.6871737241744995, "aqua_rat_60297": 0.6872603893280029, "gsm_rft_8656": 0.6873828768730164, "aqua_rat_83787": 0.6874300837516785, "gsm_rft_11828": 0.6875605583190918, "gsm_rft_8806": 0.6875605583190918, "gsm_train_14053": 0.6875605583190918, "aqua_rat_12499": 0.6876673102378845, "camel_36254": 0.687694787979126, "aqua_rat_6188": 0.6877491474151611, "gsm_rft_7428": 0.687771737575531, "gsm_train_21544": 0.6882348656654358, "gsm_rft_23018": 0.688275158405304, "aqua_rat_77586": 0.6885985136032104, "gsm_rft_7812": 0.688692569732666, "gsm_rft_6897": 0.6890679597854614, "gsm_rft_34630": 0.6891140341758728, "aqua_rat_20614": 0.6891437768936157, "aqua_rat_60511": 0.689144492149353, "gsm_rft_24978": 0.6891472935676575, "gsm_train_18003": 0.6893332004547119, "gsm_rft_24790": 0.6893332004547119, "gsm_rft_25136": 0.6893332004547119, "gsm_rft_2271": 0.6895544528961182, "gsm_rft_5305": 0.6899629235267639, "gsm_train_22045": 0.6899629235267639, "aqua_rat_60081": 0.6903675198554993, "aqua_rat_72645": 0.6904073357582092, "aqua_rat_28523": 0.6904692649841309, "aqua_rat_3859": 0.6905748248100281, "gsm_train_1691": 0.6918358206748962, "gsm_rft_18466": 0.6918358206748962, "gsm_rft_25293": 0.691931962966919, "gsm_rft_15250": 0.6920400857925415, "camel_4983": 0.6922212243080139, "aqua_rat_25154": 0.6930761933326721, "aqua_rat_63167": 0.6935163736343384, "gsm_rft_7089": 0.6938312649726868, "aqua_rat_20932": 0.6940227150917053, "gsm_rft_19748": 0.6944840550422668, "aqua_rat_67486": 0.6952003240585327, "aqua_rat_23035": 0.6957410573959351, "aqua_rat_8610": 0.6958590745925903, "gsm_rft_15228": 0.6966044902801514, "aqua_rat_61332": 0.6969196796417236, "aqua_rat_71816": 0.697288453578949, "gsm_rft_35201": 0.6975902915000916, "gsm_rft_12209": 0.6981857419013977, "aqua_rat_3234": 0.6982762813568115, "aqua_rat_43435": 0.6996117830276489, "aqua_rat_66162": 0.70013827085495, "aqua_rat_23105": 0.7014991641044617, "aqua_rat_44457": 0.7016226649284363, "aqua_rat_12010": 0.7017714381217957, "gsm_train_21024": 0.7032977342605591, "gsm_rft_3538": 0.7037929892539978, "gsm_rft_2034": 0.7037929892539978, "gsm_rft_11389": 0.7047604322433472, "gsm_rft_11031": 0.7078152298927307, "gsm_rft_2452": 0.7088370323181152, "gsm_train_17819": 0.7108170986175537, "gsm_rft_17551": 0.7108170986175537, "gsm_rft_9344": 0.7108170986175537, "aqua_rat_75111": 0.7121710181236267, "aqua_rat_81926": 0.7133597731590271, "camel_5287": 0.7183195352554321, "camel_17811": 0.7195920348167419, "TheoremQA_wenhuchen/optics5.json": 0.7760336399078369}, "TheoremQA_wenhuchen/t_test1.json": {"camel_8714": 0, "camel_8811": 0, "camel_9938": 0, "camel_8854": 0, "camel_9960": 0, "camel_8827": 0, "camel_8889": 0, "camel_8077": 0, "camel_8846": 0, "camel_8689": 0, "camel_9523": 0, "camel_8016": 0, "camel_8948": 0, "camel_9672": 0, "camel_9932": 0, "camel_8830": 0, "camel_9930": 0, "camel_8140": 0, "camel_8067": 0, "camel_8054": 0, "camel_8018": 0, "camel_8048": 0, "camel_8871": 0, "camel_8042": 0, "camel_9735": 0, "camel_8127": 0, "camel_9941": 0, "camel_9998": 0, "camel_8076": 0, "camel_8812": 0, "camel_9936": 0, "camel_8883": 0, "camel_9939": 0, "camel_8056": 0, "camel_8084": 0, "camel_9952": 0, "camel_8003": 0, "camel_8825": 0, "camel_8025": 0, "camel_8015": 0, "camel_8852": 0, "camel_8024": 0, "camel_8838": 0, "camel_8069": 0, "camel_8061": 0, "camel_8053": 0, "camel_8021": 0, "camel_8885": 0, "camel_8047": 0, "camel_8856": 0, "camel_9925": 0, "camel_9988": 0, "camel_8035": 0, "camel_9982": 0, "camel_8836": 0, "camel_8863": 0, "camel_9991": 0, "camel_8826": 0, "camel_8804": 0, "camel_8802": 0, "camel_9929": 0, "camel_9656": 0, "camel_8011": 0, "camel_9242": 0, "camel_9610": 0, "camel_8843": 0, "camel_9980": 0, "camel_8023": 0, "camel_8953": 0, "camel_8028": 0, "camel_8046": 0, "camel_8878": 0, "camel_8676": 0, "camel_8950": 0, "camel_8855": 0, "camel_8814": 0, "camel_8108": 0, "camel_8012": 0, "camel_9920": 0, "camel_8715": 0, "camel_9951": 0, "camel_8857": 0, "camel_8817": 0, "camel_8807": 0, "camel_8027": 0, "camel_8065": 0, "camel_8009": 0, "camel_9954": 0, "camel_9971": 0, "camel_8653": 0, "camel_8041": 0, "camel_8040": 0, "camel_9931": 0, "camel_9945": 0, "camel_8835": 0, "camel_9900": 0, "camel_8079": 0, "camel_8049": 0, "camel_8019": 0, "camel_8038": 0, "camel_8074": 0, "camel_8078": 0, "camel_8810": 0, "camel_8819": 0, "camel_8013": 0, "camel_8832": 0, "camel_8043": 0, "camel_8050": 0, "camel_9983": 0, "TheoremQA_wenhuchen/t_test1.json": 0, "camel_8051": 0, "camel_8823": 0, "camel_8853": 0, "camel_8072": 0, "camel_9972": 0, "camel_8063": 0, "camel_8057": 0, "camel_8030": 0, "camel_8005": 0, "camel_8058": 0, "camel_9969": 0, "camel_8020": 0, "camel_8002": 0, "camel_8034": 0, "camel_8876": 0, "camel_8010": 0, "camel_8060": 0, "camel_8044": 0, "camel_8026": 0, "camel_8039": 0, "camel_9967": 0, "camel_8926": 0, "camel_9950": 0, "camel_8029": 0, "camel_8864": 0, "camel_8073": 0, "camel_9926": 0, "camel_9958": 0, "camel_8052": 0, "camel_8847": 0, "camel_8017": 0, "camel_8037": 0, "camel_8000": 0, "camel_8014": 0, "camel_8866": 0, "camel_8033": 0, "camel_8001": 0, "camel_8068": 0, "camel_8006": 0, "camel_9671": 0, "camel_8066": 0, "camel_9979": 0, "camel_8055": 0, "camel_8031": 0, "camel_8032": 0, "camel_9994": 0, "camel_9944": 0, "camel_8842": 0, "camel_9709": 0, "camel_8008": 0, "camel_8075": 0, "camel_8833": 0, "camel_8850": 0, "camel_8036": 0, "camel_8064": 0, "camel_9963": 0, "camel_9977": 0, "camel_8070": 0, "camel_8803": 0, "camel_8071": 0, "camel_8059": 0, "camel_8849": 0, "camel_8022": 0, "camel_9978": 0, "camel_9962": 0, "camel_9996": 0, "camel_8004": 0, "aqua_rat_55086": 0.8272117376327515, "aqua_rat_25885": 0.8281112313270569, "aqua_rat_39921": 0.8283563852310181, "aqua_rat_67183": 0.8284422159194946, "aqua_rat_27492": 0.8285210132598877, "aqua_rat_56608": 0.8296589255332947, "aqua_rat_32425": 0.8298132419586182, "aqua_rat_21683": 0.8311862945556641, "aqua_rat_74055": 0.8313225507736206, "aqua_rat_638": 0.8314704895019531, "aqua_rat_61448": 0.8317447304725647, "aqua_rat_36561": 0.8327889442443848, "aqua_rat_17477": 0.8338897228240967, "aqua_rat_40988": 0.8342385292053223, "aqua_rat_29275": 0.8343781232833862, "aqua_rat_74756": 0.8352973461151123, "aqua_rat_67642": 0.84449702501297, "aqua_rat_79949": 0.8454569578170776, "aqua_rat_55278": 0.8465962409973145, "aqua_rat_43505": 0.8477681279182434, "aqua_rat_59951": 0.8489725589752197, "TheoremQA_wenhuchen/t_test2.json": 0.852423369884491, "TheoremQA_wenhuchen/t_test3.json": 0.8741246461868286}, "TheoremQA_maxku/signalprocessing6-Ztransform.json": {"TheoremQA_maxku/signalprocessing6-Ztransform.json": 0, "camel_25579": 0.6478638052940369, "camel_29110": 0.6479240655899048, "camel_30427": 0.6479613780975342, "camel_29388": 0.6480780243873596, "camel_28723": 0.6481916904449463, "camel_28819": 0.6483516693115234, "camel_29878": 0.64836585521698, "camel_29034": 0.6483685374259949, "camel_28999": 0.6484065651893616, "camel_29177": 0.6484581232070923, "camel_29681": 0.6485199928283691, "camel_28119": 0.6485673189163208, "camel_29692": 0.6486066579818726, "camel_28344": 0.6487974524497986, "camel_28772": 0.6488376259803772, "camel_25537": 0.64892578125, "camel_28883": 0.6490562558174133, "gsm_rft_11471": 0.6492004990577698, "camel_28227": 0.6493013501167297, "camel_29205": 0.6494394540786743, "TheoremQA_maxku/signalprocessing14-Ztransform.json": 0.6494734287261963, "camel_29783": 0.6496239900588989, "camel_28163": 0.6497589349746704, "camel_25522": 0.6497689485549927, "camel_29787": 0.649998128414154, "camel_25530": 0.6500280499458313, "camel_30406": 0.6500780582427979, "camel_31098": 0.6500884294509888, "camel_29867": 0.650124728679657, "camel_29716": 0.6501375436782837, "camel_28661": 0.6502332091331482, "camel_28130": 0.6504274606704712, "camel_29026": 0.6505564451217651, "camel_25528": 0.6509476900100708, "camel_29790": 0.6509798765182495, "camel_30918": 0.6510408520698547, "camel_28760": 0.651065468788147, "camel_28206": 0.6510751843452454, "camel_30895": 0.6511157155036926, "camel_28112": 0.6512016654014587, "camel_29780": 0.6513176560401917, "camel_29387": 0.6513288021087646, "camel_28329": 0.6514129638671875, "camel_28453": 0.6514485478401184, "camel_29302": 0.6515167355537415, "camel_29818": 0.6516100168228149, "camel_28101": 0.6516902446746826, "camel_29178": 0.6517706513404846, "camel_30470": 0.6518357396125793, "camel_37459": 0.6518747806549072, "camel_28154": 0.6518985629081726, "camel_28379": 0.6519002318382263, "camel_29407": 0.6519390940666199, "gsm_train_23183": 0.6519933938980103, "camel_29257": 0.6520293354988098, "camel_25597": 0.6520671248435974, "aqua_rat_6364": 0.6522232890129089, "camel_29705": 0.6522718071937561, "camel_29220": 0.6522844433784485, "camel_28520": 0.6525152325630188, "camel_30935": 0.6525347232818604, "camel_28468": 0.6527548432350159, "camel_28776": 0.6528105735778809, "camel_29746": 0.652838408946991, "camel_29680": 0.652948260307312, "camel_37933": 0.6530043482780457, "camel_29682": 0.6531057953834534, "camel_28100": 0.6532483100891113, "camel_30401": 0.6534461975097656, "camel_28439": 0.6534869074821472, "aqua_rat_85856": 0.6535630226135254, "camel_29235": 0.6536346077919006, "camel_28392": 0.6536714434623718, "camel_29515": 0.6537213921546936, "gsm_rft_28746": 0.6537489891052246, "camel_28120": 0.653900146484375, "camel_31045": 0.6539982557296753, "aqua_rat_65902": 0.6540178656578064, "camel_29329": 0.6541405916213989, "camel_31061": 0.6542887687683105, "camel_29228": 0.6542990207672119, "camel_28642": 0.654403567314148, "camel_30407": 0.6544249653816223, "camel_29700": 0.6545079350471497, "camel_30923": 0.6547808647155762, "camel_25555": 0.6548163294792175, "camel_28404": 0.6551249623298645, "camel_29251": 0.6551300883293152, "camel_31633": 0.6553415656089783, "camel_28134": 0.6555862426757812, "camel_30440": 0.6559053063392639, "camel_25542": 0.655963122844696, "camel_31047": 0.6560827493667603, "camel_28802": 0.6560962200164795, "camel_29117": 0.6561007499694824, "camel_30357": 0.6561222672462463, "camel_29184": 0.6561383008956909, "camel_28121": 0.6564150452613831, "camel_28385": 0.6565812826156616, "camel_28759": 0.6567883491516113, "camel_29947": 0.6569557785987854, "camel_29216": 0.6569627523422241, "camel_29721": 0.6570461392402649, "camel_39510": 0.6570719480514526, "camel_28433": 0.6572514772415161, "aqua_rat_68972": 0.65741366147995, "aqua_rat_10334": 0.6574733853340149, "camel_30950": 0.6576898694038391, "camel_28740": 0.657690167427063, "camel_28384": 0.6579248309135437, "camel_29277": 0.6579393148422241, "camel_29278": 0.658006489276886, "camel_28835": 0.6580124497413635, "camel_29082": 0.658215343952179, "camel_29322": 0.6583746075630188, "camel_28789": 0.6583857536315918, "camel_25578": 0.6585531830787659, "camel_29730": 0.6587241291999817, "camel_30372": 0.6591992974281311, "camel_29227": 0.659473717212677, "camel_29691": 0.6594966053962708, "camel_30959": 0.6595696210861206, "camel_28435": 0.6598204374313354, "camel_28502": 0.6598207950592041, "camel_28731": 0.6598389744758606, "camel_29373": 0.6599259376525879, "camel_28123": 0.660049557685852, "camel_29755": 0.6601664423942566, "camel_29698": 0.660249650478363, "camel_25589": 0.6605808734893799, "camel_28791": 0.6608782410621643, "camel_28156": 0.6609854102134705, "camel_29888": 0.6610810160636902, "camel_28715": 0.6613888144493103, "camel_29080": 0.6615113019943237, "camel_29697": 0.6615210771560669, "camel_29328": 0.6616840362548828, "camel_29688": 0.6617042422294617, "camel_30927": 0.661841094493866, "camel_30423": 0.6618733406066895, "camel_29122": 0.6618903875350952, "camel_29148": 0.6620151996612549, "camel_29695": 0.6622804403305054, "camel_28148": 0.6624778509140015, "camel_28462": 0.6629966497421265, "camel_30894": 0.6630229353904724, "camel_29271": 0.6632975935935974, "camel_28395": 0.6633092761039734, "camel_28116": 0.6634088754653931, "camel_29745": 0.6643539071083069, "camel_30685": 0.6644600033760071, "camel_29255": 0.6644699573516846, "camel_29301": 0.6646938920021057, "camel_28797": 0.6647005677223206, "camel_29756": 0.6648656129837036, "camel_29321": 0.6649856567382812, "camel_30925": 0.664989173412323, "camel_28084": 0.66522616147995, "camel_29741": 0.6652845144271851, "camel_28787": 0.6653546690940857, "camel_28733": 0.6656346917152405, "camel_29722": 0.6669323444366455, "camel_28793": 0.6671143174171448, "camel_29684": 0.6671277284622192, "camel_29711": 0.6673049926757812, "camel_28430": 0.6674586534500122, "camel_28081": 0.6676092147827148, "camel_29739": 0.6676182746887207, "camel_29102": 0.6678028106689453, "camel_29060": 0.6686919927597046, "camel_29042": 0.6687570810317993, "camel_29065": 0.6692338585853577, "camel_37507": 0.6695120930671692, "camel_29749": 0.669611930847168, "camel_29693": 0.6701933741569519, "camel_29279": 0.6702766418457031, "camel_29346": 0.6704293489456177, "camel_29364": 0.6708292961120605, "camel_28407": 0.672673761844635, "camel_28361": 0.6733549237251282, "camel_17545": 0.6742332577705383, "camel_28754": 0.6745961904525757, "camel_29097": 0.675068736076355, "camel_29708": 0.6765998005867004, "camel_28099": 0.6766396760940552, "camel_28149": 0.6777939796447754, "camel_29240": 0.6784243583679199, "camel_30474": 0.6784850358963013, "TheoremQA_maxku/signalprocessing13-Ztransform.json": 0.6798025369644165, "camel_29429": 0.6801262497901917, "camel_29759": 0.6806994080543518, "camel_28821": 0.6827412247657776, "camel_29078": 0.682830810546875, "camel_29752": 0.6837430000305176, "camel_29727": 0.6867004632949829, "camel_29704": 0.6894826292991638, "camel_29734": 0.6988687515258789, "camel_29719": 0.7093868255615234, "TheoremQA_maxku/signalprocessing4-Ztransform.json": 0.7352093458175659}, "TheoremQA_tonyxia/semiconductor5.json": {"TheoremQA_tonyxia/semiconductor5.json": 0, "camel_28096": 0.6795796155929565, "gsm_rft_33303": 0.6795929670333862, "gsm_rft_20099": 0.6797758340835571, "gsm_rft_20677": 0.6798924207687378, "gsm_rft_8801": 0.6801707744598389, "gsm_train_19303": 0.6801779270172119, "aqua_rat_25154": 0.680319607257843, "gsm_rft_20224": 0.6805374026298523, "gsm_rft_29034": 0.680621862411499, "aqua_rat_39787": 0.6806275248527527, "gsm_rft_29693": 0.6807654500007629, "gsm_rft_30217": 0.6809302568435669, "gsm_train_7400": 0.6809302568435669, "aqua_rat_26183": 0.6810640692710876, "gsm_rft_5015": 0.6813134551048279, "gsm_train_20544": 0.681526780128479, "gsm_rft_16632": 0.681526780128479, "gsm_rft_18677": 0.6815928816795349, "gsm_rft_34783": 0.6816365718841553, "gsm_rft_16224": 0.6816394329071045, "gsm_rft_22401": 0.681810736656189, "gsm_rft_7352": 0.6818305253982544, "gsm_train_32872": 0.6818305253982544, "gsm_rft_22448": 0.6818539500236511, "gsm_rft_33189": 0.6818728446960449, "gsm_rft_31337": 0.6819487810134888, "gsm_train_10907": 0.6820613145828247, "gsm_rft_21182": 0.6820613145828247, "gsm_rft_21366": 0.6820613145828247, "gsm_rft_30775": 0.6821836829185486, "gsm_rft_8243": 0.6821836829185486, "gsm_train_8796": 0.6821836829185486, "gsm_train_4303": 0.6822947859764099, "gsm_train_35600": 0.6824369430541992, "gsm_rft_34389": 0.6824858784675598, "gsm_rft_5106": 0.6825637221336365, "gsm_rft_21454": 0.6826055645942688, "gsm_rft_29409": 0.6826055645942688, "camel_28081": 0.682703971862793, "gsm_rft_15333": 0.6827748417854309, "gsm_rft_28086": 0.6827903389930725, "gsm_rft_15366": 0.6829488277435303, "gsm_rft_14462": 0.6830001473426819, "gsm_rft_19423": 0.6830001473426819, "gsm_train_15924": 0.6830001473426819, "aqua_rat_47596": 0.683083713054657, "gsm_rft_5019": 0.6831455230712891, "gsm_rft_24257": 0.683165431022644, "gsm_rft_1925": 0.6832990646362305, "gsm_train_33171": 0.6834987998008728, "gsm_rft_17396": 0.6835837364196777, "gsm_rft_27782": 0.6836852431297302, "gsm_rft_1637": 0.6837545037269592, "gsm_rft_3843": 0.6837652921676636, "gsm_rft_18492": 0.6837788224220276, "gsm_train_11581": 0.683803379535675, "gsm_rft_28561": 0.683803379535675, "gsm_rft_7433": 0.683803379535675, "gsm_rft_33800": 0.6839108467102051, "gsm_rft_28078": 0.6841580867767334, "gsm_rft_34396": 0.6841723322868347, "gsm_train_2639": 0.6841723322868347, "gsm_train_4698": 0.6843039989471436, "gsm_rft_18587": 0.6844150424003601, "gsm_rft_29036": 0.6844150424003601, "gsm_train_16078": 0.6844150424003601, "gsm_rft_31420": 0.684700608253479, "gsm_rft_13692": 0.6847353577613831, "gsm_rft_18917": 0.6848154664039612, "gsm_rft_23718": 0.6848154664039612, "gsm_train_28914": 0.6848154664039612, "gsm_rft_17559": 0.6848680377006531, "gsm_train_31009": 0.6848680377006531, "gsm_rft_13803": 0.6852960586547852, "gsm_rft_8024": 0.6852960586547852, "gsm_rft_26574": 0.6853387951850891, "gsm_train_15311": 0.6854878067970276, "aqua_rat_29281": 0.6855944395065308, "aqua_rat_59734": 0.6856646537780762, "gsm_rft_13516": 0.6857278347015381, "aqua_rat_35057": 0.685738742351532, "gsm_rft_10521": 0.685751736164093, "gsm_rft_2099": 0.6858721971511841, "gsm_train_10381": 0.6864550113677979, "gsm_rft_24094": 0.6864550113677979, "gsm_rft_4113": 0.6865032315254211, "gsm_train_33930": 0.6865032315254211, "gsm_rft_11790": 0.6865809559822083, "gsm_rft_30177": 0.6866402626037598, "camel_3780": 0.6866627931594849, "gsm_rft_15464": 0.6867794990539551, "gsm_rft_25914": 0.6871089935302734, "gsm_rft_9556": 0.687185525894165, "gsm_rft_2514": 0.6872808337211609, "aqua_rat_20090": 0.6874651312828064, "aqua_rat_24388": 0.6876600384712219, "aqua_rat_9906": 0.687937319278717, "gsm_rft_26756": 0.6880747675895691, "gsm_rft_12596": 0.6880802512168884, "gsm_rft_13049": 0.6891435980796814, "gsm_rft_33282": 0.6891605257987976, "aqua_rat_71661": 0.6894985437393188, "gsm_train_14053": 0.6899113655090332, "gsm_rft_11828": 0.6899113655090332, "gsm_rft_8806": 0.6899113655090332, "gsm_rft_7428": 0.6904711723327637, "gsm_rft_20164": 0.6905384659767151, "gsm_rft_12882": 0.6912026405334473, "gsm_rft_23018": 0.6913544535636902, "aqua_rat_59427": 0.6914529204368591, "gsm_rft_2362": 0.6914919018745422, "gsm_train_33849": 0.6915112733840942, "gsm_rft_13820": 0.6916131973266602, "gsm_rft_18008": 0.6916390657424927, "gsm_rft_21897": 0.6917583346366882, "gsm_rft_13903": 0.6917815804481506, "gsm_rft_2329": 0.6918027997016907, "gsm_rft_7754": 0.6918456554412842, "gsm_rft_1154": 0.6918806433677673, "gsm_rft_33600": 0.6919706463813782, "aqua_rat_11875": 0.6920304298400879, "gsm_rft_26325": 0.6920580863952637, "gsm_rft_18209": 0.6927127838134766, "gsm_rft_27207": 0.6927769184112549, "gsm_rft_26539": 0.6932389140129089, "gsm_rft_26085": 0.6933214664459229, "aqua_rat_14555": 0.6933338046073914, "gsm_rft_18087": 0.6935453414916992, "gsm_train_16316": 0.6935453414916992, "gsm_rft_4120": 0.6935781240463257, "gsm_rft_2359": 0.6935821175575256, "gsm_rft_18391": 0.6939918994903564, "gsm_rft_8656": 0.6948131322860718, "gsm_rft_882": 0.6951964497566223, "gsm_rft_23458": 0.6952066421508789, "gsm_rft_13519": 0.6952652931213379, "aqua_rat_23008": 0.6956909894943237, "gsm_rft_14068": 0.6957632303237915, "gsm_rft_24668": 0.6959551572799683, "gsm_rft_3045": 0.6960786581039429, "gsm_rft_28391": 0.6967959403991699, "gsm_train_17798": 0.6967959403991699, "gsm_rft_7832": 0.6973140835762024, "gsm_rft_10026": 0.6974568367004395, "gsm_rft_35324": 0.6975928544998169, "gsm_rft_35379": 0.6977956295013428, "gsm_rft_25518": 0.6982126832008362, "gsm_rft_8703": 0.6982693076133728, "gsm_rft_28920": 0.6983040571212769, "gsm_rft_12169": 0.6983040571212769, "gsm_rft_32526": 0.6983224749565125, "gsm_train_31158": 0.6984004378318787, "gsm_rft_1939": 0.6984004378318787, "gsm_train_29722": 0.6986821293830872, "gsm_rft_18339": 0.6991223692893982, "gsm_rft_21929": 0.6995700597763062, "gsm_rft_29368": 0.699795126914978, "gsm_rft_22946": 0.6999091506004333, "gsm_rft_35481": 0.7002758383750916, "gsm_rft_26150": 0.7013917565345764, "gsm_rft_13783": 0.7014996409416199, "aqua_rat_45026": 0.7046905159950256, "gsm_train_18124": 0.7056666612625122, "gsm_rft_15582": 0.7056666612625122, "gsm_rft_33471": 0.707024335861206, "gsm_rft_9719": 0.7078022956848145, "aqua_rat_77682": 0.7090690732002258, "camel_44806": 0.7100977897644043, "aqua_rat_28001": 0.7168920040130615, "gsm_rft_17141": 0.7173057794570923, "gsm_train_1174": 0.717400848865509, "gsm_rft_33186": 0.717400848865509, "aqua_rat_31331": 0.7177572250366211, "aqua_rat_52068": 0.7178263664245605, "gsm_rft_20711": 0.7183014154434204, "aqua_rat_52535": 0.7187445759773254, "aqua_rat_4231": 0.7189472317695618, "gsm_rft_10110": 0.7192429900169373, "gsm_rft_11166": 0.7193338871002197, "gsm_rft_33507": 0.7193338871002197, "gsm_train_31881": 0.7193338871002197, "gsm_rft_14572": 0.7193338871002197, "gsm_rft_26010": 0.7196923494338989, "aqua_rat_33683": 0.7205064296722412, "gsm_rft_28497": 0.7205925583839417, "gsm_train_18516": 0.7205925583839417, "gsm_rft_33530": 0.7216277122497559, "aqua_rat_48599": 0.7219552397727966, "gsm_rft_28624": 0.7221127152442932, "aqua_rat_2689": 0.7233840227127075, "aqua_rat_71372": 0.7241801619529724, "aqua_rat_48550": 0.7243818640708923, "aqua_rat_65009": 0.7245092988014221, "aqua_rat_24258": 0.7258772850036621, "aqua_rat_71967": 0.7268795967102051, "aqua_rat_18575": 0.7269071936607361, "aqua_rat_73083": 0.7274501323699951, "aqua_rat_79408": 0.7288962006568909, "camel_5287": 0.7314545512199402}, "TheoremQA_maxku/ipnetwork14-hammingdist.json": {"TheoremQA_maxku/ipnetwork14-hammingdist.json": 0, "aqua_rat_15480": 0.7139154076576233, "aqua_rat_51828": 0.7139983177185059, "math_train_counting_and_probability_5061": 0.7140076756477356, "aqua_rat_45512": 0.7140206098556519, "aqua_rat_88315": 0.7140305042266846, "aqua_rat_24430": 0.7140934467315674, "aqua_rat_53262": 0.7141901254653931, "aqua_rat_17359": 0.7143098711967468, "aqua_rat_35779": 0.7143194675445557, "aqua_rat_53132": 0.7143580913543701, "aqua_rat_21160": 0.714403510093689, "camel_21014": 0.7144928574562073, "aqua_rat_36194": 0.7144957780838013, "camel_19952": 0.7145166397094727, "math_train_counting_and_probability_1099": 0.714627206325531, "camel_36987": 0.7146708965301514, "aqua_rat_60927": 0.7149582505226135, "camel_37459": 0.7150669693946838, "aqua_rat_16788": 0.7151307463645935, "aqua_rat_83978": 0.7152292728424072, "aqua_rat_80982": 0.7152332663536072, "aqua_rat_68856": 0.7152788043022156, "aqua_rat_78751": 0.7153021693229675, "aqua_rat_9005": 0.7153595089912415, "aqua_rat_33938": 0.7153599262237549, "aqua_rat_19073": 0.7153609395027161, "aqua_rat_78317": 0.7153834700584412, "aqua_rat_76281": 0.7155012488365173, "camel_21152": 0.715532660484314, "camel_21517": 0.7156472206115723, "aqua_rat_15961": 0.7158073782920837, "aqua_rat_60575": 0.7158302068710327, "aqua_rat_47821": 0.715909481048584, "aqua_rat_59505": 0.7159111499786377, "camel_21128": 0.7159583568572998, "aqua_rat_68227": 0.7160301208496094, "math_train_counting_and_probability_431": 0.7160605192184448, "aqua_rat_25509": 0.7161573171615601, "aqua_rat_72891": 0.7161617279052734, "aqua_rat_57750": 0.716289222240448, "aqua_rat_80369": 0.7163092494010925, "aqua_rat_74743": 0.7163389325141907, "aqua_rat_37170": 0.7163866758346558, "aqua_rat_55110": 0.7164095044136047, "gsm_train_6284": 0.7164403796195984, "aqua_rat_2166": 0.716456413269043, "aqua_rat_39186": 0.7166002988815308, "aqua_rat_20594": 0.7166115045547485, "camel_38593": 0.7166138291358948, "aqua_rat_5247": 0.7167078852653503, "aqua_rat_1279": 0.7167232036590576, "aqua_rat_40353": 0.7168415784835815, "aqua_rat_16574": 0.7168972492218018, "camel_21995": 0.7170183658599854, "aqua_rat_23524": 0.7170850038528442, "camel_21015": 0.7171313762664795, "aqua_rat_58195": 0.7172117233276367, "camel_23285": 0.7172148823738098, "aqua_rat_4270": 0.7172778248786926, "aqua_rat_80397": 0.7174818515777588, "camel_21822": 0.7176476716995239, "aqua_rat_13921": 0.7178362607955933, "aqua_rat_79834": 0.7179539203643799, "aqua_rat_955": 0.7181287407875061, "aqua_rat_80058": 0.7181295156478882, "aqua_rat_17486": 0.7181426286697388, "aqua_rat_27656": 0.7182928323745728, "camel_21475": 0.7183451652526855, "aqua_rat_4896": 0.7184256315231323, "aqua_rat_87185": 0.7184894680976868, "aqua_rat_30941": 0.7185941338539124, "aqua_rat_43833": 0.7186267971992493, "camel_20730": 0.7186270356178284, "aqua_rat_67387": 0.7186319231987, "aqua_rat_81469": 0.7186991572380066, "aqua_rat_81982": 0.7187526822090149, "aqua_rat_82561": 0.7189021110534668, "math_train_counting_and_probability_467": 0.7191169857978821, "aqua_rat_82156": 0.7191919088363647, "aqua_rat_11623": 0.719196081161499, "aqua_rat_81021": 0.7193219065666199, "camel_20462": 0.7193809747695923, "aqua_rat_65003": 0.7194166779518127, "aqua_rat_24779": 0.7194221615791321, "camel_20839": 0.7194668054580688, "aqua_rat_54809": 0.7195582389831543, "aqua_rat_4483": 0.7196435332298279, "aqua_rat_912": 0.7197172045707703, "aqua_rat_64700": 0.7199087142944336, "camel_20128": 0.7199828624725342, "camel_20866": 0.7200672030448914, "camel_38481": 0.7205631732940674, "aqua_rat_15442": 0.7205978631973267, "aqua_rat_11279": 0.7206753492355347, "aqua_rat_27312": 0.7207176685333252, "aqua_rat_80651": 0.7207776308059692, "aqua_rat_8587": 0.721063494682312, "camel_38538": 0.7211475372314453, "aqua_rat_81895": 0.7211504578590393, "aqua_rat_87221": 0.7211964130401611, "aqua_rat_59096": 0.721339225769043, "camel_21992": 0.7213684320449829, "aqua_rat_68154": 0.7213872671127319, "aqua_rat_86299": 0.7215320467948914, "aqua_rat_59919": 0.7217881083488464, "aqua_rat_46775": 0.7218042016029358, "aqua_rat_32755": 0.7218989729881287, "aqua_rat_11382": 0.7222901582717896, "aqua_rat_15418": 0.722326934337616, "aqua_rat_49097": 0.7225571274757385, "aqua_rat_62699": 0.7225841879844666, "aqua_rat_34678": 0.72259920835495, "aqua_rat_20616": 0.722725510597229, "camel_21761": 0.722726583480835, "aqua_rat_87146": 0.7228125929832458, "aqua_rat_20302": 0.7229925394058228, "camel_21477": 0.7232006192207336, "camel_20783": 0.7232293486595154, "aqua_rat_4294": 0.7232950329780579, "aqua_rat_35121": 0.7234034538269043, "aqua_rat_19731": 0.7234887480735779, "aqua_rat_79736": 0.7235778570175171, "aqua_rat_39874": 0.7241718769073486, "aqua_rat_10149": 0.7242441773414612, "aqua_rat_21017": 0.7242535948753357, "camel_21568": 0.7243134379386902, "aqua_rat_48028": 0.7244630455970764, "aqua_rat_73560": 0.7244793176651001, "aqua_rat_8833": 0.7249365448951721, "aqua_rat_47339": 0.7249600291252136, "aqua_rat_60981": 0.7250872254371643, "aqua_rat_28998": 0.7252606749534607, "aqua_rat_44305": 0.7259084582328796, "math_train_prealgebra_770": 0.7259368300437927, "camel_20512": 0.72606360912323, "camel_21962": 0.7260739803314209, "aqua_rat_41764": 0.726502001285553, "aqua_rat_30495": 0.726677417755127, "math_test_counting_and_probability_970": 0.7266907095909119, "camel_20425": 0.7268362045288086, "aqua_rat_75580": 0.7268465757369995, "camel_37057": 0.7268524169921875, "aqua_rat_75509": 0.7272826433181763, "aqua_rat_19743": 0.727434515953064, "camel_38510": 0.7275895476341248, "aqua_rat_10179": 0.727695643901825, "aqua_rat_34919": 0.7277421951293945, "aqua_rat_688": 0.7282652854919434, "aqua_rat_85106": 0.7285841703414917, "camel_20852": 0.7287150025367737, "aqua_rat_66818": 0.7287956476211548, "math_train_counting_and_probability_769": 0.7290041446685791, "math_test_counting_and_probability_260": 0.729048490524292, "aqua_rat_55627": 0.7291274070739746, "aqua_rat_9869": 0.7293248772621155, "aqua_rat_56544": 0.7298318147659302, "aqua_rat_84808": 0.7300146222114563, "camel_21550": 0.7300440073013306, "aqua_rat_6342": 0.7302451729774475, "aqua_rat_89317": 0.7303065657615662, "aqua_rat_76846": 0.7306113839149475, "aqua_rat_229": 0.7308722734451294, "aqua_rat_18803": 0.7314457297325134, "camel_37037": 0.7315351963043213, "math_train_counting_and_probability_5032": 0.731551468372345, "camel_21596": 0.7322453856468201, "aqua_rat_41911": 0.732368528842926, "aqua_rat_54543": 0.7327398657798767, "aqua_rat_56916": 0.7340843677520752, "aqua_rat_53430": 0.7351669669151306, "aqua_rat_85697": 0.7353333234786987, "aqua_rat_5877": 0.7356386184692383, "aqua_rat_108": 0.7368020415306091, "aqua_rat_19096": 0.7372046709060669, "camel_27506": 0.7372356057167053, "aqua_rat_54587": 0.7376483082771301, "aqua_rat_59360": 0.7388774752616882, "aqua_rat_1879": 0.7393624782562256, "aqua_rat_69333": 0.739661693572998, "aqua_rat_29620": 0.7399964332580566, "aqua_rat_13646": 0.7401593923568726, "aqua_rat_2817": 0.7408216595649719, "aqua_rat_66731": 0.7409917116165161, "aqua_rat_1953": 0.7414303421974182, "aqua_rat_5625": 0.744418740272522, "aqua_rat_31214": 0.7444568276405334, "aqua_rat_85357": 0.746082603931427, "gsm_train_35467": 0.7461118102073669, "gsm_rft_24803": 0.7462843656539917, "aqua_rat_72814": 0.7469785809516907, "gsm_rft_8013": 0.7472766041755676, "aqua_rat_32047": 0.7512481808662415, "aqua_rat_73229": 0.7513154149055481, "aqua_rat_65518": 0.7541669607162476, "aqua_rat_13625": 0.7566772103309631, "camel_37553": 0.7584051489830017, "camel_37444": 0.758497953414917, "aqua_rat_34769": 0.7612720131874084, "TheoremQA_maxku/ipnetwork13-hammingdist.json": 0.8265900015830994}, "TheoremQA_jianyu_xu/Ramsey_2.json": {"camel_20906": 0, "camel_21192": 0, "camel_21191": 0, "camel_21158": 0, "camel_20256": 0, "camel_20945": 0, "camel_20312": 0, "camel_23755": 0, "camel_21068": 0, "camel_21144": 0, "camel_20577": 0, "camel_21161": 0, "camel_23693": 0, "camel_21122": 0, "camel_21798": 0, "camel_21179": 0, "camel_21165": 0, "camel_21568": 0, "camel_21148": 0, "camel_21127": 0, "camel_23695": 0, "camel_21116": 0, "camel_23690": 0, "camel_21835": 0, "camel_21040": 0, "camel_21183": 0, "camel_21123": 0, "camel_21126": 0, "camel_21146": 0, "camel_21184": 0, "camel_21125": 0, "camel_21195": 0, "camel_21142": 0, "camel_21130": 0, "camel_21162": 0, "camel_23682": 0, "camel_21173": 0, "camel_21147": 0, "camel_21124": 0, "camel_21134": 0, "camel_20540": 0, "camel_21169": 0, "camel_21175": 0, "camel_21160": 0, "camel_21170": 0, "camel_21186": 0, "camel_21180": 0, "camel_21141": 0, "camel_21193": 0, "camel_21153": 0, "TheoremQA_jianyu_xu/Ramsey_2.json": 0, "camel_21143": 0, "camel_21156": 0, "camel_21152": 0, "camel_21171": 0, "camel_21131": 0, "camel_21163": 0, "camel_21166": 0, "camel_21149": 0, "camel_21172": 0, "camel_21145": 0, "camel_21157": 0, "camel_21187": 0, "camel_21129": 0, "camel_21822": 0, "camel_21190": 0, "camel_20939": 0, "camel_21137": 0, "camel_21174": 0, "camel_21185": 0, "camel_23711": 0, "camel_21198": 0, "camel_21121": 0, "camel_21164": 0, "camel_21182": 0, "camel_21155": 0, "camel_21135": 0, "camel_20287": 0, "camel_21159": 0, "camel_21194": 0, "camel_21177": 0, "camel_21139": 0, "camel_21055": 0, "camel_21128": 0, "camel_21178": 0, "camel_23752": 0, "camel_21120": 0, "camel_21196": 0, "camel_21154": 0, "camel_21188": 0, "camel_21132": 0, "camel_20898": 0, "camel_21176": 0, "camel_21168": 0, "aqua_rat_79267": 0.7499437928199768, "aqua_rat_75970": 0.7500670552253723, "aqua_rat_15630": 0.7504566311836243, "TheoremQA_jianyu_xu/pigeonhole_4.json": 0.7504702210426331, "aqua_rat_87077": 0.7504997849464417, "camel_37266": 0.7505360841751099, "aqua_rat_84695": 0.7507153749465942, "aqua_rat_57117": 0.7509491443634033, "aqua_rat_8919": 0.7510430216789246, "aqua_rat_48766": 0.7511746287345886, "aqua_rat_85357": 0.7512475848197937, "aqua_rat_82478": 0.7512996196746826, "aqua_rat_56885": 0.7520892024040222, "aqua_rat_5877": 0.7522491216659546, "aqua_rat_48349": 0.7526284456253052, "aqua_rat_64140": 0.7529382109642029, "aqua_rat_62137": 0.7530337572097778, "aqua_rat_23636": 0.7532442808151245, "aqua_rat_35121": 0.7534439563751221, "aqua_rat_19096": 0.753878653049469, "aqua_rat_65742": 0.7542290091514587, "aqua_rat_44594": 0.754256546497345, "aqua_rat_15480": 0.7544066905975342, "aqua_rat_53805": 0.7544077634811401, "aqua_rat_54117": 0.7547168731689453, "math_test_counting_and_probability_513": 0.7551510334014893, "aqua_rat_86623": 0.7556514739990234, "camel_38538": 0.7557359337806702, "aqua_rat_34164": 0.7558709383010864, "aqua_rat_71445": 0.7558966279029846, "aqua_rat_73716": 0.75618976354599, "aqua_rat_39271": 0.7564151883125305, "aqua_rat_69238": 0.7565183043479919, "math_train_counting_and_probability_1110": 0.756521463394165, "aqua_rat_58707": 0.756777286529541, "aqua_rat_63725": 0.7568365335464478, "aqua_rat_6686": 0.7568860054016113, "aqua_rat_70146": 0.7574247121810913, "aqua_rat_26254": 0.7579116821289062, "aqua_rat_52525": 0.7579333186149597, "aqua_rat_9455": 0.7579752206802368, "aqua_rat_4199": 0.7581034302711487, "aqua_rat_29990": 0.7583709955215454, "aqua_rat_20004": 0.7585526704788208, "aqua_rat_88218": 0.7589567303657532, "aqua_rat_2765": 0.7593032121658325, "aqua_rat_48010": 0.7595797777175903, "aqua_rat_13373": 0.7596784234046936, "aqua_rat_52362": 0.7603830695152283, "aqua_rat_87746": 0.7606671452522278, "aqua_rat_7521": 0.7606911659240723, "aqua_rat_15706": 0.7608212232589722, "aqua_rat_77414": 0.7608602046966553, "aqua_rat_31932": 0.7608767747879028, "aqua_rat_83797": 0.761381208896637, "aqua_rat_24238": 0.7615773677825928, "aqua_rat_84328": 0.7617574334144592, "aqua_rat_26932": 0.762091338634491, "aqua_rat_84358": 0.7622881531715393, "aqua_rat_87294": 0.7625008225440979, "aqua_rat_53649": 0.7632638216018677, "math_test_prealgebra_1727": 0.7633141279220581, "aqua_rat_45734": 0.7635436654090881, "aqua_rat_36082": 0.7636035680770874, "aqua_rat_74390": 0.7636669278144836, "aqua_rat_46632": 0.7640235424041748, "aqua_rat_78805": 0.7647185921669006, "camel_38505": 0.7648395299911499, "math_train_prealgebra_1931": 0.7649075984954834, "aqua_rat_21374": 0.7649763226509094, "aqua_rat_7922": 0.7651942372322083, "aqua_rat_68250": 0.7660366892814636, "aqua_rat_63041": 0.7661356329917908, "aqua_rat_44306": 0.7662216424942017, "math_test_prealgebra_1764": 0.7667608857154846, "aqua_rat_62050": 0.7670403718948364, "aqua_rat_19178": 0.767623245716095, "aqua_rat_10371": 0.7683846950531006, "math_test_prealgebra_1467": 0.7685325741767883, "aqua_rat_39778": 0.7686953544616699, "aqua_rat_80216": 0.7695257067680359, "aqua_rat_56889": 0.7695443034172058, "TheoremQA_jianyu_xu/pigeonhole_3.json": 0.771261990070343, "aqua_rat_59044": 0.773597002029419, "aqua_rat_84086": 0.775381326675415, "aqua_rat_51045": 0.7778205871582031, "aqua_rat_27075": 0.7793683409690857, "aqua_rat_65264": 0.7811523675918579, "aqua_rat_59053": 0.7834075689315796, "math_train_prealgebra_325": 0.783970832824707, "aqua_rat_50597": 0.7840537428855896, "aqua_rat_80759": 0.7844713926315308, "aqua_rat_65028": 0.7855800986289978, "math_test_counting_and_probability_341": 0.7873757481575012, "aqua_rat_50073": 0.7892313599586487, "aqua_rat_33710": 0.7897892594337463, "aqua_rat_39765": 0.7919425368309021, "aqua_rat_58088": 0.7921140789985657, "aqua_rat_6737": 0.7922780513763428, "TheoremQA_jianyu_xu/Ramsey_3.json": 0.7929447293281555, "aqua_rat_14782": 0.7971232533454895, "aqua_rat_47084": 0.7989698648452759, "aqua_rat_70890": 0.8003037571907043, "aqua_rat_53788": 0.8005592823028564, "math_train_prealgebra_1917": 0.8048948049545288, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0.8322839140892029}, "TheoremQA_wenhuchen/viterbi2.json": {"camel_9513": 0, "camel_9479": 0, "camel_9497": 0, "camel_9475": 0, "math_test_counting_and_probability_503": 0, "camel_9517": 0, "camel_9514": 0, "camel_8727": 0, "camel_9441": 0, "camel_9476": 0, "camel_9481": 0, "camel_9506": 0, "camel_9461": 0, "camel_9495": 0, "camel_9471": 0, "camel_9491": 0, "camel_9496": 0, "camel_9516": 0, "camel_9511": 0, "camel_8734": 0, "camel_8784": 0, "camel_9453": 0, "camel_9446": 0, "camel_9503": 0, "camel_9448": 0, "camel_9508": 0, "camel_9502": 0, "camel_9489": 0, "camel_9474": 0, "math_train_counting_and_probability_557": 0, "camel_9500": 0, "math_train_counting_and_probability_97": 0, "camel_9480": 0, "camel_9487": 0, "camel_9477": 0, "camel_9447": 0, "camel_9464": 0, "camel_9485": 0, "camel_9454": 0, "aqua_rat_32748": 0.7817976474761963, "camel_10542": 0.7820308804512024, "camel_36345": 0.7820594310760498, "camel_10629": 0.7821086645126343, "camel_36523": 0.7821205854415894, "camel_24718": 0.7822468280792236, "camel_39408": 0.7826213240623474, "camel_11498": 0.7826680541038513, "camel_24661": 0.7826805710792542, "aqua_rat_40647": 0.7827128767967224, "gsm_rft_25950": 0.7832505106925964, "gsm_rft_34671": 0.7832505106925964, "camel_24669": 0.783286452293396, "camel_39439": 0.7836446762084961, "camel_25254": 0.7836514115333557, "camel_24652": 0.783668577671051, "camel_24660": 0.7837647795677185, "camel_37849": 0.7838932871818542, "camel_11998": 0.7839418053627014, "camel_37631": 0.7840378284454346, "aqua_rat_47489": 0.7841344475746155, "gsm_rft_28572": 0.7841411828994751, "gsm_rft_7672": 0.7841411828994751, "gsm_train_30279": 0.7841411828994751, "camel_11990": 0.7844051718711853, "camel_24653": 0.7844176292419434, "camel_10621": 0.7844904065132141, "aqua_rat_37936": 0.7845715284347534, "camel_11491": 0.7848551273345947, "camel_37907": 0.7848689556121826, "camel_37620": 0.7849969267845154, "camel_36483": 0.7850998044013977, "aqua_rat_76641": 0.7851644158363342, "aqua_rat_31129": 0.7853050827980042, "aqua_rat_15122": 0.7853677868843079, "aqua_rat_68586": 0.7855499982833862, "aqua_rat_50753": 0.7856730818748474, "camel_24685": 0.7858961820602417, "camel_10597": 0.7859237194061279, "camel_36361": 0.7859262824058533, "camel_24677": 0.7859338521957397, "camel_37912": 0.7862100005149841, "camel_39391": 0.7862163782119751, "camel_37823": 0.7866077423095703, "aqua_rat_82625": 0.7866609692573547, "aqua_rat_36135": 0.7871829271316528, "camel_11462": 0.7872041463851929, "camel_25515": 0.7875618934631348, "camel_37799": 0.7877737283706665, "aqua_rat_5883": 0.7878105640411377, "aqua_rat_34885": 0.7878274321556091, "aqua_rat_85293": 0.78783118724823, "aqua_rat_30901": 0.7880495190620422, "camel_24679": 0.7880980372428894, "camel_24671": 0.7881573438644409, "camel_11453": 0.7881996035575867, "camel_11679": 0.7882025837898254, "camel_11626": 0.7885432243347168, "camel_10571": 0.7885579466819763, "camel_11676": 0.7889845967292786, "camel_24643": 0.7890502214431763, "aqua_rat_34276": 0.7895222306251526, "camel_10469": 0.7895243763923645, "camel_25438": 0.7896066308021545, "camel_10552": 0.7898305058479309, "camel_24659": 0.7898663282394409, "camel_10620": 0.7903186082839966, "aqua_rat_17728": 0.7905006408691406, "aqua_rat_63190": 0.790557324886322, "camel_36244": 0.7905654907226562, "camel_36330": 0.7906028032302856, "camel_37986": 0.7911407351493835, "camel_36337": 0.7913586497306824, "aqua_rat_43015": 0.7917925119400024, "aqua_rat_47751": 0.7918805480003357, "aqua_rat_69941": 0.7920238971710205, "aqua_rat_59064": 0.7920301556587219, "aqua_rat_21944": 0.7924132347106934, "camel_10952": 0.7927616834640503, "camel_25447": 0.7927986979484558, "camel_10638": 0.7929590940475464, "camel_37762": 0.7929859161376953, "camel_37817": 0.7933292388916016, "camel_10555": 0.7934994697570801, "camel_37783": 0.7935129404067993, "camel_37775": 0.7937265634536743, "camel_36276": 0.7938178777694702, "camel_24689": 0.7942032217979431, "aqua_rat_34949": 0.7942802906036377, "camel_10636": 0.7943667769432068, "aqua_rat_37698": 0.7948668599128723, "camel_11869": 0.7949991226196289, "aqua_rat_40444": 0.7950870990753174, "aqua_rat_60327": 0.7951499223709106, "camel_11629": 0.7951922416687012, "aqua_rat_65593": 0.7952331304550171, "camel_24678": 0.7953327894210815, "aqua_rat_80730": 0.7953615784645081, "aqua_rat_50510": 0.7957667112350464, "aqua_rat_87308": 0.7961312532424927, "camel_37612": 0.7965103983879089, "aqua_rat_62892": 0.7966437935829163, "camel_39375": 0.7972925305366516, "camel_11898": 0.7975437045097351, "camel_24683": 0.7976245284080505, "camel_36358": 0.7976559996604919, "aqua_rat_29721": 0.798086404800415, "camel_24640": 0.7987663149833679, "aqua_rat_6577": 0.7990684509277344, "camel_24654": 0.7993897795677185, "camel_24675": 0.7997242212295532, "camel_10599": 0.7997651100158691, "camel_37905": 0.7998058199882507, "camel_25284": 0.8000973463058472, "camel_36388": 0.8005611896514893, "aqua_rat_65962": 0.801326334476471, "camel_24709": 0.801330029964447, "aqua_rat_61314": 0.80159991979599, "camel_10937": 0.8021379709243774, "camel_28142": 0.8026517629623413, "aqua_rat_41204": 0.8027352690696716, "camel_24693": 0.8028397560119629, "camel_11308": 0.8031235933303833, "aqua_rat_37772": 0.8039682507514954, "camel_36368": 0.8040728569030762, "aqua_rat_61684": 0.8043937683105469, "aqua_rat_14944": 0.8050946593284607, "camel_10588": 0.8055382370948792, "aqua_rat_44578": 0.8055781126022339, "aqua_rat_10224": 0.8056344985961914, "camel_24714": 0.8061161041259766, "camel_11796": 0.8069523572921753, "aqua_rat_42825": 0.807155191898346, "aqua_rat_38490": 0.8075723052024841, "aqua_rat_50672": 0.8081106543540955, "camel_24711": 0.8083298802375793, "camel_10618": 0.8084279894828796, "aqua_rat_8224": 0.8089661002159119, "aqua_rat_69505": 0.809224545955658, "camel_11651": 0.8092350959777832, "camel_10612": 0.8093525171279907, "aqua_rat_50853": 0.8098471760749817, "aqua_rat_73156": 0.8103707432746887, "aqua_rat_71018": 0.810755729675293, "camel_11650": 0.8108837008476257, "camel_37875": 0.8110040426254272, "aqua_rat_45407": 0.8115329146385193, "camel_11623": 0.8119221925735474, "aqua_rat_86707": 0.8122996091842651, "aqua_rat_30573": 0.8147596120834351, "aqua_rat_51142": 0.8149814605712891, "aqua_rat_84401": 0.81561279296875, "aqua_rat_87100": 0.8158792853355408, "aqua_rat_67820": 0.817320704460144, "aqua_rat_75801": 0.8180747628211975, "aqua_rat_2646": 0.818657636642456, "camel_10622": 0.818726122379303, "camel_29102": 0.819313645362854, "camel_11619": 0.8490142226219177, "camel_10639": 0.8635390400886536, "camel_10635": 0.867671549320221}, "TheoremQA_panlu/molar_heat_capacity1.json": {"TheoremQA_panlu/molar_heat_capacity1.json": 0, "aqua_rat_32841": 0.6980782151222229, "aqua_rat_31710": 0.6981325745582581, "aqua_rat_35163": 0.6981436610221863, "aqua_rat_43732": 0.6981463432312012, "aqua_rat_12500": 0.6981488466262817, "aqua_rat_52293": 0.6981583833694458, "aqua_rat_18519": 0.6982703804969788, "aqua_rat_11407": 0.6983240842819214, "gsm_rft_12781": 0.698334276676178, "gsm_train_17782": 0.698334276676178, "gsm_rft_20548": 0.6983646750450134, "aqua_rat_21256": 0.6984483003616333, "gsm_rft_20284": 0.698454737663269, "aqua_rat_52838": 0.6985348463058472, "aqua_rat_86779": 0.6985464692115784, "aqua_rat_59222": 0.6985559463500977, "gsm_train_23183": 0.6985664963722229, "aqua_rat_83991": 0.6985827684402466, "gsm_rft_5341": 0.6986095905303955, "gsm_rft_2479": 0.6986111402511597, "gsm_rft_2844": 0.6987069249153137, "aqua_rat_81445": 0.6987203359603882, "aqua_rat_89310": 0.698722243309021, "gsm_rft_27655": 0.698784589767456, "gsm_rft_28691": 0.6988388299942017, "camel_36269": 0.698867917060852, "aqua_rat_63580": 0.6989465355873108, "aqua_rat_11673": 0.6990064382553101, "aqua_rat_72520": 0.6990282535552979, "aqua_rat_20622": 0.699112057685852, "gsm_rft_6660": 0.6991689801216125, "gsm_rft_10892": 0.6992581486701965, "aqua_rat_26009": 0.6992583274841309, "gsm_rft_24327": 0.6993283033370972, "gsm_rft_15189": 0.699338972568512, "aqua_rat_54758": 0.6993644833564758, "gsm_rft_28746": 0.6993746161460876, "aqua_rat_17670": 0.6993823647499084, "aqua_rat_73348": 0.6994004249572754, "gsm_rft_9876": 0.6994515657424927, "aqua_rat_47273": 0.6995162963867188, "aqua_rat_41632": 0.6995261907577515, "aqua_rat_82279": 0.6996681690216064, "aqua_rat_51726": 0.6997317671775818, "aqua_rat_82987": 0.6998424530029297, "aqua_rat_81259": 0.6998882293701172, "aqua_rat_63850": 0.700096845626831, "aqua_rat_1928": 0.7001019716262817, "aqua_rat_29713": 0.700114905834198, "aqua_rat_40134": 0.7001792788505554, "aqua_rat_83672": 0.7001898884773254, "gsm_rft_23705": 0.7002442479133606, "aqua_rat_9230": 0.700301468372345, "aqua_rat_41833": 0.7003841996192932, "aqua_rat_66302": 0.700467050075531, "aqua_rat_3447": 0.7005163431167603, "aqua_rat_64937": 0.700542151927948, "aqua_rat_39484": 0.7005488872528076, "gsm_rft_15594": 0.7006471753120422, "gsm_rft_22912": 0.700672447681427, "aqua_rat_34926": 0.7007871866226196, "gsm_train_35436": 0.7010066509246826, "gsm_rft_33117": 0.701184093952179, "gsm_rft_23897": 0.7011914849281311, "aqua_rat_85573": 0.7012418508529663, "gsm_rft_22822": 0.7013850808143616, "aqua_rat_13838": 0.7014286518096924, "gsm_rft_15366": 0.7014779448509216, "gsm_train_6141": 0.7015401721000671, "gsm_rft_5908": 0.7015401721000671, "aqua_rat_8335": 0.7016209363937378, "aqua_rat_72055": 0.7016388773918152, "aqua_rat_86404": 0.7017319798469543, "gsm_rft_25502": 0.7017991542816162, "aqua_rat_73743": 0.7021602392196655, "aqua_rat_78348": 0.7021704316139221, "aqua_rat_54333": 0.7022278904914856, "aqua_rat_16363": 0.7023217678070068, "aqua_rat_55911": 0.7023271918296814, "aqua_rat_81955": 0.7023956775665283, "aqua_rat_4920": 0.7024025917053223, "gsm_rft_3840": 0.7024313807487488, "gsm_rft_11223": 0.7024506330490112, "aqua_rat_5823": 0.7024770379066467, "aqua_rat_17971": 0.7025151252746582, "gsm_rft_22401": 0.7027260065078735, "aqua_rat_45859": 0.7029897570610046, "gsm_train_8381": 0.7030625939369202, "gsm_rft_17134": 0.7030625939369202, "gsm_rft_29319": 0.7030819058418274, "aqua_rat_82073": 0.7032243609428406, "aqua_rat_43074": 0.7032474279403687, "aqua_rat_80823": 0.7032796144485474, "gsm_rft_13637": 0.7032997012138367, "gsm_train_9384": 0.7032997012138367, "aqua_rat_46045": 0.7035133242607117, "aqua_rat_23458": 0.7038160562515259, "aqua_rat_59033": 0.703835666179657, "aqua_rat_59413": 0.7038655281066895, "aqua_rat_11543": 0.7042163610458374, "aqua_rat_37929": 0.7042604088783264, "gsm_rft_19423": 0.7044700980186462, "gsm_rft_14462": 0.7044700980186462, "gsm_train_15924": 0.7044700980186462, "aqua_rat_49469": 0.7044724822044373, "aqua_rat_71597": 0.7045512795448303, "gsm_rft_10651": 0.7047592401504517, "gsm_rft_23759": 0.7047825455665588, "aqua_rat_1215": 0.7048489451408386, "aqua_rat_20199": 0.704866349697113, "aqua_rat_52508": 0.7051121592521667, "aqua_rat_56688": 0.705128014087677, "aqua_rat_57091": 0.7054152488708496, "aqua_rat_19482": 0.7055301070213318, "aqua_rat_70258": 0.7055440545082092, "aqua_rat_30350": 0.7055534720420837, "aqua_rat_40611": 0.7055605053901672, "aqua_rat_25019": 0.7058372497558594, "aqua_rat_18931": 0.705842137336731, "aqua_rat_81791": 0.7060428261756897, "aqua_rat_19150": 0.7062011361122131, "aqua_rat_85950": 0.7064840793609619, "aqua_rat_11960": 0.7066360116004944, "aqua_rat_316": 0.7067175507545471, "aqua_rat_19265": 0.7067871689796448, "aqua_rat_85497": 0.707007884979248, "aqua_rat_64410": 0.7073790431022644, "aqua_rat_61178": 0.7074571847915649, "aqua_rat_52633": 0.7076142430305481, "aqua_rat_19904": 0.7077639698982239, "aqua_rat_20476": 0.707962691783905, "aqua_rat_14845": 0.7083150744438171, "aqua_rat_59437": 0.7085423469543457, "aqua_rat_32205": 0.7085540294647217, "aqua_rat_55426": 0.7086697220802307, "gsm_rft_7584": 0.7089079022407532, "gsm_train_6061": 0.7089079022407532, "aqua_rat_3468": 0.7089136838912964, "aqua_rat_68704": 0.7089880704879761, "aqua_rat_66505": 0.709128737449646, "aqua_rat_33251": 0.7093731760978699, "aqua_rat_79178": 0.7094019055366516, "aqua_rat_23467": 0.7094857096672058, "gsm_rft_20890": 0.7095534205436707, "aqua_rat_43233": 0.7097009420394897, "aqua_rat_80952": 0.7101172804832458, "aqua_rat_73234": 0.7102808356285095, "aqua_rat_21162": 0.7107437252998352, "aqua_rat_2903": 0.711021900177002, "aqua_rat_57067": 0.7114238142967224, "aqua_rat_37784": 0.7115693092346191, "aqua_rat_81030": 0.7116472125053406, "aqua_rat_60497": 0.7123137712478638, "aqua_rat_55150": 0.7127959728240967, "gsm_rft_20590": 0.7129017114639282, "gsm_train_8091": 0.712952196598053, "gsm_rft_6094": 0.7131154537200928, "gsm_rft_21129": 0.7136312127113342, "gsm_rft_5594": 0.7139774560928345, "aqua_rat_72360": 0.7154078483581543, "aqua_rat_82016": 0.7161519527435303, "aqua_rat_32250": 0.7163965702056885, "aqua_rat_75205": 0.7165703773498535, "aqua_rat_71792": 0.7175646424293518, "gsm_rft_34322": 0.7178238034248352, "aqua_rat_26686": 0.7179217338562012, "gsm_rft_32487": 0.7180102467536926, "gsm_train_22269": 0.7180102467536926, "gsm_train_22817": 0.7183080315589905, "aqua_rat_35656": 0.7183086276054382, "aqua_rat_80897": 0.7185023427009583, "gsm_rft_2604": 0.7186694145202637, "gsm_rft_10620": 0.719123363494873, "aqua_rat_29911": 0.7201284170150757, "gsm_rft_6673": 0.7206752896308899, "aqua_rat_3199": 0.7222425937652588, "aqua_rat_38504": 0.722756028175354, "aqua_rat_48607": 0.723848819732666, "gsm_rft_27697": 0.7240084409713745, "aqua_rat_79036": 0.7242754697799683, "gsm_rft_14007": 0.7245743870735168, "gsm_rft_8985": 0.7250535488128662, "aqua_rat_47999": 0.725449800491333, "aqua_rat_75763": 0.7255276441574097, "gsm_rft_19969": 0.7259960770606995, "gsm_train_26725": 0.7259960770606995, "gsm_rft_21326": 0.7406830191612244, "camel_37933": 0.7438970804214478, "gsm_rft_6591": 0.7463136315345764, "gsm_train_4193": 0.7463136315345764, "gsm_train_10153": 0.746516227722168, "gsm_rft_35104": 0.7465954422950745, "gsm_rft_21213": 0.7478898763656616, "gsm_rft_23914": 0.7628883123397827, "camel_17587": 0.7645488381385803, "camel_28151": 0.7715564370155334, "camel_45925": 0.8370646834373474, "camel_37984": 0.8463829159736633, "TheoremQA_panlu/molar_heat_capacity2.json": 0.8720924854278564}, "TheoremQA_elainewan/math_algebra_3_2.json": {"camel_15912": 0, "camel_15919": 0, "camel_15885": 0, "camel_15959": 0, "camel_15611": 0, "camel_15934": 0, "camel_15629": 0, "camel_15961": 0, "camel_15993": 0, "camel_135": 0, "camel_15634": 0, "camel_15865": 0, "camel_15884": 0, "camel_15632": 0, "camel_15860": 0, "camel_15307": 0, "camel_15920": 0, "camel_15921": 0, "camel_15840": 0, "camel_99": 0, "camel_15621": 0, "camel_15913": 0, "camel_15893": 0, "camel_97": 0, "camel_15607": 0, "camel_15937": 0, "camel_15939": 0, "camel_15979": 0, "camel_15855": 0, "camel_15679": 0, "camel_15631": 0, "camel_15836": 0, "camel_15948": 0, "camel_15880": 0, "math_train_algebra_653": 0, "camel_15914": 0, "camel_15991": 0, "camel_15889": 0, "camel_15925": 0, "camel_15845": 0, "camel_15957": 0, "camel_15649": 0, "camel_15615": 0, "camel_15883": 0, "camel_15620": 0, "camel_15879": 0, "camel_15848": 0, "camel_15896": 0, "camel_15901": 0, "camel_15916": 0, "camel_14250": 0, "camel_15971": 0, "camel_15882": 0, "camel_15997": 0, "camel_15906": 0, "camel_15990": 0, "camel_15532": 0, "camel_15857": 0, "math_train_algebra_24005": 0, "camel_15929": 0, "camel_15918": 0, "camel_15953": 0, "camel_15890": 0, "camel_15967": 0, "math_test_algebra_2072": 0, "camel_15859": 0, "camel_15996": 0, "camel_15876": 0, "camel_14261": 0, "camel_15944": 0, "camel_15969": 0, "camel_15846": 0, "camel_15853": 0, "camel_14274": 0, "camel_15966": 0, "camel_15613": 0, "camel_15992": 0, "camel_15933": 0, "camel_15945": 0, "camel_14241": 0, "camel_15858": 0, "camel_15575": 0, "camel_15900": 0, "math_train_prealgebra_295": 0, "camel_15985": 0, "camel_15899": 0, "camel_15872": 0, "camel_15976": 0, "camel_15850": 0, "camel_15852": 0, "camel_15943": 0, "camel_15868": 0, "camel_15983": 0, "TheoremQA_elainewan/math_algebra_3_2.json": 0, "camel_15922": 0, "camel_15854": 0, "camel_15911": 0, "camel_15904": 0, "camel_15841": 0, "camel_15960": 0, "camel_15674": 0, "camel_15729": 0, "camel_15603": 0, "camel_15897": 0, "camel_15661": 0, "camel_15601": 0, "camel_15886": 0, "aqua_rat_15482": 0.7393136620521545, "camel_47731": 0.7393552660942078, "aqua_rat_60601": 0.7393700480461121, "aqua_rat_60631": 0.7398187518119812, "aqua_rat_7178": 0.7400153875350952, "aqua_rat_69871": 0.7401326298713684, "aqua_rat_68196": 0.7402570843696594, "aqua_rat_40548": 0.7403325438499451, "aqua_rat_16636": 0.740464448928833, "math_test_geometry_781": 0.7406216859817505, "aqua_rat_71965": 0.7406855821609497, "camel_49882": 0.740896463394165, "aqua_rat_24416": 0.7410009503364563, "aqua_rat_21741": 0.741195559501648, "camel_5859": 0.7412369251251221, "math_train_geometry_1": 0.7412465214729309, "aqua_rat_3491": 0.7413185238838196, "aqua_rat_28523": 0.7413563132286072, "aqua_rat_64639": 0.741489052772522, "aqua_rat_37873": 0.7424876093864441, "camel_5662": 0.7425495386123657, "aqua_rat_45906": 0.7426579594612122, "aqua_rat_28067": 0.7427071332931519, "aqua_rat_6857": 0.742959201335907, "camel_5942": 0.7429901957511902, "aqua_rat_8811": 0.7431410551071167, "camel_5992": 0.743370532989502, "aqua_rat_30159": 0.7440345287322998, "aqua_rat_83339": 0.7443428635597229, "aqua_rat_80163": 0.7444517016410828, "aqua_rat_52556": 0.7445353269577026, "aqua_rat_76393": 0.7447299361228943, "aqua_rat_35190": 0.7449101209640503, "aqua_rat_85563": 0.7451427578926086, "aqua_rat_26893": 0.7452279329299927, "camel_49126": 0.7452517747879028, "aqua_rat_3790": 0.7453688383102417, "aqua_rat_19925": 0.745448648929596, "aqua_rat_20932": 0.7455369830131531, "aqua_rat_43435": 0.7455435395240784, "aqua_rat_52007": 0.7459281086921692, "aqua_rat_80856": 0.7461643218994141, "aqua_rat_38323": 0.7461735606193542, "aqua_rat_69218": 0.7463593482971191, "aqua_rat_13013": 0.7466551661491394, "aqua_rat_11314": 0.7466875910758972, "aqua_rat_76534": 0.7473275065422058, "TheoremQA_elainewan/math_algebra_4.json": 0.7474023103713989, "aqua_rat_79701": 0.747435986995697, "aqua_rat_12010": 0.7474898099899292, "aqua_rat_71326": 0.7475613951683044, "aqua_rat_11620": 0.7479416131973267, "aqua_rat_44709": 0.7479466795921326, "camel_49900": 0.7479867935180664, "camel_5704": 0.7480729818344116, "aqua_rat_23667": 0.7484221458435059, "aqua_rat_66103": 0.7484232783317566, "aqua_rat_65557": 0.7486363053321838, "aqua_rat_78473": 0.7486789226531982, "aqua_rat_9047": 0.7489645481109619, "camel_5955": 0.7492052316665649, "aqua_rat_33061": 0.74945068359375, "aqua_rat_17054": 0.7495797276496887, "aqua_rat_71816": 0.750237762928009, "aqua_rat_16291": 0.7503240704536438, "camel_5983": 0.7512596249580383, "camel_49121": 0.7513036727905273, "aqua_rat_67418": 0.7513625025749207, "aqua_rat_61332": 0.7513710260391235, "camel_49851": 0.7525857090950012, "aqua_rat_60953": 0.7528074383735657, "aqua_rat_11860": 0.7541200518608093, "aqua_rat_39311": 0.7542147040367126, "aqua_rat_20605": 0.7545139193534851, "aqua_rat_2524": 0.754844069480896, "aqua_rat_41461": 0.7549417018890381, "aqua_rat_14551": 0.7552484273910522, "aqua_rat_9142": 0.7558327317237854, "camel_5683": 0.7583480477333069, "aqua_rat_78360": 0.7590004205703735, "aqua_rat_72870": 0.7594854235649109, "aqua_rat_22455": 0.7597132921218872, "aqua_rat_66081": 0.7617449164390564, "aqua_rat_23369": 0.7626332640647888, "TheoremQA_elainewan/math_algebra_3_4.json": 0.7653257250785828, "TheoremQA_elainewan/math_algebra_3.json": 0.76584392786026, "camel_36766": 0.7671592235565186, "camel_49173": 0.7782914638519287, "aqua_rat_70287": 0.7783926129341125, "math_test_geometry_167": 0.7816817760467529, "camel_49182": 0.7887693643569946, "camel_49168": 0.8009383082389832, "camel_49180": 0.8054742217063904}, "TheoremQA_elainewan/math_calculus_12.json": {"camel_7504": 0, "camel_7464": 0, "camel_7450": 0, "camel_7243": 0, "camel_7517": 0, "camel_7492": 0, "camel_7160": 0, "camel_7236": 0, "camel_7216": 0, "camel_7445": 0, "camel_7466": 0, "camel_7998": 0, "camel_7515": 0, "camel_7205": 0, "camel_7263": 0, "camel_7500": 0, "camel_7452": 0, "camel_7476": 0, "camel_7259": 0, "camel_7960": 0, "camel_7465": 0, "camel_7470": 0, "camel_7502": 0, "camel_7268": 0, "camel_7516": 0, "camel_7226": 0, "camel_7481": 0, "camel_7257": 0, "camel_7200": 0, "camel_7955": 0, "camel_7215": 0, "camel_7954": 0, "camel_7973": 0, "camel_7453": 0, "camel_7212": 0, "camel_7983": 0, "camel_7509": 0, "camel_7457": 0, "camel_7487": 0, "camel_7966": 0, "camel_7936": 0, "camel_7510": 0, "camel_6309": 0, "camel_7731": 0, "camel_7505": 0, "camel_7455": 0, "camel_7267": 0, "camel_7503": 0, "camel_7971": 0, "camel_7497": 0, "camel_7490": 0, "camel_7999": 0, "camel_7252": 0, "camel_7494": 0, "camel_7213": 0, "camel_7231": 0, "camel_7443": 0, "camel_7501": 0, "camel_7238": 0, "camel_7950": 0, "camel_7475": 0, "camel_7508": 0, "camel_7507": 0, "camel_7997": 0, "camel_7468": 0, "camel_7448": 0, "camel_7940": 0, "camel_7513": 0, "camel_7486": 0, "camel_7963": 0, "camel_7228": 0, "camel_7506": 0, "camel_7484": 0, "camel_7498": 0, "camel_7472": 0, "camel_7962": 0, "camel_7253": 0, "camel_7488": 0, "camel_7449": 0, "camel_7277": 0, "camel_7970": 0, "camel_7990": 0, "camel_7256": 0, "camel_7959": 0, "camel_7477": 0, "camel_7218": 0, "camel_7935": 0, "camel_7610": 0, "camel_7961": 0, "camel_7947": 0, "camel_7953": 0, "camel_6849": 0, "camel_7677": 0, "camel_6970": 0, "camel_7629": 0, "camel_7482": 0, "camel_7276": 0, "camel_7967": 0, "camel_7972": 0, "camel_7519": 0, "camel_7441": 0, "camel_7495": 0, "camel_7932": 0, "camel_7949": 0, "camel_7258": 0, "camel_7958": 0, "camel_7969": 0, "camel_7478": 0, "camel_7459": 0, "camel_7920": 0, "camel_7512": 0, "camel_7993": 0, "camel_7927": 0, "camel_7979": 0, "camel_7986": 0, "camel_7463": 0, "camel_7931": 0, "camel_7518": 0, "camel_7996": 0, "camel_6518": 0, "camel_7493": 0, "camel_7957": 0, "camel_7442": 0, "camel_7934": 0, "camel_7026": 0, "camel_6998": 0, "camel_7987": 0, "camel_6594": 0, "TheoremQA_elainewan/math_calculus_12.json": 0, "camel_38162": 0.7802110314369202, "camel_39254": 0.7809222936630249, "camel_5041": 0.7810769081115723, "camel_5008": 0.7811152935028076, "camel_5093": 0.7812873125076294, "camel_39513": 0.7820872664451599, "math_train_algebra_127": 0.7829645276069641, "camel_39469": 0.7832654714584351, "camel_39455": 0.7852966785430908, "math_test_algebra_613": 0.785861611366272, "camel_39488": 0.7860931754112244, "camel_39461": 0.7866960167884827, "gsm_train_21024": 0.7873691320419312, "gsm_rft_2034": 0.7875485420227051, "gsm_rft_3538": 0.7875485420227051, "aqua_rat_8703": 0.7887395620346069, "camel_476": 0.7891092300415039, "aqua_rat_65312": 0.7891805171966553, "camel_39516": 0.7896690368652344, "math_train_algebra_605": 0.7897650599479675, "camel_39338": 0.7902873158454895, "aqua_rat_11429": 0.7903123497962952, "math_train_algebra_2568": 0.7911999821662903, "camel_5029": 0.7914423942565918, "aqua_rat_47365": 0.793142557144165, "aqua_rat_84494": 0.7939326763153076, "camel_4731": 0.7949024438858032, "math_test_algebra_1774": 0.7953011989593506, "camel_39446": 0.7961054444313049, "camel_39460": 0.7979452013969421, "camel_28022": 0.7991217374801636, "math_train_algebra_25179": 0.7991257309913635, "camel_39311": 0.8002064228057861, "camel_39473": 0.8006835579872131, "camel_39509": 0.8008299469947815, "math_train_algebra_221": 0.801101565361023, "camel_39454": 0.801261842250824, "camel_28068": 0.8020884394645691, "camel_28909": 0.8024987578392029, "camel_39475": 0.8032468557357788, "math_test_algebra_1168": 0.803487241268158, "math_train_algebra_1735": 0.8036045432090759, "camel_4986": 0.806287407875061, "math_test_prealgebra_1115": 0.8073728084564209, "camel_39467": 0.8079280853271484, "camel_5016": 0.808315098285675, "camel_39505": 0.8086520433425903, "camel_39517": 0.8096082806587219, "camel_39466": 0.8144074082374573, "math_test_algebra_2731": 0.8148813247680664, "TheoremQA_elainewan/math_calculus_3_6.json": 0.8169839978218079, "camel_17565": 0.8173565864562988, "aqua_rat_19334": 0.822348952293396, "math_test_algebra_2683": 0.8300069570541382, "camel_39511": 0.8319234251976013, "camel_39468": 0.8364621996879578, "aqua_rat_9643": 0.8369527459144592, "camel_39457": 0.8377112150192261, "aqua_rat_68267": 0.8383312225341797, "camel_39441": 0.8447697758674622, "camel_441": 0.8530208468437195, "camel_39471": 0.8539837598800659, "camel_39312": 0.8545968532562256, "camel_29979": 0.8549347519874573, "camel_39486": 0.8563226461410522, "aqua_rat_57946": 0.8604899048805237, "camel_39483": 0.8635299205780029, "camel_28147": 0.8639512658119202, "aqua_rat_48488": 0.8648338317871094, "aqua_rat_47425": 0.8682440519332886, "camel_39448": 0.8710203766822815}, "TheoremQA_maxku/graphtheory7-shortestpath.json": {"camel_23961": 0, "camel_22273": 0, "camel_22279": 0, "camel_39930": 0, "camel_23947": 0, "camel_23955": 0, "camel_23935": 0, "camel_23958": 0, "camel_22251": 0, "camel_23184": 0, "camel_22885": 0, "camel_22067": 0, "camel_22414": 0, "camel_22288": 0, "camel_22295": 0, "camel_23966": 0, "camel_23952": 0, "camel_21667": 0, "camel_22286": 0, "camel_21661": 0, "camel_22073": 0, "camel_38481": 0, "camel_39964": 0, "camel_21627": 0, "camel_38584": 0, "camel_23964": 0, "camel_22814": 0, "camel_22010": 0, "camel_22433": 0, "camel_22008": 0, "camel_22368": 0, "camel_23922": 0, "camel_23970": 0, "camel_22242": 0, "camel_22004": 0, "camel_38608": 0, "camel_22075": 0, "camel_21610": 0, "camel_23957": 0, "camel_22367": 0, "camel_23192": 0, "camel_22330": 0, "camel_22449": 0, "camel_22296": 0, "camel_22276": 0, "camel_39977": 0, "camel_38564": 0, "camel_22051": 0, "camel_23991": 0, "camel_22403": 0, "camel_22312": 0, "camel_22033": 0, "camel_22306": 0, "camel_23924": 0, "camel_21654": 0, "camel_38630": 0, "camel_22366": 0, "camel_21648": 0, "camel_22432": 0, "camel_39968": 0, "camel_22417": 0, "camel_21601": 0, "camel_23990": 0, "camel_22035": 0, "camel_23996": 0, "camel_23967": 0, "camel_23963": 0, "camel_23945": 0, "camel_23951": 0, "camel_23923": 0, "camel_22038": 0, "camel_23997": 0, "camel_22170": 0, "camel_22332": 0, "camel_38619": 0, "camel_23998": 0, "camel_38501": 0, "camel_38560": 0, "camel_39926": 0, "camel_22011": 0, "camel_22300": 0, "camel_23981": 0, "camel_23921": 0, "camel_22009": 0, "camel_22294": 0, "camel_21646": 0, "camel_22361": 0, "camel_39972": 0, "camel_38572": 0, "camel_22847": 0, "camel_21609": 0, "camel_21663": 0, "camel_39920": 0, "camel_38491": 0, "camel_22017": 0, "camel_22043": 0, "camel_39987": 0, "camel_23979": 0, "camel_39954": 0, "camel_23926": 0, "camel_38576": 0, "camel_38581": 0, "camel_38583": 0, "camel_23973": 0, "camel_22024": 0, "camel_39959": 0, "camel_22266": 0, "camel_38489": 0, "camel_23980": 0, "camel_22000": 0, "camel_22076": 0, "camel_39960": 0, "camel_22057": 0, "camel_22016": 0, "camel_22443": 0, "camel_22046": 0, "camel_22252": 0, "camel_38621": 0, "camel_39995": 0, "camel_21675": 0, "camel_38611": 0, "camel_38906": 0, "camel_22809": 0, "camel_39996": 0, "camel_39999": 0, "camel_22023": 0, "camel_39938": 0, "camel_21634": 0, "camel_38635": 0, "camel_23940": 0, "camel_21628": 0, "camel_22001": 0, "camel_21639": 0, "camel_23985": 0, "camel_22061": 0, "camel_22049": 0, "TheoremQA_maxku/graphtheory7-shortestpath.json": 0, "camel_22068": 0, "camel_21678": 0, "camel_21630": 0, "camel_39931": 0, "camel_21658": 0, "camel_22053": 0, "camel_23982": 0, "camel_22022": 0, "camel_39975": 0, "camel_22003": 0, "camel_21641": 0, "camel_23942": 0, "camel_38609": 0, "camel_22397": 0, "camel_21664": 0, "camel_23938": 0, "camel_39997": 0, "camel_39957": 0, "camel_23971": 0, "camel_23930": 0, "camel_38569": 0, "camel_23983": 0, "camel_23968": 0, "camel_22031": 0, "camel_23193": 0, "camel_22041": 0, "camel_21607": 0, "camel_22277": 0, "camel_22069": 0, "camel_23127": 0, "camel_22040": 0, "camel_23960": 0, "camel_39928": 0, "camel_22467": 0, "camel_22015": 0, "camel_22060": 0, "camel_22071": 0, "camel_39974": 0, "aqua_rat_33603": 0.7955384850502014, "aqua_rat_34441": 0.7964475154876709, "gsm_rft_23948": 0.7977973818778992, "gsm_rft_13642": 0.7979393601417542, "gsm_train_24319": 0.7979393601417542, "aqua_rat_18852": 0.7985876798629761, "gsm_rft_30826": 0.7986790537834167, "gsm_rft_11706": 0.798952043056488, "aqua_rat_20425": 0.7994187474250793, "gsm_rft_12390": 0.7999804615974426, "gsm_rft_30590": 0.8003906607627869, "gsm_rft_30931": 0.8004384636878967, "aqua_rat_67605": 0.8007004261016846, "aqua_rat_43370": 0.8013173937797546, "gsm_rft_9082": 0.8013597726821899, "aqua_rat_56385": 0.8016172647476196, "gsm_rft_339": 0.8029698133468628, "camel_36749": 0.8043375611305237, "aqua_rat_44391": 0.8050205111503601, "aqua_rat_44895": 0.8109802007675171, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": 0.8122172951698303, "aqua_rat_41715": 0.812230110168457, "camel_36503": 0.835271954536438, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0.8469263315200806, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0.8509713411331177}, "TheoremQA_elainewan/econ_micro_7.json": {"camel_25263": 0, "camel_24669": 0, "camel_25343": 0, "camel_25356": 0, "camel_24197": 0, "camel_24443": 0, "camel_25257": 0, "camel_25126": 0, "camel_25686": 0, "camel_24667": 0, "camel_24316": 0, "camel_24331": 0, "camel_25892": 0, "camel_25958": 0, "camel_24690": 0, "camel_25283": 0, "camel_25112": 0, "camel_25292": 0, "camel_24713": 0, "camel_24663": 0, "camel_25341": 0, "camel_25198": 0, "camel_24688": 0, "camel_25159": 0, "camel_24339": 0, "camel_25488": 0, "camel_24650": 0, "camel_25270": 0, "camel_24657": 0, "camel_25805": 0, "camel_24702": 0, "camel_24259": 0, "camel_25279": 0, "camel_25125": 0, "camel_24647": 0, "camel_24235": 0, "camel_25278": 0, "camel_24658": 0, "camel_24686": 0, "camel_25291": 0, "camel_25176": 0, "camel_25693": 0, "camel_24369": 0, "camel_24670": 0, "camel_25721": 0, "camel_25219": 0, "camel_24273": 0, "camel_25109": 0, "camel_24462": 0, "camel_25168": 0, "camel_25224": 0, "camel_25188": 0, "camel_24368": 0, "camel_24665": 0, "camel_24303": 0, "camel_25414": 0, "camel_25043": 0, "camel_25256": 0, "camel_25021": 0, "camel_25321": 0, "camel_24717": 0, "camel_25307": 0, "camel_24684": 0, "camel_24291": 0, "camel_25243": 0, "camel_25513": 0, "camel_25332": 0, "camel_25863": 0, "camel_24664": 0, "camel_24676": 0, "camel_25156": 0, "camel_25226": 0, "camel_25337": 0, "camel_24653": 0, "camel_25152": 0, "camel_25501": 0, "camel_25305": 0, "camel_25349": 0, "camel_25244": 0, "camel_25302": 0, "camel_24649": 0, "camel_25322": 0, "camel_25470": 0, "camel_25334": 0, "camel_24666": 0, "camel_25121": 0, "camel_25357": 0, "camel_25335": 0, "camel_25181": 0, "camel_25227": 0, "camel_25496": 0, "camel_24648": 0, "TheoremQA_elainewan/econ_micro_7.json": 0, "camel_25214": 0, "camel_24708": 0, "camel_24715": 0, "camel_25225": 0, "camel_25230": 0, "camel_24644": 0, "camel_25212": 0, "camel_25688": 0, "camel_24707": 0, "camel_24655": 0, "camel_25239": 0, "camel_24691": 0, "camel_25299": 0, "camel_25464": 0, "camel_25316": 0, "camel_24467": 0, "camel_25367": 0, "camel_24694": 0, "camel_25282": 0, "camel_25185": 0, "camel_24687": 0, "camel_25241": 0, "camel_25314": 0, "camel_25171": 0, "camel_25287": 0, "camel_24672": 0, "camel_24656": 0, "camel_25318": 0, "camel_24652": 0, "camel_25446": 0, "camel_24706": 0, "camel_25359": 0, "camel_24242": 0, "camel_36361": 0.7665559649467468, "gsm_rft_28392": 0.766707181930542, "camel_38689": 0.7667460441589355, "camel_10439": 0.7669724822044373, "camel_39434": 0.7671773433685303, "camel_10491": 0.7683489918708801, "camel_39415": 0.7686843276023865, "camel_37758": 0.7689464092254639, "gsm_rft_32682": 0.7702630162239075, "camel_37696": 0.771984338760376, "camel_10499": 0.7725449800491333, "camel_37680": 0.7727875709533691, "camel_37724": 0.7730497121810913, "camel_39432": 0.7731871604919434, "camel_37721": 0.7739562392234802, "camel_10493": 0.7743781208992004, "camel_10532": 0.7745909094810486, "camel_10537": 0.7750070095062256, "camel_37682": 0.7753649950027466, "camel_37736": 0.7760317921638489, "camel_37723": 0.7761388421058655, "camel_37692": 0.7763852477073669, "camel_37757": 0.7765102982521057, "camel_37685": 0.7765121459960938, "camel_10517": 0.7772262096405029, "camel_37646": 0.7772353887557983, "camel_37709": 0.7776963710784912, "camel_10545": 0.7776965498924255, "camel_10551": 0.7778223156929016, "camel_37687": 0.7791667580604553, "camel_37729": 0.7792371511459351, "camel_37718": 0.7795728445053101, "camel_37704": 0.7797262668609619, "camel_37745": 0.7800115942955017, "camel_37725": 0.7804154753684998, "camel_10305": 0.7816417217254639, "camel_10462": 0.7827171683311462, "camel_37742": 0.7829890847206116, "camel_10284": 0.7830260992050171, "camel_37756": 0.7836336493492126, "camel_37618": 0.7841810584068298, "camel_37648": 0.7844293713569641, "camel_37740": 0.784567654132843, "camel_37752": 0.784761369228363, "camel_37635": 0.7857732176780701, "camel_37701": 0.7858257293701172, "camel_10240": 0.7862474918365479, "camel_37684": 0.7868697643280029, "camel_37683": 0.787361204624176, "camel_37730": 0.7880541086196899, "camel_37710": 0.7882477641105652, "camel_37750": 0.7889519929885864, "camel_39399": 0.7891146540641785, "camel_37691": 0.789747416973114, "camel_37703": 0.7901325821876526, "camel_37708": 0.7905052304267883, "camel_37693": 0.7907760143280029, "camel_37751": 0.7908368706703186, "camel_37749": 0.7909607887268066, "camel_37700": 0.7913620471954346, "camel_38662": 0.7922827005386353, "camel_37697": 0.7945820689201355, "camel_37699": 0.7949346303939819, "camel_37716": 0.7968384623527527, "camel_37744": 0.7982057929039001, "camel_37706": 0.8007229566574097, "camel_37738": 0.8014525175094604, "TheoremQA_elainewan/econ_micro_7_2.json": 0.8026478886604309, "camel_37651": 0.803988516330719, "camel_37669": 0.8053568601608276, "camel_39397": 0.8071423172950745, "TheoremQA_elainewan/econ_micro_18.json": 0.8072291016578674, "camel_37629": 0.8108060359954834, "camel_37741": 0.8163987994194031}, "TheoremQA_xinyi/dag_2.json": {"camel_23067": 0, "camel_23672": 0, "camel_23056": 0, "camel_23161": 0, "camel_21846": 0, "camel_22403": 0, "camel_22442": 0, "camel_23112": 0, "camel_23423": 0, "camel_22579": 0, "camel_23424": 0, "camel_22466": 0, "camel_23109": 0, "camel_23078": 0, "camel_23097": 0, "camel_23924": 0, "camel_23306": 0, "camel_22876": 0, "camel_22843": 0, "camel_22694": 0, "camel_22672": 0, "camel_23988": 0, "camel_22400": 0, "camel_23198": 0, "camel_23921": 0, "camel_22664": 0, "camel_23955": 0, "camel_23106": 0, "camel_22855": 0, "camel_23165": 0, "camel_23164": 0, "camel_22422": 0, "camel_23281": 0, "camel_22824": 0, "camel_22819": 0, "camel_22854": 0, "camel_22391": 0, "camel_22826": 0, "camel_22417": 0, "camel_22862": 0, "camel_22360": 0, "camel_22863": 0, "camel_23285": 0, "camel_22841": 0, "camel_23174": 0, "camel_22378": 0, "camel_23059": 0, "camel_23949": 0, "camel_23308": 0, "camel_23065": 0, "camel_23119": 0, "camel_22828": 0, "camel_23994": 0, "camel_22711": 0, "camel_22022": 0, "camel_23990": 0, "camel_22806": 0, "camel_23984": 0, "camel_23177": 0, "camel_22398": 0, "camel_22940": 0, "camel_22583": 0, "camel_23083": 0, "camel_23179": 0, "camel_21051": 0, "camel_22628": 0, "camel_23335": 0, "camel_23072": 0, "camel_23062": 0, "camel_23959": 0, "camel_22702": 0, "camel_23073": 0, "camel_22949": 0, "camel_23982": 0, "camel_23938": 0, "camel_22870": 0, "camel_22361": 0, "camel_22443": 0, "camel_22345": 0, "camel_22853": 0, "camel_23973": 0, "camel_23945": 0, "camel_22803": 0, "camel_23158": 0, "camel_22844": 0, "camel_22832": 0, "camel_23196": 0, "camel_22433": 0, "camel_22573": 0, "camel_23934": 0, "camel_23068": 0, "camel_22879": 0, "camel_22816": 0, "TheoremQA_xinyi/dag_2.json": 0, "camel_23920": 0, "camel_23931": 0, "camel_23114": 0, "camel_23926": 0, "camel_22866": 0, "camel_23999": 0, "camel_23131": 0, "camel_23935": 0, "camel_22053": 0, "camel_23090": 0, "camel_23933": 0, "camel_23976": 0, "camel_23969": 0, "camel_22435": 0, "camel_23975": 0, "camel_23971": 0, "camel_22867": 0, "camel_23928": 0, "camel_22068": 0, "camel_22432": 0, "camel_22061": 0, "camel_23944": 0, "camel_22462": 0, "camel_22868": 0, "camel_22440": 0, "camel_23966": 0, "camel_22461": 0, "camel_22805": 0, "camel_23985": 0, "camel_23989": 0, "camel_23940": 0, "camel_22807": 0, "camel_22847": 0, "camel_22823": 0, "camel_23972": 0, "camel_23117": 0, "camel_23085": 0, "camel_23301": 0, "camel_22463": 0, "camel_23995": 0, "camel_23354": 0, "camel_23093": 0, "camel_22170": 0, "camel_23192": 0, "camel_23189": 0, "camel_22335": 0, "camel_22397": 0, "camel_23075": 0, "camel_23181": 0, "camel_23325": 0, "camel_22808": 0, "camel_23952": 0, "camel_23400": 0, "camel_23364": 0, "camel_23977": 0, "camel_23127": 0, "camel_23941": 0, "camel_22585": 0, "camel_23963": 0, "camel_23993": 0, "camel_23997": 0, "camel_23939": 0, "camel_23103": 0, "camel_23948": 0, "camel_22457": 0, "camel_23996": 0, "camel_23983": 0, "camel_23946": 0, "camel_23954": 0, "camel_23978": 0, "camel_23105": 0, "camel_23932": 0, "camel_23057": 0, "camel_23942": 0, "camel_23986": 0, "camel_23960": 0, "camel_22467": 0, "camel_23951": 0, "camel_23060": 0, "camel_23922": 0, "camel_23998": 0, "camel_23958": 0, "camel_23193": 0, "camel_23923": 0, "camel_23968": 0, "camel_19957": 0.6715482473373413, "aqua_rat_56101": 0.671664834022522, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0.6719099879264832, "camel_36903": 0.6728096604347229, "aqua_rat_116": 0.6733112931251526, "aqua_rat_72283": 0.6737870573997498, "aqua_rat_44391": 0.6752562522888184, "aqua_rat_67605": 0.6757302284240723, "camel_18621": 0.6757848858833313, "camel_36749": 0.6759950518608093, "aqua_rat_41715": 0.6783993244171143, "camel_36805": 0.6794455051422119, "aqua_rat_27369": 0.6801481246948242, "camel_36503": 0.6820446252822876, "camel_36422": 0.6858373284339905, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0.6864084005355835, "aqua_rat_35578": 0.6872867941856384, "aqua_rat_38316": 0.7026883959770203, "aqua_rat_44063": 0.7050493955612183, "TheoremQA_xinyi/dag_3.json": 0.7677187919616699, "TheoremQA_xinyi/dag_1.json": 0.7778206467628479}, "TheoremQA_tonyxia/particle6.json": {"TheoremQA_tonyxia/particle6.json": 0, "aqua_rat_84303": 0.6554186940193176, "aqua_rat_31245": 0.6554635763168335, "aqua_rat_47932": 0.6555888056755066, "aqua_rat_25543": 0.6556880474090576, "aqua_rat_26789": 0.6557518839836121, "gsm_rft_18251": 0.6558095812797546, "aqua_rat_87372": 0.6558899283409119, "aqua_rat_58589": 0.6559128761291504, "aqua_rat_73701": 0.6559220552444458, "aqua_rat_81870": 0.6559291481971741, "aqua_rat_8539": 0.6560275554656982, "aqua_rat_42126": 0.6560478806495667, "aqua_rat_62339": 0.6561480164527893, "aqua_rat_15617": 0.6562179327011108, "aqua_rat_21246": 0.6562475562095642, "aqua_rat_54920": 0.6566967368125916, "aqua_rat_52996": 0.6567111611366272, "aqua_rat_44499": 0.6567515134811401, "aqua_rat_74631": 0.6568171381950378, "camel_17559": 0.6568861603736877, "aqua_rat_70457": 0.6569674611091614, "aqua_rat_48558": 0.6571208834648132, "aqua_rat_10943": 0.6571271419525146, "gsm_rft_34630": 0.6571753025054932, "aqua_rat_77554": 0.6572498083114624, "aqua_rat_18744": 0.6572921872138977, "aqua_rat_50146": 0.6574854254722595, "aqua_rat_21382": 0.6575272083282471, "gsm_train_18003": 0.6577345132827759, "gsm_rft_24790": 0.6577345132827759, "gsm_rft_25136": 0.6577345132827759, "aqua_rat_65241": 0.6581857800483704, "aqua_rat_31403": 0.658195436000824, "gsm_rft_24978": 0.6583477258682251, "camel_7956": 0.6584256291389465, "aqua_rat_84200": 0.6585360765457153, "aqua_rat_45652": 0.6585569381713867, "aqua_rat_6129": 0.6588177680969238, "aqua_rat_12340": 0.6589270234107971, "gsm_rft_29129": 0.6590144038200378, "aqua_rat_48273": 0.6590153574943542, "aqua_rat_38375": 0.6592576503753662, "aqua_rat_82624": 0.6593770980834961, "aqua_rat_78876": 0.6594661474227905, "aqua_rat_78218": 0.6596722602844238, "camel_7937": 0.6597026586532593, "gsm_rft_15416": 0.6597232818603516, "aqua_rat_82501": 0.6598786115646362, "aqua_rat_88921": 0.6599463820457458, "aqua_rat_71204": 0.659950852394104, "gsm_train_2068": 0.6599960327148438, "gsm_rft_4583": 0.6599960327148438, "gsm_rft_24421": 0.6600900888442993, "aqua_rat_19425": 0.6603603959083557, "gsm_rft_16695": 0.6603876352310181, "aqua_rat_42716": 0.6604155898094177, "camel_36247": 0.6605016589164734, "camel_7945": 0.660529375076294, "camel_28656": 0.6609070301055908, "aqua_rat_14541": 0.6609398126602173, "camel_36263": 0.6610507369041443, "gsm_rft_35619": 0.6612042784690857, "camel_39446": 0.6612111330032349, "camel_24382": 0.661413311958313, "aqua_rat_34706": 0.6615043878555298, "gsm_rft_2271": 0.6615851521492004, "aqua_rat_55232": 0.6620119214057922, "aqua_rat_32521": 0.6622771620750427, "aqua_rat_6964": 0.6628164649009705, "aqua_rat_35905": 0.6632649302482605, "aqua_rat_79832": 0.6633315682411194, "camel_28847": 0.6635991930961609, "aqua_rat_67115": 0.6636714339256287, "aqua_rat_4346": 0.6639419794082642, "aqua_rat_6768": 0.6639761924743652, "aqua_rat_85851": 0.6640716195106506, "aqua_rat_64606": 0.664077639579773, "aqua_rat_25846": 0.6642761826515198, "camel_39514": 0.6642851829528809, "gsm_rft_6656": 0.6644025444984436, "gsm_train_31725": 0.6644025444984436, "gsm_rft_24796": 0.6648306846618652, "camel_36254": 0.6648421287536621, "gsm_rft_7812": 0.6649147868156433, "aqua_rat_78209": 0.6649273037910461, "aqua_rat_62486": 0.6650199890136719, "aqua_rat_7671": 0.6650329828262329, "gsm_rft_6897": 0.6651614904403687, "gsm_train_21544": 0.6653022766113281, "camel_39462": 0.6654499769210815, "gsm_rft_22887": 0.6654977798461914, "aqua_rat_37341": 0.6655141115188599, "aqua_rat_81900": 0.6655412316322327, "aqua_rat_59271": 0.6657458543777466, "aqua_rat_86305": 0.6657949090003967, "camel_7984": 0.6660360097885132, "aqua_rat_20614": 0.6660476326942444, "aqua_rat_73742": 0.6661531925201416, "aqua_rat_72645": 0.666304886341095, "aqua_rat_41552": 0.6663890480995178, "aqua_rat_47505": 0.6665961742401123, "aqua_rat_48679": 0.6666483283042908, "aqua_rat_12658": 0.6667323112487793, "camel_7982": 0.6669207215309143, "aqua_rat_30607": 0.6669554710388184, "aqua_rat_55904": 0.6669787764549255, "aqua_rat_26179": 0.6672966480255127, "aqua_rat_81927": 0.6674945950508118, "aqua_rat_33317": 0.6676381230354309, "aqua_rat_63443": 0.6676557064056396, "aqua_rat_54663": 0.6677122712135315, "aqua_rat_74682": 0.6678775548934937, "aqua_rat_8426": 0.6680718660354614, "aqua_rat_56182": 0.6682805418968201, "aqua_rat_22263": 0.6683108806610107, "aqua_rat_5161": 0.6684541702270508, "aqua_rat_30868": 0.6686604619026184, "aqua_rat_15984": 0.6687389016151428, "aqua_rat_30731": 0.6687736511230469, "aqua_rat_53685": 0.6690002679824829, "aqua_rat_37623": 0.6690314412117004, "aqua_rat_51819": 0.6690386533737183, "aqua_rat_8080": 0.6691737174987793, "aqua_rat_72145": 0.6692125797271729, "gsm_rft_11389": 0.669295072555542, "aqua_rat_64399": 0.6693310141563416, "aqua_rat_50655": 0.6694458723068237, "aqua_rat_3796": 0.6696129441261292, "aqua_rat_72791": 0.66962069272995, "aqua_rat_54005": 0.6697078347206116, "aqua_rat_69977": 0.6697525382041931, "aqua_rat_12925": 0.6698493361473083, "aqua_rat_48959": 0.669853925704956, "gsm_rft_22533": 0.6699267029762268, "aqua_rat_56051": 0.6700472235679626, "aqua_rat_3859": 0.6700904965400696, "aqua_rat_11683": 0.6702250242233276, "aqua_rat_67295": 0.670432984828949, "aqua_rat_47775": 0.670963704586029, "aqua_rat_65198": 0.6711171865463257, "aqua_rat_20452": 0.6712541580200195, "camel_39485": 0.6712625026702881, "aqua_rat_32616": 0.6712626218795776, "aqua_rat_6188": 0.6713421940803528, "aqua_rat_20870": 0.6713496446609497, "aqua_rat_16681": 0.6713557243347168, "aqua_rat_80680": 0.6716774702072144, "aqua_rat_63465": 0.6720793843269348, "aqua_rat_75129": 0.6721818447113037, "aqua_rat_15732": 0.6722007393836975, "aqua_rat_47750": 0.6723418235778809, "gsm_rft_22397": 0.6724993586540222, "aqua_rat_82115": 0.6726918816566467, "aqua_rat_62767": 0.6728171110153198, "aqua_rat_28523": 0.6730080842971802, "aqua_rat_3432": 0.6731971502304077, "camel_7951": 0.6733278632164001, "aqua_rat_83605": 0.6735994815826416, "aqua_rat_197": 0.6738377213478088, "aqua_rat_25154": 0.6739046573638916, "aqua_rat_58051": 0.6742455363273621, "aqua_rat_7651": 0.6744397878646851, "aqua_rat_16975": 0.6745773553848267, "camel_39452": 0.6746886372566223, "aqua_rat_85422": 0.6752033233642578, "camel_24344": 0.6756234765052795, "aqua_rat_47058": 0.6757225394248962, "aqua_rat_10204": 0.6762173175811768, "aqua_rat_11192": 0.6769903302192688, "aqua_rat_56584": 0.6780113577842712, "aqua_rat_83526": 0.678575336933136, "aqua_rat_20932": 0.6787357926368713, "gsm_rft_10505": 0.6787756681442261, "aqua_rat_61332": 0.6791799068450928, "gsm_train_29099": 0.6793041229248047, "gsm_rft_17764": 0.6793041229248047, "TheoremQA_xinyi/work_energy_theorem.json": 0.6796268224716187, "aqua_rat_61971": 0.6804729700088501, "camel_39513": 0.680819571018219, "TheoremQA_tonyxia/relativity3.json": 0.6811354756355286, "aqua_rat_36249": 0.6816892623901367, "gsm_rft_35145": 0.6819450855255127, "aqua_rat_71816": 0.6825056672096252, "camel_28846": 0.6827917098999023, "aqua_rat_43435": 0.6839426755905151, "aqua_rat_70812": 0.685028076171875, "aqua_rat_36957": 0.6852638721466064, "aqua_rat_9493": 0.685425341129303, "aqua_rat_12010": 0.6881896257400513, "TheoremQA_xinyi/momentum.json": 0.6907547116279602, "aqua_rat_41482": 0.6915912628173828, "aqua_rat_54375": 0.6929192543029785, "aqua_rat_57727": 0.6934171319007874, "aqua_rat_73760": 0.695935070514679, "camel_17811": 0.6974334120750427, "aqua_rat_11549": 0.6982396245002747, "TheoremQA_tonyxia/particle5.json": 0.7001457810401917, "TheoremQA_tonyxia/nuclear3.json": 0.7287417650222778, "TheoremQA_tonyxia/particle4.json": 0.8702981472015381}, "TheoremQA_tonyxia/semiconductor3.json": {"TheoremQA_tonyxia/semiconductor3.json": 0, "aqua_rat_64322": 0.6569896936416626, "gsm_rft_22763": 0.6570523381233215, "gsm_rft_1976": 0.6570921540260315, "gsm_train_9769": 0.6570921540260315, "gsm_rft_1995": 0.6571258306503296, "gsm_train_9463": 0.6571258306503296, "gsm_rft_8537": 0.6571590304374695, "camel_40967": 0.6572175621986389, "gsm_rft_26150": 0.6572567820549011, "gsm_rft_8542": 0.6573743224143982, "gsm_train_23183": 0.6573807597160339, "gsm_rft_2576": 0.6573817133903503, "gsm_rft_8266": 0.6573817133903503, "gsm_rft_1199": 0.6573914885520935, "gsm_rft_16794": 0.6574921011924744, "gsm_train_14001": 0.6574921011924744, "camel_37980": 0.6575169563293457, "camel_39513": 0.6575521230697632, "gsm_rft_28746": 0.6576642394065857, "gsm_rft_10259": 0.6576745510101318, "gsm_train_12141": 0.6576745510101318, "gsm_train_30526": 0.657699465751648, "gsm_train_28661": 0.657706081867218, "gsm_rft_21153": 0.657706081867218, "gsm_rft_6323": 0.6577699184417725, "camel_44806": 0.6577883362770081, "aqua_rat_65009": 0.6577886343002319, "gsm_rft_31297": 0.6579021215438843, "gsm_rft_33525": 0.6579049825668335, "gsm_rft_26670": 0.6579208970069885, "gsm_train_15192": 0.6579260230064392, "gsm_rft_1637": 0.6579467058181763, "gsm_rft_23547": 0.6581659317016602, "gsm_train_13099": 0.6581659317016602, "aqua_rat_76514": 0.6581739783287048, "aqua_rat_88438": 0.6582106351852417, "gsm_rft_4796": 0.6582359075546265, "gsm_rft_26897": 0.6583064794540405, "camel_45018": 0.6583133935928345, "gsm_rft_13049": 0.6583227515220642, "gsm_rft_13516": 0.6583707332611084, "gsm_rft_21936": 0.6584702134132385, "gsm_rft_34034": 0.6586163640022278, "camel_28656": 0.6586238741874695, "aqua_rat_19705": 0.6586607694625854, "gsm_rft_9690": 0.6587852239608765, "gsm_train_33930": 0.6588042974472046, "gsm_rft_4113": 0.6588042974472046, "gsm_rft_7238": 0.6588108539581299, "gsm_rft_34703": 0.6588451266288757, "gsm_rft_31779": 0.6588871479034424, "gsm_rft_29094": 0.6590542793273926, "gsm_rft_1175": 0.6590542793273926, "gsm_rft_18587": 0.6594116687774658, "gsm_rft_29036": 0.6594116687774658, "gsm_train_16078": 0.6594116687774658, "gsm_rft_28164": 0.6594120264053345, "gsm_rft_23218": 0.6594799160957336, "camel_16680": 0.6596900224685669, "camel_37933": 0.6598407030105591, "gsm_rft_13386": 0.659900426864624, "gsm_train_5776": 0.659947395324707, "gsm_rft_89": 0.659947395324707, "gsm_train_33556": 0.6600949764251709, "gsm_rft_34955": 0.6600949764251709, "aqua_rat_48599": 0.6601542234420776, "gsm_rft_21021": 0.6602324843406677, "gsm_rft_31337": 0.6602627635002136, "gsm_rft_33921": 0.6603803634643555, "gsm_rft_23860": 0.6604967713356018, "gsm_train_14804": 0.6605442762374878, "gsm_rft_29362": 0.6606819033622742, "gsm_train_6688": 0.6607398986816406, "gsm_rft_16537": 0.6607398986816406, "aqua_rat_6188": 0.6608006358146667, "aqua_rat_24258": 0.6608198285102844, "gsm_rft_24775": 0.6608201265335083, "gsm_rft_2099": 0.6609209775924683, "aqua_rat_20090": 0.6609228849411011, "gsm_train_31158": 0.6609746217727661, "gsm_rft_1939": 0.6609746217727661, "gsm_rft_6176": 0.6609936952590942, "gsm_rft_13505": 0.6610673666000366, "gsm_rft_1552": 0.6611073017120361, "TheoremQA_tonyxia/particle4.json": 0.6611555814743042, "gsm_rft_25705": 0.6612138748168945, "gsm_rft_33460": 0.6614401340484619, "gsm_rft_35411": 0.6614401340484619, "gsm_rft_6932": 0.6614762544631958, "gsm_rft_10891": 0.6614959836006165, "gsm_rft_35481": 0.6615229249000549, "gsm_rft_17640": 0.6615891456604004, "gsm_rft_33825": 0.6615978479385376, "camel_36502": 0.6616576910018921, "gsm_train_11585": 0.6617265939712524, "gsm_rft_34961": 0.6620584726333618, "gsm_rft_28561": 0.6622318029403687, "gsm_rft_7433": 0.6622318029403687, "gsm_train_11581": 0.6622318029403687, "gsm_rft_18991": 0.6622464060783386, "gsm_train_13754": 0.6622464060783386, "gsm_rft_10767": 0.6624023914337158, "camel_41027": 0.6624182462692261, "gsm_rft_1756": 0.6624298691749573, "gsm_rft_1719": 0.6624387502670288, "gsm_train_7082": 0.6624387502670288, "aqua_rat_12257": 0.6624438166618347, "gsm_rft_15764": 0.6624670624732971, "gsm_train_9534": 0.6624670624732971, "gsm_train_6841": 0.6625243425369263, "gsm_rft_25245": 0.6626137495040894, "gsm_rft_3208": 0.6627872586250305, "gsm_rft_13988": 0.6629672646522522, "gsm_rft_1443": 0.6629672646522522, "gsm_rft_11809": 0.6630048751831055, "gsm_train_22833": 0.6632275581359863, "gsm_rft_29438": 0.6634725332260132, "gsm_rft_32571": 0.6634725332260132, "gsm_rft_28078": 0.6639463305473328, "gsm_rft_2782": 0.6639907956123352, "gsm_rft_23036": 0.6640811562538147, "gsm_train_5164": 0.6642503142356873, "gsm_train_4698": 0.6644166707992554, "camel_36593": 0.6644973158836365, "aqua_rat_73083": 0.664722740650177, "gsm_rft_14007": 0.6650073528289795, "gsm_rft_11805": 0.6650440692901611, "gsm_rft_32487": 0.6652114987373352, "gsm_train_22269": 0.6652114987373352, "gsm_rft_33600": 0.6652458906173706, "gsm_rft_22305": 0.6662494540214539, "gsm_rft_34322": 0.6664862632751465, "aqua_rat_66054": 0.666490912437439, "gsm_rft_21179": 0.6669229865074158, "aqua_rat_36335": 0.6678686141967773, "gsm_rft_8990": 0.667940616607666, "gsm_train_7372": 0.667940616607666, "gsm_rft_24796": 0.6684048175811768, "gsm_rft_33471": 0.6684557199478149, "gsm_train_20762": 0.6687104105949402, "gsm_rft_34235": 0.6689627766609192, "camel_16209": 0.6690004467964172, "camel_45174": 0.6692406535148621, "gsm_rft_15366": 0.6699215769767761, "camel_17587": 0.6714870929718018, "TheoremQA_tonyxia/statisticalphysics5.json": 0.6721397042274475, "gsm_rft_22401": 0.6727863550186157, "camel_45159": 0.6728878021240234, "gsm_rft_23432": 0.6731771230697632, "gsm_train_18124": 0.6732698082923889, "gsm_rft_15582": 0.6732698082923889, "gsm_rft_18008": 0.6734120845794678, "gsm_rft_13831": 0.6734333038330078, "gsm_train_9951": 0.6734333038330078, "gsm_rft_14462": 0.6735159754753113, "gsm_rft_19423": 0.6735159754753113, "gsm_train_15924": 0.6735159754753113, "gsm_rft_13903": 0.6735429763793945, "gsm_train_33849": 0.6737822890281677, "camel_39482": 0.6737962365150452, "gsm_rft_9719": 0.6738070249557495, "camel_16682": 0.6751997470855713, "gsm_rft_27207": 0.6755914092063904, "gsm_rft_24668": 0.6756589412689209, "gsm_rft_23914": 0.6763857007026672, "camel_16223": 0.6766154170036316, "gsm_train_4193": 0.676896333694458, "gsm_rft_6591": 0.676896333694458, "camel_16712": 0.6776715517044067, "gsm_rft_21326": 0.6777570247650146, "gsm_rft_14572": 0.6784993410110474, "gsm_train_31881": 0.6784993410110474, "gsm_rft_33507": 0.6784993410110474, "gsm_rft_11166": 0.6784993410110474, "gsm_rft_20711": 0.6789012551307678, "gsm_rft_10742": 0.6792312860488892, "gsm_train_28209": 0.6792312860488892, "gsm_rft_32833": 0.6793502569198608, "gsm_rft_28624": 0.6794840097427368, "camel_38919": 0.6803640127182007, "gsm_rft_21213": 0.68513423204422, "gsm_rft_35104": 0.6861900687217712, "gsm_train_10153": 0.6861918568611145, "TheoremQA_tonyxia/nuclear3.json": 0.6870673894882202, "gsm_rft_17141": 0.6873633861541748, "camel_16674": 0.6874303221702576, "gsm_train_1174": 0.6876873970031738, "gsm_rft_33186": 0.6876873970031738, "camel_16681": 0.6902962327003479, "camel_45075": 0.6914670467376709, "camel_17811": 0.6914819478988647, "gsm_rft_26010": 0.6937299370765686, "gsm_rft_28497": 0.6960788369178772, "gsm_train_18516": 0.6960788369178772, "gsm_rft_33530": 0.6965175867080688, "gsm_rft_10110": 0.699313223361969, "camel_45935": 0.7017814517021179, "TheoremQA_tonyxia/photoelectric1.json": 0.7229832410812378, "TheoremQA_tonyxia/semiconductor2.json": 0.805797278881073}, "TheoremQA_tonyxia/statisticalphysics2.json": {"TheoremQA_tonyxia/statisticalphysics2.json": 0, "camel_39482": 0.6425241231918335, "camel_39485": 0.6426975131034851, "gsm_rft_29098": 0.6428155899047852, "gsm_rft_20909": 0.6428422927856445, "camel_7956": 0.642857551574707, "gsm_rft_24796": 0.6428658962249756, "gsm_rft_15576": 0.6428658962249756, "camel_7995": 0.6429235339164734, "gsm_rft_12897": 0.6429574489593506, "gsm_rft_33134": 0.6430756449699402, "camel_28812": 0.6431927680969238, "gsm_train_11436": 0.6432793736457825, "camel_39513": 0.6433330774307251, "aqua_rat_58981": 0.6433968544006348, "gsm_rft_29554": 0.6435444355010986, "gsm_rft_17654": 0.6436291337013245, "aqua_rat_24258": 0.6439214944839478, "TheoremQA_panlu/molar_heat_capacity1.json": 0.643963634967804, "aqua_rat_48599": 0.6440491080284119, "gsm_rft_26348": 0.6440620422363281, "camel_39514": 0.6441752314567566, "aqua_rat_46594": 0.644626259803772, "gsm_rft_57": 0.6446880102157593, "camel_41002": 0.6446932554244995, "aqua_rat_71372": 0.6447896957397461, "gsm_rft_18983": 0.6448253989219666, "gsm_rft_28418": 0.6449845433235168, "aqua_rat_69157": 0.6450831294059753, "gsm_rft_22127": 0.6450944542884827, "gsm_rft_28086": 0.6450999975204468, "gsm_rft_2152": 0.6451568007469177, "camel_41021": 0.6452478766441345, "gsm_rft_10274": 0.6453328728675842, "gsm_train_11745": 0.6453328728675842, "aqua_rat_74394": 0.6453339457511902, "gsm_rft_13637": 0.6454179286956787, "gsm_train_9384": 0.6454179286956787, "gsm_rft_26085": 0.6454907655715942, "gsm_rft_29319": 0.6455463171005249, "gsm_rft_6327": 0.6455879211425781, "gsm_rft_32183": 0.6457057595252991, "gsm_train_33171": 0.6457504034042358, "gsm_rft_31420": 0.6457508206367493, "camel_28122": 0.645841121673584, "camel_17913": 0.645886242389679, "aqua_rat_73083": 0.6459054946899414, "camel_28024": 0.6459408402442932, "gsm_rft_10110": 0.6459789276123047, "gsm_rft_12069": 0.6460281014442444, "aqua_rat_2689": 0.646083652973175, "gsm_train_24172": 0.6460902690887451, "aqua_rat_70170": 0.6463666558265686, "camel_28149": 0.64640873670578, "aqua_rat_32927": 0.6464127898216248, "gsm_rft_13635": 0.6464857459068298, "gsm_rft_34703": 0.6465345025062561, "aqua_rat_15183": 0.6466043591499329, "gsm_rft_21929": 0.6467012763023376, "camel_16249": 0.6467767953872681, "gsm_rft_29034": 0.6467783451080322, "gsm_train_13099": 0.6467844247817993, "gsm_rft_23547": 0.6467844247817993, "gsm_rft_22705": 0.6467867493629456, "gsm_rft_26897": 0.6467982530593872, "aqua_rat_42126": 0.6468029618263245, "aqua_rat_38595": 0.6468388438224792, "camel_7984": 0.6468441486358643, "gsm_rft_12882": 0.6470696926116943, "camel_39452": 0.6470716595649719, "gsm_rft_22305": 0.6471568942070007, "camel_7925": 0.6474975347518921, "camel_40967": 0.6475069522857666, "gsm_rft_12169": 0.6475261449813843, "gsm_rft_28920": 0.6475261449813843, "camel_40971": 0.6476674675941467, "camel_17845": 0.6479524970054626, "gsm_rft_18209": 0.6479828357696533, "camel_7991": 0.6480414867401123, "gsm_rft_31297": 0.6480624079704285, "aqua_rat_64101": 0.6480711698532104, "gsm_rft_11471": 0.6481088995933533, "gsm_rft_13505": 0.6483203172683716, "gsm_rft_7832": 0.6485640406608582, "gsm_train_8091": 0.648607075214386, "gsm_rft_10767": 0.6486129760742188, "gsm_rft_20590": 0.6486215591430664, "gsm_rft_6094": 0.6487727165222168, "aqua_rat_827": 0.6487829089164734, "aqua_rat_67622": 0.6488386988639832, "gsm_rft_17141": 0.6490280032157898, "aqua_rat_81764": 0.6491013765335083, "gsm_rft_35379": 0.6491103172302246, "gsm_rft_23458": 0.6491201519966125, "gsm_rft_33186": 0.6493644118309021, "gsm_train_1174": 0.6493644118309021, "TheoremQA_tonyxia/particle4.json": 0.6494795680046082, "gsm_rft_13049": 0.6494833827018738, "gsm_train_7372": 0.6498191356658936, "gsm_rft_8990": 0.6498191356658936, "aqua_rat_80111": 0.650105357170105, "gsm_rft_8703": 0.6503846645355225, "gsm_rft_18917": 0.6505228877067566, "gsm_rft_23718": 0.6505228877067566, "gsm_train_28914": 0.6505228877067566, "gsm_rft_30177": 0.6505772471427917, "gsm_rft_22946": 0.6509249806404114, "aqua_rat_75331": 0.6513486504554749, "gsm_rft_13820": 0.6514027118682861, "gsm_rft_882": 0.6517140865325928, "aqua_rat_39716": 0.6517641544342041, "gsm_rft_21897": 0.6517873406410217, "gsm_rft_10026": 0.6518805027008057, "aqua_rat_21090": 0.6520187854766846, "gsm_rft_2592": 0.6520894765853882, "camel_16223": 0.6521635055541992, "camel_16522": 0.6523666977882385, "gsm_rft_26756": 0.6526620388031006, "gsm_rft_3972": 0.6526810526847839, "TheoremQA_tonyxia/wave2.json": 0.6527498960494995, "camel_16209": 0.653077244758606, "camel_7951": 0.6533144116401672, "gsm_rft_4120": 0.6533390879631042, "gsm_rft_13783": 0.6534760594367981, "gsm_rft_21326": 0.6534862518310547, "aqua_rat_28949": 0.6537041664123535, "camel_41027": 0.6539465188980103, "aqua_rat_41829": 0.6540167331695557, "camel_41009": 0.6541563868522644, "gsm_rft_7862": 0.654224157333374, "gsm_rft_28391": 0.654364824295044, "gsm_train_17798": 0.654364824295044, "gsm_rft_28838": 0.6548998355865479, "gsm_rft_24257": 0.6558477282524109, "gsm_rft_25518": 0.6559536457061768, "camel_28096": 0.6565108895301819, "gsm_rft_35324": 0.6566332578659058, "camel_41038": 0.6574657559394836, "gsm_rft_29368": 0.6576567888259888, "gsm_rft_9556": 0.6577305793762207, "gsm_rft_10857": 0.658064067363739, "gsm_train_232": 0.658064067363739, "gsm_rft_34578": 0.6581449508666992, "TheoremQA_tonyxia/semiconductor2.json": 0.6587027907371521, "gsm_rft_24094": 0.6587668061256409, "gsm_train_10381": 0.6587668061256409, "camel_16555": 0.6588340997695923, "gsm_rft_20767": 0.6593180298805237, "camel_29496": 0.6593608856201172, "gsm_rft_32833": 0.6595562100410461, "gsm_rft_33282": 0.6596408486366272, "gsm_train_2385": 0.6596565246582031, "gsm_rft_28746": 0.6597578525543213, "gsm_train_28209": 0.6597618460655212, "gsm_rft_10742": 0.6597618460655212, "gsm_train_23183": 0.6597685217857361, "gsm_rft_13692": 0.6598852276802063, "camel_28847": 0.6600509881973267, "camel_29484": 0.6606158018112183, "TheoremQA_tonyxia/nuclear3.json": 0.6608179807662964, "gsm_rft_22822": 0.6616987586021423, "gsm_rft_32487": 0.6618168354034424, "gsm_train_22269": 0.6618168354034424, "gsm_rft_34322": 0.6618654727935791, "aqua_rat_24071": 0.6622928977012634, "gsm_rft_14007": 0.6630392074584961, "camel_17811": 0.6635594964027405, "camel_45174": 0.6636293530464172, "aqua_rat_85270": 0.6652659773826599, "aqua_rat_8480": 0.6658037304878235, "gsm_train_4193": 0.6682533025741577, "gsm_rft_6591": 0.6682533025741577, "gsm_rft_15366": 0.6696840524673462, "gsm_rft_22401": 0.6706162691116333, "aqua_rat_34975": 0.6707509160041809, "TheoremQA_panlu/molar_heat_capacity2.json": 0.6721556782722473, "gsm_rft_14462": 0.672164797782898, "gsm_rft_19423": 0.672164797782898, "gsm_train_15924": 0.672164797782898, "gsm_rft_23914": 0.6725308895111084, "camel_37984": 0.6741994023323059, "aqua_rat_77124": 0.6781145930290222, "camel_29102": 0.6783652305603027, "camel_28846": 0.6799501180648804, "camel_28081": 0.680695652961731, "gsm_rft_21213": 0.6814476847648621, "gsm_train_10153": 0.6823174357414246, "gsm_rft_35104": 0.6824160218238831, "camel_28715": 0.6838640570640564, "TheoremQA_xinyi/work_energy_theorem.json": 0.6885067820549011, "camel_45925": 0.6913599371910095, "TheoremQA_tonyxia/semiconductor3.json": 0.6916059255599976, "camel_37933": 0.6916683316230774, "camel_29080": 0.6938820481300354, "camel_28656": 0.6997522115707397, "camel_17587": 0.7055096626281738, "math_test_algebra_1049": 0.710960865020752, "math_train_algebra_1913": 0.7125283479690552, "camel_28151": 0.734259307384491, "camel_38919": 0.7603053450584412}, "TheoremQA_wenhuchen/gauss_lemma2.json": {"math_train_prealgebra_612": 0, "camel_12847": 0, "camel_12860": 0, "camel_12875": 0, "camel_12878": 0, "camel_12828": 0, "math_test_prealgebra_1728": 0, "camel_12831": 0, "camel_12844": 0, "camel_13259": 0, "camel_12590": 0, "camel_12856": 0, "math_test_prealgebra_1155": 0, "camel_12846": 0, "camel_12810": 0, "camel_12840": 0, "camel_12854": 0, "camel_12838": 0, "camel_12818": 0, "camel_12808": 0, "camel_12850": 0, "camel_12801": 0, "camel_12802": 0, "camel_12865": 0, "camel_12879": 0, "camel_12861": 0, "camel_12805": 0, "camel_12859": 0, "camel_12867": 0, "camel_12822": 0, "camel_12873": 0, "camel_12807": 0, "camel_12815": 0, "camel_12817": 0, "camel_12816": 0, "camel_12837": 0, "camel_12868": 0, "camel_12827": 0, "camel_13492": 0, "camel_12857": 0, "camel_12812": 0, "camel_12811": 0, "camel_12835": 0, "camel_12848": 0, "camel_12869": 0, "camel_12870": 0, "camel_12855": 0, "camel_13636": 0, "camel_12819": 0, "camel_12841": 0, "camel_12830": 0, "camel_12871": 0, "camel_12803": 0, "camel_12852": 0, "camel_12853": 0, "camel_12821": 0, "camel_12826": 0, "camel_12800": 0, "camel_13252": 0, "camel_12863": 0, "camel_12876": 0, "aqua_rat_62240": 0.7326360940933228, "aqua_rat_68494": 0.7327976822853088, "aqua_rat_26493": 0.7328581809997559, "aqua_rat_516": 0.7329773306846619, "math_train_number_theory_56": 0.7331819534301758, "aqua_rat_16382": 0.7334079742431641, "aqua_rat_15410": 0.7338791489601135, "aqua_rat_88443": 0.7341563701629639, "math_train_number_theory_1258": 0.7344397306442261, "aqua_rat_87275": 0.7345163822174072, "aqua_rat_60492": 0.7345709204673767, "aqua_rat_66775": 0.7350083589553833, "aqua_rat_10423": 0.7354737520217896, "math_train_number_theory_1100": 0.7355190515518188, "aqua_rat_76305": 0.7357330322265625, "aqua_rat_40421": 0.7358934879302979, "math_test_counting_and_probability_455": 0.7361628413200378, "aqua_rat_76961": 0.7364579439163208, "aqua_rat_58636": 0.7367870807647705, "aqua_rat_17653": 0.7370522618293762, "aqua_rat_65745": 0.7375938892364502, "aqua_rat_17820": 0.7379373908042908, "aqua_rat_49671": 0.7380141019821167, "aqua_rat_24040": 0.7381770610809326, "aqua_rat_62745": 0.7382472157478333, "aqua_rat_35443": 0.7385870218276978, "aqua_rat_52980": 0.7386812567710876, "aqua_rat_5437": 0.7387768030166626, "aqua_rat_39906": 0.7392818331718445, "aqua_rat_61348": 0.7394479513168335, "aqua_rat_74466": 0.7394716739654541, "aqua_rat_40729": 0.739530622959137, "aqua_rat_30144": 0.7395985722541809, "aqua_rat_8357": 0.7399552464485168, "aqua_rat_12667": 0.7403011322021484, "aqua_rat_11414": 0.740323543548584, "camel_36084": 0.7410433888435364, "aqua_rat_7914": 0.7411138415336609, "aqua_rat_37181": 0.7412415146827698, "aqua_rat_57786": 0.7413076162338257, "aqua_rat_71089": 0.7421412467956543, "aqua_rat_39666": 0.7431545257568359, "aqua_rat_11571": 0.74333655834198, "aqua_rat_70769": 0.7437341213226318, "aqua_rat_22502": 0.743775486946106, "aqua_rat_44398": 0.7439078688621521, "aqua_rat_4906": 0.7442365884780884, "aqua_rat_10549": 0.7443106770515442, "aqua_rat_62476": 0.7444750666618347, "aqua_rat_2577": 0.7453131079673767, "aqua_rat_35393": 0.7458742260932922, "aqua_rat_79434": 0.7461192011833191, "aqua_rat_45009": 0.7468923330307007, "aqua_rat_54512": 0.7471381425857544, "aqua_rat_86100": 0.747280478477478, "aqua_rat_8955": 0.7482751607894897, "aqua_rat_61608": 0.7483165264129639, "camel_37435": 0.7485868334770203, "math_test_number_theory_554": 0.7487280368804932, "aqua_rat_29388": 0.7488898038864136, "aqua_rat_76929": 0.7492073774337769, "aqua_rat_50518": 0.7492882609367371, "aqua_rat_81783": 0.7493026256561279, "aqua_rat_3788": 0.749662458896637, "aqua_rat_38778": 0.7498509287834167, "math_test_number_theory_257": 0.7499800324440002, "aqua_rat_71068": 0.7510781288146973, "camel_37393": 0.7517244815826416, "aqua_rat_10127": 0.7526347637176514, "aqua_rat_26518": 0.7530540227890015, "aqua_rat_18870": 0.7535398006439209, "aqua_rat_17753": 0.7536180019378662, "aqua_rat_3156": 0.7543854117393494, "aqua_rat_29597": 0.7545119524002075, "aqua_rat_11102": 0.7549552321434021, "aqua_rat_14060": 0.7549863457679749, "aqua_rat_54413": 0.7553101181983948, "aqua_rat_44214": 0.7556512355804443, "aqua_rat_20814": 0.7561768293380737, "aqua_rat_23384": 0.7562462687492371, "aqua_rat_66817": 0.7563856840133667, "aqua_rat_87742": 0.7568371295928955, "aqua_rat_24324": 0.7572841644287109, "aqua_rat_25593": 0.7573757767677307, "aqua_rat_15625": 0.7575526833534241, "aqua_rat_33807": 0.7576221227645874, "aqua_rat_22189": 0.7577387094497681, "aqua_rat_45563": 0.7578956484794617, "aqua_rat_18263": 0.7579496502876282, "aqua_rat_35311": 0.7579910755157471, "aqua_rat_77353": 0.758299708366394, "aqua_rat_52369": 0.7586148381233215, "aqua_rat_51863": 0.7590129971504211, "aqua_rat_79633": 0.7590662837028503, "aqua_rat_10502": 0.759404182434082, "aqua_rat_82840": 0.7594233751296997, "aqua_rat_66605": 0.760177493095398, "aqua_rat_44345": 0.7605066895484924, "aqua_rat_65732": 0.7605905532836914, "aqua_rat_62422": 0.7606022357940674, "aqua_rat_46907": 0.7608677744865417, "aqua_rat_79127": 0.7611265778541565, "aqua_rat_37848": 0.7612946033477783, "camel_37164": 0.7620370388031006, "aqua_rat_77742": 0.7623920440673828, "aqua_rat_82034": 0.7627619504928589, "aqua_rat_60140": 0.7633707523345947, "aqua_rat_74130": 0.7640272974967957, "aqua_rat_1606": 0.764045238494873, "aqua_rat_86239": 0.7646595239639282, "aqua_rat_22596": 0.764820396900177, "aqua_rat_73004": 0.7655646800994873, "aqua_rat_65377": 0.7658181190490723, "aqua_rat_17168": 0.7660911679267883, "aqua_rat_33946": 0.7662562727928162, "aqua_rat_8985": 0.7664211392402649, "aqua_rat_6246": 0.7668174505233765, "aqua_rat_73948": 0.7668997049331665, "aqua_rat_79841": 0.7674254179000854, "aqua_rat_41930": 0.7675185203552246, "aqua_rat_28035": 0.7678799629211426, "aqua_rat_4039": 0.7686649560928345, "aqua_rat_19690": 0.770519495010376, "aqua_rat_24283": 0.7714143991470337, "aqua_rat_64445": 0.7719017267227173, "aqua_rat_17657": 0.7719908952713013, "aqua_rat_24322": 0.7732314467430115, "aqua_rat_15929": 0.774112343788147, "aqua_rat_49568": 0.7760617136955261, "aqua_rat_46081": 0.7781662344932556, "aqua_rat_69927": 0.7794814109802246, "aqua_rat_60360": 0.7798045873641968, "aqua_rat_61707": 0.7810128927230835, "aqua_rat_9910": 0.7816867232322693, "aqua_rat_1010": 0.7861248254776001, "aqua_rat_22220": 0.7942825555801392, "aqua_rat_50295": 0.795907735824585, "aqua_rat_48398": 0.7999680042266846, "aqua_rat_75586": 0.8003622889518738}, "TheoremQA_panlu/angular_frequency3.json": {"TheoremQA_panlu/angular_frequency3.json": 0, "gsm_rft_4583": 0.7331433296203613, "gsm_train_2068": 0.7331433296203613, "camel_7980": 0.7334764003753662, "camel_7586": 0.7338141202926636, "camel_29417": 0.7338545918464661, "gsm_rft_35619": 0.7340401411056519, "gsm_train_22933": 0.734041690826416, "camel_7536": 0.7340969443321228, "camel_5093": 0.7341701984405518, "camel_7572": 0.7342130541801453, "aqua_rat_17174": 0.7343235611915588, "camel_29989": 0.7343450784683228, "camel_7498": 0.7343476414680481, "gsm_rft_17953": 0.7343689203262329, "gsm_rft_28024": 0.7343689203262329, "camel_7519": 0.7344246506690979, "camel_16626": 0.7346958518028259, "camel_7478": 0.7347217798233032, "camel_7574": 0.7348155379295349, "camel_5178": 0.7349754571914673, "camel_29372": 0.7350504994392395, "camel_7580": 0.7352769374847412, "gsm_rft_16695": 0.7360896468162537, "aqua_rat_19334": 0.7363235354423523, "camel_7982": 0.7363725900650024, "camel_28808": 0.7364101409912109, "camel_5189": 0.7365109324455261, "gsm_rft_24421": 0.7366241216659546, "camel_17390": 0.7367613911628723, "camel_29435": 0.7370272874832153, "camel_16255": 0.738634467124939, "camel_7592": 0.7387335300445557, "camel_6246": 0.7388303875923157, "camel_29970": 0.7389628887176514, "camel_29416": 0.7390307784080505, "aqua_rat_46626": 0.7393941879272461, "camel_5227": 0.7398927807807922, "camel_7484": 0.7399519681930542, "aqua_rat_51789": 0.7400571703910828, "camel_17811": 0.7400931715965271, "camel_16273": 0.7400956153869629, "camel_7558": 0.740371823310852, "camel_7565": 0.7403795719146729, "camel_45141": 0.7405368089675903, "camel_7567": 0.7413153648376465, "camel_28815": 0.7418690323829651, "aqua_rat_29250": 0.7418698072433472, "camel_28864": 0.7422761917114258, "camel_29420": 0.7423556447029114, "aqua_rat_35036": 0.7426827549934387, "camel_29426": 0.742755651473999, "camel_16264": 0.7428824305534363, "camel_39452": 0.743094265460968, "camel_16279": 0.7433116436004639, "camel_7520": 0.7443098425865173, "math_test_algebra_1233": 0.7443931102752686, "camel_16287": 0.7456699013710022, "camel_7959": 0.7459784746170044, "camel_28836": 0.7460125684738159, "camel_29415": 0.7462396621704102, "camel_7594": 0.746467649936676, "camel_7938": 0.7465548515319824, "camel_16307": 0.7465763688087463, "camel_29927": 0.746731698513031, "camel_7945": 0.7469477653503418, "camel_28826": 0.7473949193954468, "camel_7552": 0.7475968599319458, "camel_5188": 0.7478375434875488, "camel_28833": 0.7478857040405273, "camel_28805": 0.7481380701065063, "camel_16262": 0.7482656240463257, "camel_28804": 0.7488690614700317, "aqua_rat_42357": 0.749006450176239, "camel_7922": 0.7500112652778625, "gsm_rft_34949": 0.7502343654632568, "camel_16301": 0.7503467798233032, "gsm_rft_18241": 0.7506234645843506, "gsm_train_8834": 0.7506234645843506, "camel_7937": 0.7508178949356079, "camel_5126": 0.751373291015625, "aqua_rat_54715": 0.7517022490501404, "camel_5153": 0.7521348595619202, "camel_45169": 0.7527387738227844, "camel_4979": 0.7527608871459961, "camel_29365": 0.7533010244369507, "camel_39479": 0.7537899017333984, "camel_28532": 0.7541526556015015, "aqua_rat_88338": 0.7548497915267944, "camel_7988": 0.7550523281097412, "aqua_rat_21058": 0.755378782749176, "camel_45174": 0.7557222247123718, "camel_7951": 0.7558759450912476, "camel_7568": 0.7560334205627441, "camel_16318": 0.7565415501594543, "camel_7944": 0.757237434387207, "camel_17408": 0.7575507760047913, "camel_29979": 0.7576289772987366, "camel_29381": 0.7576929330825806, "camel_39485": 0.7582636475563049, "camel_17361": 0.7583464980125427, "camel_39475": 0.7585810422897339, "aqua_rat_56629": 0.7586969137191772, "camel_29406": 0.7587464451789856, "camel_16296": 0.7589406967163086, "aqua_rat_3512": 0.7594651579856873, "camel_16271": 0.7600932717323303, "camel_28875": 0.7609757781028748, "camel_28842": 0.7611308693885803, "aqua_rat_41470": 0.7614356279373169, "camel_28809": 0.7620255947113037, "aqua_rat_69598": 0.7621025443077087, "aqua_rat_39697": 0.7627502083778381, "camel_28873": 0.763988196849823, "camel_29427": 0.7640047669410706, "aqua_rat_47344": 0.764610767364502, "camel_29419": 0.7648001909255981, "camel_16265": 0.7655463814735413, "camel_7984": 0.7656793594360352, "camel_28812": 0.7657280564308167, "camel_16243": 0.7664743661880493, "camel_45120": 0.7664943337440491, "camel_29960": 0.7665421366691589, "camel_28866": 0.7665901780128479, "camel_16300": 0.7666507959365845, "aqua_rat_26775": 0.7673386335372925, "camel_29378": 0.767365038394928, "TheoremQA_panlu/wave_speed1.json": 0.7688505053520203, "camel_28856": 0.7700530886650085, "camel_5180": 0.7702239155769348, "aqua_rat_28423": 0.7707445621490479, "aqua_rat_43491": 0.7714401483535767, "camel_16312": 0.7719234824180603, "camel_28137": 0.7726234793663025, "camel_16291": 0.7741149067878723, "camel_28816": 0.7751492261886597, "camel_16241": 0.7761351466178894, "aqua_rat_10814": 0.7764027118682861, "aqua_rat_34087": 0.7780768871307373, "camel_28872": 0.7780871987342834, "camel_45444": 0.7798170447349548, "camel_29398": 0.780210018157959, "camel_16253": 0.7839704751968384, "camel_28868": 0.7843034863471985, "camel_16628": 0.7844270467758179, "camel_28840": 0.78448885679245, "camel_28846": 0.7871542572975159, "camel_29385": 0.7879684567451477, "camel_16244": 0.7888436317443848, "camel_29363": 0.790341854095459, "camel_16290": 0.7924173474311829, "camel_17406": 0.7926784753799438, "camel_16275": 0.7934350967407227, "camel_16282": 0.7936720252037048, "camel_7584": 0.7936772108078003, "camel_28811": 0.7958424091339111, "camel_16268": 0.796343207359314, "camel_16257": 0.7977622151374817, "camel_16281": 0.8005598783493042, "camel_16240": 0.8010371923446655, "camel_28847": 0.8015135526657104, "camel_16272": 0.8025050759315491, "camel_16277": 0.802693784236908, "camel_16245": 0.8028309941291809, "TheoremQA_xinyi/work_energy_theorem.json": 0.8029348254203796, "camel_16315": 0.8033663034439087, "camel_16303": 0.8041188716888428, "camel_16288": 0.8041504621505737, "camel_16250": 0.8046296834945679, "camel_16310": 0.8048394918441772, "camel_16317": 0.8054294586181641, "camel_16316": 0.8059270977973938, "camel_16304": 0.8062184453010559, "camel_16308": 0.8070826530456543, "camel_16295": 0.8075330257415771, "camel_16311": 0.8094812631607056, "camel_16254": 0.8095988035202026, "camel_16267": 0.8101527094841003, "camel_16258": 0.8103023171424866, "camel_16286": 0.810355544090271, "camel_16302": 0.8107143044471741, "camel_16289": 0.8121585845947266, "camel_5125": 0.8131261467933655, "camel_16299": 0.8137561678886414, "camel_16294": 0.8181500434875488, "camel_16285": 0.8184031248092651, "camel_16252": 0.8196191787719727, "camel_16242": 0.8216432929039001, "camel_16314": 0.8221787810325623, "camel_16276": 0.8250360488891602, "camel_16263": 0.8266112208366394, "camel_16284": 0.8289172053337097, "camel_16251": 0.8364392518997192, "camel_17542": 0.8456301093101501, "camel_16280": 0.846082329750061, "camel_16247": 0.8464332222938538, "camel_16283": 0.8480679392814636, "camel_16266": 0.8493648171424866, "camel_16246": 0.8513863682746887, "camel_16249": 0.8690590858459473}, "TheoremQA_panlu/trapezoid1.json": {"aqua_rat_61580": 0.8184850811958313, "aqua_rat_28315": 0.8185452222824097, "camel_2505": 0.818547785282135, "aqua_rat_17501": 0.8187586069107056, "aqua_rat_7177": 0.81889408826828, "camel_3944": 0.8189743757247925, "aqua_rat_26054": 0.8193414807319641, "aqua_rat_28978": 0.8195738792419434, "aqua_rat_57592": 0.8195884227752686, "gsm_rft_7101": 0.8196138143539429, "gsm_rft_35475": 0.8196889162063599, "camel_2524": 0.8197355270385742, "camel_3903": 0.8198235034942627, "aqua_rat_70270": 0.8198458552360535, "aqua_rat_41306": 0.8199384808540344, "camel_2502": 0.8200138807296753, "aqua_rat_24966": 0.820060133934021, "aqua_rat_32849": 0.820065975189209, "camel_2485": 0.820071816444397, "aqua_rat_82076": 0.8201301097869873, "aqua_rat_66222": 0.82035231590271, "camel_2532": 0.820364236831665, "camel_2544": 0.8203879594802856, "camel_2552": 0.8206750154495239, "camel_2549": 0.8206871747970581, "math_test_prealgebra_1108": 0.8207494020462036, "camel_3846": 0.8207955360412598, "aqua_rat_1569": 0.8209764361381531, "camel_2517": 0.8209982514381409, "camel_39198": 0.8210707902908325, "camel_3874": 0.8210818767547607, "camel_2535": 0.8211081027984619, "camel_2548": 0.821244478225708, "aqua_rat_78328": 0.821382999420166, "camel_2545": 0.8214711546897888, "camel_2540": 0.8215243220329285, "aqua_rat_10775": 0.8217208385467529, "aqua_rat_8160": 0.8218386173248291, "aqua_rat_4376": 0.8218556046485901, "aqua_rat_1281": 0.8221383094787598, "aqua_rat_43302": 0.8224186301231384, "camel_3859": 0.8226021528244019, "math_train_geometry_1131": 0.8228322267532349, "aqua_rat_43317": 0.8229054808616638, "aqua_rat_58197": 0.8231598138809204, "camel_2526": 0.8233718872070312, "camel_2499": 0.8234689235687256, "camel_3988": 0.8234707713127136, "camel_2492": 0.823488175868988, "camel_2514": 0.8235037326812744, "aqua_rat_53562": 0.8236820101737976, "camel_2554": 0.8237248063087463, "camel_2525": 0.8238093852996826, "aqua_rat_36032": 0.8239766359329224, "camel_2503": 0.8240171670913696, "aqua_rat_39071": 0.8241769671440125, "aqua_rat_71722": 0.8242263197898865, "aqua_rat_27690": 0.8243074417114258, "camel_2559": 0.8243090510368347, "camel_3916": 0.8244239687919617, "aqua_rat_77482": 0.8244861364364624, "camel_3870": 0.8245514631271362, "camel_3922": 0.824632465839386, "aqua_rat_69063": 0.8246483206748962, "camel_2542": 0.8247039318084717, "aqua_rat_8442": 0.8247780203819275, "camel_2543": 0.824799120426178, "aqua_rat_79868": 0.8249045014381409, "camel_3909": 0.824905276298523, "aqua_rat_4872": 0.8249964714050293, "aqua_rat_63324": 0.8250220417976379, "camel_2510": 0.8251527547836304, "aqua_rat_39302": 0.8252479434013367, "camel_3259": 0.8253308534622192, "aqua_rat_79493": 0.8254734873771667, "math_test_geometry_433": 0.8254808187484741, "camel_2519": 0.8254993557929993, "camel_2494": 0.8256272673606873, "camel_3873": 0.8257932066917419, "aqua_rat_30282": 0.825804591178894, "camel_2495": 0.8258470892906189, "camel_2480": 0.8259016871452332, "aqua_rat_67021": 0.8260138630867004, "camel_2530": 0.8260943293571472, "camel_2498": 0.8262673616409302, "aqua_rat_35761": 0.8263274431228638, "camel_2534": 0.8266304135322571, "camel_3892": 0.8267987966537476, "camel_3905": 0.8270263671875, "aqua_rat_17909": 0.8270834684371948, "camel_2496": 0.8271101117134094, "camel_3884": 0.8271382451057434, "camel_3845": 0.8274590969085693, "camel_2550": 0.8277037143707275, "camel_3973": 0.8277104496955872, "camel_3906": 0.8279619216918945, "aqua_rat_18828": 0.8284195065498352, "camel_3897": 0.8284849524497986, "camel_2538": 0.8285534977912903, "camel_3851": 0.8286668062210083, "camel_2515": 0.8288835287094116, "aqua_rat_88934": 0.8290157318115234, "camel_2484": 0.8292621374130249, "camel_3887": 0.8292941451072693, "gsm_rft_11783": 0.8294130563735962, "gsm_train_22251": 0.8294130563735962, "gsm_rft_4293": 0.8294130563735962, "camel_2546": 0.8295304775238037, "camel_3871": 0.8296400308609009, "camel_3876": 0.830102264881134, "camel_3882": 0.8301308751106262, "aqua_rat_63990": 0.8301335573196411, "aqua_rat_31723": 0.8301612138748169, "camel_2558": 0.830456554889679, "camel_3888": 0.8305186033248901, "aqua_rat_45688": 0.8306589126586914, "aqua_rat_7163": 0.8307293653488159, "camel_3877": 0.8307509422302246, "camel_3902": 0.8308339715003967, "aqua_rat_80550": 0.8315285444259644, "camel_3918": 0.8324077725410461, "camel_2551": 0.8324165344238281, "camel_3915": 0.8326433897018433, "camel_2493": 0.8329492211341858, "camel_2539": 0.8330162167549133, "camel_3883": 0.8330948948860168, "camel_3981": 0.8335176110267639, "aqua_rat_85812": 0.8337424397468567, "camel_2483": 0.8339263200759888, "aqua_rat_45607": 0.8339933156967163, "aqua_rat_71356": 0.8341894745826721, "camel_3904": 0.8342553377151489, "camel_3912": 0.8344696164131165, "camel_3842": 0.8345464468002319, "camel_3881": 0.8347555994987488, "aqua_rat_13468": 0.8347711563110352, "math_test_geometry_462": 0.8349184989929199, "camel_3869": 0.8350219130516052, "camel_3913": 0.835494339466095, "math_test_geometry_452": 0.8355216383934021, "camel_3868": 0.8357773423194885, "camel_3989": 0.8358485102653503, "gsm_rft_23551": 0.8360123634338379, "camel_3857": 0.8360744714736938, "gsm_train_33962": 0.8360866904258728, "aqua_rat_87977": 0.8361504673957825, "camel_3999": 0.836169958114624, "aqua_rat_41860": 0.8362401723861694, "camel_3850": 0.8364270329475403, "gsm_rft_18078": 0.8364421129226685, "aqua_rat_64960": 0.8364866375923157, "aqua_rat_83941": 0.8365491628646851, "camel_3858": 0.8366079926490784, "gsm_rft_604": 0.836762011051178, "aqua_rat_8053": 0.8374404311180115, "camel_3861": 0.838085949420929, "camel_3854": 0.8384563326835632, "camel_3872": 0.8389663696289062, "aqua_rat_65273": 0.8392289280891418, "camel_3847": 0.8397526741027832, "aqua_rat_57787": 0.8399719595909119, "camel_3878": 0.8403064012527466, "aqua_rat_87317": 0.8403782844543457, "camel_3875": 0.8404540419578552, "camel_3998": 0.8405007123947144, "aqua_rat_49039": 0.8405120372772217, "aqua_rat_833": 0.8405748605728149, "camel_3893": 0.8408069610595703, "aqua_rat_71154": 0.8410220146179199, "aqua_rat_51693": 0.841497540473938, "camel_3841": 0.841810405254364, "camel_3863": 0.8419530391693115, "camel_3853": 0.8422752618789673, "camel_3901": 0.842327356338501, "camel_3900": 0.8427199125289917, "camel_3880": 0.8429737687110901, "camel_3895": 0.8430153727531433, "camel_3894": 0.8431409001350403, "camel_3954": 0.843164324760437, "camel_3899": 0.8436038494110107, "camel_3866": 0.8436835408210754, "camel_3896": 0.845079779624939, "camel_3934": 0.8462371826171875, "camel_3890": 0.8463079333305359, "camel_3862": 0.8464428186416626, "camel_3910": 0.8469690084457397, "camel_3849": 0.8471417427062988, "camel_3856": 0.8475144505500793, "camel_3843": 0.8479642271995544, "camel_3860": 0.8483518958091736, "camel_3889": 0.8485857248306274, "camel_3917": 0.8493489623069763, "camel_3879": 0.8504650592803955, "gsm_rft_19697": 0.8516109585762024, "gsm_train_30034": 0.8520364165306091, "camel_3886": 0.8523287773132324, "gsm_rft_11802": 0.8525838255882263, "gsm_rft_27714": 0.854682981967926, "camel_3852": 0.8549108505249023, "camel_3907": 0.8596949577331543}, "TheoremQA_wenhuchen/t_test2.json": {"camel_9920": 0, "camel_8830": 0, "camel_9671": 0, "camel_9932": 0, "camel_9677": 0, "camel_8108": 0, "camel_9982": 0, "camel_8833": 0, "camel_9998": 0, "camel_9656": 0, "camel_8660": 0, "camel_8950": 0, "camel_8805": 0, "camel_8042": 0, "camel_8014": 0, "camel_8034": 0, "camel_8855": 0, "camel_8715": 0, "camel_8127": 0, "camel_9929": 0, "camel_9662": 0, "camel_9644": 0, "camel_9930": 0, "camel_8679": 0, "camel_8005": 0, "camel_8049": 0, "camel_8012": 0, "camel_8055": 0, "camel_8021": 0, "TheoremQA_wenhuchen/t_test2.json": 0, "camel_8048": 0, "camel_8033": 0, "camel_8885": 0, "camel_8070": 0, "camel_8047": 0, "camel_9963": 0, "camel_9735": 0, "camel_9945": 0, "camel_8065": 0, "camel_8035": 0, "camel_8028": 0, "camel_9960": 0, "camel_8654": 0, "camel_9900": 0, "camel_8648": 0, "camel_9939": 0, "camel_8659": 0, "camel_8800": 0, "camel_9951": 0, "camel_9972": 0, "camel_9709": 0, "camel_8036": 0, "camel_9988": 0, "camel_8653": 0, "camel_8001": 0, "camel_9983": 0, "camel_9994": 0, "camel_9952": 0, "camel_8066": 0, "camel_9938": 0, "camel_8803": 0, "camel_8826": 0, "camel_8046": 0, "camel_8040": 0, "camel_8024": 0, "camel_8078": 0, "camel_8061": 0, "camel_8054": 0, "camel_8831": 0, "camel_8041": 0, "camel_9991": 0, "camel_8077": 0, "camel_9969": 0, "camel_8039": 0, "camel_8806": 0, "camel_8714": 0, "camel_8016": 0, "camel_8052": 0, "camel_8043": 0, "camel_8076": 0, "camel_8953": 0, "camel_9996": 0, "camel_8657": 0, "camel_9941": 0, "camel_8926": 0, "camel_8050": 0, "camel_8681": 0, "camel_8768": 0, "camel_8889": 0, "camel_8002": 0, "camel_8084": 0, "camel_8842": 0, "camel_9664": 0, "camel_9954": 0, "camel_8843": 0, "camel_8691": 0, "camel_8817": 0, "camel_8852": 0, "camel_8031": 0, "camel_8004": 0, "camel_8823": 0, "camel_8079": 0, "camel_8802": 0, "camel_8069": 0, "camel_8000": 0, "camel_9931": 0, "camel_9926": 0, "camel_8872": 0, "camel_8850": 0, "camel_8072": 0, "camel_8027": 0, "camel_8006": 0, "camel_8835": 0, "camel_8057": 0, "camel_9979": 0, "camel_8008": 0, "camel_8871": 0, "camel_8819": 0, "camel_8029": 0, "camel_9967": 0, "camel_8059": 0, "camel_8010": 0, "camel_8067": 0, "camel_8804": 0, "camel_8030": 0, "camel_8854": 0, "camel_8023": 0, "camel_8825": 0, "camel_9978": 0, "camel_8068": 0, "camel_8018": 0, "camel_8849": 0, "camel_8689": 0, "camel_8026": 0, "camel_8838": 0, "camel_8009": 0, "camel_9962": 0, "camel_8013": 0, "camel_8708": 0, "camel_8853": 0, "camel_9950": 0, "camel_8025": 0, "camel_8812": 0, "camel_9980": 0, "camel_8058": 0, "camel_8811": 0, "camel_8832": 0, "camel_9958": 0, "camel_8051": 0, "camel_8948": 0, "camel_8071": 0, "camel_8878": 0, "camel_8060": 0, "camel_8003": 0, "camel_8827": 0, "camel_9391": 0, "camel_8876": 0, "camel_8053": 0, "camel_8017": 0, "camel_9925": 0, "camel_9971": 0, "camel_9610": 0, "camel_8856": 0, "camel_8807": 0, "camel_9242": 0, "camel_9523": 0, "camel_8032": 0, "camel_8074": 0, "camel_8063": 0, "camel_8844": 0, "camel_8846": 0, "camel_8037": 0, "camel_8020": 0, "camel_8015": 0, "camel_8863": 0, "camel_8044": 0, "camel_8011": 0, "camel_9410": 0, "camel_8810": 0, "camel_8064": 0, "camel_8019": 0, "camel_9672": 0, "camel_8847": 0, "camel_8075": 0, "camel_8022": 0, "camel_8861": 0, "camel_8864": 0, "camel_8056": 0, "camel_8814": 0, "camel_8038": 0, "camel_8836": 0, "camel_9944": 0, "camel_9977": 0, "camel_8813": 0, "camel_8857": 0, "camel_37940": 0.8303624391555786, "TheoremQA_wenhuchen/t_test1.json": 0.8405291438102722, "camel_37974": 0.8502509593963623, "TheoremQA_wenhuchen/t_test3.json": 0.8586954474449158, "camel_37953": 0.8650957345962524}, "TheoremQA_jianyu_xu/Stirling_number_second_kind_3.json": {"camel_20599": 0, "camel_20946": 0, "camel_20256": 0, "camel_21361": 0, "camel_21022": 0, "camel_20462": 0, "camel_20930": 0, "camel_21028": 0, "camel_20695": 0, "camel_21809": 0, "camel_20022": 0, "camel_21400": 0, "camel_21200": 0, "camel_21246": 0, "camel_20853": 0, "camel_20257": 0, "camel_20614": 0, "camel_21039": 0, "camel_20808": 0, "camel_20623": 0, "camel_20514": 0, "camel_20802": 0, "camel_20312": 0, "camel_21015": 0, "camel_20841": 0, "camel_20577": 0, "camel_21050": 0, "camel_21202": 0, "camel_20598": 0, "camel_20309": 0, "camel_21808": 0, "camel_21379": 0, "camel_21215": 0, "camel_20255": 0, "camel_20540": 0, "camel_20611": 0, "camel_21530": 0, "camel_20308": 0, "camel_21568": 0, "camel_21386": 0, "camel_21431": 0, "camel_20656": 0, "camel_20302": 0, "camel_20287": 0, "camel_20637": 0, "camel_20512": 0, "aqua_rat_10096": 0.7965737581253052, "math_test_counting_and_probability_416": 0.7969539761543274, "aqua_rat_52067": 0.7972733378410339, "aqua_rat_33834": 0.7978094816207886, "aqua_rat_14806": 0.7978209853172302, "aqua_rat_2870": 0.7979074120521545, "aqua_rat_51559": 0.7979439496994019, "math_test_counting_and_probability_216": 0.798017144203186, "aqua_rat_79594": 0.7983636260032654, "aqua_rat_37642": 0.7984206676483154, "aqua_rat_29514": 0.7986568808555603, "aqua_rat_66592": 0.798774778842926, "aqua_rat_7341": 0.7987785935401917, "aqua_rat_38694": 0.7990592122077942, "aqua_rat_9412": 0.7993068099021912, "aqua_rat_10672": 0.799472987651825, "aqua_rat_34261": 0.7995632290840149, "aqua_rat_13243": 0.7995691895484924, "aqua_rat_22648": 0.7996388673782349, "aqua_rat_62261": 0.7996653914451599, "aqua_rat_28657": 0.8000048398971558, "aqua_rat_16780": 0.8000509738922119, "math_train_counting_and_probability_146": 0.8001970052719116, "aqua_rat_11273": 0.8002500534057617, "aqua_rat_59702": 0.8003604412078857, "aqua_rat_58757": 0.80153489112854, "aqua_rat_40812": 0.801675021648407, "aqua_rat_2270": 0.8017448782920837, "aqua_rat_52885": 0.8017955422401428, "aqua_rat_32162": 0.8018282651901245, "aqua_rat_34607": 0.8024044632911682, "math_test_counting_and_probability_776": 0.8024743795394897, "aqua_rat_37223": 0.8026004433631897, "aqua_rat_72210": 0.8026781678199768, "aqua_rat_35395": 0.8026809692382812, "aqua_rat_83158": 0.8027063608169556, "aqua_rat_49270": 0.8027608394622803, "aqua_rat_41861": 0.8027742505073547, "aqua_rat_18901": 0.8028002977371216, "aqua_rat_61965": 0.8030301928520203, "aqua_rat_50641": 0.8030683994293213, "aqua_rat_76271": 0.8031340837478638, "aqua_rat_74651": 0.8031867742538452, "aqua_rat_35517": 0.8034613132476807, "aqua_rat_81997": 0.8034918904304504, "aqua_rat_81265": 0.8035411238670349, "aqua_rat_39390": 0.803543210029602, "aqua_rat_4191": 0.8035556674003601, "aqua_rat_57693": 0.8036454319953918, "aqua_rat_29513": 0.8036713004112244, "aqua_rat_42333": 0.8037960529327393, "aqua_rat_19502": 0.8038524985313416, "aqua_rat_83784": 0.8038649559020996, "aqua_rat_13369": 0.8039008975028992, "aqua_rat_62715": 0.8041456937789917, "aqua_rat_76714": 0.804248034954071, "aqua_rat_575": 0.8042784929275513, "aqua_rat_79193": 0.804439127445221, "aqua_rat_77698": 0.8044652938842773, "aqua_rat_57985": 0.8046029806137085, "aqua_rat_70861": 0.8050625920295715, "aqua_rat_2658": 0.8051677942276001, "aqua_rat_37301": 0.8052008748054504, "math_test_counting_and_probability_935": 0.8053342700004578, "aqua_rat_80444": 0.8053836822509766, "aqua_rat_50942": 0.8055751919746399, "aqua_rat_25933": 0.8056928515434265, "aqua_rat_22214": 0.8058510422706604, "aqua_rat_14532": 0.80585116147995, "aqua_rat_35292": 0.8061299324035645, "aqua_rat_68198": 0.8062756061553955, "aqua_rat_88418": 0.8063219785690308, "aqua_rat_60755": 0.8064355850219727, "aqua_rat_43064": 0.8065997958183289, "aqua_rat_70446": 0.8067182302474976, "aqua_rat_66240": 0.8067341446876526, "aqua_rat_79094": 0.8072691559791565, "aqua_rat_89302": 0.8073717951774597, "aqua_rat_38594": 0.8073920607566833, "aqua_rat_51723": 0.8074302077293396, "aqua_rat_12795": 0.8074824810028076, "aqua_rat_21265": 0.8074979782104492, "aqua_rat_42155": 0.807716429233551, "math_train_counting_and_probability_617": 0.8077362775802612, "aqua_rat_30109": 0.8079032897949219, "aqua_rat_62645": 0.8079515695571899, "aqua_rat_51384": 0.8081018924713135, "aqua_rat_28538": 0.8081216812133789, "aqua_rat_13918": 0.8085504174232483, "aqua_rat_73601": 0.8086733818054199, "aqua_rat_72708": 0.8088966608047485, "aqua_rat_21868": 0.809025764465332, "aqua_rat_83332": 0.8093113899230957, "aqua_rat_33533": 0.809350848197937, "aqua_rat_371": 0.8094826936721802, "aqua_rat_15917": 0.8096833229064941, "aqua_rat_8402": 0.8099594712257385, "aqua_rat_19436": 0.810019850730896, "camel_38541": 0.8100248575210571, "aqua_rat_11651": 0.8108317852020264, "aqua_rat_13585": 0.8110212087631226, "aqua_rat_27914": 0.8110532164573669, "aqua_rat_35121": 0.8113492727279663, "aqua_rat_29306": 0.8113819360733032, "aqua_rat_64485": 0.8117361664772034, "math_train_counting_and_probability_667": 0.8119951486587524, "aqua_rat_15706": 0.8120313286781311, "aqua_rat_31957": 0.8120611310005188, "math_train_counting_and_probability_696": 0.8127603530883789, "aqua_rat_52832": 0.8128427863121033, "aqua_rat_66465": 0.8128538727760315, "aqua_rat_41924": 0.8130050301551819, "aqua_rat_7248": 0.8139389157295227, "aqua_rat_3934": 0.8143187165260315, "aqua_rat_54461": 0.8151801228523254, "aqua_rat_73402": 0.8164256811141968, "aqua_rat_66841": 0.8165343403816223, "aqua_rat_74695": 0.8173746466636658, "aqua_rat_75767": 0.8178280591964722, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": 0.818494439125061, "aqua_rat_2480": 0.8188394904136658, "aqua_rat_57095": 0.8188828825950623, "aqua_rat_71649": 0.8190478682518005, "aqua_rat_22507": 0.8191735744476318, "aqua_rat_57246": 0.8195310831069946, "aqua_rat_37185": 0.8204710483551025, "aqua_rat_15615": 0.8207760453224182, "aqua_rat_74550": 0.8210914731025696, "aqua_rat_10102": 0.822055459022522, "aqua_rat_18404": 0.8229140043258667, "aqua_rat_40108": 0.8239558935165405, "aqua_rat_30172": 0.8241929411888123, "aqua_rat_70803": 0.824520468711853, "aqua_rat_23041": 0.8249834775924683, "aqua_rat_16877": 0.8256143927574158, "aqua_rat_61885": 0.825827956199646, "aqua_rat_32732": 0.82611483335495, "aqua_rat_89113": 0.8261648416519165, "aqua_rat_89175": 0.8266067504882812, "aqua_rat_56019": 0.8267530798912048, "aqua_rat_4294": 0.8268839716911316, "aqua_rat_71336": 0.8272280693054199, "aqua_rat_62903": 0.8285017013549805, "aqua_rat_29651": 0.8291116952896118, "aqua_rat_64131": 0.8300992846488953, "aqua_rat_84159": 0.8302464485168457, "aqua_rat_73365": 0.8312920331954956, "TheoremQA_jianyu_xu/Multinomial_2.json": 0.8360277414321899, "aqua_rat_60936": 0.836186408996582, "aqua_rat_73122": 0.8368439674377441, "aqua_rat_34678": 0.8374028205871582, "math_test_counting_and_probability_79": 0.8433483839035034, "math_test_counting_and_probability_341": 0.8516746759414673, "aqua_rat_55783": 0.85923171043396}, "TheoremQA_xinyi/channel_capacity_1.json": {"aqua_rat_56215": 0.6733301877975464, "gsm_rft_5487": 0.6733641028404236, "gsm_rft_10746": 0.6734758019447327, "gsm_train_12640": 0.6734758019447327, "gsm_rft_24796": 0.6734979152679443, "camel_22548": 0.6735748648643494, "aqua_rat_61077": 0.6736425161361694, "camel_36391": 0.6737474203109741, "gsm_rft_31960": 0.6737875938415527, "camel_26864": 0.6737919449806213, "camel_36505": 0.6739664077758789, "camel_36333": 0.6739768385887146, "gsm_rft_33997": 0.6740478873252869, "camel_36765": 0.6741006970405579, "gsm_rft_19778": 0.6742733716964722, "gsm_rft_10897": 0.6743489503860474, "TheoremQA_xinyi/binary_symmetric_channel_1.json": 0.6744642853736877, "gsm_train_29765": 0.6744967103004456, "gsm_rft_27862": 0.6744967103004456, "gsm_rft_17238": 0.6746132969856262, "gsm_rft_21644": 0.6747118830680847, "gsm_train_13596": 0.6747426986694336, "camel_37452": 0.6748348474502563, "gsm_rft_3445": 0.674835205078125, "gsm_rft_32571": 0.6748422384262085, "gsm_rft_29438": 0.6748422384262085, "gsm_rft_19302": 0.6748971939086914, "gsm_train_29699": 0.6749526858329773, "gsm_rft_24758": 0.6749526858329773, "gsm_train_5164": 0.6749891638755798, "gsm_rft_30704": 0.6750264763832092, "gsm_rft_33243": 0.6750264763832092, "gsm_train_28946": 0.6750264763832092, "gsm_rft_26882": 0.6750280261039734, "gsm_rft_1187": 0.6752018332481384, "aqua_rat_52087": 0.6752079129219055, "gsm_rft_17773": 0.6753628253936768, "gsm_rft_10092": 0.67537921667099, "gsm_train_5597": 0.6754459142684937, "gsm_rft_22638": 0.6754459142684937, "gsm_rft_33536": 0.6754493117332458, "gsm_rft_8129": 0.675555408000946, "camel_26647": 0.6756716966629028, "gsm_rft_21021": 0.6757105588912964, "gsm_rft_19240": 0.6757192611694336, "camel_26582": 0.6757956743240356, "gsm_rft_29106": 0.6758382320404053, "gsm_rft_7873": 0.6758382320404053, "gsm_train_27792": 0.6758382320404053, "gsm_train_27769": 0.67591792345047, "gsm_rft_10463": 0.67593914270401, "camel_36369": 0.6759965419769287, "camel_26403": 0.6760585308074951, "camel_27281": 0.676105260848999, "camel_22520": 0.6761063933372498, "camel_26745": 0.6763196587562561, "gsm_rft_35505": 0.6763403415679932, "gsm_train_26124": 0.6763403415679932, "gsm_rft_17500": 0.6763529777526855, "gsm_rft_23643": 0.6763692498207092, "gsm_train_5107": 0.6763692498207092, "gsm_rft_14869": 0.6763909459114075, "gsm_rft_27353": 0.676412045955658, "gsm_rft_27808": 0.676412045955658, "aqua_rat_19898": 0.6764542460441589, "gsm_rft_14419": 0.6764846444129944, "gsm_train_34206": 0.676504909992218, "gsm_rft_4801": 0.6765629649162292, "camel_26560": 0.6765679121017456, "gsm_rft_936": 0.6765710115432739, "gsm_rft_1006": 0.6766812801361084, "gsm_rft_22691": 0.676746129989624, "gsm_rft_16595": 0.6767980456352234, "gsm_train_21120": 0.6767980456352234, "camel_26518": 0.6768484115600586, "aqua_rat_48726": 0.676943302154541, "camel_26567": 0.6769662499427795, "gsm_rft_7432": 0.6772913336753845, "gsm_train_7489": 0.6772913336753845, "gsm_rft_11813": 0.6774507761001587, "gsm_rft_20885": 0.6777387857437134, "gsm_train_29291": 0.6777387857437134, "camel_36458": 0.6777648329734802, "gsm_rft_15632": 0.6777951121330261, "gsm_train_17342": 0.6777951121330261, "camel_21889": 0.6779441237449646, "gsm_rft_5148": 0.6780608296394348, "aqua_rat_40609": 0.6780709624290466, "gsm_rft_15126": 0.6781483292579651, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.6781979203224182, "gsm_rft_11224": 0.6784107089042664, "camel_21895": 0.6784284114837646, "camel_27441": 0.6784946918487549, "gsm_rft_21362": 0.6785926222801208, "camel_27393": 0.6786044836044312, "camel_36470": 0.6786912083625793, "gsm_train_25440": 0.6787389516830444, "gsm_rft_3113": 0.6787389516830444, "gsm_rft_3248": 0.6788129806518555, "camel_36353": 0.6788666844367981, "aqua_rat_87402": 0.6789150238037109, "camel_37440": 0.6790521144866943, "aqua_rat_82570": 0.6792005896568298, "camel_21703": 0.6793298721313477, "gsm_rft_22281": 0.6793680787086487, "gsm_rft_13779": 0.6794927716255188, "gsm_rft_14739": 0.6795151233673096, "camel_26767": 0.6795703768730164, "gsm_rft_25357": 0.6796069145202637, "camel_27418": 0.6799083352088928, "camel_27437": 0.6800249814987183, "gsm_rft_7449": 0.6801279187202454, "camel_36343": 0.6803674101829529, "gsm_rft_4555": 0.6804155707359314, "camel_37713": 0.6806036233901978, "gsm_train_27677": 0.6806212067604065, "gsm_rft_34042": 0.6806212067604065, "camel_36808": 0.6806358695030212, "gsm_rft_30626": 0.6806759834289551, "aqua_rat_54520": 0.6807631850242615, "aqua_rat_8633": 0.6807785034179688, "gsm_rft_1995": 0.6807882189750671, "gsm_train_9463": 0.6807882189750671, "gsm_rft_25428": 0.680804431438446, "gsm_rft_22763": 0.6809408664703369, "gsm_rft_23663": 0.6811102032661438, "gsm_rft_11548": 0.6812624335289001, "gsm_train_9110": 0.6812624335289001, "gsm_rft_24984": 0.6815887689590454, "aqua_rat_70646": 0.6817167401313782, "camel_27474": 0.681824803352356, "camel_21911": 0.681939959526062, "camel_27420": 0.6823192238807678, "gsm_train_2302": 0.6829258799552917, "gsm_rft_28708": 0.6829258799552917, "camel_26460": 0.6829468011856079, "camel_27320": 0.6830112338066101, "camel_22486": 0.6830198764801025, "gsm_rft_34721": 0.6830931901931763, "gsm_rft_15216": 0.6832904815673828, "gsm_rft_10767": 0.6833783984184265, "camel_27294": 0.6834048628807068, "gsm_rft_3619": 0.6834683418273926, "gsm_rft_4917": 0.6835077404975891, "camel_39482": 0.683571994304657, "camel_27920": 0.683589518070221, "gsm_rft_9287": 0.6837352514266968, "camel_27942": 0.683823823928833, "aqua_rat_73449": 0.6839652061462402, "aqua_rat_8641": 0.6841552257537842, "camel_36356": 0.6850813031196594, "aqua_rat_1264": 0.6851422786712646, "gsm_rft_8731": 0.6852304339408875, "gsm_rft_6414": 0.6855526566505432, "gsm_rft_4133": 0.6855526566505432, "gsm_train_2795": 0.6855526566505432, "aqua_rat_53438": 0.6856963634490967, "camel_26406": 0.686130940914154, "camel_27398": 0.6863215565681458, "camel_26703": 0.6864877343177795, "gsm_train_26217": 0.6867549419403076, "aqua_rat_9712": 0.6869785785675049, "camel_13785": 0.6871193647384644, "aqua_rat_85903": 0.6871901154518127, "gsm_rft_7978": 0.6872956156730652, "gsm_rft_1020": 0.6872956156730652, "aqua_rat_36286": 0.6882743239402771, "aqua_rat_27910": 0.6888915300369263, "camel_26402": 0.6889532208442688, "camel_36367": 0.6897431015968323, "camel_36502": 0.6903108358383179, "gsm_train_8158": 0.6907788515090942, "gsm_rft_16253": 0.6907788515090942, "gsm_rft_1864": 0.6908723711967468, "camel_36360": 0.6909376382827759, "camel_26451": 0.691005527973175, "gsm_rft_8990": 0.6914533376693726, "gsm_train_7372": 0.6914533376693726, "gsm_rft_2696": 0.6920821070671082, "camel_26547": 0.692574143409729, "gsm_rft_22305": 0.6928946375846863, "camel_27961": 0.6930434107780457, "gsm_rft_12264": 0.6936571598052979, "gsm_train_24835": 0.6938924789428711, "aqua_rat_72379": 0.6948698163032532, "gsm_rft_14796": 0.6949334144592285, "gsm_train_17890": 0.6949334144592285, "gsm_rft_16634": 0.6949334144592285, "gsm_rft_12367": 0.6953373551368713, "gsm_rft_31265": 0.6960134506225586, "camel_21053": 0.696740984916687, "gsm_rft_24117": 0.6969242095947266, "camel_25447": 0.698445200920105, "camel_36756": 0.6986626386642456, "camel_36357": 0.6992948651313782, "camel_27426": 0.700400710105896, "camel_13838": 0.7010209560394287, "camel_36395": 0.7066124677658081, "aqua_rat_79062": 0.7081590294837952, "camel_37507": 0.7134884595870972}, "TheoremQA_wenhuchen/Rolle's_theorem.json": {"camel_6167": 0, "camel_7686": 0, "camel_7754": 0, "camel_7757": 0, "camel_7691": 0, "camel_6576": 0, "camel_7736": 0, "camel_7214": 0, "camel_6440": 0, "camel_6174": 0, "camel_6165": 0, "camel_7731": 0, "camel_6989": 0, "camel_7714": 0, "camel_7693": 0, "camel_7277": 0, "camel_6166": 0, "camel_6309": 0, "camel_18360": 0.748284101486206, "camel_49845": 0.7483855485916138, "camel_5007": 0.7485563158988953, "camel_46148": 0.7485900521278381, "camel_39152": 0.7485937476158142, "camel_4996": 0.7487966418266296, "camel_40817": 0.7489147186279297, "camel_1733": 0.7491722702980042, "camel_45293": 0.7491952180862427, "camel_18380": 0.7493787407875061, "aqua_rat_36627": 0.7494195699691772, "camel_18375": 0.7494746446609497, "camel_18918": 0.749581515789032, "camel_29467": 0.7496313452720642, "camel_39483": 0.7497900724411011, "camel_29060": 0.7499246001243591, "camel_39188": 0.7499907612800598, "camel_46083": 0.750061571598053, "aqua_rat_23501": 0.7502623200416565, "camel_30319": 0.7503933310508728, "aqua_rat_38400": 0.750541627407074, "camel_45315": 0.7505704164505005, "camel_28260": 0.7506129145622253, "camel_5016": 0.7506160736083984, "camel_40760": 0.7506527900695801, "aqua_rat_48488": 0.7506833076477051, "camel_41968": 0.7506852149963379, "camel_1708": 0.7508289217948914, "camel_5197": 0.7508346438407898, "camel_28815": 0.7508460879325867, "camel_39448": 0.7511001825332642, "camel_46101": 0.7512381076812744, "aqua_rat_888": 0.7513036131858826, "camel_47373": 0.7513231635093689, "camel_29979": 0.751392126083374, "math_test_prealgebra_1108": 0.7514824867248535, "camel_39489": 0.7515043616294861, "camel_39466": 0.7515291571617126, "camel_4965": 0.7515825629234314, "camel_5158": 0.7516074180603027, "camel_40850": 0.7517367005348206, "aqua_rat_9508": 0.7521684765815735, "camel_39218": 0.7522827386856079, "camel_38207": 0.7524046301841736, "aqua_rat_64993": 0.7526780962944031, "camel_46105": 0.7526819705963135, "aqua_rat_23397": 0.7528284192085266, "camel_46088": 0.7528551816940308, "aqua_rat_38896": 0.7530491948127747, "camel_5079": 0.7530888915061951, "gsm_rft_26992": 0.7532005906105042, "aqua_rat_17798": 0.7533344626426697, "gsm_rft_28321": 0.7533789277076721, "camel_1746": 0.7535523772239685, "camel_39590": 0.7536666393280029, "camel_38182": 0.7536877393722534, "aqua_rat_66974": 0.754062831401825, "gsm_train_31894": 0.7540789246559143, "camel_5177": 0.7541565299034119, "camel_41853": 0.7542035579681396, "camel_39085": 0.7542310953140259, "camel_48010": 0.7544053196907043, "camel_5181": 0.754508376121521, "camel_19759": 0.7545704245567322, "camel_19718": 0.7546005845069885, "camel_39124": 0.7546516060829163, "camel_41712": 0.7547351717948914, "camel_5035": 0.754759669303894, "aqua_rat_32286": 0.7547969222068787, "camel_39321": 0.7549559473991394, "camel_39486": 0.7549608945846558, "camel_39457": 0.7550141215324402, "camel_49430": 0.7550531029701233, "camel_39279": 0.7550837993621826, "camel_1725": 0.7551418542861938, "camel_28847": 0.7553709149360657, "camel_30167": 0.7555967569351196, "camel_5065": 0.7558158040046692, "camel_17238": 0.7558849453926086, "aqua_rat_37262": 0.7560185790061951, "camel_19781": 0.756054162979126, "camel_4993": 0.7560836672782898, "camel_46080": 0.7563604116439819, "camel_41950": 0.7563665509223938, "aqua_rat_88610": 0.7563750147819519, "camel_5172": 0.7565378546714783, "camel_39251": 0.7565584778785706, "camel_5198": 0.756804347038269, "TheoremQA_elainewan/math_calculus_12.json": 0.7572533488273621, "camel_49242": 0.7573609948158264, "camel_5037": 0.757918119430542, "camel_41882": 0.7579718828201294, "camel_49277": 0.7580002546310425, "camel_46128": 0.7582021355628967, "camel_19717": 0.758748471736908, "camel_5055": 0.7588096857070923, "aqua_rat_83913": 0.7588123679161072, "camel_38938": 0.7590422034263611, "aqua_rat_45660": 0.7590472102165222, "aqua_rat_41724": 0.7590643167495728, "camel_46129": 0.759121298789978, "camel_46151": 0.7591432332992554, "camel_46145": 0.7592751979827881, "aqua_rat_6676": 0.7595005035400391, "camel_41216": 0.7595224380493164, "camel_46143": 0.7597107291221619, "aqua_rat_14285": 0.75971519947052, "camel_19568": 0.7597590088844299, "camel_5093": 0.7597730159759521, "camel_5090": 0.7599933743476868, "camel_41705": 0.7601062655448914, "camel_39475": 0.7602932453155518, "camel_46137": 0.7605737447738647, "aqua_rat_39210": 0.7610676884651184, "camel_39223": 0.7613807320594788, "camel_40945": 0.7614297270774841, "camel_48965": 0.7616627812385559, "camel_39125": 0.7618460059165955, "camel_39579": 0.7619547247886658, "aqua_rat_64556": 0.7621152400970459, "camel_4994": 0.7623353600502014, "camel_40781": 0.7626517415046692, "camel_5041": 0.7628626823425293, "camel_5227": 0.7630295753479004, "camel_5070": 0.7631228566169739, "camel_19685": 0.7634121179580688, "camel_39311": 0.7635021805763245, "camel_30945": 0.763587236404419, "camel_39089": 0.7636572122573853, "camel_5094": 0.7637588977813721, "camel_41997": 0.7642994523048401, "camel_46097": 0.7647770643234253, "camel_46135": 0.7648357152938843, "camel_45969": 0.7650365233421326, "camel_39598": 0.765315592288971, "camel_40882": 0.7654245495796204, "camel_46100": 0.7654789686203003, "camel_39327": 0.7657653093338013, "camel_39284": 0.7664124965667725, "camel_28086": 0.7664411664009094, "TheoremQA_elainewan/math_calculus_2_11.json": 0.7667202353477478, "camel_5189": 0.7671898603439331, "camel_41967": 0.767198383808136, "camel_30880": 0.7674137353897095, "camel_5092": 0.7676052451133728, "camel_29198": 0.7676149606704712, "camel_44659": 0.7679165601730347, "camel_5043": 0.7679551243782043, "camel_18854": 0.7686108350753784, "camel_19813": 0.7690809369087219, "camel_46124": 0.7700838446617126, "camel_30907": 0.770952582359314, "camel_1744": 0.7724878191947937, "math_test_geometry_888": 0.7727663516998291, "camel_43845": 0.773038387298584, "camel_30260": 0.7733439207077026, "camel_30931": 0.7737113833427429, "camel_39104": 0.7738060355186462, "camel_19768": 0.7741901874542236, "aqua_rat_16864": 0.7745119333267212, "camel_5165": 0.7746498584747314, "camel_19754": 0.7757103443145752, "math_test_geometry_903": 0.7763858437538147, "camel_30882": 0.7778937816619873, "camel_19727": 0.7783803939819336, "camel_19784": 0.7784240245819092, "camel_46096": 0.7798289060592651, "camel_30908": 0.7807817459106445, "camel_30888": 0.7814890146255493, "camel_5029": 0.7815587520599365, "camel_4986": 0.7825628519058228, "camel_39351": 0.7832659482955933, "camel_5008": 0.7869647145271301, "camel_46120": 0.7872985601425171, "camel_19711": 0.7903915643692017, "camel_39308": 0.7908378839492798, "camel_28147": 0.7910652160644531, "camel_39254": 0.7968396544456482, "camel_39357": 0.7984243631362915, "camel_18784": 0.8003619313240051, "camel_39338": 0.8057810664176941, "camel_19728": 0.8087232112884521}, "TheoremQA_maxku/cv-cnn4.json": {"TheoremQA_maxku/cv-cnn4.json": 0, "gsm_train_10809": 0.6488357782363892, "gsm_rft_31264": 0.6488751173019409, "gsm_rft_13006": 0.6489974856376648, "camel_45709": 0.6493606567382812, "aqua_rat_71235": 0.64996737241745, "camel_30508": 0.649979829788208, "aqua_rat_22056": 0.6500391364097595, "aqua_rat_790": 0.650092601776123, "gsm_rft_19529": 0.6501766443252563, "camel_30476": 0.6502265930175781, "gsm_rft_32650": 0.650833785533905, "aqua_rat_11144": 0.6508495807647705, "camel_44739": 0.6509583592414856, "gsm_train_705": 0.650998055934906, "gsm_rft_10602": 0.6510696411132812, "gsm_rft_2925": 0.6510696411132812, "aqua_rat_69211": 0.6515499949455261, "aqua_rat_81882": 0.6516589522361755, "gsm_rft_31275": 0.6517474055290222, "gsm_rft_159": 0.6521697044372559, "gsm_train_15116": 0.6521697044372559, "camel_30876": 0.6523109078407288, "gsm_rft_4658": 0.6524396538734436, "camel_45690": 0.6528406739234924, "camel_30877": 0.6529222130775452, "camel_30556": 0.6530185341835022, "camel_27835": 0.6532132625579834, "camel_45754": 0.6533669233322144, "gsm_rft_22799": 0.6534463167190552, "camel_39281": 0.6540045738220215, "camel_45931": 0.6540586352348328, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0.654070258140564, "gsm_rft_34505": 0.6543460488319397, "camel_44447": 0.6545423865318298, "gsm_train_3509": 0.6547945737838745, "gsm_rft_4821": 0.6547945737838745, "gsm_rft_1361": 0.6547945737838745, "camel_27797": 0.654849648475647, "aqua_rat_433": 0.6549199819564819, "camel_45810": 0.6552903652191162, "camel_39339": 0.6553287506103516, "gsm_train_18364": 0.6554539799690247, "gsm_rft_19280": 0.6554539799690247, "gsm_rft_3885": 0.6554539799690247, "aqua_rat_229": 0.6565742492675781, "camel_30837": 0.657849133014679, "gsm_rft_3643": 0.6579741835594177, "gsm_train_13069": 0.6579741835594177, "aqua_rat_38167": 0.6585357189178467, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.6589533686637878, "camel_45706": 0.6589888334274292, "camel_44731": 0.6592475771903992, "camel_41413": 0.6593364477157593, "camel_30812": 0.6593505144119263, "gsm_rft_35639": 0.6594356298446655, "aqua_rat_64536": 0.6594527959823608, "camel_44459": 0.6595288515090942, "camel_28271": 0.6596329212188721, "camel_44806": 0.6596453189849854, "gsm_train_21508": 0.6601742506027222, "math_train_prealgebra_905": 0.6602795124053955, "gsm_rft_35029": 0.6602804064750671, "gsm_rft_2105": 0.6603963375091553, "gsm_rft_29903": 0.660449206829071, "gsm_train_26255": 0.660449206829071, "camel_44860": 0.6604896187782288, "aqua_rat_47040": 0.6605232357978821, "TheoremQA_maxku/cv-imageprocessing10-digital-image.json": 0.6605742573738098, "camel_45727": 0.6610172390937805, "aqua_rat_68227": 0.6611276268959045, "aqua_rat_82388": 0.661142110824585, "gsm_rft_5163": 0.661465048789978, "gsm_rft_146": 0.6615015864372253, "aqua_rat_16851": 0.6615390181541443, "gsm_train_5974": 0.6616228818893433, "math_test_prealgebra_1809": 0.6617494821548462, "camel_45684": 0.6619709134101868, "aqua_rat_21726": 0.6620042324066162, "gsm_rft_304": 0.6620086431503296, "camel_45939": 0.6622047424316406, "aqua_rat_45378": 0.6622722148895264, "aqua_rat_25886": 0.6622868180274963, "aqua_rat_80058": 0.6624633073806763, "aqua_rat_70794": 0.6624789237976074, "camel_30874": 0.6625808477401733, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.6627317070960999, "camel_30833": 0.6632940173149109, "aqua_rat_41761": 0.6634827852249146, "aqua_rat_43406": 0.6635637879371643, "aqua_rat_84253": 0.6636995673179626, "aqua_rat_16125": 0.6637217402458191, "camel_44769": 0.6640334725379944, "aqua_rat_43893": 0.6640947461128235, "camel_39138": 0.6641070246696472, "aqua_rat_82156": 0.664458692073822, "camel_30223": 0.6645289063453674, "aqua_rat_6696": 0.664624035358429, "camel_17637": 0.6654173731803894, "camel_44751": 0.6655981540679932, "aqua_rat_12780": 0.6658681631088257, "aqua_rat_60222": 0.6662515997886658, "aqua_rat_18862": 0.6668266654014587, "gsm_train_35467": 0.6669868230819702, "aqua_rat_39186": 0.6672442555427551, "gsm_rft_24803": 0.6673399806022644, "aqua_rat_47821": 0.6673657298088074, "camel_30815": 0.6674149036407471, "camel_30229": 0.6676864624023438, "gsm_rft_64": 0.6677830219268799, "gsm_rft_22250": 0.6677830219268799, "gsm_train_17996": 0.6677830219268799, "gsm_rft_8013": 0.6680346131324768, "math_test_prealgebra_1279": 0.6695622801780701, "camel_18671": 0.6701692342758179, "camel_44747": 0.6706540584564209, "camel_44726": 0.6708404421806335, "camel_44872": 0.6708753108978271, "camel_45682": 0.6710959672927856, "aqua_rat_58599": 0.6714523434638977, "camel_44791": 0.6714974641799927, "camel_44788": 0.6725397706031799, "camel_44764": 0.6739180684089661, "camel_44838": 0.6740556955337524, "camel_45819": 0.6742924451828003, "camel_18684": 0.674523115158081, "camel_44400": 0.6747305989265442, "aqua_rat_6548": 0.6750994324684143, "camel_30407": 0.6789829730987549, "gsm_rft_23591": 0.6803640723228455, "gsm_train_22690": 0.6803640723228455, "camel_44777": 0.6811189651489258, "camel_44725": 0.6812152862548828, "camel_17654": 0.6813511848449707, "gsm_rft_33011": 0.6814330220222473, "camel_44783": 0.6817563772201538, "math_test_prealgebra_969": 0.6822137832641602, "camel_44768": 0.684301495552063, "camel_44759": 0.6850670576095581, "aqua_rat_5820": 0.6852331161499023, "camel_17639": 0.6855211853981018, "camel_20495": 0.6861584782600403, "camel_44796": 0.6864930987358093, "camel_44742": 0.6881276965141296, "camel_44757": 0.688225269317627, "camel_44722": 0.6893659234046936, "camel_44792": 0.6908432841300964, "camel_44744": 0.6912055611610413, "camel_44741": 0.6915491819381714, "camel_44786": 0.6915698051452637, "camel_18719": 0.6921146512031555, "camel_44793": 0.69280606508255, "camel_44774": 0.6928130388259888, "aqua_rat_84808": 0.6932706832885742, "aqua_rat_34528": 0.6935443878173828, "camel_44784": 0.6936644911766052, "camel_44721": 0.6951767802238464, "camel_44761": 0.6954426169395447, "camel_44727": 0.696895182132721, "camel_44720": 0.6969495415687561, "camel_45936": 0.6971038579940796, "camel_44729": 0.7009630799293518, "camel_44794": 0.7011904716491699, "camel_44795": 0.7022896409034729, "camel_17618": 0.7034685015678406, "camel_44732": 0.7035740613937378, "camel_44752": 0.7038179636001587, "camel_44738": 0.7051969170570374, "camel_44743": 0.7062734365463257, "camel_44746": 0.7068122625350952, "camel_44779": 0.7069170475006104, "aqua_rat_75509": 0.706987202167511, "camel_44773": 0.7072678208351135, "camel_44776": 0.7074928879737854, "camel_44775": 0.7093188166618347, "camel_44750": 0.7108455300331116, "camel_44798": 0.7121398448944092, "camel_44778": 0.712363064289093, "camel_44723": 0.7146898508071899, "camel_44762": 0.71478670835495, "camel_44782": 0.7152794599533081, "camel_44735": 0.7160170078277588, "camel_44797": 0.7178955674171448, "TheoremQA_maxku/cv-cnn1.json": 0.7184769511222839, "camel_44767": 0.7187897562980652, "camel_44724": 0.7196472883224487, "camel_44772": 0.7208148241043091, "camel_44787": 0.7211045622825623, "camel_44760": 0.7225010991096497, "camel_44749": 0.7255256175994873, "camel_44785": 0.7272743582725525, "camel_44799": 0.729674756526947, "camel_44748": 0.7314609885215759, "camel_44758": 0.7369852066040039, "camel_44728": 0.7446563243865967, "camel_44755": 0.7460654377937317, "camel_44790": 0.7473121285438538, "camel_44424": 0.7541821599006653, "camel_44766": 0.7687405943870544, "camel_17674": 0.8153372406959534}, "TheoremQA_maxku/graphtheory3-vertexcover.json": {"camel_23134": 0, "camel_22855": 0, "camel_21116": 0, "camel_22322": 0, "camel_23416": 0, "camel_21918": 0, "camel_22850": 0, "camel_22071": 0, "camel_22040": 0, "camel_21170": 0, "camel_23430": 0, "camel_21186": 0, "camel_23146": 0, "camel_22051": 0, "camel_21197": 0, "camel_23379": 0, "camel_22820": 0, "camel_22367": 0, "camel_22388": 0, "camel_22315": 0, "camel_23400": 0, "camel_21044": 0, "camel_21678": 0, "camel_21129": 0, "camel_22223": 0, "camel_22224": 0, "camel_22863": 0, "camel_23403": 0, "camel_23141": 0, "camel_23158": 0, "camel_22755": 0, "camel_23143": 0, "camel_22760": 0, "camel_22858": 0, "camel_23432": 0, "camel_22756": 0, "camel_22857": 0, "camel_23404": 0, "camel_22335": 0, "camel_22856": 0, "camel_23374": 0, "camel_22826": 0, "camel_22294": 0, "camel_23389": 0, "camel_22808": 0, "camel_22387": 0, "camel_23424": 0, "camel_22821": 0, "camel_22726": 0, "camel_22300": 0, "camel_22117": 0, "camel_22204": 0, "camel_23770": 0, "camel_22279": 0, "camel_22374": 0, "camel_22176": 0, "camel_22355": 0, "camel_22369": 0, "camel_22393": 0, "camel_22366": 0, "camel_21057": 0, "camel_22802": 0, "camel_22758": 0, "camel_22872": 0, "camel_22210": 0, "camel_22185": 0, "camel_23360": 0, "camel_22784": 0, "camel_21176": 0, "camel_22789": 0, "camel_22745": 0, "camel_23367": 0, "camel_22765": 0, "camel_22727": 0, "camel_22009": 0, "camel_22721": 0, "camel_21152": 0, "camel_22729": 0, "camel_22809": 0, "camel_22738": 0, "camel_22375": 0, "camel_22778": 0, "camel_21133": 0, "camel_22870": 0, "camel_22854": 0, "camel_22859": 0, "camel_22829": 0, "camel_21180": 0, "camel_22363": 0, "camel_22861": 0, "camel_22753": 0, "camel_22345": 0, "camel_22347": 0, "camel_22742": 0, "camel_22754": 0, "camel_22384": 0, "camel_22744": 0, "camel_22328": 0, "camel_22873": 0, "camel_23363": 0, "camel_22752": 0, "camel_23977": 0, "camel_22761": 0, "camel_22728": 0, "camel_22361": 0, "camel_22329": 0, "camel_22746": 0, "camel_22868": 0, "camel_23395": 0, "camel_22734": 0, "camel_21083": 0, "camel_22396": 0, "camel_21198": 0, "camel_22763": 0, "camel_22168": 0, "camel_22397": 0, "camel_22398": 0, "camel_23381": 0, "camel_22847": 0, "camel_22182": 0, "camel_22875": 0, "camel_22817": 0, "camel_22749": 0, "TheoremQA_maxku/graphtheory3-vertexcover.json": 0, "camel_23427": 0, "camel_23393": 0, "camel_22330": 0, "camel_22792": 0, "camel_23397": 0, "camel_22818": 0, "camel_22179": 0, "camel_22800": 0, "camel_22769": 0, "camel_23409": 0, "camel_22806": 0, "camel_22770": 0, "camel_22860": 0, "camel_22785": 0, "camel_23438": 0, "camel_22773": 0, "camel_22377": 0, "camel_22356": 0, "camel_22835": 0, "camel_23435": 0, "camel_23362": 0, "camel_22720": 0, "camel_22722": 0, "camel_22764": 0, "camel_22768": 0, "camel_22783": 0, "camel_22795": 0, "camel_22332": 0, "camel_22743": 0, "camel_22810": 0, "camel_22737": 0, "camel_22793": 0, "camel_22777": 0, "camel_22767": 0, "camel_22757": 0, "camel_22724": 0, "camel_23410": 0, "camel_23364": 0, "camel_22799": 0, "camel_22170": 0, "aqua_rat_20425": 0.7487255334854126, "aqua_rat_56385": 0.7489909529685974, "aqua_rat_70645": 0.7496132850646973, "camel_39960": 0.7500934600830078, "TheoremQA_maxku/graphtheory4-vertexcover.json": 0.7509230375289917, "aqua_rat_54929": 0.7512273192405701, "aqua_rat_44831": 0.7520281672477722, "camel_38578": 0.7520853877067566, "camel_38564": 0.7520974278450012, "camel_39975": 0.7525872588157654, "camel_38585": 0.7526946663856506, "camel_39928": 0.7547411918640137, "camel_38489": 0.7558279633522034, "aqua_rat_44895": 0.7558419704437256, "camel_39938": 0.7561091780662537, "camel_38540": 0.7569192051887512, "camel_39974": 0.7569435834884644, "camel_38609": 0.7572692632675171, "camel_38906": 0.758118748664856, "camel_39997": 0.7584371566772461, "camel_39996": 0.7584530115127563, "camel_38569": 0.759076714515686, "camel_38561": 0.7591642737388611, "camel_38572": 0.75975102186203, "camel_38587": 0.7624130249023438, "aqua_rat_64683": 0.7635840773582458, "aqua_rat_7562": 0.7636012434959412, "aqua_rat_77006": 0.7639684677124023, "aqua_rat_10797": 0.7655496597290039, "camel_39941": 0.7665286064147949, "TheoremQA_maxku/graphtheory5-vertexcover.json": 0.7676904797554016, "aqua_rat_76903": 0.768598735332489, "TheoremQA_maxku/graphtheory2-vertexcover.json": 0.769429087638855, "aqua_rat_83797": 0.7695270776748657, "camel_38526": 0.7731406688690186, "camel_38586": 0.7742905616760254}, "TheoremQA_jianyu_xu/Stirling_number_second_kind_6.json": {"camel_21028": 0, "camel_20604": 0, "camel_20823": 0, "camel_21568": 0, "camel_20626": 0, "camel_20411": 0, "camel_20462": 0, "camel_21400": 0, "camel_20661": 0, "camel_20973": 0, "camel_20656": 0, "camel_20640": 0, "camel_20861": 0, "camel_20848": 0, "camel_20317": 0, "camel_20410": 0, "camel_20706": 0, "camel_21798": 0, "camel_21219": 0, "camel_20619": 0, "camel_20808": 0, "camel_21015": 0, "camel_20853": 0, "camel_20844": 0, "TheoremQA_jianyu_xu/Stirling_number_second_kind_6.json": 0, "camel_20506": 0, "camel_20812": 0, "camel_20695": 0, "camel_20637": 0, "camel_21223": 0, "camel_20856": 0, "camel_20299": 0, "camel_20698": 0, "camel_20308": 0, "camel_20248": 0, "camel_20262": 0, "camel_20602": 0, "camel_20849": 0, "camel_20805": 0, "camel_20623": 0, "camel_20297": 0, "camel_20867": 0, "camel_20860": 0, "camel_21117": 0, "camel_20257": 0, "camel_20514": 0, "camel_20841": 0, "camel_21361": 0, "camel_20302": 0, "camel_20609": 0, "camel_20818": 0, "camel_20577": 0, "camel_20836": 0, "camel_20499": 0, "camel_20598": 0, "camel_20578": 0, "camel_20863": 0, "camel_20414": 0, "camel_20583": 0, "camel_20813": 0, "camel_21050": 0, "camel_21246": 0, "camel_21360": 0, "camel_20614": 0, "camel_20806": 0, "camel_20301": 0, "camel_20563": 0, "camel_20596": 0, "camel_20310": 0, "aqua_rat_3279": 0.7968106865882874, "aqua_rat_10178": 0.7977743148803711, "math_train_counting_and_probability_667": 0.7977809309959412, "math_train_counting_and_probability_500": 0.797824501991272, "aqua_rat_58193": 0.7981878519058228, "aqua_rat_45153": 0.7982697486877441, "aqua_rat_24104": 0.7982725501060486, "aqua_rat_19931": 0.7984949350357056, "aqua_rat_66118": 0.7988792657852173, "aqua_rat_29319": 0.7989048361778259, "aqua_rat_20907": 0.7996227145195007, "aqua_rat_65294": 0.8002186417579651, "aqua_rat_41607": 0.8006128668785095, "aqua_rat_76303": 0.8006584644317627, "math_test_counting_and_probability_695": 0.8007152080535889, "aqua_rat_39259": 0.8012192249298096, "math_train_algebra_2532": 0.8014767169952393, "aqua_rat_44268": 0.8014793395996094, "aqua_rat_45483": 0.8014894127845764, "aqua_rat_77406": 0.8016040325164795, "aqua_rat_89037": 0.802217960357666, "aqua_rat_88489": 0.8022347092628479, "aqua_rat_49273": 0.8023139238357544, "aqua_rat_52832": 0.8023279309272766, "aqua_rat_5049": 0.8026431798934937, "math_train_counting_and_probability_70": 0.802945077419281, "aqua_rat_11273": 0.8029783368110657, "aqua_rat_81317": 0.8031483292579651, "aqua_rat_34": 0.8033417463302612, "aqua_rat_58757": 0.8034272193908691, "math_test_counting_and_probability_862": 0.8041579723358154, "aqua_rat_8375": 0.8041934967041016, "aqua_rat_73393": 0.8042462468147278, "aqua_rat_68846": 0.8043087720870972, "aqua_rat_2658": 0.8043498396873474, "aqua_rat_50641": 0.8049273490905762, "aqua_rat_11061": 0.8052050471305847, "aqua_rat_13369": 0.8053064942359924, "aqua_rat_82146": 0.8055384755134583, "aqua_rat_44511": 0.8057262897491455, "aqua_rat_53084": 0.8059163093566895, "aqua_rat_74550": 0.8065056204795837, "aqua_rat_25894": 0.8073511123657227, "camel_38534": 0.8076948523521423, "aqua_rat_13585": 0.8084579706192017, "aqua_rat_17329": 0.8084824085235596, "aqua_rat_77140": 0.8086695671081543, "aqua_rat_18404": 0.8087446093559265, "aqua_rat_27274": 0.8087860345840454, "aqua_rat_71434": 0.8090353012084961, "aqua_rat_575": 0.8091309070587158, "aqua_rat_73402": 0.8092921376228333, "aqua_rat_46365": 0.8096105456352234, "aqua_rat_35289": 0.809692919254303, "aqua_rat_37649": 0.8105325698852539, "TheoremQA_jianyu_xu/combination_and_permutation_1.json": 0.8110895156860352, "aqua_rat_18901": 0.8111347556114197, "aqua_rat_75517": 0.8112636804580688, "aqua_rat_14308": 0.8115178942680359, "aqua_rat_70446": 0.8129138350486755, "aqua_rat_5030": 0.8130176663398743, "aqua_rat_10186": 0.8133531212806702, "math_train_counting_and_probability_696": 0.8134633302688599, "aqua_rat_39115": 0.8141583204269409, "aqua_rat_11531": 0.8153871893882751, "aqua_rat_4294": 0.8153992891311646, "aqua_rat_49950": 0.8172101378440857, "math_train_counting_and_probability_784": 0.8172482252120972, "aqua_rat_2480": 0.8172685503959656, "aqua_rat_57767": 0.8174261450767517, "aops_2019_AMC_8_Problems/Problem_25": 0.8178873062133789, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": 0.8182857036590576, "aqua_rat_57502": 0.8186367154121399, "math_test_counting_and_probability_485": 0.8188623785972595, "aqua_rat_21240": 0.8189828395843506, "aqua_rat_7248": 0.8190008401870728, "math_test_counting_and_probability_341": 0.8192347884178162, "math_train_counting_and_probability_371": 0.8196868300437927, "aqua_rat_60238": 0.819776713848114, "aqua_rat_61965": 0.8203590512275696, "aqua_rat_84159": 0.8209636211395264, "aqua_rat_77698": 0.8215554356575012, "aqua_rat_49569": 0.821615993976593, "math_train_counting_and_probability_375": 0.8218140006065369, "aqua_rat_66391": 0.8221438527107239, "aqua_rat_29348": 0.8221535086631775, "aqua_rat_415": 0.8223617076873779, "aqua_rat_73122": 0.8225976824760437, "aqua_rat_39642": 0.8227283358573914, "math_train_counting_and_probability_241": 0.8227640986442566, "math_train_counting_and_probability_273": 0.8231878280639648, "aqua_rat_76714": 0.8251401782035828, "aqua_rat_54461": 0.8257102370262146, "aqua_rat_63836": 0.826022744178772, "aqua_rat_16877": 0.8262414336204529, "math_test_counting_and_probability_79": 0.8262824416160583, "math_train_counting_and_probability_125": 0.8264023065567017, "aqua_rat_89113": 0.82651287317276, "aqua_rat_34678": 0.8276604413986206, "aqua_rat_57985": 0.8277366161346436, "aqua_rat_25369": 0.8279769420623779, "aqua_rat_42061": 0.8280192613601685, "aqua_rat_61326": 0.8281227946281433, "aqua_rat_8627": 0.8302074074745178, "aqua_rat_62284": 0.830288290977478, "aqua_rat_37185": 0.8307005763053894, "aqua_rat_62261": 0.8314686417579651, "aqua_rat_40108": 0.8316216468811035, "aqua_rat_41861": 0.8322460055351257, "aqua_rat_22458": 0.8331534266471863, "aqua_rat_61885": 0.8342578411102295, "camel_12727": 0.8347441554069519, "aqua_rat_29651": 0.8356892466545105, "aqua_rat_48130": 0.8357694149017334, "math_test_counting_and_probability_416": 0.8358619809150696, "math_train_counting_and_probability_252": 0.8360549807548523, "aqua_rat_210": 0.8367555737495422, "aqua_rat_60936": 0.838441014289856, "aqua_rat_83784": 0.8388330340385437, "math_train_counting_and_probability_98": 0.8407196402549744, "aqua_rat_26524": 0.8408819437026978, "math_train_counting_and_probability_149": 0.841088593006134, "aqua_rat_75188": 0.8420173525810242, "aqua_rat_34205": 0.8439517021179199, "math_train_counting_and_probability_296": 0.8440216183662415, "aqua_rat_39610": 0.8492121696472168, "aqua_rat_19436": 0.8496320247650146, "math_test_counting_and_probability_71": 0.8555620908737183, "aqua_rat_56015": 0.8562926650047302, "math_test_counting_and_probability_294": 0.8649035692214966, "math_train_counting_and_probability_83": 0.8734613656997681}, "TheoremQA_elainewan/econ_micro_14_3.json": {"TheoremQA_elainewan/econ_micro_14_3.json": 0, "camel_39495": 0.8384828567504883, "camel_41898": 0.8385483622550964, "camel_24737": 0.8385656476020813, "camel_24920": 0.8387316465377808, "camel_37727": 0.838779628276825, "camel_39093": 0.8390030264854431, "camel_39898": 0.8390910625457764, "camel_24942": 0.839148998260498, "camel_24858": 0.8392209410667419, "camel_38929": 0.8392356634140015, "camel_24787": 0.8392666578292847, "camel_38126": 0.8392942547798157, "camel_6231": 0.8393251299858093, "camel_24957": 0.8393393754959106, "camel_38744": 0.8393583297729492, "aqua_rat_19811": 0.8393746018409729, "camel_6185": 0.8394566774368286, "camel_40712": 0.839529275894165, "camel_24773": 0.839724600315094, "camel_39437": 0.8397372364997864, "aqua_rat_65896": 0.8399174809455872, "camel_40907": 0.8399279713630676, "camel_39875": 0.8402119874954224, "camel_39869": 0.840230405330658, "aqua_rat_4104": 0.8402412533760071, "camel_41138": 0.8404384851455688, "aqua_rat_9396": 0.8405308723449707, "camel_24774": 0.8407078981399536, "camel_24883": 0.8407149910926819, "camel_24845": 0.8407459259033203, "aqua_rat_58260": 0.84078049659729, "camel_24782": 0.8409821391105652, "camel_39912": 0.8409858345985413, "aqua_rat_18808": 0.8409888744354248, "camel_25133": 0.8410317897796631, "aqua_rat_27138": 0.8410406112670898, "aqua_rat_28862": 0.8411707282066345, "camel_39846": 0.841323733329773, "camel_38180": 0.8413525223731995, "camel_24755": 0.8413773775100708, "camel_38986": 0.8414293527603149, "camel_38889": 0.8414325714111328, "camel_40822": 0.8414857387542725, "camel_24923": 0.8416243195533752, "camel_24898": 0.8417417407035828, "aqua_rat_11315": 0.8421603441238403, "camel_39106": 0.842421293258667, "camel_24727": 0.8427051305770874, "aqua_rat_64154": 0.8429657220840454, "aqua_rat_17073": 0.8433043956756592, "aqua_rat_54993": 0.8433918356895447, "camel_7712": 0.8434208631515503, "camel_39911": 0.8435719609260559, "camel_25123": 0.8436732292175293, "camel_24754": 0.8437458872795105, "aqua_rat_36925": 0.8441497683525085, "camel_39855": 0.84450763463974, "camel_24725": 0.8449680209159851, "camel_24926": 0.8451527953147888, "camel_39378": 0.8454309105873108, "camel_24816": 0.8456354737281799, "camel_39876": 0.8456786870956421, "aqua_rat_76016": 0.8458150625228882, "camel_39891": 0.8459881544113159, "aqua_rat_86319": 0.8460373878479004, "aqua_rat_996": 0.8461405038833618, "aqua_rat_27992": 0.8462836146354675, "camel_24907": 0.8463367223739624, "camel_24553": 0.8472512364387512, "camel_39552": 0.8472687005996704, "camel_38099": 0.8472839593887329, "camel_38738": 0.8473195433616638, "camel_21598": 0.8476913571357727, "camel_38863": 0.8480600714683533, "camel_39870": 0.8481218814849854, "camel_24901": 0.8486202359199524, "camel_40759": 0.849432647228241, "camel_39865": 0.8497430086135864, "camel_6228": 0.8498392701148987, "camel_24739": 0.8499362468719482, "camel_40942": 0.8501108288764954, "camel_39847": 0.8501442074775696, "camel_39754": 0.8502228260040283, "camel_24827": 0.8504878282546997, "camel_39892": 0.8505718111991882, "camel_6214": 0.8506373763084412, "camel_15793": 0.850723922252655, "camel_39845": 0.8507920503616333, "camel_38928": 0.85123211145401, "camel_39843": 0.8514494299888611, "camel_40669": 0.8514771461486816, "camel_24824": 0.8517866134643555, "camel_24925": 0.8519602417945862, "camel_38304": 0.8524420261383057, "camel_38224": 0.8526070713996887, "camel_39900": 0.852744460105896, "camel_39895": 0.8535672426223755, "camel_38220": 0.8537132740020752, "camel_39884": 0.8538246154785156, "camel_38729": 0.853940486907959, "camel_40772": 0.854042649269104, "camel_39917": 0.8540526032447815, "camel_39858": 0.8540838956832886, "camel_38205": 0.8541219234466553, "camel_39873": 0.8542597889900208, "camel_39882": 0.8542824983596802, "camel_39848": 0.8543409705162048, "camel_37759": 0.8546316027641296, "camel_39906": 0.8547192811965942, "camel_38786": 0.855873703956604, "camel_39094": 0.8559544086456299, "camel_24853": 0.8560167551040649, "camel_40598": 0.8563015460968018, "camel_39860": 0.8564057350158691, "camel_39849": 0.8565131425857544, "camel_38628": 0.856917679309845, "camel_24840": 0.856995701789856, "camel_24802": 0.8569986820220947, "camel_24743": 0.8572170734405518, "camel_39603": 0.8575902581214905, "camel_39850": 0.8579730987548828, "camel_24893": 0.8579859137535095, "camel_38256": 0.8583345413208008, "camel_24935": 0.8583638072013855, "camel_39915": 0.8592185974121094, "camel_24759": 0.8603183627128601, "camel_24875": 0.8618062138557434, "camel_39519": 0.8618822693824768, "camel_39119": 0.8619471192359924, "camel_39872": 0.862098217010498, "camel_39859": 0.8621199131011963, "camel_39857": 0.8630061149597168, "camel_39874": 0.8631142377853394, "camel_39907": 0.8631861209869385, "camel_39867": 0.8634690046310425, "camel_39854": 0.863805890083313, "camel_39861": 0.8638595938682556, "camel_24823": 0.8639206290245056, "camel_24909": 0.8644652366638184, "camel_41923": 0.8650033473968506, "camel_39856": 0.8654823899269104, "camel_41906": 0.8658699989318848, "camel_39918": 0.8666378855705261, "camel_39114": 0.8675750494003296, "camel_39899": 0.867720901966095, "camel_39844": 0.8679286241531372, "camel_41451": 0.8681558966636658, "camel_39883": 0.8682509064674377, "camel_39910": 0.8686268329620361, "camel_39914": 0.8687884211540222, "camel_40933": 0.8688597679138184, "TheoremQA_elainewan/econ_micro_11.json": 0.8688751459121704, "camel_39863": 0.8696173429489136, "camel_39842": 0.8698000907897949, "camel_40698": 0.8706300854682922, "camel_40682": 0.8707001805305481, "camel_39897": 0.8708608746528625, "camel_39893": 0.8717507719993591, "camel_39894": 0.872203528881073, "camel_39852": 0.8724859356880188, "camel_38047": 0.8729797005653381, "camel_39887": 0.8733294010162354, "camel_24729": 0.8734592199325562, "camel_39888": 0.8742466568946838, "camel_39881": 0.8747100830078125, "camel_24892": 0.8747358918190002, "camel_41835": 0.8752069473266602, "camel_39388": 0.8755906820297241, "camel_39904": 0.8762121796607971, "camel_39885": 0.8767886161804199, "camel_40796": 0.8777561783790588, "camel_39878": 0.8777614235877991, "camel_39886": 0.8779435753822327, "camel_39919": 0.8779786229133606, "camel_39868": 0.8785406947135925, "camel_39896": 0.8790234923362732, "camel_39880": 0.8795500993728638, "camel_39879": 0.8802050948143005, "camel_39877": 0.8803291320800781, "camel_39905": 0.8807737231254578, "camel_39902": 0.8810471892356873, "camel_7017": 0.8815670013427734, "camel_39908": 0.8817264437675476, "camel_39502": 0.8820177912712097, "camel_39853": 0.8833814859390259, "camel_39890": 0.8839221596717834, "camel_39909": 0.8848418593406677, "camel_39903": 0.8877117037773132, "camel_39840": 0.8880677223205566, "camel_39871": 0.8891088366508484, "camel_39498": 0.8891579508781433, "camel_39866": 0.8903703093528748, "camel_41749": 0.8921099305152893, "camel_39913": 0.8931447267532349, "camel_39332": 0.894271194934845, "camel_39464": 0.8946110010147095, "camel_39851": 0.896977961063385, "camel_38362": 0.8970716595649719, "camel_38203": 0.9006118178367615}, "TheoremQA_wenhuchen/euler's_method1.json": {"camel_7277": 0, "camel_7262": 0, "camel_16940": 0, "camel_16044": 0, "camel_6359": 0, "camel_16033": 0, "camel_17155": 0, "camel_17180": 0, "camel_17181": 0, "camel_17149": 0, "camel_17162": 0, "camel_16815": 0, "camel_6337": 0, "camel_6248": 0, "camel_7207": 0, "camel_40704": 0, "camel_7268": 0, "camel_6849": 0, "camel_7203": 0, "camel_16100": 0, "camel_6358": 0, "camel_17545": 0, "camel_17171": 0, "camel_17167": 0, "camel_17158": 0, "camel_17183": 0, "camel_17133": 0, "camel_17157": 0, "camel_17153": 0, "camel_17190": 0, "aqua_rat_9148": 0.7093896269798279, "gsm_rft_22580": 0.7094144821166992, "camel_37991": 0.7094240188598633, "gsm_rft_19857": 0.7096372842788696, "aqua_rat_76127": 0.7097584009170532, "gsm_rft_7271": 0.7098223567008972, "gsm_rft_17396": 0.7098795771598816, "gsm_rft_26800": 0.7098917365074158, "gsm_rft_29920": 0.7099215388298035, "gsm_rft_35": 0.7099548578262329, "aqua_rat_65926": 0.7099765539169312, "aqua_rat_24849": 0.7100410461425781, "aqua_rat_51871": 0.7100710272789001, "gsm_rft_14194": 0.7100785970687866, "aqua_rat_29678": 0.7101513743400574, "aqua_rat_32037": 0.7102372050285339, "aqua_rat_36251": 0.710274338722229, "aqua_rat_20090": 0.7103148698806763, "aqua_rat_53204": 0.7104257941246033, "aqua_rat_82453": 0.7104902267456055, "gsm_rft_27771": 0.7104932069778442, "gsm_rft_27286": 0.7104932069778442, "gsm_train_31678": 0.7104932069778442, "gsm_rft_3700": 0.7105597257614136, "gsm_rft_5605": 0.7105855345726013, "gsm_rft_32876": 0.7105885744094849, "gsm_train_5958": 0.710829496383667, "gsm_rft_11799": 0.710829496383667, "gsm_rft_31968": 0.7108463644981384, "aqua_rat_56227": 0.7108729481697083, "gsm_train_6685": 0.7109557390213013, "gsm_train_26241": 0.7110200524330139, "aqua_rat_89280": 0.7110387682914734, "gsm_rft_16319": 0.7111385464668274, "aqua_rat_12115": 0.7112074494361877, "gsm_rft_20038": 0.7112119793891907, "gsm_rft_30828": 0.7112269997596741, "gsm_train_29816": 0.7112487554550171, "gsm_rft_33344": 0.7112487554550171, "gsm_rft_21944": 0.7112529873847961, "gsm_rft_20403": 0.7113075256347656, "gsm_rft_23878": 0.711331307888031, "aqua_rat_32474": 0.7114018797874451, "aqua_rat_60986": 0.7114405035972595, "aqua_rat_59846": 0.7114664316177368, "aqua_rat_2718": 0.7114953994750977, "gsm_rft_9639": 0.7116039395332336, "gsm_rft_28418": 0.7116461396217346, "aqua_rat_67841": 0.7116920948028564, "aqua_rat_20826": 0.7116984724998474, "aqua_rat_15784": 0.7119060754776001, "aqua_rat_69617": 0.7121056914329529, "gsm_rft_35446": 0.7124344706535339, "gsm_rft_13191": 0.7126425504684448, "aqua_rat_9347": 0.7126695513725281, "aqua_rat_77082": 0.7127545475959778, "aqua_rat_14328": 0.7128006219863892, "aqua_rat_23237": 0.7128078937530518, "gsm_rft_21208": 0.712860107421875, "camel_45301": 0.7128773927688599, "aqua_rat_23177": 0.7129309773445129, "aqua_rat_76749": 0.7129756212234497, "gsm_rft_23499": 0.7131025195121765, "aqua_rat_39529": 0.7131618857383728, "gsm_rft_30558": 0.7131768465042114, "gsm_train_20544": 0.7132145762443542, "gsm_rft_16632": 0.7132145762443542, "gsm_rft_21318": 0.7133290767669678, "gsm_rft_30086": 0.7133290767669678, "math_train_algebra_1394": 0.7134206891059875, "aqua_rat_14786": 0.7135030031204224, "gsm_rft_419": 0.7135180830955505, "gsm_train_24798": 0.7135500907897949, "aqua_rat_30853": 0.7135846018791199, "aqua_rat_50180": 0.7136417627334595, "aqua_rat_16497": 0.7139629125595093, "camel_39458": 0.714090883731842, "camel_39505": 0.7142198085784912, "aqua_rat_32500": 0.7142238616943359, "aqua_rat_38240": 0.7143073081970215, "gsm_train_1184": 0.7143511176109314, "gsm_rft_6556": 0.7143511176109314, "aqua_rat_56844": 0.714388370513916, "gsm_rft_30976": 0.7143933176994324, "gsm_rft_9703": 0.7144812345504761, "aqua_rat_24936": 0.7144990563392639, "aqua_rat_1178": 0.714509129524231, "gsm_rft_9090": 0.714589536190033, "gsm_rft_19011": 0.7146912813186646, "aqua_rat_55760": 0.714733362197876, "aqua_rat_9211": 0.7148146629333496, "gsm_rft_8250": 0.7150301933288574, "gsm_rft_11670": 0.7152106761932373, "aqua_rat_55711": 0.715228796005249, "math_test_algebra_981": 0.7153791189193726, "aqua_rat_69620": 0.7155187726020813, "aqua_rat_27858": 0.7155596613883972, "aqua_rat_49625": 0.7159186005592346, "aqua_rat_255": 0.7161092758178711, "gsm_rft_1904": 0.7162866592407227, "aqua_rat_6661": 0.7165199518203735, "aqua_rat_24187": 0.7165899872779846, "aqua_rat_29953": 0.7166143655776978, "aqua_rat_58854": 0.7166558504104614, "gsm_rft_18763": 0.7167698740959167, "gsm_rft_13509": 0.7170841693878174, "gsm_train_31200": 0.7170841693878174, "gsm_rft_10234": 0.7170853614807129, "gsm_rft_14264": 0.7170853614807129, "gsm_rft_7403": 0.7173172831535339, "gsm_rft_7981": 0.7177003622055054, "gsm_rft_21229": 0.7177441716194153, "gsm_rft_9141": 0.7177484035491943, "gsm_train_7342": 0.7177685499191284, "gsm_rft_15498": 0.7178041934967041, "math_test_algebra_2403": 0.7180107831954956, "aqua_rat_69455": 0.7181394696235657, "gsm_train_22796": 0.718373715877533, "aqua_rat_33664": 0.7184586524963379, "aqua_rat_87246": 0.7189032435417175, "aqua_rat_8383": 0.7189564108848572, "gsm_rft_22441": 0.7193163633346558, "gsm_rft_15440": 0.7194361686706543, "gsm_rft_469": 0.7195469737052917, "gsm_train_15179": 0.7195469737052917, "gsm_rft_24409": 0.7197974920272827, "gsm_train_32181": 0.7198388576507568, "gsm_rft_7190": 0.7198509573936462, "gsm_rft_960": 0.7199487090110779, "aqua_rat_13846": 0.720061182975769, "aqua_rat_47762": 0.7207239270210266, "aqua_rat_49730": 0.7211403250694275, "gsm_rft_34686": 0.7216520309448242, "aqua_rat_59416": 0.7229607701301575, "camel_28149": 0.7229985594749451, "gsm_rft_14385": 0.7242188453674316, "aqua_rat_72895": 0.7245079874992371, "camel_37955": 0.724929928779602, "gsm_rft_33872": 0.7271401286125183, "gsm_train_16343": 0.7275709509849548, "gsm_rft_10218": 0.7275709509849548, "aqua_rat_34283": 0.7276577949523926, "gsm_rft_31224": 0.7281178832054138, "camel_39486": 0.7286895513534546, "gsm_rft_21743": 0.7287418246269226, "aqua_rat_2700": 0.730111300945282, "aqua_rat_6030": 0.7306616902351379, "gsm_train_8946": 0.730941116809845, "aqua_rat_27506": 0.7310145497322083, "aqua_rat_62048": 0.7310707569122314, "aqua_rat_84419": 0.731576144695282, "gsm_train_29627": 0.7315881252288818, "gsm_rft_17465": 0.7315881252288818, "gsm_rft_17947": 0.7315881252288818, "gsm_rft_3518": 0.7342541813850403, "gsm_train_20796": 0.7342541813850403, "camel_36269": 0.7343769669532776, "aqua_rat_75339": 0.7343863248825073, "camel_37933": 0.734421968460083, "aqua_rat_10823": 0.7350478172302246, "aqua_rat_59651": 0.7355932593345642, "camel_39457": 0.7365689873695374, "gsm_rft_32763": 0.7379078269004822, "gsm_rft_28257": 0.7379698753356934, "aqua_rat_5634": 0.7381064891815186, "aqua_rat_88394": 0.7388385534286499, "aqua_rat_12508": 0.7419715523719788, "aqua_rat_3097": 0.7426401376724243, "aqua_rat_31829": 0.7486317753791809, "aqua_rat_33076": 0.7494544982910156}, "TheoremQA_maxku/graphtheory10-shortestpath.json": {"camel_22242": 0, "camel_39922": 0, "camel_38608": 0, "camel_38598": 0, "camel_22398": 0, "camel_22032": 0, "camel_22326": 0, "camel_39990": 0, "camel_38625": 0, "camel_23921": 0, "camel_23997": 0, "camel_22056": 0, "camel_22004": 0, "camel_39964": 0, "camel_22354": 0, "camel_22062": 0, "camel_39952": 0, "camel_22296": 0, "camel_22029": 0, "camel_22264": 0, "camel_22037": 0, "camel_22277": 0, "camel_38564": 0, "camel_39941": 0, "camel_22014": 0, "camel_22247": 0, "camel_22058": 0, "camel_38573": 0, "camel_22033": 0, "camel_21670": 0, "camel_38615": 0, "camel_23973": 0, "camel_21609": 0, "camel_23947": 0, "camel_38585": 0, "camel_22266": 0, "camel_23926": 0, "camel_38906": 0, "camel_39983": 0, "camel_22031": 0, "camel_39979": 0, "camel_22065": 0, "camel_22070": 0, "camel_22021": 0, "camel_23970": 0, "camel_22042": 0, "camel_22361": 0, "camel_39932": 0, "camel_22005": 0, "camel_39947": 0, "camel_22038": 0, "camel_22324": 0, "camel_22052": 0, "camel_22006": 0, "camel_21639": 0, "camel_39980": 0, "camel_23981": 0, "camel_22073": 0, "camel_39934": 0, "camel_22028": 0, "camel_22067": 0, "camel_22449": 0, "camel_22072": 0, "camel_21589": 0, "camel_22003": 0, "camel_22240": 0, "camel_21659": 0, "camel_22294": 0, "camel_22008": 0, "camel_22044": 0, "camel_38594": 0, "camel_38583": 0, "camel_22279": 0, "camel_38501": 0, "camel_39999": 0, "camel_22053": 0, "camel_22025": 0, "camel_39971": 0, "camel_23983": 0, "camel_22035": 0, "camel_21654": 0, "camel_22069": 0, "camel_21678": 0, "camel_22017": 0, "camel_22043": 0, "camel_23980": 0, "camel_21667": 0, "camel_22300": 0, "camel_39997": 0, "camel_22077": 0, "camel_21648": 0, "camel_38627": 0, "camel_21634": 0, "camel_38611": 0, "camel_21675": 0, "camel_38587": 0, "camel_38569": 0, "camel_22001": 0, "camel_21628": 0, "camel_22075": 0, "camel_38560": 0, "camel_21612": 0, "camel_22041": 0, "camel_22252": 0, "camel_39975": 0, "camel_39959": 0, "camel_21627": 0, "camel_39946": 0, "camel_39960": 0, "camel_38609": 0, "camel_22330": 0, "camel_23964": 0, "camel_38489": 0, "camel_39926": 0, "camel_22057": 0, "camel_23991": 0, "camel_22024": 0, "camel_21664": 0, "camel_22397": 0, "camel_21663": 0, "camel_38621": 0, "camel_39957": 0, "camel_39921": 0, "camel_22051": 0, "camel_21630": 0, "camel_22344": 0, "camel_23961": 0, "camel_22046": 0, "camel_39931": 0, "camel_21610": 0, "camel_39998": 0, "camel_22000": 0, "camel_22367": 0, "camel_22055": 0, "camel_21646": 0, "camel_39968": 0, "camel_39977": 0, "camel_22026": 0, "camel_21661": 0, "camel_38491": 0, "camel_22076": 0, "camel_38561": 0, "camel_22040": 0, "camel_39972": 0, "camel_21641": 0, "camel_38635": 0, "camel_22023": 0, "camel_22340": 0, "camel_21601": 0, "camel_22016": 0, "camel_39987": 0, "camel_38576": 0, "camel_21658": 0, "camel_22059": 0, "camel_21607": 0, "camel_22010": 0, "camel_39996": 0, "camel_22061": 0, "camel_22068": 0, "camel_22022": 0, "camel_39938": 0, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0, "camel_22049": 0, "camel_22011": 0, "camel_38572": 0, "camel_38581": 0, "camel_39920": 0, "camel_22079": 0, "camel_22368": 0, "camel_22047": 0, "camel_22009": 0, "camel_22332": 0, "camel_38630": 0, "camel_22060": 0, "camel_39928": 0, "camel_22015": 0, "camel_39974": 0, "camel_22071": 0, "aqua_rat_18852": 0.7751340866088867, "gsm_rft_12390": 0.7756040692329407, "gsm_rft_30931": 0.7763968706130981, "gsm_rft_9082": 0.777334988117218, "gsm_rft_30590": 0.7775006890296936, "gsm_rft_18414": 0.7778989672660828, "gsm_rft_29652": 0.7779149413108826, "gsm_train_12841": 0.7779149413108826, "camel_36749": 0.778420627117157, "gsm_rft_4482": 0.7785589694976807, "aqua_rat_20425": 0.7798957228660583, "gsm_rft_339": 0.7801511287689209, "aqua_rat_43370": 0.7809444665908813, "aqua_rat_33603": 0.7816764712333679, "aqua_rat_41715": 0.7817977070808411, "aqua_rat_56385": 0.7821990251541138, "camel_36503": 0.7826775312423706, "aqua_rat_44895": 0.7877342104911804, "camel_41246": 0.7952701449394226, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": 0.8044255971908569, "TheoremQA_maxku/graphtheory7-shortestpath.json": 0.830583393573761, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0.8455613851547241}, "TheoremQA_wenhuchen/euler's_method2.json": {"camel_16938": 0, "camel_16947": 0, "camel_16080": 0, "camel_17433": 0, "camel_16032": 0, "camel_16046": 0, "camel_16083": 0, "camel_17005": 0, "camel_16829": 0, "camel_16860": 0, "camel_17190": 0, "camel_16960": 0, "camel_16917": 0, "camel_17018": 0, "camel_16980": 0, "camel_16089": 0, "camel_40334": 0, "camel_16054": 0, "camel_17545": 0, "camel_16028": 0, "camel_16007": 0, "camel_16903": 0, "camel_16979": 0, "camel_16909": 0, "camel_17361": 0, "camel_17027": 0, "camel_16964": 0, "camel_16956": 0, "camel_16953": 0, "camel_16898": 0, "camel_17012": 0, "camel_16963": 0, "camel_16041": 0, "camel_16061": 0, "camel_16882": 0, "camel_16918": 0, "camel_16970": 0, "camel_16001": 0, "camel_16929": 0, "camel_16937": 0, "camel_16125": 0, "camel_16151": 0, "camel_17004": 0, "camel_16022": 0, "camel_16889": 0, "camel_17097": 0, "camel_16914": 0, "camel_16940": 0, "camel_17030": 0, "camel_16057": 0, "camel_16149": 0, "camel_16900": 0, "camel_17066": 0, "camel_16913": 0, "camel_6358": 0, "camel_16905": 0, "camel_16921": 0, "camel_17054": 0, "camel_16867": 0, "camel_16978": 0, "camel_16996": 0, "camel_16973": 0, "camel_16965": 0, "camel_17022": 0, "camel_16154": 0, "camel_16958": 0, "camel_16890": 0, "camel_16851": 0, "camel_16033": 0, "camel_40249": 0, "camel_16997": 0, "camel_16936": 0, "camel_16825": 0, "camel_16988": 0, "camel_16893": 0, "camel_16943": 0, "camel_16076": 0, "camel_17028": 0, "camel_16906": 0, "camel_17068": 0, "camel_16030": 0, "camel_16986": 0, "camel_16815": 0, "camel_17020": 0, "camel_16120": 0, "camel_16100": 0, "camel_17039": 0, "camel_16044": 0, "camel_16040": 0, "camel_16961": 0, "camel_16894": 0, "camel_17017": 0, "camel_16902": 0, "camel_16944": 0, "camel_16952": 0, "camel_16003": 0, "camel_16888": 0, "camel_17023": 0, "camel_16919": 0, "camel_16895": 0, "camel_16884": 0, "camel_16925": 0, "camel_16942": 0, "camel_16901": 0, "camel_16058": 0, "camel_17000": 0, "camel_16916": 0, "camel_16976": 0, "camel_16053": 0, "camel_16922": 0, "aqua_rat_12444": 0.7239594459533691, "camel_28163": 0.7239804863929749, "aqua_rat_58683": 0.7240489721298218, "camel_28531": 0.724261999130249, "camel_29725": 0.7244226932525635, "camel_28187": 0.7247053980827332, "aqua_rat_53118": 0.7247195243835449, "camel_29691": 0.7247979640960693, "camel_29112": 0.7248238921165466, "camel_29638": 0.7248457074165344, "camel_28116": 0.7249011993408203, "camel_28190": 0.7249639630317688, "aqua_rat_32487": 0.7250493168830872, "camel_29687": 0.7253432273864746, "camel_28869": 0.7254404425621033, "aqua_rat_58277": 0.7254701256752014, "aqua_rat_31829": 0.7255324721336365, "camel_28138": 0.7259807586669922, "aqua_rat_30121": 0.726031482219696, "aqua_rat_12537": 0.726169228553772, "camel_28973": 0.726297914981842, "camel_28515": 0.7265916466712952, "camel_28993": 0.7266035079956055, "camel_29364": 0.726651668548584, "aqua_rat_42203": 0.7266941070556641, "camel_28521": 0.7269026637077332, "aqua_rat_36251": 0.7272078394889832, "aqua_rat_56755": 0.7274048328399658, "camel_29391": 0.7276483774185181, "math_train_algebra_1394": 0.727685272693634, "aqua_rat_27960": 0.7279512286186218, "camel_29372": 0.7279869318008423, "gsm_rft_14385": 0.7280756235122681, "camel_29178": 0.7281052470207214, "aqua_rat_65585": 0.7281107306480408, "aqua_rat_16386": 0.7282810211181641, "aqua_rat_67847": 0.7284116148948669, "aqua_rat_2700": 0.7288172245025635, "camel_28642": 0.7288942337036133, "camel_28068": 0.7291259765625, "camel_28946": 0.7292260527610779, "gsm_rft_9639": 0.7295171022415161, "aqua_rat_47762": 0.7296043038368225, "camel_39457": 0.7297048568725586, "camel_28874": 0.7297281622886658, "aqua_rat_52698": 0.7299461364746094, "camel_28549": 0.7300814390182495, "camel_29060": 0.7302583456039429, "aqua_rat_60986": 0.7305736541748047, "camel_29108": 0.7308283448219299, "camel_28815": 0.7318407893180847, "camel_28995": 0.7318891286849976, "camel_29705": 0.732297420501709, "camel_28081": 0.7323240637779236, "camel_29379": 0.7323374152183533, "gsm_rft_18763": 0.7325079441070557, "camel_29750": 0.7327199578285217, "camel_29388": 0.7329291701316833, "gsm_rft_7403": 0.7335668802261353, "gsm_rft_21743": 0.7345609068870544, "aqua_rat_63555": 0.7346742749214172, "camel_29072": 0.7352203726768494, "camel_28227": 0.7355984449386597, "camel_28967": 0.735643744468689, "camel_29542": 0.736088216304779, "gsm_train_8946": 0.7361629605293274, "camel_29719": 0.7363208532333374, "camel_29438": 0.7364293336868286, "aqua_rat_10823": 0.7366378903388977, "camel_29004": 0.7371861338615417, "camel_39510": 0.7394229173660278, "camel_29972": 0.7397754192352295, "camel_29026": 0.740100085735321, "camel_28837": 0.7410398721694946, "camel_29426": 0.7411893010139465, "camel_29429": 0.7421960830688477, "gsm_rft_28257": 0.7436192631721497, "camel_29373": 0.7437731027603149, "camel_28094": 0.7451540231704712, "camel_29163": 0.7462164163589478, "camel_29065": 0.7470868229866028, "camel_28715": 0.7473326921463013, "camel_29734": 0.747418224811554, "camel_28024": 0.7505360841751099, "camel_28502": 0.7515219449996948, "camel_29034": 0.7521581053733826, "camel_37933": 0.7555404901504517, "camel_29387": 0.757351815700531, "camel_20486": 0.7595586180686951, "camel_28149": 0.7706629633903503}, "TheoremQA_jianyu_xu/Catalan_2.json": {"camel_20743": 0, "camel_20730": 0, "camel_20756": 0, "camel_20813": 0, "camel_20805": 0, "camel_20591": 0, "camel_20497": 0, "camel_21266": 0, "camel_20780": 0, "camel_20988": 0, "camel_21934": 0, "camel_21999": 0, "camel_20462": 0, "camel_21028": 0, "camel_20723": 0, "camel_20776": 0, "camel_20645": 0, "camel_20495": 0, "camel_20244": 0, "camel_20769": 0, "camel_21920": 0, "camel_20728": 0, "camel_20752": 0, "camel_20331": 0, "TheoremQA_jianyu_xu/Catalan_2.json": 0, "camel_20985": 0, "camel_21935": 0, "camel_20775": 0, "camel_20711": 0, "camel_20773": 0, "camel_20794": 0, "camel_20722": 0, "camel_20784": 0, "camel_20757": 0, "camel_20783": 0, "camel_21970": 0, "camel_21960": 0, "camel_20721": 0, "camel_20332": 0, "camel_20742": 0, "camel_20747": 0, "camel_20741": 0, "camel_20760": 0, "camel_21972": 0, "camel_20796": 0, "camel_20548": 0, "aqua_rat_37170": 0.7140768766403198, "aqua_rat_72979": 0.714097261428833, "aqua_rat_72680": 0.7141115069389343, "aqua_rat_36451": 0.7142625451087952, "math_test_geometry_1097": 0.7142650485038757, "aqua_rat_2574": 0.714384138584137, "aqua_rat_13585": 0.7144033908843994, "aqua_rat_28402": 0.7144455313682556, "aqua_rat_55627": 0.7144778370857239, "aqua_rat_5816": 0.7146285176277161, "aqua_rat_3983": 0.714722752571106, "aqua_rat_36934": 0.7147541642189026, "aqua_rat_59815": 0.7148973345756531, "aqua_rat_42973": 0.7150484323501587, "aqua_rat_48596": 0.7152200937271118, "math_test_counting_and_probability_1014": 0.7153339982032776, "aqua_rat_73402": 0.715364933013916, "aqua_rat_76889": 0.7154123783111572, "aqua_rat_26460": 0.7156549096107483, "aqua_rat_49668": 0.7157042622566223, "aqua_rat_66999": 0.7157195210456848, "aqua_rat_87384": 0.715888261795044, "aqua_rat_42992": 0.7160393595695496, "aqua_rat_1085": 0.7161034345626831, "aqua_rat_18327": 0.7162525653839111, "aqua_rat_2640": 0.7163160443305969, "aqua_rat_48157": 0.7165147066116333, "aqua_rat_43406": 0.7166033983230591, "aqua_rat_60927": 0.7175279259681702, "aqua_rat_56052": 0.7176247835159302, "math_test_counting_and_probability_697": 0.7176787257194519, "math_train_counting_and_probability_5061": 0.7177874445915222, "aqua_rat_86861": 0.7178418040275574, "aqua_rat_50326": 0.7178491353988647, "aqua_rat_18803": 0.7179188132286072, "math_test_counting_and_probability_748": 0.7179502844810486, "camel_18718": 0.7182915210723877, "aqua_rat_56544": 0.7184628844261169, "aqua_rat_70794": 0.7185388207435608, "math_test_counting_and_probability_990": 0.7186887860298157, "aqua_rat_47040": 0.7186991572380066, "aqua_rat_31826": 0.7187182903289795, "aqua_rat_75875": 0.7188162207603455, "aqua_rat_67778": 0.7188509702682495, "aqua_rat_34678": 0.718865156173706, "aqua_rat_57428": 0.7189327478408813, "aqua_rat_60936": 0.7191504240036011, "aqua_rat_53430": 0.7192381024360657, "aqua_rat_26236": 0.7192670702934265, "aqua_rat_45359": 0.7192814350128174, "aqua_rat_39833": 0.7194830179214478, "aqua_rat_4483": 0.7194998860359192, "aqua_rat_40926": 0.7195974588394165, "aqua_rat_68736": 0.7197272777557373, "aqua_rat_25886": 0.7197944521903992, "aqua_rat_58195": 0.7201412916183472, "math_train_counting_and_probability_800": 0.7203666567802429, "aqua_rat_59360": 0.7204965949058533, "aqua_rat_87279": 0.7205120921134949, "aqua_rat_76281": 0.7207874059677124, "aqua_rat_89226": 0.7209049463272095, "math_train_prealgebra_1867": 0.721150815486908, "math_train_counting_and_probability_5018": 0.7212539911270142, "math_test_counting_and_probability_1115": 0.7216096520423889, "aqua_rat_68227": 0.7222100496292114, "aqua_rat_9727": 0.7222246527671814, "aqua_rat_73122": 0.7224481105804443, "aqua_rat_65597": 0.7227433919906616, "aqua_rat_8073": 0.7236317992210388, "aqua_rat_2817": 0.7239988446235657, "aqua_rat_39186": 0.7240512371063232, "aqua_rat_88083": 0.7242343425750732, "aqua_rat_29620": 0.7243653535842896, "math_train_counting_and_probability_1034": 0.7244513034820557, "aqua_rat_24334": 0.7245299816131592, "math_train_counting_and_probability_687": 0.7246304154396057, "aqua_rat_11490": 0.7252660989761353, "aqua_rat_82156": 0.7252728939056396, "math_test_counting_and_probability_894": 0.7254425883293152, "aqua_rat_34": 0.7257918119430542, "camel_18689": 0.7260388135910034, "aqua_rat_47821": 0.726172685623169, "aqua_rat_5247": 0.7262760996818542, "aqua_rat_75892": 0.7263777256011963, "aqua_rat_61326": 0.7263821959495544, "math_train_counting_and_probability_641": 0.7263864278793335, "math_train_counting_and_probability_5090": 0.726473331451416, "aqua_rat_65513": 0.7267996668815613, "aqua_rat_62238": 0.7268308401107788, "math_train_counting_and_probability_5115": 0.7272937893867493, "aops_2007_AIME_I_Problems/Problem_10": 0.7273121476173401, "aqua_rat_59912": 0.7273512482643127, "aqua_rat_54776": 0.7276216745376587, "aqua_rat_54587": 0.7278107404708862, "aqua_rat_44305": 0.7278136014938354, "aqua_rat_47540": 0.7279450297355652, "math_train_counting_and_probability_267": 0.7284744381904602, "camel_18656": 0.7285140752792358, "camel_19685": 0.72857666015625, "aqua_rat_50793": 0.7287190556526184, "camel_18678": 0.7287402153015137, "aqua_rat_80058": 0.7292732000350952, "math_train_counting_and_probability_5108": 0.7293106317520142, "aqua_rat_78109": 0.7301970720291138, "math_train_prealgebra_1271": 0.7304888963699341, "aqua_rat_32047": 0.7306930422782898, "math_train_counting_and_probability_1027": 0.7310723662376404, "camel_31168": 0.7313385009765625, "aqua_rat_31214": 0.7321920990943909, "aqua_rat_65518": 0.7322532534599304, "aqua_rat_46124": 0.7324472665786743, "aqua_rat_4158": 0.7341257929801941, "aqua_rat_69001": 0.7348645925521851, "aqua_rat_14545": 0.7349485158920288, "aqua_rat_14484": 0.7350418567657471, "aqua_rat_71998": 0.7354217171669006, "aqua_rat_33200": 0.7355630993843079, "math_train_counting_and_probability_467": 0.7363876700401306, "aqua_rat_32953": 0.7364593744277954, "aqua_rat_60744": 0.7365371584892273, "aqua_rat_26025": 0.737151563167572, "aqua_rat_62064": 0.7381322979927063, "camel_18651": 0.7385480403900146, "aqua_rat_59919": 0.7397907376289368, "aqua_rat_82230": 0.7399012446403503, "aqua_rat_13921": 0.7399470210075378, "math_train_counting_and_probability_811": 0.7411885261535645, "aqua_rat_58250": 0.7420405745506287, "math_train_counting_and_probability_5060": 0.7446178793907166, "aqua_rat_9503": 0.7446915507316589, "aqua_rat_23372": 0.7481136918067932, "aqua_rat_81161": 0.7504183053970337, "aqua_rat_19109": 0.7510364055633545, "aqua_rat_59897": 0.754127562046051, "aqua_rat_26188": 0.7642752528190613, "aqua_rat_73099": 0.7676665186882019, "aqua_rat_84260": 0.76863032579422, "aqua_rat_86075": 0.7710769176483154, "aqua_rat_23765": 0.7717750072479248, "math_test_prealgebra_1608": 0.782523512840271, "aqua_rat_63779": 0.7846848964691162, "aqua_rat_34919": 0.7964072823524475, "math_train_counting_and_probability_1024": 0.799393892288208, "aqua_rat_66818": 0.8051237463951111, "aqua_rat_51558": 0.8118802905082703, "aqua_rat_85269": 0.8141308426856995, "aqua_rat_49204": 0.8179752230644226, "aqua_rat_19731": 0.8185466527938843, "aqua_rat_16574": 0.8212742805480957, "aqua_rat_912": 0.8270347714424133, "aqua_rat_19919": 0.8396574258804321, "aqua_rat_37691": 0.8410990238189697, "aqua_rat_688": 0.8425817489624023, "aqua_rat_26519": 0.8498099446296692}, "TheoremQA_wenhuchen/double_integral2.json": {"camel_6223": 0, "camel_6194": 0, "camel_6301": 0, "camel_7727": 0, "camel_7817": 0, "camel_7086": 0, "camel_6161": 0, "camel_6233": 0, "camel_6189": 0, "camel_7830": 0, "camel_6241": 0, "camel_7104": 0, "camel_6199": 0, "camel_6201": 0, "camel_7096": 0, "camel_7750": 0, "camel_7082": 0, "camel_7115": 0, "camel_7089": 0, "camel_7709": 0, "camel_7092": 0, "camel_6170": 0, "camel_7113": 0, "camel_7110": 0, "camel_7815": 0, "camel_6217": 0, "camel_7075": 0, "camel_7050": 0, "camel_7685": 0, "camel_6237": 0, "camel_7043": 0, "camel_6210": 0, "camel_7044": 0, "camel_7106": 0, "camel_7041": 0, "camel_7688": 0, "camel_6163": 0, "camel_7822": 0, "camel_7741": 0, "camel_7081": 0, "camel_7058": 0, "camel_6245": 0, "camel_6284": 0, "camel_6302": 0, "camel_7068": 0, "camel_6204": 0, "camel_7696": 0, "camel_6183": 0, "camel_7071": 0, "camel_7720": 0, "camel_7063": 0, "camel_6983": 0, "camel_7060": 0, "camel_7099": 0, "camel_7740": 0, "camel_7052": 0, "camel_7745": 0, "camel_7046": 0, "camel_7691": 0, "camel_7731": 0, "camel_7085": 0, "camel_6160": 0, "camel_6165": 0, "camel_7054": 0, "camel_7729": 0, "camel_7698": 0, "camel_6286": 0, "camel_7681": 0, "camel_6208": 0, "camel_6197": 0, "camel_7783": 0, "camel_7101": 0, "camel_6196": 0, "camel_6166": 0, "camel_6179": 0, "camel_6227": 0, "camel_7756": 0, "camel_6230": 0, "camel_7730": 0, "camel_7737": 0, "camel_6224": 0, "camel_7686": 0, "camel_7061": 0, "camel_7719": 0, "camel_6202": 0, "camel_6218": 0, "camel_7108": 0, "camel_7093": 0, "camel_7117": 0, "camel_7107": 0, "camel_7725": 0, "camel_6309": 0, "camel_7743": 0, "camel_7100": 0, "camel_7102": 0, "camel_7718": 0, "camel_7700": 0, "camel_7048": 0, "camel_7836": 0, "camel_6167": 0, "camel_7083": 0, "camel_7835": 0, "camel_6180": 0, "camel_7716": 0, "aqua_rat_47522": 0.7523482441902161, "camel_38911": 0.7526887059211731, "aqua_rat_4376": 0.7529333829879761, "camel_39534": 0.7531336545944214, "aqua_rat_47444": 0.7532255053520203, "camel_41705": 0.753257155418396, "camel_39181": 0.7534200549125671, "camel_39128": 0.7536270022392273, "camel_39574": 0.7536698579788208, "aqua_rat_71114": 0.7538499236106873, "camel_39324": 0.7541338205337524, "camel_39146": 0.754139244556427, "camel_39194": 0.7542334198951721, "camel_39158": 0.7542644739151001, "camel_39333": 0.7542968988418579, "camel_39176": 0.7544189691543579, "camel_39169": 0.7544354200363159, "camel_39159": 0.7545943856239319, "gsm_rft_29042": 0.7546586990356445, "camel_39530": 0.7547206282615662, "camel_39311": 0.7547561526298523, "camel_19568": 0.7550134062767029, "camel_45968": 0.7552760243415833, "camel_38954": 0.7553607821464539, "camel_38820": 0.7555828094482422, "camel_39578": 0.7556522488594055, "camel_45301": 0.7557654976844788, "camel_39179": 0.7559734582901001, "camel_38825": 0.756070077419281, "aqua_rat_46766": 0.7561431527137756, "aqua_rat_25413": 0.7561970949172974, "camel_39125": 0.7562996745109558, "camel_45941": 0.7564113140106201, "aqua_rat_73868": 0.7564296722412109, "camel_39197": 0.756619930267334, "camel_39126": 0.7568262219429016, "camel_39137": 0.7569634318351746, "aqua_rat_68475": 0.7570955753326416, "aqua_rat_63192": 0.7574288249015808, "camel_16214": 0.7574884295463562, "camel_39595": 0.757726788520813, "camel_40781": 0.7578918933868408, "camel_39171": 0.7579344511032104, "camel_39282": 0.7583037614822388, "camel_17238": 0.7585089802742004, "camel_39298": 0.7585873603820801, "camel_39597": 0.7587113976478577, "camel_39529": 0.7588096857070923, "aqua_rat_67621": 0.7588367462158203, "camel_39248": 0.7589185833930969, "aqua_rat_86881": 0.7589213848114014, "camel_40793": 0.7590053677558899, "camel_39566": 0.759074330329895, "aqua_rat_41306": 0.7594553828239441, "camel_38232": 0.7595113515853882, "aqua_rat_9698": 0.7598420977592468, "camel_38176": 0.7600013613700867, "aqua_rat_18226": 0.7601948380470276, "camel_39334": 0.7603776454925537, "camel_39548": 0.7604844570159912, "aqua_rat_86892": 0.7605518102645874, "camel_39335": 0.760768473148346, "camel_39347": 0.7608626484870911, "camel_39083": 0.7613999843597412, "camel_19895": 0.7618608474731445, "camel_38207": 0.7624111771583557, "camel_41216": 0.7625126838684082, "camel_39132": 0.7625190615653992, "camel_39551": 0.7641505599021912, "camel_39191": 0.764304518699646, "math_train_algebra_564": 0.7648085951805115, "camel_38809": 0.7649749517440796, "camel_39251": 0.7650517821311951, "camel_39293": 0.7651548981666565, "camel_39166": 0.7651882171630859, "camel_39174": 0.765712559223175, "aqua_rat_88610": 0.7658784985542297, "camel_39218": 0.7665994167327881, "camel_39147": 0.7682236433029175, "camel_38182": 0.7682478427886963, "camel_4996": 0.7691857218742371, "camel_39330": 0.7710901498794556, "camel_39544": 0.7727095484733582, "camel_39297": 0.7732172608375549, "camel_39188": 0.7740381956100464, "camel_39598": 0.7763636112213135, "camel_39579": 0.7773951888084412, "camel_39124": 0.7783653140068054, "camel_38141": 0.7803454995155334, "camel_38121": 0.7811177372932434, "camel_39172": 0.7822777628898621, "camel_39155": 0.7827131748199463, "camel_39164": 0.7835891246795654, "camel_38215": 0.7860676646232605, "camel_39168": 0.787128746509552, "camel_39590": 0.791536808013916}, "TheoremQA_xueguangma/forward_price_1.json": {"TheoremQA_xueguangma/forward_price_1.json": 0, "aqua_rat_64484": 0.714568555355072, "aqua_rat_34752": 0.7146630883216858, "gsm_rft_9014": 0.7148717045783997, "aqua_rat_33006": 0.7149648070335388, "gsm_rft_34181": 0.7150563597679138, "aqua_rat_76597": 0.7150603532791138, "aqua_rat_54028": 0.7150700092315674, "math_train_algebra_369": 0.7151297926902771, "gsm_rft_31646": 0.7151868939399719, "aqua_rat_54496": 0.7152187824249268, "aqua_rat_33923": 0.7157911062240601, "aqua_rat_63067": 0.7158274054527283, "aqua_rat_1981": 0.7158478498458862, "aqua_rat_24182": 0.7159439921379089, "aqua_rat_3687": 0.7161866426467896, "aqua_rat_10990": 0.7164502143859863, "aqua_rat_33430": 0.7164790034294128, "aqua_rat_39856": 0.7164832353591919, "aqua_rat_50089": 0.7165917158126831, "aqua_rat_36783": 0.7167145609855652, "aqua_rat_65963": 0.7169032096862793, "aqua_rat_83949": 0.7169280648231506, "aqua_rat_47773": 0.7169504761695862, "aqua_rat_60181": 0.7175256013870239, "math_test_algebra_1862": 0.718173086643219, "aqua_rat_75680": 0.7182620763778687, "gsm_rft_5014": 0.7182958722114563, "aqua_rat_8298": 0.7183768153190613, "aqua_rat_9857": 0.718402624130249, "gsm_rft_11628": 0.718576967716217, "aqua_rat_23277": 0.7186682820320129, "aqua_rat_32397": 0.7187119126319885, "aqua_rat_42017": 0.718723714351654, "aqua_rat_44264": 0.7189168334007263, "aqua_rat_15764": 0.7194393277168274, "aqua_rat_32568": 0.719481885433197, "aqua_rat_52524": 0.7195612788200378, "aqua_rat_43709": 0.7196447849273682, "aqua_rat_83671": 0.7197476029396057, "aqua_rat_3830": 0.7200090289115906, "aqua_rat_29321": 0.7200254201889038, "aqua_rat_38087": 0.7201395630836487, "aqua_rat_37203": 0.7201886773109436, "aqua_rat_62047": 0.7202550768852234, "aqua_rat_2632": 0.7202562093734741, "aqua_rat_15337": 0.7203226685523987, "aqua_rat_44517": 0.7206159234046936, "aqua_rat_28883": 0.7208262085914612, "aqua_rat_6703": 0.7208515405654907, "aqua_rat_36703": 0.7211533784866333, "aqua_rat_7537": 0.7213250398635864, "aqua_rat_59199": 0.7213268876075745, "aqua_rat_1170": 0.7215057611465454, "aqua_rat_73145": 0.7220583558082581, "gsm_rft_10732": 0.7221235632896423, "gsm_train_7824": 0.7221235632896423, "aqua_rat_48160": 0.7222055792808533, "aqua_rat_41963": 0.7222574353218079, "gsm_rft_11804": 0.7223057150840759, "aqua_rat_34081": 0.722344696521759, "aqua_rat_1521": 0.722917914390564, "aqua_rat_15079": 0.7229442000389099, "aqua_rat_7674": 0.7230551242828369, "aqua_rat_17583": 0.7231202721595764, "aqua_rat_23247": 0.7231575846672058, "aqua_rat_59474": 0.7232484817504883, "aqua_rat_46898": 0.7234666347503662, "aqua_rat_62766": 0.7235990166664124, "aqua_rat_48898": 0.7239264249801636, "gsm_rft_23260": 0.7242580652236938, "aqua_rat_46552": 0.7244723439216614, "aqua_rat_9874": 0.7246893048286438, "gsm_train_6037": 0.7247008681297302, "gsm_rft_15334": 0.7247008681297302, "aqua_rat_74184": 0.7247100472450256, "aqua_rat_29417": 0.7247617840766907, "aqua_rat_13451": 0.7248957753181458, "aqua_rat_15743": 0.7255451679229736, "gsm_rft_25377": 0.7255697846412659, "aqua_rat_37258": 0.7258504033088684, "gsm_rft_7096": 0.7261765599250793, "aqua_rat_78427": 0.7262122631072998, "aqua_rat_71911": 0.7269980311393738, "aqua_rat_16448": 0.727769672870636, "aqua_rat_72794": 0.7280228734016418, "aqua_rat_73739": 0.7281956672668457, "aqua_rat_36398": 0.7283535599708557, "aqua_rat_62727": 0.7283539772033691, "aqua_rat_73390": 0.7284744381904602, "aqua_rat_77841": 0.7287311553955078, "gsm_rft_34423": 0.7288604378700256, "gsm_rft_18143": 0.7289552092552185, "aqua_rat_80269": 0.7290753126144409, "aqua_rat_78570": 0.7293713092803955, "aqua_rat_71866": 0.7296173572540283, "aqua_rat_70031": 0.7296923398971558, "aqua_rat_46883": 0.7297006845474243, "aqua_rat_84779": 0.729813277721405, "aqua_rat_68014": 0.7302736043930054, "aqua_rat_29356": 0.7303696274757385, "aqua_rat_63070": 0.7305088639259338, "aqua_rat_62371": 0.7308671474456787, "aqua_rat_32852": 0.7309274077415466, "aqua_rat_66371": 0.7312414646148682, "aqua_rat_64523": 0.7318090796470642, "aqua_rat_84549": 0.7326978445053101, "gsm_rft_15946": 0.7328227162361145, "aqua_rat_41101": 0.7330124974250793, "aqua_rat_18261": 0.7330192923545837, "camel_16747": 0.7340207695960999, "aqua_rat_65425": 0.7341184616088867, "aqua_rat_82565": 0.7346113324165344, "aqua_rat_63143": 0.7348248362541199, "aqua_rat_80303": 0.7348939776420593, "aqua_rat_57431": 0.7350518107414246, "aqua_rat_71239": 0.735289454460144, "gsm_rft_16062": 0.7354495525360107, "aqua_rat_67442": 0.7356061339378357, "aqua_rat_36461": 0.7358132600784302, "aqua_rat_77105": 0.7359920740127563, "gsm_rft_25231": 0.7361919283866882, "gsm_train_19719": 0.7361919283866882, "aqua_rat_75047": 0.7362291216850281, "aqua_rat_84306": 0.7367520332336426, "camel_37746": 0.7377053499221802, "aqua_rat_55503": 0.7386497259140015, "aqua_rat_24068": 0.7386513948440552, "aqua_rat_3885": 0.7392089366912842, "aqua_rat_56718": 0.7394763827323914, "aqua_rat_18811": 0.7395927906036377, "aqua_rat_26022": 0.7402007579803467, "aqua_rat_37299": 0.740246593952179, "aqua_rat_16442": 0.7405111193656921, "aqua_rat_58629": 0.7411231398582458, "aqua_rat_66917": 0.7413933873176575, "aqua_rat_6634": 0.7421887516975403, "aqua_rat_72737": 0.7422962784767151, "aqua_rat_46315": 0.7424250245094299, "aqua_rat_4548": 0.7427676320075989, "aqua_rat_10200": 0.7435486912727356, "aqua_rat_16875": 0.7444732785224915, "aqua_rat_611": 0.7449471354484558, "aqua_rat_74243": 0.7450515031814575, "aqua_rat_1115": 0.7451460957527161, "aqua_rat_20758": 0.7454091906547546, "TheoremQA_xueguangma/present_value_2.json": 0.7460262775421143, "aqua_rat_28984": 0.7463095188140869, "aqua_rat_59587": 0.7463130354881287, "aqua_rat_79789": 0.7463351488113403, "aqua_rat_74914": 0.7467489838600159, "aqua_rat_58924": 0.7467788457870483, "aqua_rat_15556": 0.7468451261520386, "aqua_rat_17663": 0.7479040622711182, "aqua_rat_57864": 0.7483678460121155, "aqua_rat_16445": 0.7483708262443542, "aqua_rat_73957": 0.7492718696594238, "aqua_rat_60935": 0.7496187090873718, "aqua_rat_70160": 0.7501944303512573, "aqua_rat_9530": 0.7511405348777771, "aqua_rat_13348": 0.7513698935508728, "aqua_rat_79047": 0.7514755725860596, "aqua_rat_45867": 0.7529028654098511, "aqua_rat_26425": 0.7530105710029602, "gsm_rft_6422": 0.7530505061149597, "aqua_rat_54684": 0.7535389065742493, "aqua_rat_11544": 0.7539135813713074, "aqua_rat_50660": 0.7539432048797607, "math_train_algebra_940": 0.7543895244598389, "aqua_rat_78533": 0.754907488822937, "aqua_rat_67914": 0.7560697793960571, "camel_37735": 0.7565273642539978, "aqua_rat_40411": 0.7576577663421631, "aqua_rat_6475": 0.7605639696121216, "aqua_rat_56845": 0.7620645761489868, "TheoremQA_xueguangma/forward_rate_1.json": 0.7635672092437744, "aqua_rat_87484": 0.7666503190994263, "aqua_rat_32321": 0.7676331400871277, "TheoremQA_xueguangma/present_value_1.json": 0.770896852016449, "camel_45738": 0.771181583404541, "aqua_rat_47761": 0.7721303701400757, "camel_45730": 0.7790315747261047, "aqua_rat_56436": 0.7824784517288208, "TheoremQA_xueguangma/put_call_parity_1.json": 0.7825577855110168, "aqua_rat_30597": 0.7840097546577454, "aqua_rat_85902": 0.784024178981781, "aqua_rat_57507": 0.7845790386199951, "aqua_rat_88843": 0.7852041125297546, "aqua_rat_29154": 0.785429835319519, "aqua_rat_26043": 0.788175106048584, "TheoremQA_xueguangma/spot_rate.json": 0.7895533442497253, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7951785326004028, "aqua_rat_80676": 0.797341525554657, "aqua_rat_36498": 0.8018258213996887, "aqua_rat_49352": 0.8046939373016357, "aqua_rat_79856": 0.8066018223762512, "aqua_rat_31553": 0.812522292137146, "aqua_rat_45508": 0.8219982981681824, "TheoremQA_xueguangma/forward_price_2.json": 0.8334484696388245, "TheoremQA_xueguangma/forward_price_3.json": 0.8463538885116577}, "TheoremQA_wenhuchen/cauchy_integral1.json": {"camel_42230": 0, "camel_42191": 0, "camel_43501": 0, "camel_42165": 0, "camel_43009": 0, "camel_42237": 0, "camel_42218": 0, "camel_42131": 0, "camel_42178": 0, "camel_43019": 0, "camel_42166": 0, "camel_43450": 0, "camel_42180": 0, "camel_42161": 0, "camel_42224": 0, "camel_42187": 0, "camel_42200": 0, "camel_43845": 0, "camel_42197": 0, "camel_43426": 0, "camel_42164": 0, "camel_43823": 0, "camel_42214": 0, "camel_42181": 0, "camel_42168": 0, "camel_42176": 0, "camel_42225": 0, "camel_42223": 0, "camel_42236": 0, "camel_42162": 0, "camel_42208": 0, "camel_30259": 0.7111884951591492, "camel_45318": 0.7112491130828857, "camel_7299": 0.7114214897155762, "camel_7112": 0.7114825248718262, "camel_39311": 0.7115722298622131, "camel_6168": 0.7117034792900085, "camel_7096": 0.7117497324943542, "camel_44170": 0.7122926115989685, "camel_30296": 0.7123072743415833, "camel_17294": 0.7125639915466309, "camel_7752": 0.7127200961112976, "camel_3683": 0.7128596901893616, "camel_7083": 0.7128693461418152, "camel_6166": 0.7130690813064575, "camel_19784": 0.7131345868110657, "camel_19628": 0.7131608724594116, "camel_7117": 0.7131720781326294, "camel_45120": 0.7132601737976074, "aqua_rat_2746": 0.7133036851882935, "camel_44176": 0.7133090496063232, "camel_30764": 0.7134066820144653, "camel_17303": 0.7136887907981873, "camel_4993": 0.7137383818626404, "camel_17282": 0.7139210104942322, "camel_39590": 0.7139425277709961, "camel_7359": 0.7141638994216919, "camel_3744": 0.7142627239227295, "camel_18783": 0.7143120169639587, "camel_7326": 0.7143332362174988, "camel_39327": 0.7145796418190002, "camel_28245": 0.7146788239479065, "camel_7046": 0.7146956324577332, "camel_19731": 0.7147856950759888, "camel_17273": 0.7148551940917969, "camel_5181": 0.714986264705658, "camel_29467": 0.7151725888252258, "camel_17335": 0.7153100967407227, "camel_19725": 0.7153432965278625, "camel_17241": 0.7156292796134949, "camel_19711": 0.7158803343772888, "camel_28302": 0.7159513831138611, "camel_17353": 0.716023325920105, "camel_7107": 0.7163249254226685, "camel_30182": 0.7164481282234192, "camel_28265": 0.7164827585220337, "camel_7691": 0.7165592908859253, "camel_7297": 0.7167508602142334, "camel_19768": 0.7167824506759644, "math_test_geometry_888": 0.7167978286743164, "camel_17299": 0.7168263792991638, "camel_19600": 0.717004656791687, "camel_17283": 0.7172247171401978, "camel_48498": 0.7172796726226807, "camel_7346": 0.7172969579696655, "camel_7050": 0.7175652384757996, "camel_7347": 0.7175715565681458, "camel_7058": 0.7176501750946045, "camel_45322": 0.717685878276825, "camel_7089": 0.7177314758300781, "camel_7044": 0.7180256247520447, "camel_17328": 0.7181134223937988, "aqua_rat_74869": 0.7181894779205322, "camel_30218": 0.7182404398918152, "camel_7068": 0.7191346883773804, "camel_46101": 0.7191786766052246, "camel_7092": 0.7192807197570801, "camel_5070": 0.7194314002990723, "camel_28260": 0.7197144031524658, "camel_19729": 0.7198406457901001, "camel_7296": 0.7199085354804993, "camel_45668": 0.7199183106422424, "camel_7108": 0.7201436161994934, "camel_5008": 0.7201966047286987, "camel_7099": 0.7202147841453552, "camel_45344": 0.7203587889671326, "camel_17352": 0.720524787902832, "camel_7041": 0.7206622958183289, "camel_5029": 0.720833957195282, "camel_30167": 0.7210289239883423, "camel_7081": 0.7211276888847351, "camel_7110": 0.721173882484436, "camel_47373": 0.7212663888931274, "camel_7304": 0.7212852835655212, "camel_46124": 0.7214481234550476, "camel_16214": 0.7215467691421509, "camel_5307": 0.7215468287467957, "camel_30160": 0.7215892672538757, "camel_17274": 0.7217624187469482, "camel_7048": 0.7218289971351624, "aqua_rat_75605": 0.7220783233642578, "camel_19605": 0.7220883965492249, "camel_45310": 0.7220937013626099, "camel_7104": 0.7221277356147766, "camel_4986": 0.7222098112106323, "camel_7043": 0.7224833369255066, "camel_39284": 0.7225550413131714, "camel_39223": 0.7229200601577759, "camel_7052": 0.7229287624359131, "camel_19622": 0.7230233550071716, "camel_30319": 0.7230952978134155, "camel_19664": 0.7234646677970886, "camel_7085": 0.7234938144683838, "camel_7054": 0.7235107421875, "camel_7119": 0.7238110899925232, "camel_5303": 0.7238693237304688, "camel_44659": 0.7239376902580261, "camel_7061": 0.7244340181350708, "camel_46120": 0.7244749069213867, "camel_19716": 0.7248836159706116, "aqua_rat_32286": 0.7251256704330444, "aqua_rat_88610": 0.7252914905548096, "camel_45614": 0.725603461265564, "camel_5357": 0.7256575226783752, "camel_45621": 0.7256959080696106, "camel_5344": 0.7262474298477173, "camel_17344": 0.726800262928009, "camel_7309": 0.7274733781814575, "camel_3698": 0.7278035879135132, "camel_7101": 0.7281534075737, "camel_7317": 0.7285509705543518, "camel_3148": 0.7287524342536926, "camel_17238": 0.7296513915061951, "camel_30303": 0.7296924591064453, "camel_5333": 0.7298097610473633, "camel_17340": 0.7298380136489868, "camel_45299": 0.7298781871795654, "camel_19754": 0.7309099435806274, "camel_45953": 0.7309593558311462, "camel_7102": 0.7318736910820007, "camel_5189": 0.731890082359314, "aqua_rat_16864": 0.7323164343833923, "camel_47478": 0.7324949502944946, "camel_45312": 0.7325354218482971, "camel_17333": 0.7325620055198669, "camel_45293": 0.7333733439445496, "camel_19759": 0.73405921459198, "camel_30260": 0.7340663075447083, "camel_30171": 0.7343874573707581, "camel_5165": 0.7348574995994568, "camel_19629": 0.7350345253944397, "camel_39559": 0.7355107069015503, "camel_19717": 0.7362917065620422, "camel_7100": 0.7364321947097778, "camel_7071": 0.7365428805351257, "camel_17325": 0.7368252277374268, "camel_7093": 0.7369539737701416, "camel_17280": 0.7372231483459473, "camel_17261": 0.7374997735023499, "camel_17214": 0.7376144528388977, "camel_17286": 0.7378711104393005, "camel_19728": 0.7380245923995972, "camel_44680": 0.7381884455680847, "camel_45645": 0.738335371017456, "camel_44347": 0.7400396466255188, "camel_5285": 0.7408703565597534, "camel_19647": 0.7428253889083862, "camel_45679": 0.7442344427108765, "camel_39254": 0.7447769045829773, "camel_39279": 0.7460326552391052, "camel_17323": 0.746549665927887, "camel_7053": 0.7495765089988708, "camel_17265": 0.7496032118797302, "camel_39338": 0.7531712055206299, "camel_19895": 0.755163848400116, "camel_5342": 0.7568690180778503, "camel_17301": 0.7636796832084656, "camel_45315": 0.7732391953468323, "camel_7731": 0.7809925675392151, "camel_19568": 0.7910447120666504}, "TheoremQA_panlu/gravitational_force1.json": {"TheoremQA_panlu/gravitational_force1.json": 0, "aqua_rat_2612": 0.7034772038459778, "camel_7574": 0.7035815119743347, "gsm_rft_8897": 0.7037235498428345, "camel_39441": 0.7038028836250305, "gsm_rft_3828": 0.7039458751678467, "camel_7440": 0.7041082382202148, "camel_45673": 0.7042935490608215, "camel_28809": 0.7044184803962708, "camel_28143": 0.7045567035675049, "aqua_rat_5999": 0.7047316431999207, "camel_7974": 0.7047795653343201, "aqua_rat_58858": 0.7049025297164917, "camel_28715": 0.7054840326309204, "gsm_rft_32849": 0.7057949304580688, "gsm_train_26360": 0.7057949304580688, "camel_7968": 0.7057960033416748, "camel_7499": 0.7058388590812683, "aqua_rat_10676": 0.705839216709137, "gsm_rft_2421": 0.7060976624488831, "camel_39509": 0.7062137722969055, "camel_7986": 0.7062661051750183, "camel_17542": 0.7063964009284973, "camel_7491": 0.7064170837402344, "aqua_rat_18184": 0.7064691185951233, "camel_6205": 0.7071245908737183, "camel_39500": 0.7074733376502991, "camel_7610": 0.7075208425521851, "camel_39453": 0.7075371146202087, "aqua_rat_58122": 0.708289384841919, "camel_7976": 0.7083820104598999, "camel_7461": 0.7088367938995361, "camel_39514": 0.7088494896888733, "camel_5842": 0.7088561058044434, "aqua_rat_20932": 0.7088719606399536, "camel_16266": 0.7091278433799744, "camel_16249": 0.7091817259788513, "camel_28532": 0.7092209458351135, "aqua_rat_71816": 0.709364116191864, "aqua_rat_88155": 0.7096891403198242, "aqua_rat_61332": 0.709879457950592, "aqua_rat_56584": 0.7100363969802856, "camel_7514": 0.7101864218711853, "camel_7580": 0.7102690935134888, "camel_7592": 0.7103650569915771, "aqua_rat_72825": 0.7106170654296875, "camel_28804": 0.7106988430023193, "camel_39460": 0.7107558250427246, "camel_7925": 0.7109423875808716, "aqua_rat_37688": 0.7110725045204163, "camel_7567": 0.7113447785377502, "camel_7960": 0.7113834023475647, "aqua_rat_26489": 0.7113963961601257, "aqua_rat_10999": 0.7114356756210327, "camel_28022": 0.7115798592567444, "camel_28833": 0.7117785811424255, "camel_39308": 0.7118943929672241, "camel_17559": 0.7123676538467407, "camel_16252": 0.7125892043113708, "camel_7568": 0.712742030620575, "aqua_rat_58561": 0.7129055261611938, "camel_39468": 0.712908148765564, "camel_7565": 0.7130002975463867, "camel_17565": 0.7131547331809998, "camel_39446": 0.713171124458313, "camel_7962": 0.7133622765541077, "TheoremQA_wenhuchen/Fluid_mechanics2.json": 0.7134742736816406, "camel_7527": 0.7135521173477173, "camel_28537": 0.7136496901512146, "aqua_rat_82693": 0.7140262126922607, "aqua_rat_42126": 0.7142303586006165, "TheoremQA_panlu/uniform_circular_motion2.json": 0.7143647074699402, "camel_7956": 0.7147260308265686, "camel_7952": 0.7147584557533264, "aqua_rat_12010": 0.7153887152671814, "camel_7595": 0.715430498123169, "camel_39462": 0.7157856822013855, "camel_16283": 0.7159196734428406, "camel_7940": 0.7162269353866577, "camel_7973": 0.7163544297218323, "camel_7541": 0.7170283794403076, "aqua_rat_48545": 0.7174234986305237, "camel_39484": 0.7175082564353943, "aqua_rat_53936": 0.7177509665489197, "camel_39476": 0.7178933024406433, "camel_7520": 0.7182687520980835, "camel_7936": 0.7186284065246582, "camel_7563": 0.7188268303871155, "camel_7990": 0.7189102172851562, "camel_7972": 0.719168484210968, "aqua_rat_85100": 0.7194876670837402, "camel_28875": 0.7195383310317993, "TheoremQA_xinyi/work_energy_theorem.json": 0.7196124792098999, "TheoremQA_wenhuchen/kepler's_law1.json": 0.7200700044631958, "camel_28865": 0.7207782864570618, "camel_39471": 0.7210859060287476, "camel_28873": 0.7211459279060364, "camel_7946": 0.7212886810302734, "aqua_rat_63716": 0.7213189601898193, "aqua_rat_81174": 0.7214203476905823, "aqua_rat_43435": 0.7214779853820801, "camel_28866": 0.7216924428939819, "camel_39469": 0.7220965623855591, "camel_16246": 0.7221872806549072, "camel_7991": 0.7223003506660461, "camel_7954": 0.7224295139312744, "camel_7920": 0.722628653049469, "aqua_rat_51750": 0.7233605980873108, "aqua_rat_49952": 0.7239145040512085, "camel_7949": 0.7239187955856323, "camel_5311": 0.7240836024284363, "camel_28137": 0.7251855134963989, "camel_7951": 0.7269109487533569, "camel_7931": 0.7269226908683777, "camel_7935": 0.7278834581375122, "aqua_rat_31294": 0.7279205918312073, "camel_7572": 0.7282435297966003, "camel_7993": 0.7282646894454956, "aqua_rat_67610": 0.7285573482513428, "camel_7999": 0.7286715507507324, "camel_7927": 0.7290922403335571, "camel_7528": 0.7293614149093628, "aqua_rat_58700": 0.7296900749206543, "aqua_rat_70741": 0.7303025126457214, "camel_7966": 0.7307623028755188, "camel_7964": 0.7311937212944031, "camel_7947": 0.7316114902496338, "camel_43563": 0.7322594523429871, "aqua_rat_36865": 0.7323461771011353, "camel_7998": 0.7323702573776245, "camel_7476": 0.73274827003479, "camel_7967": 0.7328236103057861, "aqua_rat_43112": 0.733024537563324, "camel_7987": 0.7330480813980103, "camel_7498": 0.7356392741203308, "camel_28068": 0.7364091277122498, "camel_7519": 0.7366204261779785, "camel_39475": 0.7366864681243896, "camel_28909": 0.7373362183570862, "camel_39479": 0.7380543947219849, "camel_7594": 0.7380563616752625, "camel_7480": 0.7392553091049194, "camel_7478": 0.7398112416267395, "camel_39467": 0.7399770617485046, "aqua_rat_19334": 0.741016149520874, "aqua_rat_36823": 0.7410978674888611, "camel_4731": 0.7412060499191284, "camel_7508": 0.7419515252113342, "camel_28840": 0.7425133585929871, "camel_28856": 0.742525577545166, "aqua_rat_6249": 0.7429596781730652, "TheoremQA_panlu/angular_frequency3.json": 0.7430528402328491, "camel_7980": 0.743144690990448, "camel_28872": 0.743186891078949, "camel_7988": 0.744941234588623, "camel_39511": 0.745573878288269, "camel_7934": 0.7458696961402893, "camel_7982": 0.7461333274841309, "math_test_algebra_518": 0.7461952567100525, "camel_7586": 0.746462345123291, "camel_7937": 0.7471649646759033, "TheoremQA_panlu/black_hole1.json": 0.7472511529922485, "aqua_rat_18805": 0.7478642463684082, "camel_7945": 0.7479445934295654, "camel_7463": 0.7480581402778625, "camel_7484": 0.7481370568275452, "camel_7959": 0.7482885122299194, "camel_39452": 0.7485373616218567, "camel_7922": 0.7486282587051392, "camel_5001": 0.7492905259132385, "camel_39515": 0.7495754361152649, "camel_39508": 0.7498504519462585, "camel_7995": 0.7515932321548462, "camel_28811": 0.7515977025032043, "camel_28868": 0.75189208984375, "camel_5857": 0.7524830102920532, "camel_7977": 0.75465327501297, "camel_29979": 0.7566267251968384, "camel_39461": 0.7572042346000671, "camel_39455": 0.7584490776062012, "camel_39447": 0.7603015899658203, "camel_39488": 0.7604944705963135, "camel_28846": 0.7608007788658142, "camel_4979": 0.7613744139671326, "camel_7984": 0.7619172930717468, "camel_7928": 0.7620725035667419, "camel_39485": 0.7634176015853882, "camel_17406": 0.7639994621276855, "camel_28847": 0.7679913640022278, "TheoremQA_wenhuchen/kepler's_law3.json": 0.7762569189071655, "camel_6246": 0.7819322347640991, "camel_7938": 0.7826835513114929, "camel_39449": 0.7861521244049072, "camel_39513": 0.7881478667259216, "camel_7552": 0.7938041687011719, "camel_7944": 0.8076372146606445, "TheoremQA_panlu/energy_conservation1.json": 0.816830039024353, "TheoremQA_panlu/gravitational_force2.json": 0.8365806341171265, "math_train_algebra_2156": 0.8703609108924866, "TheoremQA_wenhuchen/kepler's_law2.json": 0.8910084962844849}, "TheoremQA_maxku/signalprocessing13-Ztransform.json": {"TheoremQA_maxku/signalprocessing13-Ztransform.json": 0, "camel_29708": 0.6424986720085144, "camel_45809": 0.642681360244751, "camel_44524": 0.6427710056304932, "camel_45492": 0.6430060863494873, "camel_28384": 0.6430617570877075, "camel_45775": 0.6431278586387634, "camel_45471": 0.6432099342346191, "camel_44797": 0.6435120105743408, "camel_44516": 0.6435971856117249, "camel_29220": 0.6436803936958313, "camel_44773": 0.6438158750534058, "camel_44743": 0.6440605521202087, "camel_29693": 0.6440784335136414, "camel_45745": 0.6440935134887695, "camel_44751": 0.6441816687583923, "camel_44820": 0.6443167328834534, "camel_29271": 0.6444246172904968, "camel_29166": 0.6445684432983398, "camel_37476": 0.6446241736412048, "camel_29984": 0.6446912884712219, "camel_45468": 0.6447992920875549, "camel_29684": 0.6448864340782166, "camel_45504": 0.6449745297431946, "camel_45314": 0.6449865698814392, "camel_44799": 0.6451615691184998, "camel_43612": 0.6451842784881592, "camel_45683": 0.6452223062515259, "camel_45453": 0.6454787850379944, "TheoremQA_maxku/cv-cnn1.json": 0.6455082297325134, "camel_28787": 0.6455085873603821, "camel_45424": 0.6461352109909058, "camel_45712": 0.6461408734321594, "camel_29251": 0.646156370639801, "camel_29888": 0.6462150812149048, "camel_45392": 0.6462811827659607, "camel_29255": 0.6463184356689453, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.6464391350746155, "camel_44735": 0.6464395523071289, "camel_45370": 0.646669328212738, "camel_45443": 0.6470109224319458, "camel_29705": 0.6470483541488647, "camel_28821": 0.6472759246826172, "camel_45374": 0.6472890973091125, "camel_45736": 0.6473212242126465, "camel_29925": 0.6473786234855652, "camel_29216": 0.647454559803009, "camel_45437": 0.6475547552108765, "camel_45409": 0.6478121280670166, "camel_29741": 0.6478930711746216, "camel_29899": 0.6479323506355286, "camel_29364": 0.6480043530464172, "camel_29387": 0.6482505798339844, "camel_45432": 0.6485369801521301, "camel_45949": 0.6485602855682373, "camel_44776": 0.6485950350761414, "camel_29969": 0.6488898396492004, "camel_45418": 0.6493972539901733, "camel_29218": 0.6494745016098022, "camel_45174": 0.6495364308357239, "camel_45689": 0.649580180644989, "camel_44793": 0.6495954394340515, "camel_45740": 0.6498590707778931, "camel_26519": 0.6499403119087219, "camel_44744": 0.6501579880714417, "camel_44467": 0.6501969695091248, "camel_44795": 0.6503424048423767, "camel_45318": 0.6504079103469849, "camel_29749": 0.6504098773002625, "camel_45198": 0.6505149006843567, "camel_44798": 0.6506641507148743, "camel_45763": 0.6506657004356384, "camel_29759": 0.6510616540908813, "camel_44373": 0.6511030197143555, "camel_44462": 0.6514761447906494, "camel_29277": 0.6515073776245117, "gsm_rft_21298": 0.651519775390625, "gsm_train_20944": 0.651519775390625, "camel_44861": 0.6518376469612122, "camel_45498": 0.6521296501159668, "camel_45803": 0.6521523594856262, "camel_29438": 0.652534008026123, "gsm_rft_33863": 0.6525453329086304, "camel_45368": 0.6526750326156616, "camel_45713": 0.6527084708213806, "camel_44752": 0.6528329253196716, "camel_45834": 0.6528357267379761, "camel_29752": 0.6529802680015564, "camel_45604": 0.6531585454940796, "camel_44401": 0.6532248258590698, "camel_17639": 0.6532393097877502, "camel_44768": 0.6532405614852905, "camel_45762": 0.6532977819442749, "camel_45003": 0.6533731818199158, "camel_45379": 0.6534810066223145, "camel_45796": 0.6536372900009155, "camel_29204": 0.6538043022155762, "camel_29228": 0.6539654731750488, "camel_45939": 0.654019296169281, "camel_45756": 0.654189944267273, "camel_44772": 0.6543139219284058, "camel_17545": 0.6543363928794861, "camel_44775": 0.6545189619064331, "camel_44447": 0.6546199321746826, "camel_45807": 0.6548045873641968, "camel_29240": 0.654807448387146, "camel_29388": 0.6549992561340332, "camel_45503": 0.6550695300102234, "camel_45741": 0.6552466154098511, "camel_26497": 0.6554373502731323, "camel_29691": 0.6559453010559082, "camel_45721": 0.6560254693031311, "camel_44873": 0.6561526656150818, "camel_45835": 0.6567226052284241, "camel_28379": 0.6573052406311035, "TheoremQA_maxku/cv-cnn4.json": 0.6575668454170227, "camel_44762": 0.6578026413917542, "gsm_rft_11471": 0.6580905914306641, "camel_45952": 0.6581721305847168, "camel_44746": 0.6584796905517578, "camel_44400": 0.6592302322387695, "camel_45797": 0.6594918370246887, "camel_29205": 0.6595364809036255, "camel_45401": 0.6595990061759949, "camel_45718": 0.6600427627563477, "camel_44760": 0.6604940295219421, "camel_45831": 0.6611539721488953, "camel_45199": 0.661484956741333, "TheoremQA_maxku/signalprocessing19-period.json": 0.6619122624397278, "camel_45508": 0.6619417667388916, "camel_29278": 0.6620097756385803, "camel_45696": 0.6620583534240723, "camel_45607": 0.6625567078590393, "camel_45701": 0.663189709186554, "camel_45786": 0.6633954048156738, "camel_45646": 0.6637280583381653, "camel_44785": 0.663864016532898, "camel_45380": 0.6644078493118286, "camel_44749": 0.6645483374595642, "camel_29373": 0.664698600769043, "camel_45690": 0.66510409116745, "camel_44782": 0.6651585698127747, "camel_45151": 0.6652989983558655, "camel_44796": 0.6653446555137634, "camel_29227": 0.6654175519943237, "camel_45476": 0.6654956340789795, "camel_44487": 0.6669539213180542, "camel_44748": 0.6673262715339661, "camel_45744": 0.6679807305335999, "camel_44766": 0.6681351065635681, "camel_29429": 0.66825270652771, "camel_44443": 0.6682835221290588, "camel_29279": 0.6683554649353027, "camel_45457": 0.6686599850654602, "camel_45772": 0.6690372824668884, "camel_45159": 0.6700927019119263, "camel_29727": 0.6701757907867432, "camel_45722": 0.670387327671051, "camel_44411": 0.670490026473999, "camel_45489": 0.6705469489097595, "camel_29219": 0.6706271767616272, "camel_45410": 0.6710046529769897, "camel_44492": 0.6711039543151855, "camel_44790": 0.6734488010406494, "camel_44728": 0.6735084652900696, "camel_45430": 0.6743462085723877, "camel_45725": 0.674688458442688, "camel_45727": 0.6754101514816284, "camel_44806": 0.675633430480957, "camel_45680": 0.6757931709289551, "camel_44848": 0.6759588718414307, "camel_44459": 0.6761387586593628, "camel_44538": 0.6770991086959839, "camel_45146": 0.6773691177368164, "camel_45754": 0.6789373755455017, "camel_45688": 0.6793190836906433, "camel_29734": 0.6816444396972656, "camel_45693": 0.681734561920166, "camel_45518": 0.6819793581962585, "camel_29704": 0.683122992515564, "camel_45171": 0.6836119890213013, "camel_45706": 0.6836996674537659, "camel_45819": 0.6838251352310181, "camel_44537": 0.6843997240066528, "camel_45698": 0.6848818063735962, "camel_45709": 0.6866622567176819, "camel_45684": 0.6900988221168518, "camel_45676": 0.6915873289108276, "camel_29719": 0.6916949152946472, "camel_45931": 0.6934076547622681, "camel_45936": 0.6950464844703674, "camel_45682": 0.6968773007392883, "camel_44872": 0.6981256604194641, "camel_45512": 0.6985423564910889, "camel_44424": 0.7037362456321716, "TheoremQA_maxku/signalprocessing14-Ztransform.json": 0.7086248993873596, "camel_17674": 0.7184590101242065, "camel_44838": 0.7226264476776123, "TheoremQA_maxku/signalprocessing6-Ztransform.json": 0.74180668592453, "TheoremQA_maxku/signalprocessing4-Ztransform.json": 0.8452659249305725}, "TheoremQA_jianyu_xu/Multinomial_2.json": {"camel_21202": 0, "camel_20336": 0, "camel_21405": 0, "camel_21395": 0, "camel_20462": 0, "camel_20855": 0, "camel_20570": 0, "camel_21200": 0, "camel_21388": 0, "camel_21419": 0, "camel_20540": 0, "camel_21034": 0, "camel_20826": 0, "camel_21568": 0, "camel_20853": 0, "camel_20946": 0, "camel_20523": 0, "camel_20293": 0, "camel_20270": 0, "camel_21431": 0, "camel_21429": 0, "camel_20257": 0, "camel_21572": 0, "camel_21386": 0, "camel_20312": 0, "camel_20808": 0, "camel_21371": 0, "camel_21110": 0, "camel_20619": 0, "camel_20577": 0, "camel_21039": 0, "camel_21528": 0, "camel_21400": 0, "camel_20520": 0, "camel_21379": 0, "camel_20364": 0, "camel_20514": 0, "camel_21236": 0, "camel_20656": 0, "camel_21215": 0, "camel_20611": 0, "camel_20930": 0, "camel_20512": 0, "camel_20802": 0, "camel_20255": 0, "camel_21081": 0, "camel_20598": 0, "camel_20599": 0, "camel_21022": 0, "camel_21049": 0, "camel_21808": 0, "camel_21015": 0, "camel_21028": 0, "camel_20287": 0, "camel_20309": 0, "camel_21530": 0, "TheoremQA_jianyu_xu/Multinomial_2.json": 0, "aqua_rat_57095": 0.8222441673278809, "aqua_rat_52885": 0.8226621150970459, "aqua_rat_77698": 0.822806715965271, "aqua_rat_10096": 0.822830319404602, "aqua_rat_60100": 0.8229786157608032, "aqua_rat_77021": 0.8230040073394775, "aqua_rat_76714": 0.8231831192970276, "aqua_rat_63018": 0.8232530951499939, "aqua_rat_30392": 0.8232673406600952, "aqua_rat_34607": 0.8234310150146484, "aqua_rat_69384": 0.823713481426239, "aqua_rat_58323": 0.8237509727478027, "aqua_rat_61946": 0.8237773180007935, "aqua_rat_44961": 0.8241286873817444, "aqua_rat_37642": 0.824185311794281, "aqua_rat_5288": 0.8243132829666138, "aqua_rat_9556": 0.824321985244751, "aqua_rat_74651": 0.8243725895881653, "aqua_rat_62715": 0.8244104385375977, "aqua_rat_38594": 0.8244403004646301, "aqua_rat_81265": 0.8246599435806274, "aqua_rat_37185": 0.8247714042663574, "aqua_rat_29514": 0.825014054775238, "aqua_rat_34318": 0.8251797556877136, "aqua_rat_55839": 0.8255590796470642, "aqua_rat_57693": 0.8258039355278015, "aqua_rat_58614": 0.8259811997413635, "aqua_rat_55429": 0.8260207772254944, "aqua_rat_79094": 0.8262015581130981, "aqua_rat_22214": 0.8264484405517578, "aqua_rat_35292": 0.8266660571098328, "aqua_rat_9182": 0.8269204497337341, "aqua_rat_7341": 0.8270490169525146, "aqua_rat_83158": 0.8271194696426392, "aqua_rat_19069": 0.8274762034416199, "aqua_rat_21179": 0.8277071714401245, "aqua_rat_25933": 0.8278218507766724, "camel_38493": 0.8280011415481567, "aqua_rat_49505": 0.8280211091041565, "aqua_rat_60691": 0.828315258026123, "aqua_rat_52067": 0.8283387422561646, "aqua_rat_73601": 0.8288175463676453, "aqua_rat_42155": 0.8288634419441223, "aqua_rat_72708": 0.8288999795913696, "math_test_counting_and_probability_935": 0.829054057598114, "aqua_rat_27914": 0.8291177153587341, "aqua_rat_371": 0.8294441103935242, "aqua_rat_88325": 0.8294948935508728, "aqua_rat_2149": 0.8296259641647339, "aqua_rat_4191": 0.8297375440597534, "aqua_rat_13918": 0.8298386335372925, "aqua_rat_43064": 0.8300984501838684, "aqua_rat_78830": 0.8303658962249756, "aqua_rat_48135": 0.8303998112678528, "aqua_rat_34272": 0.8304336071014404, "aqua_rat_55626": 0.8304647207260132, "aqua_rat_33533": 0.830493688583374, "aqua_rat_68946": 0.830620288848877, "aqua_rat_41924": 0.8308373689651489, "aqua_rat_81997": 0.8309904336929321, "aqua_rat_74695": 0.8311617970466614, "math_train_counting_and_probability_929": 0.8314971923828125, "aqua_rat_49270": 0.8317621350288391, "aqua_rat_79594": 0.8320446610450745, "aqua_rat_80444": 0.832053542137146, "aqua_rat_27717": 0.8320733904838562, "aqua_rat_64485": 0.832129955291748, "aqua_rat_70861": 0.8322603106498718, "aqua_rat_59702": 0.8322672843933105, "aqua_rat_62645": 0.8323551416397095, "aqua_rat_68198": 0.8324710726737976, "aqua_rat_14281": 0.832526683807373, "aqua_rat_8402": 0.8326824307441711, "aqua_rat_60755": 0.8327252864837646, "aqua_rat_23041": 0.8327941298484802, "aqua_rat_74719": 0.8328073024749756, "aqua_rat_87094": 0.8328649401664734, "aqua_rat_4294": 0.8329959511756897, "aqua_rat_7248": 0.8332894444465637, "aqua_rat_76271": 0.8336034417152405, "aqua_rat_3870": 0.833635151386261, "math_train_counting_and_probability_1110": 0.8340129256248474, "aqua_rat_48109": 0.8340604901313782, "aqua_rat_3934": 0.8344734907150269, "aqua_rat_52832": 0.8344845175743103, "aqua_rat_21265": 0.8345690965652466, "aqua_rat_72210": 0.8348126411437988, "aqua_rat_29967": 0.8350717425346375, "aqua_rat_88559": 0.8356019258499146, "aqua_rat_11651": 0.835702657699585, "aqua_rat_42333": 0.8357490301132202, "math_test_counting_and_probability_650": 0.8358348608016968, "aqua_rat_51559": 0.8360058665275574, "aqua_rat_2480": 0.8363642692565918, "aqua_rat_73402": 0.8367326259613037, "aqua_rat_13585": 0.8368741869926453, "aqua_rat_7086": 0.8372790813446045, "aqua_rat_66465": 0.8374980688095093, "aqua_rat_18404": 0.8379240036010742, "aqua_rat_28538": 0.8383627533912659, "aqua_rat_32162": 0.8383874297142029, "aqua_rat_74550": 0.8384156823158264, "aqua_rat_36385": 0.8385437726974487, "aqua_rat_54461": 0.8387672901153564, "aqua_rat_22648": 0.8391679525375366, "aqua_rat_16780": 0.8396920561790466, "aqua_rat_21868": 0.8397231101989746, "aqua_rat_88698": 0.8398059010505676, "aqua_rat_79193": 0.8400482535362244, "math_test_counting_and_probability_79": 0.8402721285820007, "math_test_counting_and_probability_341": 0.8403081297874451, "aqua_rat_30109": 0.8405473232269287, "aqua_rat_60936": 0.8417613506317139, "aqua_rat_61885": 0.8419767618179321, "aqua_rat_89113": 0.8419971466064453, "aqua_rat_40108": 0.8422009348869324, "aqua_rat_16877": 0.8427411317825317, "aqua_rat_52092": 0.842890202999115, "aqua_rat_29306": 0.8439803123474121, "aqua_rat_29651": 0.8443731069564819, "aqua_rat_57246": 0.8444531559944153, "aqua_rat_14532": 0.8465536832809448, "aqua_rat_73365": 0.8467036485671997, "math_train_counting_and_probability_918": 0.8475070595741272, "aqua_rat_73122": 0.8479239344596863, "aqua_rat_34420": 0.8482030630111694, "aqua_rat_71649": 0.8482138514518738, "aqua_rat_34678": 0.8501747846603394, "aqua_rat_66841": 0.8529332876205444, "aqua_rat_22507": 0.8534587621688843, "aqua_rat_66240": 0.8542613983154297, "aqua_rat_10102": 0.8560592532157898, "aqua_rat_84159": 0.8585190773010254, "aqua_rat_32732": 0.8588084578514099, "aqua_rat_62903": 0.8605366349220276, "aqua_rat_55783": 0.8639373779296875, "aqua_rat_56019": 0.8644776940345764, "aqua_rat_71336": 0.866807758808136, "aqua_rat_15615": 0.8720901608467102, "aqua_rat_30172": 0.8722405433654785, "aqua_rat_89175": 0.8741835951805115, "aqua_rat_70803": 0.8751388192176819, "aqua_rat_64131": 0.8882928490638733}, "TheoremQA_maxku/ipnetwork21-ip-2.json": {"TheoremQA_maxku/ipnetwork21-ip-2.json": 0, "camel_41269": 0.7010089755058289, "camel_22018": 0.701042652130127, "camel_38501": 0.7014813423156738, "camel_22366": 0.7016765475273132, "camel_21675": 0.701764702796936, "camel_41254": 0.7018531560897827, "camel_41277": 0.7019780874252319, "camel_22329": 0.7020404934883118, "camel_23968": 0.7026483416557312, "camel_22803": 0.7026832103729248, "camel_21630": 0.7027304768562317, "camel_22300": 0.7028428912162781, "camel_22013": 0.7028533220291138, "camel_39958": 0.7029001712799072, "camel_23928": 0.7031120657920837, "camel_38561": 0.7031469941139221, "camel_22806": 0.7032420635223389, "camel_22548": 0.7032552361488342, "camel_22294": 0.7035055160522461, "aqua_rat_44391": 0.7035865783691406, "camel_22870": 0.7036206722259521, "camel_41206": 0.7036793231964111, "camel_22854": 0.7039288878440857, "camel_23970": 0.7041076421737671, "camel_22844": 0.70418381690979, "camel_23174": 0.7042919397354126, "camel_38906": 0.7044248580932617, "camel_21913": 0.7044538259506226, "camel_22847": 0.704475462436676, "camel_23977": 0.7047914266586304, "camel_22841": 0.7048114538192749, "camel_21912": 0.7048246264457703, "aqua_rat_41715": 0.7052040100097656, "aqua_rat_67605": 0.7053572535514832, "camel_22876": 0.7055716514587402, "camel_22007": 0.7060163617134094, "camel_38635": 0.7066724300384521, "camel_41204": 0.7067179679870605, "camel_22020": 0.7069289684295654, "camel_23991": 0.7071105241775513, "camel_22066": 0.7072370648384094, "camel_22503": 0.7074980735778809, "camel_23926": 0.7080436944961548, "camel_22868": 0.7080509662628174, "camel_22484": 0.7082993388175964, "camel_38609": 0.7084023356437683, "camel_41263": 0.708431601524353, "camel_39930": 0.7087383270263672, "camel_22826": 0.7088223695755005, "camel_23945": 0.7089570164680481, "aqua_rat_23372": 0.7090197205543518, "camel_22417": 0.7090300917625427, "camel_22362": 0.7092342376708984, "camel_36493": 0.7092658877372742, "camel_23951": 0.7095310688018799, "camel_39977": 0.7095677256584167, "camel_21628": 0.7098539471626282, "camel_23131": 0.7098923325538635, "camel_22377": 0.7099675536155701, "camel_22059": 0.7100653648376465, "camel_36749": 0.7106044292449951, "camel_22383": 0.7111415266990662, "camel_39959": 0.7112764120101929, "camel_22332": 0.7113941311836243, "camel_39931": 0.7118339538574219, "camel_22378": 0.7120126485824585, "camel_22360": 0.7123011350631714, "camel_41247": 0.7125323414802551, "camel_23990": 0.7126110792160034, "camel_22170": 0.7130612134933472, "camel_22042": 0.7131370902061462, "camel_38586": 0.7132806181907654, "camel_39947": 0.7134117484092712, "gsm_rft_27803": 0.7135854959487915, "camel_39928": 0.713809072971344, "gsm_train_9826": 0.71381676197052, "gsm_rft_14862": 0.71381676197052, "camel_22052": 0.7139478325843811, "camel_22003": 0.7153058648109436, "camel_22832": 0.7155209183692932, "camel_39972": 0.7157026529312134, "camel_41241": 0.7157230377197266, "camel_39964": 0.7164688110351562, "camel_22026": 0.7164917588233948, "camel_22335": 0.7165103554725647, "camel_39920": 0.7167113423347473, "camel_22396": 0.7168576717376709, "camel_23364": 0.717039942741394, "camel_21664": 0.7171950936317444, "camel_22034": 0.7173864841461182, "camel_22019": 0.7178688645362854, "camel_21663": 0.7181004881858826, "camel_38611": 0.7182323932647705, "camel_23193": 0.7182763814926147, "camel_22037": 0.7183038592338562, "camel_22387": 0.7183520793914795, "camel_22058": 0.718504011631012, "camel_22028": 0.7186024785041809, "camel_22398": 0.7186183333396912, "camel_22539": 0.7189955711364746, "camel_22449": 0.7193271517753601, "camel_41753": 0.7193328142166138, "camel_21678": 0.719753623008728, "camel_22078": 0.7199730277061462, "camel_22010": 0.7207440137863159, "camel_41200": 0.7212090492248535, "camel_22070": 0.7213668823242188, "camel_41246": 0.7216946482658386, "camel_22031": 0.7219237089157104, "camel_22055": 0.722718358039856, "camel_22345": 0.7231622934341431, "camel_41255": 0.7232666611671448, "camel_39957": 0.7232868671417236, "camel_41202": 0.7232906222343445, "camel_22056": 0.7235338687896729, "camel_22041": 0.7236005067825317, "camel_22807": 0.723901093006134, "camel_21641": 0.7243668437004089, "camel_23923": 0.7244156002998352, "camel_22014": 0.7245073914527893, "camel_22004": 0.7246966361999512, "camel_39975": 0.725730836391449, "camel_22069": 0.7260328531265259, "camel_22064": 0.7264241576194763, "camel_22397": 0.7270208597183228, "camel_22361": 0.7274069786071777, "camel_22039": 0.7275476455688477, "camel_41252": 0.7277957201004028, "camel_22025": 0.7280466556549072, "camel_38630": 0.7281464338302612, "camel_22079": 0.7285237908363342, "camel_38587": 0.7289038300514221, "camel_22002": 0.7289653420448303, "camel_22336": 0.7290891408920288, "camel_39926": 0.7291629910469055, "camel_39960": 0.7293767929077148, "camel_22940": 0.7296152710914612, "camel_22074": 0.7308367490768433, "camel_22044": 0.7308635115623474, "camel_22006": 0.7311444282531738, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0.7311676144599915, "camel_22063": 0.7317661643028259, "camel_38569": 0.7330726981163025, "camel_22033": 0.7330748438835144, "camel_22040": 0.7341565489768982, "camel_22027": 0.7346770167350769, "camel_22045": 0.7358057498931885, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0.7363677024841309, "camel_22067": 0.7372410893440247, "camel_39997": 0.7375660538673401, "camel_39996": 0.7377261519432068, "camel_22035": 0.7387716770172119, "camel_22012": 0.739280641078949, "camel_22072": 0.7397973537445068, "camel_22029": 0.7401978373527527, "camel_36503": 0.7407913208007812, "camel_22043": 0.7410024404525757, "camel_22062": 0.7413457632064819, "camel_38489": 0.7415025234222412, "camel_38560": 0.7420904040336609, "camel_22053": 0.7427725791931152, "camel_22065": 0.7429471611976624, "camel_22030": 0.7446162104606628, "camel_22000": 0.7451459765434265, "camel_22032": 0.7452139258384705, "camel_22017": 0.7461825609207153, "camel_39938": 0.7474908828735352, "camel_39974": 0.74822998046875, "camel_22075": 0.7482656240463257, "camel_22016": 0.7506454586982727, "camel_22008": 0.7527682185173035, "camel_22061": 0.7528880834579468, "camel_22060": 0.7537302374839783, "camel_22015": 0.7538936138153076, "camel_22022": 0.7545824646949768, "camel_23980": 0.7551636099815369, "camel_22057": 0.7557029724121094, "camel_22005": 0.7560386061668396, "TheoremQA_maxku/graphtheory7-shortestpath.json": 0.7560627460479736, "camel_22021": 0.7572323679924011, "camel_23971": 0.7579177021980286, "camel_22036": 0.7583641409873962, "camel_22077": 0.7593563795089722, "camel_22046": 0.7617387175559998, "camel_22051": 0.7624266147613525, "camel_22009": 0.7628320455551147, "camel_22049": 0.7636440396308899, "camel_22073": 0.7641621232032776, "camel_22001": 0.7646826505661011, "camel_22024": 0.7660027742385864, "camel_22068": 0.7677640914916992, "camel_22076": 0.7702495455741882, "camel_22071": 0.7730267643928528, "camel_22038": 0.7730831503868103, "camel_22023": 0.7747941613197327, "camel_22054": 0.7751736044883728, "camel_22011": 0.7816377878189087, "camel_38576": 0.7856449484825134, "camel_22047": 0.793199360370636}, "TheoremQA_wenhuchen/kepler's_law1.json": {"TheoremQA_wenhuchen/kepler's_law1.json": 0, "aqua_rat_43793": 0.7148379683494568, "aqua_rat_9830": 0.7149380445480347, "camel_5008": 0.7150857448577881, "camel_5092": 0.7152211666107178, "gsm_rft_5789": 0.715225100517273, "aqua_rat_70370": 0.7152660489082336, "gsm_rft_22397": 0.7152671217918396, "aqua_rat_12166": 0.7153262495994568, "aqua_rat_35129": 0.7153364419937134, "aqua_rat_45660": 0.7153759002685547, "gsm_rft_10505": 0.7154895663261414, "camel_5311": 0.7155207991600037, "aqua_rat_45645": 0.7155855298042297, "aqua_rat_72071": 0.7155911326408386, "aqua_rat_86431": 0.7156033515930176, "aqua_rat_33984": 0.7156858444213867, "aqua_rat_60956": 0.7156872749328613, "aqua_rat_28240": 0.7157951593399048, "aqua_rat_25430": 0.715999960899353, "aqua_rat_29648": 0.7161641716957092, "aqua_rat_11110": 0.716164231300354, "gsm_rft_24185": 0.7162622809410095, "aqua_rat_13503": 0.7162841558456421, "aqua_rat_57087": 0.7163048982620239, "aqua_rat_71933": 0.7163548469543457, "TheoremQA_panlu/gravitational_force1.json": 0.716415524482727, "aqua_rat_53176": 0.7164682149887085, "aqua_rat_46742": 0.7164866924285889, "aqua_rat_2995": 0.7166198492050171, "aqua_rat_83073": 0.7168974876403809, "aqua_rat_83499": 0.7169368863105774, "camel_5138": 0.7171491384506226, "aqua_rat_60106": 0.7173804640769958, "aqua_rat_37688": 0.7174667119979858, "aqua_rat_17798": 0.7174804210662842, "aqua_rat_38896": 0.7174916863441467, "aqua_rat_65249": 0.7175479531288147, "aqua_rat_76350": 0.7176504731178284, "aqua_rat_43369": 0.7176828980445862, "aqua_rat_75920": 0.7178816199302673, "aqua_rat_5744": 0.7181077003479004, "gsm_rft_6137": 0.7182461619377136, "aqua_rat_83913": 0.7182667255401611, "aqua_rat_76549": 0.718304455280304, "camel_5070": 0.7185076475143433, "aqua_rat_61468": 0.7185819149017334, "aqua_rat_25695": 0.7185826897621155, "aqua_rat_43435": 0.7186011075973511, "aqua_rat_2038": 0.7190614938735962, "aqua_rat_17586": 0.7191210985183716, "aqua_rat_86618": 0.7191413044929504, "aqua_rat_64993": 0.7192765474319458, "TheoremQA_panlu/black_hole1.json": 0.7193150520324707, "aqua_rat_52253": 0.7194721102714539, "aqua_rat_48696": 0.719555139541626, "camel_5117": 0.7196088433265686, "camel_5057": 0.7196280360221863, "camel_28143": 0.7196469306945801, "math_test_prealgebra_393": 0.7196528315544128, "camel_29489": 0.7197515368461609, "camel_17406": 0.7198096513748169, "aqua_rat_47721": 0.719880223274231, "aqua_rat_57525": 0.7205962538719177, "aqua_rat_62625": 0.7206338047981262, "gsm_rft_26567": 0.7208391427993774, "gsm_rft_7556": 0.7211917042732239, "gsm_train_15621": 0.7211978435516357, "aqua_rat_68112": 0.7213362455368042, "aqua_rat_79757": 0.7214572429656982, "camel_5358": 0.7216188311576843, "gsm_rft_20646": 0.7218850255012512, "gsm_train_8611": 0.7218850255012512, "camel_29603": 0.7220019698143005, "aqua_rat_23397": 0.7221415638923645, "gsm_rft_35605": 0.7222303152084351, "aqua_rat_73912": 0.7223982810974121, "camel_28537": 0.72249835729599, "aqua_rat_79557": 0.7225539088249207, "aqua_rat_19853": 0.722756564617157, "camel_5114": 0.7227697372436523, "aqua_rat_77082": 0.7234175801277161, "aqua_rat_14801": 0.7237938642501831, "gsm_rft_18251": 0.7238536477088928, "camel_3148": 0.7240031361579895, "aqua_rat_35471": 0.7240597605705261, "aqua_rat_28149": 0.7240641713142395, "camel_28532": 0.7244040966033936, "aqua_rat_45615": 0.7247178554534912, "aqua_rat_71386": 0.7247587442398071, "aqua_rat_43143": 0.724759042263031, "camel_3710": 0.7248560190200806, "aqua_rat_32454": 0.7249478697776794, "aqua_rat_8986": 0.7254488468170166, "aqua_rat_10341": 0.7255225777626038, "gsm_rft_17764": 0.7258968949317932, "gsm_train_29099": 0.7258968949317932, "math_test_prealgebra_1423": 0.7266945838928223, "camel_28096": 0.7267716526985168, "aqua_rat_32037": 0.7268726229667664, "aqua_rat_6676": 0.7270272970199585, "camel_4969": 0.7270289063453674, "camel_4972": 0.7274281978607178, "aqua_rat_53348": 0.7275938987731934, "aqua_rat_36048": 0.7277256846427917, "aqua_rat_8248": 0.7279250025749207, "aqua_rat_71793": 0.7279371619224548, "aqua_rat_64811": 0.7280281782150269, "gsm_rft_35145": 0.7280492782592773, "math_test_geometry_169": 0.7282654047012329, "camel_19647": 0.728511393070221, "camel_4987": 0.7286498546600342, "gsm_train_18003": 0.7289190292358398, "gsm_rft_24790": 0.7289190292358398, "gsm_rft_25136": 0.7289190292358398, "aqua_rat_26876": 0.7289447784423828, "camel_5029": 0.7291589975357056, "aqua_rat_68269": 0.729258120059967, "aqua_rat_34381": 0.7294461131095886, "aqua_rat_73548": 0.7296769022941589, "aqua_rat_4051": 0.7297763824462891, "aqua_rat_81657": 0.729863166809082, "aqua_rat_84659": 0.7299085855484009, "aqua_rat_57461": 0.72994464635849, "aqua_rat_51549": 0.7300719022750854, "aqua_rat_59830": 0.7301270961761475, "aqua_rat_88155": 0.7303929328918457, "aqua_rat_66318": 0.7307604551315308, "aqua_rat_67556": 0.7309269309043884, "aqua_rat_30978": 0.7310073971748352, "camel_5001": 0.7312300801277161, "aqua_rat_43469": 0.731347918510437, "aqua_rat_64696": 0.7313772439956665, "camel_5165": 0.7315404415130615, "aqua_rat_2921": 0.7316211462020874, "camel_5189": 0.7317563891410828, "TheoremQA_xinyi/newtons_laws_1.json": 0.7323718667030334, "math_test_algebra_2631": 0.7325226068496704, "aqua_rat_51123": 0.7325435280799866, "aqua_rat_6305": 0.7326578497886658, "gsm_rft_1431": 0.7331186532974243, "aqua_rat_55212": 0.7332981824874878, "gsm_rft_34630": 0.7335376739501953, "gsm_rft_10934": 0.733786940574646, "gsm_train_23496": 0.733892560005188, "camel_4993": 0.7340156435966492, "aqua_rat_43860": 0.7342351675033569, "gsm_rft_24978": 0.7344411015510559, "gsm_rft_32685": 0.7346917390823364, "aqua_rat_56518": 0.7348402738571167, "aqua_rat_54538": 0.734928548336029, "aqua_rat_18441": 0.7350772619247437, "aqua_rat_34465": 0.7352861166000366, "aqua_rat_4364": 0.7354303598403931, "aqua_rat_75022": 0.7354450821876526, "aqua_rat_8908": 0.7355251312255859, "aqua_rat_20229": 0.7359828948974609, "camel_4999": 0.7367338538169861, "aqua_rat_75694": 0.737119734287262, "math_test_geometry_602": 0.737133800983429, "aqua_rat_60136": 0.737220287322998, "aqua_rat_42202": 0.737298846244812, "camel_5093": 0.7376021146774292, "aqua_rat_40694": 0.7376453280448914, "aqua_rat_3802": 0.7381781935691833, "aqua_rat_20126": 0.7388114333152771, "aqua_rat_29570": 0.739206075668335, "aqua_rat_26489": 0.7400646209716797, "aqua_rat_8349": 0.7403584122657776, "aqua_rat_63716": 0.741293728351593, "aqua_rat_65833": 0.7443230748176575, "camel_4994": 0.7445578575134277, "camel_5197": 0.7460415363311768, "TheoremQA_panlu/uniform_circular_motion2.json": 0.7465987801551819, "camel_5035": 0.7468087077140808, "camel_5284": 0.7469459176063538, "aqua_rat_70945": 0.748936116695404, "TheoremQA_panlu/energy_conservation1.json": 0.7505500912666321, "aqua_rat_70741": 0.7506862282752991, "camel_5178": 0.7510741353034973, "math_test_prealgebra_1007": 0.7512888312339783, "aqua_rat_43112": 0.7521025538444519, "camel_5004": 0.7557546496391296, "aqua_rat_24388": 0.7570131421089172, "TheoremQA_wenhuchen/kepler's_law2.json": 0.7590848207473755, "aqua_rat_42233": 0.7606879472732544, "camel_5344": 0.7615332007408142, "aqua_rat_6249": 0.7641323208808899, "gsm_rft_14753": 0.7650819420814514, "gsm_rft_21861": 0.7650819420814514, "gsm_train_25944": 0.7650819420814514, "aqua_rat_36823": 0.7658963203430176, "camel_28137": 0.7687427401542664, "math_train_algebra_2156": 0.7691000699996948, "camel_39513": 0.7733789086341858, "aqua_rat_18805": 0.7768190503120422, "math_test_algebra_1169": 0.7807496190071106, "math_train_algebra_2034": 0.7834481000900269, "camel_39449": 0.8026899695396423, "TheoremQA_wenhuchen/kepler's_law3.json": 0.8333380222320557}, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": {"TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0, "aqua_rat_29047": 0.7000064849853516, "gsm_rft_29866": 0.7000486254692078, "aqua_rat_35043": 0.7004567384719849, "gsm_rft_6376": 0.7005483508110046, "gsm_rft_9202": 0.7007355690002441, "gsm_rft_21534": 0.7007755637168884, "gsm_train_34667": 0.7007755637168884, "gsm_rft_30626": 0.7007767558097839, "gsm_rft_17490": 0.700866162776947, "aqua_rat_65750": 0.7008687257766724, "aqua_rat_43928": 0.7008692622184753, "aqua_rat_74118": 0.7009389400482178, "gsm_rft_22430": 0.7009481191635132, "aqua_rat_36417": 0.7009950876235962, "gsm_rft_521": 0.7011539340019226, "aqua_rat_8353": 0.7011598944664001, "aqua_rat_3509": 0.7011736035346985, "aqua_rat_19945": 0.7012348771095276, "gsm_rft_22391": 0.701278805732727, "gsm_train_30943": 0.7013105750083923, "gsm_rft_7911": 0.7014361023902893, "gsm_rft_7352": 0.7014896869659424, "gsm_train_32872": 0.7014896869659424, "gsm_rft_19481": 0.7015975117683411, "aqua_rat_2708": 0.7017239928245544, "gsm_rft_2329": 0.7018508911132812, "aqua_rat_48677": 0.7020258903503418, "aqua_rat_35655": 0.7020946145057678, "aqua_rat_35972": 0.7021334767341614, "gsm_rft_23591": 0.7021615505218506, "gsm_train_22690": 0.7021615505218506, "aqua_rat_4993": 0.7022987604141235, "aqua_rat_44149": 0.7023243308067322, "gsm_rft_7189": 0.7023509740829468, "gsm_train_26253": 0.7025964260101318, "gsm_train_27703": 0.7027488350868225, "gsm_rft_19343": 0.7030386924743652, "aqua_rat_50137": 0.7030898928642273, "gsm_rft_28569": 0.7030905485153198, "gsm_rft_31557": 0.7030991315841675, "math_train_prealgebra_1358": 0.7031238675117493, "aqua_rat_25590": 0.7033751606941223, "gsm_rft_33995": 0.7033997774124146, "aqua_rat_44157": 0.7034144997596741, "gsm_rft_33011": 0.7034155130386353, "aqua_rat_60866": 0.7038070559501648, "gsm_rft_28656": 0.7039259076118469, "aqua_rat_22015": 0.7039980292320251, "camel_26594": 0.7046741247177124, "aqua_rat_20092": 0.7048841714859009, "camel_44732": 0.7051776647567749, "gsm_rft_4279": 0.7052395939826965, "aqua_rat_3461": 0.7052451968193054, "aqua_rat_38865": 0.7055141925811768, "aqua_rat_59341": 0.7056401968002319, "aqua_rat_42782": 0.7056583762168884, "gsm_rft_23312": 0.7057835459709167, "aqua_rat_69971": 0.7063014507293701, "gsm_rft_27461": 0.706420361995697, "gsm_train_25333": 0.706420361995697, "gsm_rft_20126": 0.70660799741745, "aqua_rat_7783": 0.706762969493866, "gsm_rft_398": 0.7068511247634888, "aqua_rat_30134": 0.707015872001648, "camel_13806": 0.7076044082641602, "gsm_train_5776": 0.707613468170166, "gsm_rft_89": 0.707613468170166, "aqua_rat_59131": 0.7076522707939148, "gsm_rft_13386": 0.7076549530029297, "aqua_rat_39830": 0.7077294588088989, "gsm_train_33147": 0.7081264853477478, "aqua_rat_69248": 0.7081973552703857, "gsm_rft_10321": 0.7082359194755554, "gsm_rft_28764": 0.7084149718284607, "gsm_train_30821": 0.7084193229675293, "gsm_rft_32670": 0.7084193229675293, "gsm_rft_23242": 0.7089980840682983, "aqua_rat_73185": 0.7090349793434143, "gsm_rft_28181": 0.7096959352493286, "aqua_rat_84478": 0.7098478674888611, "gsm_rft_28561": 0.7100845575332642, "gsm_train_11581": 0.7100845575332642, "gsm_rft_7433": 0.7100845575332642, "aqua_rat_60195": 0.7101745009422302, "gsm_rft_18202": 0.710268497467041, "aqua_rat_49275": 0.7102897763252258, "aqua_rat_6253": 0.7103874683380127, "gsm_rft_34628": 0.7104119658470154, "aqua_rat_10496": 0.7107312083244324, "gsm_rft_1234": 0.7110419869422913, "aqua_rat_22212": 0.7110642194747925, "gsm_rft_1963": 0.7112898230552673, "gsm_rft_12027": 0.7122340202331543, "gsm_rft_9950": 0.7124066352844238, "gsm_rft_22880": 0.7124322056770325, "aqua_rat_52087": 0.7124729752540588, "camel_13795": 0.712763786315918, "gsm_train_3804": 0.712801992893219, "gsm_rft_16361": 0.7129677534103394, "gsm_train_19829": 0.7130143642425537, "gsm_rft_24388": 0.713164746761322, "gsm_rft_3729": 0.7131819128990173, "aqua_rat_53867": 0.7132323980331421, "gsm_rft_12713": 0.7132360339164734, "gsm_rft_33599": 0.713265597820282, "aqua_rat_78286": 0.7139424085617065, "aqua_rat_5881": 0.7139558792114258, "aqua_rat_16513": 0.7142546772956848, "gsm_rft_7226": 0.7143841981887817, "gsm_rft_22092": 0.7144856452941895, "aqua_rat_85903": 0.7148599028587341, "gsm_rft_27312": 0.7148672342300415, "gsm_rft_1805": 0.7150253653526306, "gsm_train_34775": 0.7151128053665161, "aqua_rat_83472": 0.7151811718940735, "gsm_train_4199": 0.7152738571166992, "gsm_rft_9272": 0.7152738571166992, "gsm_rft_229": 0.7152738571166992, "gsm_rft_33571": 0.7153264880180359, "gsm_rft_21828": 0.7153587937355042, "gsm_rft_11985": 0.7153942584991455, "gsm_rft_4746": 0.7155085206031799, "aqua_rat_87402": 0.7158477902412415, "aqua_rat_71393": 0.715908408164978, "gsm_rft_25368": 0.7159969806671143, "aqua_rat_50724": 0.7160424590110779, "gsm_train_26101": 0.7161548137664795, "gsm_rft_10255": 0.7161548137664795, "gsm_rft_15313": 0.7161548137664795, "gsm_rft_17206": 0.7162503004074097, "gsm_rft_32313": 0.7164754867553711, "gsm_train_31599": 0.7166310548782349, "aqua_rat_433": 0.7166455388069153, "aqua_rat_9712": 0.7169267535209656, "gsm_rft_33753": 0.7174063324928284, "gsm_rft_25774": 0.717511773109436, "aqua_rat_69799": 0.7178142070770264, "gsm_rft_20159": 0.717866837978363, "gsm_rft_9162": 0.718059778213501, "gsm_rft_25272": 0.718298614025116, "gsm_train_13705": 0.7183578610420227, "gsm_rft_5276": 0.7183578610420227, "aqua_rat_36286": 0.7184070348739624, "gsm_rft_29593": 0.7184259295463562, "gsm_rft_14419": 0.7185352444648743, "gsm_rft_13859": 0.7187040448188782, "gsm_rft_32533": 0.7198988199234009, "aqua_rat_5613": 0.7199285626411438, "gsm_rft_6860": 0.7199538350105286, "aqua_rat_8126": 0.7200396656990051, "gsm_rft_32270": 0.7202423810958862, "gsm_train_27467": 0.7202423810958862, "gsm_rft_11215": 0.7204388380050659, "gsm_rft_411": 0.7209296822547913, "gsm_train_12172": 0.7209296822547913, "gsm_rft_34987": 0.7214740514755249, "camel_26365": 0.7217401266098022, "gsm_rft_17389": 0.7221783995628357, "aqua_rat_27910": 0.7225057482719421, "camel_27982": 0.7239328026771545, "gsm_rft_34505": 0.7243937849998474, "aqua_rat_88092": 0.7243981957435608, "gsm_rft_20353": 0.7248342633247375, "gsm_rft_14307": 0.7250012755393982, "aqua_rat_8857": 0.7255945205688477, "aqua_rat_51499": 0.7257386445999146, "gsm_rft_33965": 0.7259679436683655, "camel_44728": 0.7261864542961121, "gsm_rft_12105": 0.7276265025138855, "gsm_rft_2105": 0.7277895212173462, "gsm_train_21508": 0.7277933955192566, "gsm_train_15116": 0.7280141115188599, "gsm_rft_159": 0.7280141115188599, "gsm_rft_4658": 0.7287336587905884, "gsm_rft_5163": 0.7292075157165527, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.7292083501815796, "gsm_rft_2717": 0.7319295406341553, "gsm_train_15441": 0.7341637015342712, "gsm_rft_9514": 0.7341637015342712, "gsm_rft_19302": 0.7343544960021973, "gsm_rft_23745": 0.734382688999176, "camel_44741": 0.7351371049880981, "math_train_prealgebra_1637": 0.7414457201957703, "camel_44798": 0.7503364086151123, "camel_36295": 0.7517678737640381, "camel_44424": 0.7522308826446533, "gsm_rft_24062": 0.7529999613761902, "gsm_rft_6010": 0.7615964412689209, "gsm_train_21444": 0.7615964412689209, "gsm_rft_17939": 0.7680248618125916, "gsm_rft_4843": 0.7774580717086792, "camel_44748": 0.7854934930801392, "gsm_rft_24925": 0.7855975031852722, "gsm_train_27821": 0.7855975031852722, "gsm_rft_4144": 0.7978387475013733, "gsm_rft_15756": 0.7978387475013733, "gsm_train_25080": 0.7988361120223999, "TheoremQA_maxku/cv-imageprocessing10-digital-image.json": 0.8040778636932373, "TheoremQA_maxku/cv-colorsci1-rgb.json": 0.820756733417511}, "TheoremQA_jianyu_xu/pigeonhole_4.json": {"camel_21157": 0, "camel_21246": 0, "camel_21123": 0, "camel_21568": 0, "camel_21190": 0, "camel_21153": 0, "camel_20287": 0, "camel_21142": 0, "camel_21193": 0, "camel_20540": 0, "camel_21139": 0, "camel_21163": 0, "camel_21187": 0, "camel_21171": 0, "camel_21125": 0, "camel_21182": 0, "camel_21835": 0, "camel_21188": 0, "camel_21154": 0, "camel_21141": 0, "camel_21170": 0, "camel_21126": 0, "camel_21132": 0, "camel_20577": 0, "camel_21165": 0, "camel_20256": 0, "camel_21162": 0, "camel_21120": 0, "camel_21174": 0, "camel_21185": 0, "camel_21195": 0, "camel_21169": 0, "camel_21172": 0, "camel_21137": 0, "camel_21147": 0, "camel_21146": 0, "camel_21176": 0, "camel_21040": 0, "camel_21152": 0, "camel_21198": 0, "camel_21160": 0, "camel_21143": 0, "camel_21128": 0, "camel_21121": 0, "camel_21159": 0, "camel_21177": 0, "camel_21055": 0, "camel_20898": 0, "camel_21168": 0, "camel_21798": 0, "camel_21196": 0, "camel_21183": 0, "TheoremQA_jianyu_xu/pigeonhole_4.json": 0, "aqua_rat_43666": 0.7353449463844299, "aqua_rat_86623": 0.7358276844024658, "aqua_rat_10136": 0.7358911037445068, "aqua_rat_84086": 0.7359259128570557, "aqua_rat_19096": 0.7359536290168762, "aqua_rat_47936": 0.7361393570899963, "aqua_rat_54117": 0.7362130880355835, "aqua_rat_37903": 0.7364606857299805, "aqua_rat_3736": 0.7367067933082581, "aqua_rat_87748": 0.7367145419120789, "aqua_rat_8919": 0.7368997931480408, "aqua_rat_15511": 0.7372438907623291, "aqua_rat_52817": 0.7373879551887512, "aqua_rat_32157": 0.7374696731567383, "aqua_rat_20969": 0.7375861406326294, "aqua_rat_66391": 0.7376892566680908, "aqua_rat_56885": 0.7377443909645081, "aqua_rat_46126": 0.737900972366333, "camel_23711": 0.7379510998725891, "aqua_rat_56889": 0.7379927039146423, "aqua_rat_40065": 0.738042950630188, "aqua_rat_44306": 0.7380939722061157, "aqua_rat_40097": 0.7382583618164062, "aqua_rat_60456": 0.7382791638374329, "TheoremQA_jianyu_xu/Ramsey_2.json": 0.7386008501052856, "aqua_rat_82478": 0.7387536764144897, "aqua_rat_26459": 0.7389494776725769, "aqua_rat_17717": 0.7390488982200623, "aqua_rat_56528": 0.7394779324531555, "aqua_rat_52362": 0.7395091652870178, "aqua_rat_84502": 0.7395470142364502, "aqua_rat_58655": 0.7395577430725098, "aqua_rat_82439": 0.7401264309883118, "aqua_rat_78662": 0.7401431798934937, "aqua_rat_17862": 0.7402119040489197, "aqua_rat_41411": 0.7403801083564758, "aqua_rat_65028": 0.7403952479362488, "aqua_rat_48130": 0.7404407262802124, "aqua_rat_83796": 0.7406607866287231, "aqua_rat_44594": 0.7406859397888184, "aqua_rat_52771": 0.7410527467727661, "aqua_rat_81742": 0.7411688566207886, "aqua_rat_48816": 0.7414606213569641, "aqua_rat_21205": 0.7415174841880798, "aqua_rat_56307": 0.7415316700935364, "aqua_rat_23573": 0.7415663599967957, "aqua_rat_87077": 0.7415959239006042, "aqua_rat_73560": 0.7416830062866211, "aqua_rat_80759": 0.7420298457145691, "aqua_rat_42578": 0.7420890927314758, "aqua_rat_38419": 0.7425647974014282, "math_train_counting_and_probability_531": 0.7426689267158508, "aqua_rat_73523": 0.7427894473075867, "aqua_rat_47768": 0.7428446412086487, "aqua_rat_62050": 0.7429795861244202, "aqua_rat_45273": 0.7430347204208374, "aqua_rat_66313": 0.7434096932411194, "aqua_rat_63725": 0.7434841394424438, "aqua_rat_31932": 0.7435132265090942, "aqua_rat_57117": 0.7435741424560547, "aqua_rat_17359": 0.743598997592926, "aqua_rat_23636": 0.7436585426330566, "aqua_rat_7922": 0.7438030242919922, "aqua_rat_25103": 0.7439748644828796, "aqua_rat_46435": 0.743980348110199, "aqua_rat_40277": 0.744013786315918, "aqua_rat_76356": 0.7440723180770874, "math_test_counting_and_probability_341": 0.7441081404685974, "aqua_rat_86939": 0.7441220879554749, "aqua_rat_48326": 0.7441366314888, "aqua_rat_10371": 0.7441449761390686, "aqua_rat_19178": 0.7445054054260254, "aqua_rat_39765": 0.7447691559791565, "aqua_rat_73303": 0.7448058128356934, "aqua_rat_15706": 0.7450242638587952, "aqua_rat_22669": 0.7451189756393433, "aqua_rat_71445": 0.7451671957969666, "aqua_rat_31828": 0.7451944947242737, "aqua_rat_19090": 0.7453881502151489, "aqua_rat_80435": 0.7454790472984314, "aqua_rat_59044": 0.7455534934997559, "aqua_rat_53788": 0.7455688118934631, "aqua_rat_30710": 0.7457141280174255, "aqua_rat_27921": 0.7460548877716064, "aqua_rat_15442": 0.7460727095603943, "aqua_rat_59053": 0.7462958097457886, "aqua_rat_65742": 0.7468059659004211, "aqua_rat_43005": 0.7468066811561584, "aqua_rat_149": 0.7469441294670105, "aqua_rat_6686": 0.7470031976699829, "aqua_rat_7904": 0.7473272085189819, "aqua_rat_3108": 0.7478618621826172, "aqua_rat_73716": 0.748166024684906, "math_train_prealgebra_325": 0.7489665746688843, "aqua_rat_71213": 0.7494809627532959, "aqua_rat_30610": 0.7496055364608765, "aqua_rat_31046": 0.7503980398178101, "aqua_rat_78805": 0.7504217624664307, "aqua_rat_46632": 0.7504762411117554, "aqua_rat_23524": 0.7522531747817993, "aqua_rat_7521": 0.7523943185806274, "aqua_rat_72312": 0.7525355219841003, "aqua_rat_48028": 0.753911018371582, "aqua_rat_38285": 0.7539399862289429, "aqua_rat_26254": 0.7545157670974731, "aqua_rat_20302": 0.7548720836639404, "aqua_rat_37188": 0.755381166934967, "math_train_prealgebra_1917": 0.7559458017349243, "aqua_rat_87746": 0.7562527060508728, "aqua_rat_27075": 0.7562819123268127, "aqua_rat_74390": 0.7569999098777771, "math_train_counting_and_probability_5123": 0.7573428153991699, "aqua_rat_16788": 0.7577752470970154, "aqua_rat_67387": 0.7588095664978027, "aqua_rat_51541": 0.7590115666389465, "camel_11562": 0.7597446441650391, "aqua_rat_15480": 0.7601968050003052, "aqua_rat_53649": 0.7610518932342529, "aqua_rat_34164": 0.7612533569335938, "aqua_rat_47084": 0.7642903327941895, "aqua_rat_52525": 0.7650161981582642, "aqua_rat_69238": 0.765598475933075, "aqua_rat_70890": 0.7663130760192871, "aqua_rat_4199": 0.7666807770729065, "aqua_rat_27348": 0.7675800919532776, "camel_11574": 0.7707827091217041, "aqua_rat_26932": 0.7715551853179932, "aqua_rat_11601": 0.7720181941986084, "aqua_rat_56614": 0.7734171152114868, "aqua_rat_50073": 0.7734602689743042, "camel_11579": 0.7750794887542725, "camel_38538": 0.7751902341842651, "aqua_rat_58088": 0.7754392027854919, "aqua_rat_75262": 0.7768750786781311, "aqua_rat_87294": 0.7789634466171265, "aqua_rat_5662": 0.781731128692627, "aqua_rat_86710": 0.7817450165748596, "aqua_rat_51045": 0.7851019501686096, "aqua_rat_65264": 0.7901425361633301, "camel_11570": 0.7928828001022339, "aqua_rat_50597": 0.7934798002243042, "aqua_rat_33710": 0.7952824234962463, "aqua_rat_14782": 0.7997024655342102, "aqua_rat_6737": 0.8028385043144226, "camel_11529": 0.8150161504745483, "TheoremQA_jianyu_xu/pigeonhole_3.json": 0.8175121545791626, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0.897204577922821}, "TheoremQA_elainewan/math_calculus_5.json": {"camel_6256": 0, "camel_7115": 0, "camel_7283": 0, "camel_6291": 0, "camel_6296": 0, "camel_7761": 0, "camel_7057": 0, "camel_7787": 0, "camel_6254": 0, "camel_7085": 0, "camel_7334": 0, "camel_7296": 0, "camel_6319": 0, "camel_7114": 0, "camel_7792": 0, "camel_7807": 0, "camel_6279": 0, "camel_6282": 0, "camel_7068": 0, "camel_7099": 0, "camel_7050": 0, "camel_7304": 0, "camel_7346": 0, "camel_7041": 0, "camel_7117": 0, "camel_7089": 0, "camel_7359": 0, "camel_7076": 0, "camel_7096": 0, "camel_7799": 0, "camel_7327": 0, "camel_7347": 0, "camel_6308": 0, "camel_7686": 0, "camel_6270": 0, "camel_7309": 0, "camel_6295": 0, "camel_6292": 0, "camel_7823": 0, "camel_6265": 0, "camel_7058": 0, "camel_7797": 0, "camel_7811": 0, "camel_7780": 0, "camel_7065": 0, "camel_7075": 0, "camel_7104": 0, "camel_6165": 0, "camel_7080": 0, "camel_7100": 0, "camel_7795": 0, "camel_7297": 0, "camel_7791": 0, "camel_7818": 0, "camel_7046": 0, "camel_7043": 0, "camel_6166": 0, "camel_7097": 0, "camel_6244": 0, "camel_7101": 0, "camel_7292": 0, "camel_7113": 0, "camel_7782": 0, "camel_6294": 0, "camel_6267": 0, "camel_6313": 0, "camel_7805": 0, "camel_6299": 0, "camel_6300": 0, "camel_6247": 0, "camel_6262": 0, "camel_6266": 0, "camel_7048": 0, "camel_6261": 0, "camel_6288": 0, "camel_7083": 0, "camel_6290": 0, "camel_6316": 0, "camel_6314": 0, "camel_7820": 0, "camel_7831": 0, "camel_7819": 0, "camel_7081": 0, "camel_7779": 0, "camel_7804": 0, "camel_7816": 0, "camel_7107": 0, "camel_7830": 0, "camel_7796": 0, "camel_6250": 0, "camel_7766": 0, "camel_7838": 0, "camel_7785": 0, "camel_7093": 0, "camel_7102": 0, "camel_7767": 0, "camel_7826": 0, "camel_7119": 0, "camel_7815": 0, "camel_7784": 0, "camel_7768": 0, "camel_7071": 0, "camel_6315": 0, "camel_7781": 0, "camel_7763": 0, "camel_7776": 0, "camel_7836": 0, "camel_6285": 0, "camel_7832": 0, "camel_7317": 0, "camel_7770": 0, "camel_7834": 0, "camel_7829": 0, "camel_7762": 0, "camel_7063": 0, "camel_7769": 0, "camel_7808": 0, "camel_6312": 0, "camel_7783": 0, "camel_6307": 0, "camel_7764": 0, "camel_6983": 0, "camel_7835": 0, "camel_7814": 0, "camel_7772": 0, "camel_7060": 0, "camel_7837": 0, "camel_7786": 0, "camel_7108": 0, "camel_7082": 0, "camel_7731": 0, "camel_7802": 0, "camel_7824": 0, "camel_7086": 0, "camel_7822": 0, "camel_7833": 0, "camel_7110": 0, "camel_7773": 0, "camel_7052": 0, "camel_7821": 0, "camel_6283": 0, "camel_7812": 0, "camel_7839": 0, "camel_6273": 0, "camel_6252": 0, "camel_7054": 0, "camel_7798": 0, "camel_7106": 0, "camel_7803": 0, "camel_7778": 0, "camel_7061": 0, "camel_6317": 0, "camel_7817": 0, "camel_6249": 0, "camel_7801": 0, "camel_6318": 0, "camel_7825": 0, "camel_6306": 0, "camel_6272": 0, "camel_6280": 0, "camel_7793": 0, "camel_6275": 0, "camel_7092": 0, "camel_6297": 0, "camel_7800": 0, "camel_6253": 0, "camel_6264": 0, "camel_6255": 0, "camel_7760": 0, "camel_7775": 0, "camel_6311": 0, "camel_6305": 0, "camel_6269": 0, "camel_6276": 0, "camel_6298": 0, "camel_6242": 0, "camel_6286": 0, "camel_6263": 0, "camel_6243": 0, "camel_6274": 0, "camel_6284": 0, "camel_6301": 0, "camel_6245": 0, "camel_6241": 0, "camel_6302": 0, "camel_41216": 0.794852077960968, "camel_5320": 0.7955261468887329, "camel_5313": 0.7961508631706238, "camel_5282": 0.799572765827179, "camel_39544": 0.801302433013916, "camel_5357": 0.8023020029067993, "camel_5327": 0.8030507564544678, "camel_5351": 0.8031533360481262, "camel_19568": 0.8062301278114319, "camel_39579": 0.8087953925132751, "camel_44347": 0.8102990388870239, "camel_5342": 0.8124288320541382, "camel_19895": 0.814258873462677, "camel_5307": 0.8209893703460693, "camel_45941": 0.8234983682632446}, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": {"camel_20862": 0, "camel_20281": 0, "camel_20257": 0, "camel_21039": 0, "camel_20643": 0, "camel_21567": 0, "camel_20308": 0, "camel_20410": 0, "camel_20299": 0, "camel_20640": 0, "camel_20449": 0, "camel_20487": 0, "camel_20506": 0, "camel_21246": 0, "camel_20611": 0, "camel_20255": 0, "camel_20864": 0, "camel_21261": 0, "camel_20706": 0, "camel_20861": 0, "camel_20823": 0, "camel_21400": 0, "camel_20844": 0, "camel_20248": 0, "camel_20853": 0, "camel_20808": 0, "camel_20462": 0, "camel_20579": 0, "camel_20464": 0, "camel_20973": 0, "camel_20637": 0, "camel_20805": 0, "camel_20813": 0, "camel_20818": 0, "camel_21117": 0, "camel_20514": 0, "camel_20626": 0, "camel_21050": 0, "camel_20297": 0, "camel_20661": 0, "camel_20302": 0, "camel_20609": 0, "camel_20602": 0, "camel_20849": 0, "camel_20578": 0, "camel_20623": 0, "camel_20656": 0, "camel_20860": 0, "camel_20848": 0, "camel_21798": 0, "camel_20604": 0, "camel_20411": 0, "camel_20262": 0, "camel_20867": 0, "camel_20841": 0, "camel_21361": 0, "camel_20499": 0, "camel_20836": 0, "camel_20598": 0, "camel_20317": 0, "camel_20863": 0, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": 0, "camel_21223": 0, "camel_20856": 0, "camel_20812": 0, "camel_20619": 0, "camel_20698": 0, "camel_20583": 0, "camel_20414": 0, "camel_21219": 0, "camel_20806": 0, "camel_20695": 0, "camel_20614": 0, "camel_20301": 0, "camel_20563": 0, "camel_20310": 0, "camel_20596": 0, "aqua_rat_41607": 0.8066536784172058, "aqua_rat_34": 0.8068721890449524, "aqua_rat_17329": 0.8069169521331787, "aqua_rat_37649": 0.8069660663604736, "aqua_rat_53084": 0.8069885969161987, "aqua_rat_82146": 0.8072753548622131, "aqua_rat_30172": 0.8073517680168152, "aqua_rat_8375": 0.807563841342926, "math_test_counting_and_probability_862": 0.807820200920105, "aqua_rat_49410": 0.8082119226455688, "aqua_rat_74550": 0.8085778951644897, "aqua_rat_44511": 0.8088658452033997, "aqua_rat_77478": 0.8088843822479248, "aqua_rat_18404": 0.8103445172309875, "aqua_rat_10178": 0.8105336427688599, "aqua_rat_81317": 0.8108481764793396, "math_train_counting_and_probability_696": 0.8112738728523254, "aqua_rat_49569": 0.811333954334259, "aqua_rat_73402": 0.8121063709259033, "aqua_rat_21789": 0.8122298717498779, "aqua_rat_11164": 0.8123141527175903, "aqua_rat_39259": 0.8127661347389221, "aqua_rat_5030": 0.813049852848053, "aqua_rat_65294": 0.8131632208824158, "aqua_rat_77406": 0.8132001757621765, "aqua_rat_64485": 0.8138179779052734, "aqua_rat_25894": 0.8144770264625549, "camel_12727": 0.8145190477371216, "aqua_rat_35289": 0.8146297931671143, "aqua_rat_58193": 0.8147197961807251, "aqua_rat_13585": 0.8148398399353027, "aqua_rat_88489": 0.8150168657302856, "aqua_rat_50641": 0.8152137398719788, "aqua_rat_57502": 0.8152287006378174, "aqua_rat_75517": 0.8153863549232483, "aqua_rat_14308": 0.8165351152420044, "aqua_rat_4294": 0.8171515464782715, "aqua_rat_13369": 0.8172388672828674, "aqua_rat_11531": 0.8181303143501282, "aqua_rat_10186": 0.8182728886604309, "aqua_rat_66391": 0.8186214566230774, "aqua_rat_27274": 0.819280207157135, "aqua_rat_2480": 0.8195174336433411, "aqua_rat_54525": 0.819549560546875, "math_train_counting_and_probability_273": 0.8198202252388, "aqua_rat_89113": 0.8204053640365601, "aqua_rat_19931": 0.8205933570861816, "math_train_counting_and_probability_784": 0.8208102583885193, "aqua_rat_44268": 0.8208814859390259, "aqua_rat_45483": 0.8209121227264404, "aqua_rat_575": 0.8209372162818909, "aqua_rat_41924": 0.8213921785354614, "aqua_rat_62284": 0.8214303851127625, "aqua_rat_11651": 0.8217700719833374, "aqua_rat_16877": 0.8218966126441956, "aqua_rat_61326": 0.8222804665565491, "aqua_rat_61965": 0.8224635124206543, "aqua_rat_18901": 0.8227607011795044, "aqua_rat_2658": 0.8227856159210205, "aqua_rat_58757": 0.8227996826171875, "math_test_counting_and_probability_341": 0.8228347897529602, "aqua_rat_46365": 0.823288083076477, "aqua_rat_49950": 0.8233902454376221, "aqua_rat_29348": 0.8236508965492249, "math_train_counting_and_probability_241": 0.8247228264808655, "aqua_rat_70446": 0.8252950310707092, "aqua_rat_57767": 0.8256164789199829, "aqua_rat_415": 0.8258944749832153, "TheoremQA_jianyu_xu/combination_and_permutation_1.json": 0.8261155486106873, "aqua_rat_73122": 0.8271227478981018, "math_train_counting_and_probability_125": 0.8278337121009827, "aqua_rat_7248": 0.8279145956039429, "aqua_rat_39115": 0.8285796642303467, "aops_2019_AMC_8_Problems/Problem_25": 0.8286146521568298, "math_test_counting_and_probability_485": 0.8290295600891113, "aqua_rat_39642": 0.8295079469680786, "aqua_rat_34678": 0.8297752141952515, "aqua_rat_5049": 0.8301945328712463, "aqua_rat_73393": 0.8306409120559692, "math_train_counting_and_probability_371": 0.8311361074447632, "aqua_rat_40108": 0.8313974142074585, "aqua_rat_84159": 0.8316458463668823, "math_test_counting_and_probability_79": 0.8319242596626282, "aqua_rat_48130": 0.8321853280067444, "aqua_rat_61885": 0.8322252631187439, "camel_38534": 0.8322504162788391, "aqua_rat_63836": 0.8326454162597656, "aqua_rat_11061": 0.8334824442863464, "aqua_rat_8627": 0.8336568474769592, "aqua_rat_52832": 0.8341017961502075, "aqua_rat_77140": 0.8341636061668396, "aqua_rat_77698": 0.8342236876487732, "aqua_rat_29651": 0.8346954584121704, "aqua_rat_21240": 0.8348498940467834, "aqua_rat_71434": 0.8366565108299255, "aqua_rat_42061": 0.8369027376174927, "math_train_counting_and_probability_375": 0.837181568145752, "aqua_rat_60238": 0.8381845951080322, "aqua_rat_210": 0.8394088745117188, "aqua_rat_54461": 0.8395463824272156, "aqua_rat_76714": 0.8401237726211548, "aqua_rat_22458": 0.8410471081733704, "aqua_rat_62261": 0.8410844802856445, "aqua_rat_57985": 0.8419076204299927, "aqua_rat_83784": 0.8433785438537598, "aqua_rat_41861": 0.8445150256156921, "aqua_rat_37185": 0.8460294008255005, "aqua_rat_19436": 0.8470056056976318, "math_test_counting_and_probability_416": 0.847813606262207, "aqua_rat_60936": 0.8487719297409058, "aqua_rat_56015": 0.8492947816848755, "aqua_rat_25369": 0.8496226668357849, "aqua_rat_26524": 0.8534069061279297, "math_train_counting_and_probability_252": 0.853945255279541, "aqua_rat_75188": 0.85689377784729, "aqua_rat_34205": 0.8569185137748718, "aqua_rat_39610": 0.8579335808753967, "math_train_counting_and_probability_98": 0.8587643504142761, "math_train_counting_and_probability_296": 0.8614031076431274, "math_train_counting_and_probability_149": 0.8637160658836365, "math_test_counting_and_probability_71": 0.8701562285423279, "math_test_counting_and_probability_294": 0.8750931620597839, "math_train_counting_and_probability_83": 0.8835012912750244}, "TheoremQA_xinyi/dag_3.json": {"camel_20516": 0, "camel_21100": 0, "camel_23060": 0, "camel_21133": 0, "camel_23119": 0, "camel_21537": 0, "camel_23986": 0, "camel_21817": 0, "camel_20979": 0, "camel_20075": 0, "camel_21086": 0, "camel_23971": 0, "camel_23307": 0, "camel_21176": 0, "camel_23573": 0, "camel_20029": 0, "camel_20789": 0, "camel_23292": 0, "camel_21525": 0, "camel_20734": 0, "camel_21228": 0, "camel_21085": 0, "camel_21815": 0, "camel_23114": 0, "camel_20398": 0, "camel_21059": 0, "camel_23558": 0, "camel_21000": 0, "camel_23944": 0, "camel_23561": 0, "camel_23348": 0, "camel_21051": 0, "camel_20787": 0, "camel_20540": 0, "camel_23284": 0, "camel_20377": 0, "camel_21064": 0, "camel_21809": 0, "camel_20121": 0, "camel_20050": 0, "camel_20512": 0, "camel_21764": 0, "camel_23312": 0, "camel_21167": 0, "TheoremQA_xinyi/dag_3.json": 0, "math_train_counting_and_probability_202": 0.7071225047111511, "aqua_rat_12956": 0.7071256041526794, "math_test_counting_and_probability_103": 0.7071521282196045, "aqua_rat_75334": 0.7071855664253235, "aqua_rat_19988": 0.7071934342384338, "aqua_rat_19604": 0.7072573900222778, "math_test_counting_and_probability_748": 0.7072898149490356, "aqua_rat_23955": 0.707594633102417, "aqua_rat_3911": 0.7076582312583923, "math_train_prealgebra_536": 0.7076832056045532, "aqua_rat_14023": 0.707693338394165, "aqua_rat_15612": 0.7079236507415771, "aqua_rat_85987": 0.7079697251319885, "aqua_rat_88292": 0.7083630561828613, "aqua_rat_80580": 0.708512544631958, "aqua_rat_21138": 0.7085762023925781, "aqua_rat_10420": 0.7086358666419983, "aqua_rat_29590": 0.7088127136230469, "aqua_rat_15245": 0.7088143825531006, "aqua_rat_74262": 0.708847165107727, "aqua_rat_76556": 0.7088944315910339, "aqua_rat_63109": 0.7088978290557861, "aqua_rat_52342": 0.7089057564735413, "aqua_rat_52866": 0.7091492414474487, "aqua_rat_50687": 0.7091597318649292, "aqua_rat_50869": 0.7091914415359497, "aqua_rat_75260": 0.7093544602394104, "aqua_rat_71764": 0.7094811201095581, "aqua_rat_19025": 0.7095008492469788, "aqua_rat_83838": 0.7095668911933899, "aqua_rat_80531": 0.709568977355957, "aqua_rat_5839": 0.7096291780471802, "math_test_counting_and_probability_1081": 0.7096372842788696, "aqua_rat_9720": 0.7097043991088867, "aqua_rat_62566": 0.7099432349205017, "camel_38550": 0.710017740726471, "aqua_rat_38197": 0.7103365659713745, "aqua_rat_41967": 0.7104624509811401, "aqua_rat_20609": 0.7104864120483398, "aqua_rat_9727": 0.7105422616004944, "aqua_rat_36934": 0.710644543170929, "aqua_rat_2962": 0.71073317527771, "aqua_rat_9062": 0.7107577323913574, "aqua_rat_37116": 0.7109506130218506, "aqua_rat_48187": 0.7109929919242859, "aqua_rat_21179": 0.7110564708709717, "math_train_prealgebra_1720": 0.7111148834228516, "aqua_rat_29948": 0.7112037539482117, "math_test_counting_and_probability_38": 0.711363673210144, "aqua_rat_28558": 0.7113945484161377, "aqua_rat_56019": 0.7114484906196594, "aqua_rat_64118": 0.7114669680595398, "aqua_rat_7564": 0.7115103602409363, "aqua_rat_11087": 0.7116842269897461, "aqua_rat_68736": 0.7117390036582947, "aqua_rat_26130": 0.7117661237716675, "aqua_rat_3691": 0.7118260860443115, "aqua_rat_63677": 0.7119119167327881, "aqua_rat_71566": 0.7119954824447632, "math_test_counting_and_probability_1052": 0.7121899724006653, "aqua_rat_70796": 0.712253987789154, "aqua_rat_26378": 0.7123128771781921, "aqua_rat_69842": 0.7124409079551697, "aqua_rat_21868": 0.7124454975128174, "aqua_rat_73050": 0.7125586271286011, "aqua_rat_62784": 0.7126117944717407, "aqua_rat_55380": 0.7127283811569214, "aqua_rat_6636": 0.7127642631530762, "aqua_rat_42196": 0.7127768993377686, "aqua_rat_26294": 0.7129268646240234, "aqua_rat_23405": 0.7129581570625305, "aqua_rat_46999": 0.7130157351493835, "aqua_rat_13786": 0.7130653858184814, "aqua_rat_61836": 0.7131028771400452, "camel_19957": 0.7133665084838867, "aqua_rat_54367": 0.7135719656944275, "aqua_rat_87110": 0.7136008739471436, "aqua_rat_62395": 0.7136716246604919, "aqua_rat_62961": 0.713718056678772, "aqua_rat_79638": 0.7138097882270813, "aqua_rat_26482": 0.7139098048210144, "aqua_rat_85320": 0.7139564156532288, "aqua_rat_30581": 0.7140448093414307, "aqua_rat_5729": 0.7142605185508728, "aqua_rat_17116": 0.714408278465271, "aqua_rat_53423": 0.7144244909286499, "aqua_rat_53443": 0.7145677208900452, "aqua_rat_10808": 0.7146077752113342, "aqua_rat_21785": 0.7150058150291443, "aqua_rat_24032": 0.7159819006919861, "aqua_rat_55263": 0.7161957025527954, "aqua_rat_69610": 0.7164816856384277, "aqua_rat_65989": 0.7169349789619446, "math_train_prealgebra_351": 0.7169416546821594, "math_test_prealgebra_1572": 0.7172683477401733, "aqua_rat_31473": 0.7175440788269043, "math_test_counting_and_probability_378": 0.7175753712654114, "aqua_rat_23141": 0.7179133892059326, "aqua_rat_44454": 0.7183016538619995, "aqua_rat_36803": 0.718551754951477, "aqua_rat_68946": 0.7190424799919128, "aqua_rat_12408": 0.7191329002380371, "math_train_counting_and_probability_22": 0.7192806601524353, "aqua_rat_39088": 0.7193307280540466, "math_test_counting_and_probability_159": 0.719362199306488, "aqua_rat_62238": 0.7194657325744629, "aqua_rat_351": 0.7195083498954773, "math_train_counting_and_probability_797": 0.7195091843605042, "aqua_rat_59912": 0.7196164727210999, "aqua_rat_3702": 0.7196636199951172, "math_train_counting_and_probability_749": 0.7198513150215149, "aqua_rat_60476": 0.7200641632080078, "math_train_counting_and_probability_466": 0.7204130291938782, "math_train_prealgebra_158": 0.7206880450248718, "aqua_rat_34628": 0.7209951281547546, "aqua_rat_77042": 0.7210787534713745, "aqua_rat_27920": 0.7214781045913696, "aqua_rat_14": 0.7223381400108337, "aqua_rat_38586": 0.7228522896766663, "aqua_rat_2574": 0.723274290561676, "aqua_rat_29967": 0.7234830856323242, "aqua_rat_3870": 0.72353196144104, "aqua_rat_32829": 0.7235907316207886, "aqua_rat_797": 0.723764955997467, "math_train_counting_and_probability_831": 0.7242693305015564, "aqua_rat_30701": 0.7247805595397949, "aqua_rat_13247": 0.7251015305519104, "aqua_rat_81312": 0.7254427075386047, "aqua_rat_6563": 0.7255312204360962, "aqua_rat_34272": 0.7257767915725708, "aqua_rat_14281": 0.7259766459465027, "aqua_rat_43496": 0.7261679172515869, "aqua_rat_68730": 0.7262645363807678, "aqua_rat_72237": 0.7263963222503662, "aqua_rat_77763": 0.7264716029167175, "aqua_rat_84091": 0.726493775844574, "aqua_rat_47326": 0.7266049385070801, "aqua_rat_56829": 0.7267137169837952, "aqua_rat_14817": 0.7276983261108398, "aqua_rat_16904": 0.728400707244873, "aqua_rat_51466": 0.7286328673362732, "aqua_rat_35588": 0.7287085056304932, "aqua_rat_9085": 0.7288353443145752, "math_test_counting_and_probability_623": 0.7300797700881958, "aqua_rat_48706": 0.7305896282196045, "aqua_rat_65738": 0.7320300340652466, "aqua_rat_22747": 0.7321869134902954, "math_train_counting_and_probability_720": 0.7332350611686707, "aqua_rat_71410": 0.7334816455841064, "math_test_counting_and_probability_1046": 0.7339578866958618, "aqua_rat_26470": 0.7360361814498901, "aqua_rat_67804": 0.7363141179084778, "aqua_rat_54776": 0.7366389036178589, "aqua_rat_48109": 0.7398439645767212, "aqua_rat_38901": 0.7408571839332581}, "TheoremQA_jianyu_xu/Graph_2.json": {"camel_23794": 0, "camel_22426": 0, "camel_21116": 0, "camel_22405": 0, "camel_22445": 0, "camel_22362": 0, "camel_23966": 0, "camel_21062": 0, "camel_23187": 0, "camel_22407": 0, "camel_22447": 0, "camel_23153": 0, "camel_22327": 0, "camel_22370": 0, "camel_22441": 0, "camel_23137": 0, "camel_22824": 0, "camel_22664": 0, "camel_23358": 0, "camel_22916": 0, "camel_23994": 0, "camel_21107": 0, "camel_22334": 0, "camel_22444": 0, "camel_22823": 0, "camel_22439": 0, "camel_23322": 0, "camel_23975": 0, "camel_22922": 0, "camel_22437": 0, "camel_23108": 0, "camel_23175": 0, "camel_23364": 0, "camel_23123": 0, "camel_23168": 0, "camel_23128": 0, "camel_23342": 0, "camel_23195": 0, "camel_23119": 0, "camel_21106": 0, "camel_23995": 0, "camel_22413": 0, "camel_22412": 0, "camel_23199": 0, "camel_23430": 0, "camel_21133": 0, "camel_22333": 0, "camel_23424": 0, "camel_22430": 0, "camel_22473": 0, "camel_22469": 0, "camel_22887": 0, "camel_21100": 0, "camel_22853": 0, "camel_23155": 0, "camel_22061": 0, "camel_23159": 0, "camel_23427": 0, "camel_22456": 0, "camel_22415": 0, "camel_23180": 0, "camel_23348": 0, "camel_21078": 0, "camel_22432": 0, "camel_22450": 0, "camel_23425": 0, "camel_22423": 0, "camel_22451": 0, "camel_21083": 0, "camel_23317": 0, "camel_23191": 0, "camel_23573": 0, "camel_22453": 0, "camel_23145": 0, "camel_22389": 0, "camel_23951": 0, "camel_23954": 0, "camel_23968": 0, "camel_22477": 0, "camel_23147": 0, "camel_23382": 0, "camel_23163": 0, "camel_22866": 0, "camel_23151": 0, "camel_23172": 0, "camel_22838": 0, "camel_22471": 0, "camel_23164": 0, "camel_23423": 0, "camel_23974": 0, "camel_22352": 0, "camel_23181": 0, "camel_22862": 0, "camel_23941": 0, "camel_22937": 0, "camel_23161": 0, "camel_23372": 0, "camel_22808": 0, "camel_22424": 0, "camel_21047": 0, "camel_23284": 0, "camel_23312": 0, "camel_22391": 0, "camel_23965": 0, "camel_23196": 0, "camel_23060": 0, "camel_22912": 0, "camel_23135": 0, "camel_23391": 0, "camel_22476": 0, "camel_22373": 0, "camel_22863": 0, "camel_23114": 0, "camel_23154": 0, "camel_22422": 0, "camel_22949": 0, "camel_21072": 0, "camel_22435": 0, "camel_22443": 0, "camel_21059": 0, "camel_22478": 0, "camel_23292": 0, "camel_23165": 0, "camel_22331": 0, "camel_23999": 0, "camel_23944": 0, "camel_23400": 0, "camel_22411": 0, "camel_23144": 0, "camel_21103": 0, "camel_21063": 0, "camel_21084": 0, "camel_21051": 0, "camel_23934": 0, "camel_23150": 0, "camel_22458": 0, "camel_22457": 0, "camel_21064": 0, "camel_22464": 0, "camel_22452": 0, "camel_23183": 0, "camel_23403": 0, "camel_23328": 0, "camel_21817": 0, "camel_21087": 0, "camel_23189": 0, "camel_23943": 0, "camel_23307": 0, "camel_23176": 0, "camel_23198": 0, "camel_22418": 0, "camel_23174": 0, "camel_23122": 0, "camel_23158": 0, "camel_23173": 0, "camel_22867": 0, "camel_23156": 0, "camel_23393": 0, "camel_23945": 0, "camel_23369": 0, "camel_23923": 0, "camel_23177": 0, "camel_22454": 0, "camel_23977": 0, "camel_23932": 0, "camel_21108": 0, "camel_23162": 0, "camel_23126": 0, "camel_22393": 0, "camel_23432": 0, "camel_23166": 0, "camel_23948": 0, "camel_23193": 0, "camel_21804": 0, "camel_21098": 0, "camel_23946": 0, "camel_23179": 0, "camel_23993": 0, "camel_23986": 0, "camel_21764": 0, "aqua_rat_77006": 0.7455347180366516, "aqua_rat_64683": 0.7455579042434692, "aqua_rat_23955": 0.746715784072876, "aqua_rat_10797": 0.7472283840179443, "aqua_rat_7562": 0.7475310564041138, "aqua_rat_44895": 0.7488128542900085, "aqua_rat_26201": 0.7535492777824402, "camel_36749": 0.7553384304046631, "aqua_rat_43370": 0.7569220662117004, "aqua_rat_28685": 0.7610061764717102, "aqua_rat_38901": 0.7699725031852722, "aqua_rat_54929": 0.7709558010101318, "aqua_rat_70645": 0.7794578075408936, "aqua_rat_76009": 0.7807609438896179, "aqua_rat_44831": 0.7811290621757507, "aqua_rat_40504": 0.7847215533256531, "aqua_rat_25794": 0.7859290242195129, "math_train_prealgebra_350": 0.792071521282196, "aqua_rat_36545": 0.7968725562095642, "camel_19957": 0.812242329120636}, "TheoremQA_tonyxia/euler-graph2.json": {"camel_23849": 0, "camel_23902": 0, "camel_23881": 0, "camel_22636": 0, "camel_22564": 0, "camel_20780": 0, "camel_23868": 0, "camel_23890": 0, "camel_23918": 0, "camel_23852": 0, "camel_23912": 0, "camel_23917": 0, "camel_23846": 0, "camel_22632": 0, "camel_23919": 0, "camel_22635": 0, "camel_23880": 0, "camel_23913": 0, "camel_22614": 0, "camel_23863": 0, "camel_23894": 0, "camel_22560": 0, "camel_22631": 0, "camel_23847": 0, "camel_23911": 0, "camel_22605": 0, "camel_22563": 0, "camel_23870": 0, "camel_23910": 0, "camel_23908": 0, "camel_23887": 0, "camel_23871": 0, "camel_23869": 0, "camel_22638": 0, "camel_22572": 0, "camel_23857": 0, "camel_22630": 0, "camel_23874": 0, "camel_23864": 0, "camel_22588": 0, "camel_22607": 0, "camel_22561": 0, "camel_23891": 0, "camel_23875": 0, "camel_22604": 0, "camel_22634": 0, "camel_23903": 0, "camel_23842": 0, "camel_22568": 0, "camel_23884": 0, "camel_22591": 0, "camel_23844": 0, "camel_22616": 0, "camel_22603": 0, "camel_22592": 0, "camel_23862": 0, "camel_22621": 0, "camel_23901": 0, "camel_22637": 0, "camel_22589": 0, "camel_22600": 0, "camel_23873": 0, "camel_22594": 0, "camel_22562": 0, "camel_22575": 0, "camel_22609": 0, "camel_23916": 0, "camel_22599": 0, "camel_22584": 0, "camel_23866": 0, "camel_22593": 0, "camel_23840": 0, "camel_23841": 0, "camel_23867": 0, "camel_22619": 0, "camel_22565": 0, "camel_23909": 0, "camel_23907": 0, "camel_23877": 0, "camel_23859": 0, "TheoremQA_tonyxia/euler-graph2.json": 0, "camel_22580": 0, "camel_22606": 0, "camel_22595": 0, "camel_22586": 0, "camel_22598": 0, "camel_22610": 0, "camel_23893": 0, "camel_22574": 0, "camel_23878": 0, "camel_23848": 0, "camel_23905": 0, "camel_23861": 0, "camel_22569": 0, "camel_23898": 0, "camel_22587": 0, "camel_22567": 0, "camel_22624": 0, "camel_22577": 0, "camel_22623": 0, "camel_22622": 0, "camel_22639": 0, "camel_22626": 0, "camel_22576": 0, "camel_22617": 0, "aqua_rat_60927": 0.7275799512863159, "gsm_rft_25274": 0.7278671860694885, "camel_18706": 0.7282924056053162, "camel_18589": 0.7283215522766113, "camel_19921": 0.7292604446411133, "camel_18571": 0.7293773293495178, "aqua_rat_35489": 0.7295622229576111, "camel_18700": 0.7297987937927246, "camel_18656": 0.7311135530471802, "math_test_prealgebra_1940": 0.7312433123588562, "camel_18619": 0.7317380905151367, "camel_18591": 0.7319400310516357, "aqua_rat_87384": 0.7324032783508301, "camel_18595": 0.7332086563110352, "aqua_rat_46775": 0.7333610653877258, "camel_19402": 0.7343169450759888, "aqua_rat_44305": 0.734542965888977, "camel_18680": 0.7346377968788147, "camel_18623": 0.7351575493812561, "gsm_rft_32651": 0.7367590665817261, "camel_18676": 0.7385992407798767, "camel_18578": 0.738609254360199, "aqua_rat_76281": 0.7387564778327942, "camel_18621": 0.7389274835586548, "camel_18618": 0.7391754388809204, "aqua_rat_50843": 0.7407172918319702, "camel_18642": 0.7411094307899475, "camel_18664": 0.7420637607574463, "camel_18566": 0.7423660755157471, "math_test_geometry_188": 0.7445206642150879, "camel_19825": 0.7455991506576538, "camel_18873": 0.7458618879318237, "gsm_train_15934": 0.7468277812004089, "gsm_rft_4437": 0.7468277812004089, "camel_18606": 0.7477683424949646, "camel_18693": 0.7479474544525146, "camel_18675": 0.7484625577926636, "camel_18639": 0.7518237829208374, "camel_19956": 0.7545396685600281, "camel_18638": 0.7547780871391296, "gsm_rft_4179": 0.7556889057159424, "camel_18877": 0.760655403137207, "camel_18598": 0.7609522342681885, "camel_18634": 0.7612862586975098, "camel_18636": 0.7625120282173157, "camel_18674": 0.7645705938339233, "camel_18831": 0.7653728127479553, "math_train_geometry_821": 0.7653753161430359, "camel_18624": 0.7701592445373535, "camel_18698": 0.7705017328262329, "camel_18626": 0.7713584899902344, "math_test_geometry_154": 0.7729116082191467, "camel_18662": 0.7742130160331726, "camel_19970": 0.7750659584999084, "camel_18569": 0.7755790948867798, "camel_18711": 0.778597891330719, "camel_19812": 0.7795556783676147, "math_test_geometry_713": 0.7810946702957153, "math_test_geometry_217": 0.7813184857368469, "math_test_counting_and_probability_385": 0.7813414931297302, "TheoremQA_tonyxia/maxplanar3.json": 0.7865920662879944, "camel_18644": 0.787602961063385, "TheoremQA_tonyxia/maxplanar1.json": 0.7878175973892212, "camel_18692": 0.7892633676528931, "aqua_rat_15736": 0.7895739078521729, "camel_18715": 0.7934327125549316, "math_train_geometry_6085": 0.7941820621490479, "camel_18643": 0.7972403764724731, "math_train_geometry_758": 0.7974750995635986, "camel_18717": 0.7988882064819336, "aqua_rat_49777": 0.8011534214019775, "camel_18964": 0.8021812438964844, "camel_18608": 0.8023511171340942, "camel_18658": 0.8032196164131165, "camel_18659": 0.8042850494384766, "TheoremQA_tonyxia/euler-graph3.json": 0.8066965937614441, "camel_18627": 0.8076925873756409, "aqua_rat_16933": 0.8089978694915771, "camel_19723": 0.8100122809410095, "camel_18673": 0.8115556836128235, "camel_18672": 0.8118565678596497, "aqua_rat_551": 0.8120219707489014, "aqua_rat_72587": 0.8129794597625732, "math_train_prealgebra_519": 0.8141276836395264, "aqua_rat_23171": 0.8151896595954895, "camel_18701": 0.8154782056808472, "camel_18652": 0.8177290558815002, "camel_18688": 0.8184379935264587, "camel_18677": 0.8235229849815369, "camel_18686": 0.8255678415298462, "camel_18699": 0.8350265026092529, "camel_19888": 0.8361929655075073, "camel_18679": 0.8425888419151306, "camel_19741": 0.8455894589424133, "math_train_geometry_6025": 0.848691463470459}, "TheoremQA_jianyu_xu/Stirling_number_first_kind_6.json": {"camel_20359": 0, "camel_21232": 0, "camel_20980": 0, "camel_21112": 0, "camel_21581": 0, "camel_20971": 0, "camel_21004": 0, "camel_20733": 0, "camel_20663": 0, "camel_21260": 0, "camel_21228": 0, "TheoremQA_jianyu_xu/Stirling_number_first_kind_6.json": 0, "camel_20967": 0, "camel_21085": 0, "camel_20992": 0, "camel_21018": 0, "aqua_rat_3831": 0.8509822487831116, "aqua_rat_34500": 0.8510655760765076, "aqua_rat_56235": 0.8511481285095215, "aqua_rat_52342": 0.8513084650039673, "aqua_rat_72606": 0.8523357510566711, "math_test_counting_and_probability_134": 0.8526134490966797, "aqua_rat_87133": 0.8526881337165833, "TheoremQA_jianyu_xu/Stirling_number_first_kind_5.json": 0.8527776002883911, "aqua_rat_56279": 0.852820634841919, "aqua_rat_69626": 0.8530194759368896, "aqua_rat_24589": 0.8530200123786926, "aqua_rat_1243": 0.8532071113586426, "aqua_rat_25873": 0.8532460927963257, "aqua_rat_5839": 0.8534889817237854, "aqua_rat_81586": 0.8538235425949097, "aqua_rat_56084": 0.8540822863578796, "aqua_rat_57448": 0.8542057871818542, "aqua_rat_59877": 0.8546050190925598, "aqua_rat_9085": 0.8550112247467041, "aqua_rat_75048": 0.8555672764778137, "aqua_rat_1211": 0.856193482875824, "aqua_rat_70746": 0.8563854694366455, "aqua_rat_65242": 0.8565636277198792, "aqua_rat_43248": 0.8566504716873169, "aqua_rat_14194": 0.8569244742393494, "aqua_rat_79446": 0.8570980429649353, "math_train_counting_and_probability_5127": 0.8572213053703308, "aqua_rat_77386": 0.8574762940406799, "aqua_rat_66645": 0.8577463030815125, "aqua_rat_71707": 0.8580007553100586, "aqua_rat_48706": 0.8581646084785461, "aqua_rat_20389": 0.858475387096405, "aqua_rat_797": 0.8585292100906372, "aqua_rat_51466": 0.858855664730072, "aqua_rat_66893": 0.8588619828224182, "aqua_rat_35620": 0.860360860824585, "aqua_rat_75334": 0.8607320785522461, "aqua_rat_8391": 0.8610450625419617, "aqua_rat_51443": 0.861090898513794, "aqua_rat_58987": 0.8611510396003723, "aqua_rat_34628": 0.8611530065536499, "aqua_rat_40391": 0.8612005114555359, "aqua_rat_55888": 0.8615154027938843, "aqua_rat_28522": 0.8618295788764954, "aqua_rat_32302": 0.8619750142097473, "math_train_counting_and_probability_237": 0.8621219992637634, "aqua_rat_65965": 0.8623135685920715, "aqua_rat_74862": 0.8624645471572876, "aqua_rat_37018": 0.8627787828445435, "aqua_rat_73729": 0.8627830147743225, "aqua_rat_47342": 0.8632991313934326, "aqua_rat_7564": 0.8638736009597778, "aqua_rat_80989": 0.8641064763069153, "aqua_rat_35925": 0.864345908164978, "aqua_rat_54394": 0.8647820353507996, "aqua_rat_16904": 0.8649311065673828, "aqua_rat_44513": 0.8650439977645874, "aqua_rat_32832": 0.8654447197914124, "aqua_rat_11114": 0.8654947876930237, "math_train_counting_and_probability_957": 0.8656001091003418, "aqua_rat_39088": 0.865656852722168, "aqua_rat_21315": 0.8662557601928711, "aqua_rat_62842": 0.866571843624115, "aqua_rat_12474": 0.866981565952301, "aqua_rat_39095": 0.8670294880867004, "aqua_rat_26470": 0.8671356439590454, "aqua_rat_33554": 0.8672202229499817, "aqua_rat_5511": 0.867595911026001, "aqua_rat_72264": 0.8677952289581299, "aqua_rat_34278": 0.8681166768074036, "aqua_rat_68044": 0.8684370517730713, "math_test_counting_and_probability_159": 0.8686586618423462, "aqua_rat_74134": 0.8691412806510925, "math_train_counting_and_probability_487": 0.8694650530815125, "aqua_rat_15635": 0.8695205450057983, "aqua_rat_78867": 0.8695969581604004, "aqua_rat_35816": 0.8697584271430969, "aqua_rat_50417": 0.869774341583252, "aqua_rat_58659": 0.8700738549232483, "aqua_rat_76556": 0.8701342940330505, "aqua_rat_65743": 0.8701716065406799, "aqua_rat_26378": 0.8702676892280579, "aqua_rat_81651": 0.8705560564994812, "aqua_rat_68341": 0.8709446787834167, "math_test_counting_and_probability_623": 0.8710867762565613, "aqua_rat_25491": 0.8713374137878418, "aqua_rat_69466": 0.8714979290962219, "math_train_counting_and_probability_466": 0.8715341687202454, "aqua_rat_70809": 0.8716146349906921, "aqua_rat_22061": 0.871903657913208, "aqua_rat_34094": 0.872084379196167, "aqua_rat_41912": 0.8723427653312683, "aqua_rat_126": 0.8726182579994202, "aqua_rat_70049": 0.8726301789283752, "aqua_rat_51288": 0.8728085160255432, "math_train_counting_and_probability_646": 0.8732120394706726, "aqua_rat_50865": 0.8735759258270264, "aqua_rat_68644": 0.8744009733200073, "math_test_counting_and_probability_238": 0.8744195699691772, "aqua_rat_5282": 0.8753031492233276, "aqua_rat_79173": 0.8761118650436401, "aqua_rat_53443": 0.8765178918838501, "aqua_rat_11818": 0.8766355514526367, "aqua_rat_27882": 0.8767192959785461, "aqua_rat_11605": 0.8767374753952026, "aqua_rat_49516": 0.876933217048645, "aqua_rat_49928": 0.8773100972175598, "aqua_rat_37078": 0.877455472946167, "aqua_rat_15263": 0.8775888085365295, "aqua_rat_55411": 0.8776862025260925, "aqua_rat_15999": 0.8782176375389099, "math_test_counting_and_probability_653": 0.8783309459686279, "aqua_rat_55136": 0.8786870241165161, "aqua_rat_10748": 0.8792834281921387, "math_train_counting_and_probability_76": 0.8801004886627197, "aqua_rat_43397": 0.8802905678749084, "aqua_rat_13247": 0.8807902932167053, "aqua_rat_77200": 0.8812002539634705, "math_test_counting_and_probability_477": 0.8815025687217712, "aqua_rat_70944": 0.8827866911888123, "aqua_rat_62617": 0.8830058574676514, "aqua_rat_10077": 0.8831326365470886, "math_test_counting_and_probability_215": 0.883132815361023, "aqua_rat_43496": 0.88433438539505, "aqua_rat_39587": 0.8843586444854736, "math_test_counting_and_probability_796": 0.8847749829292297, "math_test_counting_and_probability_103": 0.8849563598632812, "aqua_rat_35588": 0.8859262466430664, "aqua_rat_58183": 0.8868196606636047, "aqua_rat_18622": 0.8873496055603027, "aqua_rat_6563": 0.8874857425689697, "aqua_rat_7949": 0.8875381946563721, "aqua_rat_72490": 0.8877683281898499, "aqua_rat_44714": 0.888064444065094, "aqua_rat_67395": 0.8881707787513733, "aqua_rat_85657": 0.8882760405540466, "aqua_rat_83431": 0.8887957334518433, "aqua_rat_49470": 0.8893235921859741, "aqua_rat_72930": 0.8893868327140808, "aqua_rat_79164": 0.8894545435905457, "aqua_rat_27360": 0.8894758224487305, "aqua_rat_22143": 0.8897084593772888, "aqua_rat_78055": 0.8897632360458374, "aqua_rat_9008": 0.8898738026618958, "aqua_rat_17277": 0.8899937272071838, "aqua_rat_76078": 0.890069842338562, "math_test_counting_and_probability_378": 0.8902014493942261, "aqua_rat_73694": 0.8908704519271851, "aqua_rat_20745": 0.8909509778022766, "aqua_rat_47815": 0.89116370677948, "aqua_rat_78326": 0.8911854028701782, "aqua_rat_63326": 0.8917014002799988, "aqua_rat_8052": 0.8917257189750671, "aqua_rat_34175": 0.8919739127159119, "aqua_rat_57577": 0.892274022102356, "aqua_rat_39020": 0.8933058977127075, "aqua_rat_48525": 0.8936272859573364, "aqua_rat_26444": 0.8940582871437073, "aqua_rat_12909": 0.8940942883491516, "aqua_rat_28375": 0.8943822383880615, "aqua_rat_28558": 0.8959344625473022, "aqua_rat_82470": 0.8965787887573242, "aqua_rat_38197": 0.8966436982154846, "aqua_rat_83838": 0.8968446254730225, "aqua_rat_59796": 0.8968616724014282, "aqua_rat_88199": 0.8970987200737, "aqua_rat_84091": 0.8976449370384216, "aqua_rat_23742": 0.8979712128639221, "aqua_rat_23659": 0.8990658521652222, "aqua_rat_5884": 0.8993433117866516, "aqua_rat_49652": 0.89955073595047, "aqua_rat_8977": 0.9000141620635986, "aqua_rat_58284": 0.9013746976852417, "math_test_counting_and_probability_1047": 0.9022490978240967, "aqua_rat_38881": 0.9034123420715332, "aqua_rat_26482": 0.9063908457756042, "aqua_rat_12094": 0.9064404368400574, "aqua_rat_62784": 0.9072004556655884, "aqua_rat_15245": 0.9085144400596619, "aqua_rat_78595": 0.9086035490036011, "aqua_rat_75260": 0.9088277220726013, "aqua_rat_54745": 0.9151397347450256, "aqua_rat_47629": 0.915715754032135, "aqua_rat_74262": 0.9178189635276794}, "TheoremQA_xueguangma/present_value_1.json": {"camel_36759": 0.7893950939178467, "aqua_rat_20758": 0.7895037531852722, "aqua_rat_86342": 0.7896578907966614, "aqua_rat_25162": 0.7896618247032166, "aqua_rat_41963": 0.7898632884025574, "gsm_rft_23662": 0.78987717628479, "aqua_rat_10904": 0.7899712920188904, "math_train_algebra_2324": 0.7900691032409668, "aqua_rat_31350": 0.7901390790939331, "aqua_rat_84549": 0.7901862859725952, "aqua_rat_69547": 0.7902626395225525, "aqua_rat_412": 0.7904855012893677, "aqua_rat_13817": 0.7905067205429077, "gsm_rft_6559": 0.7905240654945374, "gsm_rft_8879": 0.7905553579330444, "math_test_algebra_311": 0.7906062006950378, "aqua_rat_49082": 0.7908740043640137, "gsm_rft_12757": 0.7908844351768494, "gsm_rft_3485": 0.7908844351768494, "gsm_rft_9871": 0.7908844351768494, "gsm_train_6379": 0.7908844351768494, "gsm_rft_17539": 0.7909632921218872, "aqua_rat_79904": 0.7912418246269226, "gsm_train_35597": 0.791242241859436, "gsm_rft_27795": 0.791242241859436, "aqua_rat_12597": 0.7912829518318176, "gsm_rft_12956": 0.7913252115249634, "gsm_rft_32563": 0.7914345860481262, "aqua_rat_24068": 0.7914828658103943, "aqua_rat_57458": 0.7916181683540344, "gsm_rft_29634": 0.791681706905365, "aqua_rat_88174": 0.7916867733001709, "aqua_rat_32864": 0.791702389717102, "aqua_rat_17663": 0.7917191982269287, "aqua_rat_44517": 0.7919407486915588, "aqua_rat_79047": 0.7920297980308533, "aqua_rat_51796": 0.7920441627502441, "aqua_rat_6703": 0.7920891046524048, "gsm_rft_4473": 0.7921236753463745, "gsm_rft_5669": 0.7921532988548279, "aqua_rat_39422": 0.7922168374061584, "aqua_rat_72687": 0.7924922704696655, "aqua_rat_28984": 0.792610764503479, "gsm_rft_14102": 0.792670488357544, "gsm_train_11462": 0.792670488357544, "gsm_rft_11620": 0.7927225232124329, "aqua_rat_50660": 0.7927950620651245, "aqua_rat_68636": 0.7928741574287415, "aqua_rat_4236": 0.7930271625518799, "math_test_algebra_337": 0.793121874332428, "math_test_algebra_155": 0.7934948801994324, "gsm_train_25622": 0.7936537861824036, "aqua_rat_37269": 0.7937751412391663, "aqua_rat_2257": 0.7938470840454102, "aqua_rat_78533": 0.7942491769790649, "aqua_rat_21334": 0.7945520877838135, "math_train_algebra_667": 0.7947760820388794, "aqua_rat_7674": 0.794872522354126, "aqua_rat_56852": 0.7949616312980652, "aqua_rat_26976": 0.7951031923294067, "aqua_rat_30386": 0.7951080203056335, "aqua_rat_81302": 0.7952357530593872, "aqua_rat_33430": 0.7952380180358887, "aqua_rat_58298": 0.7952523231506348, "aqua_rat_21866": 0.7954689860343933, "gsm_rft_25658": 0.7955082058906555, "aqua_rat_69273": 0.7955778241157532, "gsm_rft_10656": 0.7957284450531006, "aqua_rat_21814": 0.7957465052604675, "aqua_rat_82565": 0.7957839369773865, "aqua_rat_42017": 0.7958259582519531, "aqua_rat_26425": 0.7958966493606567, "aqua_rat_84309": 0.795961320400238, "gsm_rft_24617": 0.7963259220123291, "aqua_rat_75047": 0.7964553833007812, "aqua_rat_63322": 0.7967826128005981, "gsm_rft_8179": 0.7969223856925964, "aqua_rat_57943": 0.7970274686813354, "gsm_rft_19092": 0.7972212433815002, "gsm_train_26849": 0.7972212433815002, "aqua_rat_6679": 0.7974525690078735, "aqua_rat_65963": 0.7975627183914185, "math_test_algebra_1862": 0.7976294755935669, "aqua_rat_59829": 0.7980969548225403, "aqua_rat_63070": 0.7981046438217163, "aqua_rat_36240": 0.7982064485549927, "aqua_rat_5641": 0.7982287406921387, "aqua_rat_38068": 0.7983039021492004, "aqua_rat_61585": 0.7983192205429077, "aqua_rat_86835": 0.7986446022987366, "aqua_rat_66927": 0.7989293932914734, "aqua_rat_60181": 0.799176812171936, "aqua_rat_7537": 0.7993362545967102, "aqua_rat_20423": 0.7994384169578552, "aqua_rat_86432": 0.7995165586471558, "aqua_rat_869": 0.7995193004608154, "gsm_rft_17795": 0.7995931506156921, "aqua_rat_38785": 0.8000244498252869, "aqua_rat_49908": 0.8004833459854126, "aqua_rat_18368": 0.8005646467208862, "gsm_rft_33831": 0.8006660342216492, "aqua_rat_48494": 0.8008965849876404, "gsm_rft_28176": 0.8011611104011536, "gsm_rft_27047": 0.8011832237243652, "gsm_rft_22915": 0.8012109398841858, "aqua_rat_32852": 0.8012644052505493, "aqua_rat_40411": 0.8013230562210083, "gsm_rft_16633": 0.8014633655548096, "aqua_rat_37258": 0.8016449213027954, "aqua_rat_10582": 0.8018361330032349, "gsm_rft_5849": 0.8019498586654663, "aqua_rat_15337": 0.8023467659950256, "aqua_rat_5231": 0.8027183413505554, "aqua_rat_11679": 0.8028104305267334, "aqua_rat_78121": 0.8031365275382996, "aqua_rat_87589": 0.8032775521278381, "aqua_rat_27053": 0.8033803105354309, "aqua_rat_735": 0.8035622835159302, "aqua_rat_54028": 0.8038877844810486, "aqua_rat_81805": 0.8040564060211182, "math_test_algebra_608": 0.8042418360710144, "gsm_rft_9932": 0.8054810166358948, "aqua_rat_51100": 0.805646538734436, "aqua_rat_5907": 0.8059207201004028, "aqua_rat_68287": 0.8059363961219788, "aqua_rat_64664": 0.8060866594314575, "math_test_algebra_2626": 0.8062141537666321, "aqua_rat_53421": 0.8064956665039062, "aqua_rat_72794": 0.8065103888511658, "camel_37735": 0.8066436052322388, "aqua_rat_32958": 0.8067377209663391, "aqua_rat_68014": 0.8069368004798889, "aqua_rat_29170": 0.8072299361228943, "aqua_rat_32321": 0.8073327541351318, "aqua_rat_83234": 0.8075384497642517, "aqua_rat_19480": 0.8078790903091431, "math_test_algebra_990": 0.8081378936767578, "aqua_rat_46552": 0.8083354234695435, "aqua_rat_24347": 0.8086524605751038, "aqua_rat_37382": 0.8088293671607971, "aqua_rat_3536": 0.8090412616729736, "gsm_rft_7180": 0.8091027736663818, "gsm_train_5941": 0.8091027736663818, "aqua_rat_27039": 0.8092330694198608, "math_train_algebra_1277": 0.8096007704734802, "aqua_rat_78349": 0.809765636920929, "aqua_rat_72933": 0.8100792169570923, "aqua_rat_69526": 0.8109081387519836, "aqua_rat_30717": 0.8111594319343567, "gsm_rft_12217": 0.811360239982605, "aqua_rat_79979": 0.8115297555923462, "aqua_rat_59668": 0.8115975260734558, "aqua_rat_13797": 0.8119760751724243, "aqua_rat_53504": 0.8122345805168152, "aqua_rat_26339": 0.8125342130661011, "gsm_rft_5946": 0.8125534057617188, "math_train_algebra_957": 0.8130975961685181, "aqua_rat_88960": 0.8133373856544495, "aqua_rat_28282": 0.813342273235321, "gsm_train_30707": 0.8134676814079285, "gsm_rft_20456": 0.8135056495666504, "gsm_rft_22572": 0.813754677772522, "aqua_rat_67841": 0.8138734698295593, "aqua_rat_71239": 0.8160246014595032, "aqua_rat_73390": 0.8160490393638611, "aqua_rat_255": 0.8163399696350098, "gsm_rft_6203": 0.8164041042327881, "aqua_rat_66371": 0.8173446655273438, "aqua_rat_44615": 0.8177562355995178, "aqua_rat_28662": 0.818335235118866, "aqua_rat_86234": 0.820146918296814, "aqua_rat_59403": 0.8205888271331787, "aqua_rat_67698": 0.8214489817619324, "aqua_rat_1115": 0.8219301104545593, "aqua_rat_34332": 0.8226868510246277, "aqua_rat_87246": 0.8226925730705261, "aqua_rat_64914": 0.8227037787437439, "aqua_rat_29356": 0.8235621452331543, "aqua_rat_56718": 0.8237470388412476, "aqua_rat_52978": 0.8241910934448242, "aqua_rat_87884": 0.8242017030715942, "aqua_rat_73739": 0.8242624402046204, "aqua_rat_58694": 0.8244187831878662, "aqua_rat_33006": 0.8248200416564941, "aqua_rat_66298": 0.825664758682251, "aqua_rat_44549": 0.8259208798408508, "aqua_rat_70031": 0.8261949419975281, "aqua_rat_47773": 0.8269519209861755, "aqua_rat_75833": 0.8277128338813782, "math_train_algebra_369": 0.8281394839286804, "aqua_rat_33923": 0.8282880783081055, "aqua_rat_10990": 0.8283861875534058, "aqua_rat_83740": 0.8290300369262695, "aqua_rat_29321": 0.8297649025917053, "aqua_rat_50447": 0.830613911151886, "aqua_rat_70690": 0.8306154012680054, "aqua_rat_9965": 0.8306237459182739, "math_test_algebra_594": 0.8336148262023926, "math_train_algebra_940": 0.8447823524475098, "math_test_algebra_1611": 0.8500611782073975}, "TheoremQA_maxku/graphtheory4-vertexcover.json": {"camel_21163": 0, "camel_23407": 0, "camel_22861": 0, "camel_22168": 0, "camel_23383": 0, "camel_23425": 0, "camel_23816": 0, "camel_22223": 0, "camel_22800": 0, "camel_23435": 0, "camel_22777": 0, "camel_23404": 0, "camel_22873": 0, "camel_23182": 0, "camel_21122": 0, "camel_21124": 0, "camel_22825": 0, "camel_22890": 0, "camel_23423": 0, "camel_23162": 0, "camel_22820": 0, "camel_22737": 0, "camel_23159": 0, "camel_21044": 0, "camel_21156": 0, "camel_21178": 0, "camel_21188": 0, "camel_22355": 0, "camel_23767": 0, "camel_22729": 0, "camel_23190": 0, "camel_22335": 0, "camel_23148": 0, "camel_23192": 0, "camel_22791": 0, "camel_22345": 0, "camel_22862": 0, "camel_22849": 0, "camel_22329": 0, "camel_22875": 0, "camel_23807": 0, "camel_22191": 0, "camel_22810": 0, "camel_23126": 0, "camel_23129": 0, "camel_23161": 0, "camel_22858": 0, "camel_23393": 0, "camel_22182": 0, "camel_23418": 0, "camel_22752": 0, "camel_21130": 0, "camel_22753": 0, "camel_23825": 0, "camel_22375": 0, "camel_21175": 0, "camel_21182": 0, "camel_23157": 0, "camel_23389": 0, "camel_21135": 0, "camel_21137": 0, "camel_23391": 0, "camel_22835": 0, "camel_21161": 0, "camel_22396": 0, "camel_21181": 0, "camel_21197": 0, "camel_21157": 0, "camel_22210": 0, "camel_22812": 0, "camel_22763": 0, "camel_22870": 0, "camel_22728": 0, "camel_22920": 0, "camel_23174": 0, "camel_22867": 0, "camel_22379": 0, "camel_22837": 0, "camel_22780": 0, "camel_22328": 0, "camel_22334": 0, "camel_23146": 0, "camel_22743": 0, "camel_22734": 0, "camel_23166": 0, "camel_23382": 0, "camel_22783": 0, "camel_22765": 0, "camel_23438": 0, "camel_23398": 0, "camel_22727": 0, "camel_22767": 0, "camel_23399": 0, "camel_23414": 0, "camel_23144": 0, "camel_22808": 0, "camel_21129": 0, "camel_22793": 0, "camel_22393": 0, "camel_21180": 0, "camel_23416": 0, "camel_22356": 0, "camel_23141": 0, "camel_22179": 0, "camel_21107": 0, "camel_21083": 0, "camel_23395": 0, "camel_23189": 0, "camel_21132": 0, "camel_21186": 0, "camel_23400": 0, "camel_23397": 0, "camel_21113": 0, "camel_22792": 0, "camel_23165": 0, "camel_21198": 0, "camel_23196": 0, "camel_23172": 0, "camel_23367": 0, "camel_23374": 0, "camel_23363": 0, "camel_23372": 0, "camel_23430": 0, "camel_22692": 0, "camel_21133": 0, "camel_22117": 0, "camel_21194": 0, "camel_21784": 0, "camel_22746": 0, "camel_21173": 0, "camel_22859": 0, "camel_21152": 0, "camel_21193": 0, "camel_23422": 0, "camel_23977": 0, "camel_23150": 0, "camel_23362": 0, "camel_22818": 0, "camel_23427": 0, "camel_22176": 0, "camel_22347": 0, "camel_22397": 0, "camel_22761": 0, "camel_21190": 0, "camel_21185": 0, "camel_22204": 0, "camel_22384": 0, "camel_21187": 0, "camel_22369": 0, "camel_21170": 0, "camel_22838": 0, "camel_23770": 0, "camel_23789": 0, "camel_21179": 0, "camel_23381": 0, "camel_22778": 0, "camel_23424": 0, "camel_22188": 0, "camel_23409": 0, "camel_21172": 0, "camel_21162": 0, "camel_21057": 0, "camel_23403": 0, "camel_23128": 0, "camel_22724": 0, "camel_22218": 0, "camel_23158": 0, "camel_22377": 0, "camel_21123": 0, "camel_23135": 0, "camel_22363": 0, "camel_22863": 0, "camel_23164": 0, "camel_21145": 0, "camel_22721": 0, "camel_23134": 0, "camel_22215": 0, "camel_22388": 0, "camel_22185": 0, "camel_21116": 0, "camel_23410": 0, "camel_23432": 0, "camel_23369": 0, "camel_22799": 0, "camel_23364": 0, "camel_21176": 0, "camel_22170": 0, "math_train_prealgebra_350": 0.7970607876777649, "aqua_rat_64683": 0.8002995252609253, "aqua_rat_54929": 0.8008767366409302, "aqua_rat_83797": 0.8017557859420776, "aqua_rat_40504": 0.8031347393989563, "aqua_rat_76009": 0.8037009239196777, "aqua_rat_76903": 0.8037875890731812, "aqua_rat_77006": 0.8056173920631409, "aqua_rat_7562": 0.8059993982315063, "aqua_rat_10797": 0.8073540329933167, "aqua_rat_44831": 0.8081789612770081, "aqua_rat_25794": 0.8090395927429199, "aqua_rat_70645": 0.8101388812065125}, "TheoremQA_maxku/signalprocessing19-period.json": {"TheoremQA_maxku/signalprocessing19-period.json": 0, "gsm_rft_32203": 0.6721159219741821, "gsm_rft_31770": 0.6721341609954834, "gsm_train_800": 0.6721341609954834, "aqua_rat_55497": 0.6722798943519592, "gsm_train_29686": 0.6726799011230469, "gsm_rft_24420": 0.6726799011230469, "gsm_rft_6507": 0.6726964712142944, "aqua_rat_77909": 0.6727102398872375, "gsm_rft_21788": 0.672743022441864, "camel_29046": 0.6727601289749146, "camel_28857": 0.6729244589805603, "gsm_rft_2576": 0.6729742288589478, "gsm_rft_8266": 0.6729742288589478, "camel_29228": 0.6729772686958313, "camel_45809": 0.673061728477478, "camel_28759": 0.6730952262878418, "aqua_rat_683": 0.6732332706451416, "camel_37817": 0.6733447909355164, "aqua_rat_15905": 0.6735228896141052, "camel_44498": 0.6741712689399719, "aqua_rat_34026": 0.6742228865623474, "camel_29327": 0.6744094491004944, "camel_44728": 0.6744157671928406, "camel_45685": 0.6746688485145569, "camel_28386": 0.6748110055923462, "gsm_rft_30984": 0.6748244762420654, "camel_29937": 0.6749833822250366, "camel_29371": 0.6750902533531189, "camel_29346": 0.6752638220787048, "aqua_rat_80959": 0.6752792000770569, "aqua_rat_45126": 0.6752867102622986, "camel_44788": 0.6754510402679443, "camel_45314": 0.675610363483429, "camel_28461": 0.6756331920623779, "camel_8613": 0.6756957173347473, "camel_28433": 0.6757057905197144, "gsm_rft_18896": 0.6758390069007874, "gsm_train_23484": 0.6758390069007874, "gsm_rft_11073": 0.6761961579322815, "camel_29058": 0.6766113638877869, "camel_29088": 0.676665186882019, "camel_28802": 0.6766796708106995, "camel_44849": 0.6767126321792603, "camel_45713": 0.6767629981040955, "camel_45757": 0.6768103241920471, "gsm_rft_5868": 0.6768250465393066, "camel_29162": 0.6769309639930725, "aqua_rat_9358": 0.6772494912147522, "camel_44538": 0.6776244640350342, "camel_27835": 0.6776813268661499, "camel_28528": 0.6778239011764526, "camel_29173": 0.6778690814971924, "camel_44790": 0.6779155135154724, "aqua_rat_75568": 0.6780812740325928, "camel_44785": 0.6783844828605652, "camel_26497": 0.6784195303916931, "camel_45681": 0.678564727306366, "camel_44537": 0.6785761713981628, "camel_28441": 0.6787037253379822, "camel_29388": 0.678789496421814, "camel_44873": 0.6788666844367981, "camel_29184": 0.6789593696594238, "aqua_rat_50936": 0.6790435910224915, "camel_29302": 0.6791936159133911, "aqua_rat_23269": 0.6791945695877075, "aqua_rat_33141": 0.6792361736297607, "aqua_rat_63857": 0.6792722940444946, "aqua_rat_63802": 0.679311215877533, "camel_28329": 0.6799125075340271, "camel_45748": 0.6801109910011292, "aqua_rat_66793": 0.6806445717811584, "camel_37507": 0.680653989315033, "camel_45199": 0.6813060641288757, "camel_29060": 0.6813812851905823, "camel_29321": 0.6816269159317017, "camel_29987": 0.6817138195037842, "aqua_rat_48155": 0.6817391514778137, "camel_45712": 0.6821175217628479, "camel_28754": 0.6821416616439819, "aqua_rat_11220": 0.6823509335517883, "camel_44750": 0.6824899315834045, "camel_27797": 0.6825771331787109, "camel_28354": 0.6826475858688354, "camel_45939": 0.682695209980011, "camel_28430": 0.6828084588050842, "camel_28948": 0.6828605532646179, "camel_45700": 0.6828983426094055, "camel_44400": 0.6830863952636719, "aqua_rat_47200": 0.6833734512329102, "aqua_rat_77027": 0.683660626411438, "aqua_rat_39089": 0.6836894154548645, "camel_28821": 0.6839540004730225, "camel_45740": 0.6842747330665588, "camel_45710": 0.6843158006668091, "camel_28835": 0.6843467354774475, "camel_29155": 0.6844805479049683, "camel_29182": 0.684485137462616, "camel_29407": 0.6846945881843567, "camel_44411": 0.6847178339958191, "aqua_rat_60661": 0.6849614381790161, "camel_28736": 0.6851999163627625, "camel_30474": 0.6853345036506653, "aqua_rat_22859": 0.6855310797691345, "aqua_rat_36319": 0.6856619119644165, "aqua_rat_12229": 0.6857812404632568, "aqua_rat_14667": 0.6859034895896912, "camel_45676": 0.6859533190727234, "camel_29845": 0.686000406742096, "camel_28787": 0.6860194802284241, "camel_45722": 0.6861997842788696, "aqua_rat_18701": 0.6862104535102844, "camel_29154": 0.6863037943840027, "camel_29734": 0.6863561272621155, "camel_45736": 0.6866520643234253, "camel_28397": 0.6867839694023132, "camel_28385": 0.6870189905166626, "camel_45683": 0.6871508359909058, "aqua_rat_34688": 0.6877612471580505, "camel_28382": 0.6880119442939758, "camel_29611": 0.6881480813026428, "camel_45696": 0.6886013746261597, "camel_8574": 0.6891868710517883, "camel_28392": 0.6892611980438232, "camel_29373": 0.6892925500869751, "camel_44806": 0.6898438930511475, "camel_28395": 0.6898825764656067, "aqua_rat_59336": 0.6898831129074097, "camel_45745": 0.6900020837783813, "aqua_rat_86103": 0.6900807023048401, "camel_28407": 0.6901969909667969, "camel_28502": 0.690481960773468, "camel_29364": 0.6909144520759583, "camel_29429": 0.6910185813903809, "camel_45171": 0.6910533308982849, "camel_44459": 0.6910586953163147, "camel_44765": 0.6915798187255859, "camel_28838": 0.6919973492622375, "camel_17545": 0.6920806169509888, "camel_28321": 0.6927435398101807, "aqua_rat_60605": 0.6928703188896179, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.6935517191886902, "camel_45718": 0.693670392036438, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.6936937570571899, "camel_28348": 0.6942952871322632, "math_train_counting_and_probability_708": 0.6952776908874512, "camel_28404": 0.6959378123283386, "camel_45146": 0.6962103843688965, "camel_29121": 0.6963342428207397, "camel_28384": 0.6967789530754089, "camel_44872": 0.6971645355224609, "camel_29719": 0.6975546479225159, "camel_45726": 0.6979649662971497, "camel_29752": 0.6983266472816467, "camel_45952": 0.6993262767791748, "camel_29971": 0.6993696689605713, "camel_29984": 0.6996834874153137, "camel_29730": 0.7000359296798706, "camel_45721": 0.700498640537262, "camel_29078": 0.7012155055999756, "camel_45744": 0.70561683177948, "camel_44424": 0.7058203816413879, "camel_28357": 0.7067461013793945, "camel_28361": 0.7067850232124329, "camel_27561": 0.7070881724357605, "camel_45680": 0.7073260545730591, "camel_44762": 0.7093058228492737, "camel_29684": 0.7100738883018494, "camel_45727": 0.7101405262947083, "camel_29727": 0.7123953700065613, "camel_45689": 0.7124615907669067, "camel_28744": 0.7127227187156677, "camel_45741": 0.7129290103912354, "camel_29122": 0.7132948040962219, "camel_45936": 0.7138693332672119, "camel_29042": 0.7170559763908386, "camel_45684": 0.7173921465873718, "camel_29947": 0.7176138162612915, "camel_28740": 0.7207402586936951, "camel_45682": 0.7228057980537415, "camel_45931": 0.7236248254776001, "camel_29166": 0.7237273454666138, "camel_28379": 0.724033772945404, "camel_45693": 0.7254689931869507, "camel_45688": 0.7268062829971313, "camel_45690": 0.727448582649231, "camel_45706": 0.7275611758232117, "gsm_rft_11471": 0.7302039265632629, "gsm_rft_33863": 0.7302650809288025, "gsm_train_20944": 0.7343651652336121, "gsm_rft_21298": 0.7343651652336121, "camel_45697": 0.7417657375335693, "camel_45725": 0.7419660687446594, "camel_45687": 0.743395209312439, "camel_45709": 0.7443948984146118, "camel_45701": 0.7444362640380859, "camel_29704": 0.7486804723739624, "camel_44838": 0.7595205307006836, "camel_45698": 0.7666027545928955, "camel_45754": 0.7773817181587219}, "TheoremQA_xueguangma/dividend_discount_model_4.json": {"TheoremQA_xueguangma/dividend_discount_model_4.json": 0, "aqua_rat_15749": 0.7272246479988098, "aqua_rat_17504": 0.7272480726242065, "gsm_rft_13721": 0.7272866368293762, "gsm_rft_15208": 0.7272942066192627, "aqua_rat_70856": 0.7273361682891846, "gsm_rft_8880": 0.7273721098899841, "gsm_rft_14276": 0.7273926734924316, "gsm_rft_25277": 0.727405309677124, "aqua_rat_72074": 0.7274637222290039, "aqua_rat_10866": 0.7274924516677856, "aqua_rat_11679": 0.7275408506393433, "aqua_rat_62242": 0.7276079058647156, "aqua_rat_27035": 0.7276497483253479, "aqua_rat_62036": 0.7276501655578613, "aqua_rat_31414": 0.7278265953063965, "gsm_rft_17649": 0.7278879880905151, "gsm_rft_29688": 0.7278992533683777, "gsm_rft_19467": 0.7279887199401855, "gsm_train_14708": 0.7280248403549194, "gsm_rft_23395": 0.7280248403549194, "gsm_rft_6266": 0.7281950116157532, "gsm_rft_252": 0.7282185554504395, "gsm_rft_5809": 0.7282209396362305, "aqua_rat_43035": 0.7284092903137207, "aqua_rat_26821": 0.7285947799682617, "gsm_rft_3720": 0.7287048101425171, "aqua_rat_10392": 0.7287272214889526, "aqua_rat_56922": 0.7287609577178955, "aqua_rat_48354": 0.7287610769271851, "aqua_rat_23836": 0.7288969159126282, "gsm_rft_11189": 0.7291578054428101, "aqua_rat_80953": 0.7293376922607422, "aqua_rat_88958": 0.7293638586997986, "gsm_rft_13281": 0.7293741703033447, "gsm_rft_34497": 0.7293853163719177, "gsm_rft_26705": 0.7293853163719177, "gsm_rft_22073": 0.7294667363166809, "aqua_rat_85499": 0.7296016812324524, "aqua_rat_9933": 0.7297225594520569, "gsm_rft_34608": 0.7301129102706909, "aqua_rat_45726": 0.7302712798118591, "gsm_rft_27319": 0.7302947640419006, "aqua_rat_17859": 0.730306088924408, "aqua_rat_49748": 0.7303473949432373, "gsm_train_14821": 0.730379045009613, "aqua_rat_77492": 0.7304314374923706, "gsm_train_18102": 0.7305037379264832, "gsm_rft_8874": 0.7305037379264832, "gsm_rft_3769": 0.7305681109428406, "aqua_rat_85433": 0.7307432293891907, "aqua_rat_76045": 0.7307823896408081, "aqua_rat_80511": 0.7309871315956116, "aqua_rat_29207": 0.7310174107551575, "aqua_rat_80175": 0.7310248017311096, "aqua_rat_70191": 0.7310737371444702, "aqua_rat_87246": 0.7311459183692932, "gsm_rft_33054": 0.7311647534370422, "aqua_rat_61459": 0.7312252521514893, "gsm_train_16212": 0.7312645316123962, "gsm_rft_31378": 0.7312645316123962, "gsm_rft_1668": 0.7312645316123962, "gsm_rft_29637": 0.7312920689582825, "aqua_rat_87884": 0.731295645236969, "gsm_rft_34600": 0.7313258647918701, "gsm_rft_27287": 0.7313678860664368, "aqua_rat_16627": 0.7315272688865662, "aqua_rat_16258": 0.7316860556602478, "aqua_rat_73408": 0.731779158115387, "gsm_train_10049": 0.7318230867385864, "gsm_rft_14506": 0.7318230867385864, "gsm_rft_20457": 0.7320565581321716, "gsm_train_19765": 0.7320565581321716, "aqua_rat_88687": 0.7321246862411499, "gsm_rft_26721": 0.7322626113891602, "gsm_rft_30093": 0.7323077321052551, "aqua_rat_42339": 0.7324028015136719, "aqua_rat_12799": 0.7324995398521423, "gsm_rft_21165": 0.7327693104743958, "gsm_rft_8605": 0.732872724533081, "gsm_train_14812": 0.7328903675079346, "aqua_rat_72156": 0.7333364486694336, "gsm_rft_26599": 0.7335307002067566, "gsm_train_26918": 0.7335307002067566, "gsm_rft_32819": 0.7336318492889404, "gsm_rft_29683": 0.733709990978241, "aqua_rat_66501": 0.7337278127670288, "aqua_rat_52070": 0.7337324023246765, "gsm_rft_1289": 0.7340719103813171, "aqua_rat_798": 0.7340894937515259, "gsm_rft_24497": 0.7344459891319275, "gsm_rft_19671": 0.7351266741752625, "gsm_train_5087": 0.7351266741752625, "gsm_rft_4489": 0.7351266741752625, "gsm_train_18514": 0.7351850867271423, "gsm_rft_5012": 0.7352215647697449, "aqua_rat_77486": 0.7353507280349731, "gsm_rft_7079": 0.7354829907417297, "gsm_rft_29910": 0.73554527759552, "aqua_rat_2713": 0.7356715798377991, "gsm_rft_4368": 0.7356922626495361, "aqua_rat_758": 0.7357559204101562, "aqua_rat_87442": 0.7359876036643982, "gsm_rft_35059": 0.7361769080162048, "aqua_rat_80299": 0.7361811995506287, "aqua_rat_46713": 0.736207127571106, "aqua_rat_67283": 0.7363219261169434, "aqua_rat_55338": 0.7365445494651794, "gsm_train_22659": 0.7367700338363647, "gsm_rft_28000": 0.7368459105491638, "aqua_rat_20008": 0.7370842695236206, "aqua_rat_52833": 0.7371788024902344, "aqua_rat_27489": 0.7372739315032959, "aqua_rat_42852": 0.7373220324516296, "aqua_rat_63332": 0.7375784516334534, "aqua_rat_56727": 0.7379772663116455, "gsm_rft_32019": 0.7380012273788452, "aqua_rat_46607": 0.7382552027702332, "gsm_train_25772": 0.7383968830108643, "gsm_rft_31049": 0.7384715676307678, "gsm_rft_27770": 0.7385289669036865, "aqua_rat_18140": 0.7385728359222412, "gsm_train_14713": 0.7386974692344666, "aqua_rat_53268": 0.7387855648994446, "gsm_rft_15258": 0.7388829588890076, "gsm_rft_22277": 0.7391347885131836, "gsm_rft_10252": 0.73923259973526, "gsm_rft_16966": 0.7393811941146851, "aqua_rat_15639": 0.7393920421600342, "aqua_rat_17685": 0.7394043207168579, "gsm_rft_31412": 0.7394943237304688, "math_train_prealgebra_1338": 0.7397506833076477, "aqua_rat_69571": 0.7402272820472717, "gsm_rft_17816": 0.740312933921814, "aqua_rat_69201": 0.740946888923645, "aqua_rat_46293": 0.7410052418708801, "aqua_rat_55181": 0.7410191297531128, "gsm_rft_23795": 0.7411203384399414, "aqua_rat_28801": 0.7415086030960083, "gsm_rft_11850": 0.7415598034858704, "aqua_rat_69026": 0.7421626448631287, "aqua_rat_37709": 0.7422197461128235, "aqua_rat_46842": 0.742467999458313, "gsm_train_374": 0.7428253889083862, "gsm_rft_20347": 0.7428253889083862, "gsm_rft_5070": 0.7432747483253479, "aqua_rat_76011": 0.7434700727462769, "aqua_rat_59298": 0.7441120743751526, "aqua_rat_61026": 0.7445070147514343, "aqua_rat_59171": 0.7447336316108704, "aqua_rat_945": 0.7449171543121338, "aqua_rat_80382": 0.7452336549758911, "gsm_rft_26543": 0.7467733025550842, "aqua_rat_64914": 0.7477467060089111, "aqua_rat_67487": 0.7478965520858765, "aqua_rat_45227": 0.7479931116104126, "aqua_rat_20382": 0.7495025396347046, "aqua_rat_69591": 0.749697208404541, "aqua_rat_78741": 0.749754786491394, "aqua_rat_56240": 0.7508079409599304, "aqua_rat_71897": 0.751562237739563, "aqua_rat_75134": 0.7524495720863342, "aqua_rat_49749": 0.7525841593742371, "aqua_rat_14152": 0.7529885768890381, "aqua_rat_88770": 0.7532883286476135, "aqua_rat_8292": 0.7538779973983765, "aqua_rat_40840": 0.754641056060791, "aqua_rat_46623": 0.754660427570343, "aqua_rat_85762": 0.7560040950775146, "aqua_rat_74699": 0.7564858794212341, "aqua_rat_1364": 0.7565383911132812, "aqua_rat_24626": 0.7569307088851929, "aqua_rat_89004": 0.7575506567955017, "aqua_rat_73772": 0.7579757571220398, "aqua_rat_57386": 0.7587302923202515, "aqua_rat_52474": 0.7591667771339417, "aqua_rat_52197": 0.7593880891799927, "aqua_rat_64527": 0.7594693899154663, "aqua_rat_16849": 0.7599554657936096, "TheoremQA_xueguangma/dividend_discount_model_1.json": 0.7612106800079346, "aqua_rat_19454": 0.7612550258636475, "aqua_rat_73532": 0.7623913288116455, "aqua_rat_86309": 0.7627893686294556, "aqua_rat_63119": 0.7631074786186218, "aqua_rat_6973": 0.763405442237854, "aqua_rat_67497": 0.7637903690338135, "aqua_rat_76890": 0.7643336653709412, "aqua_rat_37337": 0.7653665542602539, "aqua_rat_26820": 0.7657350301742554, "aqua_rat_80962": 0.768558144569397, "aqua_rat_55929": 0.7695860862731934, "aqua_rat_36204": 0.7700774073600769, "aqua_rat_79547": 0.7725241780281067, "aqua_rat_87163": 0.7738425731658936, "aqua_rat_12664": 0.7769988775253296, "aqua_rat_81348": 0.7776615023612976, "aqua_rat_76879": 0.7813706994056702, "aqua_rat_33283": 0.7849345803260803, "TheoremQA_xueguangma/dividend_discount_model_2.json": 0.8046640753746033, "TheoremQA_xueguangma/dividend_discount_model_5.json": 0.8066889047622681}, "TheoremQA_maxku/signalprocessing9-signalrep.json": {"camel_45424": 0.6835899353027344, "camel_29925": 0.6837127804756165, "camel_29704": 0.6837778091430664, "camel_29421": 0.6838938593864441, "camel_45682": 0.683998167514801, "camel_45503": 0.6840845346450806, "camel_5124": 0.6841446161270142, "TheoremQA_maxku/signalprocessing12-nyquist.json": 0.6842001080513, "camel_45835": 0.6842167377471924, "camel_5097": 0.6842673420906067, "camel_44790": 0.6843344569206238, "camel_44530": 0.684649646282196, "camel_44846": 0.6847872734069824, "camel_44545": 0.6850197911262512, "camel_29945": 0.6850869655609131, "camel_45123": 0.6851000785827637, "camel_28348": 0.6853121519088745, "camel_29999": 0.6854123473167419, "camel_29371": 0.6856159567832947, "camel_29389": 0.6857587695121765, "camel_29166": 0.6858354806900024, "camel_44401": 0.68663090467453, "camel_45518": 0.6866540908813477, "camel_5164": 0.6878597140312195, "camel_44524": 0.6881971955299377, "camel_45357": 0.6882448792457581, "camel_45688": 0.6883648633956909, "camel_5106": 0.6884575486183167, "camel_45334": 0.6886478662490845, "camel_29985": 0.688984751701355, "camel_28744": 0.6892764568328857, "camel_44802": 0.6893101930618286, "camel_29928": 0.6895817518234253, "camel_29420": 0.6900693774223328, "camel_5113": 0.6901262998580933, "camel_5169": 0.6902613639831543, "camel_45120": 0.69047611951828, "camel_45179": 0.6906299591064453, "camel_44448": 0.6908381581306458, "camel_44551": 0.6910912394523621, "camel_5098": 0.6912159323692322, "camel_45512": 0.6918362379074097, "camel_45784": 0.6920782923698425, "camel_44537": 0.6922849416732788, "camel_45810": 0.6925480365753174, "camel_45727": 0.6938280463218689, "camel_45772": 0.6947507858276367, "camel_45152": 0.6953748464584351, "camel_44512": 0.6954827904701233, "camel_45149": 0.6957055926322937, "camel_45400": 0.69576096534729, "camel_44552": 0.6965968608856201, "camel_45936": 0.6966315507888794, "camel_29415": 0.6967342495918274, "camel_44873": 0.6967997550964355, "camel_45687": 0.6968854069709778, "camel_45839": 0.6975230574607849, "camel_29989": 0.6975544691085815, "camel_45342": 0.698253870010376, "camel_29973": 0.6984544992446899, "camel_45142": 0.6985846161842346, "camel_45697": 0.6990725994110107, "camel_44400": 0.6991739273071289, "camel_45696": 0.6992625594139099, "camel_45699": 0.6999626159667969, "camel_44542": 0.7000088691711426, "camel_45721": 0.7001950740814209, "camel_45763": 0.7019317150115967, "camel_44864": 0.7033450603485107, "camel_5100": 0.7038555145263672, "camel_45720": 0.7040889859199524, "camel_45776": 0.7041198015213013, "camel_45288": 0.7042197585105896, "camel_45722": 0.7045359015464783, "camel_44872": 0.7060147523880005, "camel_44555": 0.7063726782798767, "camel_45807": 0.7064646482467651, "camel_45923": 0.7064847946166992, "camel_44870": 0.7071239948272705, "camel_44488": 0.7071259021759033, "camel_44861": 0.7072045803070068, "camel_44532": 0.7076066732406616, "camel_29984": 0.7079727053642273, "camel_44807": 0.7091307044029236, "camel_44426": 0.7094389200210571, "camel_29964": 0.7097290754318237, "camel_45789": 0.7097693085670471, "camel_44447": 0.7104297876358032, "camel_45129": 0.7108842134475708, "camel_44486": 0.7110768556594849, "camel_45788": 0.7111731171607971, "camel_29948": 0.7124060392379761, "camel_45741": 0.712541401386261, "camel_44531": 0.7136080861091614, "camel_45689": 0.7137151956558228, "camel_45718": 0.7144731879234314, "camel_45996": 0.7149977087974548, "camel_45698": 0.715156614780426, "camel_45162": 0.715243399143219, "TheoremQA_maxku/signalprocessing19-period.json": 0.7156643867492676, "camel_44471": 0.7157559394836426, "camel_45790": 0.7158799171447754, "camel_45931": 0.7159929871559143, "camel_44550": 0.7167974710464478, "camel_45928": 0.717628002166748, "camel_45134": 0.7177066206932068, "camel_44416": 0.7179912328720093, "camel_45766": 0.7182126641273499, "camel_29969": 0.7182188034057617, "camel_5147": 0.7184182405471802, "camel_45806": 0.720017671585083, "camel_44506": 0.7210010290145874, "camel_44517": 0.7220478057861328, "camel_45797": 0.7220529317855835, "camel_44462": 0.7224743366241455, "camel_45199": 0.7230517864227295, "camel_44526": 0.7235888838768005, "camel_44475": 0.7239667177200317, "camel_44510": 0.7242950201034546, "camel_45764": 0.7244090437889099, "camel_44466": 0.726015031337738, "camel_45198": 0.7264602184295654, "camel_45170": 0.7266561388969421, "camel_45988": 0.726714015007019, "camel_45706": 0.7268041372299194, "camel_45173": 0.7268248796463013, "camel_45690": 0.7268638610839844, "camel_45791": 0.7272968292236328, "camel_44487": 0.7275596857070923, "camel_45684": 0.7275727391242981, "camel_44538": 0.7281802892684937, "camel_45748": 0.7283190488815308, "camel_44420": 0.7283395528793335, "camel_44851": 0.7283665537834167, "camel_45308": 0.7285504937171936, "camel_44546": 0.7287381887435913, "camel_44523": 0.72946697473526, "camel_44411": 0.729701578617096, "camel_45811": 0.7299173474311829, "camel_45713": 0.7310210466384888, "camel_45130": 0.7327107191085815, "camel_45693": 0.7328615784645081, "camel_44533": 0.7331792712211609, "camel_45744": 0.733748733997345, "camel_44838": 0.7342190742492676, "camel_44828": 0.7344109416007996, "camel_45782": 0.7363443374633789, "camel_44826": 0.737025260925293, "camel_44534": 0.7378990650177002, "camel_44516": 0.7380999326705933, "camel_45680": 0.7382465600967407, "camel_44473": 0.7383920550346375, "camel_45176": 0.73867267370224, "camel_45379": 0.7387471199035645, "camel_44852": 0.7392624020576477, "camel_45743": 0.7394470572471619, "camel_45729": 0.7398428916931152, "camel_45314": 0.7400268316268921, "camel_45615": 0.7402790784835815, "camel_45725": 0.740310549736023, "camel_45759": 0.7404760718345642, "camel_44421": 0.7404872179031372, "camel_45796": 0.7405322790145874, "camel_45700": 0.741048276424408, "camel_45754": 0.7414320111274719, "camel_45781": 0.7414952516555786, "camel_44839": 0.7414990067481995, "camel_45799": 0.7417784929275513, "camel_44865": 0.7422689199447632, "camel_44544": 0.7430499792098999, "camel_44849": 0.7432647943496704, "camel_45966": 0.7433865666389465, "camel_45803": 0.743414044380188, "camel_45137": 0.743960976600647, "camel_44498": 0.7455712556838989, "camel_45676": 0.7457701563835144, "camel_45709": 0.7466068863868713, "camel_45815": 0.746768593788147, "camel_45717": 0.7469373941421509, "camel_44825": 0.7480605840682983, "camel_45821": 0.7483993172645569, "camel_44504": 0.7485322952270508, "camel_45685": 0.7486453652381897, "camel_45320": 0.7497234344482422, "camel_44554": 0.7497362494468689, "camel_45765": 0.7498137354850769, "camel_44818": 0.7503663301467896, "camel_45792": 0.751606285572052, "camel_45798": 0.7529714703559875, "camel_45166": 0.7531135678291321, "camel_45155": 0.7535419464111328, "camel_45184": 0.7538000345230103, "camel_45607": 0.7538977265357971, "camel_45681": 0.7615213394165039, "camel_45492": 0.762482225894928, "camel_45745": 0.7643013596534729, "camel_44820": 0.7675703167915344, "camel_44848": 0.7723489999771118, "camel_45171": 0.7777615785598755, "camel_45146": 0.7799942493438721}, "TheoremQA_jianyu_xu/Multinomial_1.json": {"camel_20392": 0, "camel_20517": 0, "camel_21022": 0, "camel_21572": 0, "camel_20998": 0, "camel_20698": 0, "camel_20317": 0, "camel_20297": 0, "camel_20996": 0, "camel_20499": 0, "camel_21371": 0, "camel_20844": 0, "camel_21419": 0, "camel_20860": 0, "camel_20578": 0, "camel_21429": 0, "camel_20853": 0, "camel_20599": 0, "camel_20706": 0, "camel_21400": 0, "camel_20514": 0, "camel_20312": 0, "camel_20623": 0, "camel_21261": 0, "camel_21200": 0, "camel_20462": 0, "camel_20262": 0, "camel_20308": 0, "camel_20414": 0, "camel_21246": 0, "camel_20570": 0, "camel_20270": 0, "camel_20287": 0, "camel_20248": 0, "camel_20863": 0, "camel_20930": 0, "camel_20813": 0, "camel_20808": 0, "camel_21808": 0, "camel_20257": 0, "camel_21379": 0, "camel_20022": 0, "camel_20818": 0, "camel_21386": 0, "camel_20946": 0, "camel_20611": 0, "camel_20867": 0, "camel_20656": 0, "camel_21431": 0, "camel_20856": 0, "camel_20973": 0, "camel_20598": 0, "camel_20802": 0, "camel_21202": 0, "camel_21049": 0, "camel_20309": 0, "camel_20614": 0, "camel_21015": 0, "camel_20523": 0, "camel_21528": 0, "camel_21050": 0, "camel_20302": 0, "camel_21215": 0, "camel_20849": 0, "camel_20310": 0, "camel_20619": 0, "camel_21028": 0, "camel_20255": 0, "camel_21530": 0, "camel_20637": 0, "camel_20512": 0, "camel_21039": 0, "math_train_counting_and_probability_149": 0.8148346543312073, "aqua_rat_49505": 0.8148611783981323, "aqua_rat_35517": 0.8150267601013184, "aqua_rat_77698": 0.8150875568389893, "math_train_counting_and_probability_617": 0.8151519894599915, "aqua_rat_68846": 0.8152193427085876, "aqua_rat_15820": 0.8152393698692322, "aqua_rat_61965": 0.8152591586112976, "camel_38541": 0.8155650496482849, "aqua_rat_87094": 0.8157228231430054, "aqua_rat_67749": 0.8158161640167236, "aqua_rat_55266": 0.8159301280975342, "aqua_rat_24104": 0.8159719109535217, "aqua_rat_14532": 0.8164540529251099, "aqua_rat_39610": 0.8165270686149597, "aqua_rat_80161": 0.8165825009346008, "aqua_rat_63836": 0.816583514213562, "aqua_rat_32489": 0.8170757293701172, "aqua_rat_78830": 0.8171089887619019, "aqua_rat_27914": 0.817139744758606, "aqua_rat_29319": 0.8173590898513794, "aqua_rat_84364": 0.8174830079078674, "aqua_rat_51384": 0.8176870346069336, "math_test_prealgebra_1572": 0.8181251287460327, "aqua_rat_21240": 0.81830233335495, "aqua_rat_53084": 0.8184794187545776, "aqua_rat_71336": 0.8185477256774902, "aqua_rat_57095": 0.8186185956001282, "aqua_rat_87992": 0.8187957406044006, "aqua_rat_15615": 0.8189802765846252, "aqua_rat_11531": 0.8190183639526367, "aqua_rat_35395": 0.8190444707870483, "aqua_rat_71649": 0.8192318081855774, "aqua_rat_79349": 0.8193755149841309, "aqua_rat_49273": 0.81954026222229, "aqua_rat_87327": 0.8196641206741333, "aqua_rat_210": 0.8196991682052612, "aqua_rat_62261": 0.820032000541687, "aqua_rat_42061": 0.8203496932983398, "aqua_rat_76714": 0.8204440474510193, "aqua_rat_34205": 0.8205349445343018, "aqua_rat_73365": 0.8208082318305969, "aqua_rat_6365": 0.8208920955657959, "aqua_rat_62715": 0.8210077285766602, "aqua_rat_9762": 0.8214766979217529, "aqua_rat_15917": 0.8216232657432556, "aqua_rat_57246": 0.8216795325279236, "aqua_rat_15927": 0.8217223882675171, "aqua_rat_41861": 0.8217905759811401, "math_train_counting_and_probability_918": 0.8221629858016968, "aqua_rat_22648": 0.8225719332695007, "aqua_rat_77021": 0.8226111531257629, "aqua_rat_57985": 0.8228014707565308, "aqua_rat_57176": 0.8229159116744995, "aqua_rat_60238": 0.822989821434021, "aqua_rat_35289": 0.8233507871627808, "aqua_rat_83547": 0.8240959048271179, "aqua_rat_57767": 0.8241086006164551, "math_train_counting_and_probability_318": 0.8243359923362732, "aqua_rat_51723": 0.8243476152420044, "math_train_counting_and_probability_696": 0.8244323134422302, "aqua_rat_50641": 0.8245142698287964, "math_train_prealgebra_115": 0.8254508972167969, "aqua_rat_371": 0.8257223963737488, "aqua_rat_56019": 0.8257250189781189, "aqua_rat_16780": 0.826065719127655, "aqua_rat_18901": 0.826147735118866, "aqua_rat_29348": 0.8261686563491821, "math_test_counting_and_probability_341": 0.8262524604797363, "aqua_rat_1184": 0.8264402151107788, "aqua_rat_13369": 0.8265799283981323, "aqua_rat_65667": 0.826580286026001, "aqua_rat_89175": 0.8268367052078247, "aqua_rat_70803": 0.8269938826560974, "aqua_rat_10186": 0.8273481130599976, "aqua_rat_575": 0.8277034759521484, "aqua_rat_3934": 0.827895998954773, "aqua_rat_79755": 0.8279464840888977, "aqua_rat_7341": 0.8283377289772034, "aqua_rat_8375": 0.8288425207138062, "aqua_rat_30172": 0.8288925886154175, "aqua_rat_58757": 0.8292093276977539, "aqua_rat_70446": 0.8300665616989136, "aqua_rat_83158": 0.8306265473365784, "aqua_rat_8627": 0.8306548595428467, "aqua_rat_19436": 0.8309052586555481, "aqua_rat_2658": 0.8311446309089661, "aqua_rat_52067": 0.8316289782524109, "aqua_rat_54461": 0.832038938999176, "aqua_rat_10096": 0.8329456448554993, "aqua_rat_23041": 0.8331642150878906, "aqua_rat_32162": 0.8341336846351624, "aqua_rat_21868": 0.8383064866065979, "aqua_rat_22458": 0.838350236415863, "aqua_rat_22507": 0.8383980989456177, "aqua_rat_12795": 0.8398969173431396, "TheoremQA_jianyu_xu/Multinomial_2.json": 0.8401108384132385, "aqua_rat_64131": 0.8404713273048401, "aqua_rat_66841": 0.8406203985214233, "math_test_counting_and_probability_416": 0.8408166170120239, "aqua_rat_34600": 0.8412162661552429, "aqua_rat_7911": 0.842115044593811, "aqua_rat_55783": 0.8421642184257507, "aqua_rat_11164": 0.8430230617523193, "aqua_rat_10102": 0.8441053628921509, "math_test_counting_and_probability_79": 0.8442082405090332, "aqua_rat_73402": 0.8445305824279785, "aqua_rat_49410": 0.8449754118919373, "aqua_rat_36385": 0.8455469012260437, "aqua_rat_77478": 0.847358763217926, "aqua_rat_37185": 0.8477097153663635, "aqua_rat_18404": 0.8480690121650696, "aqua_rat_32732": 0.8481406569480896, "aqua_rat_62903": 0.8498446941375732, "aqua_rat_4294": 0.8501743078231812, "aqua_rat_2480": 0.8502495884895325, "aqua_rat_74550": 0.8513713479042053, "aqua_rat_7248": 0.8543115854263306, "aqua_rat_13585": 0.8550743460655212, "aqua_rat_89113": 0.8591203689575195, "aqua_rat_16877": 0.8594682216644287, "aqua_rat_84159": 0.8623507618904114, "aqua_rat_29651": 0.865408182144165, "aqua_rat_40108": 0.8657220005989075, "aqua_rat_73122": 0.8662630915641785, "aqua_rat_34678": 0.8669312000274658, "aqua_rat_61885": 0.8677876591682434, "aqua_rat_60936": 0.8756536841392517}, "TheoremQA_jianyu_xu/Cayley_3.json": {"camel_23148": 0, "camel_22203": 0, "camel_23188": 0, "camel_21062": 0, "camel_23155": 0, "camel_23124": 0, "camel_22381": 0, "camel_22396": 0, "camel_22405": 0, "camel_21107": 0, "camel_23284": 0, "camel_22471": 0, "camel_22946": 0, "camel_22430": 0, "camel_22879": 0, "camel_22428": 0, "camel_21103": 0, "camel_22457": 0, "camel_23129": 0, "camel_22412": 0, "camel_22478": 0, "camel_22411": 0, "camel_22407": 0, "camel_22333": 0, "camel_22327": 0, "camel_23995": 0, "camel_23060": 0, "camel_22890": 0, "camel_22447": 0, "camel_22362": 0, "camel_23328": 0, "camel_22812": 0, "camel_23975": 0, "camel_23199": 0, "camel_22331": 0, "camel_22432": 0, "camel_21067": 0, "camel_23951": 0, "camel_22334": 0, "camel_22453": 0, "camel_22477": 0, "camel_23312": 0, "camel_23132": 0, "camel_22937": 0, "camel_23425": 0, "camel_23128": 0, "camel_23114": 0, "camel_22445": 0, "camel_21083": 0, "camel_23994": 0, "camel_23153": 0, "camel_22887": 0, "camel_23307": 0, "camel_22664": 0, "camel_22444": 0, "camel_23144": 0, "camel_22338": 0, "camel_23358": 0, "camel_23427": 0, "camel_23424": 0, "camel_22435": 0, "camel_22476": 0, "camel_23292": 0, "camel_23999": 0, "camel_23943": 0, "camel_22418": 0, "camel_21078": 0, "camel_23794": 0, "camel_22170": 0, "camel_22464": 0, "camel_22441": 0, "camel_23945": 0, "camel_23968": 0, "camel_23954": 0, "camel_21087": 0, "camel_23175": 0, "camel_23183": 0, "camel_21804": 0, "camel_23187": 0, "camel_23123": 0, "camel_22916": 0, "camel_23168": 0, "camel_23382": 0, "camel_23147": 0, "camel_23154": 0, "camel_23369": 0, "camel_22415": 0, "camel_21059": 0, "camel_22391": 0, "camel_21047": 0, "camel_23164": 0, "camel_22413": 0, "camel_23135": 0, "camel_23941": 0, "camel_23393": 0, "camel_22849": 0, "camel_23177": 0, "camel_23150": 0, "camel_22867": 0, "camel_21817": 0, "camel_23403": 0, "camel_21072": 0, "camel_22452": 0, "camel_22373": 0, "camel_23161": 0, "camel_21051": 0, "camel_22838": 0, "camel_22437": 0, "camel_23198": 0, "camel_22866": 0, "camel_22454": 0, "camel_22801": 0, "camel_22949": 0, "camel_21084": 0, "camel_22424": 0, "camel_23172": 0, "camel_23348": 0, "camel_22456": 0, "camel_23342": 0, "camel_23159": 0, "camel_23423": 0, "camel_22473": 0, "camel_21064": 0, "camel_22352": 0, "camel_22370": 0, "camel_23158": 0, "camel_22450": 0, "camel_22862": 0, "camel_22922": 0, "camel_22393": 0, "camel_23944": 0, "camel_21063": 0, "camel_23180": 0, "camel_22863": 0, "camel_23430": 0, "camel_23196": 0, "camel_21133": 0, "camel_21106": 0, "camel_22451": 0, "camel_21108": 0, "camel_22824": 0, "camel_23372": 0, "camel_23923": 0, "camel_22443": 0, "camel_22823": 0, "camel_22458": 0, "camel_23364": 0, "camel_21098": 0, "camel_22422": 0, "camel_22808": 0, "camel_23137": 0, "camel_23934": 0, "camel_23932": 0, "camel_22853": 0, "camel_22389": 0, "camel_23181": 0, "camel_23174": 0, "camel_23191": 0, "camel_22912": 0, "camel_23176": 0, "camel_23145": 0, "camel_23156": 0, "camel_23165": 0, "camel_23977": 0, "camel_23391": 0, "camel_23173": 0, "camel_23400": 0, "camel_23122": 0, "camel_23948": 0, "camel_23195": 0, "camel_23974": 0, "camel_23163": 0, "camel_23126": 0, "camel_23432": 0, "camel_23162": 0, "camel_23193": 0, "camel_23151": 0, "camel_23166": 0, "camel_23189": 0, "camel_23946": 0, "camel_23993": 0, "camel_23965": 0, "camel_23179": 0, "camel_21764": 0, "camel_23986": 0, "aqua_rat_64683": 0.7575494647026062, "aqua_rat_77006": 0.7581275701522827, "aqua_rat_10797": 0.7593165040016174, "aqua_rat_7562": 0.7603105306625366, "aqua_rat_28685": 0.7675678730010986, "aqua_rat_38901": 0.773221492767334, "aqua_rat_54929": 0.7756214737892151, "math_train_prealgebra_350": 0.7839277982711792, "aqua_rat_44831": 0.7878758311271667, "aqua_rat_76009": 0.7884625196456909, "aqua_rat_70645": 0.7894065976142883, "aqua_rat_40504": 0.8026924729347229, "aqua_rat_25794": 0.8049595952033997, "aqua_rat_36545": 0.8079399466514587, "camel_19957": 0.8323377966880798}, "TheoremQA_wenhuchen/infinite_series_sum3.json": {"camel_42663": 0.6846106648445129, "camel_31881": 0.684643030166626, "camel_31213": 0.6846661567687988, "TheoremQA_wenhuchen/series_convergen2.json": 0.6847628355026245, "camel_42051": 0.6847750544548035, "camel_30740": 0.6851892471313477, "camel_42671": 0.6852009296417236, "camel_42666": 0.6853430867195129, "camel_31444": 0.6854408383369446, "camel_42708": 0.6856968998908997, "camel_31103": 0.6857112646102905, "camel_42715": 0.6858018636703491, "camel_30959": 0.6858810782432556, "camel_30360": 0.6859309673309326, "camel_31115": 0.6862133145332336, "camel_31339": 0.6862995624542236, "camel_31947": 0.6863508224487305, "camel_42720": 0.6864035725593567, "camel_42707": 0.6864092350006104, "camel_42674": 0.6864367723464966, "camel_42792": 0.6865331530570984, "camel_42773": 0.6866825819015503, "camel_42063": 0.6867251992225647, "camel_42676": 0.6867465376853943, "camel_42734": 0.6869290471076965, "camel_30883": 0.6873539686203003, "camel_31205": 0.6875209212303162, "camel_20541": 0.6876178979873657, "camel_30927": 0.6877589225769043, "camel_42762": 0.6878117918968201, "camel_42679": 0.6879608631134033, "aqua_rat_6250": 0.6879939436912537, "camel_30948": 0.6880569458007812, "camel_31257": 0.6880925297737122, "camel_31247": 0.6883043050765991, "math_train_algebra_553": 0.688438355922699, "camel_30930": 0.688587486743927, "camel_42728": 0.6887299418449402, "camel_30765": 0.6888682246208191, "camel_42740": 0.688980221748352, "camel_37811": 0.6893326640129089, "aqua_rat_11917": 0.6895300149917603, "camel_42705": 0.6895763278007507, "camel_37790": 0.68964684009552, "camel_42771": 0.6897010207176208, "camel_43381": 0.6899694800376892, "aqua_rat_23208": 0.689998984336853, "camel_42658": 0.6900956630706787, "camel_31884": 0.690175473690033, "camel_31269": 0.6901808977127075, "camel_42787": 0.6902669072151184, "camel_42794": 0.6902804970741272, "aqua_rat_78042": 0.6906436085700989, "camel_42713": 0.690936803817749, "aqua_rat_61662": 0.6910146474838257, "camel_30942": 0.6910549402236938, "camel_31236": 0.6912367939949036, "camel_42793": 0.6912791132926941, "aqua_rat_64676": 0.691515326499939, "aqua_rat_37866": 0.6915397047996521, "camel_42779": 0.6918261647224426, "camel_31241": 0.6921547651290894, "camel_30658": 0.6921680569648743, "camel_31505": 0.6922950148582458, "camel_31258": 0.6926076412200928, "camel_31248": 0.6926110982894897, "camel_30936": 0.6926137804985046, "camel_31098": 0.6926145553588867, "camel_19558": 0.6934873461723328, "math_train_algebra_1589": 0.693543553352356, "camel_42711": 0.6942896246910095, "camel_44110": 0.6943693161010742, "camel_43001": 0.6945381760597229, "aqua_rat_65902": 0.6947075128555298, "camel_30899": 0.6947905421257019, "camel_30921": 0.6951321363449097, "TheoremQA_wenhuchen/series_convergen1.json": 0.695152759552002, "camel_30897": 0.6951687335968018, "aqua_rat_4332": 0.6952410340309143, "camel_49079": 0.6952949166297913, "camel_31238": 0.6953369975090027, "camel_31228": 0.695510745048523, "camel_31356": 0.6955893635749817, "camel_31209": 0.6957542896270752, "camel_30923": 0.6958981156349182, "camel_31045": 0.6963425874710083, "camel_42766": 0.6967290639877319, "camel_30726": 0.6968748569488525, "camel_31279": 0.6970169544219971, "camel_42688": 0.6970829367637634, "camel_42615": 0.697088360786438, "camel_30396": 0.6972237825393677, "aqua_rat_67612": 0.6973010301589966, "camel_30886": 0.6976074576377869, "camel_31702": 0.6978182196617126, "aqua_rat_36268": 0.697820782661438, "camel_42685": 0.6985110640525818, "aqua_rat_68972": 0.6985673308372498, "camel_31323": 0.6989760398864746, "aqua_rat_6364": 0.6993378400802612, "aqua_rat_85856": 0.6995899081230164, "camel_30887": 0.7001128792762756, "camel_42753": 0.7003016471862793, "camel_42645": 0.7003569602966309, "camel_31112": 0.7005805373191833, "aqua_rat_53870": 0.7009106278419495, "camel_42716": 0.7011556029319763, "aqua_rat_10334": 0.7015069127082825, "camel_31863": 0.7016171216964722, "aqua_rat_55051": 0.7019729614257812, "camel_42693": 0.7029030323028564, "aqua_rat_53748": 0.7029895186424255, "camel_42747": 0.703163743019104, "camel_42778": 0.7038645148277283, "camel_44158": 0.7041895389556885, "TheoremQA_mingyin/Lebesgue-measure1.json": 0.7045407295227051, "camel_44141": 0.7046422362327576, "camel_37619": 0.7051434516906738, "camel_30809": 0.7051765322685242, "camel_42703": 0.7053751349449158, "camel_30330": 0.7057164907455444, "camel_42732": 0.7059175372123718, "camel_42670": 0.7071112990379333, "camel_42749": 0.7075054049491882, "camel_31452": 0.7077437043190002, "camel_30385": 0.7079738974571228, "camel_31973": 0.7079806327819824, "camel_42760": 0.7086214423179626, "aqua_rat_54656": 0.7086856365203857, "aqua_rat_69318": 0.7087650299072266, "camel_42677": 0.708804190158844, "camel_42659": 0.7088978886604309, "camel_30813": 0.7091206312179565, "aqua_rat_35341": 0.7092950940132141, "aqua_rat_48885": 0.7094855308532715, "camel_42643": 0.7095529437065125, "aqua_rat_76921": 0.7096132040023804, "aqua_rat_49434": 0.7104602456092834, "aqua_rat_19560": 0.7115220427513123, "camel_30409": 0.7117599248886108, "camel_42070": 0.7129673361778259, "camel_30353": 0.7142687439918518, "camel_42704": 0.7142854928970337, "camel_42756": 0.7145118117332458, "camel_42045": 0.7145968079566956, "camel_42990": 0.7147812843322754, "aqua_rat_50166": 0.7148642539978027, "TheoremQA_wenhuchen/infinite_series_sum2.json": 0.7154258489608765, "camel_44106": 0.7163429856300354, "camel_30889": 0.716376543045044, "camel_44100": 0.7169668078422546, "camel_42755": 0.7181127667427063, "camel_30327": 0.7187372446060181, "camel_42776": 0.7189876437187195, "camel_30346": 0.7198700308799744, "camel_49109": 0.7203607559204102, "camel_31842": 0.7221602201461792, "aqua_rat_37159": 0.7229498624801636, "aqua_rat_8747": 0.7245672345161438, "camel_31880": 0.7253422141075134, "camel_42013": 0.7253700494766235, "camel_42672": 0.7262983322143555, "camel_31915": 0.7265290021896362, "camel_30759": 0.7271720767021179, "aqua_rat_35123": 0.727381706237793, "camel_30688": 0.7275511026382446, "camel_42678": 0.7276495099067688, "camel_31984": 0.7287465929985046, "camel_31089": 0.7289757132530212, "camel_30440": 0.7290613055229187, "camel_30341": 0.7291361093521118, "camel_42777": 0.7293099164962769, "camel_30371": 0.7304999232292175, "camel_28309": 0.7311303019523621, "aqua_rat_52544": 0.7318036556243896, "camel_30093": 0.7342932224273682, "camel_30357": 0.7358559370040894, "camel_42668": 0.7368993759155273, "math_test_algebra_2477": 0.7370343804359436, "camel_30392": 0.7371244430541992, "camel_44121": 0.7376823425292969, "camel_30345": 0.7377908229827881, "camel_30797": 0.740267813205719, "camel_30338": 0.7407145500183105, "camel_30372": 0.743224561214447, "camel_30342": 0.7433311343193054, "camel_30339": 0.7463075518608093, "camel_30354": 0.7472178936004639, "camel_30383": 0.7478116750717163, "camel_31759": 0.7485566139221191, "camel_30374": 0.7496176958084106, "camel_31869": 0.7503566145896912, "camel_30685": 0.7509163022041321, "camel_49051": 0.7569267153739929, "camel_30202": 0.7667298913002014, "camel_30680": 0.7722214460372925, "camel_31084": 0.7753745317459106, "camel_31056": 0.7756710052490234, "camel_31057": 0.7791318297386169, "camel_31061": 0.7880986332893372}, "TheoremQA_maxku/cv-colorsci3-rgb.json": {"TheoremQA_maxku/cv-colorsci3-rgb.json": 0, "gsm_rft_17546": 0.714765727519989, "aqua_rat_50381": 0.7147825360298157, "aqua_rat_78877": 0.714952826499939, "gsm_train_30227": 0.7150231003761292, "gsm_train_16544": 0.7150295376777649, "gsm_rft_1371": 0.7150906920433044, "gsm_rft_33423": 0.7150922417640686, "gsm_rft_6576": 0.715164065361023, "gsm_rft_25355": 0.7151663899421692, "gsm_rft_24202": 0.7152276039123535, "gsm_rft_9738": 0.7152276039123535, "gsm_train_3431": 0.7152866125106812, "gsm_rft_22237": 0.7152990102767944, "aqua_rat_86815": 0.7155250906944275, "aqua_rat_8581": 0.7155547738075256, "gsm_rft_23733": 0.7157792448997498, "aqua_rat_63732": 0.7158270478248596, "aqua_rat_15870": 0.715954601764679, "aqua_rat_22938": 0.716010332107544, "aqua_rat_79345": 0.7160218358039856, "gsm_train_24910": 0.7161588072776794, "gsm_train_12649": 0.7163023948669434, "gsm_rft_15386": 0.7164205312728882, "gsm_rft_30455": 0.7165425419807434, "gsm_rft_21493": 0.7165999412536621, "gsm_rft_6315": 0.7166138291358948, "gsm_rft_27313": 0.7167455554008484, "gsm_train_29227": 0.7169634699821472, "gsm_rft_2972": 0.7170956134796143, "gsm_rft_25326": 0.7171827554702759, "gsm_rft_16476": 0.7173128724098206, "aqua_rat_87371": 0.7173256278038025, "gsm_rft_20039": 0.7173433303833008, "gsm_rft_6828": 0.7173652648925781, "gsm_rft_31633": 0.7174136638641357, "gsm_rft_31983": 0.7174211740493774, "gsm_rft_34182": 0.7175127267837524, "aqua_rat_59369": 0.7175143957138062, "aqua_rat_44274": 0.7177574038505554, "gsm_rft_25645": 0.7179958820343018, "gsm_rft_2890": 0.7180681228637695, "gsm_train_188": 0.7180681228637695, "gsm_rft_35008": 0.7181202173233032, "aqua_rat_85460": 0.7181660532951355, "gsm_rft_9053": 0.7181983590126038, "gsm_train_9463": 0.7183077335357666, "gsm_rft_1995": 0.7183077335357666, "aqua_rat_50616": 0.7183252573013306, "aqua_rat_81549": 0.7183739542961121, "gsm_train_33000": 0.7183780670166016, "gsm_rft_3218": 0.7183780670166016, "gsm_rft_22763": 0.7185664772987366, "gsm_rft_6312": 0.718791127204895, "aqua_rat_80060": 0.7189079523086548, "gsm_rft_26309": 0.718909740447998, "gsm_rft_23876": 0.7189776301383972, "aqua_rat_5518": 0.7191205620765686, "aqua_rat_71134": 0.7192388772964478, "gsm_rft_13434": 0.7192952036857605, "gsm_rft_25877": 0.7193709015846252, "gsm_rft_28893": 0.7194926142692566, "gsm_rft_13638": 0.7195401191711426, "gsm_train_2129": 0.7195949554443359, "gsm_rft_16916": 0.7196693420410156, "gsm_train_17680": 0.7197643518447876, "gsm_rft_21092": 0.7197643518447876, "gsm_rft_13340": 0.7198517322540283, "gsm_rft_3958": 0.7198714017868042, "aqua_rat_68434": 0.7199476957321167, "gsm_train_13923": 0.7199535965919495, "gsm_rft_14505": 0.7200491428375244, "camel_37822": 0.7200717926025391, "gsm_rft_22314": 0.7200965881347656, "gsm_rft_11875": 0.7201225161552429, "gsm_rft_6621": 0.7202025055885315, "gsm_rft_21329": 0.7202807068824768, "gsm_train_29660": 0.7202988862991333, "aqua_rat_46648": 0.7204606533050537, "gsm_rft_32944": 0.7206629514694214, "gsm_rft_21457": 0.7206719517707825, "gsm_rft_29411": 0.7207826375961304, "gsm_rft_6321": 0.720801055431366, "gsm_rft_8487": 0.7208529114723206, "gsm_rft_31898": 0.7208889722824097, "gsm_rft_21510": 0.7209734320640564, "gsm_rft_7102": 0.7210716605186462, "gsm_rft_13148": 0.7211667895317078, "gsm_rft_33841": 0.721194326877594, "gsm_rft_10349": 0.7214686870574951, "gsm_rft_11414": 0.7218210697174072, "gsm_rft_11927": 0.7218210697174072, "gsm_train_24856": 0.7218484878540039, "aqua_rat_18455": 0.721906304359436, "gsm_rft_32562": 0.7219473123550415, "gsm_train_24988": 0.7220526337623596, "gsm_rft_8477": 0.7222045063972473, "gsm_train_8438": 0.7223640084266663, "gsm_rft_12335": 0.7223640084266663, "gsm_rft_13217": 0.7223943471908569, "gsm_rft_10389": 0.7224090099334717, "gsm_rft_21588": 0.7224137187004089, "gsm_rft_9763": 0.7228699922561646, "gsm_train_30887": 0.7229158878326416, "gsm_rft_13838": 0.722922146320343, "gsm_rft_21610": 0.7229727506637573, "aqua_rat_2003": 0.7232121825218201, "aqua_rat_82211": 0.7233519554138184, "aqua_rat_80601": 0.7233630418777466, "gsm_rft_15730": 0.723719596862793, "gsm_rft_32182": 0.7237564921379089, "gsm_rft_18784": 0.7237570881843567, "gsm_rft_11457": 0.723784863948822, "gsm_rft_27135": 0.7239961624145508, "gsm_rft_3157": 0.7241064310073853, "gsm_rft_16988": 0.7241175174713135, "gsm_train_32836": 0.7243425250053406, "gsm_rft_29493": 0.7243502736091614, "gsm_rft_7108": 0.7244075536727905, "gsm_rft_23497": 0.7245633006095886, "gsm_rft_15856": 0.7246723175048828, "gsm_rft_15722": 0.7247042059898376, "gsm_train_9152": 0.7247254848480225, "gsm_rft_6458": 0.7247254848480225, "gsm_rft_32389": 0.724775493144989, "gsm_rft_15804": 0.7249428629875183, "aqua_rat_34033": 0.7250036597251892, "gsm_rft_1690": 0.7250993251800537, "aqua_rat_6933": 0.7251569032669067, "gsm_train_17368": 0.7251656651496887, "gsm_rft_25461": 0.7253099679946899, "aqua_rat_21052": 0.7257478833198547, "gsm_rft_10427": 0.7263711094856262, "math_train_prealgebra_580": 0.7266248464584351, "gsm_rft_25307": 0.727161169052124, "gsm_rft_12104": 0.7274744510650635, "gsm_rft_7520": 0.7277190089225769, "gsm_rft_30157": 0.7277625203132629, "gsm_rft_25755": 0.7277932167053223, "TheoremQA_maxku/cv-colorsci2-hsi.json": 0.7278040051460266, "gsm_train_2836": 0.7279582023620605, "gsm_rft_35232": 0.7282453179359436, "gsm_rft_12710": 0.7287831902503967, "gsm_rft_9461": 0.7289860844612122, "gsm_rft_3146": 0.7290831804275513, "gsm_rft_7818": 0.7296850681304932, "aqua_rat_81163": 0.7304414510726929, "gsm_rft_27243": 0.7306710481643677, "gsm_train_27431": 0.7306710481643677, "gsm_rft_5985": 0.730695366859436, "gsm_rft_26902": 0.7307714819908142, "aqua_rat_72223": 0.7311363220214844, "gsm_rft_10422": 0.7313275337219238, "gsm_rft_1422": 0.7314643859863281, "gsm_rft_3420": 0.7317094802856445, "gsm_rft_35627": 0.7317112684249878, "gsm_rft_13588": 0.7319111227989197, "gsm_rft_3211": 0.7322290539741516, "gsm_train_9788": 0.7322290539741516, "gsm_rft_18673": 0.7322526574134827, "gsm_rft_5722": 0.7324721813201904, "gsm_rft_16817": 0.7329546809196472, "gsm_train_26494": 0.7330610752105713, "gsm_rft_31285": 0.7330610752105713, "gsm_rft_3862": 0.734192967414856, "gsm_rft_10212": 0.734539270401001, "gsm_rft_32041": 0.7345893979072571, "gsm_train_18947": 0.7346922755241394, "gsm_rft_29861": 0.7346922755241394, "gsm_rft_24703": 0.7356148958206177, "gsm_rft_11441": 0.7372148633003235, "aqua_rat_4046": 0.7393335103988647, "aqua_rat_63612": 0.740256130695343, "gsm_rft_18771": 0.7424609661102295, "aqua_rat_47454": 0.7458463311195374, "aqua_rat_32944": 0.7464773058891296, "aqua_rat_86352": 0.7483473420143127, "aqua_rat_42415": 0.7493024468421936, "TheoremQA_maxku/cv-colorsci4-hsi.json": 0.7511925101280212, "aqua_rat_37735": 0.7515010237693787, "aqua_rat_16002": 0.7521734237670898, "aqua_rat_56838": 0.7524590492248535, "aqua_rat_1658": 0.7525241374969482, "aqua_rat_78694": 0.754091203212738, "aqua_rat_5931": 0.7541657090187073, "aqua_rat_53426": 0.7557381987571716, "aqua_rat_24892": 0.7568041682243347, "aqua_rat_50736": 0.7600231170654297, "aqua_rat_84280": 0.7668473124504089, "aqua_rat_35390": 0.7677001357078552, "gsm_train_19996": 0.7688400745391846, "gsm_rft_23405": 0.7688400745391846, "gsm_rft_17183": 0.7715408205986023, "aqua_rat_10760": 0.7747558355331421, "aqua_rat_54992": 0.7789322733879089, "aqua_rat_18162": 0.7839707136154175, "aqua_rat_47586": 0.7892459034919739, "aqua_rat_87245": 0.7892894148826599, "aqua_rat_63536": 0.7901270985603333, "aqua_rat_22474": 0.7953281402587891}, "TheoremQA_wenhuchen/trapezoidal_rule3.json": {"camel_40274": 0, "camel_7762": 0, "camel_7113": 0, "camel_7688": 0, "camel_6282": 0, "camel_7766": 0, "camel_7076": 0, "camel_7110": 0, "camel_7048": 0, "camel_7820": 0, "camel_7065": 0, "camel_40313": 0, "camel_7695": 0, "camel_6249": 0, "camel_6272": 0, "camel_7101": 0, "camel_7108": 0, "camel_6247": 0, "camel_7068": 0, "camel_7304": 0, "camel_7075": 0, "camel_7818": 0, "camel_7060": 0, "camel_7083": 0, "camel_7057": 0, "camel_7080": 0, "camel_40261": 0, "camel_6291": 0, "camel_6317": 0, "camel_6316": 0, "camel_7780": 0, "camel_6261": 0, "camel_7778": 0, "camel_7050": 0, "camel_7099": 0, "camel_6293": 0, "camel_7833": 0, "camel_6166": 0, "camel_7115": 0, "camel_7085": 0, "camel_7346": 0, "camel_7096": 0, "camel_41216": 0, "camel_7086": 0, "camel_7821": 0, "camel_7763": 0, "camel_6309": 0, "camel_7078": 0, "camel_7814": 0, "camel_7114": 0, "camel_7292": 0, "camel_7829": 0, "camel_7104": 0, "camel_7046": 0, "camel_6280": 0, "camel_6290": 0, "camel_7805": 0, "camel_7309": 0, "camel_7791": 0, "camel_6255": 0, "camel_6262": 0, "camel_6269": 0, "camel_7797": 0, "camel_7775": 0, "camel_7102": 0, "camel_7772": 0, "camel_7106": 0, "camel_6284": 0, "camel_7784": 0, "camel_7832": 0, "camel_7058": 0, "camel_7063": 0, "camel_7796": 0, "camel_7760": 0, "camel_7839": 0, "camel_7816": 0, "camel_7819": 0, "camel_6252": 0, "camel_6294": 0, "camel_7837": 0, "camel_6307": 0, "camel_7831": 0, "camel_7835": 0, "camel_7802": 0, "camel_7773": 0, "camel_7785": 0, "camel_7817": 0, "camel_7767": 0, "camel_7764": 0, "camel_7043": 0, "camel_7804": 0, "camel_7041": 0, "camel_7052": 0, "camel_6167": 0, "camel_7071": 0, "camel_7061": 0, "camel_7100": 0, "camel_6286": 0, "camel_7812": 0, "camel_7808": 0, "camel_7823": 0, "camel_7793": 0, "camel_7768": 0, "camel_40280": 0, "camel_7087": 0, "camel_7815": 0, "camel_7089": 0, "camel_6250": 0, "camel_7770": 0, "camel_7107": 0, "camel_7117": 0, "camel_7836": 0, "camel_7830": 0, "camel_7798": 0, "camel_6312": 0, "camel_7769": 0, "camel_6983": 0, "camel_7334": 0, "TheoremQA_wenhuchen/trapezoidal_rule3.json": 0, "camel_7781": 0, "camel_6275": 0, "camel_6313": 0, "camel_7093": 0, "camel_7786": 0, "camel_7834": 0, "camel_6299": 0, "camel_7838": 0, "camel_7826": 0, "camel_7822": 0, "camel_6165": 0, "camel_7825": 0, "camel_7092": 0, "camel_7801": 0, "camel_6254": 0, "camel_7783": 0, "camel_7054": 0, "camel_7811": 0, "camel_6292": 0, "camel_7824": 0, "camel_6306": 0, "camel_6253": 0, "camel_6266": 0, "camel_7800": 0, "camel_6285": 0, "camel_7081": 0, "camel_6288": 0, "camel_6315": 0, "camel_6318": 0, "camel_6297": 0, "camel_6298": 0, "camel_7803": 0, "camel_6243": 0, "camel_6264": 0, "camel_6265": 0, "camel_6276": 0, "camel_7779": 0, "camel_6314": 0, "camel_6311": 0, "camel_7731": 0, "camel_6305": 0, "camel_6242": 0, "camel_6274": 0, "camel_6245": 0, "camel_6301": 0, "camel_6263": 0, "camel_6302": 0, "camel_6241": 0, "aqua_rat_2145": 0.7400802969932556, "aqua_rat_67474": 0.7407277822494507, "aqua_rat_3172": 0.7410693168640137, "gsm_rft_28906": 0.7411960959434509, "camel_19568": 0.7418647408485413, "camel_5327": 0.7427784204483032, "aqua_rat_5347": 0.7436197996139526, "camel_39579": 0.7437098026275635, "gsm_rft_27927": 0.7441381812095642, "gsm_rft_10281": 0.7443408370018005, "camel_5282": 0.7451428174972534, "gsm_rft_9807": 0.7455676794052124, "gsm_train_35547": 0.7458496689796448, "camel_45941": 0.7460140585899353, "gsm_rft_32158": 0.7464646100997925, "camel_39190": 0.7464827299118042, "aqua_rat_72501": 0.7468587160110474, "aqua_rat_54918": 0.7470067739486694, "camel_38121": 0.7474641799926758, "gsm_rft_20964": 0.7475659847259521, "camel_39590": 0.747636616230011, "camel_5307": 0.748434841632843, "camel_5351": 0.7512775659561157, "aqua_rat_18628": 0.7518055438995361, "aqua_rat_4685": 0.7519770264625549, "aqua_rat_7876": 0.7525225281715393, "aqua_rat_14981": 0.7544012069702148, "camel_39544": 0.7552262544631958, "aqua_rat_88034": 0.7555202841758728, "aqua_rat_4376": 0.7576132416725159, "aqua_rat_39251": 0.7585914134979248, "TheoremQA_wenhuchen/trapezoidal_rule2.json": 0.7599479556083679, "camel_19895": 0.7670962810516357}, "TheoremQA_elainewan/math_calculus_3_8.json": {"camel_6861": 0, "camel_7487": 0, "camel_6831": 0, "camel_6825": 0, "camel_6854": 0, "camel_7513": 0, "camel_6830": 0, "camel_6832": 0, "camel_6834": 0, "camel_6877": 0, "camel_6811": 0, "camel_6808": 0, "camel_7961": 0, "camel_7472": 0, "camel_6805": 0, "camel_6857": 0, "camel_7217": 0, "camel_6803": 0, "camel_6809": 0, "camel_6867": 0, "camel_6801": 0, "camel_6833": 0, "camel_6839": 0, "camel_6816": 0, "camel_7497": 0, "camel_6849": 0, "camel_6836": 0, "camel_6802": 0, "camel_6879": 0, "camel_6822": 0, "camel_7053": 0, "camel_6865": 0, "camel_6837": 0, "camel_6817": 0, "camel_6819": 0, "camel_6874": 0, "camel_6851": 0, "camel_6824": 0, "camel_6820": 0, "camel_6632": 0, "camel_7249": 0, "camel_6876": 0, "camel_6852": 0, "camel_6863": 0, "camel_6594": 0, "TheoremQA_elainewan/math_calculus_3_8.json": 0, "aqua_rat_48696": 0.775258481502533, "camel_5861": 0.7752696871757507, "camel_5272": 0.7755221128463745, "camel_5129": 0.7757776975631714, "aqua_rat_45660": 0.7758541107177734, "camel_19711": 0.7758817672729492, "aqua_rat_59830": 0.7759401798248291, "camel_5883": 0.7761210799217224, "aqua_rat_86356": 0.7763016819953918, "camel_19746": 0.7765470147132874, "aqua_rat_23397": 0.7765740752220154, "camel_28068": 0.7766296863555908, "camel_5970": 0.7766385078430176, "camel_28842": 0.7766967415809631, "camel_5995": 0.7768117189407349, "camel_5615": 0.7770781517028809, "camel_5853": 0.777381181716919, "camel_28909": 0.7774212956428528, "camel_19726": 0.7775861024856567, "camel_5952": 0.7776327729225159, "camel_19680": 0.7777681350708008, "aqua_rat_16291": 0.7777979373931885, "camel_47813": 0.7779481410980225, "camel_5922": 0.7780444622039795, "camel_19753": 0.7781195640563965, "camel_4179": 0.7781515121459961, "camel_5936": 0.7782363891601562, "camel_5920": 0.778308093547821, "camel_5037": 0.7784003019332886, "camel_4988": 0.778501033782959, "camel_5962": 0.7785030007362366, "camel_4232": 0.7785531282424927, "aqua_rat_44770": 0.7789252996444702, "aqua_rat_33061": 0.7792465686798096, "math_train_geometry_1008": 0.7793176770210266, "aqua_rat_29761": 0.779356062412262, "camel_5933": 0.7795372009277344, "aqua_rat_46186": 0.779776394367218, "aqua_rat_11620": 0.7799739837646484, "camel_5662": 0.7800630927085876, "aqua_rat_51549": 0.7802137732505798, "camel_5893": 0.7802789807319641, "camel_28024": 0.7803043723106384, "aqua_rat_71780": 0.7804921269416809, "camel_5227": 0.7807410955429077, "aqua_rat_9508": 0.7808809280395508, "camel_4175": 0.7811397314071655, "camel_4813": 0.7812773585319519, "camel_4550": 0.7814024090766907, "camel_5967": 0.7818557620048523, "camel_5930": 0.7819072604179382, "camel_5940": 0.7819536328315735, "aqua_rat_20605": 0.7822167277336121, "camel_5938": 0.7824366688728333, "aqua_rat_66974": 0.7824520468711853, "aqua_rat_6676": 0.7825915813446045, "camel_5198": 0.7830623984336853, "camel_5055": 0.7831571698188782, "camel_47373": 0.783206582069397, "camel_5172": 0.7833141088485718, "camel_5197": 0.7834222912788391, "camel_5334": 0.7837957739830017, "camel_5158": 0.7838236689567566, "aqua_rat_43469": 0.784064531326294, "aqua_rat_3802": 0.7841326594352722, "gsm_rft_2338": 0.7842273116111755, "TheoremQA_elainewan/math_calculus_14.json": 0.7842419743537903, "camel_5955": 0.7846069931983948, "camel_28022": 0.7848162055015564, "gsm_rft_2985": 0.7850771546363831, "aqua_rat_74869": 0.7854587435722351, "camel_4992": 0.7854810953140259, "camel_5948": 0.7857254147529602, "gsm_train_32410": 0.7857753038406372, "camel_45315": 0.7858960032463074, "camel_39443": 0.7859467267990112, "aqua_rat_18320": 0.7864403128623962, "camel_5988": 0.7866840362548828, "camel_5980": 0.7868913412094116, "aqua_rat_15482": 0.7869954109191895, "camel_5284": 0.7872079610824585, "camel_5311": 0.7873426079750061, "camel_19718": 0.7873674035072327, "camel_5177": 0.7873997688293457, "gsm_rft_18987": 0.7875153422355652, "camel_19750": 0.7883490920066833, "aqua_rat_46515": 0.7885540723800659, "camel_5899": 0.7886685132980347, "camel_5854": 0.7889729142189026, "camel_5105": 0.7898702621459961, "TheoremQA_xinyi/newtons_laws_1.json": 0.7907792329788208, "camel_47347": 0.7909542322158813, "aqua_rat_69929": 0.7910018563270569, "camel_5840": 0.7911521196365356, "aqua_rat_20932": 0.7915042638778687, "camel_5849": 0.7915139198303223, "aqua_rat_7575": 0.7918058037757874, "camel_5014": 0.7919158935546875, "camel_19754": 0.7920845746994019, "aqua_rat_65833": 0.7924045920372009, "aqua_rat_75605": 0.7926284670829773, "camel_4862": 0.7926406264305115, "camel_19717": 0.7926951050758362, "aqua_rat_12010": 0.7928479909896851, "aqua_rat_35903": 0.7928814888000488, "camel_5181": 0.7936378121376038, "camel_29979": 0.7936472296714783, "aqua_rat_71816": 0.7937575578689575, "camel_19647": 0.7938793301582336, "aqua_rat_61332": 0.7942496538162231, "aqua_rat_22455": 0.7945144772529602, "camel_5974": 0.794854998588562, "camel_5041": 0.7949848771095276, "camel_5997": 0.7952755689620972, "math_train_algebra_826": 0.7962422370910645, "camel_5928": 0.7968599796295166, "camel_4969": 0.7976221442222595, "camel_5189": 0.7979118227958679, "TheoremQA_elainewan/math_calculus_12.json": 0.7979692220687866, "camel_5008": 0.7989495992660522, "aqua_rat_43435": 0.7990840077400208, "camel_47290": 0.7996917963027954, "camel_5566": 0.8003278970718384, "camel_19721": 0.8003774285316467, "camel_5092": 0.8005543947219849, "camel_5094": 0.8008526563644409, "camel_5344": 0.800993025302887, "aqua_rat_46219": 0.802333414554596, "camel_4972": 0.8024232387542725, "math_test_geometry_903": 0.8035199046134949, "camel_5043": 0.8035953640937805, "aqua_rat_42233": 0.8038583993911743, "camel_5178": 0.8081972002983093, "camel_19727": 0.809526264667511, "camel_5059": 0.8097942471504211, "camel_4987": 0.8101329207420349, "camel_5093": 0.810310423374176, "camel_4999": 0.8107613325119019, "camel_5165": 0.8136693835258484, "camel_5035": 0.8153892159461975, "camel_5057": 0.8154857754707336, "camel_4986": 0.8162675499916077, "camel_5117": 0.8176225423812866, "camel_5358": 0.8178920149803162, "camel_39503": 0.819341242313385, "camel_5004": 0.8200559020042419, "camel_5070": 0.8202778697013855, "camel_19715": 0.8205569982528687, "camel_5079": 0.822544515132904, "camel_5011": 0.824633777141571, "camel_5114": 0.8259766101837158, "camel_4993": 0.8269504308700562, "camel_4994": 0.8316574096679688, "camel_5029": 0.8422905206680298}, "TheoremQA_jianyu_xu/Binomial_5.json": {"camel_20946": 0, "camel_21202": 0, "camel_20874": 0, "camel_20948": 0, "camel_20260": 0, "camel_20656": 0, "camel_20998": 0, "camel_20293": 0, "camel_21388": 0, "camel_20294": 0, "camel_20246": 0, "camel_21056": 0, "camel_20269": 0, "camel_21386": 0, "camel_21808": 0, "camel_20336": 0, "camel_20611": 0, "camel_20272": 0, "camel_20996": 0, "camel_20512": 0, "camel_20802": 0, "camel_21255": 0, "camel_21215": 0, "camel_20598": 0, "camel_20312": 0, "camel_20256": 0, "camel_20302": 0, "camel_20022": 0, "camel_21530": 0, "camel_20930": 0, "camel_20287": 0, "aqua_rat_50942": 0.8159967660903931, "aqua_rat_76271": 0.8160535097122192, "aqua_rat_15548": 0.8160787224769592, "aqua_rat_52707": 0.8162121772766113, "aqua_rat_88698": 0.8162259459495544, "aqua_rat_50290": 0.8163259625434875, "aqua_rat_40137": 0.8164716362953186, "aqua_rat_28657": 0.8164832592010498, "aqua_rat_13647": 0.8165544271469116, "aqua_rat_33834": 0.8166027665138245, "aqua_rat_74248": 0.8166399002075195, "aqua_rat_8260": 0.8167130351066589, "aqua_rat_72660": 0.8167511224746704, "aqua_rat_65642": 0.8168315291404724, "aqua_rat_44130": 0.8168991804122925, "math_test_counting_and_probability_535": 0.8171181678771973, "aqua_rat_72437": 0.8174545168876648, "aqua_rat_78895": 0.8176580667495728, "aqua_rat_72210": 0.8177428245544434, "aqua_rat_72868": 0.817760169506073, "aqua_rat_73040": 0.8179404139518738, "aqua_rat_8402": 0.8179532885551453, "aqua_rat_23582": 0.8179841637611389, "aqua_rat_48666": 0.8181523084640503, "aqua_rat_38594": 0.8182216286659241, "aqua_rat_75767": 0.8182480931282043, "aqua_rat_74550": 0.8183716535568237, "aqua_rat_88418": 0.8188033103942871, "math_train_counting_and_probability_683": 0.8188104629516602, "aqua_rat_58309": 0.8189280033111572, "aqua_rat_2147": 0.8189835548400879, "aqua_rat_63012": 0.8192257285118103, "aqua_rat_77361": 0.8192492127418518, "aqua_rat_35121": 0.8192898035049438, "aqua_rat_78014": 0.8197523951530457, "aqua_rat_56715": 0.8200430274009705, "aqua_rat_58044": 0.8201835751533508, "aqua_rat_29306": 0.8202095031738281, "aqua_rat_43064": 0.8204807639122009, "aqua_rat_89113": 0.8204928040504456, "aqua_rat_84460": 0.8205280900001526, "aqua_rat_58707": 0.8206582069396973, "aqua_rat_37185": 0.8206708431243896, "aqua_rat_64894": 0.8207177519798279, "aqua_rat_7409": 0.8207808136940002, "aqua_rat_29513": 0.8207947015762329, "aqua_rat_12781": 0.8208506107330322, "aqua_rat_8468": 0.8209196925163269, "aqua_rat_29651": 0.8209795355796814, "aqua_rat_16877": 0.82099449634552, "aqua_rat_82087": 0.8211290240287781, "aqua_rat_4294": 0.8211386203765869, "aqua_rat_83206": 0.8212653398513794, "aqua_rat_35015": 0.8212718963623047, "aqua_rat_24963": 0.8213967084884644, "aqua_rat_15615": 0.8213992714881897, "aqua_rat_61885": 0.8214452266693115, "aqua_rat_5150": 0.8215212821960449, "math_train_counting_and_probability_249": 0.821547269821167, "aqua_rat_16762": 0.8216932415962219, "aqua_rat_41775": 0.8218820691108704, "aqua_rat_34242": 0.8219826221466064, "aqua_rat_2630": 0.822026252746582, "aqua_rat_9713": 0.8223417401313782, "aqua_rat_70803": 0.8227900862693787, "aqua_rat_67179": 0.8228700757026672, "camel_38505": 0.8228879570960999, "aqua_rat_12795": 0.8231613636016846, "aqua_rat_4811": 0.8233177065849304, "aqua_rat_42445": 0.8235264420509338, "aqua_rat_40108": 0.8235378265380859, "aqua_rat_4954": 0.8236035704612732, "math_test_counting_and_probability_1033": 0.8238577842712402, "aqua_rat_55590": 0.8238915801048279, "aqua_rat_22214": 0.8246179223060608, "aqua_rat_79094": 0.8247607350349426, "aqua_rat_8673": 0.8248696327209473, "aqua_rat_7341": 0.8249428868293762, "aqua_rat_779": 0.8250541687011719, "aqua_rat_53149": 0.8251214027404785, "aqua_rat_89175": 0.8252236247062683, "aqua_rat_59747": 0.8252556324005127, "aqua_rat_46850": 0.8252648711204529, "aqua_rat_78074": 0.8253895044326782, "aqua_rat_63254": 0.8254019021987915, "aqua_rat_371": 0.82540363073349, "aqua_rat_25181": 0.8256404399871826, "aqua_rat_47506": 0.8257186412811279, "aqua_rat_19502": 0.8259387612342834, "aqua_rat_53852": 0.8260889649391174, "aqua_rat_12398": 0.826093316078186, "aqua_rat_13243": 0.8260941505432129, "aqua_rat_39390": 0.826414167881012, "aqua_rat_66465": 0.8277673125267029, "aqua_rat_78732": 0.8278682231903076, "aqua_rat_28183": 0.8280079364776611, "aqua_rat_24776": 0.8280503749847412, "aqua_rat_54446": 0.8281906247138977, "aqua_rat_74695": 0.8282907605171204, "aqua_rat_84398": 0.8287795782089233, "aqua_rat_72310": 0.8289968371391296, "aqua_rat_41506": 0.8294764757156372, "aqua_rat_89302": 0.8296834230422974, "aqua_rat_73122": 0.8297439217567444, "aqua_rat_34678": 0.829933226108551, "aqua_rat_60936": 0.8299872279167175, "math_train_counting_and_probability_918": 0.8300203084945679, "aqua_rat_39411": 0.8301390409469604, "aqua_rat_42881": 0.8303371667861938, "aqua_rat_71578": 0.8304755091667175, "aqua_rat_75780": 0.8305906057357788, "aqua_rat_71649": 0.8309260010719299, "aqua_rat_84957": 0.8309329748153687, "aqua_rat_55783": 0.831214189529419, "aqua_rat_73365": 0.8316193222999573, "aqua_rat_83332": 0.8318882584571838, "aqua_rat_25421": 0.831896185874939, "aqua_rat_81997": 0.8320169448852539, "aqua_rat_86468": 0.8320353031158447, "aqua_rat_48676": 0.8321276903152466, "aqua_rat_64131": 0.8325532078742981, "aqua_rat_18452": 0.8326220512390137, "aqua_rat_35292": 0.8328737020492554, "aqua_rat_37223": 0.8328858613967896, "aqua_rat_49270": 0.8333675265312195, "aqua_rat_50541": 0.8337739706039429, "aqua_rat_58323": 0.8352964520454407, "math_test_counting_and_probability_216": 0.8355345129966736, "aqua_rat_31957": 0.835544764995575, "aqua_rat_84736": 0.836581289768219, "aqua_rat_27914": 0.8370285630226135, "aqua_rat_74651": 0.837551474571228, "aqua_rat_57095": 0.8377598524093628, "math_test_counting_and_probability_776": 0.8382478356361389, "aqua_rat_22507": 0.8384889960289001, "aqua_rat_42333": 0.8386061787605286, "aqua_rat_70861": 0.8386451005935669, "aqua_rat_57693": 0.8395549654960632, "aqua_rat_79193": 0.8397843241691589, "aqua_rat_28538": 0.8398056030273438, "aqua_rat_11347": 0.8398245573043823, "aqua_rat_64653": 0.8403635025024414, "aqua_rat_62645": 0.8405827283859253, "aqua_rat_30109": 0.8406477570533752, "aqua_rat_10102": 0.840787947177887, "aqua_rat_42155": 0.8420122265815735, "aqua_rat_73601": 0.8430238366127014, "aqua_rat_81265": 0.8431308269500732, "aqua_rat_13918": 0.8433744311332703, "aqua_rat_72708": 0.8438279032707214, "aqua_rat_66841": 0.8438428640365601, "aqua_rat_60755": 0.8444950580596924, "aqua_rat_62903": 0.844656765460968, "aqua_rat_32732": 0.844857394695282, "aqua_rat_33533": 0.8454574942588806, "aqua_rat_51384": 0.8457280397415161, "aqua_rat_3934": 0.8463455438613892, "aqua_rat_68198": 0.8469846844673157, "aqua_rat_43584": 0.8526200652122498, "aqua_rat_89036": 0.8535879254341125, "aqua_rat_35395": 0.8545083403587341, "aqua_rat_57246": 0.8545180559158325, "aqua_rat_87992": 0.855319082736969, "aqua_rat_84364": 0.8571900725364685, "camel_38541": 0.8573585152626038, "aqua_rat_35517": 0.8599474430084229, "aqua_rat_51723": 0.8603719472885132, "aqua_rat_15917": 0.8643285632133484, "aqua_rat_23041": 0.8722245693206787}, "TheoremQA_elainewan/econ_micro_7_2.json": {"camel_24647": 0, "camel_25156": 0, "camel_25147": 0, "camel_25513": 0, "camel_25276": 0, "camel_25289": 0, "camel_24242": 0, "camel_25359": 0, "camel_25243": 0, "camel_25253": 0, "camel_24707": 0, "camel_24713": 0, "camel_25296": 0, "camel_25446": 0, "camel_25203": 0, "camel_25224": 0, "camel_25207": 0, "camel_25345": 0, "camel_24664": 0, "camel_25220": 0, "camel_25136": 0, "camel_25278": 0, "camel_25321": 0, "camel_25356": 0, "camel_25159": 0, "camel_25219": 0, "camel_25124": 0, "camel_25281": 0, "camel_25217": 0, "camel_25292": 0, "camel_25287": 0, "camel_25171": 0, "camel_25239": 0, "camel_25332": 0, "camel_25268": 0, "camel_25221": 0, "camel_25863": 0, "camel_24706": 0, "camel_25214": 0, "camel_25299": 0, "camel_24273": 0, "camel_25270": 0, "camel_24684": 0, "camel_25263": 0, "camel_25125": 0, "camel_25309": 0, "camel_25958": 0, "camel_25181": 0, "camel_25308": 0, "camel_25693": 0, "camel_25261": 0, "camel_25314": 0, "camel_25291": 0, "camel_25226": 0, "camel_25189": 0, "camel_25316": 0, "camel_25340": 0, "camel_25251": 0, "camel_25302": 0, "camel_25241": 0, "camel_25357": 0, "camel_25334": 0, "camel_25294": 0, "camel_25337": 0, "TheoremQA_elainewan/econ_micro_7_2.json": 0, "camel_25341": 0, "camel_25121": 0, "camel_25188": 0, "camel_25257": 0, "camel_25230": 0, "camel_25152": 0, "camel_25213": 0, "camel_25688": 0, "camel_25282": 0, "camel_25176": 0, "camel_24676": 0, "camel_25168": 0, "camel_25315": 0, "camel_25227": 0, "camel_25295": 0, "camel_25185": 0, "camel_25279": 0, "camel_25322": 0, "camel_25307": 0, "camel_25305": 0, "camel_25892": 0, "camel_25198": 0, "camel_25349": 0, "camel_24715": 0, "camel_25496": 0, "camel_25212": 0, "camel_25269": 0, "camel_25244": 0, "camel_25318": 0, "camel_25335": 0, "camel_10506": 0.784956693649292, "camel_10482": 0.786300539970398, "camel_38648": 0.7865098118782043, "camel_37704": 0.7865450382232666, "camel_38692": 0.7873783707618713, "camel_10498": 0.7877702116966248, "aqua_rat_41336": 0.7881302237510681, "camel_38795": 0.7883475422859192, "camel_10512": 0.788417398929596, "camel_10525": 0.7887176871299744, "camel_10505": 0.7896970510482788, "camel_10502": 0.7911274433135986, "camel_10497": 0.7921996712684631, "camel_10526": 0.7923117876052856, "camel_38709": 0.7924590110778809, "camel_37741": 0.7925481200218201, "camel_37651": 0.7926005721092224, "camel_37722": 0.7927342653274536, "camel_10544": 0.792762279510498, "gsm_train_23349": 0.7930012941360474, "gsm_rft_21285": 0.7930012941360474, "gsm_rft_28392": 0.7933536171913147, "camel_10553": 0.7936919927597046, "camel_10519": 0.7938517928123474, "camel_10515": 0.7941178679466248, "camel_37680": 0.7949560284614563, "camel_37736": 0.795725405216217, "camel_38643": 0.7959158420562744, "camel_10481": 0.7959447503089905, "camel_39399": 0.7964891195297241, "camel_10531": 0.7967301607131958, "camel_10529": 0.7968258857727051, "camel_38678": 0.7968992590904236, "camel_37692": 0.7969573736190796, "camel_38645": 0.7970784902572632, "camel_38686": 0.7984444499015808, "camel_37718": 0.7988803386688232, "camel_37725": 0.7989290356636047, "camel_39366": 0.799547016620636, "camel_10546": 0.8005995750427246, "camel_37739": 0.8006738424301147, "camel_10541": 0.8008283376693726, "gsm_rft_32682": 0.8009135723114014, "camel_38693": 0.8012480139732361, "camel_37669": 0.8016269207000732, "camel_37693": 0.8019713163375854, "camel_10488": 0.8021774291992188, "camel_8334": 0.8026732206344604, "camel_37710": 0.8038947582244873, "camel_37685": 0.8040966987609863, "camel_38699": 0.8048187494277954, "camel_37758": 0.805149257183075, "camel_10491": 0.8054397702217102, "camel_37703": 0.8055232763290405, "camel_37709": 0.8062795996665955, "camel_37745": 0.8063836097717285, "camel_37714": 0.8066827654838562, "camel_37740": 0.8067797422409058, "camel_37751": 0.8070370554924011, "camel_10499": 0.8075288534164429, "camel_37629": 0.8084824681282043, "camel_38714": 0.8087273836135864, "camel_10240": 0.8094626665115356, "camel_38666": 0.8098729848861694, "camel_10551": 0.8101241588592529, "camel_37699": 0.810822606086731, "camel_37721": 0.8109018802642822, "camel_37683": 0.8110707998275757, "camel_37738": 0.8115454912185669, "camel_37696": 0.8117916584014893, "camel_10305": 0.8124744892120361, "camel_37724": 0.8136834502220154, "camel_37701": 0.8138582110404968, "camel_10507": 0.8143623471260071, "camel_37757": 0.8144883513450623, "camel_10517": 0.8148089051246643, "camel_37756": 0.8150358200073242, "camel_10540": 0.815176248550415, "camel_37749": 0.8157132267951965, "camel_10493": 0.8166197538375854, "camel_37691": 0.8166913986206055, "camel_10537": 0.8168707489967346, "camel_37706": 0.8176733255386353, "camel_10545": 0.8179453015327454, "camel_10514": 0.8182011842727661, "camel_37716": 0.818679928779602, "camel_10532": 0.8187317252159119, "camel_37730": 0.8200060129165649, "camel_37635": 0.8200139999389648, "camel_10284": 0.8203173875808716, "camel_37723": 0.8212648034095764, "camel_37708": 0.8223859667778015, "camel_37742": 0.8225045204162598, "camel_37750": 0.8234182000160217, "camel_37682": 0.8236302733421326, "camel_38689": 0.8247426748275757, "camel_37687": 0.825313925743103, "camel_37697": 0.825553297996521, "camel_37744": 0.828525185585022, "camel_37700": 0.8289501070976257, "camel_37752": 0.8325526714324951, "TheoremQA_elainewan/econ_micro_18.json": 0.8331594467163086, "camel_39397": 0.8363256454467773, "camel_37729": 0.8386279344558716, "camel_38662": 0.8404659032821655}, "TheoremQA_xueguangma/effective_rates_1.json": {"TheoremQA_xueguangma/effective_rates_1.json": 0, "aqua_rat_86517": 0.761400043964386, "aqua_rat_64422": 0.7620291709899902, "gsm_rft_12217": 0.762066125869751, "aqua_rat_85275": 0.7621682286262512, "aqua_rat_44549": 0.7622135877609253, "aqua_rat_58518": 0.7623300552368164, "aqua_rat_46158": 0.7623302936553955, "gsm_rft_22915": 0.7625531554222107, "aqua_rat_21326": 0.7630285024642944, "aqua_rat_86234": 0.7632071375846863, "aqua_rat_59098": 0.7632165551185608, "aqua_rat_51332": 0.7635062336921692, "aqua_rat_5907": 0.7635430097579956, "aqua_rat_34698": 0.7637031674385071, "aqua_rat_40489": 0.7637892365455627, "gsm_rft_31902": 0.7643826603889465, "aqua_rat_15764": 0.7648788690567017, "aqua_rat_63512": 0.7651486992835999, "aqua_rat_32321": 0.7657521963119507, "aqua_rat_82669": 0.7659770250320435, "gsm_rft_7180": 0.7663460969924927, "gsm_train_5941": 0.7663460969924927, "aqua_rat_30447": 0.766618549823761, "aqua_rat_58694": 0.7667587995529175, "aqua_rat_50447": 0.7667650580406189, "aqua_rat_43060": 0.7668306827545166, "aqua_rat_15471": 0.7668755650520325, "aqua_rat_33006": 0.7670243382453918, "aqua_rat_18510": 0.7671866416931152, "math_train_algebra_1011": 0.7682036757469177, "gsm_rft_25658": 0.7691336870193481, "aqua_rat_49963": 0.7699769139289856, "aqua_rat_49718": 0.7699773907661438, "aqua_rat_3773": 0.7701147794723511, "aqua_rat_32851": 0.7701447606086731, "math_train_algebra_1658": 0.7701629400253296, "gsm_train_11462": 0.7705367207527161, "gsm_rft_14102": 0.7705367207527161, "aqua_rat_86308": 0.7707861661911011, "aqua_rat_75817": 0.7709414958953857, "aqua_rat_60064": 0.7716304659843445, "aqua_rat_47882": 0.7716596722602844, "aqua_rat_34332": 0.7717322707176208, "aqua_rat_34082": 0.7723868489265442, "aqua_rat_71142": 0.7726929783821106, "TheoremQA_wenhuchen/compound_interest1.json": 0.7730080485343933, "aqua_rat_17751": 0.7738768458366394, "aqua_rat_27543": 0.7741681933403015, "aqua_rat_83740": 0.7756209969520569, "aqua_rat_57943": 0.7757161259651184, "aqua_rat_29356": 0.7757335305213928, "aqua_rat_30717": 0.7757812142372131, "math_test_algebra_1862": 0.7759573459625244, "aqua_rat_66803": 0.7770335674285889, "aqua_rat_47773": 0.7770369052886963, "aqua_rat_75833": 0.7771238684654236, "aqua_rat_85721": 0.7777207493782043, "aqua_rat_33923": 0.7780702114105225, "aqua_rat_10990": 0.7781126499176025, "gsm_train_25622": 0.7782405614852905, "gsm_rft_11620": 0.7788696885108948, "gsm_rft_6559": 0.7798760533332825, "gsm_rft_5849": 0.7807416319847107, "aqua_rat_80246": 0.7809017896652222, "aqua_rat_53568": 0.7809576988220215, "aqua_rat_46552": 0.781078040599823, "aqua_rat_36240": 0.7811951041221619, "math_test_algebra_608": 0.7814573645591736, "aqua_rat_69447": 0.7817514538764954, "aqua_rat_70031": 0.7821534276008606, "aqua_rat_79715": 0.7823076248168945, "math_train_algebra_369": 0.7823619246482849, "aqua_rat_49908": 0.7825631499290466, "aqua_rat_51548": 0.7826278209686279, "aqua_rat_20488": 0.7830598950386047, "aqua_rat_53914": 0.7831295132637024, "aqua_rat_48358": 0.7834978103637695, "aqua_rat_6415": 0.7835742235183716, "aqua_rat_51740": 0.7836567759513855, "aqua_rat_53819": 0.7837664484977722, "aqua_rat_25723": 0.7838171720504761, "aqua_rat_1115": 0.784005880355835, "aqua_rat_34775": 0.7840666174888611, "aqua_rat_75046": 0.7841053605079651, "math_train_algebra_2306": 0.7843431830406189, "aqua_rat_53336": 0.7847829461097717, "math_test_algebra_594": 0.7852357029914856, "aqua_rat_66371": 0.7857775092124939, "aqua_rat_34263": 0.7859717607498169, "aqua_rat_24532": 0.7868511080741882, "aqua_rat_3402": 0.7876799702644348, "aqua_rat_13239": 0.7891004681587219, "math_test_algebra_82": 0.7894148826599121, "aqua_rat_42017": 0.7895722389221191, "aqua_rat_29976": 0.7899168729782104, "aqua_rat_48494": 0.7900325059890747, "aqua_rat_39049": 0.7912121415138245, "aqua_rat_15743": 0.7913033366203308, "aqua_rat_37258": 0.7913074493408203, "aqua_rat_73739": 0.791654646396637, "aqua_rat_56718": 0.7924961447715759, "aqua_rat_7674": 0.7925552725791931, "aqua_rat_68014": 0.7928138971328735, "aqua_rat_71239": 0.7928513288497925, "aqua_rat_33430": 0.7931146025657654, "aqua_rat_25162": 0.7933186888694763, "aqua_rat_63070": 0.7933274507522583, "math_test_algebra_2626": 0.7936091423034668, "aqua_rat_8658": 0.7943019866943359, "aqua_rat_17663": 0.7944847345352173, "aqua_rat_69905": 0.7945457696914673, "aqua_rat_28984": 0.7951641082763672, "aqua_rat_16448": 0.7964746356010437, "aqua_rat_44930": 0.7968636155128479, "aqua_rat_21814": 0.7973293662071228, "aqua_rat_46898": 0.7974313497543335, "aqua_rat_56852": 0.7979808449745178, "aqua_rat_32852": 0.7981257438659668, "TheoremQA_xueguangma/effective_rates_2.json": 0.7984926700592041, "aqua_rat_73390": 0.7984960079193115, "math_train_algebra_957": 0.7987667918205261, "aqua_rat_12597": 0.8001610040664673, "aqua_rat_10686": 0.8005119562149048, "aqua_rat_2257": 0.800992488861084, "aqua_rat_69547": 0.8010345697402954, "aqua_rat_78121": 0.8011075258255005, "aqua_rat_38657": 0.8011456727981567, "aqua_rat_20423": 0.8011491298675537, "math_test_algebra_337": 0.8012097477912903, "aqua_rat_28883": 0.8013707399368286, "aqua_rat_88174": 0.8015919923782349, "aqua_rat_6679": 0.8018360733985901, "aqua_rat_14414": 0.8030859231948853, "aqua_rat_72687": 0.8031303882598877, "aqua_rat_30386": 0.8033024668693542, "aqua_rat_21728": 0.8033351898193359, "aqua_rat_51796": 0.8035392761230469, "aqua_rat_87589": 0.8040323257446289, "aqua_rat_1549": 0.80423903465271, "aqua_rat_6180": 0.804435670375824, "aqua_rat_32350": 0.8047329187393188, "aqua_rat_59892": 0.8052532076835632, "aqua_rat_82806": 0.8061177730560303, "aqua_rat_42733": 0.8068326711654663, "aqua_rat_72794": 0.8072486519813538, "aqua_rat_84309": 0.8076330423355103, "aqua_rat_26976": 0.8077782392501831, "aqua_rat_59": 0.8078036308288574, "aqua_rat_86835": 0.8083716630935669, "aqua_rat_58298": 0.8086522817611694, "aqua_rat_735": 0.8098728656768799, "aqua_rat_67076": 0.8101793527603149, "aqua_rat_59829": 0.8106399178504944, "aqua_rat_31334": 0.8111078143119812, "aqua_rat_62727": 0.8114616870880127, "aqua_rat_10582": 0.8115226030349731, "aqua_rat_54481": 0.8118929266929626, "aqua_rat_2618": 0.8120818734169006, "aqua_rat_17404": 0.8129058480262756, "aqua_rat_869": 0.812936544418335, "aqua_rat_63322": 0.8150287866592407, "aqua_rat_83839": 0.8154956102371216, "aqua_rat_51100": 0.816230833530426, "aqua_rat_15079": 0.8174996972084045, "aqua_rat_56129": 0.8177161812782288, "aqua_rat_75047": 0.8190034627914429, "aqua_rat_6566": 0.8192971348762512, "math_train_algebra_667": 0.8193308711051941, "aqua_rat_60493": 0.8196660280227661, "aqua_rat_88415": 0.8202860355377197, "math_test_algebra_311": 0.8204149007797241, "aqua_rat_79047": 0.8208103775978088, "aqua_rat_40411": 0.8208988904953003, "aqua_rat_68693": 0.8213392496109009, "aqua_rat_78533": 0.8221244812011719, "aqua_rat_53431": 0.8232111930847168, "aqua_rat_65964": 0.823223888874054, "aqua_rat_3687": 0.8246421813964844, "aqua_rat_26425": 0.8259859681129456, "aqua_rat_88003": 0.826267421245575, "aqua_rat_54664": 0.8283534049987793, "aqua_rat_42515": 0.8284200429916382, "aqua_rat_50660": 0.8293065428733826, "math_train_algebra_767": 0.8297951221466064, "aqua_rat_19784": 0.8322538733482361, "aqua_rat_64105": 0.8333420157432556, "aqua_rat_24052": 0.8336232304573059, "aqua_rat_61400": 0.8336319327354431, "aqua_rat_38900": 0.834601640701294, "aqua_rat_88758": 0.8372682332992554, "aqua_rat_45867": 0.841651439666748, "aqua_rat_3885": 0.8521607518196106, "aqua_rat_46315": 0.8538239598274231, "aqua_rat_21626": 0.8541041612625122, "aqua_rat_20758": 0.8556106686592102, "aqua_rat_72737": 0.856320858001709, "aqua_rat_36461": 0.8610639572143555, "aqua_rat_41963": 0.8611982464790344, "aqua_rat_42949": 0.8612587451934814}, "TheoremQA_jianyu_xu/Multinomial_4.json": {"camel_20549": 0, "camel_21233": 0, "camel_20987": 0, "camel_20447": 0, "camel_20297": 0, "camel_20249": 0, "camel_20730": 0, "camel_21029": 0, "camel_20332": 0, "camel_20038": 0, "camel_21028": 0, "camel_20783": 0, "camel_20244": 0, "camel_20545": 0, "camel_20356": 0, "camel_20988": 0, "camel_20973": 0, "camel_20985": 0, "camel_20951": 0, "camel_20175": 0, "camel_20519": 0, "camel_20283": 0, "math_test_counting_and_probability_36": 0.8054586052894592, "aqua_rat_73969": 0.8054887056350708, "aqua_rat_4294": 0.805595874786377, "aqua_rat_36127": 0.8056803941726685, "aqua_rat_48793": 0.8056843280792236, "aqua_rat_84146": 0.8058031797409058, "aqua_rat_2480": 0.8058083653450012, "aqua_rat_3729": 0.8058578372001648, "aqua_rat_46658": 0.8059014081954956, "aqua_rat_46484": 0.8059961795806885, "aqua_rat_27623": 0.8060864806175232, "aqua_rat_46116": 0.8061038851737976, "aqua_rat_61793": 0.8061426877975464, "aqua_rat_88236": 0.8061570525169373, "aqua_rat_58077": 0.8061818480491638, "aqua_rat_62840": 0.8064021468162537, "aqua_rat_25285": 0.8064586520195007, "aqua_rat_71998": 0.806532621383667, "aqua_rat_80880": 0.8065458536148071, "aqua_rat_78519": 0.8066155314445496, "math_train_prealgebra_408": 0.8066918849945068, "aqua_rat_73402": 0.8067511320114136, "aqua_rat_67061": 0.8068937063217163, "math_train_counting_and_probability_925": 0.8069639801979065, "aqua_rat_59360": 0.8069673180580139, "aqua_rat_2640": 0.8069677352905273, "aqua_rat_80121": 0.8072352409362793, "aqua_rat_31694": 0.8072637915611267, "aqua_rat_26857": 0.8073256015777588, "aqua_rat_17738": 0.8073490858078003, "aqua_rat_17329": 0.8073654174804688, "aqua_rat_80321": 0.807488739490509, "aqua_rat_75182": 0.8078376054763794, "aqua_rat_58195": 0.8078721761703491, "aqua_rat_17184": 0.8078838586807251, "aqua_rat_13585": 0.8079551458358765, "aqua_rat_39833": 0.807998538017273, "aqua_rat_14535": 0.8081566095352173, "aqua_rat_89113": 0.8082267642021179, "aqua_rat_5247": 0.8082488775253296, "aqua_rat_2072": 0.8082983493804932, "aqua_rat_35638": 0.8083484768867493, "math_train_counting_and_probability_1032": 0.8084133863449097, "aqua_rat_74550": 0.8085283041000366, "aqua_rat_19231": 0.8085787892341614, "aqua_rat_39966": 0.8086063265800476, "aqua_rat_35669": 0.8086671233177185, "aqua_rat_15196": 0.8088398575782776, "aqua_rat_11652": 0.8089186549186707, "aqua_rat_66723": 0.8090317845344543, "aqua_rat_38599": 0.8092761635780334, "aqua_rat_56544": 0.8093189597129822, "aqua_rat_67588": 0.8093273043632507, "aqua_rat_55249": 0.8095108866691589, "aqua_rat_7035": 0.8096221685409546, "aqua_rat_74542": 0.8096480965614319, "aqua_rat_86117": 0.8097081184387207, "aqua_rat_24104": 0.8097230792045593, "aqua_rat_50221": 0.8097459673881531, "aqua_rat_18404": 0.8101552128791809, "aqua_rat_63880": 0.8102904558181763, "aqua_rat_25182": 0.8103011846542358, "aqua_rat_55627": 0.810478150844574, "aqua_rat_29935": 0.8105009198188782, "aqua_rat_14173": 0.8106595277786255, "aqua_rat_80157": 0.8106983304023743, "aqua_rat_53190": 0.8107309341430664, "aqua_rat_7373": 0.8108333945274353, "aqua_rat_13701": 0.8112444877624512, "aqua_rat_16439": 0.8114002346992493, "aqua_rat_72671": 0.811549723148346, "aqua_rat_32332": 0.8116365671157837, "aqua_rat_18803": 0.8116844892501831, "aqua_rat_29319": 0.8117401003837585, "aqua_rat_11242": 0.8119063973426819, "aqua_rat_29651": 0.8121532797813416, "aqua_rat_56247": 0.8122479915618896, "aqua_rat_67953": 0.8125155568122864, "aqua_rat_73122": 0.8126983642578125, "aqua_rat_16877": 0.8127145171165466, "aqua_rat_27835": 0.8128951191902161, "aqua_rat_51352": 0.8130807876586914, "aqua_rat_9727": 0.8131952881813049, "aqua_rat_56615": 0.8132855296134949, "aqua_rat_74743": 0.8133982419967651, "aqua_rat_17735": 0.8133991360664368, "aqua_rat_83505": 0.8137380480766296, "aqua_rat_34214": 0.8137596845626831, "aqua_rat_77579": 0.8138245344161987, "math_train_prealgebra_1167": 0.8138458132743835, "aqua_rat_60936": 0.813953697681427, "aqua_rat_58473": 0.8139799237251282, "aqua_rat_63885": 0.8140958547592163, "aqua_rat_49273": 0.8141839504241943, "aqua_rat_67694": 0.8142551183700562, "math_train_counting_and_probability_441": 0.8146551251411438, "aqua_rat_14321": 0.8152554035186768, "aqua_rat_28086": 0.8152647018432617, "aqua_rat_1550": 0.8154087662696838, "aqua_rat_40108": 0.8157180547714233, "aqua_rat_55986": 0.8157714605331421, "aqua_rat_38573": 0.815995454788208, "aqua_rat_55663": 0.8160364031791687, "aqua_rat_10800": 0.8161976933479309, "aqua_rat_66552": 0.8164941072463989, "aqua_rat_36159": 0.8165218830108643, "aqua_rat_37487": 0.816775918006897, "aqua_rat_38774": 0.8168140649795532, "aqua_rat_58075": 0.8168531656265259, "aqua_rat_61885": 0.8171043395996094, "aqua_rat_36385": 0.8179112672805786, "aqua_rat_72012": 0.8182194232940674, "aqua_rat_32025": 0.8182706832885742, "aqua_rat_47456": 0.8183399438858032, "aqua_rat_34678": 0.8188157081604004, "aqua_rat_37506": 0.8195468187332153, "aqua_rat_59342": 0.8199384808540344, "aqua_rat_34268": 0.8202463388442993, "aqua_rat_22599": 0.8202725648880005, "aqua_rat_4355": 0.8203290700912476, "aqua_rat_45187": 0.8207799792289734, "aqua_rat_51800": 0.8208757042884827, "aqua_rat_36022": 0.8209585547447205, "aqua_rat_69444": 0.8210513591766357, "aqua_rat_4340": 0.8211893439292908, "aqua_rat_13225": 0.8214777112007141, "aqua_rat_89246": 0.8214831352233887, "aqua_rat_50550": 0.8215492367744446, "aqua_rat_27137": 0.821615993976593, "aqua_rat_31049": 0.8221097588539124, "aqua_rat_27207": 0.8226332068443298, "aqua_rat_41645": 0.8227787017822266, "aqua_rat_73109": 0.8228069543838501, "math_test_prealgebra_1107": 0.8231741189956665, "aqua_rat_593": 0.8235822319984436, "aqua_rat_13164": 0.8239002823829651, "aqua_rat_77275": 0.8240039348602295, "aqua_rat_75975": 0.8240792155265808, "aqua_rat_19798": 0.8240821957588196, "aqua_rat_11143": 0.8245185613632202, "aqua_rat_63250": 0.8247710466384888, "aqua_rat_59942": 0.8247841596603394, "aqua_rat_16429": 0.8248533010482788, "aqua_rat_79918": 0.8248878717422485, "aqua_rat_81021": 0.8258219957351685, "aqua_rat_45147": 0.826004147529602, "math_test_prealgebra_1204": 0.8260488510131836, "aqua_rat_58208": 0.8269582390785217, "aqua_rat_60662": 0.827150285243988, "aqua_rat_35796": 0.8272035717964172, "math_train_counting_and_probability_1099": 0.827495276927948, "math_train_counting_and_probability_29": 0.8276134133338928, "aqua_rat_86519": 0.8285098671913147, "aqua_rat_32954": 0.8287783861160278, "aqua_rat_22118": 0.8288708925247192, "aqua_rat_37766": 0.8290690779685974, "aqua_rat_9005": 0.8301123380661011, "aqua_rat_65284": 0.8309921622276306, "aqua_rat_69596": 0.8322087526321411, "aqua_rat_35991": 0.8334100842475891, "aqua_rat_20032": 0.8335724472999573, "aqua_rat_69806": 0.8340210318565369, "aqua_rat_64457": 0.8342612385749817, "aqua_rat_15466": 0.8343053460121155, "aqua_rat_21632": 0.8343089818954468, "aqua_rat_8913": 0.8370279669761658, "aqua_rat_34136": 0.8391873240470886, "aqua_rat_19714": 0.8403932452201843, "aqua_rat_58870": 0.8430861830711365, "aqua_rat_9747": 0.8434658050537109, "aqua_rat_9063": 0.8436633348464966, "aqua_rat_41332": 0.8455362915992737, "aqua_rat_28709": 0.8464542627334595, "aqua_rat_45246": 0.8468670845031738, "aqua_rat_15353": 0.8525989055633545, "aqua_rat_66661": 0.8536220192909241, "aqua_rat_80293": 0.8544451594352722, "aqua_rat_16417": 0.8557000756263733}, "TheoremQA_maxku/cv-colorsci1-rgb.json": {"TheoremQA_maxku/cv-colorsci1-rgb.json": 0, "aqua_rat_65113": 0.6191513538360596, "aqua_rat_6342": 0.6191863417625427, "gsm_rft_7633": 0.6192196011543274, "gsm_rft_15022": 0.6192207336425781, "gsm_rft_32389": 0.6192777752876282, "gsm_rft_34616": 0.6192916035652161, "gsm_rft_32944": 0.6193622350692749, "aqua_rat_79345": 0.619401752948761, "math_test_prealgebra_1741": 0.6194191575050354, "gsm_rft_19470": 0.6194650530815125, "gsm_train_28434": 0.6196557879447937, "aqua_rat_49371": 0.6198516488075256, "gsm_rft_15856": 0.6200314164161682, "gsm_rft_14803": 0.6200509667396545, "aqua_rat_84478": 0.6201980710029602, "gsm_rft_17019": 0.6202762126922607, "gsm_train_18440": 0.6202762126922607, "aqua_rat_52771": 0.6203873753547668, "gsm_rft_493": 0.6204785704612732, "gsm_rft_11441": 0.620517373085022, "gsm_rft_26915": 0.6205360293388367, "aqua_rat_72416": 0.6207940578460693, "gsm_train_9280": 0.6208112239837646, "gsm_rft_1777": 0.6208112239837646, "aqua_rat_10760": 0.6208727359771729, "gsm_rft_22340": 0.6210190057754517, "gsm_rft_32041": 0.6210487484931946, "gsm_rft_32921": 0.6211047172546387, "gsm_rft_4843": 0.6211633086204529, "gsm_train_21508": 0.6212469935417175, "gsm_rft_5056": 0.6213195323944092, "gsm_rft_2105": 0.6213209629058838, "gsm_rft_12591": 0.6213977932929993, "gsm_train_22109": 0.6213977932929993, "gsm_rft_31436": 0.6215561032295227, "gsm_rft_5163": 0.6216711401939392, "gsm_rft_15413": 0.6217094659805298, "camel_49846": 0.621827244758606, "camel_18671": 0.6219452619552612, "gsm_train_30430": 0.6220200657844543, "aqua_rat_6933": 0.6220901012420654, "camel_27982": 0.622177243232727, "gsm_rft_251": 0.6222041249275208, "gsm_rft_29861": 0.6222368478775024, "gsm_train_18947": 0.6222368478775024, "gsm_rft_31758": 0.62225341796875, "gsm_rft_24925": 0.6222957968711853, "gsm_train_27821": 0.6222957968711853, "aqua_rat_34769": 0.6223553419113159, "gsm_train_18529": 0.6225435137748718, "aqua_rat_63536": 0.6225442290306091, "gsm_rft_24705": 0.6225906014442444, "aqua_rat_38540": 0.6226623058319092, "gsm_rft_18771": 0.6226649880409241, "gsm_rft_29411": 0.622726321220398, "gsm_rft_23405": 0.6227759122848511, "gsm_train_19996": 0.6227759122848511, "camel_13806": 0.6229758262634277, "aqua_rat_34033": 0.6231682896614075, "gsm_rft_9461": 0.6232050061225891, "gsm_rft_3862": 0.6233099699020386, "camel_44424": 0.6234360933303833, "math_train_counting_and_probability_580": 0.6235247254371643, "gsm_rft_30981": 0.6237567663192749, "gsm_rft_13638": 0.6238235831260681, "gsm_rft_12710": 0.6239060759544373, "gsm_rft_34182": 0.624069333076477, "gsm_rft_24703": 0.6241440773010254, "gsm_rft_21510": 0.6241670250892639, "aqua_rat_32834": 0.6241748929023743, "gsm_rft_3737": 0.6244081258773804, "gsm_rft_14505": 0.6244579553604126, "camel_20425": 0.6244591474533081, "gsm_train_29660": 0.6244969367980957, "camel_36754": 0.624509334564209, "aqua_rat_59265": 0.6246170401573181, "gsm_rft_27243": 0.6249212622642517, "gsm_train_27431": 0.6249212622642517, "gsm_rft_30399": 0.6250036358833313, "gsm_rft_34814": 0.6252022981643677, "aqua_rat_39612": 0.6252199411392212, "gsm_rft_5985": 0.625592052936554, "gsm_rft_16741": 0.6256781816482544, "aqua_rat_7648": 0.6259829998016357, "aqua_rat_32472": 0.6260302066802979, "gsm_rft_17183": 0.6261066794395447, "gsm_rft_6315": 0.6261129379272461, "gsm_train_24910": 0.6263056993484497, "gsm_rft_3146": 0.626352846622467, "gsm_rft_32215": 0.6265360116958618, "aqua_rat_5877": 0.6267741322517395, "gsm_rft_10389": 0.6267848014831543, "aqua_rat_4648": 0.6268810629844666, "gsm_rft_13217": 0.6268872022628784, "gsm_rft_10212": 0.6270490884780884, "gsm_train_12649": 0.6270899176597595, "gsm_rft_29535": 0.6273490190505981, "gsm_rft_15386": 0.627432107925415, "camel_36357": 0.6274440884590149, "gsm_rft_6576": 0.6279197335243225, "gsm_rft_30455": 0.6279335618019104, "camel_20172": 0.6279900670051575, "gsm_rft_23733": 0.6285105347633362, "gsm_rft_3024": 0.6285667419433594, "gsm_rft_9763": 0.6286333203315735, "aqua_rat_28450": 0.6287263035774231, "gsm_rft_9791": 0.6287356019020081, "gsm_rft_31898": 0.628746509552002, "gsm_rft_34166": 0.6287481784820557, "gsm_rft_23738": 0.6287481784820557, "gsm_train_28486": 0.6287481784820557, "aqua_rat_47586": 0.6288648247718811, "aqua_rat_11272": 0.6289008259773254, "gsm_rft_13434": 0.6289276480674744, "gsm_rft_29186": 0.6290395855903625, "gsm_rft_6621": 0.6292335391044617, "gsm_rft_16476": 0.6294560432434082, "gsm_rft_23571": 0.6299837827682495, "gsm_rft_10479": 0.6300085186958313, "gsm_train_24988": 0.6301231384277344, "gsm_rft_10349": 0.6301400065422058, "camel_36363": 0.6302739381790161, "gsm_rft_22314": 0.6302928924560547, "gsm_rft_16275": 0.6304168701171875, "gsm_rft_14882": 0.6305581331253052, "gsm_train_6284": 0.6307823657989502, "gsm_rft_19557": 0.6308963894844055, "aqua_rat_7700": 0.6309693455696106, "gsm_train_125": 0.6310431957244873, "gsm_rft_28857": 0.6310431957244873, "gsm_rft_23008": 0.6320011019706726, "gsm_rft_10607": 0.632068932056427, "aqua_rat_84727": 0.6325567364692688, "aqua_rat_87221": 0.6327221393585205, "gsm_rft_29435": 0.6328727006912231, "gsm_rft_31148": 0.6330435872077942, "gsm_rft_13838": 0.6331294775009155, "gsm_rft_23472": 0.6337371468544006, "gsm_train_33000": 0.6339533925056458, "gsm_rft_3218": 0.6339533925056458, "gsm_rft_35008": 0.6342859864234924, "math_train_prealgebra_353": 0.6344968676567078, "aqua_rat_41911": 0.6348386406898499, "gsm_rft_24906": 0.6349590420722961, "gsm_rft_30300": 0.6350411176681519, "gsm_rft_9540": 0.6352314949035645, "gsm_train_29739": 0.6352314949035645, "gsm_rft_15326": 0.6353288888931274, "aqua_rat_76846": 0.6354013085365295, "gsm_rft_26309": 0.6355590224266052, "gsm_rft_25326": 0.6355875134468079, "aqua_rat_64294": 0.6356118321418762, "gsm_rft_23876": 0.6358217597007751, "gsm_rft_30157": 0.6359284520149231, "aqua_rat_87245": 0.6360181570053101, "gsm_rft_33841": 0.6361921429634094, "gsm_train_16544": 0.6362507939338684, "gsm_rft_23497": 0.6363535523414612, "gsm_rft_1690": 0.6364398002624512, "gsm_rft_31285": 0.6365652084350586, "gsm_train_26494": 0.6365652084350586, "gsm_rft_15804": 0.6365971565246582, "gsm_rft_15722": 0.6366351842880249, "gsm_rft_24803": 0.6367143988609314, "camel_20413": 0.6368472576141357, "gsm_rft_16817": 0.6370199918746948, "gsm_train_35467": 0.6370278596878052, "gsm_train_13923": 0.6371286511421204, "gsm_rft_9738": 0.6371632814407349, "gsm_rft_24202": 0.6371632814407349, "gsm_rft_26902": 0.6374842524528503, "gsm_rft_18784": 0.637713611125946, "math_train_counting_and_probability_715": 0.6377812623977661, "camel_44741": 0.6382965445518494, "gsm_rft_1422": 0.6385165452957153, "gsm_rft_35627": 0.638538658618927, "gsm_rft_11927": 0.6386451125144958, "gsm_rft_11414": 0.6386451125144958, "gsm_rft_27034": 0.6387596130371094, "gsm_rft_8013": 0.6388040781021118, "aqua_rat_85357": 0.6388571262359619, "gsm_train_24856": 0.6388850212097168, "gsm_train_4068": 0.6392052173614502, "camel_21233": 0.6395418047904968, "aqua_rat_19096": 0.6395821571350098, "gsm_rft_34974": 0.6399077773094177, "gsm_rft_16775": 0.641878068447113, "gsm_rft_18016": 0.6428588032722473, "gsm_rft_159": 0.6454683542251587, "gsm_train_15116": 0.6454683542251587, "gsm_rft_4658": 0.6463456153869629, "aqua_rat_22474": 0.6543116569519043, "TheoremQA_maxku/cv-imageprocessing10-digital-image.json": 0.6667051911354065, "camel_36295": 0.6695713996887207, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.6712589263916016, "TheoremQA_maxku/cv-colorsci4-hsi.json": 0.6813822388648987, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0.702303409576416, "TheoremQA_maxku/cv-colorsci2-hsi.json": 0.7041065692901611, "TheoremQA_maxku/cv-colorsci3-rgb.json": 0.7437543272972107}, "TheoremQA_panlu/similarity3.json": {"camel_3267": 0, "camel_3222": 0, "TheoremQA_panlu/similarity3.json": 0, "camel_3237": 0, "camel_3219": 0, "camel_3203": 0, "camel_3240": 0, "camel_3275": 0, "camel_3235": 0, "camel_3223": 0, "camel_3251": 0, "camel_3233": 0, "camel_3207": 0, "camel_3208": 0, "camel_3238": 0, "math_test_geometry_634": 0, "camel_3234": 0, "camel_3204": 0, "camel_3250": 0, "math_test_geometry_433": 0, "camel_3229": 0, "camel_3221": 0, "camel_3247": 0, "camel_3211": 0, "camel_3998": 0, "camel_3205": 0, "camel_3961": 0, "math_train_geometry_809": 0, "camel_3259": 0, "camel_3244": 0, "camel_3213": 0, "camel_3276": 0, "math_train_geometry_350": 0, "camel_3951": 0, "camel_3988": 0, "camel_3274": 0, "camel_3246": 0, "camel_3218": 0, "camel_3226": 0, "camel_3243": 0, "camel_3239": 0, "camel_3262": 0, "camel_3249": 0, "camel_3264": 0, "camel_3230": 0, "camel_3236": 0, "camel_3939": 0, "camel_3269": 0, "camel_3981": 0, "camel_3272": 0, "camel_3206": 0, "camel_3248": 0, "camel_3217": 0, "camel_3270": 0, "camel_3989": 0, "camel_3925": 0, "math_train_geometry_694": 0, "camel_2745": 0, "camel_3241": 0, "camel_3934": 0, "camel_3202": 0, "camel_3954": 0, "math_train_geometry_272": 0, "math_train_geometry_804": 0, "math_train_geometry_636": 0, "aqua_rat_47522": 0.7670266628265381, "aqua_rat_24553": 0.767065703868866, "aqua_rat_31626": 0.7675037980079651, "aqua_rat_21994": 0.767566442489624, "aqua_rat_54286": 0.7677583694458008, "camel_18695": 0.7679274082183838, "aqua_rat_84589": 0.7679847478866577, "math_train_prealgebra_1943": 0.768437922000885, "aqua_rat_79604": 0.7684903144836426, "aqua_rat_53060": 0.7684988379478455, "aqua_rat_11528": 0.7685139775276184, "gsm_rft_11783": 0.7685719132423401, "gsm_train_22251": 0.7685719132423401, "gsm_rft_4293": 0.7685719132423401, "aqua_rat_66122": 0.7686514258384705, "aqua_rat_62729": 0.7687340378761292, "aqua_rat_27892": 0.7688362002372742, "aqua_rat_964": 0.7688682675361633, "aqua_rat_68945": 0.7688948512077332, "aqua_rat_43993": 0.7689144015312195, "aqua_rat_6742": 0.7691088914871216, "aqua_rat_47444": 0.769210159778595, "aqua_rat_82269": 0.7693082690238953, "aqua_rat_73457": 0.7694135308265686, "aqua_rat_11558": 0.7694964408874512, "gsm_rft_27714": 0.769661545753479, "aqua_rat_2100": 0.7697009444236755, "aqua_rat_63454": 0.7697576880455017, "aqua_rat_41018": 0.7698237299919128, "math_train_prealgebra_1919": 0.7698259949684143, "aqua_rat_10513": 0.7699412703514099, "aqua_rat_80634": 0.7700021862983704, "aqua_rat_57816": 0.7700928449630737, "aqua_rat_22832": 0.7701641321182251, "aqua_rat_88865": 0.7702044248580933, "aqua_rat_35191": 0.7703988552093506, "gsm_rft_881": 0.7707561254501343, "aqua_rat_38963": 0.7710179090499878, "aqua_rat_60805": 0.7710252404212952, "aqua_rat_65543": 0.7711862921714783, "aqua_rat_86050": 0.7712500691413879, "aqua_rat_21659": 0.771253228187561, "gsm_train_33962": 0.7712560892105103, "aqua_rat_68615": 0.7712704539299011, "aqua_rat_59462": 0.7712851166725159, "aqua_rat_51469": 0.771308183670044, "aqua_rat_73119": 0.7713109254837036, "aqua_rat_46334": 0.7714457511901855, "math_test_prealgebra_1154": 0.7715743780136108, "aqua_rat_55386": 0.7716623544692993, "aqua_rat_25937": 0.7716805338859558, "aqua_rat_31651": 0.7716936469078064, "gsm_rft_23551": 0.7717119455337524, "aqua_rat_35895": 0.7717493176460266, "aqua_rat_74046": 0.7718229293823242, "aqua_rat_46418": 0.7718295454978943, "aqua_rat_12657": 0.7719916105270386, "aqua_rat_34355": 0.7720094323158264, "gsm_rft_18078": 0.772025465965271, "gsm_rft_604": 0.7721213698387146, "aqua_rat_25214": 0.7724884152412415, "aqua_rat_50119": 0.7725675106048584, "aqua_rat_31615": 0.7729641199111938, "aqua_rat_49039": 0.7734290957450867, "aqua_rat_51497": 0.7734777331352234, "aqua_rat_46305": 0.7735583782196045, "aqua_rat_83024": 0.7741797566413879, "aqua_rat_52689": 0.7745278477668762, "aqua_rat_34219": 0.7746034264564514, "aqua_rat_86238": 0.7746478319168091, "aqua_rat_38464": 0.7751139998435974, "camel_38916": 0.7752442955970764, "aqua_rat_25987": 0.775263249874115, "aqua_rat_30560": 0.7752679586410522, "aqua_rat_71170": 0.7753716111183167, "aqua_rat_4256": 0.7756766676902771, "aqua_rat_32103": 0.7758159637451172, "aqua_rat_23657": 0.7764252424240112, "aqua_rat_78695": 0.7767224907875061, "aqua_rat_30114": 0.7767740488052368, "aqua_rat_52886": 0.7767879962921143, "aqua_rat_35944": 0.7770307064056396, "aqua_rat_82212": 0.7771528959274292, "aqua_rat_27097": 0.7771760821342468, "aqua_rat_6785": 0.7771801948547363, "aqua_rat_22619": 0.7772445678710938, "aqua_rat_71832": 0.7776138186454773, "aqua_rat_8837": 0.7780376672744751, "aqua_rat_3357": 0.7781293988227844, "aqua_rat_71002": 0.7781800627708435, "aqua_rat_69391": 0.7785484790802002, "aqua_rat_69445": 0.7788310050964355, "aqua_rat_26054": 0.7792682647705078, "aqua_rat_66321": 0.7792683243751526, "camel_4737": 0.779499888420105, "aqua_rat_4020": 0.7795369029045105, "aqua_rat_57712": 0.7796251773834229, "aqua_rat_73491": 0.7796851992607117, "aqua_rat_51406": 0.7802035212516785, "aqua_rat_86892": 0.7811852693557739, "aqua_rat_44109": 0.7816521525382996, "aqua_rat_67621": 0.783430814743042, "aqua_rat_72722": 0.7835028767585754, "aqua_rat_41306": 0.7836809754371643, "aqua_rat_30186": 0.7844104170799255, "aqua_rat_45935": 0.7847122550010681, "aqua_rat_87552": 0.7853389978408813, "aqua_rat_41026": 0.7854185700416565, "aqua_rat_74464": 0.7857125401496887, "aqua_rat_10906": 0.7857142090797424, "aqua_rat_80461": 0.7857753038406372, "aqua_rat_60233": 0.7865245938301086, "aqua_rat_86615": 0.7866967916488647, "aqua_rat_1569": 0.7869349122047424, "aqua_rat_40813": 0.7874280214309692, "aqua_rat_34112": 0.7887203693389893, "aqua_rat_6553": 0.7893996834754944, "aqua_rat_55057": 0.7900174856185913, "aqua_rat_76843": 0.7905015349388123, "aqua_rat_37605": 0.7913936376571655, "aqua_rat_54093": 0.7920122742652893, "math_train_prealgebra_606": 0.7929589748382568, "aqua_rat_12240": 0.7931390404701233, "aqua_rat_48835": 0.7948355674743652, "aqua_rat_86522": 0.7967470288276672, "aqua_rat_51855": 0.7976933717727661, "aqua_rat_25578": 0.7987505793571472, "aqua_rat_40399": 0.8002275228500366, "gsm_rft_26471": 0.8065640926361084, "gsm_train_9974": 0.8065640926361084, "gsm_rft_30397": 0.8065640926361084, "gsm_rft_33960": 0.8070394396781921, "aqua_rat_9227": 0.819132387638092, "camel_18647": 0.83616042137146, "math_test_prealgebra_1586": 0.8380493521690369}, "TheoremQA_maxku/cv-cnn1.json": {"TheoremQA_maxku/cv-cnn1.json": 0, "gsm_rft_2925": 0.6885595917701721, "gsm_rft_10682": 0.688610315322876, "gsm_train_705": 0.6886700987815857, "gsm_rft_9537": 0.6886813044548035, "gsm_rft_18527": 0.6886813044548035, "gsm_rft_12834": 0.6887255311012268, "gsm_rft_22312": 0.6888136267662048, "aqua_rat_84253": 0.6888920068740845, "gsm_rft_5731": 0.6889355182647705, "gsm_train_24148": 0.6889779567718506, "gsm_rft_14419": 0.6890233755111694, "gsm_rft_575": 0.6890584826469421, "gsm_rft_31275": 0.6890590190887451, "gsm_rft_23708": 0.6890685558319092, "gsm_train_4545": 0.6890685558319092, "gsm_rft_27215": 0.6890776753425598, "gsm_rft_3111": 0.689146876335144, "gsm_rft_33841": 0.6892136335372925, "gsm_rft_21524": 0.6894480586051941, "gsm_rft_7130": 0.6895725131034851, "gsm_rft_9475": 0.6896597743034363, "gsm_rft_25889": 0.6897401809692383, "aqua_rat_16513": 0.6897657513618469, "aqua_rat_38167": 0.6898305416107178, "gsm_rft_1425": 0.6898651719093323, "gsm_train_27703": 0.6899226903915405, "gsm_rft_31655": 0.6899235248565674, "gsm_rft_1103": 0.6899248361587524, "gsm_rft_29148": 0.6899906992912292, "gsm_rft_33581": 0.6900182962417603, "gsm_train_30509": 0.6900182962417603, "gsm_rft_3386": 0.6901159286499023, "gsm_train_31313": 0.6901159286499023, "gsm_rft_14380": 0.6901848316192627, "gsm_rft_11414": 0.6901868581771851, "gsm_rft_11927": 0.6901868581771851, "gsm_rft_21580": 0.6902794241905212, "math_train_prealgebra_353": 0.6903284192085266, "gsm_rft_16932": 0.6903749704360962, "gsm_train_24856": 0.6905732750892639, "gsm_rft_8921": 0.6905863881111145, "gsm_rft_22799": 0.690737783908844, "aqua_rat_43893": 0.6908423900604248, "gsm_rft_34240": 0.6908949613571167, "gsm_rft_21356": 0.6909219026565552, "gsm_rft_18410": 0.6910820007324219, "aqua_rat_45378": 0.6911870241165161, "gsm_rft_7513": 0.6913484334945679, "gsm_rft_31497": 0.6914300918579102, "gsm_train_33655": 0.6914300918579102, "gsm_train_8683": 0.6917039752006531, "gsm_rft_1995": 0.6917696595191956, "gsm_train_9463": 0.6917696595191956, "gsm_rft_17206": 0.6917971968650818, "gsm_rft_1805": 0.6918137669563293, "gsm_train_7154": 0.6918469667434692, "gsm_rft_22763": 0.6919152736663818, "camel_44746": 0.6919684410095215, "gsm_rft_32969": 0.6920238733291626, "gsm_rft_16215": 0.6921034455299377, "camel_44782": 0.6921982169151306, "gsm_rft_25621": 0.6922198534011841, "gsm_train_34775": 0.6923412084579468, "gsm_rft_19111": 0.6924088597297668, "camel_44724": 0.6924622058868408, "math_test_prealgebra_1279": 0.69249427318573, "camel_44779": 0.6925822496414185, "aqua_rat_12780": 0.6925987601280212, "camel_44723": 0.6926171183586121, "gsm_rft_26539": 0.6927112340927124, "camel_44760": 0.6927331686019897, "gsm_train_22411": 0.6927973031997681, "camel_39339": 0.6928302049636841, "gsm_rft_27782": 0.6929223537445068, "gsm_rft_12347": 0.6929552555084229, "gsm_rft_13197": 0.6929900050163269, "gsm_rft_9864": 0.6930133700370789, "gsm_train_8130": 0.693047821521759, "gsm_rft_35138": 0.693047821521759, "math_test_prealgebra_969": 0.6930545568466187, "gsm_rft_30981": 0.6930936574935913, "gsm_train_18529": 0.6931247115135193, "gsm_rft_18442": 0.6931716203689575, "gsm_train_18640": 0.6931716203689575, "gsm_rft_34047": 0.6936112642288208, "gsm_rft_14507": 0.6936675310134888, "gsm_rft_13283": 0.6938067078590393, "gsm_train_26255": 0.6939190030097961, "gsm_rft_29903": 0.6939190030097961, "gsm_rft_33847": 0.693967878818512, "gsm_rft_35029": 0.6940000057220459, "camel_44799": 0.6940116286277771, "gsm_rft_14096": 0.6941239833831787, "gsm_rft_34085": 0.6943502426147461, "gsm_rft_7911": 0.6945922374725342, "gsm_rft_146": 0.6947216391563416, "camel_18719": 0.6947374939918518, "gsm_rft_7352": 0.6948041319847107, "gsm_train_32872": 0.6948041319847107, "camel_44775": 0.6948408484458923, "gsm_rft_23576": 0.6949344277381897, "gsm_rft_6392": 0.6950171589851379, "gsm_rft_33076": 0.6950171589851379, "gsm_train_29880": 0.6950171589851379, "gsm_train_15116": 0.6952282786369324, "gsm_rft_159": 0.6952282786369324, "gsm_train_9652": 0.6953123211860657, "gsm_rft_18087": 0.6954110860824585, "gsm_train_16316": 0.6954110860824585, "gsm_rft_3643": 0.6954151391983032, "gsm_train_13069": 0.6954151391983032, "gsm_rft_16939": 0.6954598426818848, "gsm_rft_7754": 0.6955146193504333, "gsm_rft_27312": 0.6955426335334778, "gsm_rft_33011": 0.6956039667129517, "gsm_rft_3973": 0.6956422328948975, "gsm_rft_31776": 0.6956928968429565, "aqua_rat_34528": 0.6957054734230042, "gsm_rft_22880": 0.6958261728286743, "gsm_rft_2359": 0.6958649158477783, "gsm_rft_31518": 0.6958941221237183, "camel_45936": 0.6959609985351562, "gsm_rft_4658": 0.6959714889526367, "gsm_rft_35639": 0.6959843635559082, "gsm_train_22690": 0.6960371732711792, "gsm_rft_23591": 0.6960371732711792, "camel_40840": 0.6961072087287903, "gsm_rft_15171": 0.6963684558868408, "gsm_rft_7696": 0.6964443325996399, "TheoremQA_maxku/cv-imageprocessing10-digital-image.json": 0.6966767907142639, "camel_44767": 0.6968719363212585, "gsm_rft_2329": 0.6968808174133301, "gsm_rft_33004": 0.6974798440933228, "gsm_rft_1660": 0.6976356506347656, "gsm_rft_12854": 0.6981009244918823, "TheoremQA_maxku/cv-colorsci1-rgb.json": 0.6982251405715942, "gsm_rft_33771": 0.6992937326431274, "camel_44735": 0.6994149684906006, "camel_30229": 0.6996618509292603, "gsm_rft_25774": 0.6999983787536621, "camel_44772": 0.700576663017273, "gsm_rft_14030": 0.7008745074272156, "gsm_rft_398": 0.7014445662498474, "gsm_rft_35121": 0.7018622159957886, "gsm_rft_6053": 0.7020320296287537, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0.7023815512657166, "camel_30474": 0.7025087475776672, "gsm_rft_9950": 0.7026800513267517, "camel_44787": 0.703083872795105, "aqua_rat_229": 0.7031499743461609, "gsm_rft_34505": 0.7037466764450073, "gsm_rft_29593": 0.7053178548812866, "gsm_rft_13006": 0.7057968974113464, "gsm_train_10809": 0.7058560848236084, "gsm_rft_12896": 0.7058560848236084, "gsm_rft_32313": 0.7060424089431763, "aqua_rat_84808": 0.7063775062561035, "gsm_rft_1361": 0.7066280245780945, "gsm_train_3509": 0.7066280245780945, "gsm_rft_4821": 0.7066280245780945, "aqua_rat_56916": 0.7069941759109497, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.7078564763069153, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.7093610167503357, "TheoremQA_maxku/cv-cnn4.json": 0.7096543908119202, "aqua_rat_433": 0.7096638679504395, "gsm_train_21508": 0.7102126479148865, "gsm_rft_2105": 0.7104739546775818, "camel_30407": 0.7110089063644409, "gsm_train_34667": 0.7110125422477722, "gsm_rft_21534": 0.7110125422477722, "camel_44758": 0.7113761901855469, "gsm_rft_5163": 0.7115028500556946, "gsm_rft_32270": 0.7117370367050171, "gsm_train_27467": 0.7117370367050171, "gsm_rft_22430": 0.711919903755188, "camel_18671": 0.7133392691612244, "aqua_rat_75509": 0.7136050462722778, "camel_30223": 0.7136144042015076, "camel_44785": 0.7152724862098694, "gsm_train_19003": 0.7212328910827637, "gsm_rft_8508": 0.7212328910827637, "gsm_rft_4689": 0.7212328910827637, "camel_44749": 0.72441166639328, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.7261136174201965, "gsm_train_35467": 0.7299826145172119, "gsm_rft_24803": 0.7303004264831543, "camel_44741": 0.7304218411445618, "camel_44790": 0.7311381697654724, "gsm_rft_8013": 0.7316702604293823, "camel_44732": 0.7321484684944153, "camel_44762": 0.7325931787490845, "camel_44750": 0.7328608632087708, "camel_44748": 0.7350596785545349, "camel_44755": 0.738849937915802, "camel_44728": 0.7424463629722595, "camel_44766": 0.7464069128036499, "camel_44424": 0.7569154500961304, "camel_44798": 0.7591332197189331, "camel_17674": 0.7762667536735535}, "TheoremQA_wenhuchen/t_test3.json": {"camel_9709": 0, "camel_9556": 0, "camel_9656": 0, "camel_8079": 0, "camel_8031": 0, "camel_8000": 0, "camel_8712": 0, "camel_9894": 0, "camel_8020": 0, "camel_9602": 0, "camel_8685": 0, "camel_8030": 0, "camel_8255": 0, "camel_8004": 0, "camel_9667": 0, "camel_9950": 0, "camel_8032": 0, "camel_8026": 0, "camel_9389": 0, "camel_8844": 0, "camel_9738": 0, "camel_9902": 0, "camel_9885": 0, "camel_9736": 0, "camel_8017": 0, "camel_9858": 0, "camel_8680": 0, "camel_8970": 0, "camel_9880": 0, "camel_8804": 0, "camel_8883": 0, "camel_9915": 0, "camel_8060": 0, "camel_9672": 0, "camel_8306": 0, "camel_8874": 0, "camel_9704": 0, "camel_8660": 0, "camel_9866": 0, "camel_8715": 0, "camel_9223": 0, "camel_9693": 0, "camel_8698": 0, "camel_8861": 0, "camel_8661": 0, "camel_8873": 0, "camel_9679": 0, "camel_8566": 0, "camel_9872": 0, "camel_8691": 0, "camel_9910": 0, "camel_8817": 0, "camel_9410": 0, "camel_8878": 0, "camel_9432": 0, "camel_8856": 0, "camel_8895": 0, "camel_9978": 0, "camel_8898": 0, "camel_8841": 0, "camel_9657": 0, "camel_8821": 0, "camel_8842": 0, "camel_8867": 0, "camel_8853": 0, "camel_8872": 0, "camel_8836": 0, "camel_8846": 0, "camel_8719": 0, "camel_8072": 0, "camel_8838": 0, "camel_9952": 0, "camel_8830": 0, "camel_8051": 0, "camel_8714": 0, "camel_8825": 0, "camel_8063": 0, "TheoremQA_wenhuchen/t_test3.json": 0, "camel_8934": 0, "camel_8849": 0, "camel_8833": 0, "camel_8855": 0, "camel_8802": 0, "camel_9242": 0, "camel_8819": 0, "camel_8850": 0, "camel_8805": 0, "camel_9392": 0, "camel_9603": 0, "camel_8922": 0, "camel_8812": 0, "camel_8835": 0, "camel_8676": 0, "camel_9900": 0, "camel_8071": 0, "camel_8840": 0, "camel_8876": 0, "camel_9811": 0, "camel_8854": 0, "camel_8864": 0, "camel_8811": 0, "camel_8827": 0, "camel_9874": 0, "camel_8832": 0, "camel_8852": 0, "camel_8921": 0, "camel_8837": 0, "camel_8823": 0, "camel_8646": 0, "camel_9394": 0, "camel_9918": 0, "camel_8920": 0, "camel_8814": 0, "camel_8866": 0, "camel_8847": 0, "camel_8820": 0, "camel_8073": 0, "camel_8654": 0, "camel_8831": 0, "camel_8674": 0, "camel_8885": 0, "camel_8839": 0, "camel_9912": 0, "camel_8656": 0, "camel_9863": 0, "camel_8068": 0, "camel_8009": 0, "camel_8652": 0, "camel_8810": 0, "camel_8843": 0, "camel_8871": 0, "camel_8857": 0, "camel_8665": 0, "camel_9867": 0, "camel_9972": 0, "aqua_rat_14265": 0.8142238855361938, "gsm_rft_22746": 0.8142437934875488, "gsm_rft_32557": 0.8142437934875488, "aqua_rat_82507": 0.8142900466918945, "aqua_rat_45361": 0.8146176338195801, "aqua_rat_42762": 0.8146631121635437, "aqua_rat_1436": 0.814750611782074, "aqua_rat_49293": 0.8148154020309448, "aqua_rat_87732": 0.8148185610771179, "aqua_rat_66872": 0.8152812123298645, "aqua_rat_55613": 0.8153181076049805, "aqua_rat_41231": 0.8154948949813843, "aqua_rat_53261": 0.8155326843261719, "aqua_rat_88531": 0.8155442476272583, "aqua_rat_56608": 0.8156188726425171, "aqua_rat_84948": 0.8157011866569519, "aqua_rat_48419": 0.8157280087471008, "aqua_rat_43145": 0.815744161605835, "aqua_rat_4394": 0.8159873485565186, "aqua_rat_81444": 0.8160008788108826, "aqua_rat_32961": 0.8161746859550476, "aqua_rat_57373": 0.8161970376968384, "aqua_rat_62328": 0.8162494897842407, "aqua_rat_25397": 0.8162806034088135, "aqua_rat_79065": 0.8168285489082336, "aqua_rat_17436": 0.8168759942054749, "aqua_rat_42890": 0.8178209066390991, "aqua_rat_86494": 0.8179853558540344, "aqua_rat_19183": 0.8181517124176025, "aqua_rat_27492": 0.8184930682182312, "aqua_rat_76476": 0.8188896775245667, "aqua_rat_38523": 0.8204952478408813, "aqua_rat_9767": 0.8207634091377258, "aqua_rat_75271": 0.8208246231079102, "aqua_rat_79949": 0.820908784866333, "aqua_rat_67367": 0.8210522532463074, "aqua_rat_36561": 0.8213709592819214, "aqua_rat_74756": 0.8221877217292786, "aqua_rat_45390": 0.8224228620529175, "aqua_rat_73405": 0.8225386142730713, "aqua_rat_79014": 0.8227159976959229, "aqua_rat_26951": 0.8236895203590393, "aqua_rat_53461": 0.8238160610198975, "aqua_rat_67642": 0.8245662450790405, "aqua_rat_21513": 0.8253419995307922, "aqua_rat_55278": 0.8272044062614441, "aqua_rat_55086": 0.8287597894668579, "aqua_rat_59951": 0.8288300037384033, "aqua_rat_43505": 0.8295029401779175, "aqua_rat_53364": 0.8305944204330444, "aqua_rat_9541": 0.8309106230735779, "aqua_rat_83416": 0.8312630653381348, "aqua_rat_5525": 0.8339099287986755, "camel_37940": 0.8340548276901245, "aqua_rat_8925": 0.8343175053596497, "aqua_rat_26184": 0.8343205451965332, "aqua_rat_61448": 0.8366993069648743, "aqua_rat_74055": 0.8375031352043152, "aqua_rat_29275": 0.838458776473999, "aqua_rat_40988": 0.8403459191322327, "camel_37953": 0.8413888216018677, "aqua_rat_40884": 0.8427989482879639, "aqua_rat_17235": 0.8461338877677917, "TheoremQA_wenhuchen/t_test2.json": 0.8756961226463318, "TheoremQA_wenhuchen/t_test1.json": 0.876438558101654}, "TheoremQA_maxku/signalprocessing7-phaseshift.json": {"gsm_rft_32394": 0.7381784319877625, "aqua_rat_2384": 0.7382368445396423, "gsm_rft_4189": 0.7382714152336121, "aqua_rat_1264": 0.738271951675415, "aqua_rat_38243": 0.7383894324302673, "aqua_rat_11568": 0.7384184002876282, "camel_11861": 0.7384911775588989, "aqua_rat_20868": 0.73851478099823, "aqua_rat_48775": 0.7387217879295349, "gsm_rft_33243": 0.738741934299469, "gsm_train_28946": 0.738741934299469, "gsm_rft_30704": 0.738741934299469, "aqua_rat_13506": 0.738763689994812, "gsm_rft_4564": 0.738764226436615, "gsm_rft_194": 0.7387752532958984, "camel_11926": 0.7387934327125549, "aqua_rat_64033": 0.7388819456100464, "aqua_rat_64383": 0.7390196323394775, "aqua_rat_80987": 0.7390367388725281, "gsm_rft_16210": 0.7392038702964783, "gsm_rft_20712": 0.7393603324890137, "gsm_rft_21175": 0.7394360899925232, "aqua_rat_1435": 0.7395616173744202, "aqua_rat_49213": 0.7395733594894409, "gsm_rft_14076": 0.73957359790802, "aqua_rat_86211": 0.7396698594093323, "aqua_rat_36335": 0.7397623658180237, "aqua_rat_70646": 0.7399165034294128, "aqua_rat_33164": 0.7400280833244324, "camel_36242": 0.7400997281074524, "gsm_rft_3744": 0.740436851978302, "gsm_rft_16323": 0.7404887080192566, "gsm_rft_29262": 0.7405391335487366, "gsm_train_29838": 0.7405391335487366, "aqua_rat_71554": 0.7405700087547302, "aqua_rat_66054": 0.7405834794044495, "gsm_rft_8354": 0.7406604886054993, "aqua_rat_6296": 0.7406756281852722, "gsm_rft_28166": 0.7408173680305481, "gsm_rft_15319": 0.7408338189125061, "gsm_rft_11916": 0.740941047668457, "camel_11187": 0.7409688234329224, "gsm_rft_3191": 0.7411180734634399, "gsm_train_9121": 0.7411180734634399, "gsm_rft_22773": 0.7411867380142212, "gsm_rft_29251": 0.7412596940994263, "aqua_rat_36298": 0.7413122057914734, "aqua_rat_37053": 0.741334855556488, "gsm_rft_10606": 0.7416841983795166, "camel_39612": 0.741703987121582, "camel_11988": 0.7421849966049194, "aqua_rat_6761": 0.7422439455986023, "aqua_rat_82468": 0.7422656416893005, "aqua_rat_49245": 0.7422908544540405, "gsm_rft_4857": 0.7423726916313171, "aqua_rat_22368": 0.7424399256706238, "gsm_rft_1248": 0.7424744963645935, "gsm_train_11962": 0.7425090670585632, "gsm_rft_15995": 0.7425090670585632, "aqua_rat_20502": 0.7426086068153381, "gsm_train_33434": 0.7426894307136536, "gsm_rft_32740": 0.7426894307136536, "gsm_rft_15903": 0.7427645921707153, "aqua_rat_86103": 0.7428207397460938, "aqua_rat_85290": 0.7428340911865234, "aqua_rat_17632": 0.742989182472229, "aqua_rat_47200": 0.7431641817092896, "aqua_rat_38240": 0.7435631155967712, "aqua_rat_24053": 0.743565022945404, "aqua_rat_42728": 0.7436044216156006, "aqua_rat_88905": 0.743630588054657, "aqua_rat_24061": 0.7436730861663818, "aqua_rat_23464": 0.7438338994979858, "aqua_rat_66793": 0.7443172335624695, "gsm_rft_5574": 0.7445017099380493, "aqua_rat_51594": 0.7446466088294983, "aqua_rat_64742": 0.7447978258132935, "gsm_rft_34515": 0.7448457479476929, "aqua_rat_62169": 0.7449079155921936, "gsm_rft_6098": 0.7451050877571106, "gsm_rft_21255": 0.74521803855896, "gsm_rft_10046": 0.7452503442764282, "aqua_rat_86315": 0.7454617619514465, "camel_36287": 0.7455723881721497, "math_test_counting_and_probability_162": 0.7458487153053284, "aqua_rat_83469": 0.7459172010421753, "aqua_rat_26590": 0.7459750175476074, "aqua_rat_14667": 0.7459825873374939, "aqua_rat_42937": 0.7460877895355225, "gsm_rft_25625": 0.7461339235305786, "gsm_train_542": 0.746264636516571, "camel_37941": 0.7462751269340515, "gsm_rft_16096": 0.7462789416313171, "aqua_rat_1026": 0.746337354183197, "aqua_rat_48155": 0.7464329600334167, "aqua_rat_81686": 0.7467434406280518, "aqua_rat_60605": 0.7467471957206726, "gsm_train_15066": 0.7467921376228333, "aqua_rat_36319": 0.7471002340316772, "aqua_rat_62869": 0.7471128106117249, "aqua_rat_6661": 0.747259259223938, "gsm_train_33933": 0.7472771406173706, "gsm_rft_20390": 0.7472771406173706, "gsm_rft_25236": 0.7472771406173706, "aqua_rat_15905": 0.7474004030227661, "aqua_rat_52894": 0.7474773526191711, "aqua_rat_30853": 0.747520923614502, "aqua_rat_24936": 0.7477424144744873, "aqua_rat_47751": 0.7477878928184509, "aqua_rat_6577": 0.748060405254364, "aqua_rat_19347": 0.7483250498771667, "aqua_rat_69941": 0.7484297752380371, "aqua_rat_20054": 0.7484481930732727, "aqua_rat_60327": 0.7486361861228943, "aqua_rat_56844": 0.7486575841903687, "gsm_rft_11073": 0.7488851547241211, "aqua_rat_34026": 0.7489826083183289, "aqua_rat_683": 0.7490218281745911, "aqua_rat_43092": 0.749039351940155, "aqua_rat_37698": 0.7493438124656677, "gsm_rft_18896": 0.7495371699333191, "gsm_train_23484": 0.7495371699333191, "aqua_rat_80730": 0.7495625615119934, "aqua_rat_82581": 0.7497380971908569, "aqua_rat_55368": 0.7503556609153748, "gsm_rft_21477": 0.7503701448440552, "aqua_rat_15711": 0.7504191398620605, "aqua_rat_75568": 0.7504728436470032, "aqua_rat_88599": 0.7506296634674072, "gsm_rft_5868": 0.7507254481315613, "aqua_rat_62536": 0.751426100730896, "aqua_rat_28973": 0.7516652941703796, "aqua_rat_21944": 0.7517021298408508, "aqua_rat_45126": 0.7518340945243835, "aqua_rat_87308": 0.7520649433135986, "aqua_rat_40444": 0.7524808049201965, "aqua_rat_50510": 0.7528815269470215, "aqua_rat_46017": 0.7530895471572876, "aqua_rat_76531": 0.753161609172821, "aqua_rat_85660": 0.7532435655593872, "aqua_rat_37149": 0.7536162734031677, "aqua_rat_38747": 0.7538030743598938, "aqua_rat_12229": 0.7542409300804138, "gsm_rft_8901": 0.7543004155158997, "camel_39625": 0.7548176050186157, "aqua_rat_9346": 0.7549294233322144, "aqua_rat_39089": 0.7552959322929382, "aqua_rat_86475": 0.7553486227989197, "aqua_rat_63802": 0.7554826736450195, "camel_10359": 0.7561126351356506, "gsm_train_8631": 0.7561726570129395, "gsm_rft_33601": 0.7563621401786804, "gsm_rft_23806": 0.756392240524292, "gsm_rft_33119": 0.7566635608673096, "aqua_rat_57702": 0.7568032741546631, "aqua_rat_60485": 0.7573589086532593, "camel_39614": 0.7582270503044128, "camel_36307": 0.7591063976287842, "aqua_rat_77027": 0.7591314315795898, "aqua_rat_72840": 0.7596100568771362, "aqua_rat_5337": 0.7598443031311035, "aqua_rat_59336": 0.7598659992218018, "aqua_rat_11220": 0.7601351141929626, "gsm_rft_32000": 0.7607969045639038, "aqua_rat_18701": 0.7608928680419922, "gsm_train_9826": 0.7614744901657104, "gsm_rft_14862": 0.7614744901657104, "aqua_rat_48773": 0.7617992758750916, "gsm_rft_23999": 0.7620662450790405, "aqua_rat_45598": 0.7621666193008423, "aqua_rat_4725": 0.762211263179779, "gsm_rft_27803": 0.7624642252922058, "gsm_rft_4810": 0.7631367444992065, "aqua_rat_27395": 0.7633088827133179, "aqua_rat_34189": 0.763346254825592, "aqua_rat_4849": 0.7642929553985596, "gsm_rft_34909": 0.7645770311355591, "camel_36286": 0.7652501463890076, "aqua_rat_68610": 0.7654270529747009, "gsm_rft_33198": 0.765804648399353, "aqua_rat_89088": 0.7670572400093079, "aqua_rat_77065": 0.7673947811126709, "aqua_rat_27796": 0.7675771117210388, "math_test_number_theory_960": 0.7678815126419067, "aqua_rat_66771": 0.7705249786376953, "aqua_rat_60711": 0.7710040211677551, "gsm_rft_30221": 0.7726116180419922, "aqua_rat_26702": 0.7732665538787842, "gsm_rft_32686": 0.7744032740592957, "aqua_rat_69304": 0.7744100689888, "aqua_rat_80959": 0.7744839191436768, "gsm_rft_22376": 0.775442361831665, "aqua_rat_63857": 0.7762678861618042, "aqua_rat_46532": 0.7774626612663269, "math_train_counting_and_probability_708": 0.7840609550476074, "aqua_rat_33141": 0.791641116142273, "aqua_rat_9358": 0.7924674153327942, "aqua_rat_34688": 0.7954925894737244, "aqua_rat_22859": 0.7963988184928894, "aqua_rat_60661": 0.7972730398178101}, "TheoremQA_xinyi/sum_product_algorithm.json": {"camel_22834": 0, "camel_22371": 0, "camel_23394": 0, "camel_23160": 0, "camel_22820": 0, "camel_23149": 0, "camel_22855": 0, "camel_23389": 0, "camel_23170": 0, "camel_22864": 0, "camel_23168": 0, "camel_23392": 0, "camel_22385": 0, "camel_22359": 0, "camel_23928": 0, "camel_23427": 0, "camel_23405": 0, "camel_23146": 0, "camel_22389": 0, "camel_23932": 0, "camel_23410": 0, "camel_23123": 0, "camel_22356": 0, "camel_23124": 0, "camel_23363": 0, "camel_22328": 0, "camel_22876": 0, "camel_22388": 0, "camel_22844": 0, "camel_22940": 0, "camel_23157": 0, "camel_22347": 0, "camel_22325": 0, "camel_22825": 0, "camel_23306": 0, "camel_23125": 0, "camel_21158": 0, "camel_22380": 0, "camel_22878": 0, "camel_23122": 0, "camel_23139": 0, "camel_22810": 0, "camel_23137": 0, "camel_23934": 0, "camel_23192": 0, "camel_22179": 0, "camel_22828": 0, "camel_23156": 0, "camel_23177": 0, "camel_23977": 0, "camel_21044": 0, "camel_22373": 0, "camel_22386": 0, "camel_22320": 0, "camel_22803": 0, "camel_22843": 0, "camel_23188": 0, "camel_22355": 0, "camel_22837": 0, "camel_23132": 0, "camel_22418": 0, "camel_23386": 0, "camel_23155": 0, "camel_23971": 0, "camel_23425": 0, "camel_22819": 0, "camel_23995": 0, "camel_22849": 0, "camel_22850": 0, "camel_22664": 0, "camel_21133": 0, "camel_22392": 0, "camel_21179": 0, "TheoremQA_xinyi/sum_product_algorithm.json": 0, "camel_22366": 0, "camel_23199": 0, "camel_22061": 0, "camel_22068": 0, "camel_22845": 0, "camel_23154": 0, "camel_23399": 0, "camel_23127": 0, "camel_22862": 0, "camel_21057": 0, "camel_23951": 0, "camel_23923": 0, "camel_23367": 0, "camel_23145": 0, "camel_23175": 0, "camel_23148": 0, "camel_23147": 0, "camel_23126": 0, "camel_23195": 0, "camel_22374": 0, "camel_23129": 0, "camel_23191": 0, "camel_23432": 0, "camel_23198": 0, "camel_23189": 0, "camel_22832": 0, "camel_22863": 0, "camel_23190": 0, "camel_23144": 0, "camel_22333": 0, "camel_22383": 0, "camel_22912": 0, "camel_23391": 0, "camel_22838": 0, "camel_22805": 0, "camel_22384": 0, "camel_23400": 0, "camel_22352": 0, "camel_22381": 0, "camel_21107": 0, "camel_22360": 0, "camel_22812": 0, "camel_22808": 0, "camel_22806": 0, "camel_22397": 0, "camel_22375": 0, "camel_22379": 0, "camel_22949": 0, "camel_23424": 0, "camel_22824": 0, "camel_23159": 0, "camel_22847": 0, "camel_23158": 0, "camel_22361": 0, "camel_22345": 0, "camel_22329": 0, "camel_23196": 0, "camel_22391": 0, "camel_23372": 0, "camel_23358": 0, "camel_22393": 0, "camel_22369": 0, "camel_22866": 0, "camel_22443": 0, "camel_22807": 0, "camel_22879": 0, "camel_23135": 0, "camel_23374": 0, "camel_23165": 0, "camel_22322": 0, "camel_23161": 0, "camel_23180": 0, "camel_22387": 0, "camel_22870": 0, "camel_23141": 0, "camel_22337": 0, "camel_23172": 0, "camel_23182": 0, "camel_21083": 0, "camel_22331": 0, "camel_22853": 0, "camel_22398": 0, "camel_22816": 0, "camel_22370": 0, "camel_23131": 0, "camel_23430": 0, "camel_23393": 0, "camel_22801": 0, "camel_22867": 0, "camel_22334": 0, "camel_22823": 0, "camel_23414": 0, "camel_22335": 0, "camel_22868": 0, "camel_22362": 0, "camel_22872": 0, "camel_22364": 0, "camel_23128": 0, "camel_23397": 0, "camel_23173": 0, "camel_23174": 0, "camel_22338": 0, "camel_22382": 0, "camel_23187": 0, "camel_22377": 0, "camel_23166": 0, "camel_23176": 0, "camel_23179": 0, "camel_22396": 0, "camel_23163": 0, "camel_22327": 0, "camel_23162": 0, "camel_23403": 0, "camel_23183": 0, "camel_23151": 0, "camel_23369": 0, "camel_23181": 0, "camel_23150": 0, "camel_22378": 0, "camel_23382": 0, "camel_23423": 0, "camel_23164": 0, "camel_23193": 0, "camel_22170": 0, "camel_23364": 0, "camel_38586": 0.7358372807502747}, "TheoremQA_jianyu_xu/Binomial_4.json": {"camel_21272": 0, "camel_20874": 0, "camel_20397": 0, "camel_21572": 0, "camel_21419": 0, "camel_20802": 0, "camel_20336": 0, "camel_21526": 0, "camel_20298": 0, "camel_20307": 0, "camel_20364": 0, "camel_21267": 0, "camel_20240": 0, "camel_20384": 0, "camel_21005": 0, "camel_21388": 0, "camel_20749": 0, "camel_21528": 0, "camel_20984": 0, "camel_20394": 0, "camel_20915": 0, "camel_21386": 0, "camel_20344": 0, "camel_21236": 0, "camel_20271": 0, "camel_21546": 0, "camel_20611": 0, "camel_20260": 0, "camel_21563": 0, "camel_20930": 0, "camel_20293": 0, "camel_21530": 0, "camel_20348": 0, "aqua_rat_50541": 0.8593853712081909, "aqua_rat_57693": 0.859581708908081, "math_test_counting_and_probability_535": 0.859786868095398, "math_test_counting_and_probability_23957": 0.8598864078521729, "aqua_rat_29306": 0.8599836826324463, "aqua_rat_2653": 0.8600463271141052, "aqua_rat_48676": 0.8601608276367188, "aqua_rat_50290": 0.8603302836418152, "aqua_rat_82085": 0.8603774309158325, "aqua_rat_88698": 0.8603906035423279, "aqua_rat_43716": 0.8604202270507812, "aqua_rat_47631": 0.860512912273407, "aqua_rat_59675": 0.8606014251708984, "aqua_rat_14483": 0.8606482744216919, "aqua_rat_43584": 0.8607861399650574, "aqua_rat_13647": 0.8607884049415588, "aqua_rat_35841": 0.8608379364013672, "aqua_rat_19534": 0.8608521819114685, "aqua_rat_10119": 0.8610098958015442, "aqua_rat_33997": 0.8610783219337463, "aqua_rat_8260": 0.8610917925834656, "aqua_rat_36512": 0.8611505627632141, "aqua_rat_81265": 0.8611598610877991, "aqua_rat_80017": 0.8612564206123352, "math_train_prealgebra_236": 0.861361563205719, "aqua_rat_36115": 0.861430287361145, "aqua_rat_65577": 0.8614574670791626, "aqua_rat_8404": 0.8615896105766296, "aqua_rat_31467": 0.8617435693740845, "aqua_rat_78706": 0.8617591261863708, "aqua_rat_30172": 0.861873209476471, "aqua_rat_41775": 0.8620027899742126, "aqua_rat_53921": 0.862171471118927, "aqua_rat_29257": 0.8621830940246582, "aqua_rat_89064": 0.8622041940689087, "aqua_rat_7156": 0.862338662147522, "aqua_rat_82087": 0.8623411059379578, "aqua_rat_70526": 0.86249840259552, "aqua_rat_79851": 0.8625421524047852, "aqua_rat_13742": 0.8625457286834717, "aqua_rat_45416": 0.8625763058662415, "aqua_rat_53149": 0.8626160025596619, "aqua_rat_24058": 0.8626431226730347, "aqua_rat_20113": 0.8626489043235779, "aqua_rat_75475": 0.8627254962921143, "math_train_counting_and_probability_444": 0.8627973198890686, "aqua_rat_11962": 0.8631091713905334, "aqua_rat_81548": 0.8631632924079895, "aqua_rat_23154": 0.8632385730743408, "aqua_rat_50043": 0.8632489442825317, "aqua_rat_84364": 0.8632724285125732, "aqua_rat_78074": 0.863297700881958, "aqua_rat_58185": 0.863692045211792, "aqua_rat_38820": 0.8637768030166626, "aqua_rat_24686": 0.8638721704483032, "aqua_rat_72868": 0.8639423847198486, "aqua_rat_14825": 0.8640068769454956, "aqua_rat_76271": 0.864189863204956, "math_test_counting_and_probability_190": 0.8642944097518921, "aqua_rat_71578": 0.8645144701004028, "math_train_prealgebra_811": 0.8646399974822998, "aqua_rat_13243": 0.8647373914718628, "math_train_counting_and_probability_417": 0.864750325679779, "aqua_rat_7035": 0.8649027943611145, "aqua_rat_60755": 0.8649722337722778, "TheoremQA_jianyu_xu/Binomial_5.json": 0.8650401830673218, "aqua_rat_49270": 0.8651992082595825, "aqua_rat_52714": 0.8652265667915344, "aqua_rat_8436": 0.8653091788291931, "aqua_rat_9556": 0.8654079437255859, "aqua_rat_7409": 0.8654085397720337, "aqua_rat_87775": 0.8654427528381348, "aqua_rat_72310": 0.8656094670295715, "aqua_rat_60998": 0.8657236695289612, "aqua_rat_41153": 0.8658360242843628, "aqua_rat_68198": 0.865906834602356, "aqua_rat_84957": 0.865918755531311, "aqua_rat_63963": 0.8659499883651733, "math_train_counting_and_probability_338": 0.866094172000885, "aqua_rat_83206": 0.8661222457885742, "aqua_rat_16863": 0.866125762462616, "aqua_rat_84736": 0.8661733269691467, "aqua_rat_42746": 0.866495668888092, "aqua_rat_2630": 0.8666906356811523, "aqua_rat_74901": 0.8667560815811157, "aqua_rat_38845": 0.8669518828392029, "aqua_rat_42177": 0.8671963810920715, "aqua_rat_51559": 0.8672351241111755, "aqua_rat_25421": 0.8672745227813721, "aqua_rat_31360": 0.8673369288444519, "aqua_rat_73601": 0.8674101829528809, "aqua_rat_81997": 0.8678571581840515, "aqua_rat_66240": 0.8679578304290771, "aqua_rat_8021": 0.8681859970092773, "aqua_rat_65642": 0.868254542350769, "aqua_rat_19500": 0.8682628273963928, "aqua_rat_32212": 0.8682923913002014, "aqua_rat_15343": 0.8683335185050964, "aqua_rat_68232": 0.8685420751571655, "aqua_rat_72210": 0.8687090277671814, "aqua_rat_77361": 0.8689542412757874, "aqua_rat_27914": 0.8691438436508179, "aqua_rat_63018": 0.8694494962692261, "aqua_rat_27717": 0.8697724342346191, "aqua_rat_42671": 0.8698276877403259, "math_train_counting_and_probability_236": 0.8698475956916809, "aqua_rat_52092": 0.8699193000793457, "aqua_rat_35292": 0.8699854612350464, "aqua_rat_58309": 0.8705415725708008, "aqua_rat_18760": 0.8706206679344177, "aqua_rat_23582": 0.8706288933753967, "aqua_rat_31768": 0.8706459999084473, "aqua_rat_71649": 0.8707459568977356, "aqua_rat_80242": 0.8708373308181763, "aqua_rat_29622": 0.8715601563453674, "aqua_rat_47513": 0.8715713024139404, "aqua_rat_70861": 0.8719833493232727, "aqua_rat_78732": 0.8720998764038086, "aqua_rat_20722": 0.872277021408081, "aqua_rat_78895": 0.87229984998703, "aqua_rat_10102": 0.8723104596138, "camel_38493": 0.8724322319030762, "aqua_rat_22507": 0.8726457953453064, "aqua_rat_13853": 0.8729910254478455, "aqua_rat_83916": 0.8730441331863403, "aqua_rat_79238": 0.8733386993408203, "aqua_rat_70803": 0.873650312423706, "aqua_rat_89175": 0.8742479085922241, "aqua_rat_15615": 0.8742676377296448, "aqua_rat_64131": 0.8745813965797424, "aqua_rat_62903": 0.8748749494552612, "aqua_rat_32732": 0.875171422958374, "aqua_rat_4069": 0.8756756782531738, "aqua_rat_35015": 0.8758469223976135, "aqua_rat_23820": 0.8761579394340515, "math_test_counting_and_probability_80": 0.8762855529785156, "aqua_rat_42333": 0.8763887882232666, "aqua_rat_9713": 0.876400351524353, "aqua_rat_16762": 0.8771584630012512, "aqua_rat_67179": 0.8773238658905029, "aqua_rat_46850": 0.8782658576965332, "aqua_rat_42445": 0.8783055543899536, "aqua_rat_28538": 0.8784967064857483, "aqua_rat_58323": 0.8787574768066406, "aqua_rat_22077": 0.8789269924163818, "math_test_counting_and_probability_107": 0.8794736862182617, "aqua_rat_66841": 0.8794766068458557, "aqua_rat_5288": 0.8804841041564941, "aqua_rat_57246": 0.8805093169212341, "aqua_rat_79193": 0.8808885216712952, "aqua_rat_30648": 0.8810171484947205, "aqua_rat_85174": 0.8827104568481445, "math_train_counting_and_probability_929": 0.8830141425132751, "aqua_rat_34245": 0.8836677670478821, "aqua_rat_25085": 0.8847156763076782, "aqua_rat_85599": 0.8860148787498474, "aqua_rat_44712": 0.8866620659828186, "aqua_rat_17487": 0.8869181871414185, "aqua_rat_41430": 0.8869640231132507, "aqua_rat_69384": 0.8873158693313599, "aqua_rat_14884": 0.8873334527015686, "aqua_rat_16920": 0.8892520070075989, "aqua_rat_9182": 0.8894116878509521, "aqua_rat_7086": 0.8896090984344482, "aqua_rat_53395": 0.8900773525238037, "aqua_rat_35900": 0.890109658241272, "aqua_rat_30109": 0.8924674987792969}, "TheoremQA_maxku/fourier6-FT.json": {"camel_45754": 0, "camel_28520": 0.6409317851066589, "camel_28789": 0.6410483717918396, "camel_29539": 0.6410518884658813, "aqua_rat_60661": 0.6410819888114929, "camel_30407": 0.6411797404289246, "camel_28780": 0.641250491142273, "camel_28745": 0.6412823796272278, "camel_30953": 0.6413331031799316, "camel_26540": 0.6414058804512024, "aqua_rat_23957": 0.6414079070091248, "camel_47817": 0.6414552330970764, "camel_29346": 0.6414623260498047, "camel_29429": 0.6416040658950806, "camel_28487": 0.641639769077301, "aqua_rat_31136": 0.6418185830116272, "camel_30903": 0.641839325428009, "camel_47835": 0.6419118046760559, "aqua_rat_50936": 0.6419786214828491, "camel_30937": 0.6422291994094849, "camel_37853": 0.6423138380050659, "camel_29580": 0.6423217058181763, "aqua_rat_11898": 0.6423364877700806, "camel_47819": 0.6423749923706055, "camel_28810": 0.6424734592437744, "aqua_rat_60879": 0.6425440907478333, "camel_30946": 0.6425563097000122, "camel_29088": 0.6426168084144592, "camel_29783": 0.6426530480384827, "camel_27440": 0.6426634192466736, "camel_28752": 0.642834484577179, "camel_27537": 0.6428604125976562, "gsm_rft_2696": 0.6428987979888916, "camel_28206": 0.6429213881492615, "camel_28345": 0.6429824233055115, "camel_26647": 0.6429972648620605, "camel_29162": 0.6430528163909912, "camel_30954": 0.6430788636207581, "gsm_rft_18389": 0.6431840062141418, "gsm_train_2018": 0.6431840062141418, "camel_27797": 0.6432804465293884, "camel_30952": 0.6434741616249084, "camel_31294": 0.6435922384262085, "camel_31251": 0.6436948180198669, "camel_29790": 0.6438524723052979, "camel_47805": 0.6438546776771545, "camel_29770": 0.6438556909561157, "aqua_rat_5850": 0.6438705325126648, "math_train_number_theory_358": 0.6439868807792664, "camel_28801": 0.6440824270248413, "aqua_rat_59654": 0.6441665887832642, "camel_30223": 0.6442331671714783, "camel_29836": 0.644271194934845, "camel_27800": 0.6446353793144226, "aqua_rat_43874": 0.6446372270584106, "aqua_rat_51685": 0.6448013186454773, "camel_29327": 0.6448063850402832, "aqua_rat_68705": 0.6450238823890686, "camel_30922": 0.6451551914215088, "gsm_rft_21298": 0.6451821327209473, "gsm_train_20944": 0.6451821327209473, "camel_28385": 0.6451903581619263, "camel_26487": 0.6452951431274414, "camel_26499": 0.645298182964325, "camel_30921": 0.6453038454055786, "gsm_rft_19613": 0.6453751921653748, "camel_30401": 0.6453987956047058, "camel_29984": 0.6454183459281921, "camel_28791": 0.6456258893013, "camel_30888": 0.6456984877586365, "camel_28857": 0.6457825899124146, "gsm_train_6184": 0.6458399891853333, "aqua_rat_1415": 0.6458732485771179, "gsm_rft_12368": 0.6459337472915649, "aqua_rat_1227": 0.6459766626358032, "camel_28825": 0.6461187601089478, "camel_28836": 0.6461397409439087, "camel_29719": 0.6461896300315857, "math_train_counting_and_probability_1028": 0.6462700963020325, "camel_28461": 0.6464329957962036, "aqua_rat_34049": 0.6465126872062683, "aqua_rat_23666": 0.6466984748840332, "aqua_rat_23632": 0.6467598676681519, "aqua_rat_73398": 0.6467810869216919, "camel_27475": 0.6468814015388489, "camel_28795": 0.6468845009803772, "camel_28753": 0.6470342874526978, "camel_28348": 0.6472553014755249, "camel_31329": 0.6473308801651001, "camel_27561": 0.647633969783783, "camel_30882": 0.6476573348045349, "camel_29684": 0.6476929783821106, "aqua_rat_41681": 0.6476965546607971, "camel_29937": 0.647861123085022, "camel_28148": 0.6479668617248535, "camel_28397": 0.6481236219406128, "camel_28785": 0.648260235786438, "camel_28797": 0.6483048796653748, "aqua_rat_4189": 0.64838045835495, "gsm_rft_11471": 0.6484559178352356, "camel_28870": 0.6485947966575623, "camel_29121": 0.6490403413772583, "camel_30935": 0.6493022441864014, "gsm_rft_33863": 0.6494876742362976, "camel_28321": 0.6495616436004639, "gsm_rft_11538": 0.6496303081512451, "gsm_train_23103": 0.6496303081512451, "aqua_rat_74864": 0.6496384143829346, "camel_27504": 0.6497959494590759, "camel_28120": 0.6498774290084839, "camel_47815": 0.6500129103660583, "camel_29734": 0.6500516533851624, "camel_28453": 0.6500852108001709, "camel_28815": 0.6502139568328857, "camel_29947": 0.6504335999488831, "camel_30895": 0.6505566835403442, "camel_28723": 0.6507193446159363, "camel_28736": 0.6507459282875061, "camel_28439": 0.6509987711906433, "gsm_rft_14072": 0.6511279344558716, "camel_28776": 0.6511548161506653, "camel_47769": 0.6511855721473694, "camel_28528": 0.6512119770050049, "camel_28084": 0.6520445346832275, "camel_28733": 0.6520702838897705, "camel_28354": 0.6521117687225342, "camel_30907": 0.6523093581199646, "camel_30880": 0.652574360370636, "camel_28787": 0.6527417302131653, "camel_28433": 0.6527706980705261, "camel_29752": 0.6529741883277893, "aqua_rat_82251": 0.6531087160110474, "aqua_rat_66272": 0.6532623767852783, "camel_29305": 0.6533827781677246, "math_train_counting_and_probability_708": 0.6534571647644043, "camel_28329": 0.6535130739212036, "camel_28883": 0.6535425186157227, "camel_29780": 0.6537079215049744, "camel_29364": 0.6537874937057495, "aqua_rat_32099": 0.6539164185523987, "camel_30470": 0.6539234519004822, "camel_26483": 0.6540698409080505, "math_train_number_theory_803": 0.6543076634407043, "camel_28384": 0.6544540524482727, "camel_30944": 0.6544944643974304, "camel_28877": 0.6545903086662292, "aqua_rat_31017": 0.6548242568969727, "camel_28386": 0.6552173495292664, "camel_29727": 0.6552560329437256, "camel_28819": 0.6556397080421448, "aqua_rat_87692": 0.6557716131210327, "camel_28802": 0.6560748219490051, "camel_29042": 0.6561441421508789, "camel_29467": 0.6564344763755798, "camel_29704": 0.6565820574760437, "camel_29799": 0.6566660404205322, "camel_28435": 0.6567354798316956, "camel_28502": 0.6568356156349182, "camel_30423": 0.6568764448165894, "camel_30945": 0.6572253704071045, "camel_36290": 0.6577089428901672, "camel_30927": 0.6578055620193481, "camel_28324": 0.657981812953949, "camel_28392": 0.6583446264266968, "camel_29148": 0.6585874557495117, "aqua_rat_88322": 0.6595519185066223, "camel_27835": 0.6597487926483154, "camel_28382": 0.6605961918830872, "camel_28441": 0.6609388589859009, "camel_28835": 0.6610172986984253, "camel_36765": 0.6614269018173218, "camel_27474": 0.6616405248641968, "math_test_counting_and_probability_883": 0.6620420813560486, "camel_29060": 0.6622295379638672, "camel_19973": 0.6622946262359619, "camel_28395": 0.6624316573143005, "camel_30925": 0.6631025671958923, "camel_28948": 0.6635217070579529, "camel_29078": 0.664645254611969, "camel_28357": 0.6648783683776855, "gsm_rft_22691": 0.6655131578445435, "gsm_train_21120": 0.6657761335372925, "gsm_rft_16595": 0.6657761335372925, "camel_28821": 0.6660067439079285, "camel_28754": 0.666093647480011, "camel_28379": 0.6663984060287476, "aqua_rat_41243": 0.6668340563774109, "camel_28404": 0.6674895882606506, "camel_28759": 0.6704356074333191, "camel_30474": 0.6708160042762756, "camel_29321": 0.6712089776992798, "camel_26554": 0.6726318001747131, "camel_28838": 0.6745593547821045, "camel_28744": 0.6767076253890991, "camel_28407": 0.6774876713752747, "camel_28361": 0.6782549023628235, "camel_28765": 0.6798334717750549, "camel_26497": 0.6817500591278076, "camel_28430": 0.683388352394104, "camel_28740": 0.6864797472953796}, "TheoremQA_xinyi/neural_networks.json": {"TheoremQA_xinyi/neural_networks.json": 0, "camel_29636": 0.6142759919166565, "camel_37440": 0.6143943667411804, "camel_37551": 0.6145225167274475, "camel_40967": 0.6147499680519104, "camel_40704": 0.6147710680961609, "camel_28759": 0.614801287651062, "camel_28424": 0.6148214340209961, "camel_29972": 0.6148338913917542, "camel_29935": 0.6148565411567688, "camel_29746": 0.6148762106895447, "camel_29882": 0.615024209022522, "camel_28435": 0.6152558326721191, "camel_37490": 0.6152798533439636, "camel_29284": 0.6154068112373352, "TheoremQA_maxku/signalprocessing4-Ztransform.json": 0.6154768466949463, "camel_29135": 0.6155957579612732, "camel_28382": 0.6156192421913147, "camel_40850": 0.6156922578811646, "camel_29954": 0.6157116889953613, "camel_29338": 0.615787923336029, "camel_41977": 0.615854799747467, "math_test_intermediate_algebra_128": 0.6158701777458191, "camel_29161": 0.6159313917160034, "camel_28381": 0.6159691214561462, "camel_18918": 0.6163458824157715, "camel_29491": 0.6164065599441528, "camel_28434": 0.61646568775177, "camel_29278": 0.6166385412216187, "camel_29822": 0.6166418790817261, "camel_28433": 0.6166788935661316, "TheoremQA_elainewan/math_algebra_6.json": 0.6167606115341187, "camel_28206": 0.616864025592804, "camel_37052": 0.616899311542511, "camel_29688": 0.6169239282608032, "camel_29670": 0.616962730884552, "camel_29121": 0.6170782446861267, "camel_29730": 0.6171360015869141, "camel_29270": 0.6171593070030212, "camel_29984": 0.617192804813385, "camel_29845": 0.6171959042549133, "camel_29755": 0.6172271966934204, "camel_29346": 0.6172322034835815, "camel_36938": 0.6173186898231506, "camel_41067": 0.6174031496047974, "camel_28399": 0.6174261569976807, "camel_29541": 0.6174951791763306, "camel_29879": 0.6176589131355286, "camel_29992": 0.6176620125770569, "camel_28386": 0.6176908016204834, "camel_29756": 0.6178103685379028, "camel_28329": 0.6178183555603027, "camel_29302": 0.6178943514823914, "camel_29374": 0.6179066300392151, "camel_28340": 0.6179491877555847, "camel_29341": 0.6179659366607666, "camel_29371": 0.6180309057235718, "camel_29732": 0.6182608604431152, "camel_40833": 0.6182878017425537, "camel_41431": 0.6183235049247742, "camel_28357": 0.6183346509933472, "camel_29918": 0.618335485458374, "camel_29612": 0.6183404326438904, "camel_29609": 0.6183698773384094, "camel_29947": 0.6184137463569641, "camel_41093": 0.6187581419944763, "camel_29132": 0.6188467741012573, "camel_29745": 0.6188933253288269, "camel_29180": 0.6191516518592834, "camel_28787": 0.6192631125450134, "camel_40964": 0.6194072961807251, "camel_29802": 0.6197136044502258, "camel_29370": 0.6197684407234192, "camel_29387": 0.6198277473449707, "camel_29878": 0.6198663115501404, "camel_40670": 0.6199217438697815, "camel_29220": 0.6199274659156799, "camel_28397": 0.6199358701705933, "camel_29969": 0.6200264096260071, "camel_29322": 0.6200433969497681, "camel_28395": 0.6202352046966553, "camel_28430": 0.620242714881897, "camel_28479": 0.6202600598335266, "camel_29265": 0.6205386519432068, "camel_37511": 0.6206752061843872, "camel_18919": 0.6209883689880371, "camel_28869": 0.6210629343986511, "camel_29224": 0.6211199760437012, "camel_28407": 0.6212392449378967, "camel_37457": 0.6212664246559143, "camel_29903": 0.6214199066162109, "camel_29234": 0.6214770674705505, "camel_29922": 0.6215291023254395, "camel_28723": 0.6215950846672058, "camel_28780": 0.6216962337493896, "camel_29987": 0.6225071549415588, "camel_28520": 0.622789204120636, "camel_29899": 0.6229511499404907, "camel_29697": 0.6229981184005737, "camel_36754": 0.6234835386276245, "camel_28384": 0.6235917806625366, "camel_29722": 0.623591959476471, "camel_28733": 0.6236323118209839, "camel_28361": 0.6236799359321594, "camel_29867": 0.6237255334854126, "camel_29739": 0.6239083409309387, "camel_29692": 0.6243393421173096, "camel_29216": 0.6243471503257751, "camel_17834": 0.6244149208068848, "camel_40647": 0.6245169639587402, "camel_29759": 0.6246028542518616, "camel_29244": 0.6247709393501282, "camel_29467": 0.6250211596488953, "camel_29060": 0.6254233121871948, "camel_29235": 0.6256179213523865, "camel_29888": 0.6258476972579956, "camel_41414": 0.6259165406227112, "camel_29229": 0.6265423893928528, "camel_28404": 0.6265931725502014, "camel_28754": 0.6268308162689209, "camel_28385": 0.6268401145935059, "camel_28379": 0.6269906163215637, "camel_37452": 0.6270222663879395, "camel_18920": 0.627070963382721, "camel_29435": 0.6271403431892395, "camel_37495": 0.6272937059402466, "camel_29340": 0.6272961497306824, "camel_29734": 0.6274175643920898, "camel_29329": 0.6274964809417725, "camel_29222": 0.6275341510772705, "camel_29698": 0.6276808977127075, "camel_36444": 0.6279160976409912, "camel_37480": 0.6280129551887512, "camel_28794": 0.6282758712768555, "camel_37474": 0.6284791827201843, "camel_29205": 0.6287577152252197, "camel_39101": 0.6289680600166321, "camel_29682": 0.6290463805198669, "camel_39086": 0.6292600035667419, "camel_29257": 0.6293901205062866, "camel_29255": 0.6294335126876831, "camel_29321": 0.6294559836387634, "camel_29301": 0.6294839382171631, "camel_29704": 0.6296632289886475, "camel_29364": 0.6298762559890747, "camel_29971": 0.6301113963127136, "camel_29328": 0.6304906010627747, "camel_29429": 0.6305268406867981, "camel_29373": 0.6305798292160034, "camel_29711": 0.6309450268745422, "camel_29907": 0.6312306523323059, "camel_29337": 0.6313139200210571, "camel_18905": 0.6313753724098206, "camel_29881": 0.6313758492469788, "camel_29753": 0.6314367055892944, "TheoremQA_xinyi/kernel_1.json": 0.6315922141075134, "camel_28086": 0.6318181157112122, "camel_37488": 0.6318878531455994, "camel_29245": 0.6319292187690735, "camel_29910": 0.6325387954711914, "camel_18936": 0.6327677965164185, "camel_29691": 0.6330251097679138, "camel_29978": 0.6332672238349915, "camel_29162": 0.6335790157318115, "camel_29752": 0.633622407913208, "camel_29705": 0.6336473226547241, "camel_29271": 0.633913516998291, "camel_29438": 0.633922278881073, "camel_29737": 0.6342121958732605, "camel_29204": 0.6345828771591187, "camel_29272": 0.6355166435241699, "camel_29407": 0.6360327005386353, "camel_29894": 0.6371623277664185, "camel_39059": 0.6383265852928162, "camel_29228": 0.6383616328239441, "camel_29227": 0.6385676264762878, "camel_29684": 0.6385964751243591, "camel_29721": 0.6390397548675537, "camel_29388": 0.6390522718429565, "camel_29693": 0.6396598219871521, "camel_29276": 0.6400933861732483, "camel_29741": 0.640178918838501, "camel_29288": 0.6403675675392151, "camel_37507": 0.6407963037490845, "camel_37476": 0.64119553565979, "camel_29279": 0.6420049667358398, "camel_29277": 0.6423313617706299, "camel_36936": 0.6426782011985779, "camel_29251": 0.6429683566093445, "camel_29716": 0.6439013481140137, "camel_29240": 0.6445744633674622, "camel_29749": 0.6450672149658203, "camel_29327": 0.6451207399368286, "camel_29700": 0.6460238099098206, "camel_37492": 0.646988570690155, "camel_29916": 0.6470056176185608, "camel_36502": 0.6483720541000366, "camel_29727": 0.649956226348877, "camel_29695": 0.6536087393760681, "camel_29719": 0.6606370806694031}, "TheoremQA_xinyi/kernel_1.json": {"TheoremQA_xinyi/kernel_1.json": 0, "math_train_algebra_1657": 0.6538201570510864, "camel_9044": 0.6539261937141418, "camel_8209": 0.6539563536643982, "camel_9263": 0.6539973020553589, "camel_9145": 0.6540610194206238, "camel_8481": 0.6540722250938416, "camel_5869": 0.6540753841400146, "camel_8160": 0.6540817618370056, "camel_9129": 0.6541029810905457, "camel_9206": 0.6541886925697327, "camel_5917": 0.6542233228683472, "camel_8547": 0.6543066501617432, "camel_9146": 0.6543518304824829, "camel_37937": 0.6544520854949951, "camel_8966": 0.6545073986053467, "camel_9138": 0.6546110510826111, "camel_9064": 0.6546522378921509, "camel_8208": 0.6547361612319946, "camel_9132": 0.6547797322273254, "aqua_rat_67418": 0.654829740524292, "camel_8557": 0.6548948287963867, "camel_9205": 0.6550294160842896, "camel_8524": 0.6550302505493164, "camel_8222": 0.655034065246582, "camel_39417": 0.6551889181137085, "camel_9240": 0.6552217602729797, "camel_9057": 0.6553345918655396, "camel_37997": 0.6554175019264221, "camel_5881": 0.6554405093193054, "camel_9846": 0.6554487347602844, "camel_9000": 0.6554598808288574, "camel_8499": 0.655531644821167, "camel_5871": 0.6558334827423096, "camel_9208": 0.6560799479484558, "camel_9151": 0.6565285325050354, "camel_9217": 0.6567577123641968, "camel_36614": 0.6567791104316711, "camel_9124": 0.6573119759559631, "camel_9186": 0.6573681235313416, "camel_9248": 0.6574046015739441, "camel_37962": 0.6583166718482971, "camel_8532": 0.6584974527359009, "camel_9198": 0.658875048160553, "camel_9237": 0.6590264439582825, "camel_5651": 0.6593294143676758, "camel_8989": 0.6595643758773804, "camel_9209": 0.6595779657363892, "camel_9218": 0.6596335172653198, "camel_9297": 0.6596387624740601, "camel_9012": 0.6599105596542358, "camel_5643": 0.6599677205085754, "camel_9013": 0.6599816083908081, "camel_8988": 0.6601804494857788, "camel_8511": 0.6603078246116638, "aqua_rat_87580": 0.6603549122810364, "camel_36493": 0.660550057888031, "camel_9267": 0.6611066460609436, "camel_8992": 0.6611616611480713, "camel_36611": 0.6613478660583496, "camel_36748": 0.6613578796386719, "camel_8228": 0.6613714098930359, "camel_5653": 0.661480188369751, "camel_9213": 0.6615780591964722, "camel_37970": 0.6616503596305847, "camel_9153": 0.6616957187652588, "camel_8500": 0.6617127060890198, "camel_37935": 0.6617370843887329, "camel_9116": 0.662068784236908, "camel_8545": 0.6621155738830566, "camel_9163": 0.6621348857879639, "camel_8239": 0.6622439622879028, "camel_9275": 0.6622865200042725, "camel_37923": 0.6623997688293457, "aqua_rat_81157": 0.6624430418014526, "TheoremQA_elainewan/math_algebra_6.json": 0.6629278063774109, "camel_8980": 0.6629389524459839, "camel_9133": 0.6629573702812195, "camel_8548": 0.6632040739059448, "camel_8495": 0.6633360981941223, "camel_9246": 0.6634354591369629, "camel_8482": 0.66363126039505, "camel_5874": 0.6637367010116577, "camel_9245": 0.6638178825378418, "camel_8554": 0.6639978289604187, "camel_9305": 0.6641896963119507, "camel_8541": 0.6645347476005554, "camel_36875": 0.6646363735198975, "camel_25427": 0.66469407081604, "camel_9080": 0.6648121476173401, "camel_8176": 0.6648644208908081, "camel_9845": 0.6648665070533752, "camel_9310": 0.6649712920188904, "camel_8549": 0.6652217507362366, "camel_8238": 0.6653560400009155, "camel_9210": 0.6654296517372131, "camel_9070": 0.6655486226081848, "camel_8982": 0.6657173037528992, "camel_9084": 0.665988564491272, "camel_8188": 0.6661304235458374, "camel_9296": 0.6663707494735718, "camel_9173": 0.6664438843727112, "camel_9330": 0.6665685772895813, "camel_8995": 0.6670952439308167, "camel_9358": 0.6671207547187805, "camel_8224": 0.6673023700714111, "camel_9299": 0.6674166321754456, "camel_9229": 0.6676453351974487, "camel_9115": 0.6677815318107605, "camel_36936": 0.6678001880645752, "camel_8480": 0.6679353713989258, "camel_8977": 0.6682119369506836, "camel_9113": 0.6683180332183838, "camel_5879": 0.6684661507606506, "camel_8530": 0.6685011386871338, "camel_9339": 0.6685060262680054, "camel_9295": 0.6685543656349182, "camel_8509": 0.6686042547225952, "camel_9005": 0.6686080098152161, "camel_9277": 0.6687055826187134, "camel_5758": 0.6690974235534668, "camel_9283": 0.669122576713562, "camel_36766": 0.6696944832801819, "camel_8485": 0.6698156595230103, "camel_9260": 0.6698545813560486, "camel_9249": 0.6699671745300293, "camel_5889": 0.6702001690864563, "camel_5678": 0.6705890893936157, "camel_9335": 0.670665979385376, "camel_9211": 0.6707655787467957, "camel_9230": 0.6709468364715576, "camel_8529": 0.6711516380310059, "camel_9226": 0.6720451712608337, "camel_8553": 0.6723895072937012, "camel_8226": 0.6727859973907471, "camel_36502": 0.6728438138961792, "camel_37926": 0.6734532117843628, "camel_8236": 0.6735579371452332, "camel_8167": 0.6736599206924438, "camel_9001": 0.6739799380302429, "camel_8488": 0.6743907928466797, "camel_8184": 0.674589216709137, "camel_8531": 0.674873948097229, "camel_9469": 0.6750489473342896, "camel_8976": 0.67597496509552, "camel_8223": 0.6763738989830017, "camel_8483": 0.6766378283500671, "camel_9227": 0.6782240271568298, "camel_8975": 0.678834080696106, "camel_8174": 0.6792258024215698, "camel_9294": 0.6794024705886841, "camel_8504": 0.6803172826766968, "camel_9022": 0.6803565621376038, "camel_8987": 0.6811123490333557, "camel_9031": 0.6812333464622498, "camel_8969": 0.6812951564788818, "camel_9006": 0.6829609870910645, "camel_8997": 0.6835401654243469, "camel_9034": 0.6843101978302002, "camel_8971": 0.6848219633102417, "camel_8512": 0.6868864297866821, "camel_8993": 0.6871412992477417, "camel_8494": 0.6874732971191406, "camel_9169": 0.6878101825714111, "camel_9009": 0.6879538893699646, "camel_8973": 0.6883286237716675, "camel_5692": 0.68839031457901, "camel_9018": 0.6886560320854187, "camel_8978": 0.6892114281654358, "camel_9016": 0.6900100111961365, "camel_37989": 0.6900467276573181, "camel_8225": 0.690098226070404, "camel_8521": 0.6904016733169556, "camel_37934": 0.6904277205467224, "camel_40840": 0.6904985904693604, "camel_9152": 0.6918044686317444, "camel_9359": 0.6927309632301331, "camel_8505": 0.6928951144218445, "camel_8534": 0.6930051445960999, "camel_8533": 0.6934511661529541, "camel_8487": 0.6936188340187073, "camel_9026": 0.6952122449874878, "camel_9004": 0.6957845687866211, "camel_8528": 0.6974807977676392, "camel_5739": 0.6991543173789978, "camel_8536": 0.7003297209739685, "camel_9028": 0.7008107304573059, "camel_9017": 0.701442301273346, "camel_9030": 0.7022034525871277, "camel_9842": 0.7026448845863342, "camel_8200": 0.7026543021202087, "camel_8486": 0.7032145857810974, "camel_9020": 0.705056369304657, "camel_8999": 0.706632673740387, "camel_37924": 0.7072834968566895, "camel_9015": 0.710124135017395, "camel_9032": 0.7152296304702759, "camel_8963": 0.7177615761756897, "camel_9025": 0.7193484902381897, "camel_8965": 0.7206920385360718}, "TheoremQA_wenhuchen/viterbi1.json": {"camel_9501": 0, "camel_9516": 0, "camel_9443": 0, "camel_8377": 0, "camel_9448": 0, "camel_9445": 0, "camel_9503": 0, "camel_9464": 0, "camel_9491": 0, "camel_9505": 0, "camel_9487": 0, "camel_9481": 0, "camel_9446": 0, "camel_9479": 0, "camel_9461": 0, "camel_9500": 0, "camel_9489": 0, "camel_8784": 0, "camel_9441": 0, "camel_9513": 0, "camel_9476": 0, "camel_9511": 0, "camel_9517": 0, "camel_9453": 0, "camel_9508": 0, "math_train_counting_and_probability_557": 0, "camel_9477": 0, "camel_8727": 0, "camel_9590": 0, "camel_9496": 0, "math_train_counting_and_probability_97": 0, "camel_9506": 0, "camel_9474": 0, "camel_9490": 0, "camel_9452": 0, "camel_9504": 0, "camel_9466": 0, "camel_9502": 0, "camel_9495": 0, "camel_9475": 0, "camel_9497": 0, "camel_9471": 0, "camel_9447": 0, "camel_9514": 0, "camel_9480": 0, "camel_9454": 0, "camel_9485": 0, "camel_11010": 0.7780886888504028, "TheoremQA_wenhuchen/viterbi2.json": 0.778149425983429, "aqua_rat_15170": 0.7782525420188904, "camel_37875": 0.7784988284111023, "camel_10992": 0.7786601185798645, "camel_36260": 0.7786839604377747, "aqua_rat_43015": 0.7790119647979736, "camel_10603": 0.7790269255638123, "aqua_rat_65593": 0.7790834903717041, "camel_11631": 0.779288113117218, "camel_24671": 0.7793713212013245, "aqua_rat_42090": 0.7794364094734192, "camel_10557": 0.7795723080635071, "camel_11126": 0.7795904874801636, "aqua_rat_50853": 0.7799553871154785, "aqua_rat_82625": 0.780076801776886, "camel_11315": 0.7801070809364319, "camel_11866": 0.7801320552825928, "aqua_rat_34949": 0.7801923155784607, "aqua_rat_15122": 0.7802520990371704, "aqua_rat_61314": 0.7802692651748657, "camel_11021": 0.7803012728691101, "camel_37988": 0.780353307723999, "aqua_rat_50672": 0.7803915739059448, "aqua_rat_44578": 0.7804491519927979, "camel_11662": 0.7804637551307678, "aqua_rat_38490": 0.7804831266403198, "camel_36368": 0.7804977297782898, "aqua_rat_3261": 0.7807188630104065, "aqua_rat_34276": 0.780859112739563, "camel_11314": 0.7809886932373047, "aqua_rat_39913": 0.7810410857200623, "camel_11548": 0.781438410282135, "camel_11800": 0.7814980149269104, "camel_11836": 0.7815455794334412, "camel_11462": 0.7817481160163879, "camel_37799": 0.7818968296051025, "aqua_rat_76641": 0.7819023728370667, "aqua_rat_8224": 0.7819081544876099, "camel_10542": 0.7820142507553101, "camel_10829": 0.7821481823921204, "aqua_rat_34885": 0.78249591588974, "camel_11876": 0.7825965285301208, "camel_25438": 0.7826355695724487, "camel_10361": 0.7827301025390625, "camel_37907": 0.7829437851905823, "camel_11121": 0.7829497456550598, "camel_37849": 0.7829859256744385, "camel_10612": 0.7832101583480835, "camel_10624": 0.7834291458129883, "camel_11796": 0.7835178375244141, "aqua_rat_62892": 0.7838197946548462, "camel_39375": 0.7838918566703796, "camel_36330": 0.7839092016220093, "aqua_rat_30901": 0.7841765284538269, "aqua_rat_86847": 0.7842822670936584, "camel_11872": 0.7845408320426941, "camel_11362": 0.7845505475997925, "camel_24714": 0.7846783399581909, "camel_24693": 0.784694254398346, "aqua_rat_65680": 0.7847739458084106, "camel_11326": 0.7849543690681458, "aqua_rat_62298": 0.7849565148353577, "camel_11004": 0.7849904894828796, "camel_11622": 0.7850805521011353, "camel_10968": 0.7851241230964661, "camel_11616": 0.7851999402046204, "aqua_rat_42842": 0.7857275009155273, "camel_11644": 0.7858263850212097, "camel_10638": 0.7858324646949768, "camel_10523": 0.7861788272857666, "camel_37620": 0.7862244248390198, "camel_36507": 0.7862982153892517, "camel_11660": 0.7864996790885925, "aqua_rat_37936": 0.7868697643280029, "aqua_rat_50753": 0.7868980169296265, "aqua_rat_45407": 0.7869521379470825, "camel_11032": 0.7873108386993408, "camel_11869": 0.7873350977897644, "aqua_rat_32748": 0.7874044179916382, "camel_10389": 0.787511944770813, "camel_11667": 0.7877892255783081, "camel_10552": 0.7879369854927063, "aqua_rat_60327": 0.788087785243988, "camel_11138": 0.7884235978126526, "aqua_rat_21944": 0.7886109352111816, "aqua_rat_47751": 0.7889582514762878, "aqua_rat_31129": 0.7890090346336365, "camel_25254": 0.789167046546936, "aqua_rat_87308": 0.7897199988365173, "camel_11453": 0.7897471189498901, "camel_10608": 0.7908197641372681, "camel_11135": 0.7909812927246094, "aqua_rat_69941": 0.7910260558128357, "camel_10604": 0.7910658121109009, "aqua_rat_17728": 0.7911820411682129, "aqua_rat_50510": 0.7915863394737244, "camel_10828": 0.7917013764381409, "camel_11013": 0.791843831539154, "camel_11331": 0.7923463582992554, "aqua_rat_37698": 0.7927331328392029, "camel_10983": 0.7929185032844543, "aqua_rat_80730": 0.7931244969367981, "camel_11822": 0.7931433916091919, "aqua_rat_5883": 0.7934176325798035, "camel_10583": 0.7934529185295105, "aqua_rat_6577": 0.7937719821929932, "camel_11005": 0.7941747307777405, "camel_24711": 0.7946648001670837, "camel_11898": 0.7947037220001221, "aqua_rat_40444": 0.7947394847869873, "aqua_rat_29721": 0.7947633266448975, "camel_10602": 0.7950277328491211, "aqua_rat_71018": 0.7955912947654724, "camel_37612": 0.7957107424736023, "aqua_rat_61393": 0.7959457039833069, "camel_10634": 0.796998143196106, "camel_11156": 0.797194242477417, "camel_10571": 0.7979680895805359, "aqua_rat_86707": 0.8001515865325928, "aqua_rat_51142": 0.8001857399940491, "aqua_rat_73156": 0.8005079627037048, "aqua_rat_14944": 0.8009066581726074, "camel_28142": 0.8014901876449585, "camel_10952": 0.8018637895584106, "aqua_rat_87100": 0.8022101521492004, "camel_29102": 0.8032047748565674, "aqua_rat_69505": 0.8035220503807068, "aqua_rat_30573": 0.8036043643951416, "camel_10937": 0.8037125468254089, "camel_10511": 0.8038252592086792, "camel_10555": 0.8038572669029236, "aqua_rat_84401": 0.803986668586731, "camel_10890": 0.8045716881752014, "camel_36244": 0.8045975565910339, "camel_11650": 0.8047999143600464, "camel_10914": 0.8050553202629089, "camel_11498": 0.8052847981452942, "camel_10636": 0.8056808710098267, "camel_10599": 0.8062579035758972, "camel_11679": 0.8064218163490295, "aqua_rat_67820": 0.8068938851356506, "aqua_rat_75801": 0.8081430792808533, "camel_11623": 0.8093199729919434, "camel_10622": 0.8097205758094788, "camel_11308": 0.8115555644035339, "aqua_rat_2646": 0.8128123879432678, "camel_36276": 0.818065345287323, "camel_11629": 0.8186219334602356, "camel_11491": 0.8237400054931641, "camel_11619": 0.8383382558822632, "camel_10635": 0.8430432081222534, "camel_10639": 0.847837507724762}, "TheoremQA_wenhuchen/kepler's_law3.json": {"TheoremQA_wenhuchen/kepler's_law3.json": 0, "camel_39452": 0.6994274258613586, "math_test_algebra_2631": 0.6994543671607971, "aqua_rat_18752": 0.6994771361351013, "aqua_rat_49753": 0.6995494961738586, "camel_28840": 0.6995518803596497, "camel_36840": 0.6995662450790405, "aqua_rat_47837": 0.6995786428451538, "aqua_rat_8007": 0.6996464133262634, "aqua_rat_6676": 0.6997874975204468, "gsm_rft_4136": 0.699806272983551, "aqua_rat_2020": 0.6998512148857117, "camel_4972": 0.7000139951705933, "math_test_prealgebra_1873": 0.700219452381134, "aqua_rat_4869": 0.7002337574958801, "gsm_rft_14302": 0.7003453969955444, "gsm_train_15265": 0.7003453969955444, "gsm_rft_5566": 0.7003453969955444, "camel_5057": 0.7003517150878906, "camel_39500": 0.7004187703132629, "aqua_rat_40694": 0.7004314064979553, "aqua_rat_73831": 0.7006759643554688, "aqua_rat_12254": 0.7006780505180359, "aqua_rat_78220": 0.700727105140686, "camel_17811": 0.7008156180381775, "aqua_rat_39787": 0.7010688185691833, "aqua_rat_75694": 0.7011674642562866, "camel_28909": 0.7011811137199402, "aqua_rat_60136": 0.7012912034988403, "aqua_rat_87545": 0.7014016509056091, "camel_28811": 0.7014489769935608, "camel_4969": 0.7015119791030884, "aqua_rat_59621": 0.7016009092330933, "aqua_rat_56309": 0.7017980813980103, "aqua_rat_43369": 0.7021857500076294, "camel_24344": 0.7022448778152466, "gsm_rft_12769": 0.7024062871932983, "aqua_rat_60511": 0.7024279236793518, "aqua_rat_13443": 0.7024682760238647, "camel_39488": 0.7028807997703552, "aqua_rat_50879": 0.702906608581543, "aqua_rat_12499": 0.7029476761817932, "aqua_rat_65833": 0.702987015247345, "aqua_rat_73906": 0.7031196355819702, "gsm_rft_8748": 0.7031745314598083, "aqua_rat_40402": 0.7032222151756287, "aqua_rat_9906": 0.7032510042190552, "aqua_rat_20126": 0.7037355303764343, "camel_28532": 0.7037472724914551, "camel_4979": 0.703751802444458, "aqua_rat_17586": 0.7039888501167297, "aqua_rat_67038": 0.7040098309516907, "aqua_rat_20614": 0.7040508985519409, "gsm_rft_24796": 0.7044654488563538, "aqua_rat_49292": 0.7044901251792908, "aqua_rat_28523": 0.7046224474906921, "aqua_rat_67003": 0.7047578692436218, "aqua_rat_6709": 0.7051795721054077, "aqua_rat_77888": 0.7052218914031982, "aqua_rat_76036": 0.705520749092102, "camel_39455": 0.7055453062057495, "aqua_rat_29570": 0.7056959867477417, "gsm_rft_14868": 0.705893874168396, "gsm_rft_12701": 0.7059549689292908, "aqua_rat_18184": 0.705958902835846, "aqua_rat_24388": 0.7060789465904236, "gsm_train_3790": 0.7061524391174316, "gsm_rft_5266": 0.7061524391174316, "aqua_rat_86431": 0.7061627507209778, "camel_28846": 0.7064903974533081, "aqua_rat_61971": 0.7072024345397949, "aqua_rat_64885": 0.7074455618858337, "camel_37936": 0.7075206637382507, "aqua_rat_6162": 0.7077609300613403, "camel_28068": 0.7079724073410034, "camel_5311": 0.7080565690994263, "aqua_rat_36411": 0.708147406578064, "aqua_rat_25154": 0.7081508040428162, "camel_39446": 0.7085431814193726, "gsm_rft_2271": 0.7086251378059387, "aqua_rat_64905": 0.709509551525116, "gsm_train_5301": 0.7095500230789185, "aqua_rat_76700": 0.7096408605575562, "gsm_rft_11101": 0.7096743583679199, "gsm_rft_2601": 0.7096743583679199, "camel_5284": 0.7105890512466431, "camel_4987": 0.7107201218605042, "gsm_train_21544": 0.7107897400856018, "aqua_rat_3859": 0.7107993960380554, "aqua_rat_48696": 0.7108370065689087, "aqua_rat_9793": 0.7109026312828064, "camel_39447": 0.7111173868179321, "gsm_rft_19699": 0.7111774682998657, "gsm_train_2173": 0.7111774682998657, "aqua_rat_81631": 0.711313009262085, "gsm_rft_32618": 0.7113285064697266, "gsm_rft_7812": 0.7113638520240784, "gsm_rft_6897": 0.7118545174598694, "aqua_rat_18562": 0.7118856310844421, "aqua_rat_57727": 0.7119289040565491, "gsm_rft_7695": 0.7121239304542542, "camel_39453": 0.712136447429657, "aqua_rat_60297": 0.7124582529067993, "aqua_rat_42126": 0.7124853134155273, "aqua_rat_41482": 0.713026225566864, "aqua_rat_11549": 0.7133840918540955, "aqua_rat_20932": 0.7134802937507629, "aqua_rat_2995": 0.7135099768638611, "aqua_rat_73760": 0.7136537432670593, "camel_5004": 0.7140957713127136, "gsm_rft_34580": 0.7146178483963013, "aqua_rat_53936": 0.714654266834259, "aqua_rat_15489": 0.7148000001907349, "camel_39467": 0.7148969769477844, "aqua_rat_54375": 0.7150692343711853, "aqua_rat_71816": 0.7152089476585388, "aqua_rat_61332": 0.715269148349762, "aqua_rat_3331": 0.7153931260108948, "camel_5178": 0.7159320116043091, "aqua_rat_51123": 0.7161284685134888, "aqua_rat_79015": 0.7162843346595764, "aqua_rat_77586": 0.7163215279579163, "aqua_rat_16975": 0.7173187732696533, "gsm_train_21024": 0.7180399298667908, "gsm_rft_3538": 0.7180793881416321, "gsm_rft_2034": 0.7180793881416321, "aqua_rat_15984": 0.7181715369224548, "gsm_train_21052": 0.7182477712631226, "gsm_rft_6386": 0.7185730338096619, "gsm_rft_9980": 0.7186915278434753, "gsm_rft_5789": 0.7193345427513123, "camel_4999": 0.7199776768684387, "camel_39471": 0.7204023003578186, "aqua_rat_47596": 0.720637321472168, "aqua_rat_12010": 0.7207714915275574, "gsm_rft_10934": 0.7208967804908752, "gsm_rft_1431": 0.7210030555725098, "gsm_train_23496": 0.7210097312927246, "camel_4993": 0.7210492491722107, "camel_28847": 0.7211272716522217, "gsm_rft_18251": 0.7211305499076843, "gsm_rft_32685": 0.7212395071983337, "aqua_rat_11192": 0.7214308977127075, "math_test_algebra_1169": 0.7216092944145203, "aqua_rat_58051": 0.721808671951294, "aqua_rat_11867": 0.7218853831291199, "gsm_train_18003": 0.7219505906105042, "gsm_rft_25136": 0.7219505906105042, "gsm_rft_24790": 0.7219505906105042, "TheoremQA_xinyi/newtons_laws_1.json": 0.7220144867897034, "camel_5001": 0.722568154335022, "camel_29979": 0.7229295969009399, "camel_5035": 0.7238606214523315, "aqua_rat_42202": 0.7244789600372314, "aqua_rat_35471": 0.7246215343475342, "gsm_rft_10474": 0.7250024080276489, "gsm_rft_57": 0.7250819802284241, "gsm_rft_22533": 0.7251908779144287, "aqua_rat_42233": 0.7251994609832764, "aqua_rat_56584": 0.725299060344696, "gsm_rft_3828": 0.7262179255485535, "gsm_rft_22295": 0.7263129949569702, "camel_4994": 0.7263386249542236, "aqua_rat_43435": 0.7264035940170288, "math_train_algebra_2034": 0.7264166474342346, "camel_17406": 0.7271236181259155, "gsm_rft_24978": 0.7277459502220154, "gsm_rft_34630": 0.728262722492218, "camel_29489": 0.7292115092277527, "gsm_rft_22397": 0.7293960452079773, "aqua_rat_86642": 0.7299568057060242, "gsm_rft_10505": 0.7307589054107666, "camel_5344": 0.7317273616790771, "gsm_train_29099": 0.735309898853302, "gsm_rft_17764": 0.735309898853302, "gsm_rft_35145": 0.7372189164161682, "TheoremQA_panlu/uniform_circular_motion2.json": 0.7380487322807312, "camel_28137": 0.7419782876968384, "aqua_rat_70945": 0.7442405819892883, "aqua_rat_88155": 0.7468183636665344, "camel_39515": 0.749331533908844, "TheoremQA_panlu/gravitational_force2.json": 0.7509174942970276, "TheoremQA_panlu/gravitational_force1.json": 0.7544122934341431, "TheoremQA_panlu/black_hole1.json": 0.7554770708084106, "aqua_rat_26489": 0.7563496232032776, "aqua_rat_63716": 0.7607676386833191, "gsm_rft_21861": 0.765092134475708, "gsm_train_25944": 0.765092134475708, "gsm_rft_14753": 0.765092134475708, "aqua_rat_70741": 0.7673199772834778, "aqua_rat_43112": 0.7721995115280151, "math_train_algebra_2156": 0.7798139452934265, "aqua_rat_6249": 0.7824417948722839, "aqua_rat_36823": 0.7828149199485779, "aqua_rat_18805": 0.7928127646446228, "TheoremQA_panlu/energy_conservation1.json": 0.7952439188957214, "camel_39513": 0.8138626217842102, "TheoremQA_wenhuchen/kepler's_law2.json": 0.8138918876647949, "TheoremQA_wenhuchen/kepler's_law1.json": 0.825800895690918, "camel_39449": 0.8605405688285828}, "TheoremQA_wenhuchen/L'H\u00f4pital_rule2.json": {"camel_6449": 0, "camel_7251": 0, "camel_7035": 0, "camel_7221": 0, "camel_7714": 0, "camel_7208": 0, "camel_7317": 0, "camel_6107": 0, "camel_7304": 0, "camel_7309": 0, "camel_7202": 0, "camel_7244": 0, "camel_7224": 0, "camel_7260": 0, "camel_6309": 0, "camel_7125": 0, "camel_7011": 0, "camel_7019": 0, "camel_7128": 0, "camel_7252": 0, "camel_7263": 0, "camel_7254": 0, "camel_7273": 0, "camel_7149": 0, "camel_7247": 0, "camel_7259": 0, "camel_7261": 0, "camel_7232": 0, "camel_7267": 0, "camel_7236": 0, "camel_7211": 0, "camel_7218": 0, "camel_7256": 0, "camel_7209": 0, "camel_7138": 0, "camel_7262": 0, "camel_7205": 0, "camel_7275": 0, "camel_7266": 0, "camel_7230": 0, "camel_7270": 0, "camel_7269": 0, "camel_7257": 0, "camel_7248": 0, "camel_7238": 0, "camel_7160": 0, "camel_7214": 0, "camel_7233": 0, "camel_7250": 0, "camel_7231": 0, "camel_7016": 0, "camel_7276": 0, "camel_7731": 0, "camel_7226": 0, "camel_7223": 0, "camel_7227": 0, "camel_7124": 0, "camel_6989": 0, "camel_7234": 0, "camel_7215": 0, "camel_7212": 0, "camel_6166": 0, "TheoremQA_wenhuchen/L'H\u00f4pital_rule2.json": 0, "camel_7204": 0, "camel_7277": 0, "camel_7268": 0, "camel_7237": 0, "camel_40945": 0.7165269255638123, "camel_5189": 0.7167013883590698, "camel_39323": 0.716861367225647, "camel_39314": 0.7169275879859924, "camel_30946": 0.7169386744499207, "camel_29198": 0.7171380519866943, "camel_19725": 0.7172282338142395, "camel_5051": 0.7173332571983337, "camel_30947": 0.7175724506378174, "camel_30955": 0.7179383635520935, "camel_39486": 0.7181271910667419, "camel_38221": 0.7183234095573425, "camel_18947": 0.7183621525764465, "TheoremQA_elainewan/math_calculus_2_11.json": 0.7183694839477539, "camel_43012": 0.7185148596763611, "camel_43036": 0.7187292575836182, "camel_5048": 0.7187414765357971, "aqua_rat_49646": 0.7188215851783752, "camel_45680": 0.7188273072242737, "camel_30959": 0.7188288569450378, "camel_41712": 0.7188405394554138, "camel_38121": 0.7188432216644287, "camel_30160": 0.7191311120986938, "camel_5165": 0.7193255424499512, "camel_5342": 0.7195958495140076, "camel_5111": 0.719606339931488, "camel_18295": 0.7196949124336243, "camel_38892": 0.7197606563568115, "camel_31309": 0.7198740839958191, "camel_18928": 0.720193088054657, "camel_30883": 0.7203799486160278, "camel_18956": 0.7207666635513306, "camel_5098": 0.7208454012870789, "camel_5066": 0.7213219404220581, "camel_5314": 0.7213401198387146, "camel_40882": 0.7217077016830444, "camel_18130": 0.7218661308288574, "camel_31316": 0.7219429016113281, "camel_41950": 0.7223895192146301, "TheoremQA_elainewan/math_calculus_14.json": 0.7225688099861145, "camel_39085": 0.722712516784668, "camel_45969": 0.7230032682418823, "camel_38938": 0.7232964038848877, "camel_40781": 0.7233438491821289, "camel_30921": 0.7234269976615906, "camel_45312": 0.7234725952148438, "camel_39351": 0.7238216400146484, "camel_30925": 0.7245436906814575, "camel_30954": 0.7245703935623169, "camel_30881": 0.7250037789344788, "camel_30942": 0.7251036763191223, "camel_30892": 0.7251630425453186, "camel_42925": 0.7254222631454468, "camel_18918": 0.7256125211715698, "camel_30886": 0.7259455919265747, "aqua_rat_16683": 0.7264184355735779, "camel_4986": 0.7266966700553894, "camel_40850": 0.7271859645843506, "camel_30914": 0.7273732423782349, "camel_42911": 0.7274516224861145, "camel_19813": 0.7277444005012512, "camel_18893": 0.727863073348999, "camel_31104": 0.7285952568054199, "camel_5065": 0.7287634611129761, "camel_30928": 0.7288654446601868, "camel_41997": 0.7290462851524353, "camel_45293": 0.7293274998664856, "camel_41853": 0.7293952703475952, "camel_39466": 0.729532778263092, "camel_5008": 0.7298100590705872, "camel_31339": 0.7298215627670288, "camel_46120": 0.7308475971221924, "camel_30948": 0.7309206128120422, "camel_42816": 0.7309624552726746, "camel_5303": 0.7316716313362122, "camel_1528": 0.7324475049972534, "camel_29060": 0.7326071262359619, "camel_18783": 0.7327438592910767, "camel_31294": 0.7334169745445251, "camel_30887": 0.7335541248321533, "camel_30898": 0.7336610555648804, "camel_39598": 0.7342833876609802, "camel_18139": 0.7343674302101135, "camel_18922": 0.734671950340271, "camel_30952": 0.7354987263679504, "camel_39104": 0.7359859347343445, "camel_45342": 0.7360581159591675, "camel_18905": 0.73639315366745, "camel_30943": 0.7371607422828674, "camel_30944": 0.7372617721557617, "camel_30923": 0.7380430698394775, "camel_41967": 0.7388520240783691, "camel_28086": 0.7403365969657898, "camel_30920": 0.7412580251693726, "camel_30956": 0.7417267560958862, "camel_5090": 0.7417870163917542, "camel_30916": 0.7427479028701782, "camel_18784": 0.7429923415184021, "camel_30926": 0.7431824803352356, "camel_1750": 0.7443997263908386, "camel_30885": 0.7451070547103882, "camel_28147": 0.7453945279121399, "camel_30953": 0.7456098794937134, "camel_30884": 0.7458884716033936, "camel_30917": 0.7461443543434143, "camel_39338": 0.7461548447608948, "camel_18936": 0.7477704882621765, "camel_42282": 0.7484868168830872, "camel_30904": 0.7493979334831238, "TheoremQA_xueguangma/rolle_theorem.json": 0.7506526112556458, "camel_18951": 0.7507721781730652, "camel_30888": 0.7510135769844055, "camel_30931": 0.7519282698631287, "camel_39357": 0.7528793215751648, "camel_18891": 0.752894401550293, "camel_30932": 0.7532792091369629, "camel_39254": 0.7550008296966553, "camel_30903": 0.7567090392112732, "camel_18950": 0.7615010142326355, "camel_30908": 0.7627092599868774, "camel_30919": 0.7659351229667664, "camel_30882": 0.767221987247467, "camel_18920": 0.7722232937812805, "camel_18917": 0.7723501920700073, "camel_18940": 0.7742117047309875, "camel_30880": 0.7747759819030762, "camel_30907": 0.7756304144859314, "camel_18883": 0.7757713198661804, "camel_30945": 0.7806959748268127, "camel_18909": 0.786058783531189, "camel_18957": 0.790190577507019, "camel_18919": 0.7935457825660706, "camel_18882": 0.804229199886322}, "TheoremQA_elainewan/math_calculus_2_6.json": {"camel_6239": 0, "camel_7731": 0, "camel_5108": 0.6959666013717651, "camel_5124": 0.6960322260856628, "camel_5270": 0.6960680484771729, "camel_4842": 0.6960957646369934, "camel_45179": 0.6961092948913574, "camel_5163": 0.6962142586708069, "camel_5069": 0.6962752342224121, "camel_4980": 0.6964150071144104, "camel_4777": 0.696418285369873, "camel_17811": 0.6966665387153625, "camel_5212": 0.6966708898544312, "camel_5075": 0.6966805458068848, "camel_4983": 0.6967059969902039, "camel_5049": 0.6968745589256287, "camel_5225": 0.6969441175460815, "camel_16592": 0.6970586180686951, "camel_4954": 0.697087287902832, "camel_16623": 0.6971408724784851, "camel_4992": 0.6971533298492432, "camel_5265": 0.6971936821937561, "camel_5102": 0.6972076296806335, "camel_5136": 0.697296142578125, "camel_5133": 0.6973196268081665, "camel_5571": 0.6973303556442261, "camel_5071": 0.6973543763160706, "camel_16572": 0.6973773241043091, "camel_5192": 0.6975299119949341, "camel_45195": 0.6975416541099548, "camel_5256": 0.6975900530815125, "camel_45146": 0.6976595520973206, "camel_45969": 0.6977042555809021, "camel_5215": 0.6977939605712891, "camel_5010": 0.697897732257843, "camel_5157": 0.6983113288879395, "camel_45182": 0.6983771920204163, "camel_5046": 0.6983998417854309, "camel_5017": 0.6986182332038879, "camel_5257": 0.6986363530158997, "camel_5188": 0.6988499760627747, "camel_4792": 0.698905348777771, "camel_5853": 0.6989293098449707, "camel_45492": 0.6989830732345581, "camel_5123": 0.699277937412262, "camel_5176": 0.6994139552116394, "camel_29979": 0.6994345784187317, "camel_5214": 0.6994984149932861, "camel_45352": 0.6995998620986938, "camel_5223": 0.6997031569480896, "camel_45759": 0.6998901963233948, "camel_28147": 0.6998922824859619, "camel_5090": 0.6999181509017944, "camel_5148": 0.6999518275260925, "camel_45191": 0.6999717950820923, "camel_5087": 0.7000188231468201, "camel_39308": 0.7001147270202637, "camel_5285": 0.7003037929534912, "camel_5112": 0.7003814578056335, "camel_5169": 0.700632631778717, "camel_5130": 0.7007755041122437, "camel_5164": 0.7008149027824402, "camel_45289": 0.7008407115936279, "camel_5012": 0.7008578777313232, "camel_5151": 0.7010512351989746, "camel_45184": 0.7011047601699829, "camel_5184": 0.7014559507369995, "camel_5072": 0.7018040418624878, "camel_5210": 0.7020048499107361, "camel_5548": 0.702098548412323, "camel_16564": 0.702193021774292, "camel_5032": 0.7024343013763428, "camel_5044": 0.7024458646774292, "camel_5899": 0.7025660872459412, "camel_4928": 0.7028785943984985, "camel_4132": 0.7028940916061401, "camel_4946": 0.7031775712966919, "camel_17784": 0.7033233046531677, "camel_4820": 0.703659176826477, "camel_4495": 0.7037060260772705, "camel_4837": 0.7040388584136963, "camel_45286": 0.7040390968322754, "camel_5093": 0.7040446996688843, "camel_45322": 0.7040708661079407, "camel_5205": 0.7041845321655273, "camel_45199": 0.704253077507019, "camel_39489": 0.7042712569236755, "camel_5089": 0.7043737769126892, "camel_5083": 0.7043755054473877, "camel_5191": 0.7047346830368042, "camel_5026": 0.7048134207725525, "camel_5065": 0.7048198580741882, "camel_5147": 0.7048302888870239, "camel_4974": 0.7048621773719788, "camel_4961": 0.705071747303009, "camel_5146": 0.7052174210548401, "camel_45745": 0.7053264379501343, "camel_45142": 0.7053716778755188, "camel_5153": 0.7054862976074219, "camel_4988": 0.7058419585227966, "camel_5334": 0.7058439254760742, "camel_5085": 0.7060930132865906, "camel_5181": 0.706420361995697, "camel_5152": 0.7064638137817383, "camel_5063": 0.7067391276359558, "camel_5118": 0.7067668437957764, "camel_5059": 0.7069133520126343, "camel_28080": 0.7071155309677124, "camel_39254": 0.7081918716430664, "camel_5198": 0.7083742618560791, "camel_5233": 0.7086454033851624, "camel_43782": 0.709217369556427, "camel_5134": 0.7094668745994568, "camel_16597": 0.7094814777374268, "camel_16626": 0.7097272872924805, "camel_5073": 0.7097862362861633, "camel_5167": 0.7098836302757263, "camel_5103": 0.7099841833114624, "camel_5053": 0.7101415991783142, "camel_16577": 0.7105650305747986, "camel_16598": 0.7105997204780579, "camel_5043": 0.7110122442245483, "camel_5101": 0.7111853957176208, "camel_5094": 0.7113896012306213, "camel_4978": 0.7118259072303772, "camel_5222": 0.7119635343551636, "camel_5357": 0.712058961391449, "camel_45129": 0.7121996879577637, "camel_39327": 0.712767481803894, "camel_16567": 0.7132396101951599, "camel_16618": 0.7133232355117798, "camel_5086": 0.7133793234825134, "camel_5077": 0.7133920192718506, "camel_5172": 0.7135746479034424, "camel_45681": 0.713827908039093, "camel_45314": 0.7139604687690735, "camel_5158": 0.7141072154045105, "camel_5034": 0.7142109274864197, "camel_5333": 0.7143522500991821, "camel_5272": 0.7146449089050293, "camel_16627": 0.7146663665771484, "camel_5185": 0.7148876786231995, "camel_5177": 0.7150850892066956, "camel_5189": 0.7152750492095947, "camel_5303": 0.7152875661849976, "camel_16579": 0.715490996837616, "camel_45359": 0.716390073299408, "camel_5139": 0.7163915038108826, "camel_5029": 0.7165552973747253, "camel_5180": 0.7167477607727051, "camel_5111": 0.7169598340988159, "camel_16616": 0.7172254920005798, "camel_5055": 0.7172598242759705, "camel_16613": 0.7172654271125793, "camel_29860": 0.717294454574585, "camel_5104": 0.7173454165458679, "camel_45174": 0.7173805236816406, "camel_5119": 0.7175793051719666, "camel_45185": 0.7178873419761658, "camel_5078": 0.7179784774780273, "camel_5113": 0.7180691361427307, "camel_45301": 0.7181040644645691, "camel_5129": 0.7184861302375793, "camel_16615": 0.7184866070747375, "camel_5068": 0.7186271548271179, "camel_5007": 0.7186663746833801, "camel_5037": 0.7189207077026367, "camel_16590": 0.719001054763794, "camel_5041": 0.7191286087036133, "camel_5295": 0.719300389289856, "camel_4986": 0.7195024490356445, "camel_5048": 0.7195900082588196, "camel_45340": 0.7199501395225525, "camel_16588": 0.7207147479057312, "camel_5109": 0.7213508486747742, "camel_45293": 0.7219094634056091, "camel_4991": 0.7219353914260864, "camel_5216": 0.7224516868591309, "camel_5235": 0.7224531769752502, "camel_45988": 0.7227033376693726, "camel_39338": 0.7231228947639465, "camel_45170": 0.723289430141449, "camel_5070": 0.7233035564422607, "camel_5092": 0.7240377068519592, "camel_5314": 0.7240628004074097, "camel_17798": 0.7252234816551208, "camel_45312": 0.7257956862449646, "camel_4965": 0.7261618375778198, "camel_16634": 0.7265738844871521, "camel_5165": 0.7288634181022644, "camel_45318": 0.730185329914093, "camel_5051": 0.7301887273788452, "camel_5098": 0.730556845664978, "camel_45342": 0.7309977412223816, "camel_5008": 0.7348997592926025, "camel_16581": 0.7355461120605469, "camel_45299": 0.7374210357666016, "camel_5227": 0.7396426796913147, "camel_28086": 0.7396933436393738, "camel_45323": 0.7441380023956299}, "TheoremQA_xueguangma/future_value_1.json": {"aqua_rat_11824": 0.8241849541664124, "aqua_rat_42949": 0.8242040872573853, "aqua_rat_60181": 0.8242505192756653, "aqua_rat_42733": 0.8242701292037964, "aqua_rat_9965": 0.8243282437324524, "aqua_rat_37916": 0.8245015144348145, "aqua_rat_27270": 0.8248732089996338, "aqua_rat_70690": 0.8250572085380554, "aqua_rat_78349": 0.8252468705177307, "aqua_rat_53421": 0.825340211391449, "aqua_rat_46898": 0.8254229426383972, "aqua_rat_88415": 0.8255027532577515, "aqua_rat_17663": 0.8255028128623962, "aqua_rat_35907": 0.8256149888038635, "aqua_rat_64664": 0.8256575465202332, "aqua_rat_85193": 0.8257204294204712, "aqua_rat_40411": 0.8257456421852112, "aqua_rat_13549": 0.8258798718452454, "aqua_rat_36240": 0.8261815905570984, "aqua_rat_59299": 0.826257586479187, "aqua_rat_88746": 0.8263298273086548, "aqua_rat_46888": 0.8263662457466125, "gsm_rft_6559": 0.8265312910079956, "aqua_rat_24646": 0.8265897631645203, "aqua_rat_27053": 0.8267131447792053, "aqua_rat_79047": 0.8269071578979492, "aqua_rat_87246": 0.8269570469856262, "aqua_rat_1115": 0.8269726037979126, "aqua_rat_48535": 0.8271474242210388, "math_train_algebra_1011": 0.8273005485534668, "math_test_algebra_990": 0.827832043170929, "aqua_rat_61757": 0.8279001712799072, "aqua_rat_50383": 0.8280675411224365, "aqua_rat_62528": 0.8282085657119751, "aqua_rat_18368": 0.828457772731781, "aqua_rat_9944": 0.828624963760376, "aqua_rat_76156": 0.8287280797958374, "aqua_rat_7674": 0.8290286660194397, "aqua_rat_28520": 0.8292873501777649, "aqua_rat_88960": 0.829423189163208, "gsm_rft_14102": 0.8295004367828369, "gsm_train_11462": 0.8295004367828369, "aqua_rat_46552": 0.8296226859092712, "aqua_rat_83638": 0.8296580910682678, "aqua_rat_61190": 0.8298829197883606, "aqua_rat_25723": 0.830010712146759, "aqua_rat_30447": 0.8301033973693848, "aqua_rat_9529": 0.8302154541015625, "aqua_rat_26770": 0.8303086161613464, "aqua_rat_56852": 0.8305239677429199, "aqua_rat_15079": 0.8305734992027283, "aqua_rat_65963": 0.8306707143783569, "aqua_rat_64635": 0.8307700157165527, "aqua_rat_66298": 0.8310056924819946, "aqua_rat_7357": 0.8310205340385437, "aqua_rat_72933": 0.8310648798942566, "math_test_algebra_311": 0.8313210606575012, "aqua_rat_47773": 0.8313394784927368, "aqua_rat_30717": 0.8313449025154114, "math_test_algebra_1611": 0.8315004706382751, "aqua_rat_38071": 0.8316066861152649, "aqua_rat_60321": 0.8316729664802551, "aqua_rat_53914": 0.8318727016448975, "aqua_rat_41143": 0.8319336771965027, "aqua_rat_3536": 0.8319931030273438, "aqua_rat_56718": 0.8323203921318054, "aqua_rat_44671": 0.8323562145233154, "aqua_rat_37780": 0.832373321056366, "aqua_rat_10990": 0.8326533436775208, "gsm_rft_11620": 0.8327104449272156, "aqua_rat_78692": 0.832882821559906, "aqua_rat_60064": 0.8329195976257324, "gsm_train_25622": 0.8330519199371338, "aqua_rat_63322": 0.8331742286682129, "aqua_rat_77744": 0.833367109298706, "aqua_rat_59668": 0.8335985541343689, "aqua_rat_59892": 0.8337651491165161, "aqua_rat_33923": 0.8338421583175659, "aqua_rat_66803": 0.8339325189590454, "aqua_rat_83234": 0.8339661359786987, "math_train_algebra_2484": 0.833979070186615, "aqua_rat_34332": 0.8341812491416931, "aqua_rat_1549": 0.8342276811599731, "aqua_rat_6657": 0.8342320919036865, "aqua_rat_42017": 0.834513247013092, "aqua_rat_75833": 0.8345230221748352, "math_train_algebra_2324": 0.8346575498580933, "aqua_rat_20903": 0.8348252177238464, "aqua_rat_77602": 0.8350781798362732, "aqua_rat_32851": 0.8351369500160217, "math_test_algebra_2626": 0.8355516195297241, "aqua_rat_59": 0.8355581164360046, "aqua_rat_22060": 0.8359518051147461, "aqua_rat_53044": 0.8361016511917114, "aqua_rat_37382": 0.8362483978271484, "aqua_rat_62727": 0.8362749814987183, "aqua_rat_63070": 0.8363844752311707, "aqua_rat_69526": 0.8363880515098572, "aqua_rat_83740": 0.8364222645759583, "aqua_rat_32350": 0.8364366888999939, "aqua_rat_72687": 0.8365293145179749, "gsm_rft_25658": 0.8366042971611023, "aqua_rat_49963": 0.8366557359695435, "aqua_rat_50447": 0.8366702795028687, "math_test_algebra_337": 0.8367337584495544, "aqua_rat_69339": 0.8368566632270813, "aqua_rat_68636": 0.8372175097465515, "aqua_rat_79904": 0.8372183442115784, "aqua_rat_87589": 0.8373191952705383, "TheoremQA_wenhuchen/compound_interest1.json": 0.837462306022644, "aqua_rat_16693": 0.8375058770179749, "aqua_rat_49718": 0.8377275466918945, "aqua_rat_64092": 0.8377403020858765, "aqua_rat_44615": 0.8378137946128845, "aqua_rat_26339": 0.8379343748092651, "aqua_rat_84309": 0.8379378318786621, "aqua_rat_39288": 0.838007390499115, "aqua_rat_34698": 0.8381588459014893, "aqua_rat_71142": 0.8383477330207825, "aqua_rat_75047": 0.8383944630622864, "aqua_rat_67698": 0.8384837508201599, "aqua_rat_10686": 0.8385195732116699, "gsm_rft_5946": 0.8386321067810059, "aqua_rat_64976": 0.8388031125068665, "aqua_rat_33430": 0.8388057351112366, "aqua_rat_49908": 0.8389039039611816, "aqua_rat_44549": 0.8389080166816711, "aqua_rat_74003": 0.8390364646911621, "aqua_rat_42515": 0.8390803337097168, "aqua_rat_13396": 0.8391708731651306, "aqua_rat_10582": 0.839429497718811, "aqua_rat_73739": 0.8396045565605164, "aqua_rat_47882": 0.8397438526153564, "aqua_rat_43060": 0.8397815227508545, "aqua_rat_72794": 0.8399901390075684, "math_train_algebra_2129": 0.8401520252227783, "aqua_rat_88174": 0.8401556611061096, "aqua_rat_51796": 0.8402697443962097, "aqua_rat_58298": 0.8402906656265259, "gsm_rft_22915": 0.8403815627098083, "aqua_rat_43046": 0.8405534029006958, "aqua_rat_2257": 0.8407118916511536, "aqua_rat_25325": 0.8409537672996521, "aqua_rat_26976": 0.8411640524864197, "aqua_rat_48358": 0.841195285320282, "math_test_algebra_1862": 0.8415068984031677, "aqua_rat_29356": 0.8420565128326416, "aqua_rat_67076": 0.8421217203140259, "aqua_rat_65985": 0.8423966765403748, "aqua_rat_58694": 0.8424938917160034, "aqua_rat_48494": 0.8431939482688904, "gsm_rft_5849": 0.8432241678237915, "gsm_rft_7180": 0.8432591557502747, "gsm_train_5941": 0.8432591557502747, "gsm_rft_5669": 0.843260645866394, "gsm_rft_12217": 0.843592643737793, "aqua_rat_69547": 0.8437743782997131, "aqua_rat_32852": 0.8444117307662964, "aqua_rat_70031": 0.8451451063156128, "aqua_rat_41963": 0.8456659913063049, "aqua_rat_28662": 0.8461662530899048, "aqua_rat_6679": 0.8466741442680359, "gsm_rft_24617": 0.8469494581222534, "aqua_rat_59403": 0.8472088575363159, "aqua_rat_59829": 0.8502225279808044, "aqua_rat_7537": 0.8510982990264893, "aqua_rat_28282": 0.8512037396430969, "gsm_rft_17331": 0.8519935011863708, "math_train_algebra_1277": 0.8522434830665588, "aqua_rat_15337": 0.8526259660720825, "aqua_rat_735": 0.8532511591911316, "aqua_rat_869": 0.8533744812011719, "aqua_rat_33006": 0.8539203405380249, "math_train_algebra_707": 0.8539210557937622, "aqua_rat_37258": 0.8544877767562866, "math_train_algebra_667": 0.8554606437683105, "aqua_rat_86835": 0.8554731011390686, "aqua_rat_29321": 0.855685293674469, "aqua_rat_86234": 0.8566870093345642, "aqua_rat_30386": 0.857208251953125, "aqua_rat_68014": 0.8580058813095093, "aqua_rat_51100": 0.8581763505935669, "aqua_rat_39049": 0.8584209680557251, "aqua_rat_29976": 0.8584675788879395, "aqua_rat_25162": 0.8590074181556702, "aqua_rat_78121": 0.8603853583335876, "aqua_rat_71239": 0.8625531196594238, "aqua_rat_66371": 0.8633961081504822, "aqua_rat_12597": 0.8642048835754395, "math_test_algebra_608": 0.8642213940620422, "aqua_rat_73390": 0.8658250570297241, "aqua_rat_21814": 0.8664780855178833, "aqua_rat_20423": 0.8684015870094299, "gsm_rft_9932": 0.8719466328620911, "math_train_algebra_957": 0.8721486330032349, "gsm_train_26849": 0.8749818205833435, "gsm_rft_19092": 0.8749818205833435, "gsm_rft_28176": 0.8760573863983154, "math_train_algebra_369": 0.8831526637077332, "math_test_algebra_594": 0.8879278302192688}, "TheoremQA_jianyu_xu/pigeonhole_1.json": {"camel_21164": 0, "camel_21184": 0, "camel_20540": 0, "camel_21194": 0, "camel_20256": 0, "camel_21155": 0, "camel_21180": 0, "camel_21568": 0, "camel_21130": 0, "camel_20287": 0, "camel_21179": 0, "camel_21822": 0, "camel_21158": 0, "camel_20898": 0, "camel_21146": 0, "camel_21162": 0, "camel_21178": 0, "camel_21123": 0, "camel_21147": 0, "camel_21156": 0, "camel_21190": 0, "camel_21137": 0, "camel_21798": 0, "camel_21159": 0, "camel_21193": 0, "camel_21165": 0, "camel_21166": 0, "camel_21185": 0, "camel_21131": 0, "camel_21124": 0, "camel_21126": 0, "camel_21142": 0, "camel_21163": 0, "camel_21182": 0, "camel_21161": 0, "camel_21141": 0, "camel_21171": 0, "camel_21177": 0, "camel_21122": 0, "camel_21120": 0, "camel_21139": 0, "camel_21153": 0, "camel_21174": 0, "camel_21134": 0, "camel_21172": 0, "camel_21154": 0, "camel_21186": 0, "camel_21376": 0, "camel_21128": 0, "camel_21157": 0, "camel_21187": 0, "camel_21152": 0, "camel_21160": 0, "camel_21121": 0, "camel_21196": 0, "camel_21173": 0, "camel_21132": 0, "camel_21170": 0, "camel_21175": 0, "camel_21143": 0, "camel_21125": 0, "camel_21168": 0, "camel_21145": 0, "camel_21188": 0, "camel_20577": 0, "camel_21198": 0, "camel_21195": 0, "camel_21135": 0, "camel_21055": 0, "camel_21169": 0, "camel_21176": 0, "camel_21040": 0, "camel_21835": 0, "camel_21183": 0, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0, "aqua_rat_81742": 0.7511252164840698, "aqua_rat_63725": 0.751182496547699, "aqua_rat_46435": 0.7512783408164978, "math_test_counting_and_probability_987": 0.7516161799430847, "aqua_rat_37188": 0.7516970038414001, "aqua_rat_45273": 0.7520228624343872, "aqua_rat_62050": 0.7520635724067688, "aqua_rat_47768": 0.7524521350860596, "aqua_rat_73523": 0.7524567246437073, "aqua_rat_19178": 0.7527171969413757, "aqua_rat_66892": 0.7527765035629272, "camel_23752": 0.7530834078788757, "aqua_rat_10371": 0.7532368898391724, "aqua_rat_79267": 0.753415048122406, "aqua_rat_17359": 0.7535316348075867, "aqua_rat_48326": 0.7537055015563965, "aqua_rat_40065": 0.7540026903152466, "aqua_rat_51541": 0.7542088627815247, "aqua_rat_38419": 0.7545269131660461, "aqua_rat_56889": 0.7545710802078247, "aqua_rat_42578": 0.7548439502716064, "aqua_rat_24238": 0.7551648020744324, "aqua_rat_29990": 0.7554215788841248, "aqua_rat_11601": 0.7559335827827454, "aqua_rat_17862": 0.7559656500816345, "aqua_rat_30610": 0.7562064528465271, "aqua_rat_82439": 0.7562785744667053, "aqua_rat_34677": 0.7563345432281494, "math_train_counting_and_probability_1110": 0.7565370798110962, "aqua_rat_85357": 0.7565600872039795, "aqua_rat_39271": 0.7566004395484924, "aqua_rat_83797": 0.756820023059845, "aqua_rat_56307": 0.7569674253463745, "camel_23693": 0.7570319771766663, "aqua_rat_40277": 0.7570437788963318, "aqua_rat_19090": 0.7572806477546692, "aqua_rat_48010": 0.7573789954185486, "aqua_rat_20004": 0.757468044757843, "aqua_rat_31828": 0.7575064897537231, "aqua_rat_75262": 0.7575599551200867, "math_train_counting_and_probability_5123": 0.7582887411117554, "aqua_rat_33643": 0.7585290670394897, "aqua_rat_83796": 0.7585423588752747, "aqua_rat_31046": 0.7588561177253723, "aqua_rat_27921": 0.7589015364646912, "aqua_rat_80435": 0.7589668035507202, "aqua_rat_15442": 0.7591170072555542, "aqua_rat_73303": 0.7592690587043762, "camel_38526": 0.7597042322158813, "aqua_rat_31932": 0.7600148320198059, "aqua_rat_149": 0.760015070438385, "aqua_rat_76846": 0.7605136036872864, "aqua_rat_27075": 0.760634183883667, "aqua_rat_72312": 0.7606956362724304, "aqua_rat_76356": 0.760796308517456, "aqua_rat_23636": 0.7611376047134399, "camel_23690": 0.7622094750404358, "aqua_rat_71213": 0.762576699256897, "aqua_rat_86710": 0.7628818154335022, "aqua_rat_52525": 0.7632169127464294, "aqua_rat_5662": 0.7634838819503784, "camel_38505": 0.763497531414032, "aqua_rat_15511": 0.7635032534599304, "aqua_rat_46632": 0.7635318636894226, "aqua_rat_19096": 0.7635954022407532, "aqua_rat_8519": 0.7641648650169373, "aqua_rat_33304": 0.7648295164108276, "aqua_rat_39047": 0.7649960517883301, "aqua_rat_38285": 0.7650792598724365, "aqua_rat_16788": 0.7652954459190369, "aqua_rat_78805": 0.7655973434448242, "math_test_counting_and_probability_341": 0.7657200694084167, "math_train_prealgebra_1917": 0.765902578830719, "aqua_rat_10136": 0.7663618326187134, "aqua_rat_26254": 0.7664953470230103, "aqua_rat_59053": 0.7666739821434021, "aqua_rat_80759": 0.7667589783668518, "aqua_rat_23524": 0.7668460011482239, "aqua_rat_73560": 0.7670413255691528, "aqua_rat_7648": 0.76711106300354, "aqua_rat_20969": 0.767175555229187, "aqua_rat_7521": 0.7672551274299622, "aqua_rat_65028": 0.7675897479057312, "aqua_rat_87746": 0.7677052021026611, "aqua_rat_5877": 0.7679847478866577, "aqua_rat_15706": 0.7683776021003723, "aqua_rat_67387": 0.7684113383293152, "aqua_rat_48028": 0.7689475417137146, "aqua_rat_84086": 0.7700920104980469, "aqua_rat_74390": 0.7702022790908813, "aqua_rat_9092": 0.7705017924308777, "TheoremQA_jianyu_xu/pigeonhole_3.json": 0.770550549030304, "aqua_rat_34164": 0.7706981301307678, "aqua_rat_48816": 0.7713419198989868, "aqua_rat_20302": 0.7714656591415405, "aqua_rat_80145": 0.7716546654701233, "aqua_rat_25103": 0.7719887495040894, "aqua_rat_53649": 0.773196816444397, "aqua_rat_4199": 0.7733604907989502, "aqua_rat_55838": 0.7742320895195007, "aqua_rat_6686": 0.7759951949119568, "camel_11529": 0.7760655283927917, "aqua_rat_52771": 0.7767471671104431, "aqua_rat_26932": 0.7771183252334595, "aqua_rat_47084": 0.7776033282279968, "aqua_rat_70890": 0.7783126831054688, "aqua_rat_15480": 0.7806246876716614, "camel_23682": 0.7825175523757935, "aqua_rat_53788": 0.7825382351875305, "aqua_rat_69238": 0.7842933535575867, "TheoremQA_jianyu_xu/Ramsey_3.json": 0.7844564318656921, "camel_38538": 0.7854297161102295, "aqua_rat_50073": 0.7855809926986694, "aqua_rat_39765": 0.7861529588699341, "aqua_rat_58088": 0.7880281805992126, "camel_23711": 0.7919549345970154, "aqua_rat_87294": 0.793346107006073, "TheoremQA_jianyu_xu/Ramsey_2.json": 0.7942839860916138, "aqua_rat_51045": 0.7943902015686035, "aqua_rat_65264": 0.7960653901100159, "aqua_rat_50597": 0.7987287044525146, "aqua_rat_33710": 0.8033407926559448, "TheoremQA_jianyu_xu/pigeonhole_4.json": 0.8113148808479309, "aqua_rat_14782": 0.8114381432533264, "aqua_rat_6737": 0.8130452632904053}, "TheoremQA_jianyu_xu/Ramsey_3.json": {"camel_22780": 0, "camel_23753": 0, "camel_22959": 0, "camel_23687": 0, "camel_23766": 0, "camel_23696": 0, "camel_21809": 0, "camel_21773": 0, "camel_21793": 0, "camel_23706": 0, "camel_21781": 0, "camel_23686": 0, "camel_23422": 0, "camel_22934": 0, "camel_21774": 0, "camel_22939": 0, "camel_23764": 0, "camel_23728": 0, "camel_21040": 0, "camel_21065": 0, "camel_23714": 0, "camel_23427": 0, "camel_22138": 0, "camel_21169": 0, "camel_21106": 0, "camel_23784": 0, "camel_22917": 0, "camel_21812": 0, "camel_21068": 0, "camel_22164": 0, "camel_23816": 0, "camel_21103": 0, "camel_23724": 0, "camel_21784": 0, "camel_23736": 0, "camel_22170": 0, "camel_23827": 0, "camel_23369": 0, "camel_23790": 0, "camel_23751": 0, "camel_22356": 0, "camel_22927": 0, "camel_22347": 0, "camel_21183": 0, "camel_23720": 0, "camel_22947": 0, "camel_21806": 0, "camel_21120": 0, "camel_21196": 0, "camel_21794": 0, "camel_23418": 0, "camel_21184": 0, "camel_23744": 0, "camel_21782": 0, "camel_22203": 0, "camel_21136": 0, "camel_21767": 0, "camel_21803": 0, "camel_23737": 0, "camel_22161": 0, "camel_23788": 0, "camel_23795": 0, "camel_22239": 0, "camel_23775": 0, "camel_21158": 0, "camel_21149": 0, "camel_23695": 0, "camel_23700": 0, "camel_23710": 0, "camel_21768": 0, "camel_22238": 0, "camel_23742": 0, "camel_22202": 0, "camel_23734": 0, "camel_21192": 0, "camel_23414": 0, "camel_23741": 0, "camel_23747": 0, "camel_21818": 0, "camel_21826": 0, "camel_21159": 0, "camel_23684": 0, "camel_23681": 0, "camel_23713": 0, "camel_23719": 0, "camel_23745": 0, "camel_23717": 0, "camel_23749": 0, "camel_21147": 0, "camel_21167": 0, "camel_21141": 0, "camel_21174": 0, "camel_21176": 0, "camel_21144": 0, "camel_23711": 0, "camel_21160": 0, "camel_21135": 0, "camel_21124": 0, "camel_21161": 0, "camel_21111": 0, "camel_21175": 0, "camel_21131": 0, "camel_21129": 0, "camel_23367": 0, "camel_21156": 0, "camel_21130": 0, "camel_21166": 0, "camel_21181": 0, "camel_21146": 0, "camel_21191": 0, "camel_21116": 0, "camel_23707": 0, "camel_21134": 0, "camel_21151": 0, "camel_21179": 0, "camel_21824": 0, "camel_21153": 0, "camel_21148": 0, "camel_23755": 0, "camel_22388": 0, "camel_21190": 0, "camel_21137": 0, "camel_21168": 0, "camel_23729": 0, "camel_21185": 0, "camel_21193": 0, "camel_21142": 0, "camel_22905": 0, "camel_21182": 0, "camel_23740": 0, "camel_21143": 0, "camel_21178": 0, "TheoremQA_jianyu_xu/Ramsey_3.json": 0, "camel_23750": 0, "camel_23756": 0, "camel_21123": 0, "camel_21152": 0, "camel_21188": 0, "camel_23699": 0, "camel_21155": 0, "camel_23789": 0, "camel_23693": 0, "camel_21145": 0, "camel_21797": 0, "camel_21180": 0, "camel_23735": 0, "camel_21122": 0, "camel_22207": 0, "camel_23685": 0, "camel_23399": 0, "camel_21173": 0, "camel_21195": 0, "camel_21139": 0, "camel_23748": 0, "camel_21186": 0, "camel_22393": 0, "camel_21157": 0, "camel_21172": 0, "camel_22230": 0, "camel_21127": 0, "camel_23732": 0, "camel_21170": 0, "camel_23680": 0, "camel_23692": 0, "camel_23739": 0, "camel_21187": 0, "camel_21198": 0, "camel_21163": 0, "camel_23705": 0, "camel_21162": 0, "camel_23758": 0, "camel_23709": 0, "camel_21194": 0, "camel_23683": 0, "camel_21121": 0, "camel_23759": 0, "camel_21125": 0, "camel_23703": 0, "camel_23723": 0, "camel_23697": 0, "camel_23682": 0, "camel_21133": 0, "camel_21171": 0, "camel_23688": 0, "camel_21132": 0, "camel_23752": 0, "camel_23794": 0, "camel_23690": 0, "camel_21164": 0, "aqua_rat_40504": 0.7398725152015686, "aqua_rat_84086": 0.7412617802619934, "aqua_rat_25794": 0.7418968677520752, "aqua_rat_53788": 0.7480378150939941, "aqua_rat_39765": 0.7499827742576599, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0.7521929740905762, "math_test_prealgebra_849": 0.7522625923156738, "math_test_counting_and_probability_987": 0.7583634257316589, "aqua_rat_83797": 0.7658533453941345, "math_train_counting_and_probability_914": 0.7813658118247986, "TheoremQA_jianyu_xu/Ramsey_2.json": 0.8873610496520996}, "TheoremQA_wenhuchen/Poisson_process2.json": {"camel_9536": 0, "camel_10961": 0, "camel_11031": 0, "camel_10483": 0, "camel_11971": 0, "camel_11293": 0, "camel_9567": 0, "camel_11256": 0, "camel_10690": 0, "camel_11322": 0, "camel_9593": 0, "camel_10350": 0, "camel_11154": 0, "camel_11342": 0, "camel_11189": 0, "camel_11536": 0, "camel_11758": 0, "camel_10694": 0, "camel_10813": 0, "camel_10839": 0, "camel_11174": 0, "camel_11596": 0, "camel_9557": 0, "camel_10918": 0, "camel_10895": 0, "camel_11173": 0, "camel_10369": 0, "camel_10853": 0, "camel_10911": 0, "camel_11412": 0, "camel_10996": 0, "camel_10242": 0, "camel_10698": 0, "camel_10409": 0, "camel_10908": 0, "camel_11439": 0, "camel_11385": 0, "camel_11669": 0, "camel_11192": 0, "camel_10919": 0, "camel_10982": 0, "camel_9591": 0, "camel_11325": 0, "camel_10380": 0, "camel_9554": 0, "camel_10969": 0, "camel_11003": 0, "camel_10867": 0, "camel_11127": 0, "camel_11281": 0, "camel_10806": 0, "camel_10947": 0, "camel_9569": 0, "camel_10800": 0, "camel_11027": 0, "camel_9542": 0, "camel_10857": 0, "camel_10889": 0, "camel_11355": 0, "camel_11149": 0, "camel_8351": 0, "camel_11124": 0, "camel_11457": 0, "camel_10948": 0, "camel_10705": 0, "camel_10927": 0, "camel_10950": 0, "camel_9522": 0, "camel_10951": 0, "camel_10897": 0, "camel_10656": 0, "camel_11431": 0, "camel_11411": 0, "camel_10939": 0, "camel_11190": 0, "camel_11364": 0, "camel_10697": 0, "camel_11365": 0, "camel_11704": 0, "camel_10700": 0, "camel_9584": 0, "camel_10893": 0, "camel_10974": 0, "camel_11234": 0, "camel_10393": 0, "camel_11186": 0, "camel_11001": 0, "camel_11181": 0, "camel_11046": 0, "camel_11302": 0, "camel_11328": 0, "camel_10355": 0, "camel_10929": 0, "camel_11841": 0, "camel_11029": 0, "camel_11182": 0, "camel_10351": 0, "camel_10341": 0, "camel_11153": 0, "camel_11014": 0, "camel_9532": 0, "camel_11604": 0, "camel_11605": 0, "camel_10810": 0, "camel_10936": 0, "camel_10943": 0, "camel_10335": 0, "camel_9599": 0, "camel_10966": 0, "camel_11000": 0, "camel_11032": 0, "camel_10957": 0, "camel_11649": 0, "camel_11196": 0, "camel_11179": 0, "camel_10983": 0, "camel_11161": 0, "camel_10953": 0, "camel_11122": 0, "camel_11112": 0, "camel_9484": 0, "camel_11296": 0, "camel_10998": 0, "camel_10934": 0, "camel_10976": 0, "camel_11294": 0, "camel_10887": 0, "camel_10606": 0, "camel_10364": 0, "camel_9570": 0, "camel_11335": 0, "camel_10958": 0, "camel_10944": 0, "camel_8323": 0, "camel_11323": 0, "camel_11665": 0, "camel_10920": 0, "camel_11346": 0, "camel_11810": 0, "camel_10385": 0, "camel_10930": 0, "camel_10955": 0, "camel_11297": 0, "camel_11208": 0, "camel_11558": 0, "camel_11130": 0, "camel_10882": 0, "camel_11308": 0, "camel_11643": 0, "camel_9558": 0, "camel_11010": 0, "camel_11369": 0, "camel_11307": 0, "camel_11036": 0, "camel_11188": 0, "camel_10904": 0, "camel_11178": 0, "camel_11310": 0, "camel_11185": 0, "camel_10581": 0, "camel_11143": 0, "camel_11282": 0, "camel_10816": 0, "camel_11239": 0, "camel_10979": 0, "camel_10568": 0, "camel_11162": 0, "camel_11168": 0, "camel_11397": 0, "camel_11539": 0, "camel_11286": 0, "camel_11228": 0, "camel_10858": 0, "camel_11201": 0, "camel_11255": 0, "camel_11633": 0, "camel_11356": 0, "camel_11218": 0, "camel_10828": 0, "camel_10905": 0, "camel_11804": 0, "camel_10896": 0, "camel_11563": 0, "camel_10938": 0, "camel_10860": 0, "camel_10923": 0, "camel_11983": 0, "camel_11317": 0, "camel_10922": 0, "camel_11344": 0, "camel_11358": 0, "camel_11321": 0, "camel_38686": 0.7006703615188599, "camel_38645": 0.7035813927650452, "camel_29105": 0.704302966594696, "camel_38648": 0.7045376300811768, "camel_38660": 0.7058796882629395, "aqua_rat_56490": 0.7089892625808716, "camel_38655": 0.7305002808570862, "camel_38674": 0.7470126748085022}, "TheoremQA_wenhuchen/jensen2.json": {"math_train_counting_and_probability_5052": 0.7201470732688904, "aqua_rat_72505": 0.7201757431030273, "camel_4554": 0.7201771140098572, "camel_4657": 0.7202903032302856, "camel_5565": 0.7205328345298767, "camel_4498": 0.720559298992157, "camel_5037": 0.7205648422241211, "camel_4558": 0.7206453680992126, "camel_4666": 0.7206703424453735, "camel_3246": 0.7206788063049316, "camel_4702": 0.7209482789039612, "aqua_rat_19700": 0.7209558486938477, "aqua_rat_10894": 0.7210351228713989, "aqua_rat_71395": 0.7211361527442932, "camel_4473": 0.7211521863937378, "camel_5744": 0.7212421298027039, "camel_4468": 0.7212701439857483, "camel_4511": 0.7213138341903687, "camel_39131": 0.7214316129684448, "camel_4508": 0.721489429473877, "camel_4697": 0.7216763496398926, "camel_4677": 0.7217836380004883, "camel_4709": 0.7222496271133423, "camel_4516": 0.7223041653633118, "camel_4703": 0.7223845720291138, "camel_4699": 0.7224318385124207, "camel_4426": 0.7230756282806396, "camel_19700": 0.7232412099838257, "camel_4505": 0.7232951521873474, "camel_4548": 0.7233210206031799, "camel_4715": 0.7235690951347351, "camel_4542": 0.7236185073852539, "camel_47380": 0.7236607074737549, "camel_4496": 0.7238743305206299, "camel_3992": 0.7239179015159607, "camel_5547": 0.7240394949913025, "camel_4719": 0.7241635322570801, "camel_4663": 0.7241774201393127, "camel_4479": 0.7242101430892944, "camel_4503": 0.7242202758789062, "camel_4535": 0.7246307730674744, "camel_4439": 0.7246735692024231, "aqua_rat_36227": 0.7249894142150879, "camel_4853": 0.7250209450721741, "camel_4559": 0.725156843662262, "camel_4531": 0.7251716256141663, "camel_4488": 0.7252225875854492, "camel_4525": 0.7252488732337952, "camel_4522": 0.7255342602729797, "camel_4419": 0.7257013916969299, "math_train_prealgebra_781": 0.7258751392364502, "camel_4710": 0.7259535193443298, "camel_4713": 0.7259708046913147, "camel_5681": 0.7260124087333679, "camel_4446": 0.7260186672210693, "camel_4988": 0.7262093424797058, "camel_4437": 0.7263582944869995, "camel_4427": 0.7265233397483826, "camel_4835": 0.7265701293945312, "camel_5904": 0.7268560528755188, "camel_18681": 0.7273465394973755, "camel_4645": 0.7273901700973511, "camel_4672": 0.7274979948997498, "camel_5647": 0.7275389432907104, "camel_4504": 0.7276082634925842, "camel_4549": 0.727703332901001, "camel_4487": 0.7280915975570679, "aqua_rat_31579": 0.7281439304351807, "camel_4553": 0.7282258868217468, "camel_3979": 0.7284225821495056, "camel_4053": 0.7284583449363708, "camel_4685": 0.7286399602890015, "camel_4532": 0.7287237644195557, "camel_4355": 0.7288431525230408, "camel_3937": 0.7288717031478882, "camel_4541": 0.728889524936676, "camel_5689": 0.7290142178535461, "camel_4640": 0.7291003465652466, "camel_4716": 0.7292606830596924, "camel_4540": 0.7292782068252563, "camel_4466": 0.7293487787246704, "camel_4555": 0.7296175360679626, "camel_4484": 0.7298145890235901, "camel_4557": 0.7301746606826782, "camel_38916": 0.7301803827285767, "camel_4547": 0.7302303910255432, "camel_4527": 0.7302823662757874, "camel_4443": 0.7303194403648376, "camel_46137": 0.7303361892700195, "camel_4451": 0.7304640412330627, "camel_4423": 0.730516254901886, "camel_4417": 0.7308025360107422, "camel_4512": 0.730886697769165, "camel_4520": 0.7309190630912781, "camel_4331": 0.731143593788147, "aqua_rat_78573": 0.7314103245735168, "camel_4454": 0.7314616441726685, "camel_4806": 0.7315673828125, "camel_3976": 0.7316765189170837, "camel_5625": 0.7323272824287415, "camel_4430": 0.7324026823043823, "camel_4978": 0.7324275970458984, "camel_4544": 0.7326445579528809, "camel_4497": 0.7326861619949341, "camel_3943": 0.7327885627746582, "camel_4483": 0.7328807711601257, "camel_4538": 0.732883870601654, "camel_4405": 0.7329100966453552, "camel_4480": 0.7330426573753357, "camel_4506": 0.7332581877708435, "camel_4429": 0.7332801222801208, "camel_4482": 0.7333447337150574, "camel_4513": 0.7334429621696472, "camel_4529": 0.7336481809616089, "camel_4494": 0.7337209582328796, "camel_4546": 0.7338326573371887, "camel_4539": 0.7338443994522095, "camel_4514": 0.7339923977851868, "camel_3996": 0.7341251969337463, "camel_4521": 0.7341259717941284, "camel_4490": 0.7341673374176025, "camel_5887": 0.7342403531074524, "camel_4517": 0.7342793941497803, "camel_4556": 0.7343969941139221, "camel_4536": 0.7345523834228516, "camel_4669": 0.7350068092346191, "camel_4910": 0.735440731048584, "camel_4481": 0.7356663942337036, "camel_4500": 0.7358040809631348, "camel_39244": 0.7358161807060242, "camel_3938": 0.735836386680603, "camel_4501": 0.7362019419670105, "aqua_rat_13481": 0.7362221479415894, "camel_4526": 0.7363474369049072, "camel_4486": 0.7364410758018494, "camel_4509": 0.7364658713340759, "camel_4491": 0.7365350723266602, "camel_5594": 0.7365662455558777, "camel_4515": 0.7367023229598999, "camel_4518": 0.7368515133857727, "camel_4530": 0.7368698120117188, "camel_19754": 0.7372857928276062, "camel_4489": 0.7374824285507202, "camel_4523": 0.7375291585922241, "camel_5893": 0.737654983997345, "camel_3972": 0.7377835512161255, "camel_4524": 0.7379162311553955, "camel_5030": 0.7379606366157532, "camel_4954": 0.738393247127533, "aqua_rat_22633": 0.738491952419281, "aqua_rat_60518": 0.7385897636413574, "camel_5538": 0.7387232184410095, "camel_5552": 0.7387675046920776, "aqua_rat_71054": 0.7387939095497131, "camel_5522": 0.7388791441917419, "camel_5580": 0.7390403747558594, "aqua_rat_53476": 0.7394292950630188, "camel_3941": 0.7398577332496643, "camel_3987": 0.7398910522460938, "camel_4551": 0.7400193214416504, "aqua_rat_34002": 0.740388035774231, "camel_4534": 0.7404139637947083, "camel_3991": 0.7404362559318542, "camel_5653": 0.7405614852905273, "camel_3947": 0.7407929301261902, "camel_19734": 0.7408280372619629, "camel_19746": 0.7410796284675598, "camel_3953": 0.7411688566207886, "aqua_rat_70065": 0.7412826418876648, "camel_4499": 0.7419304251670837, "camel_19685": 0.7422584295272827, "aqua_rat_72151": 0.7424517273902893, "camel_3920": 0.7425350546836853, "camel_19705": 0.7427215576171875, "camel_5613": 0.7429046034812927, "aqua_rat_21589": 0.7431995272636414, "aqua_rat_25949": 0.7435203194618225, "camel_18649": 0.7435569167137146, "camel_4844": 0.7439911961555481, "camel_3926": 0.7441987991333008, "camel_4519": 0.7447534799575806, "camel_4848": 0.745037317276001, "camel_4528": 0.7450655102729797, "camel_19687": 0.7464649081230164, "camel_4464": 0.7465744614601135, "camel_3962": 0.746862530708313, "camel_5891": 0.7478635311126709, "camel_3932": 0.7478986978530884, "camel_4537": 0.7493653893470764, "camel_4543": 0.750180721282959, "camel_4407": 0.7503286004066467, "aqua_rat_47647": 0.7507521510124207, "camel_4459": 0.7513212561607361, "camel_5520": 0.7528514266014099, "camel_19727": 0.7542082071304321, "camel_3983": 0.7568619847297668, "camel_5679": 0.7584959864616394, "camel_4686": 0.7634956240653992, "camel_5637": 0.7686048746109009, "aqua_rat_27834": 0.7722772359848022}, "TheoremQA_xueguangma/binomial_model_1.json": {"TheoremQA_xueguangma/binomial_model_1.json": 0, "aqua_rat_32748": 0.7409647703170776, "camel_10389": 0.7412240505218506, "camel_11286": 0.7413852214813232, "gsm_rft_28392": 0.7413896918296814, "camel_9452": 0.74167400598526, "camel_24676": 0.7416889667510986, "gsm_train_23349": 0.741690456867218, "gsm_rft_21285": 0.741690456867218, "camel_37612": 0.741702139377594, "aqua_rat_69554": 0.7418752908706665, "camel_10527": 0.741890013217926, "aqua_rat_77539": 0.7421149015426636, "aqua_rat_75743": 0.7424431443214417, "camel_10590": 0.7425594329833984, "camel_10541": 0.7428171634674072, "aqua_rat_37936": 0.7429113984107971, "camel_9547": 0.7429696917533875, "aqua_rat_77396": 0.7430766820907593, "camel_11625": 0.7437211275100708, "camel_17946": 0.7440476417541504, "camel_10496": 0.7441096901893616, "camel_10622": 0.7443969249725342, "camel_11758": 0.7444737553596497, "camel_17448": 0.7450145483016968, "camel_10994": 0.7450350522994995, "camel_17988": 0.7450456619262695, "camel_17941": 0.7452629208564758, "camel_10635": 0.745313286781311, "camel_11661": 0.7455170154571533, "camel_17968": 0.745697021484375, "camel_10410": 0.7459180951118469, "camel_10554": 0.7461569905281067, "camel_17979": 0.7463718056678772, "camel_10429": 0.7464140057563782, "camel_10568": 0.7465051412582397, "camel_37799": 0.7465214729309082, "camel_10571": 0.7472398281097412, "camel_10545": 0.7472543716430664, "camel_10505": 0.7473209500312805, "camel_10485": 0.7474061250686646, "camel_11915": 0.747407853603363, "camel_16791": 0.7475976347923279, "camel_17990": 0.7482771873474121, "camel_17950": 0.7487344741821289, "camel_11539": 0.748750627040863, "camel_10509": 0.748814046382904, "camel_10963": 0.7489223480224609, "camel_10431": 0.7489319443702698, "camel_11453": 0.7489731907844543, "camel_9485": 0.7489967346191406, "camel_10500": 0.7490067481994629, "camel_17935": 0.7490547299385071, "camel_10467": 0.749075710773468, "camel_10917": 0.7491511702537537, "camel_11627": 0.7492362260818481, "camel_11850": 0.749405026435852, "camel_11822": 0.749678373336792, "camel_16763": 0.7499480843544006, "camel_11868": 0.7503595352172852, "camel_10975": 0.7505564093589783, "camel_10597": 0.7506275773048401, "camel_37620": 0.7507490515708923, "aqua_rat_18878": 0.7511528730392456, "aqua_rat_3470": 0.7511830925941467, "camel_10416": 0.7512670755386353, "camel_9575": 0.7513222694396973, "camel_10599": 0.751446008682251, "camel_11484": 0.7514933347702026, "camel_9576": 0.7515513896942139, "camel_17955": 0.7517315149307251, "camel_11018": 0.7518700361251831, "camel_17927": 0.7519822120666504, "camel_17961": 0.7522869110107422, "camel_17984": 0.7527979016304016, "camel_17983": 0.7528174519538879, "camel_10457": 0.7528810501098633, "camel_9570": 0.7531712651252747, "camel_9562": 0.7532561421394348, "aqua_rat_26732": 0.7539814710617065, "camel_10437": 0.7540534138679504, "camel_16754": 0.7541123032569885, "gsm_rft_32682": 0.7543787956237793, "camel_17440": 0.7543899416923523, "camel_17921": 0.7546969056129456, "camel_9557": 0.7547925114631653, "camel_11394": 0.7548463344573975, "camel_10639": 0.7550726532936096, "camel_9504": 0.755279541015625, "aqua_rat_11779": 0.7553186416625977, "camel_10536": 0.7556661367416382, "aqua_rat_79964": 0.755728006362915, "camel_10608": 0.7557420134544373, "camel_17457": 0.7559158205986023, "camel_24713": 0.756373405456543, "camel_10883": 0.7566694021224976, "camel_10400": 0.7569131851196289, "aqua_rat_39784": 0.7572557330131531, "camel_10409": 0.7573321461677551, "camel_11350": 0.7576333284378052, "camel_10489": 0.7579975128173828, "camel_10517": 0.7580181956291199, "aqua_rat_86591": 0.7585777044296265, "camel_10424": 0.7585932016372681, "camel_8740": 0.7589228749275208, "camel_29102": 0.7592706680297852, "camel_10446": 0.759711742401123, "camel_10548": 0.7600342631340027, "camel_10473": 0.7602332234382629, "aqua_rat_33669": 0.7603879570960999, "math_test_counting_and_probability_359": 0.7604281306266785, "camel_10603": 0.760833740234375, "camel_17488": 0.7609626054763794, "aqua_rat_73293": 0.7611131072044373, "camel_24684": 0.7613381147384644, "camel_10495": 0.7614118456840515, "camel_9567": 0.7614297270774841, "camel_10840": 0.7616074085235596, "camel_10440": 0.7624297738075256, "camel_10559": 0.7624931931495667, "aqua_rat_34158": 0.7630420923233032, "camel_10526": 0.7632418274879456, "camel_17924": 0.7636457681655884, "camel_9455": 0.7647866606712341, "aqua_rat_32300": 0.7656369805335999, "camel_17479": 0.7658587098121643, "camel_9590": 0.7658725380897522, "camel_10481": 0.7661177515983582, "camel_17482": 0.7663412690162659, "camel_10943": 0.7664654850959778, "camel_11621": 0.7665083408355713, "camel_10522": 0.7665371894836426, "camel_17989": 0.7665562629699707, "camel_17491": 0.76728755235672, "camel_10507": 0.7675281763076782, "camel_9495": 0.7676497101783752, "camel_9490": 0.7678015828132629, "camel_17963": 0.7678382992744446, "camel_10540": 0.7678892612457275, "camel_10460": 0.7679051160812378, "camel_11563": 0.7684298753738403, "camel_10483": 0.7689933776855469, "camel_10415": 0.7690075039863586, "camel_17475": 0.7691283822059631, "camel_38662": 0.7692854404449463, "camel_10512": 0.770260751247406, "camel_10445": 0.7704092860221863, "camel_10491": 0.7710890769958496, "camel_10418": 0.7720765471458435, "aqua_rat_75689": 0.7721651792526245, "camel_17518": 0.7722274661064148, "camel_10482": 0.7728464603424072, "camel_37652": 0.7729069590568542, "camel_10551": 0.7729102969169617, "camel_10546": 0.7733772993087769, "camel_17923": 0.7737577557563782, "camel_17484": 0.7747030258178711, "camel_10465": 0.775377631187439, "camel_10448": 0.7758894562721252, "camel_17965": 0.7774363160133362, "camel_10242": 0.7780528664588928, "camel_10474": 0.7785643935203552, "camel_10497": 0.7800492644309998, "camel_10498": 0.7818264961242676, "camel_10544": 0.7827512621879578, "camel_10537": 0.7882258296012878, "camel_17446": 0.7894629240036011, "camel_10515": 0.790180504322052, "camel_10531": 0.7921838164329529, "camel_9461": 0.792391300201416, "camel_10532": 0.792650043964386, "camel_10520": 0.7966468334197998, "camel_10493": 0.7978792190551758, "camel_10513": 0.8011088371276855, "camel_10504": 0.8011339902877808, "camel_17469": 0.8020588755607605, "camel_17513": 0.8026059865951538, "camel_10529": 0.805022120475769, "camel_10502": 0.8060941696166992, "camel_10552": 0.8062971234321594, "TheoremQA_xueguangma/binomial_model_2.json": 0.8066364526748657, "camel_10514": 0.8092620968818665, "camel_10486": 0.8122221231460571, "camel_10494": 0.8124374747276306, "camel_10506": 0.8145800232887268, "camel_10553": 0.8157097697257996, "camel_10534": 0.8173122406005859, "camel_10557": 0.8190204501152039, "camel_10530": 0.824080765247345, "camel_10535": 0.8278091549873352, "camel_10480": 0.8365083336830139, "camel_10539": 0.8388728499412537, "camel_10523": 0.8400599360466003, "camel_10558": 0.8440090417861938, "camel_10488": 0.854155957698822, "camel_10543": 0.8580952286720276, "camel_10511": 0.8593868613243103, "camel_10542": 0.8671618103981018, "camel_10492": 0.8692324161529541, "camel_10555": 0.870201826095581}, "TheoremQA_wenhuchen/newton2.json": {"camel_6449": 0, "camel_41857": 0, "camel_40734": 0, "camel_40850": 0, "camel_40797": 0, "camel_40929": 0, "camel_40765": 0, "camel_6404": 0, "camel_7827": 0, "camel_40788": 0, "camel_40494": 0, "camel_6439": 0, "camel_40486": 0, "camel_6463": 0, "camel_41904": 0, "camel_40729": 0, "camel_40731": 0, "camel_40785": 0, "camel_40737": 0, "camel_6475": 0, "camel_7765": 0, "camel_7021": 0, "camel_41637": 0, "camel_41950": 0, "camel_41967": 0, "camel_40798": 0, "camel_40752": 0, "camel_40770": 0, "camel_41935": 0, "camel_7789": 0, "camel_7777": 0, "camel_40780": 0, "camel_40763": 0, "camel_40735": 0, "camel_40885": 0, "camel_40817": 0, "camel_7695": 0, "camel_6418": 0, "camel_40515": 0, "camel_40522": 0, "camel_40756": 0, "camel_40779": 0, "camel_40754": 0, "camel_40499": 0, "camel_40547": 0, "camel_41882": 0, "camel_40913": 0, "camel_41961": 0, "camel_6576": 0, "camel_6415": 0, "camel_41997": 0, "camel_40514": 0, "camel_40791": 0, "camel_40760": 0, "camel_40882": 0, "camel_40945": 0, "camel_7774": 0, "TheoremQA_wenhuchen/newton2.json": 0, "aqua_rat_32459": 0.7627248167991638, "camel_48133": 0.7630682587623596, "camel_39343": 0.763201892375946, "aqua_rat_6090": 0.7632381916046143, "camel_1621": 0.7634817361831665, "math_train_algebra_461": 0.7637784481048584, "camel_28446": 0.7638620734214783, "camel_153": 0.7638782262802124, "aqua_rat_84881": 0.7638877630233765, "camel_445": 0.763995885848999, "camel_1723": 0.7647334933280945, "camel_5016": 0.7647766470909119, "aqua_rat_45553": 0.7650228142738342, "camel_48014": 0.765026330947876, "camel_49430": 0.7651260495185852, "camel_1694": 0.765306830406189, "camel_1699": 0.765530526638031, "camel_1749": 0.7657363414764404, "camel_49225": 0.7657522559165955, "camel_1688": 0.7662253975868225, "camel_1737": 0.7665490508079529, "aqua_rat_79793": 0.7666570544242859, "camel_49277": 0.7666980624198914, "aqua_rat_61355": 0.76682448387146, "camel_1701": 0.7670562267303467, "camel_1753": 0.7672867178916931, "camel_456": 0.7673245072364807, "camel_1683": 0.7674970626831055, "camel_459": 0.767540693283081, "aqua_rat_48553": 0.7675836682319641, "camel_1754": 0.7682278156280518, "camel_48038": 0.7683700919151306, "aqua_rat_46099": 0.7690994739532471, "camel_1730": 0.769584596157074, "camel_1731": 0.7696627378463745, "TheoremQA_elainewan/math_calculus_2_11.json": 0.7697353959083557, "aqua_rat_46083": 0.7705963850021362, "TheoremQA_wenhuchen/Regula-Falsi.json": 0.7708089351654053, "camel_39140": 0.7708476781845093, "camel_48045": 0.7709178328514099, "camel_1738": 0.7710285782814026, "camel_28475": 0.7710687518119812, "aqua_rat_13843": 0.7711251974105835, "camel_49876": 0.7711849212646484, "camel_478": 0.7712455987930298, "aqua_rat_42779": 0.7718057036399841, "aqua_rat_57286": 0.772049069404602, "camel_1750": 0.7722887396812439, "aqua_rat_4632": 0.7723679542541504, "aqua_rat_6248": 0.7723920941352844, "camel_1666": 0.7724206447601318, "camel_48005": 0.7726870179176331, "camel_1631": 0.7727673649787903, "aqua_rat_28718": 0.7727802991867065, "camel_49140": 0.7727870345115662, "camel_48033": 0.7728774547576904, "aqua_rat_53738": 0.7729910612106323, "aqua_rat_48329": 0.7733386158943176, "aqua_rat_52047": 0.7745457291603088, "camel_39306": 0.7747093439102173, "TheoremQA_wenhuchen/Graffe's_root2.json": 0.7755392789840698, "camel_436": 0.7758336067199707, "aqua_rat_42392": 0.7769778370857239, "camel_19483": 0.7770214080810547, "aqua_rat_28179": 0.777478039264679, "camel_1742": 0.7780003547668457, "camel_1704": 0.7783732414245605, "camel_425": 0.7785188555717468, "camel_452": 0.7787355780601501, "aqua_rat_56076": 0.778809130191803, "TheoremQA_wenhuchen/Descartes_Rule_of_Signs.json": 0.779059112071991, "camel_39085": 0.7795053720474243, "camel_476": 0.7797343730926514, "aqua_rat_965": 0.7799891829490662, "camel_1736": 0.7800050973892212, "aqua_rat_27289": 0.7800769209861755, "camel_38938": 0.7802436351776123, "camel_39104": 0.780830979347229, "camel_1604": 0.7814545631408691, "camel_1693": 0.781659722328186, "camel_1715": 0.7820717692375183, "camel_48096": 0.782143235206604, "camel_49242": 0.7822202444076538, "camel_1756": 0.7822750806808472, "camel_28147": 0.7831664085388184, "aqua_rat_56649": 0.7834987044334412, "camel_48016": 0.7835747599601746, "camel_48121": 0.7836915850639343, "aqua_rat_18768": 0.7838354110717773, "aqua_rat_16683": 0.7847096920013428, "camel_1695": 0.7848710417747498, "camel_39125": 0.7859538197517395, "camel_403": 0.7862482666969299, "camel_48888": 0.7865293025970459, "camel_1672": 0.7896637320518494, "camel_1755": 0.7897945642471313, "aqua_rat_17489": 0.7909126281738281, "camel_1729": 0.7909674048423767, "aqua_rat_40536": 0.7915610074996948, "camel_48036": 0.7925776839256287, "camel_1728": 0.7931618094444275, "camel_48000": 0.7934455871582031, "camel_1757": 0.7954065799713135, "camel_1643": 0.7974802851676941, "aqua_rat_69050": 0.7986574769020081, "aqua_rat_21304": 0.7994896769523621, "camel_1702": 0.7998372316360474, "camel_1733": 0.8011132478713989, "aqua_rat_76599": 0.8025234937667847, "aqua_rat_7450": 0.8037496209144592, "aqua_rat_51085": 0.8063175678253174, "camel_1660": 0.8074694275856018, "camel_1745": 0.80753493309021, "camel_1707": 0.8078503012657166, "camel_1697": 0.8082636594772339, "camel_1751": 0.8085616827011108, "camel_1691": 0.8116533756256104, "camel_1743": 0.8138953447341919, "camel_48965": 0.8158131837844849, "camel_1708": 0.8206265568733215, "camel_1705": 0.8210099935531616, "camel_1759": 0.8230522274971008, "camel_48010": 0.823096752166748, "camel_1735": 0.8261353373527527, "camel_1686": 0.8289509415626526, "camel_1717": 0.830234706401825, "camel_1628": 0.8306665420532227, "camel_48078": 0.8331730961799622, "camel_1706": 0.83587247133255, "camel_1748": 0.8388338088989258, "camel_1732": 0.8406603336334229, "camel_1712": 0.8423452973365784, "camel_1727": 0.8457987308502197, "camel_1614": 0.8463539481163025, "camel_1719": 0.8494482636451721, "camel_1744": 0.8502830862998962, "camel_1714": 0.8510251641273499, "camel_1690": 0.8558341860771179, "camel_1711": 0.8633493781089783, "camel_1713": 0.8643857836723328, "camel_1725": 0.8657762408256531, "camel_1746": 0.8695449233055115}, "TheoremQA_elainewan/econ_micro_11.json": {"TheoremQA_elainewan/econ_micro_11.json": 0, "camel_38091": 0.8118882775306702, "camel_38786": 0.8124536871910095, "aqua_rat_23264": 0.8127807378768921, "gsm_rft_16238": 0.812842845916748, "gsm_train_9850": 0.812842845916748, "camel_40948": 0.8128854632377625, "camel_38853": 0.8131497502326965, "aqua_rat_37751": 0.8131527900695801, "math_train_algebra_488": 0.8132971525192261, "camel_6973": 0.8133049011230469, "camel_39919": 0.813340425491333, "camel_24556": 0.8134198188781738, "aqua_rat_64503": 0.8136395812034607, "camel_41138": 0.8137610554695129, "aqua_rat_84440": 0.8138133883476257, "camel_38180": 0.8139284253120422, "camel_39487": 0.814019501209259, "aqua_rat_5399": 0.8141754865646362, "camel_38760": 0.8143519759178162, "aqua_rat_66406": 0.8143805861473083, "camel_39300": 0.814429521560669, "camel_37944": 0.8144411444664001, "camel_39872": 0.814831554889679, "camel_39598": 0.8148521780967712, "camel_40661": 0.8149466514587402, "camel_38182": 0.8149681091308594, "gsm_rft_9962": 0.8149807453155518, "camel_39914": 0.8149940371513367, "camel_39910": 0.8151224851608276, "camel_37702": 0.8153446912765503, "camel_17532": 0.8154788017272949, "camel_39854": 0.8155660629272461, "camel_38186": 0.8156099319458008, "aqua_rat_31837": 0.8156177401542664, "camel_38318": 0.8162258863449097, "camel_6228": 0.8163794279098511, "camel_40759": 0.8164184093475342, "camel_39904": 0.8164188861846924, "camel_38744": 0.8165575265884399, "aqua_rat_26528": 0.8166468739509583, "camel_38220": 0.8167213201522827, "camel_38300": 0.8167392611503601, "camel_38245": 0.8168556690216064, "camel_6231": 0.8168845772743225, "camel_38933": 0.8170628547668457, "camel_39881": 0.8172459602355957, "camel_39048": 0.8172553777694702, "camel_40956": 0.8173841834068298, "camel_38131": 0.8174511194229126, "camel_38155": 0.8175593018531799, "camel_37727": 0.8176125884056091, "camel_6967": 0.8178309798240662, "camel_39495": 0.8178408741950989, "camel_38173": 0.8178992867469788, "camel_41615": 0.8182145953178406, "camel_41992": 0.8183776140213013, "gsm_train_32864": 0.8184208869934082, "camel_38389": 0.8184515237808228, "camel_38968": 0.8186557292938232, "camel_39884": 0.8186606168746948, "camel_38146": 0.8186756372451782, "camel_38216": 0.8187537789344788, "gsm_rft_14359": 0.8190990686416626, "camel_38120": 0.8192142844200134, "camel_38828": 0.8192489743232727, "aqua_rat_18808": 0.8192846179008484, "gsm_rft_32008": 0.8194454908370972, "camel_39093": 0.8194993734359741, "camel_38833": 0.8195479512214661, "camel_39874": 0.8198319673538208, "camel_38738": 0.8199012875556946, "camel_39852": 0.819982647895813, "camel_39842": 0.8201339244842529, "aqua_rat_71495": 0.8201484084129333, "camel_38439": 0.8202955722808838, "camel_40647": 0.8205183148384094, "camel_41906": 0.8208023905754089, "camel_40940": 0.8213618397712708, "camel_38863": 0.8214076161384583, "camel_38729": 0.8214738368988037, "gsm_rft_28930": 0.8216735124588013, "gsm_train_9916": 0.8216735124588013, "camel_40942": 0.821675717830658, "camel_40772": 0.8217626214027405, "camel_6193": 0.8218389749526978, "camel_40901": 0.8218522071838379, "camel_40712": 0.8220876455307007, "camel_41170": 0.8222928643226624, "aqua_rat_6133": 0.8223211765289307, "aqua_rat_84126": 0.8225042819976807, "camel_39918": 0.822550892829895, "camel_24530": 0.8226956129074097, "camel_39068": 0.8227044343948364, "camel_37999": 0.8228151202201843, "camel_39868": 0.8233428001403809, "aqua_rat_4104": 0.8233989477157593, "camel_39896": 0.8235813975334167, "camel_37694": 0.8236290216445923, "camel_39498": 0.8236544132232666, "camel_39754": 0.8238065838813782, "gsm_rft_28204": 0.8238376379013062, "camel_39917": 0.8241387605667114, "camel_41835": 0.8241536617279053, "camel_24531": 0.8243436217308044, "camel_38252": 0.8244079351425171, "camel_38272": 0.8244454860687256, "camel_39903": 0.8248195052146912, "camel_39859": 0.8249547481536865, "camel_39119": 0.8253939151763916, "camel_40890": 0.8254296183586121, "camel_38306": 0.8254660367965698, "camel_7712": 0.8255541324615479, "camel_39894": 0.825831949710846, "camel_39893": 0.8259837627410889, "camel_25123": 0.8261147737503052, "camel_6184": 0.8263574838638306, "camel_39897": 0.8264968991279602, "camel_39902": 0.8266128897666931, "aqua_rat_11315": 0.8266478776931763, "camel_40947": 0.8267754316329956, "camel_38224": 0.8269446492195129, "aqua_rat_58260": 0.8272982835769653, "camel_15793": 0.8274075388908386, "camel_39886": 0.8275967836380005, "camel_40933": 0.8276904225349426, "camel_38628": 0.8277962803840637, "aqua_rat_9396": 0.8281190991401672, "camel_38768": 0.828154444694519, "camel_21598": 0.8282104134559631, "camel_41651": 0.8287831544876099, "camel_38195": 0.8291025161743164, "camel_39320": 0.8295450210571289, "camel_39873": 0.8299093842506409, "camel_41821": 0.8301546573638916, "camel_38928": 0.8301773071289062, "camel_41898": 0.8302177786827087, "camel_39880": 0.8302537202835083, "camel_40669": 0.8304924964904785, "aqua_rat_16260": 0.8307074308395386, "camel_39879": 0.8308189511299133, "camel_39106": 0.8312770128250122, "camel_39851": 0.8320955634117126, "camel_38281": 0.8322573900222778, "camel_39878": 0.8324332237243652, "camel_6214": 0.8324534893035889, "camel_40598": 0.8327304124832153, "camel_38126": 0.8328527212142944, "camel_39909": 0.833391547203064, "camel_39094": 0.8334662318229675, "camel_39887": 0.8334959745407104, "camel_41451": 0.8335925340652466, "camel_39853": 0.8337442874908447, "camel_40822": 0.8339173793792725, "camel_39888": 0.8339329361915588, "camel_39866": 0.8346324563026428, "aqua_rat_996": 0.8348057270050049, "camel_39603": 0.8350271582603455, "aqua_rat_27992": 0.835085928440094, "camel_38099": 0.8352328538894653, "camel_39519": 0.8352997899055481, "camel_40704": 0.8374695777893066, "camel_41749": 0.838078498840332, "aqua_rat_54993": 0.8381473422050476, "camel_6185": 0.8386217951774597, "aqua_rat_76016": 0.8386386036872864, "aqua_rat_17073": 0.8386610150337219, "camel_24553": 0.8389208912849426, "aqua_rat_36925": 0.8391957879066467, "camel_39877": 0.8393968343734741, "camel_39388": 0.8407221436500549, "camel_39840": 0.8408471941947937, "aqua_rat_86319": 0.8408882021903992, "camel_38203": 0.8409839868545532, "camel_40907": 0.8410068154335022, "camel_6169": 0.8411125540733337, "camel_39057": 0.8426183462142944, "camel_7017": 0.8426225781440735, "camel_38304": 0.8433386087417603, "camel_39890": 0.843414843082428, "camel_39905": 0.8434542417526245, "camel_39913": 0.844757616519928, "camel_39883": 0.8450381755828857, "camel_39162": 0.8463324904441833, "camel_39885": 0.846885085105896, "camel_38205": 0.8500418066978455, "camel_40682": 0.8508832454681396, "camel_39464": 0.8515802621841431, "camel_39861": 0.8528503179550171, "camel_38047": 0.8540474772453308, "camel_40698": 0.8558241724967957, "camel_40796": 0.8562444448471069, "camel_41923": 0.8577004671096802, "camel_39908": 0.8579395413398743, "camel_39502": 0.8581588268280029, "camel_39114": 0.8590711951255798, "camel_39871": 0.8627505302429199, "camel_38362": 0.8684844970703125, "camel_38256": 0.8695769906044006, "camel_39332": 0.8777138590812683}, "TheoremQA_jianyu_xu/Catalan_1.json": {"camel_20339": 0, "camel_21807": 0, "camel_20787": 0, "camel_20783": 0, "camel_21302": 0, "camel_21398": 0, "camel_20721": 0, "camel_21064": 0, "camel_21042": 0, "camel_20660": 0, "camel_20512": 0, "camel_21951": 0, "camel_21015": 0, "camel_21086": 0, "camel_21245": 0, "camel_20789": 0, "camel_20075": 0, "camel_21204": 0, "camel_21428": 0, "camel_21215": 0, "camel_20392": 0, "camel_21809": 0, "camel_21208": 0, "camel_21574": 0, "camel_21271": 0, "camel_21920": 0, "aqua_rat_66165": 0.7242520451545715, "aqua_rat_32829": 0.7242556810379028, "aqua_rat_65989": 0.7242725491523743, "aqua_rat_8587": 0.7245379090309143, "camel_38538": 0.7246466875076294, "math_train_prealgebra_536": 0.7247253656387329, "aqua_rat_82798": 0.7247810363769531, "aqua_rat_54372": 0.7248477339744568, "aqua_rat_46435": 0.7249841094017029, "aqua_rat_75443": 0.7250012159347534, "aqua_rat_36302": 0.7250213027000427, "aqua_rat_10500": 0.7250227928161621, "aqua_rat_68730": 0.7255395650863647, "math_test_counting_and_probability_1046": 0.7256590723991394, "aqua_rat_50640": 0.725675106048584, "aqua_rat_35588": 0.7259741425514221, "aqua_rat_69610": 0.7259959578514099, "aqua_rat_61273": 0.7260103821754456, "aqua_rat_9085": 0.7260942459106445, "aqua_rat_59532": 0.7261767983436584, "aqua_rat_35224": 0.7262452244758606, "aqua_rat_59572": 0.7265929579734802, "aqua_rat_88126": 0.7266507744789124, "aqua_rat_21868": 0.7267664670944214, "aqua_rat_12408": 0.7271605730056763, "aqua_rat_24191": 0.7271785736083984, "aqua_rat_69290": 0.727207601070404, "math_test_counting_and_probability_763": 0.7273475527763367, "aqua_rat_33731": 0.7274576425552368, "aqua_rat_30701": 0.727845311164856, "aqua_rat_13835": 0.7278633117675781, "aqua_rat_48326": 0.7278648018836975, "math_test_counting_and_probability_341": 0.72801274061203, "aqua_rat_36803": 0.7285206317901611, "aqua_rat_15754": 0.7286820411682129, "aqua_rat_52866": 0.728841245174408, "aqua_rat_56829": 0.7290704846382141, "aqua_rat_81742": 0.7292712330818176, "aqua_rat_47768": 0.7292877435684204, "aqua_rat_65738": 0.7294149398803711, "aqua_rat_41411": 0.7296091914176941, "aqua_rat_81312": 0.7297315001487732, "aqua_rat_47326": 0.729945182800293, "aqua_rat_78389": 0.7304741740226746, "aqua_rat_48706": 0.7304985523223877, "aqua_rat_28465": 0.7306718826293945, "math_test_counting_and_probability_748": 0.73076331615448, "aqua_rat_48109": 0.7309734225273132, "aqua_rat_68736": 0.7310774922370911, "aqua_rat_73122": 0.7315821647644043, "aqua_rat_55223": 0.7317485809326172, "camel_38550": 0.7320414781570435, "aqua_rat_27967": 0.7321398258209229, "aqua_rat_69001": 0.7321993112564087, "math_test_prealgebra_579": 0.7322990298271179, "math_train_counting_and_probability_5061": 0.7326840162277222, "camel_23348": 0.732934832572937, "math_train_prealgebra_733": 0.7333306074142456, "aqua_rat_74162": 0.7333851456642151, "aqua_rat_68930": 0.7337391972541809, "aqua_rat_15706": 0.7351016402244568, "math_train_counting_and_probability_720": 0.7351299524307251, "aqua_rat_17116": 0.7354319095611572, "aqua_rat_2574": 0.7355078458786011, "aqua_rat_71410": 0.7356412410736084, "aqua_rat_693": 0.735960066318512, "aqua_rat_37859": 0.7362463474273682, "aqua_rat_2774": 0.7365431189537048, "aqua_rat_58883": 0.7365764379501343, "aqua_rat_10961": 0.7367798089981079, "aqua_rat_44859": 0.7369390726089478, "math_test_counting_and_probability_1081": 0.7369620203971863, "aqua_rat_34678": 0.7369704246520996, "aqua_rat_54343": 0.7370469570159912, "aqua_rat_25080": 0.7372912168502808, "math_train_counting_and_probability_22": 0.73740553855896, "aqua_rat_14817": 0.7374460101127625, "aqua_rat_15355": 0.7374767065048218, "aqua_rat_56031": 0.7375253438949585, "aqua_rat_15612": 0.7377166748046875, "math_test_prealgebra_1071": 0.7378655672073364, "aqua_rat_85987": 0.738068699836731, "camel_23284": 0.7382516860961914, "aqua_rat_13921": 0.7389999628067017, "math_test_counting_and_probability_894": 0.739166259765625, "math_train_counting_and_probability_5121": 0.7404032945632935, "aqua_rat_22747": 0.7405808568000793, "math_train_prealgebra_23": 0.7407695651054382, "aqua_rat_83470": 0.7411157488822937, "aqua_rat_75127": 0.7413671016693115, "aqua_rat_46577": 0.741633951663971, "aqua_rat_48135": 0.7417358160018921, "aqua_rat_15856": 0.7422006130218506, "aqua_rat_31881": 0.7428097724914551, "aqua_rat_48039": 0.7431269884109497, "aqua_rat_73045": 0.7432878017425537, "aqua_rat_40544": 0.7442206740379333, "aqua_rat_30392": 0.7442266345024109, "aqua_rat_37692": 0.7446964383125305, "aqua_rat_11490": 0.7447488903999329, "camel_23312": 0.7449644207954407, "aqua_rat_51154": 0.7450569868087769, "aqua_rat_21138": 0.7451640963554382, "aqua_rat_73050": 0.7454074621200562, "aqua_rat_74406": 0.7458588480949402, "aqua_rat_79317": 0.745938777923584, "aqua_rat_50142": 0.7459728717803955, "aqua_rat_26293": 0.7465431690216064, "aqua_rat_54776": 0.7465509176254272, "aqua_rat_2962": 0.7475495338439941, "math_train_counting_and_probability_5018": 0.7478025555610657, "aqua_rat_88984": 0.7478559017181396, "aqua_rat_22125": 0.7478765845298767, "aqua_rat_24032": 0.7479755878448486, "aqua_rat_60315": 0.7480072379112244, "aqua_rat_63325": 0.7481149435043335, "aqua_rat_26871": 0.7481159567832947, "aqua_rat_43308": 0.7481587529182434, "aqua_rat_53479": 0.7493441700935364, "aqua_rat_39212": 0.7496724128723145, "aqua_rat_40955": 0.7497754096984863, "aqua_rat_3565": 0.7499361634254456, "aqua_rat_85332": 0.7499522566795349, "aqua_rat_58335": 0.7504644989967346, "aqua_rat_78291": 0.7507604360580444, "aqua_rat_69734": 0.7510250806808472, "aqua_rat_15155": 0.7511605024337769, "aqua_rat_88691": 0.7514446377754211, "aqua_rat_46132": 0.7514660358428955, "aqua_rat_46999": 0.7518692016601562, "aqua_rat_38335": 0.7519004344940186, "math_train_counting_and_probability_797": 0.7519341111183167, "aqua_rat_52759": 0.7519720196723938, "aqua_rat_26130": 0.7520069479942322, "aqua_rat_88225": 0.7521452903747559, "aqua_rat_37133": 0.7521535158157349, "aqua_rat_72667": 0.7521666884422302, "aqua_rat_9837": 0.7528141140937805, "aqua_rat_351": 0.7530742287635803, "aqua_rat_51040": 0.753250777721405, "aqua_rat_54560": 0.7538237571716309, "aqua_rat_37678": 0.7543249130249023, "aqua_rat_71764": 0.7551915645599365, "aqua_rat_55380": 0.7555569410324097, "aqua_rat_63918": 0.7567911744117737, "aqua_rat_60100": 0.7572084665298462, "aqua_rat_31473": 0.7598613500595093, "aqua_rat_31528": 0.7600371241569519, "aqua_rat_40713": 0.7600725889205933, "aqua_rat_37490": 0.7606000304222107, "aqua_rat_21233": 0.7609273791313171, "aqua_rat_72007": 0.7609529495239258, "aqua_rat_39611": 0.7621658444404602, "aqua_rat_14": 0.7625914216041565, "aqua_rat_29122": 0.7629187107086182, "aqua_rat_77042": 0.7636951804161072, "aqua_rat_28508": 0.7643450498580933, "aqua_rat_3702": 0.764395534992218, "aqua_rat_27920": 0.7645792961120605, "aqua_rat_44454": 0.7649413347244263, "aqua_rat_60691": 0.7653428316116333, "aqua_rat_88559": 0.7657379508018494, "aqua_rat_84407": 0.7686142921447754, "aqua_rat_3763": 0.7706642150878906, "aqua_rat_67804": 0.7726693749427795, "aqua_rat_51470": 0.7739067077636719, "aqua_rat_60481": 0.7766047120094299, "aqua_rat_13218": 0.7800465226173401, "aqua_rat_32304": 0.780708372592926, "math_train_prealgebra_446": 0.7811915278434753, "math_train_counting_and_probability_757": 0.7907697558403015, "math_train_counting_and_probability_600": 0.7981566786766052, "math_train_counting_and_probability_979": 0.8014507293701172, "aqua_rat_75954": 0.805711567401886}, "TheoremQA_jianyu_xu/Binomial_3.json": {"camel_20874": 0, "camel_20312": 0, "camel_20022": 0, "camel_20930": 0, "camel_21480": 0, "camel_20029": 0, "camel_20294": 0, "camel_20002": 0, "camel_20256": 0, "camel_20260": 0, "camel_21388": 0, "camel_20378": 0, "camel_20263": 0, "camel_20525": 0, "TheoremQA_jianyu_xu/Binomial_3.json": 0, "camel_20287": 0, "camel_20121": 0, "camel_21530": 0, "aqua_rat_63777": 0.8454958200454712, "aqua_rat_67321": 0.8455846309661865, "math_train_counting_and_probability_122": 0.8457469940185547, "aqua_rat_52714": 0.845781147480011, "aqua_rat_43308": 0.845869243144989, "aqua_rat_81548": 0.8458707928657532, "aqua_rat_85740": 0.8460081815719604, "aqua_rat_81765": 0.8461073637008667, "aqua_rat_69170": 0.8462778925895691, "aqua_rat_69282": 0.8463983535766602, "aqua_rat_11590": 0.8464169502258301, "aqua_rat_67236": 0.8464753031730652, "aqua_rat_2653": 0.8465555310249329, "aqua_rat_74901": 0.846571147441864, "aqua_rat_64131": 0.8465762138366699, "math_test_counting_and_probability_993": 0.8466438055038452, "aqua_rat_46060": 0.8468566536903381, "aqua_rat_80420": 0.8469364047050476, "aqua_rat_371": 0.8469893932342529, "aqua_rat_10136": 0.8470472693443298, "aqua_rat_8260": 0.8470821976661682, "aqua_rat_61543": 0.8471201062202454, "aqua_rat_16780": 0.8471395373344421, "aqua_rat_19502": 0.8472303152084351, "math_train_counting_and_probability_683": 0.8472691774368286, "aqua_rat_20460": 0.847291886806488, "aqua_rat_779": 0.8472983837127686, "aqua_rat_11962": 0.8473057746887207, "aqua_rat_8218": 0.8473524451255798, "aqua_rat_51457": 0.8473762273788452, "aqua_rat_42177": 0.8474944829940796, "aqua_rat_38845": 0.8475027680397034, "aqua_rat_20119": 0.8476461172103882, "aqua_rat_55169": 0.8477192521095276, "aqua_rat_62681": 0.8477272987365723, "aqua_rat_64894": 0.8478824496269226, "aqua_rat_32475": 0.8478983044624329, "aqua_rat_71035": 0.8479073643684387, "aqua_rat_66362": 0.8479412198066711, "aqua_rat_28800": 0.8479673266410828, "aqua_rat_88222": 0.8481023907661438, "aqua_rat_31528": 0.8481919765472412, "aqua_rat_1184": 0.8483070135116577, "aqua_rat_79851": 0.8483285307884216, "aqua_rat_25103": 0.8484275341033936, "aqua_rat_48321": 0.8484706282615662, "aqua_rat_58185": 0.8485080003738403, "math_train_prealgebra_115": 0.8487961888313293, "aqua_rat_85823": 0.8488243222236633, "aqua_rat_53149": 0.8488569259643555, "aqua_rat_3809": 0.8489679098129272, "aqua_rat_83332": 0.849033534526825, "aqua_rat_89036": 0.8491334319114685, "aqua_rat_77361": 0.8491343259811401, "aqua_rat_71764": 0.8494206070899963, "math_test_counting_and_probability_535": 0.8495739102363586, "aqua_rat_3004": 0.8496535420417786, "aqua_rat_46352": 0.8497015237808228, "aqua_rat_70482": 0.849797785282135, "aqua_rat_48816": 0.8498754501342773, "aqua_rat_24776": 0.849886953830719, "aqua_rat_36512": 0.8499549627304077, "camel_38505": 0.8499756455421448, "aqua_rat_2630": 0.8501503467559814, "aqua_rat_60755": 0.8502761721611023, "aqua_rat_36115": 0.8502832651138306, "aqua_rat_40955": 0.8504613637924194, "aqua_rat_57246": 0.8505326509475708, "aqua_rat_30874": 0.8505390882492065, "aqua_rat_42240": 0.8506055474281311, "aqua_rat_41506": 0.8506107330322266, "aqua_rat_12398": 0.8507331013679504, "aqua_rat_41153": 0.850771963596344, "aqua_rat_47513": 0.8508016467094421, "aqua_rat_6963": 0.8508101105690002, "aqua_rat_49505": 0.8508228659629822, "aqua_rat_60774": 0.8509263396263123, "aqua_rat_42231": 0.8510009050369263, "aqua_rat_72868": 0.851057231426239, "aqua_rat_33957": 0.8510677218437195, "aqua_rat_44983": 0.8511570692062378, "aqua_rat_19345": 0.851271390914917, "aqua_rat_32182": 0.8513215780258179, "aqua_rat_60100": 0.8517571687698364, "aqua_rat_65642": 0.8519244194030762, "aqua_rat_22953": 0.8520112037658691, "aqua_rat_72310": 0.8521649837493896, "aqua_rat_26382": 0.8522986173629761, "aqua_rat_66711": 0.8523944020271301, "aqua_rat_61514": 0.8524535298347473, "aqua_rat_52223": 0.8526303172111511, "aqua_rat_41111": 0.8527706861495972, "aqua_rat_14257": 0.8528820276260376, "aqua_rat_38314": 0.8531723022460938, "aqua_rat_37764": 0.8532136678695679, "aqua_rat_86028": 0.8532723188400269, "aqua_rat_13414": 0.8534558415412903, "aqua_rat_48676": 0.8534565567970276, "aqua_rat_8519": 0.8535060286521912, "aqua_rat_62773": 0.8535268902778625, "aqua_rat_71181": 0.8539209365844727, "aqua_rat_56933": 0.8541612029075623, "aqua_rat_59747": 0.8543539047241211, "aqua_rat_34486": 0.854467511177063, "aqua_rat_78732": 0.8544701337814331, "aqua_rat_43584": 0.855247437953949, "aqua_rat_81997": 0.8555371165275574, "aqua_rat_84736": 0.855559766292572, "math_train_counting_and_probability_165": 0.8556368350982666, "math_train_counting_and_probability_961": 0.8556573987007141, "aqua_rat_10665": 0.8558756113052368, "aqua_rat_1480": 0.856213390827179, "aqua_rat_58335": 0.8564945459365845, "aqua_rat_55116": 0.8564957976341248, "aqua_rat_30109": 0.856631338596344, "aqua_rat_18452": 0.8566516637802124, "aqua_rat_7341": 0.8567615747451782, "aqua_rat_79193": 0.8572199940681458, "aqua_rat_50541": 0.8574531078338623, "math_test_counting_and_probability_694": 0.8576915860176086, "aqua_rat_2112": 0.8577687740325928, "aqua_rat_9713": 0.8577690720558167, "aqua_rat_52092": 0.8579730987548828, "aqua_rat_35841": 0.8583220839500427, "math_train_prealgebra_806": 0.8584625720977783, "aqua_rat_24602": 0.8587005734443665, "aqua_rat_23705": 0.8589265942573547, "aqua_rat_62575": 0.8594365119934082, "math_train_counting_and_probability_249": 0.8594837188720703, "aqua_rat_22507": 0.859750509262085, "aqua_rat_60691": 0.8598883748054504, "aqua_rat_86468": 0.8599396347999573, "aqua_rat_71578": 0.859954297542572, "aqua_rat_53467": 0.8601982593536377, "aqua_rat_50290": 0.8603821396827698, "aqua_rat_3700": 0.8605660796165466, "aqua_rat_28538": 0.860842227935791, "aqua_rat_84364": 0.8608425259590149, "aqua_rat_67181": 0.8610167503356934, "aqua_rat_72589": 0.861160159111023, "aqua_rat_88559": 0.8612313270568848, "aqua_rat_4069": 0.8612729907035828, "aqua_rat_73040": 0.8616281151771545, "aqua_rat_61693": 0.8617820739746094, "aqua_rat_49270": 0.8618372082710266, "aqua_rat_75249": 0.8621766567230225, "aqua_rat_16861": 0.8623225092887878, "aqua_rat_74949": 0.8626079559326172, "aqua_rat_42205": 0.8626464009284973, "aqua_rat_55382": 0.8627654910087585, "aqua_rat_22465": 0.8627690076828003, "math_train_counting_and_probability_929": 0.8627869486808777, "aqua_rat_13647": 0.8628382682800293, "aqua_rat_8338": 0.8628649711608887, "aqua_rat_37993": 0.8628657460212708, "aqua_rat_43337": 0.8629157543182373, "aqua_rat_78014": 0.8629329800605774, "aqua_rat_41775": 0.8630926012992859, "aqua_rat_23820": 0.8631238341331482, "aqua_rat_5150": 0.8633566498756409, "aqua_rat_82553": 0.8635374307632446, "aqua_rat_25421": 0.863592267036438, "aqua_rat_61775": 0.8637210726737976, "aqua_rat_50686": 0.8637900352478027, "aqua_rat_58309": 0.8643351793289185, "aqua_rat_15343": 0.864546537399292, "aqua_rat_10102": 0.8645605444908142, "aqua_rat_16762": 0.8649397492408752, "aqua_rat_10394": 0.8653844594955444, "aqua_rat_62903": 0.8654648661613464, "aqua_rat_32732": 0.8655420541763306, "aqua_rat_63741": 0.8656032681465149, "aqua_rat_8728": 0.8663313388824463, "aqua_rat_84957": 0.8671978712081909, "math_train_counting_and_probability_918": 0.8672753572463989, "aqua_rat_46850": 0.8675653338432312, "aqua_rat_87992": 0.8690055012702942, "math_train_counting_and_probability_738": 0.8704717755317688, "aqua_rat_35015": 0.8714298605918884, "aqua_rat_66841": 0.8718628883361816, "math_train_counting_and_probability_562": 0.8774707913398743, "aqua_rat_82087": 0.8843564391136169}, "TheoremQA_elainewan/econ_micro_18.json": {"camel_25271": 0, "camel_25234": 0, "camel_24717": 0, "camel_25283": 0, "camel_25686": 0, "camel_24649": 0, "camel_24708": 0, "camel_25263": 0, "camel_25721": 0, "camel_25043": 0, "camel_25307": 0, "camel_25693": 0, "camel_24467": 0, "camel_25220": 0, "camel_25197": 0, "camel_25296": 0, "camel_25221": 0, "camel_25367": 0, "camel_25219": 0, "camel_25247": 0, "camel_24706": 0, "camel_24684": 0, "camel_24273": 0, "camel_25207": 0, "camel_25272": 0, "camel_25892": 0, "camel_24676": 0, "camel_25217": 0, "camel_25137": 0, "camel_25391": 0, "camel_25216": 0, "camel_25359": 0, "camel_25249": 0, "camel_25356": 0, "camel_25292": 0, "camel_25958": 0, "camel_25349": 0, "camel_25224": 0, "camel_24644": 0, "camel_25172": 0, "camel_25274": 0, "camel_24707": 0, "camel_25270": 0, "camel_25177": 0, "camel_25184": 0, "camel_24242": 0, "camel_25125": 0, "camel_25269": 0, "camel_24443": 0, "camel_24665": 0, "camel_25337": 0, "camel_25171": 0, "camel_25294": 0, "camel_25805": 0, "camel_24259": 0, "camel_24369": 0, "camel_25160": 0, "camel_24316": 0, "camel_25470": 0, "camel_25265": 0, "camel_24715": 0, "camel_25446": 0, "camel_25334": 0, "camel_25181": 0, "camel_25226": 0, "camel_25335": 0, "camel_25513": 0, "camel_25124": 0, "camel_25126": 0, "camel_25257": 0, "camel_25213": 0, "camel_25208": 0, "camel_25136": 0, "camel_24664": 0, "camel_25152": 0, "camel_25321": 0, "camel_25188": 0, "camel_24291": 0, "camel_25244": 0, "camel_25212": 0, "camel_25156": 0, "camel_25299": 0, "camel_25251": 0, "camel_25225": 0, "camel_25688": 0, "camel_25243": 0, "camel_25287": 0, "camel_25256": 0, "camel_25121": 0, "camel_25185": 0, "camel_25214": 0, "camel_25302": 0, "camel_25357": 0, "camel_25314": 0, "camel_25863": 0, "camel_25253": 0, "camel_25157": 0, "camel_25147": 0, "camel_24687": 0, "camel_25279": 0, "camel_25282": 0, "camel_25278": 0, "camel_25241": 0, "camel_25198": 0, "camel_25291": 0, "camel_25168": 0, "camel_25203": 0, "camel_25227": 0, "camel_25332": 0, "camel_25318": 0, "camel_25322": 0, "camel_25176": 0, "camel_25341": 0, "camel_25496": 0, "camel_24462": 0, "camel_25305": 0, "camel_25159": 0, "camel_25340": 0, "camel_25268": 0, "camel_25238": 0, "camel_25230": 0, "camel_25239": 0, "camel_25345": 0, "camel_25316": 0, "camel_25189": 0, "TheoremQA_elainewan/econ_micro_18.json": 0, "camel_37688": 0.8059272170066833, "camel_10532": 0.8061639070510864, "camel_8334": 0.8073098659515381, "camel_10540": 0.8074395060539246, "aqua_rat_41336": 0.8076658248901367, "camel_37646": 0.8099038600921631, "camel_10507": 0.8100817799568176, "camel_38689": 0.8110275864601135, "camel_10499": 0.8112878203392029, "camel_37618": 0.8120589256286621, "camel_39432": 0.8127760291099548, "camel_38714": 0.8138517141342163, "camel_10517": 0.8140920400619507, "camel_10551": 0.8147319555282593, "camel_10537": 0.8154714107513428, "camel_37739": 0.8169721961021423, "camel_10545": 0.8200111389160156, "camel_39366": 0.82063227891922, "camel_38758": 0.8224283456802368, "camel_37651": 0.8230032324790955, "camel_37704": 0.8235562443733215, "camel_37684": 0.8236526846885681, "camel_10240": 0.8242523074150085, "camel_39399": 0.8244551420211792, "camel_37722": 0.8270103335380554, "camel_10284": 0.8283241391181946, "camel_37724": 0.8286586999893188, "camel_37736": 0.8289045095443726, "camel_37725": 0.8290624022483826, "camel_37718": 0.8302863836288452, "camel_37692": 0.831084132194519, "camel_10305": 0.8317719101905823, "camel_37680": 0.8322346210479736, "camel_37629": 0.8333194255828857, "camel_37758": 0.8347662687301636, "camel_37714": 0.8348196744918823, "camel_37730": 0.8356499075889587, "camel_37709": 0.8359482884407043, "camel_37669": 0.8359725475311279, "camel_37740": 0.8369921445846558, "TheoremQA_elainewan/econ_micro_7_2.json": 0.8375017046928406, "camel_37710": 0.8377988934516907, "camel_37703": 0.8378163576126099, "camel_37757": 0.8380352854728699, "camel_37696": 0.838599681854248, "camel_38662": 0.8390505909919739, "camel_37685": 0.840408205986023, "camel_37699": 0.8413652181625366, "camel_37708": 0.8416480422019958, "camel_37741": 0.8429701328277588, "camel_37721": 0.8432909250259399, "camel_37723": 0.8442169427871704, "camel_37738": 0.8446659445762634, "camel_37683": 0.8455165028572083, "camel_37691": 0.8459213972091675, "camel_37745": 0.8463060855865479, "camel_37697": 0.8481543064117432, "camel_37756": 0.8493438363075256, "camel_37751": 0.8497753739356995, "camel_37693": 0.8500382304191589, "camel_37729": 0.8527659177780151, "camel_37700": 0.8540858626365662, "camel_37750": 0.8549306988716125, "camel_37749": 0.8550944328308105, "camel_37752": 0.8572884202003479, "camel_37635": 0.8575465083122253, "camel_37701": 0.8576779961585999, "camel_37682": 0.8582258820533752, "camel_37687": 0.8583639860153198, "camel_37744": 0.8589844107627869, "camel_37742": 0.8601734042167664, "camel_37716": 0.8666033744812012, "camel_37706": 0.8682708144187927, "camel_39397": 0.8792628049850464}, "TheoremQA_jianyu_xu/Multinomial_3.json": {"camel_20549": 0, "camel_20250": 0, "camel_20730": 0, "camel_20038": 0, "camel_20332": 0, "camel_20331": 0, "camel_20987": 0, "camel_20977": 0, "camel_20519": 0, "camel_20988": 0, "camel_21026": 0, "camel_20356": 0, "camel_20545": 0, "camel_21233": 0, "camel_21028": 0, "camel_20249": 0, "camel_20783": 0, "camel_21029": 0, "camel_20244": 0, "camel_20283": 0, "camel_20985": 0, "camel_20175": 0, "camel_20973": 0, "camel_20951": 0, "aqua_rat_17184": 0.8084156513214111, "aqua_rat_51352": 0.8084380030632019, "aqua_rat_60578": 0.8084422945976257, "aqua_rat_56247": 0.8084750771522522, "aqua_rat_48793": 0.8085528016090393, "aqua_rat_80157": 0.8086525201797485, "aqua_rat_51107": 0.8087049126625061, "aqua_rat_12425": 0.8087328672409058, "aqua_rat_31694": 0.8087682723999023, "aqua_rat_66920": 0.8088058829307556, "aqua_rat_14535": 0.8088240027427673, "aqua_rat_63387": 0.8088783025741577, "math_train_prealgebra_178": 0.8088786602020264, "aqua_rat_25182": 0.8088915348052979, "math_train_counting_and_probability_925": 0.8089705109596252, "aqua_rat_67953": 0.8089724183082581, "aqua_rat_34214": 0.8091157674789429, "aqua_rat_17735": 0.8091205358505249, "aqua_rat_68154": 0.8091263771057129, "aqua_rat_86117": 0.809190571308136, "aqua_rat_67694": 0.8093457221984863, "aqua_rat_56123": 0.8093464970588684, "aqua_rat_80121": 0.8093641996383667, "aqua_rat_39833": 0.8094574809074402, "aqua_rat_18729": 0.809540331363678, "aqua_rat_54587": 0.8095874786376953, "aqua_rat_49713": 0.8096278309822083, "aqua_rat_11382": 0.8096492886543274, "aqua_rat_35289": 0.8096598386764526, "aqua_rat_73402": 0.8096752762794495, "math_train_prealgebra_1740": 0.8097983002662659, "aqua_rat_10199": 0.8098686337471008, "aqua_rat_1550": 0.8098938465118408, "aqua_rat_53262": 0.8099284768104553, "aqua_rat_26857": 0.8100252747535706, "aqua_rat_55663": 0.8100823163986206, "aqua_rat_58075": 0.8101566433906555, "aqua_rat_27623": 0.8101609349250793, "aqua_rat_11004": 0.810649037361145, "aqua_rat_89113": 0.8106635808944702, "aqua_rat_28086": 0.8107135891914368, "aqua_rat_59038": 0.8107355237007141, "aqua_rat_59815": 0.8109191656112671, "aqua_rat_38599": 0.8109986782073975, "aqua_rat_14966": 0.81110680103302, "math_train_counting_and_probability_918": 0.8112742900848389, "aqua_rat_15196": 0.8113083243370056, "aqua_rat_24104": 0.8113955855369568, "aqua_rat_74550": 0.8114636540412903, "aqua_rat_46484": 0.8114822506904602, "aqua_rat_58195": 0.811487078666687, "aqua_rat_24634": 0.8114902377128601, "aqua_rat_28402": 0.8115743398666382, "aqua_rat_78519": 0.8116680979728699, "aqua_rat_57130": 0.8117268681526184, "aqua_rat_71998": 0.8117717504501343, "aqua_rat_83505": 0.81197589635849, "aqua_rat_35669": 0.8120546340942383, "aqua_rat_38774": 0.812157154083252, "aqua_rat_5247": 0.8122159838676453, "aqua_rat_29983": 0.8123130202293396, "math_train_counting_and_probability_893": 0.8123267292976379, "aqua_rat_17800": 0.8123656511306763, "aqua_rat_63885": 0.812553882598877, "math_test_counting_and_probability_130": 0.8125635981559753, "aqua_rat_39440": 0.8127468228340149, "aqua_rat_75182": 0.8129261136054993, "aqua_rat_46658": 0.8129622340202332, "aqua_rat_61793": 0.8129789233207703, "aqua_rat_42379": 0.8130202293395996, "aqua_rat_29651": 0.8130746483802795, "aqua_rat_29319": 0.8131745457649231, "aqua_rat_59360": 0.813234269618988, "aqua_rat_2328": 0.8136339783668518, "aqua_rat_49273": 0.8136767148971558, "aqua_rat_2072": 0.8136836290359497, "aqua_rat_4294": 0.8138047456741333, "math_train_counting_and_probability_1032": 0.8138117790222168, "aqua_rat_10800": 0.8140044808387756, "aqua_rat_56544": 0.814069926738739, "aqua_rat_37487": 0.8141120672225952, "aqua_rat_18404": 0.814132034778595, "aqua_rat_72012": 0.814287543296814, "aqua_rat_85966": 0.8144175410270691, "aqua_rat_19231": 0.8146101832389832, "aqua_rat_12956": 0.8147432804107666, "aqua_rat_29935": 0.8150339126586914, "aqua_rat_7373": 0.8150342106819153, "aqua_rat_77275": 0.8150850534439087, "aqua_rat_14173": 0.8152058720588684, "aqua_rat_16877": 0.8152561187744141, "aqua_rat_51800": 0.8154304027557373, "aqua_rat_36385": 0.8156681060791016, "aqua_rat_55627": 0.8162177801132202, "aqua_rat_36159": 0.816452145576477, "aqua_rat_16439": 0.8166692852973938, "aqua_rat_18803": 0.817060649394989, "aqua_rat_40108": 0.8176993131637573, "aqua_rat_37506": 0.8177130222320557, "aqua_rat_59342": 0.817811131477356, "aqua_rat_60936": 0.8179517984390259, "aqua_rat_47456": 0.8179866671562195, "aqua_rat_66552": 0.8181371092796326, "aqua_rat_73122": 0.8186658024787903, "math_train_prealgebra_1167": 0.8189963102340698, "aqua_rat_89246": 0.8190962672233582, "aqua_rat_67588": 0.8191218376159668, "aqua_rat_77579": 0.8192267417907715, "aqua_rat_13225": 0.8194174766540527, "aqua_rat_36022": 0.8196511268615723, "aqua_rat_61885": 0.819685697555542, "aqua_rat_63250": 0.8197391033172607, "aqua_rat_4355": 0.8198091387748718, "aqua_rat_58473": 0.8199703693389893, "aqua_rat_79918": 0.8200647830963135, "aqua_rat_55986": 0.8203088045120239, "aqua_rat_11143": 0.821135938167572, "aqua_rat_45187": 0.8221430778503418, "aqua_rat_27835": 0.8222442865371704, "aqua_rat_9727": 0.822868287563324, "aqua_rat_73109": 0.823280930519104, "aqua_rat_59942": 0.8235517740249634, "aqua_rat_27137": 0.8241717219352722, "math_test_prealgebra_1204": 0.8245630264282227, "math_test_prealgebra_1107": 0.8245884776115417, "aqua_rat_593": 0.8247035145759583, "aqua_rat_34678": 0.8248144388198853, "aqua_rat_86519": 0.8250406384468079, "aqua_rat_32332": 0.8250498175621033, "math_train_counting_and_probability_441": 0.8250813484191895, "aqua_rat_19798": 0.8253450989723206, "aqua_rat_31049": 0.8256117105484009, "aqua_rat_41645": 0.8258122801780701, "aqua_rat_32025": 0.8260571956634521, "aqua_rat_27207": 0.8264847993850708, "aqua_rat_34268": 0.8265687227249146, "aqua_rat_16429": 0.8267465233802795, "aqua_rat_69444": 0.8270740509033203, "aqua_rat_81021": 0.8272914290428162, "aqua_rat_4340": 0.8272919058799744, "aqua_rat_75975": 0.827423095703125, "aqua_rat_60662": 0.8277515769004822, "aqua_rat_74743": 0.8279402852058411, "aqua_rat_50550": 0.8280896544456482, "aqua_rat_22599": 0.8284985423088074, "aqua_rat_65284": 0.8306002616882324, "aqua_rat_13164": 0.8308352828025818, "aqua_rat_22118": 0.830992579460144, "aqua_rat_45147": 0.8316406011581421, "aqua_rat_69596": 0.8319250345230103, "aqua_rat_35991": 0.8330446481704712, "aqua_rat_32954": 0.8336395025253296, "aqua_rat_35796": 0.8336781859397888, "aqua_rat_9005": 0.8337541818618774, "aqua_rat_21632": 0.8337886333465576, "aqua_rat_15466": 0.8338478803634644, "aqua_rat_64457": 0.8339571952819824, "aqua_rat_20032": 0.8343195915222168, "aqua_rat_58208": 0.834927499294281, "math_train_counting_and_probability_29": 0.835361897945404, "math_train_counting_and_probability_1099": 0.8371541500091553, "aqua_rat_69806": 0.8374088406562805, "aqua_rat_37766": 0.8388025760650635, "aqua_rat_9063": 0.8389577865600586, "aqua_rat_34136": 0.8391041159629822, "aqua_rat_8913": 0.8394731283187866, "aqua_rat_58870": 0.840924084186554, "aqua_rat_19714": 0.8433191180229187, "aqua_rat_9747": 0.8438639640808105, "aqua_rat_80293": 0.8467440009117126, "aqua_rat_41332": 0.8469204306602478, "aqua_rat_28709": 0.8495831489562988, "aqua_rat_45246": 0.8515995740890503, "aqua_rat_15353": 0.8521434664726257, "aqua_rat_66661": 0.8522428274154663, "aqua_rat_16417": 0.8592544794082642}, "TheoremQA_tonyxia/semiconductor2.json": {"TheoremQA_tonyxia/semiconductor2.json": 0, "camel_45321": 0.5973625183105469, "gsm_rft_35008": 0.5973825454711914, "aqua_rat_21925": 0.5975906252861023, "camel_29122": 0.597618818283081, "camel_29146": 0.597640335559845, "gsm_train_33171": 0.5977346301078796, "aqua_rat_63167": 0.5977632999420166, "aqua_rat_8480": 0.5978165864944458, "camel_39458": 0.5978931188583374, "aqua_rat_81926": 0.5979094505310059, "camel_29154": 0.5979263782501221, "camel_7735": 0.5981686115264893, "camel_45033": 0.5981688499450684, "aqua_rat_53630": 0.5982582569122314, "aqua_rat_16139": 0.598354697227478, "aqua_rat_10339": 0.5984642505645752, "aqua_rat_51960": 0.5985572934150696, "aqua_rat_13703": 0.5986880660057068, "gsm_rft_11471": 0.5987138152122498, "camel_40967": 0.5987585186958313, "gsm_rft_23876": 0.5987590551376343, "aqua_rat_63612": 0.5987691283226013, "aqua_rat_66469": 0.5988306403160095, "camel_16621": 0.5988661646842957, "camel_37938": 0.5991129279136658, "gsm_rft_3218": 0.5992873311042786, "gsm_train_33000": 0.5992873311042786, "gsm_rft_6865": 0.5993660688400269, "camel_45957": 0.5994743704795837, "gsm_rft_20711": 0.5996628999710083, "camel_29045": 0.5997589826583862, "gsm_rft_22305": 0.599828839302063, "aqua_rat_76667": 0.5998516082763672, "gsm_rft_14572": 0.5999979972839355, "gsm_rft_33507": 0.5999979972839355, "gsm_train_31881": 0.5999979972839355, "gsm_rft_11166": 0.5999979972839355, "aqua_rat_50074": 0.6000509858131409, "aqua_rat_28949": 0.6000587344169617, "aqua_rat_56122": 0.600188136100769, "aqua_rat_14902": 0.6002686023712158, "gsm_train_11581": 0.6003153324127197, "gsm_rft_28561": 0.6003153324127197, "gsm_rft_7433": 0.6003153324127197, "aqua_rat_4231": 0.6004073023796082, "aqua_rat_31331": 0.6006047129631042, "aqua_rat_71661": 0.60074782371521, "camel_37957": 0.6009174585342407, "aqua_rat_30572": 0.6012893915176392, "aqua_rat_42126": 0.6014302968978882, "camel_39482": 0.6014902591705322, "gsm_rft_13049": 0.6015551686286926, "aqua_rat_4046": 0.601607084274292, "camel_39219": 0.6016944646835327, "camel_17288": 0.6018038392066956, "aqua_rat_23035": 0.6018397808074951, "camel_16605": 0.6023536920547485, "aqua_rat_55520": 0.6024361848831177, "camel_29160": 0.6024816632270813, "camel_45302": 0.6024823188781738, "TheoremQA_tonyxia/statisticalphysics5.json": 0.6024953126907349, "gsm_rft_10767": 0.6025285720825195, "aqua_rat_12188": 0.6028384566307068, "aqua_rat_16995": 0.6034185290336609, "camel_16602": 0.60345059633255, "aqua_rat_40044": 0.6035358905792236, "aqua_rat_63126": 0.6037777066230774, "gsm_rft_28624": 0.6037819385528564, "camel_45295": 0.6038937568664551, "aqua_rat_24258": 0.6039491891860962, "aqua_rat_48550": 0.6039546728134155, "aqua_rat_71967": 0.604175329208374, "gsm_train_7372": 0.6042985916137695, "gsm_rft_8990": 0.6042985916137695, "gsm_rft_2592": 0.604421854019165, "camel_36593": 0.6046013832092285, "aqua_rat_42817": 0.6048374772071838, "camel_28715": 0.6048445701599121, "aqua_rat_22739": 0.6048586368560791, "aqua_rat_65009": 0.6049515604972839, "camel_29155": 0.605238139629364, "aqua_rat_33854": 0.6052935123443604, "gsm_train_31158": 0.6053435802459717, "gsm_rft_1939": 0.6053435802459717, "camel_17141": 0.6056593060493469, "gsm_rft_34322": 0.6056739091873169, "gsm_rft_35481": 0.6058048009872437, "aqua_rat_71372": 0.6058202385902405, "aqua_rat_18575": 0.6060072183609009, "TheoremQA_tonyxia/statisticalphysics2.json": 0.6061972975730896, "aqua_rat_2689": 0.6064030528068542, "aqua_rat_87245": 0.6065436601638794, "aqua_rat_73083": 0.6068509817123413, "camel_37959": 0.6069796085357666, "aqua_rat_48599": 0.6070407629013062, "gsm_rft_9719": 0.6070553660392761, "gsm_rft_15582": 0.6072608232498169, "gsm_train_18124": 0.6072608232498169, "aqua_rat_81880": 0.6073522567749023, "aqua_rat_7350": 0.6079041957855225, "gsm_train_22269": 0.6089755892753601, "gsm_rft_32487": 0.6089755892753601, "camel_16169": 0.609276533126831, "aqua_rat_79408": 0.6093391180038452, "camel_17873": 0.6093838810920715, "aqua_rat_65183": 0.6093884110450745, "gsm_rft_14007": 0.6094411611557007, "gsm_rft_33471": 0.6097615361213684, "gsm_rft_8044": 0.6099281311035156, "gsm_train_10599": 0.6099281311035156, "gsm_rft_31522": 0.6102478504180908, "gsm_rft_3972": 0.6102817058563232, "camel_16681": 0.6113205552101135, "gsm_rft_28838": 0.6114723086357117, "camel_28656": 0.6114872694015503, "camel_45148": 0.6118124723434448, "camel_16586": 0.6121322512626648, "TheoremQA_panlu/linear_expansion1.json": 0.6126381754875183, "camel_37879": 0.6128903031349182, "camel_45925": 0.6132922172546387, "camel_16581": 0.613364577293396, "camel_45149": 0.6137668490409851, "camel_43779": 0.6141261458396912, "camel_28143": 0.6142134666442871, "camel_16680": 0.6145485043525696, "camel_29173": 0.6152042746543884, "camel_16571": 0.6152142286300659, "camel_45933": 0.6152410507202148, "camel_29145": 0.6152428984642029, "gsm_rft_7862": 0.6152772903442383, "gsm_rft_22822": 0.6157268285751343, "camel_29123": 0.6161260604858398, "camel_16179": 0.6170134544372559, "aqua_rat_35618": 0.6173751354217529, "camel_38919": 0.6174380779266357, "camel_28081": 0.6177262663841248, "gsm_rft_17141": 0.6181268095970154, "camel_28151": 0.6182278990745544, "gsm_train_1174": 0.6183308959007263, "gsm_rft_33186": 0.6183308959007263, "gsm_rft_26010": 0.6184099316596985, "camel_45169": 0.6184437870979309, "gsm_rft_15366": 0.6186435222625732, "camel_16712": 0.6188806295394897, "gsm_rft_22401": 0.6194417476654053, "gsm_train_23183": 0.6195321083068848, "gsm_rft_28746": 0.6197550892829895, "camel_16674": 0.6200834512710571, "gsm_rft_19423": 0.6203038692474365, "gsm_rft_14462": 0.6203038692474365, "gsm_train_15924": 0.6203038692474365, "gsm_rft_28497": 0.6203892230987549, "gsm_train_18516": 0.6203892230987549, "aqua_rat_24388": 0.6209404468536377, "camel_16682": 0.6213070750236511, "camel_44967": 0.6213776469230652, "camel_45163": 0.6213972568511963, "gsm_rft_33530": 0.6214489936828613, "camel_45323": 0.6222972273826599, "camel_39513": 0.6228302121162415, "camel_45952": 0.6239158511161804, "gsm_rft_21326": 0.6241171360015869, "camel_45992": 0.6248812675476074, "gsm_rft_10110": 0.624968945980072, "camel_16209": 0.625901997089386, "camel_16223": 0.6260483860969543, "camel_29199": 0.6268266439437866, "camel_44806": 0.6276538968086243, "camel_45018": 0.6296972632408142, "camel_29184": 0.6301820874214172, "camel_45677": 0.6322067379951477, "gsm_train_4193": 0.6328213810920715, "gsm_rft_6591": 0.6328213810920715, "camel_45075": 0.6351816058158875, "camel_16634": 0.6361140608787537, "camel_45140": 0.6363945603370667, "gsm_rft_23914": 0.6389158368110657, "camel_45174": 0.6395928263664246, "camel_16596": 0.639693021774292, "camel_17811": 0.6423465013504028, "camel_45986": 0.6441599130630493, "camel_45159": 0.6441630721092224, "camel_45199": 0.644792377948761, "camel_37933": 0.6450768709182739, "camel_17587": 0.6461418271064758, "math_test_algebra_578": 0.6469037532806396, "camel_16573": 0.6538141965866089, "gsm_rft_21213": 0.655735194683075, "gsm_train_10153": 0.6558124423027039, "camel_45999": 0.6559956073760986, "gsm_rft_35104": 0.6562002897262573, "TheoremQA_tonyxia/wave2.json": 0.6669539213180542, "camel_45956": 0.6674407720565796, "camel_16575": 0.6718355417251587, "TheoremQA_panlu/wave_length1.json": 0.6741613149642944, "TheoremQA_tonyxia/photoelectric1.json": 0.6848261952400208, "camel_45967": 0.7207926511764526, "camel_45935": 0.7263672351837158, "TheoremQA_tonyxia/semiconductor3.json": 0.8113616704940796}, "TheoremQA_xueguangma/present_value_2.json": {"TheoremQA_xueguangma/present_value_2.json": 0, "gsm_rft_31412": 0.7355207800865173, "aqua_rat_16723": 0.7355877757072449, "aqua_rat_59199": 0.7355909943580627, "gsm_rft_34181": 0.7357380390167236, "aqua_rat_64914": 0.7359079122543335, "gsm_rft_17451": 0.7359825968742371, "aqua_rat_24068": 0.7360217571258545, "aqua_rat_36703": 0.7361756563186646, "gsm_rft_33358": 0.7362490296363831, "gsm_train_22081": 0.7363173961639404, "aqua_rat_6634": 0.7363339066505432, "gsm_train_859": 0.736402690410614, "gsm_rft_18163": 0.7364615797996521, "gsm_rft_15946": 0.7365029454231262, "gsm_rft_15258": 0.7365477681159973, "aqua_rat_37299": 0.7366414666175842, "aqua_rat_64484": 0.7367632389068604, "aqua_rat_79789": 0.7368848323822021, "aqua_rat_44517": 0.7369263172149658, "aqua_rat_55287": 0.7370160818099976, "gsm_rft_22590": 0.737046480178833, "camel_37682": 0.7372593283653259, "gsm_rft_34423": 0.7372632622718811, "aqua_rat_74243": 0.737535297870636, "gsm_rft_14276": 0.737745463848114, "gsm_rft_21730": 0.737800121307373, "gsm_rft_18143": 0.7378979325294495, "gsm_rft_32168": 0.737966775894165, "aqua_rat_80837": 0.738129734992981, "gsm_rft_11804": 0.7381357550621033, "gsm_rft_31372": 0.7382398843765259, "gsm_train_4730": 0.7382398843765259, "aqua_rat_80303": 0.7382560968399048, "aqua_rat_1115": 0.7383095622062683, "aqua_rat_17583": 0.73834627866745, "gsm_rft_21062": 0.7384060025215149, "aqua_rat_55503": 0.7384331226348877, "aqua_rat_26022": 0.7384347319602966, "gsm_rft_10641": 0.7385708689689636, "gsm_train_4924": 0.7385708689689636, "aqua_rat_82832": 0.7386288642883301, "gsm_train_30707": 0.7388710379600525, "gsm_rft_15888": 0.7389109134674072, "gsm_train_21876": 0.7389109134674072, "gsm_rft_24735": 0.7389211058616638, "gsm_rft_6751": 0.7389407157897949, "gsm_train_34638": 0.7389407157897949, "gsm_rft_14240": 0.7389484643936157, "aqua_rat_57864": 0.7390435338020325, "aqua_rat_57431": 0.7390520572662354, "gsm_train_2595": 0.7391626834869385, "gsm_rft_20558": 0.7392042279243469, "gsm_rft_15020": 0.7392341494560242, "aqua_rat_39841": 0.7392846941947937, "gsm_rft_33617": 0.7394154667854309, "aqua_rat_34081": 0.7395414710044861, "gsm_rft_6203": 0.7396088242530823, "gsm_rft_35170": 0.7396320104598999, "aqua_rat_84306": 0.7398415207862854, "aqua_rat_48160": 0.7400873899459839, "aqua_rat_66917": 0.74013352394104, "camel_25251": 0.7402254343032837, "gsm_rft_22041": 0.7403407096862793, "gsm_train_24478": 0.7403407096862793, "aqua_rat_50029": 0.7403573989868164, "gsm_rft_29226": 0.7404689192771912, "gsm_rft_20456": 0.7405632734298706, "aqua_rat_18811": 0.7408053874969482, "gsm_rft_25913": 0.7411051392555237, "aqua_rat_87484": 0.7411286234855652, "aqua_rat_73957": 0.7411401271820068, "gsm_rft_22572": 0.7413630485534668, "gsm_rft_33659": 0.741849422454834, "aqua_rat_24542": 0.7426609396934509, "gsm_rft_24249": 0.7430655360221863, "aqua_rat_83671": 0.7432210445404053, "gsm_rft_15334": 0.7432571649551392, "gsm_train_6037": 0.7432571649551392, "aqua_rat_5272": 0.743432879447937, "aqua_rat_67914": 0.7435393929481506, "gsm_rft_12600": 0.7437964081764221, "aqua_rat_56922": 0.7439298629760742, "aqua_rat_78719": 0.7439956068992615, "gsm_rft_33006": 0.7440659403800964, "aqua_rat_12055": 0.7440896034240723, "aqua_rat_16445": 0.7441615462303162, "gsm_rft_25508": 0.7441644072532654, "gsm_train_22552": 0.7441644072532654, "aqua_rat_74914": 0.7441852688789368, "gsm_rft_8126": 0.7443735003471375, "gsm_rft_3126": 0.7444077730178833, "gsm_rft_17545": 0.7447956800460815, "aqua_rat_32321": 0.7448100447654724, "gsm_rft_7096": 0.7448865175247192, "aqua_rat_38199": 0.7449803352355957, "gsm_rft_34606": 0.7450340390205383, "aqua_rat_16875": 0.7450411319732666, "camel_37720": 0.745252251625061, "camel_37722": 0.7453121542930603, "aqua_rat_37392": 0.745695948600769, "gsm_rft_30907": 0.7458904385566711, "aqua_rat_4548": 0.7460066080093384, "aqua_rat_58924": 0.7464135885238647, "gsm_rft_7924": 0.7467209696769714, "gsm_train_22362": 0.7467209696769714, "gsm_rft_32767": 0.7470405101776123, "aqua_rat_47761": 0.7471275925636292, "aqua_rat_27143": 0.7475021481513977, "aqua_rat_64296": 0.7475618124008179, "gsm_rft_12517": 0.7478752732276917, "aqua_rat_23836": 0.7479840517044067, "gsm_rft_7891": 0.7481131553649902, "aqua_rat_53305": 0.7489596009254456, "gsm_rft_32019": 0.7490536570549011, "aqua_rat_9488": 0.7490715980529785, "TheoremQA_xueguangma/dividend_discount_model_5.json": 0.7495839595794678, "aqua_rat_60935": 0.7497877478599548, "aqua_rat_15749": 0.749883234500885, "gsm_rft_9581": 0.7502977252006531, "aqua_rat_48456": 0.7506447434425354, "aqua_rat_13348": 0.750670850276947, "aqua_rat_66654": 0.750758707523346, "TheoremQA_xueguangma/put_call_parity_1.json": 0.750920295715332, "aqua_rat_87486": 0.7513993382453918, "aqua_rat_11544": 0.7517126202583313, "aqua_rat_14235": 0.7517272233963013, "aqua_rat_69764": 0.7522929906845093, "aqua_rat_63174": 0.7523259520530701, "gsm_rft_9128": 0.7524704337120056, "camel_37729": 0.7527653574943542, "gsm_rft_5014": 0.7530168890953064, "aqua_rat_9530": 0.7536404132843018, "aqua_rat_611": 0.7538399696350098, "gsm_rft_10732": 0.7540118098258972, "gsm_train_7824": 0.7540118098258972, "aqua_rat_67442": 0.7540968656539917, "aqua_rat_65316": 0.7545132040977478, "aqua_rat_3830": 0.7546940445899963, "gsm_rft_28287": 0.7550463676452637, "gsm_rft_33880": 0.7551230788230896, "aqua_rat_31099": 0.7551685571670532, "aqua_rat_54684": 0.7552945017814636, "aqua_rat_16258": 0.7557215690612793, "gsm_rft_21130": 0.7560417652130127, "gsm_rft_19903": 0.7560417652130127, "gsm_train_12933": 0.7560417652130127, "aqua_rat_65768": 0.7563498020172119, "aqua_rat_83178": 0.7566859126091003, "gsm_rft_23260": 0.756918728351593, "gsm_rft_3411": 0.7579203248023987, "aqua_rat_62371": 0.7581656575202942, "aqua_rat_27652": 0.7587834596633911, "aqua_rat_24247": 0.7588590383529663, "aqua_rat_87442": 0.7598026990890503, "aqua_rat_8298": 0.7599536776542664, "aqua_rat_9857": 0.7601442933082581, "aqua_rat_76597": 0.7603647708892822, "aqua_rat_32568": 0.7615245580673218, "gsm_rft_1672": 0.7621681690216064, "gsm_rft_27542": 0.7629820704460144, "gsm_train_3010": 0.7632646560668945, "TheoremQA_xueguangma/forward_price_3.json": 0.7642084956169128, "aqua_rat_71866": 0.764559268951416, "aqua_rat_70160": 0.7670565843582153, "aqua_rat_26043": 0.7677334547042847, "gsm_rft_16062": 0.7680163383483887, "gsm_rft_25231": 0.7682207822799683, "gsm_train_19719": 0.7682207822799683, "camel_37735": 0.7684543132781982, "aqua_rat_6475": 0.7684550881385803, "aqua_rat_29417": 0.7701712250709534, "aqua_rat_37203": 0.7720751166343689, "gsm_rft_6422": 0.7729235887527466, "camel_45730": 0.7756428122520447, "camel_37747": 0.7766563296318054, "camel_45738": 0.7787091732025146, "aqua_rat_56845": 0.7796881198883057, "aqua_rat_59587": 0.7802274823188782, "aqua_rat_64523": 0.7808772325515747, "aqua_rat_85902": 0.7830712199211121, "aqua_rat_46883": 0.783973753452301, "TheoremQA_xueguangma/forward_price_1.json": 0.7842690944671631, "aqua_rat_29154": 0.7844576835632324, "aqua_rat_56436": 0.7853052616119385, "aqua_rat_30597": 0.7854645252227783, "aqua_rat_88843": 0.786068320274353, "math_train_algebra_940": 0.787415087223053, "aqua_rat_57507": 0.7881884574890137, "aqua_rat_36498": 0.7922953963279724, "camel_37746": 0.7996845841407776, "TheoremQA_xueguangma/spot_rate.json": 0.8008589744567871, "aqua_rat_80676": 0.8028191924095154, "aqua_rat_79856": 0.8028971552848816, "TheoremQA_xueguangma/present_value_1.json": 0.8102538585662842, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.8117936253547668, "aqua_rat_49352": 0.8121291995048523, "TheoremQA_xueguangma/forward_price_2.json": 0.816372275352478, "aqua_rat_45508": 0.8250837922096252, "aqua_rat_31553": 0.8369922637939453}, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": {"camel_38611": 0, "camel_21600": 0, "camel_21606": 0, "camel_39951": 0, "camel_21661": 0, "camel_39925": 0, "camel_38518": 0, "camel_22248": 0, "camel_22363": 0, "camel_39974": 0, "camel_21665": 0, "camel_21653": 0, "camel_39940": 0, "camel_39927": 0, "camel_21664": 0, "camel_39975": 0, "camel_21671": 0, "camel_38609": 0, "camel_22842": 0, "camel_38615": 0, "camel_22818": 0, "camel_22332": 0, "camel_39960": 0, "camel_23970": 0, "camel_23967": 0, "camel_22016": 0, "camel_38560": 0, "camel_21641": 0, "camel_39942": 0, "camel_21676": 0, "camel_21615": 0, "camel_21622": 0, "camel_38622": 0, "camel_22051": 0, "camel_22172": 0, "camel_39955": 0, "camel_38639": 0, "camel_22276": 0, "camel_21662": 0, "camel_39929": 0, "camel_22735": 0, "camel_38637": 0, "camel_22266": 0, "camel_21634": 0, "camel_21612": 0, "camel_22060": 0, "camel_39962": 0, "camel_39963": 0, "camel_38569": 0, "camel_22046": 0, "camel_21640": 0, "camel_22000": 0, "camel_21669": 0, "camel_21674": 0, "camel_39954": 0, "camel_23957": 0, "camel_21614": 0, "camel_21617": 0, "camel_21601": 0, "camel_38627": 0, "camel_21666": 0, "camel_21646": 0, "camel_21675": 0, "camel_39976": 0, "camel_21677": 0, "camel_21626": 0, "camel_39968": 0, "camel_23982": 0, "camel_39967": 0, "camel_39952": 0, "camel_21607": 0, "camel_22037": 0, "camel_39989": 0, "camel_22341": 0, "camel_39977": 0, "camel_22003": 0, "camel_22009": 0, "camel_39943": 0, "camel_22301": 0, "camel_21589": 0, "camel_22285": 0, "camel_22395": 0, "camel_22055": 0, "camel_22279": 0, "camel_38599": 0, "camel_21667": 0, "camel_22057": 0, "camel_22290": 0, "camel_21656": 0, "camel_21642": 0, "camel_38594": 0, "camel_39979": 0, "camel_23953": 0, "camel_22069": 0, "camel_21637": 0, "camel_38491": 0, "camel_22344": 0, "camel_21655": 0, "camel_22324": 0, "camel_39933": 0, "camel_21633": 0, "camel_21645": 0, "camel_21660": 0, "camel_21647": 0, "camel_39944": 0, "camel_39972": 0, "camel_21658": 0, "camel_21635": 0, "camel_21670": 0, "camel_21604": 0, "camel_23184": 0, "camel_22326": 0, "camel_23936": 0, "camel_39981": 0, "camel_21644": 0, "camel_21672": 0, "camel_21631": 0, "camel_21621": 0, "camel_39936": 0, "camel_39987": 0, "camel_21632": 0, "camel_22041": 0, "camel_22040": 0, "camel_39956": 0, "camel_22043": 0, "camel_39994": 0, "camel_21618": 0, "camel_39932": 0, "camel_39931": 0, "camel_23950": 0, "camel_21678": 0, "camel_23981": 0, "camel_39998": 0, "camel_39970": 0, "camel_39920": 0, "camel_21651": 0, "camel_38564": 0, "camel_21603": 0, "camel_39997": 0, "camel_21602": 0, "camel_21643": 0, "camel_21619": 0, "camel_21605": 0, "camel_39986": 0, "camel_21616": 0, "camel_39950": 0, "camel_21679": 0, "camel_21673": 0, "camel_22350": 0, "camel_38621": 0, "camel_22340": 0, "camel_39982": 0, "camel_39980": 0, "camel_21623": 0, "camel_38581": 0, "camel_21628": 0, "camel_38630": 0, "camel_22390": 0, "camel_22330": 0, "camel_39953": 0, "camel_21625": 0, "camel_22479": 0, "camel_21654": 0, "camel_21663": 0, "camel_38573": 0, "camel_21659": 0, "camel_22354": 0, "camel_23924": 0, "camel_39966": 0, "camel_22247": 0, "camel_39983": 0, "camel_23973": 0, "camel_21657": 0, "camel_39978": 0, "camel_38501": 0, "camel_21639": 0, "camel_21620": 0, "camel_22831": 0, "camel_21649": 0, "camel_39990": 0, "camel_39959": 0, "camel_39988": 0, "camel_23947": 0, "camel_23991": 0, "camel_39965": 0, "camel_39937": 0, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": 0, "camel_23961": 0, "camel_22367": 0, "camel_39971": 0, "camel_39999": 0, "camel_38489": 0, "camel_21611": 0, "camel_22368": 0, "aqua_rat_23848": 0.8339301943778992, "aqua_rat_81541": 0.8346408605575562, "aqua_rat_9572": 0.8352668285369873, "aqua_rat_49003": 0.8437539935112, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0.8512837290763855, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0.860783040523529}, "TheoremQA_wenhuchen/p_value2.json": {"camel_9521": 0, "camel_9464": 0, "camel_9534": 0, "camel_9540": 0, "camel_9593": 0, "camel_8375": 0, "camel_9543": 0, "camel_9578": 0, "camel_8784": 0, "camel_9561": 0, "camel_9579": 0, "camel_9599": 0, "camel_8037": 0, "camel_8731": 0, "camel_9563": 0, "camel_8045": 0, "camel_9582": 0, "camel_8740": 0, "camel_9570": 0, "camel_9529": 0, "camel_9583": 0, "camel_9463": 0, "camel_8017": 0, "camel_9584": 0, "camel_9574": 0, "camel_9525": 0, "camel_8737": 0, "camel_9575": 0, "camel_9559": 0, "camel_9531": 0, "TheoremQA_wenhuchen/p_value2.json": 0, "camel_9590": 0, "camel_9530": 0, "camel_9924": 0, "camel_9562": 0, "camel_10656": 0.8044703602790833, "camel_10273": 0.8045640587806702, "camel_10448": 0.804667055606842, "camel_37781": 0.804676353931427, "camel_11439": 0.8046806454658508, "camel_24640": 0.8046903014183044, "aqua_rat_2534": 0.8049168586730957, "camel_25283": 0.8049594759941101, "camel_10752": 0.8049604892730713, "camel_10837": 0.8050228357315063, "camel_10741": 0.8051433563232422, "camel_10092": 0.8051649332046509, "camel_11364": 0.8051848411560059, "camel_10154": 0.8053531050682068, "camel_37775": 0.8053633570671082, "camel_10460": 0.8053736090660095, "camel_11495": 0.8055087924003601, "aqua_rat_67122": 0.8056244254112244, "camel_11450": 0.8057354688644409, "camel_11118": 0.8060604929924011, "aqua_rat_30478": 0.8060984015464783, "camel_11493": 0.80624920129776, "camel_11443": 0.806319534778595, "camel_11462": 0.8064157366752625, "gsm_rft_34226": 0.8064376711845398, "gsm_train_32701": 0.8064376711845398, "camel_10070": 0.8064694404602051, "camel_10386": 0.8065472841262817, "camel_11822": 0.8066766858100891, "camel_11623": 0.8067789077758789, "gsm_rft_3381": 0.8068653345108032, "aqua_rat_78959": 0.8070473670959473, "camel_11446": 0.8071305155754089, "camel_10557": 0.8072561621665955, "camel_10263": 0.8074383735656738, "camel_11586": 0.8075008988380432, "camel_10657": 0.8075253963470459, "camel_10462": 0.8076328635215759, "camel_11316": 0.8078415393829346, "camel_11356": 0.8081361651420593, "aqua_rat_71021": 0.8085336089134216, "camel_11713": 0.8086211681365967, "camel_10926": 0.8086308240890503, "aqua_rat_57279": 0.8086477518081665, "aqua_rat_38290": 0.8091014623641968, "aqua_rat_46341": 0.8091087341308594, "camel_37830": 0.8092687129974365, "camel_11436": 0.8096532225608826, "camel_11416": 0.8096646070480347, "camel_11308": 0.8098636865615845, "camel_10652": 0.8101713061332703, "camel_10467": 0.810207724571228, "aqua_rat_43445": 0.8103904724121094, "camel_37802": 0.8104672431945801, "math_train_counting_and_probability_257": 0.8107094764709473, "aqua_rat_20022": 0.8108235597610474, "camel_10074": 0.8113723397254944, "aqua_rat_71125": 0.8114283084869385, "camel_11463": 0.8115099668502808, "camel_10682": 0.811823308467865, "math_test_counting_and_probability_359": 0.8121495842933655, "camel_10793": 0.8125703930854797, "aqua_rat_37618": 0.8128324151039124, "camel_11348": 0.8129529356956482, "camel_10694": 0.8129603862762451, "camel_11818": 0.8129767775535583, "aqua_rat_56702": 0.8130029439926147, "aqua_rat_72672": 0.8130369782447815, "camel_10717": 0.8131601810455322, "aqua_rat_23049": 0.8132423758506775, "camel_10555": 0.8132448196411133, "aqua_rat_67067": 0.8132779598236084, "camel_11967": 0.8133876323699951, "camel_11465": 0.813643753528595, "aqua_rat_18011": 0.8137543797492981, "camel_11423": 0.8138595223426819, "camel_10316": 0.8139641284942627, "camel_11990": 0.8139724731445312, "camel_11756": 0.8142490983009338, "camel_24683": 0.8145622611045837, "camel_37612": 0.8146510720252991, "camel_10409": 0.8147640824317932, "camel_10432": 0.814990758895874, "camel_11548": 0.8152226805686951, "aqua_rat_23510": 0.815372884273529, "camel_11422": 0.8154929876327515, "aqua_rat_34192": 0.8156219720840454, "camel_10369": 0.815766453742981, "aqua_rat_56774": 0.816049337387085, "camel_11499": 0.8160831928253174, "camel_24675": 0.8161306381225586, "aqua_rat_62298": 0.8162758946418762, "camel_10301": 0.8166237473487854, "camel_10423": 0.8170113563537598, "camel_11786": 0.8170720934867859, "camel_11453": 0.8171045184135437, "camel_11531": 0.8189420700073242, "camel_10327": 0.8189566135406494, "camel_10597": 0.8192429542541504, "camel_11238": 0.8194968700408936, "camel_11925": 0.8196110725402832, "camel_11619": 0.8196802735328674, "camel_10603": 0.8199057579040527, "aqua_rat_61314": 0.8199080228805542, "camel_10720": 0.8204637169837952, "aqua_rat_16030": 0.8206360340118408, "camel_10700": 0.8206398487091064, "camel_11985": 0.8207747340202332, "camel_24662": 0.8209508061408997, "camel_10406": 0.8213990330696106, "aqua_rat_33941": 0.8217042088508606, "camel_11850": 0.8222156763076782, "aqua_rat_31288": 0.8226264119148254, "camel_10705": 0.8227205276489258, "camel_11726": 0.8230826258659363, "camel_10698": 0.8235077261924744, "camel_10373": 0.8236067891120911, "camel_37884": 0.8239320516586304, "camel_10943": 0.8248916864395142, "camel_11693": 0.8250596523284912, "camel_10365": 0.8253661394119263, "camel_11758": 0.8264148831367493, "camel_39375": 0.826568067073822, "camel_11455": 0.8267351388931274, "camel_24693": 0.8267529010772705, "camel_11286": 0.8286555409431458, "camel_24654": 0.829196572303772, "aqua_rat_5883": 0.8298871517181396, "camel_10019": 0.8300484418869019, "aqua_rat_31129": 0.8308238983154297, "aqua_rat_86847": 0.8308692574501038, "camel_10590": 0.8308768272399902, "aqua_rat_42842": 0.8309102058410645, "aqua_rat_29721": 0.8309772610664368, "camel_10568": 0.8322573304176331, "aqua_rat_75743": 0.8336122035980225, "aqua_rat_32748": 0.833756148815155, "aqua_rat_63187": 0.8337734341621399, "camel_10469": 0.8340355157852173, "camel_11558": 0.8369201421737671, "aqua_rat_37936": 0.838209867477417, "math_test_counting_and_probability_878": 0.838596522808075, "camel_37652": 0.8395017981529236, "aqua_rat_15170": 0.8402830958366394, "camel_10242": 0.8427843451499939, "camel_37762": 0.844004213809967, "TheoremQA_wenhuchen/p_value1.json": 0.8455440402030945, "camel_11457": 0.8467549085617065, "aqua_rat_45572": 0.8471970558166504, "camel_37799": 0.8484088778495789, "aqua_rat_64138": 0.8487075567245483, "camel_10006": 0.8489217162132263, "math_train_counting_and_probability_97": 0.849795937538147, "aqua_rat_42517": 0.8541989922523499, "aqua_rat_2657": 0.8543353080749512, "aqua_rat_66708": 0.8575679659843445, "aqua_rat_84637": 0.8577375411987305, "camel_11539": 0.8580881357192993, "aqua_rat_32857": 0.8583309054374695, "camel_11563": 0.8587942719459534, "aqua_rat_74523": 0.859523594379425, "aqua_rat_5264": 0.8620249629020691, "aqua_rat_36135": 0.8624410033226013, "camel_10004": 0.869888186454773, "camel_37875": 0.8700377345085144}, "TheoremQA_xueguangma/dividend_discount_model_1.json": {"TheoremQA_xueguangma/dividend_discount_model_1.json": 0, "aqua_rat_24355": 0.7203794717788696, "gsm_rft_11189": 0.720386803150177, "aqua_rat_9771": 0.7205068469047546, "aqua_rat_76890": 0.7205390930175781, "gsm_rft_25984": 0.7205754518508911, "camel_25270": 0.7206072211265564, "TheoremQA_xueguangma/forward_price_1.json": 0.7206473350524902, "gsm_rft_17441": 0.7206616401672363, "gsm_rft_6203": 0.7206724286079407, "TheoremQA_xueguangma/present_value_1.json": 0.7206899523735046, "camel_25188": 0.7207127213478088, "aqua_rat_62036": 0.7207224369049072, "gsm_rft_33880": 0.720737874507904, "camel_39796": 0.7207896709442139, "gsm_rft_8432": 0.7209100127220154, "gsm_train_11721": 0.7209100127220154, "aqua_rat_68283": 0.7209383845329285, "gsm_rft_26823": 0.7210642695426941, "gsm_rft_24611": 0.7212955355644226, "camel_25201": 0.7213268280029297, "gsm_train_17735": 0.7213740944862366, "gsm_rft_27436": 0.7213967442512512, "aqua_rat_46623": 0.7214016318321228, "aqua_rat_75134": 0.7214973568916321, "math_test_algebra_1043": 0.7215113043785095, "aqua_rat_69571": 0.7215760946273804, "gsm_rft_7079": 0.7217693328857422, "aqua_rat_59171": 0.721893846988678, "gsm_rft_14407": 0.7220032811164856, "gsm_rft_14276": 0.7221620082855225, "camel_37722": 0.7221648097038269, "gsm_rft_35059": 0.7222295999526978, "camel_25257": 0.72236168384552, "camel_25239": 0.7226470708847046, "gsm_rft_32019": 0.7227771878242493, "camel_25249": 0.7228261828422546, "gsm_rft_31854": 0.7228494882583618, "aqua_rat_88687": 0.722858726978302, "TheoremQA_elainewan/econ_micro_18.json": 0.7229052186012268, "aqua_rat_70690": 0.7230116128921509, "gsm_rft_25277": 0.7230385541915894, "camel_10506": 0.7230565547943115, "aqua_rat_86373": 0.7231085300445557, "camel_37714": 0.7231106162071228, "gsm_rft_31738": 0.7231184840202332, "aqua_rat_6973": 0.7231698036193848, "gsm_train_22659": 0.723285436630249, "gsm_rft_28000": 0.7236071825027466, "aqua_rat_9965": 0.7236393690109253, "gsm_rft_34497": 0.7239415645599365, "gsm_rft_26705": 0.7239415645599365, "aqua_rat_16849": 0.7240768074989319, "gsm_rft_29688": 0.7244492173194885, "aqua_rat_39503": 0.724465012550354, "aqua_rat_72156": 0.7246058583259583, "aqua_rat_16627": 0.7246764898300171, "aqua_rat_87246": 0.7246972918510437, "gsm_rft_17302": 0.724735677242279, "aqua_rat_59298": 0.7247375845909119, "gsm_rft_10252": 0.7248085737228394, "aqua_rat_22731": 0.7248463034629822, "gsm_rft_27770": 0.7249476909637451, "gsm_train_14713": 0.725214421749115, "gsm_rft_1672": 0.725315272808075, "gsm_rft_27542": 0.7254951000213623, "aqua_rat_45227": 0.7255277037620544, "gsm_rft_27319": 0.7257305383682251, "aqua_rat_73424": 0.7257872819900513, "gsm_rft_24082": 0.7261929512023926, "gsm_rft_13281": 0.7262749075889587, "gsm_train_14821": 0.7263051271438599, "aqua_rat_77486": 0.7263059616088867, "aqua_rat_49748": 0.72637939453125, "aqua_rat_16605": 0.726390540599823, "gsm_train_3010": 0.7264008522033691, "aqua_rat_2713": 0.7264389991760254, "gsm_rft_3769": 0.7265408635139465, "camel_37754": 0.7266115546226501, "aqua_rat_798": 0.7267864942550659, "aqua_rat_85499": 0.7267917990684509, "gsm_rft_34608": 0.7268190979957581, "gsm_rft_29906": 0.7269200086593628, "gsm_train_16035": 0.7269200086593628, "aqua_rat_69026": 0.7271201610565186, "aqua_rat_27446": 0.7274017930030823, "gsm_train_14812": 0.7274892330169678, "aqua_rat_87884": 0.7277837991714478, "gsm_rft_34694": 0.7279285192489624, "camel_37747": 0.7282341122627258, "gsm_rft_252": 0.7283919453620911, "gsm_rft_23395": 0.7287496328353882, "gsm_train_14708": 0.7287496328353882, "aqua_rat_64527": 0.728847324848175, "gsm_rft_6266": 0.7292864322662354, "aqua_rat_82399": 0.7294047474861145, "aqua_rat_56727": 0.729717493057251, "aqua_rat_88958": 0.7298131585121155, "aqua_rat_9579": 0.7298862934112549, "aqua_rat_56240": 0.729902446269989, "aqua_rat_26820": 0.7300881147384644, "aqua_rat_80175": 0.7302736639976501, "aqua_rat_74699": 0.7305141091346741, "aqua_rat_73408": 0.730523943901062, "camel_25268": 0.7307426929473877, "gsm_rft_14506": 0.7310338616371155, "gsm_train_10049": 0.7310338616371155, "aqua_rat_11679": 0.7311781644821167, "aqua_rat_61026": 0.7312006950378418, "aqua_rat_6366": 0.7314777970314026, "aqua_rat_18140": 0.7314836382865906, "camel_25151": 0.7315043807029724, "aqua_rat_42852": 0.7317718267440796, "gsm_train_26918": 0.7320782542228699, "gsm_rft_26599": 0.7320782542228699, "gsm_rft_24497": 0.7321448922157288, "gsm_rft_8605": 0.7324681878089905, "camel_25213": 0.7324856519699097, "aqua_rat_17685": 0.7327922582626343, "aqua_rat_55929": 0.733260452747345, "aqua_rat_4287": 0.7336769700050354, "gsm_rft_4368": 0.7337203025817871, "gsm_rft_31049": 0.7338143587112427, "aqua_rat_55181": 0.7338168621063232, "gsm_rft_5012": 0.7338207960128784, "gsm_rft_33387": 0.7340176105499268, "gsm_train_25772": 0.7341693639755249, "aqua_rat_46293": 0.7342051267623901, "math_train_prealgebra_1338": 0.7344245910644531, "gsm_rft_15258": 0.7344526648521423, "aqua_rat_34230": 0.7347210645675659, "gsm_train_18514": 0.7353394031524658, "aqua_rat_67487": 0.73549884557724, "aqua_rat_79547": 0.73603755235672, "camel_37742": 0.7362045645713806, "gsm_rft_31412": 0.7363191843032837, "aqua_rat_48354": 0.7363402247428894, "aqua_rat_945": 0.7365222573280334, "gsm_rft_2996": 0.7372043132781982, "aqua_rat_77492": 0.7372246980667114, "aqua_rat_63119": 0.7372975945472717, "aqua_rat_87163": 0.737326979637146, "aqua_rat_46713": 0.737866222858429, "aqua_rat_14152": 0.7381759881973267, "aqua_rat_40840": 0.739808976650238, "aqua_rat_19454": 0.740096926689148, "gsm_rft_14574": 0.7410438656806946, "aqua_rat_15749": 0.7416228652000427, "aqua_rat_80299": 0.7417477369308472, "aqua_rat_36204": 0.7418596744537354, "camel_37729": 0.7419115304946899, "aqua_rat_89004": 0.7421600818634033, "aqua_rat_76879": 0.7426338791847229, "aqua_rat_758": 0.74294114112854, "gsm_rft_34600": 0.7433356046676636, "aqua_rat_27489": 0.7434170842170715, "aqua_rat_56922": 0.7435445785522461, "gsm_rft_33804": 0.7440414428710938, "aqua_rat_23836": 0.74411541223526, "aqua_rat_37709": 0.7441752552986145, "gsm_rft_17649": 0.7445070147514343, "gsm_rft_28490": 0.7446175217628479, "camel_25253": 0.7446960806846619, "aqua_rat_76011": 0.7447769641876221, "camel_37746": 0.7449928522109985, "aqua_rat_16258": 0.7459086775779724, "aqua_rat_64914": 0.7460019588470459, "aqua_rat_46842": 0.7466246485710144, "aqua_rat_12664": 0.7474184036254883, "gsm_rft_26721": 0.747764527797699, "gsm_rft_27287": 0.7479487061500549, "gsm_rft_23795": 0.7480608820915222, "camel_25251": 0.7482361197471619, "gsm_rft_4489": 0.7489970922470093, "gsm_train_5087": 0.7489970922470093, "gsm_rft_19671": 0.7489970922470093, "gsm_rft_11850": 0.749015748500824, "aqua_rat_87442": 0.7496691942214966, "gsm_rft_17816": 0.7500686645507812, "aqua_rat_85762": 0.7505512237548828, "gsm_train_374": 0.7507086396217346, "gsm_rft_20347": 0.7507086396217346, "gsm_rft_26543": 0.7513409852981567, "TheoremQA_xueguangma/dividend_discount_model_2.json": 0.752878725528717, "aqua_rat_1364": 0.7542040348052979, "gsm_rft_22277": 0.7542052865028381, "gsm_rft_16966": 0.7544286847114563, "aqua_rat_88770": 0.7545128464698792, "aqua_rat_52197": 0.7567028403282166, "aqua_rat_8292": 0.7574522495269775, "aqua_rat_24626": 0.7587998509407043, "aqua_rat_52474": 0.759399950504303, "aqua_rat_86309": 0.7601299285888672, "aqua_rat_57386": 0.7608261108398438, "gsm_rft_5070": 0.7615159749984741, "aqua_rat_80962": 0.7631317973136902, "aqua_rat_33283": 0.764698326587677, "aqua_rat_81348": 0.7741090059280396, "TheoremQA_xueguangma/dividend_discount_model_5.json": 0.7825544476509094, "TheoremQA_xueguangma/dividend_discount_model_4.json": 0.8167164325714111}, "TheoremQA_xinyi/rate_distortion_function_2.json": {"TheoremQA_xinyi/rate_distortion_function_2.json": 0, "aqua_rat_56215": 0.6289334893226624, "gsm_rft_4313": 0.6289464831352234, "camel_41963": 0.6290001273155212, "aqua_rat_29047": 0.6291720271110535, "aqua_rat_36417": 0.6291977167129517, "camel_13785": 0.6293036341667175, "aqua_rat_54087": 0.6294212937355042, "camel_44755": 0.6294969320297241, "camel_25977": 0.6295213103294373, "camel_41830": 0.6296271681785583, "aqua_rat_2785": 0.6296891570091248, "camel_39948": 0.6299057006835938, "aqua_rat_5881": 0.629915177822113, "camel_25452": 0.6299231052398682, "camel_39340": 0.6299881339073181, "gsm_rft_14796": 0.6299973726272583, "gsm_rft_16634": 0.6299973726272583, "gsm_train_17890": 0.6299973726272583, "camel_41958": 0.6300125122070312, "gsm_rft_6010": 0.6300134062767029, "gsm_train_21444": 0.6300134062767029, "camel_41005": 0.630085289478302, "gsm_rft_24117": 0.6302528977394104, "camel_38940": 0.6302642226219177, "camel_41071": 0.6303656101226807, "gsm_rft_3283": 0.6303802132606506, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.630449116230011, "camel_37507": 0.6305168867111206, "gsm_rft_21331": 0.6305490732192993, "camel_41079": 0.6307021379470825, "gsm_rft_22319": 0.6307392716407776, "gsm_rft_6361": 0.6309173107147217, "gsm_rft_19506": 0.6309837102890015, "gsm_train_17407": 0.6309837102890015, "camel_41288": 0.631064772605896, "camel_41921": 0.6310768723487854, "camel_9152": 0.6311500668525696, "camel_41135": 0.6311502456665039, "aqua_rat_85313": 0.631169319152832, "gsm_rft_10581": 0.6312918663024902, "gsm_rft_241": 0.631337583065033, "camel_30407": 0.6314238905906677, "camel_41706": 0.6314406394958496, "camel_44728": 0.6315677762031555, "camel_38603": 0.6315896511077881, "camel_38618": 0.6316158175468445, "gsm_rft_28347": 0.6316408514976501, "TheoremQA_maxku/ipnetwork7-lan.json": 0.6317283511161804, "camel_39973": 0.6317625641822815, "gsm_rft_9928": 0.6317853927612305, "camel_9153": 0.6317940950393677, "aqua_rat_52745": 0.6318036913871765, "camel_41290": 0.63203364610672, "camel_41753": 0.6320908069610596, "TheoremQA_xinyi/binary_symmetric_channel_1.json": 0.6322118043899536, "gsm_rft_24984": 0.6323462724685669, "aqua_rat_53526": 0.6323493123054504, "aqua_rat_31535": 0.6325761079788208, "camel_41947": 0.632588803768158, "aqua_rat_38672": 0.632655143737793, "camel_41992": 0.6327725648880005, "camel_41742": 0.6328197717666626, "camel_39332": 0.6328839063644409, "aqua_rat_19344": 0.6329123377799988, "aqua_rat_12162": 0.6329327821731567, "camel_39472": 0.6329411268234253, "camel_21539": 0.6330078840255737, "gsm_rft_17939": 0.6330328583717346, "camel_41302": 0.633516788482666, "camel_41944": 0.6337093710899353, "gsm_rft_9514": 0.6338215470314026, "gsm_train_15441": 0.6338215470314026, "gsm_rft_12365": 0.633874773979187, "gsm_train_12172": 0.6340517997741699, "gsm_rft_411": 0.6340517997741699, "gsm_rft_9523": 0.6341162919998169, "camel_41922": 0.6341196894645691, "gsm_rft_23745": 0.6342359781265259, "gsm_rft_12332": 0.6342774033546448, "camel_9328": 0.6345120668411255, "camel_8236": 0.6345244646072388, "gsm_rft_34987": 0.6347158551216125, "gsm_rft_4671": 0.634922444820404, "gsm_rft_1706": 0.6349956393241882, "TheoremQA_maxku/cv-imageprocessing9-digital-image.json": 0.6353528499603271, "camel_25266": 0.635445237159729, "camel_41197": 0.6354759931564331, "gsm_rft_7297": 0.6354954838752747, "camel_41104": 0.6355068683624268, "camel_9198": 0.6355717182159424, "gsm_rft_18287": 0.6356915235519409, "camel_41090": 0.6359379291534424, "camel_41981": 0.6359559893608093, "camel_39930": 0.6360170841217041, "gsm_rft_13965": 0.6360837817192078, "gsm_train_30685": 0.6360837817192078, "gsm_rft_3717": 0.6361445784568787, "gsm_train_144": 0.6361445784568787, "camel_41813": 0.6362804770469666, "gsm_rft_23628": 0.6363445520401001, "camel_9124": 0.6363779306411743, "gsm_rft_9844": 0.6364675760269165, "camel_36593": 0.6365211009979248, "camel_41077": 0.6369684338569641, "aqua_rat_22015": 0.6372750997543335, "TheoremQA_xinyi/fano_inequality.json": 0.6372901201248169, "camel_40948": 0.6373041272163391, "TheoremQA_xinyi/kraft_inequality.json": 0.6376339197158813, "camel_39395": 0.6378768086433411, "aqua_rat_76117": 0.6384879946708679, "camel_21911": 0.6385658383369446, "camel_41329": 0.6386781930923462, "camel_37980": 0.6390448808670044, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.6391257643699646, "TheoremQA_maxku/signalprocessing5-nyquist.json": 0.6392830610275269, "gsm_rft_18146": 0.6393254399299622, "camel_41923": 0.6398153901100159, "aqua_rat_84478": 0.6400440335273743, "camel_41751": 0.6401951313018799, "camel_41988": 0.6402976512908936, "camel_9173": 0.6408000588417053, "camel_41413": 0.640932023525238, "camel_37961": 0.6410694718360901, "aqua_rat_55461": 0.64115971326828, "camel_45778": 0.6414269208908081, "camel_17545": 0.641537606716156, "aqua_rat_14739": 0.6416317820549011, "aqua_rat_53724": 0.6417093873023987, "aqua_rat_24133": 0.6417552828788757, "camel_36502": 0.6418956518173218, "camel_41940": 0.6419992446899414, "aqua_rat_50137": 0.6421307325363159, "gsm_rft_8462": 0.6426500678062439, "gsm_train_21008": 0.6426500678062439, "gsm_rft_15239": 0.6428484320640564, "camel_26547": 0.6429396271705627, "camel_40967": 0.6431608200073242, "gsm_rft_2091": 0.6431837677955627, "camel_21909": 0.6433924436569214, "gsm_train_33244": 0.643396258354187, "camel_44424": 0.6435487270355225, "gsm_rft_32143": 0.6436181664466858, "gsm_rft_33191": 0.6439880132675171, "camel_38565": 0.6440283060073853, "gsm_train_13705": 0.6447073221206665, "gsm_rft_5276": 0.6447073221206665, "aqua_rat_25646": 0.6447525024414062, "camel_30223": 0.6447724103927612, "camel_37713": 0.6450622081756592, "aqua_rat_85903": 0.6453343629837036, "camel_41991": 0.6458090543746948, "camel_38567": 0.6464048624038696, "camel_41986": 0.6486515402793884, "gsm_train_25080": 0.6487505435943604, "gsm_rft_14419": 0.648823618888855, "camel_41098": 0.6495493054389954, "gsm_rft_19302": 0.6505434513092041, "gsm_rft_4144": 0.6508494019508362, "gsm_rft_15756": 0.6508494019508362, "aqua_rat_52087": 0.6515203714370728, "aqua_rat_27910": 0.6525465250015259, "aqua_rat_87402": 0.6526637077331543, "aqua_rat_36286": 0.6529353857040405, "gsm_rft_16361": 0.6532473564147949, "camel_30474": 0.6549059748649597, "gsm_rft_11985": 0.6549611687660217, "aqua_rat_2322": 0.6552383303642273, "aqua_rat_66093": 0.6554139852523804, "gsm_rft_25368": 0.6555723547935486, "camel_45836": 0.6559051275253296, "gsm_rft_229": 0.6561383605003357, "gsm_train_4199": 0.6561383605003357, "gsm_rft_9272": 0.6561383605003357, "gsm_train_31599": 0.6566465497016907, "gsm_rft_6860": 0.6568523049354553, "aqua_rat_38416": 0.6569026112556458, "gsm_rft_12713": 0.6570577025413513, "camel_36493": 0.6572406888008118, "aqua_rat_72089": 0.657296895980835, "aqua_rat_73185": 0.657582700252533, "aqua_rat_78286": 0.6578851342201233, "aqua_rat_8926": 0.6584766507148743, "camel_38787": 0.6587539315223694, "gsm_rft_14307": 0.6594011783599854, "camel_40840": 0.6595066785812378, "aqua_rat_10496": 0.6603661775588989, "aqua_rat_9712": 0.660963773727417, "camel_39060": 0.6615115404129028, "camel_44732": 0.6620833277702332, "aqua_rat_53867": 0.6627428531646729, "aqua_rat_60195": 0.6628539562225342, "TheoremQA_xinyi/shannon_lower_bound.json": 0.6647377014160156, "TheoremQA_maxku/ipnetwork10-datatransmission.json": 0.6659219264984131, "camel_39482": 0.6660563349723816, "camel_45819": 0.6754209399223328, "TheoremQA_maxku/signalprocessing18-noisebark.json": 0.6768198609352112, "camel_45809": 0.6780703663825989, "camel_44741": 0.6914740800857544, "camel_44798": 0.7069311141967773}, "TheoremQA_wenhuchen/jensen1.json": {"camel_4456": 0.732810914516449, "aqua_rat_49835": 0.73282390832901, "camel_4554": 0.7328249216079712, "aqua_rat_63599": 0.732994794845581, "camel_4692": 0.7330287098884583, "aqua_rat_22224": 0.7331233024597168, "camel_4452": 0.7331555485725403, "camel_4863": 0.7331741452217102, "gsm_rft_26751": 0.7332208752632141, "camel_5534": 0.7333123087882996, "camel_5555": 0.7333168983459473, "camel_4427": 0.733427882194519, "camel_5015": 0.7334833741188049, "camel_5547": 0.7335049510002136, "camel_4640": 0.733526885509491, "camel_5861": 0.7336254715919495, "camel_5007": 0.7337548732757568, "camel_3995": 0.7337624430656433, "camel_19734": 0.7337816953659058, "camel_4557": 0.7338101863861084, "camel_5565": 0.7340567708015442, "camel_3938": 0.7343844771385193, "camel_4678": 0.7346410155296326, "camel_4406": 0.7346509695053101, "camel_4546": 0.7347005605697632, "camel_4654": 0.7348675727844238, "camel_4643": 0.7349555492401123, "camel_5034": 0.7351323962211609, "camel_5554": 0.7352202534675598, "camel_5531": 0.7353997230529785, "camel_4501": 0.7355532646179199, "gsm_rft_17678": 0.7356899976730347, "camel_2812": 0.7357161641120911, "aqua_rat_56655": 0.7359296083450317, "camel_4489": 0.736107587814331, "camel_4507": 0.7361796498298645, "camel_4702": 0.7362107038497925, "camel_4029": 0.7362208366394043, "camel_19705": 0.7363357543945312, "camel_4754": 0.7365325093269348, "camel_4538": 0.7366001605987549, "camel_3969": 0.7367119193077087, "camel_3954": 0.7367424964904785, "camel_5569": 0.7367722988128662, "gsm_train_2408": 0.7368056178092957, "camel_4523": 0.7368267774581909, "camel_4822": 0.7371360063552856, "camel_3976": 0.7372600436210632, "gsm_rft_19016": 0.7374274134635925, "camel_4674": 0.7374524474143982, "camel_4518": 0.7374732494354248, "camel_4438": 0.7375001907348633, "camel_4145": 0.7375186681747437, "camel_4777": 0.7376475930213928, "camel_4812": 0.73799067735672, "camel_4522": 0.7379944324493408, "camel_5899": 0.7381046414375305, "camel_4718": 0.7381206750869751, "camel_4511": 0.7383356690406799, "camel_4697": 0.7384448647499084, "camel_5540": 0.738519549369812, "camel_4541": 0.7386718392372131, "camel_5018": 0.7386854887008667, "camel_3996": 0.7389154434204102, "camel_5033": 0.738949716091156, "camel_4451": 0.7390768527984619, "camel_4689": 0.7391337752342224, "camel_4517": 0.7391501665115356, "camel_4536": 0.7391610741615295, "camel_4660": 0.7393146753311157, "camel_5891": 0.7395328283309937, "camel_5017": 0.7396296858787537, "camel_4966": 0.739795446395874, "camel_4514": 0.739827573299408, "camel_5552": 0.7399505376815796, "camel_4650": 0.7400932312011719, "camel_4495": 0.740195095539093, "camel_4816": 0.7402067184448242, "camel_7693": 0.7403278946876526, "camel_4714": 0.7403886318206787, "camel_4698": 0.7404821515083313, "camel_4710": 0.7404925227165222, "camel_4843": 0.7406437397003174, "camel_4454": 0.740705132484436, "camel_4539": 0.7407128214836121, "camel_4515": 0.740860641002655, "camel_4547": 0.7409396767616272, "camel_4530": 0.7410561442375183, "camel_3979": 0.7411378026008606, "camel_4658": 0.7411980628967285, "camel_5567": 0.7412331104278564, "camel_4666": 0.7412663698196411, "camel_4537": 0.7415761947631836, "camel_3992": 0.7416213154792786, "camel_4699": 0.741698682308197, "camel_3941": 0.7418914437294006, "camel_4499": 0.7419375777244568, "camel_4505": 0.7419407963752747, "camel_4703": 0.7421231269836426, "camel_4677": 0.7421509027481079, "TheoremQA_tonyxia/semiconductor5.json": 0.7421851754188538, "camel_4520": 0.7423383593559265, "camel_4510": 0.7429825067520142, "camel_4657": 0.743109941482544, "camel_4491": 0.7433409094810486, "camel_4645": 0.7434992790222168, "camel_3999": 0.7436012625694275, "math_train_prealgebra_781": 0.7436602115631104, "camel_4559": 0.7437741160392761, "camel_4496": 0.7438201904296875, "camel_4811": 0.7439982295036316, "camel_4053": 0.7440583109855652, "camel_4331": 0.7442326545715332, "camel_4487": 0.7443571090698242, "camel_4540": 0.7447003722190857, "camel_4516": 0.7447088360786438, "camel_39131": 0.7447110414505005, "camel_4479": 0.7448136210441589, "camel_4519": 0.7448977828025818, "camel_4709": 0.7449450492858887, "camel_4685": 0.7453337907791138, "camel_4445": 0.745338499546051, "camel_4446": 0.745431125164032, "camel_3926": 0.7454832196235657, "camel_4532": 0.7454833984375, "camel_3987": 0.7454849481582642, "camel_4544": 0.7455200552940369, "camel_3947": 0.7455868721008301, "camel_4663": 0.7458296418190002, "camel_5594": 0.7459587454795837, "camel_4466": 0.7460206747055054, "camel_4833": 0.7460501194000244, "camel_3943": 0.7461037635803223, "camel_5648": 0.7461181282997131, "camel_3953": 0.7461183667182922, "camel_4713": 0.7462918162345886, "camel_4443": 0.7465263605117798, "camel_4481": 0.7467508912086487, "camel_4490": 0.7469646334648132, "camel_4528": 0.7471217513084412, "camel_4853": 0.747306227684021, "camel_5679": 0.7475277185440063, "camel_4672": 0.7476053237915039, "camel_5538": 0.7476556897163391, "camel_4430": 0.7476940155029297, "camel_4954": 0.7478450536727905, "camel_4556": 0.7479811310768127, "camel_4935": 0.7480913400650024, "camel_4429": 0.7481122612953186, "camel_4486": 0.7482830882072449, "camel_4855": 0.7485593557357788, "camel_4716": 0.7485716938972473, "camel_5580": 0.7485929727554321, "camel_3986": 0.7487198710441589, "camel_4437": 0.7490026950836182, "camel_4543": 0.7496979832649231, "camel_4405": 0.7497344017028809, "camel_5287": 0.749885082244873, "camel_4494": 0.7498860955238342, "camel_4488": 0.7500897645950317, "camel_3962": 0.7501315474510193, "camel_4555": 0.7501530647277832, "camel_4508": 0.7501958608627319, "camel_4679": 0.7502353191375732, "camel_4970": 0.7506015300750732, "camel_2876": 0.750686526298523, "camel_4648": 0.7507144212722778, "camel_4683": 0.7509483098983765, "camel_4509": 0.7509668469429016, "camel_4482": 0.751105010509491, "camel_4521": 0.7517168521881104, "camel_3932": 0.7518940567970276, "camel_5520": 0.7525069713592529, "camel_4988": 0.7530472874641418, "camel_5893": 0.7531899213790894, "camel_4910": 0.7533693909645081, "camel_4839": 0.7539311051368713, "camel_4506": 0.7539644241333008, "camel_4483": 0.7542277574539185, "aqua_rat_27834": 0.7544820308685303, "camel_3920": 0.7545623183250427, "camel_5030": 0.7548158764839172, "camel_4534": 0.75502610206604, "camel_4512": 0.757038950920105, "camel_4844": 0.7576730847358704, "camel_6239": 0.7581216096878052, "camel_3983": 0.7582530975341797, "camel_5522": 0.7583845257759094, "camel_4715": 0.759333610534668, "camel_4806": 0.7603525519371033, "camel_4524": 0.7604514956474304, "camel_4459": 0.7607554793357849, "camel_3937": 0.7607568502426147, "camel_4669": 0.7608082294464111, "camel_4464": 0.7620391845703125, "camel_4551": 0.7643349170684814, "camel_4407": 0.7660166025161743, "camel_4978": 0.7714731693267822, "camel_5637": 0.7753159999847412, "camel_4686": 0.7822228074073792}, "TheoremQA_maxku/signalprocessing14-Ztransform.json": {"camel_29878": 0.7003593444824219, "camel_28145": 0.7004057168960571, "camel_28461": 0.7007089853286743, "camel_28515": 0.7007171511650085, "camel_28465": 0.700873851776123, "camel_29978": 0.7011225819587708, "camel_28517": 0.7011826038360596, "camel_29245": 0.701208233833313, "camel_30423": 0.7012565732002258, "camel_28740": 0.7013794779777527, "camel_28545": 0.7014158368110657, "camel_29691": 0.7015260457992554, "camel_29817": 0.7015976905822754, "camel_28324": 0.7016147375106812, "camel_28676": 0.7017776370048523, "camel_29935": 0.7019810080528259, "camel_29222": 0.7020295262336731, "camel_29768": 0.7020508050918579, "camel_28793": 0.7020699977874756, "camel_28857": 0.7021080851554871, "camel_28170": 0.7021418213844299, "camel_29371": 0.7021461129188538, "camel_29204": 0.7021583318710327, "camel_28718": 0.7023741006851196, "camel_29276": 0.7024068236351013, "camel_28439": 0.7024641036987305, "camel_29088": 0.7025144696235657, "camel_28460": 0.7025341987609863, "camel_29205": 0.7025977969169617, "camel_29715": 0.7026510238647461, "camel_28156": 0.7028350830078125, "camel_29141": 0.7028875350952148, "camel_29867": 0.7029896378517151, "camel_29340": 0.7030247449874878, "camel_29818": 0.7030704021453857, "camel_28131": 0.7031596302986145, "camel_28433": 0.7031776905059814, "camel_28708": 0.7031930088996887, "camel_29097": 0.7032380104064941, "camel_29636": 0.7034990191459656, "camel_28397": 0.7035543322563171, "camel_29082": 0.7042269110679626, "camel_29224": 0.7042347192764282, "camel_28733": 0.7043547630310059, "camel_29987": 0.7046569585800171, "camel_29177": 0.704674243927002, "camel_28453": 0.7047899961471558, "camel_29060": 0.7049500346183777, "camel_28709": 0.7050538063049316, "camel_29925": 0.7051442265510559, "camel_29716": 0.7051637172698975, "camel_28321": 0.7053419947624207, "camel_29042": 0.7054128646850586, "camel_29975": 0.7054268717765808, "camel_28386": 0.7054413557052612, "camel_28230": 0.7058688998222351, "camel_28088": 0.7062391638755798, "camel_30474": 0.7062684893608093, "camel_28492": 0.7062909007072449, "camel_29023": 0.7063872218132019, "camel_29515": 0.7067434191703796, "camel_28237": 0.7069337368011475, "camel_28978": 0.7069553732872009, "camel_28456": 0.7070367336273193, "camel_29234": 0.7071221470832825, "camel_29700": 0.7072084546089172, "camel_29682": 0.7073961496353149, "camel_28776": 0.7075906991958618, "camel_28329": 0.7076655030250549, "camel_29780": 0.7079881429672241, "camel_29999": 0.7083519101142883, "camel_29984": 0.7085076570510864, "camel_29688": 0.7085085511207581, "camel_29216": 0.708764374256134, "camel_28577": 0.7087692022323608, "camel_29374": 0.7089778184890747, "camel_29122": 0.7091408967971802, "camel_28434": 0.7091742753982544, "camel_28883": 0.7092580199241638, "camel_29888": 0.7093160152435303, "camel_29322": 0.7093378901481628, "camel_28787": 0.7093696594238281, "camel_28354": 0.7096158862113953, "camel_28819": 0.7096269726753235, "camel_28384": 0.709743857383728, "camel_29787": 0.7098192572593689, "camel_28995": 0.7101337313652039, "camel_29755": 0.7101788520812988, "camel_28154": 0.7102175354957581, "camel_29257": 0.7104316353797913, "camel_29438": 0.7106199264526367, "camel_28234": 0.7106805443763733, "camel_29705": 0.7108669281005859, "camel_29612": 0.7110931873321533, "camel_28218": 0.7117927670478821, "camel_29790": 0.711798369884491, "camel_28999": 0.7119277715682983, "camel_29739": 0.711955189704895, "camel_28683": 0.712162435054779, "camel_28789": 0.7122251987457275, "camel_17403": 0.7124733328819275, "camel_29235": 0.7125802636146545, "camel_28835": 0.7126523852348328, "camel_28731": 0.7126917839050293, "camel_28113": 0.7127248644828796, "camel_29220": 0.7127281427383423, "camel_29027": 0.7127575874328613, "camel_29388": 0.7127735018730164, "camel_28468": 0.7128517627716064, "camel_29277": 0.7130773067474365, "camel_29711": 0.7130975723266602, "camel_28379": 0.713167130947113, "camel_28120": 0.7133308053016663, "camel_29693": 0.7134329676628113, "camel_29697": 0.7134593725204468, "camel_29416": 0.7136447429656982, "camel_29756": 0.7137405276298523, "camel_29695": 0.713789701461792, "camel_29178": 0.7139359712600708, "camel_28791": 0.714130163192749, "camel_28178": 0.7145243287086487, "camel_29435": 0.7148609757423401, "camel_29721": 0.7148635387420654, "camel_28528": 0.7148882150650024, "camel_29018": 0.7149171829223633, "camel_29698": 0.7149909734725952, "camel_29741": 0.7154908776283264, "camel_29034": 0.7157240509986877, "camel_29080": 0.7157557010650635, "camel_29026": 0.7159404158592224, "camel_29730": 0.7159721851348877, "camel_28357": 0.7161591649055481, "camel_29329": 0.7165452837944031, "camel_29969": 0.7170074582099915, "camel_28392": 0.7174019813537598, "camel_29407": 0.717411458492279, "camel_29116": 0.7175168395042419, "camel_28163": 0.7175338268280029, "camel_28435": 0.7180814743041992, "camel_29964": 0.7181679606437683, "camel_28187": 0.7183775901794434, "camel_29278": 0.718426525592804, "camel_29971": 0.7187179327011108, "camel_28404": 0.7188551425933838, "camel_29759": 0.7191064357757568, "camel_28134": 0.7191765904426575, "camel_28119": 0.7192839980125427, "camel_28760": 0.7194520831108093, "camel_29228": 0.7201451659202576, "camel_29328": 0.720173180103302, "camel_28138": 0.7205374240875244, "camel_28487": 0.7205390334129333, "camel_29745": 0.7208082675933838, "camel_29722": 0.7211625576019287, "camel_28149": 0.7212126851081848, "camel_28385": 0.7213074564933777, "camel_28797": 0.7221077084541321, "camel_29373": 0.7226155400276184, "camel_29251": 0.7226945757865906, "camel_29148": 0.7229703068733215, "camel_29321": 0.7230732440948486, "camel_28101": 0.7232556343078613, "camel_28821": 0.7236457467079163, "camel_29346": 0.7237526774406433, "camel_28754": 0.7238011956214905, "camel_28502": 0.724242091178894, "camel_28462": 0.7244536876678467, "camel_28116": 0.7246707081794739, "camel_29271": 0.7248321771621704, "camel_28121": 0.7249031662940979, "camel_28361": 0.7255150675773621, "camel_28430": 0.7255755066871643, "camel_29301": 0.72563236951828, "camel_28195": 0.7259084582328796, "camel_28148": 0.7262231707572937, "camel_28520": 0.7263259887695312, "camel_28206": 0.7263308763504028, "camel_29255": 0.7268834114074707, "camel_29708": 0.7271409034729004, "camel_28227": 0.7274747490882874, "camel_29947": 0.7282117605209351, "camel_28395": 0.7282373309135437, "camel_28084": 0.7286125421524048, "camel_29227": 0.7297552227973938, "camel_29749": 0.7300662994384766, "camel_29684": 0.7319304943084717, "camel_29078": 0.7331497073173523, "camel_28407": 0.7344116568565369, "camel_29240": 0.7384774684906006, "camel_29279": 0.7386903762817383, "camel_29704": 0.7387688755989075, "camel_28099": 0.7387988567352295, "camel_29727": 0.7406187057495117, "TheoremQA_maxku/signalprocessing4-Ztransform.json": 0.7409189939498901, "camel_29752": 0.7453084588050842, "camel_29364": 0.7465533018112183, "camel_29734": 0.7486574649810791, "camel_29065": 0.751964271068573, "camel_29429": 0.7551978230476379, "camel_29719": 0.7646609544754028}, "TheoremQA_elainewan/math_calculus_11.json": {"camel_7205": 0, "camel_6100": 0, "camel_7252": 0, "camel_7259": 0, "camel_6174": 0, "camel_7204": 0, "camel_7211": 0, "camel_7214": 0, "camel_7219": 0, "camel_7223": 0, "camel_7235": 0, "camel_7277": 0, "camel_6088": 0, "camel_7263": 0, "camel_7268": 0, "TheoremQA_elainewan/math_calculus_11.json": 0, "camel_7276": 0, "camel_7212": 0, "camel_7226": 0, "camel_7236": 0, "camel_6386": 0, "camel_7231": 0, "camel_7256": 0, "camel_7229": 0, "camel_6151": 0, "camel_7242": 0, "aqua_rat_31463": 0.7027444243431091, "math_train_prealgebra_638": 0.7027506232261658, "aqua_rat_9148": 0.702836275100708, "aqua_rat_38823": 0.7030208706855774, "aqua_rat_86102": 0.7031565308570862, "camel_36477": 0.703201413154602, "camel_31984": 0.7032867074012756, "math_train_prealgebra_559": 0.7033353447914124, "aqua_rat_26412": 0.703562319278717, "aqua_rat_11295": 0.7036431431770325, "aqua_rat_83164": 0.7036540508270264, "aqua_rat_15397": 0.7036634087562561, "aqua_rat_57969": 0.7037206292152405, "aqua_rat_442": 0.7037465572357178, "aqua_rat_83037": 0.7037774324417114, "camel_39486": 0.7037962675094604, "aqua_rat_35084": 0.7038522362709045, "aqua_rat_73502": 0.7039534449577332, "aqua_rat_11429": 0.7040650248527527, "aqua_rat_65820": 0.7043870091438293, "aqua_rat_52770": 0.7044265270233154, "math_train_algebra_1672": 0.704463005065918, "aqua_rat_8947": 0.7045111060142517, "gsm_train_19122": 0.7045223116874695, "gsm_rft_27425": 0.7045223116874695, "aqua_rat_56551": 0.7046064734458923, "aqua_rat_4051": 0.7046884298324585, "aqua_rat_31751": 0.7048438787460327, "aqua_rat_5148": 0.7048846483230591, "aqua_rat_85207": 0.7049002051353455, "aqua_rat_7140": 0.7049341797828674, "aqua_rat_32037": 0.7050043344497681, "gsm_rft_5789": 0.7050052285194397, "aqua_rat_51397": 0.7050129175186157, "aqua_rat_7830": 0.7050913572311401, "camel_42677": 0.7052764892578125, "aqua_rat_84494": 0.705609917640686, "aqua_rat_59023": 0.7057119607925415, "aqua_rat_86386": 0.7058131694793701, "aqua_rat_41455": 0.705885648727417, "aqua_rat_59820": 0.7058896422386169, "aqua_rat_9735": 0.705900251865387, "aqua_rat_67522": 0.7059957981109619, "gsm_rft_24120": 0.7060052752494812, "aqua_rat_20777": 0.7060587406158447, "aqua_rat_45": 0.7061183452606201, "aqua_rat_14328": 0.7061712145805359, "aqua_rat_42376": 0.7062152624130249, "gsm_train_3948": 0.7062346339225769, "aqua_rat_70956": 0.7062464356422424, "aqua_rat_59846": 0.706470787525177, "aqua_rat_39776": 0.7065111994743347, "aqua_rat_74381": 0.706576406955719, "aqua_rat_11729": 0.7066949605941772, "aqua_rat_17120": 0.7067654728889465, "math_test_prealgebra_1578": 0.706950843334198, "aqua_rat_59630": 0.7070331573486328, "aqua_rat_29678": 0.7071729302406311, "aqua_rat_23484": 0.7072252035140991, "aqua_rat_77082": 0.707301914691925, "aqua_rat_4578": 0.7073237299919128, "aqua_rat_42383": 0.7074075937271118, "math_test_intermediate_algebra_1178": 0.707466185092926, "aqua_rat_48114": 0.707500159740448, "camel_31057": 0.7076981663703918, "aqua_rat_76643": 0.7078987956047058, "aqua_rat_850": 0.7081985473632812, "aqua_rat_37483": 0.7081995606422424, "aqua_rat_62985": 0.7082061767578125, "aqua_rat_40051": 0.70829176902771, "gsm_rft_6517": 0.7083646059036255, "aqua_rat_75264": 0.7085103988647461, "aqua_rat_69934": 0.7087082266807556, "aqua_rat_23177": 0.7088915109634399, "aqua_rat_68011": 0.7089016437530518, "camel_40761": 0.7090861201286316, "aqua_rat_39647": 0.7091745734214783, "aqua_rat_83930": 0.7092185020446777, "camel_18301": 0.7094386219978333, "aqua_rat_50180": 0.7095152735710144, "aqua_rat_15563": 0.7097432017326355, "aqua_rat_81222": 0.7099531888961792, "math_train_number_theory_7070": 0.7100232839584351, "aqua_rat_78838": 0.7104285359382629, "camel_30354": 0.7104933261871338, "aqua_rat_17824": 0.7106097340583801, "camel_42478": 0.7106630802154541, "aqua_rat_31551": 0.7106685638427734, "aqua_rat_63183": 0.7107645869255066, "aqua_rat_27858": 0.7112888693809509, "aqua_rat_57306": 0.7114889025688171, "aqua_rat_64372": 0.7116203308105469, "aqua_rat_268": 0.7120602130889893, "aqua_rat_36782": 0.7122318148612976, "aqua_rat_37668": 0.7123340964317322, "aqua_rat_56788": 0.7126163840293884, "aqua_rat_50530": 0.7126291990280151, "aqua_rat_56309": 0.7127048373222351, "camel_30374": 0.7131929993629456, "aqua_rat_83913": 0.7132710218429565, "aqua_rat_85202": 0.7132830619812012, "aqua_rat_42696": 0.7135623693466187, "aqua_rat_26481": 0.7135875225067139, "math_train_algebra_2630": 0.7136292457580566, "aqua_rat_50085": 0.7141251564025879, "aqua_rat_42745": 0.7141602635383606, "aqua_rat_73781": 0.7141645550727844, "aqua_rat_18977": 0.7142022848129272, "aqua_rat_63624": 0.7145125865936279, "aqua_rat_14574": 0.7146196365356445, "aqua_rat_84355": 0.7148113250732422, "aqua_rat_43130": 0.7153313159942627, "aqua_rat_88394": 0.715461254119873, "aqua_rat_8029": 0.7156544327735901, "aqua_rat_69903": 0.7161605358123779, "aqua_rat_80881": 0.7161731719970703, "math_test_prealgebra_1778": 0.7174218893051147, "aqua_rat_23682": 0.7176623940467834, "camel_37996": 0.7179886102676392, "aqua_rat_43508": 0.7182894945144653, "aqua_rat_63913": 0.7182999849319458, "aqua_rat_59289": 0.7186073064804077, "aqua_rat_27940": 0.7192097306251526, "gsm_rft_7714": 0.7197316288948059, "aqua_rat_82043": 0.7198008298873901, "gsm_rft_15666": 0.7201394438743591, "aqua_rat_45431": 0.7201725244522095, "aqua_rat_27515": 0.7202898859977722, "aqua_rat_52511": 0.7203361988067627, "gsm_train_228": 0.7203732132911682, "gsm_rft_7166": 0.7203732132911682, "aqua_rat_38558": 0.7204583883285522, "aqua_rat_48688": 0.7207427024841309, "aqua_rat_78243": 0.7209421396255493, "aqua_rat_45189": 0.7211665511131287, "aqua_rat_39626": 0.721792995929718, "aqua_rat_44120": 0.7224074602127075, "aqua_rat_10863": 0.7227792143821716, "aqua_rat_65996": 0.7233244180679321, "aqua_rat_75239": 0.7237640619277954, "aqua_rat_11117": 0.7240365147590637, "aqua_rat_5634": 0.7240468263626099, "aqua_rat_58677": 0.7240984439849854, "aqua_rat_73706": 0.7244488596916199, "aqua_rat_71294": 0.7251526713371277, "aqua_rat_17535": 0.725261390209198, "camel_31084": 0.7269952893257141, "aqua_rat_12665": 0.7276244163513184, "aqua_rat_2131": 0.7278371453285217, "aqua_rat_4332": 0.727912425994873, "aqua_rat_14942": 0.7285626530647278, "aqua_rat_55870": 0.7287057042121887, "aqua_rat_58691": 0.7287980318069458, "aqua_rat_28976": 0.7291523218154907, "aqua_rat_3097": 0.7297455668449402, "aqua_rat_20824": 0.7300801873207092, "aqua_rat_46370": 0.7301862239837646, "aqua_rat_33076": 0.7302526831626892, "aqua_rat_47352": 0.7303605079650879, "aqua_rat_31829": 0.7304385304450989, "aqua_rat_83081": 0.7308478951454163, "aqua_rat_17555": 0.7310106158256531, "aqua_rat_3061": 0.7317177057266235, "aqua_rat_36474": 0.7322399616241455, "aqua_rat_72299": 0.7324857115745544, "aqua_rat_54718": 0.7326135039329529, "aqua_rat_31598": 0.7335458397865295, "camel_18096": 0.7365135550498962, "aqua_rat_20804": 0.7369585037231445, "aqua_rat_49646": 0.7404360175132751, "camel_31056": 0.7412769198417664, "aqua_rat_27506": 0.7417473196983337, "aqua_rat_12508": 0.7485703229904175, "TheoremQA_elainewan/math_calculus_2_10.json": 0.7579697966575623}, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": {"TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0, "camel_30727": 0.7245330810546875, "aqua_rat_80984": 0.724593997001648, "aqua_rat_65765": 0.7246240973472595, "camel_19716": 0.724635899066925, "aqua_rat_26602": 0.7247511148452759, "aqua_rat_1141": 0.724757969379425, "camel_7714": 0.7247644066810608, "aqua_rat_36743": 0.7248383164405823, "math_test_algebra_1591": 0.724880039691925, "aqua_rat_9175": 0.7249346375465393, "aqua_rat_67812": 0.7249857783317566, "aqua_rat_50832": 0.7250818610191345, "aqua_rat_39099": 0.7250827550888062, "aqua_rat_32416": 0.725139319896698, "aqua_rat_882": 0.725235104560852, "aqua_rat_24200": 0.7252398729324341, "math_test_algebra_1929": 0.7254077196121216, "camel_9790": 0.7254367470741272, "aqua_rat_18285": 0.7255108952522278, "aqua_rat_11272": 0.7255117893218994, "camel_9544": 0.7255517840385437, "camel_49180": 0.7256157398223877, "math_train_counting_and_probability_971": 0.7256825566291809, "aqua_rat_25895": 0.7257609963417053, "camel_28384": 0.7258097529411316, "aqua_rat_80662": 0.7260119915008545, "aqua_rat_37702": 0.7260146737098694, "camel_19686": 0.7260294556617737, "aqua_rat_59216": 0.7260620594024658, "aqua_rat_6426": 0.7261031866073608, "camel_9738": 0.7261114716529846, "camel_30260": 0.7261351943016052, "math_train_algebra_848": 0.7262585759162903, "camel_46131": 0.7262847423553467, "aqua_rat_31000": 0.7264339327812195, "aqua_rat_43966": 0.726448655128479, "aqua_rat_68580": 0.7265052199363708, "aqua_rat_44665": 0.7265162467956543, "camel_15766": 0.7266217470169067, "aqua_rat_71415": 0.7267473340034485, "aqua_rat_31940": 0.7267633080482483, "aqua_rat_10381": 0.7269163131713867, "camel_8963": 0.7269346714019775, "aqua_rat_44300": 0.7269929051399231, "camel_8719": 0.7270603775978088, "aqua_rat_36322": 0.7272299528121948, "aqua_rat_18244": 0.7272904515266418, "aqua_rat_22624": 0.7273505330085754, "aqua_rat_52888": 0.7273569107055664, "camel_30793": 0.7274019718170166, "aqua_rat_18222": 0.7274473905563354, "aqua_rat_27888": 0.7275403738021851, "camel_46110": 0.7276590466499329, "aqua_rat_55086": 0.7280228137969971, "camel_19721": 0.7281231880187988, "aqua_rat_45553": 0.7282109260559082, "aqua_rat_68196": 0.7282684445381165, "aqua_rat_76786": 0.7283177971839905, "aqua_rat_69871": 0.7283545136451721, "aqua_rat_37864": 0.7285125851631165, "aqua_rat_54821": 0.7285609841346741, "camel_47731": 0.7289853096008301, "camel_30304": 0.7291336059570312, "aqua_rat_71822": 0.7291527986526489, "aqua_rat_83284": 0.7292253971099854, "aqua_rat_3491": 0.7292668223381042, "aqua_rat_67291": 0.7294011116027832, "camel_38481": 0.7294039130210876, "aqua_rat_84154": 0.7294361591339111, "camel_39001": 0.7296087145805359, "aqua_rat_4946": 0.7298762202262878, "aqua_rat_4038": 0.7305340766906738, "camel_18380": 0.7307484745979309, "aqua_rat_85940": 0.7308784127235413, "aqua_rat_29275": 0.7309083938598633, "aqua_rat_60553": 0.7309343218803406, "math_train_geometry_671": 0.730995774269104, "aqua_rat_39514": 0.7314226031303406, "aqua_rat_41461": 0.7315312027931213, "camel_19685": 0.7315945029258728, "aqua_rat_83884": 0.7317640781402588, "camel_9760": 0.7318968772888184, "aqua_rat_76393": 0.7319276928901672, "camel_46082": 0.7320185899734497, "aqua_rat_42375": 0.7321016192436218, "aqua_rat_26893": 0.73216712474823, "math_train_algebra_1808": 0.7322036027908325, "camel_9553": 0.7324144244194031, "aqua_rat_54156": 0.7324805855751038, "aqua_rat_21741": 0.7325542569160461, "camel_46145": 0.7326200008392334, "aqua_rat_29637": 0.7326309680938721, "aqua_rat_8811": 0.7327966094017029, "camel_9207": 0.7329146265983582, "aqua_rat_30593": 0.7329310774803162, "camel_28361": 0.7330307364463806, "camel_9133": 0.7330310940742493, "aqua_rat_10716": 0.7331632375717163, "camel_30293": 0.7333594560623169, "aqua_rat_74055": 0.733818769454956, "aqua_rat_53872": 0.7339938879013062, "aqua_rat_10426": 0.7342046499252319, "aqua_rat_84213": 0.7344841361045837, "camel_49918": 0.7345776557922363, "aqua_rat_13841": 0.7346950173377991, "camel_19726": 0.7347080111503601, "aqua_rat_17181": 0.734890341758728, "aqua_rat_62326": 0.7352936267852783, "aqua_rat_12225": 0.735420286655426, "aqua_rat_60680": 0.735512912273407, "aqua_rat_40988": 0.7355562448501587, "aqua_rat_61448": 0.7356002926826477, "aqua_rat_57399": 0.7356762290000916, "aqua_rat_61258": 0.7356811165809631, "aqua_rat_6077": 0.7357851266860962, "aqua_rat_43043": 0.736003041267395, "camel_9596": 0.7361701130867004, "camel_49277": 0.7366884350776672, "math_train_intermediate_algebra_1483": 0.7367303967475891, "camel_15770": 0.7368019223213196, "math_test_algebra_26": 0.7369303703308105, "aqua_rat_76912": 0.7369402647018433, "aqua_rat_85395": 0.7375633716583252, "aqua_rat_59992": 0.7375983595848083, "aqua_rat_17383": 0.7376677989959717, "camel_15836": 0.7381190061569214, "camel_9274": 0.7382508516311646, "aqua_rat_72870": 0.7384517788887024, "aqua_rat_73639": 0.7385156154632568, "aqua_rat_12090": 0.7389668226242065, "aqua_rat_47280": 0.7390034794807434, "aqua_rat_63524": 0.7391762733459473, "aqua_rat_417": 0.7396479249000549, "aqua_rat_9099": 0.7397729754447937, "aqua_rat_1436": 0.7402029633522034, "aqua_rat_34002": 0.7402341365814209, "camel_19718": 0.7404947876930237, "aqua_rat_39251": 0.7405411601066589, "aqua_rat_64423": 0.7406294345855713, "aqua_rat_39207": 0.7409090399742126, "camel_15832": 0.7413310408592224, "camel_9134": 0.7418084144592285, "aqua_rat_71184": 0.7420867681503296, "camel_19727": 0.7431054711341858, "aqua_rat_2076": 0.7431953549385071, "aqua_rat_60518": 0.7447498440742493, "aqua_rat_72151": 0.7461837530136108, "aqua_rat_26206": 0.7466599345207214, "aqua_rat_79209": 0.7467385530471802, "aqua_rat_24388": 0.7468826770782471, "aqua_rat_53476": 0.7469304203987122, "aqua_rat_22633": 0.7474706768989563, "camel_15821": 0.7490668296813965, "aqua_rat_24416": 0.749517560005188, "aqua_rat_64490": 0.7509489059448242, "aqua_rat_20454": 0.7511839270591736, "aqua_rat_79728": 0.7516489624977112, "camel_28935": 0.7520359754562378, "aqua_rat_16636": 0.7527197003364563, "aqua_rat_13013": 0.7527595162391663, "aqua_rat_20141": 0.7529125213623047, "aqua_rat_67725": 0.7530505657196045, "aqua_rat_19449": 0.7536907196044922, "aqua_rat_3790": 0.7544389963150024, "aqua_rat_31052": 0.7559611201286316, "aqua_rat_76216": 0.7561407685279846, "aqua_rat_49279": 0.7563852071762085, "aqua_rat_86106": 0.7580851316452026, "aqua_rat_32592": 0.7586410641670227, "aqua_rat_10411": 0.7589846253395081, "aqua_rat_38356": 0.7596552968025208, "math_train_algebra_2169": 0.7603327035903931, "aqua_rat_85048": 0.7607475519180298, "aqua_rat_77838": 0.7614429593086243, "aqua_rat_88630": 0.7638798356056213, "aqua_rat_85328": 0.7641108632087708, "aqua_rat_9335": 0.764254093170166, "aqua_rat_36627": 0.7653833031654358, "aqua_rat_36704": 0.7654114961624146, "aqua_rat_6823": 0.7666318416595459, "aqua_rat_82465": 0.7667236924171448, "aqua_rat_83185": 0.7668366432189941, "aqua_rat_38400": 0.766950249671936, "aqua_rat_43896": 0.7673115134239197, "aqua_rat_71780": 0.7673255801200867, "aqua_rat_24670": 0.7673434019088745, "aqua_rat_888": 0.7674468755722046, "aqua_rat_23501": 0.767481803894043, "aqua_rat_5254": 0.767741858959198, "aqua_rat_9508": 0.767961859703064, "aqua_rat_14389": 0.7683836817741394, "aqua_rat_50696": 0.7685297131538391, "aqua_rat_10932": 0.7688718438148499, "aqua_rat_47046": 0.7701237201690674, "aqua_rat_26062": 0.7713032960891724, "aqua_rat_66974": 0.7714182138442993, "aqua_rat_7497": 0.7717947363853455, "aqua_rat_25540": 0.7729774713516235, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.8376610279083252}, "TheoremQA_elainewan/math_abstact_algebra_7.json": {"math_train_prealgebra_1264": 0, "math_train_prealgebra_1285": 0, "math_test_prealgebra_1608": 0, "aqua_rat_77867": 0.7193224430084229, "aqua_rat_51813": 0.7194710373878479, "aqua_rat_80615": 0.7196216583251953, "aqua_rat_60555": 0.7198507785797119, "math_train_counting_and_probability_500": 0.7199850082397461, "aqua_rat_22388": 0.7200515270233154, "aqua_rat_12956": 0.7201923131942749, "aqua_rat_84088": 0.7202152013778687, "aqua_rat_71410": 0.7204062342643738, "aqua_rat_1524": 0.7204077243804932, "aqua_rat_85320": 0.7204492688179016, "aqua_rat_36803": 0.7206225395202637, "aqua_rat_56247": 0.7206884622573853, "aqua_rat_67694": 0.7208016514778137, "aqua_rat_32162": 0.7208828926086426, "aqua_rat_78110": 0.7210127115249634, "camel_21050": 0.7210978269577026, "aqua_rat_37642": 0.7212139368057251, "aqua_rat_56536": 0.7212655544281006, "aqua_rat_74719": 0.7213248014450073, "aqua_rat_76913": 0.7214075922966003, "aqua_rat_61637": 0.72148597240448, "aqua_rat_64485": 0.7215129137039185, "math_train_counting_and_probability_149": 0.7215306758880615, "TheoremQA_jianyu_xu/Stirling_number_second_kind_5.json": 0.7215659022331238, "aqua_rat_60936": 0.7222210168838501, "aqua_rat_7868": 0.7223749756813049, "aqua_rat_38594": 0.722411572933197, "camel_20308": 0.7225634455680847, "aqua_rat_83158": 0.7226271033287048, "camel_21028": 0.7226788401603699, "aqua_rat_6365": 0.7226823568344116, "math_test_counting_and_probability_461": 0.722881555557251, "aqua_rat_81275": 0.7230403423309326, "aqua_rat_11661": 0.7231139540672302, "aqua_rat_15706": 0.7231430411338806, "aqua_rat_81052": 0.7232553362846375, "aqua_rat_54461": 0.7234437465667725, "aqua_rat_74667": 0.7234985828399658, "aqua_rat_29514": 0.7238053679466248, "camel_20325": 0.7239534854888916, "aqua_rat_65447": 0.724364697933197, "aqua_rat_5585": 0.724365770816803, "aqua_rat_38433": 0.7245066165924072, "aqua_rat_79638": 0.7245278358459473, "aqua_rat_73144": 0.7245583534240723, "aqua_rat_22214": 0.7246080040931702, "aqua_rat_29306": 0.7246809005737305, "camel_20836": 0.7247465252876282, "aqua_rat_13836": 0.7248020172119141, "aqua_rat_86861": 0.7249091863632202, "aqua_rat_72210": 0.7249312996864319, "aqua_rat_14532": 0.7249680161476135, "aqua_rat_55250": 0.7251242995262146, "camel_23312": 0.7252147793769836, "aqua_rat_26642": 0.7254167199134827, "aqua_rat_30957": 0.7256829738616943, "aqua_rat_38586": 0.7257696986198425, "aqua_rat_66465": 0.7259504795074463, "math_test_counting_and_probability_485": 0.7263422012329102, "math_train_counting_and_probability_5092": 0.7263724207878113, "aqua_rat_3870": 0.7265092134475708, "aqua_rat_84877": 0.7265565991401672, "aqua_rat_72130": 0.7267025113105774, "aqua_rat_31162": 0.7267441749572754, "aqua_rat_41924": 0.7267597317695618, "aqua_rat_41884": 0.7267884016036987, "aqua_rat_34946": 0.7267978191375732, "aqua_rat_62903": 0.726807177066803, "aqua_rat_24829": 0.7268575429916382, "aqua_rat_77021": 0.7269297242164612, "camel_21596": 0.7272387742996216, "aqua_rat_71649": 0.727246105670929, "aqua_rat_34272": 0.7272489666938782, "aqua_rat_68946": 0.7273468375205994, "aqua_rat_63051": 0.7274174690246582, "aqua_rat_34469": 0.7274316549301147, "aqua_rat_88698": 0.7275080680847168, "aqua_rat_37897": 0.7275088429450989, "aqua_rat_50508": 0.7275149822235107, "aqua_rat_25933": 0.7278414368629456, "aqua_rat_14281": 0.7278414964675903, "aqua_rat_4294": 0.7279500365257263, "camel_20988": 0.728147029876709, "aqua_rat_5318": 0.7282004952430725, "aqua_rat_59702": 0.728221595287323, "aqua_rat_15112": 0.728256344795227, "aqua_rat_22444": 0.7282740473747253, "aqua_rat_71699": 0.7283713221549988, "aqua_rat_80429": 0.7284196019172668, "camel_23284": 0.7285448908805847, "camel_21040": 0.728614866733551, "aqua_rat_66240": 0.7286734580993652, "aqua_rat_32829": 0.7287940979003906, "camel_21026": 0.7289225459098816, "aqua_rat_63774": 0.7289415597915649, "aqua_rat_64566": 0.7290657758712769, "aqua_rat_62715": 0.7293041348457336, "aqua_rat_11651": 0.729396641254425, "aqua_rat_33238": 0.7295390367507935, "aqua_rat_13585": 0.7299224138259888, "camel_21042": 0.7300884127616882, "aqua_rat_23141": 0.7301085591316223, "aqua_rat_42815": 0.7303559184074402, "aqua_rat_23669": 0.7305933237075806, "camel_20980": 0.7308487892150879, "aqua_rat_55627": 0.7308861017227173, "math_train_counting_and_probability_5039": 0.7309958338737488, "aqua_rat_9727": 0.7314518094062805, "aqua_rat_68154": 0.7315864562988281, "aqua_rat_19807": 0.7316778898239136, "aqua_rat_20640": 0.7316922545433044, "aqua_rat_45153": 0.7318824529647827, "aqua_rat_36385": 0.7318934202194214, "aqua_rat_85713": 0.7319134473800659, "aqua_rat_84159": 0.7320218682289124, "aqua_rat_34607": 0.7322784066200256, "aqua_rat_54036": 0.7324862480163574, "aqua_rat_66146": 0.7324955463409424, "aqua_rat_11490": 0.7325013279914856, "aqua_rat_4554": 0.7326536178588867, "aqua_rat_32366": 0.7328792810440063, "aqua_rat_75859": 0.7328799962997437, "aqua_rat_29967": 0.7330538630485535, "aqua_rat_56498": 0.7330830693244934, "camel_20425": 0.7332134246826172, "aqua_rat_52067": 0.733275830745697, "aqua_rat_62396": 0.7333200573921204, "aqua_rat_11459": 0.7334520220756531, "camel_20244": 0.7335017919540405, "camel_20614": 0.7335655093193054, "camel_20804": 0.7335989475250244, "aqua_rat_76271": 0.7336401343345642, "camel_20599": 0.7345133423805237, "aqua_rat_79594": 0.7346395254135132, "aqua_rat_56544": 0.7348074316978455, "aqua_rat_73122": 0.7352126836776733, "camel_20853": 0.7353276014328003, "aqua_rat_59360": 0.7353564500808716, "aqua_rat_53882": 0.7356003522872925, "aqua_rat_81367": 0.7357727885246277, "aqua_rat_83489": 0.7360643148422241, "aqua_rat_74550": 0.7361428737640381, "math_train_counting_and_probability_5127": 0.7361823320388794, "camel_21120": 0.7361825108528137, "camel_21431": 0.7362598180770874, "aqua_rat_18803": 0.7372725605964661, "camel_20672": 0.7372891902923584, "aqua_rat_8402": 0.738107442855835, "aqua_rat_21265": 0.7381404638290405, "aqua_rat_89113": 0.7381458878517151, "aqua_rat_73365": 0.7384642362594604, "aqua_rat_32623": 0.7386983036994934, "aqua_rat_83905": 0.7387905716896057, "camel_21039": 0.7388965487480164, "aqua_rat_15820": 0.7394537925720215, "camel_20257": 0.7396562695503235, "aqua_rat_42625": 0.739686906337738, "aqua_rat_4191": 0.7401041984558105, "aqua_rat_70081": 0.7402238845825195, "aqua_rat_73402": 0.7402397990226746, "aqua_rat_78820": 0.7405162453651428, "aqua_rat_40108": 0.7406458854675293, "camel_20803": 0.7408487796783447, "aqua_rat_16877": 0.7410348653793335, "aqua_rat_25912": 0.7410393357276917, "camel_20462": 0.7411823868751526, "aqua_rat_80444": 0.7413121461868286, "aqua_rat_2480": 0.7420247197151184, "aqua_rat_7248": 0.74204421043396, "aqua_rat_61885": 0.7420637011528015, "camel_21015": 0.7420790195465088, "aqua_rat_65907": 0.7421602606773376, "aqua_rat_14684": 0.7430123090744019, "aqua_rat_29651": 0.743035614490509, "aqua_rat_18404": 0.743657648563385, "aqua_rat_41742": 0.7442654371261597, "camel_21798": 0.7444620728492737, "aqua_rat_65651": 0.7448811531066895, "camel_21390": 0.7461190223693848, "aqua_rat_21868": 0.7469747066497803, "aqua_rat_34678": 0.7470383644104004, "aqua_rat_36769": 0.7485107779502869, "camel_20255": 0.7486957907676697, "aqua_rat_5705": 0.7510406970977783, "aqua_rat_48109": 0.7521603107452393, "camel_20841": 0.7544807195663452, "camel_20564": 0.7555669546127319, "camel_20787": 0.7565016746520996, "camel_21034": 0.7569195628166199, "camel_20911": 0.7572683095932007, "TheoremQA_jianyu_xu/Multinomial_2.json": 0.7589153051376343, "aqua_rat_56019": 0.7629030346870422, "TheoremQA_jianyu_xu/Stirling_number_second_kind_6.json": 0.7640392184257507, "camel_20808": 0.7677006721496582, "camel_21001": 0.7699241638183594, "camel_21138": 0.7928210496902466}, "TheoremQA_maxku/signalprocessing2-DB.json": {"TheoremQA_maxku/signalprocessing2-DB.json": 0, "camel_37879": 0.6840718388557434, "aqua_rat_65183": 0.6841028332710266, "gsm_rft_15409": 0.6841270327568054, "gsm_rft_11389": 0.6841712594032288, "gsm_rft_4300": 0.6841816306114197, "gsm_train_23861": 0.6841816306114197, "aqua_rat_77996": 0.6842535734176636, "gsm_rft_12659": 0.6843035221099854, "gsm_rft_5944": 0.6843087673187256, "gsm_rft_19678": 0.6843265891075134, "gsm_rft_1396": 0.6843987703323364, "aqua_rat_54005": 0.6844094395637512, "aqua_rat_81927": 0.6844549179077148, "gsm_train_24865": 0.6845950484275818, "aqua_rat_35485": 0.6845986247062683, "gsm_rft_2378": 0.6846979856491089, "gsm_train_6694": 0.6846979856491089, "gsm_rft_2592": 0.6847789287567139, "gsm_rft_23684": 0.6848094463348389, "aqua_rat_36411": 0.6848198771476746, "gsm_rft_11101": 0.6849424242973328, "gsm_rft_2601": 0.6849424242973328, "gsm_rft_32377": 0.6849481463432312, "gsm_train_5301": 0.6849753856658936, "aqua_rat_57727": 0.6852277517318726, "gsm_rft_7714": 0.6854223012924194, "gsm_rft_31703": 0.6855441927909851, "gsm_train_3954": 0.6855441927909851, "gsm_rft_10319": 0.6858230233192444, "gsm_rft_27876": 0.6858380436897278, "gsm_rft_19359": 0.6859134435653687, "gsm_rft_5855": 0.6859134435653687, "gsm_train_727": 0.6859134435653687, "gsm_rft_20536": 0.6859516501426697, "gsm_train_21064": 0.6859516501426697, "gsm_rft_2687": 0.6860153079032898, "gsm_rft_33791": 0.6860153079032898, "gsm_rft_34111": 0.6860905289649963, "gsm_rft_986": 0.6861330270767212, "aqua_rat_77586": 0.686276912689209, "gsm_rft_22968": 0.6864200830459595, "gsm_train_21663": 0.686511754989624, "gsm_rft_2622": 0.686511754989624, "gsm_rft_30211": 0.686511754989624, "gsm_rft_16671": 0.6865763068199158, "gsm_rft_11776": 0.686618447303772, "camel_37936": 0.6866926550865173, "aqua_rat_60297": 0.6868705153465271, "aqua_rat_53207": 0.686952531337738, "aqua_rat_71372": 0.6870083808898926, "aqua_rat_73760": 0.6870245933532715, "aqua_rat_67295": 0.6870955228805542, "gsm_rft_15860": 0.6871459484100342, "gsm_rft_28669": 0.6871459484100342, "gsm_train_11193": 0.6871459484100342, "gsm_rft_32265": 0.6873018145561218, "gsm_train_29348": 0.6873018145561218, "aqua_rat_36957": 0.687596321105957, "gsm_train_5581": 0.6877187490463257, "gsm_rft_7166": 0.6877687573432922, "gsm_train_228": 0.6877687573432922, "gsm_rft_11288": 0.6877960562705994, "gsm_rft_15666": 0.6878786683082581, "gsm_rft_28838": 0.6879035830497742, "gsm_rft_26059": 0.687952995300293, "aqua_rat_47750": 0.6880906224250793, "gsm_rft_12505": 0.6881412863731384, "gsm_rft_14389": 0.6883231997489929, "aqua_rat_16469": 0.6885842680931091, "aqua_rat_85422": 0.6886528134346008, "aqua_rat_26183": 0.6887107491493225, "aqua_rat_41482": 0.6890832185745239, "aqua_rat_8539": 0.6890960335731506, "gsm_rft_33191": 0.6891002058982849, "gsm_rft_3972": 0.6891404390335083, "gsm_train_33244": 0.6893894672393799, "gsm_rft_9792": 0.6894598603248596, "aqua_rat_65009": 0.6894932985305786, "aqua_rat_57835": 0.6897802948951721, "aqua_rat_21504": 0.6898464560508728, "aqua_rat_24258": 0.6901776790618896, "gsm_rft_35312": 0.6902231574058533, "gsm_train_19337": 0.6902450323104858, "gsm_rft_2091": 0.6902921199798584, "gsm_rft_17141": 0.6903056502342224, "gsm_rft_7862": 0.6903534531593323, "gsm_rft_33186": 0.6903882622718811, "gsm_train_1174": 0.6903882622718811, "gsm_rft_25934": 0.690421998500824, "gsm_rft_30374": 0.6904389262199402, "gsm_rft_22363": 0.6905617117881775, "gsm_rft_10851": 0.6907410621643066, "aqua_rat_6188": 0.6907689571380615, "camel_37959": 0.691028892993927, "gsm_rft_17944": 0.6913029551506042, "gsm_rft_6406": 0.6914594173431396, "gsm_rft_2034": 0.6916049122810364, "gsm_rft_3538": 0.6916049122810364, "gsm_train_21024": 0.6917718648910522, "camel_28143": 0.692055881023407, "gsm_rft_25894": 0.6920607686042786, "gsm_rft_20209": 0.6921976208686829, "gsm_train_22328": 0.6921976208686829, "gsm_rft_3001": 0.6921976208686829, "gsm_rft_2271": 0.6922222971916199, "aqua_rat_2689": 0.6922257542610168, "gsm_rft_22822": 0.692283570766449, "gsm_rft_32684": 0.6923195123672485, "aqua_rat_73083": 0.6923498511314392, "aqua_rat_48599": 0.6925315856933594, "aqua_rat_21246": 0.6925333738327026, "gsm_rft_17396": 0.6925497055053711, "aqua_rat_26179": 0.6926605105400085, "gsm_rft_33299": 0.6928173899650574, "gsm_rft_27862": 0.6928894519805908, "gsm_train_29765": 0.6928894519805908, "aqua_rat_6088": 0.6931069493293762, "gsm_rft_10897": 0.6931160092353821, "gsm_rft_6897": 0.6931343078613281, "gsm_rft_15529": 0.6933532357215881, "gsm_rft_9828": 0.6933532357215881, "gsm_rft_7812": 0.6935595870018005, "gsm_train_21544": 0.693588376045227, "gsm_rft_15582": 0.6936458349227905, "gsm_train_18124": 0.6936458349227905, "gsm_train_33385": 0.6938243508338928, "gsm_train_13214": 0.6940686702728271, "gsm_rft_366": 0.6941095590591431, "gsm_rft_7089": 0.6942272782325745, "gsm_rft_24796": 0.6942526698112488, "aqua_rat_2392": 0.694462239742279, "gsm_rft_2956": 0.6945119500160217, "gsm_rft_26961": 0.6945174336433411, "gsm_rft_9719": 0.6947827339172363, "gsm_train_23183": 0.6950048804283142, "gsm_rft_13860": 0.695099413394928, "camel_28122": 0.695428729057312, "gsm_rft_8537": 0.6957823038101196, "gsm_train_29686": 0.6960211396217346, "gsm_rft_24420": 0.6960211396217346, "gsm_rft_8266": 0.6961635947227478, "gsm_rft_2576": 0.6961635947227478, "gsm_rft_28746": 0.6961763501167297, "gsm_rft_19748": 0.6964921951293945, "camel_17811": 0.6966986060142517, "gsm_rft_1939": 0.6972830295562744, "gsm_train_31158": 0.6972830295562744, "aqua_rat_69297": 0.6974700689315796, "gsm_train_1691": 0.6974879503250122, "gsm_rft_18466": 0.6974879503250122, "aqua_rat_23127": 0.6977576017379761, "gsm_rft_870": 0.6990479230880737, "gsm_rft_2575": 0.6990479230880737, "gsm_rft_35481": 0.6992210149765015, "gsm_train_31124": 0.6994066834449768, "gsm_rft_28645": 0.6994066834449768, "gsm_rft_30836": 0.6994066834449768, "gsm_rft_28878": 0.6994066834449768, "gsm_rft_6277": 0.7004952430725098, "gsm_train_24294": 0.7005792260169983, "gsm_rft_10781": 0.7007342576980591, "aqua_rat_66305": 0.7010833024978638, "aqua_rat_36347": 0.7017934322357178, "aqua_rat_47596": 0.7021552324295044, "aqua_rat_60714": 0.70244961977005, "aqua_rat_9906": 0.7031280398368835, "gsm_train_858": 0.7033594250679016, "aqua_rat_82138": 0.7034469246864319, "aqua_rat_54325": 0.7037462592124939, "aqua_rat_84169": 0.7038434147834778, "gsm_rft_31953": 0.7041500806808472, "gsm_rft_8384": 0.7041500806808472, "gsm_rft_6261": 0.7041500806808472, "aqua_rat_63167": 0.7046343684196472, "aqua_rat_22426": 0.7056734561920166, "aqua_rat_81926": 0.7067639827728271, "aqua_rat_57141": 0.7076931595802307, "aqua_rat_61003": 0.7096096277236938, "aqua_rat_3234": 0.7099773287773132, "gsm_rft_26010": 0.7103774547576904, "aqua_rat_60081": 0.7106847763061523, "aqua_rat_59779": 0.7111955285072327, "gsm_rft_28497": 0.7114561796188354, "gsm_train_18516": 0.7114561796188354, "aqua_rat_23035": 0.7119580507278442, "aqua_rat_73381": 0.7122629880905151, "gsm_rft_33530": 0.713036298751831, "aqua_rat_59558": 0.713342010974884, "aqua_rat_66162": 0.71440589427948, "aqua_rat_44457": 0.7144163250923157, "aqua_rat_23105": 0.7149035334587097, "gsm_rft_10110": 0.7156388163566589, "aqua_rat_67486": 0.7164167165756226, "aqua_rat_27769": 0.7165960669517517, "aqua_rat_32984": 0.716926634311676, "aqua_rat_75111": 0.7181445956230164, "aqua_rat_8610": 0.7183366417884827, "gsm_rft_33471": 0.721935510635376, "camel_45809": 0.7247182130813599}, "TheoremQA_panlu/gravitational_force2.json": {"TheoremQA_panlu/gravitational_force2.json": 0, "camel_7952": 0.7262005805969238, "gsm_rft_15576": 0.7263226509094238, "gsm_rft_4136": 0.7266759872436523, "aqua_rat_70945": 0.7267317771911621, "camel_39475": 0.7269500494003296, "camel_39509": 0.7269859313964844, "camel_2116": 0.7271031141281128, "camel_7972": 0.7271177768707275, "camel_39476": 0.7272176742553711, "camel_28022": 0.7276753783226013, "gsm_rft_6359": 0.7278237342834473, "aqua_rat_35471": 0.727914035320282, "gsm_rft_13505": 0.7279260754585266, "gsm_rft_31297": 0.7279761433601379, "gsm_rft_12769": 0.7281597256660461, "aqua_rat_62800": 0.7281990051269531, "camel_39454": 0.7284563779830933, "TheoremQA_xinyi/newtons_laws_1.json": 0.7289124131202698, "gsm_rft_8897": 0.7295536398887634, "gsm_rft_25136": 0.7295702695846558, "gsm_train_18003": 0.7295702695846558, "gsm_rft_24790": 0.7295702695846558, "gsm_train_12141": 0.7297667264938354, "gsm_rft_10259": 0.7297667264938354, "camel_7499": 0.7299329042434692, "camel_17565": 0.7299956679344177, "camel_39453": 0.7302370667457581, "camel_7999": 0.730526864528656, "gsm_train_553": 0.7308045029640198, "camel_39460": 0.7308865785598755, "gsm_rft_18266": 0.730908989906311, "aqua_rat_29931": 0.7310667634010315, "camel_39441": 0.7312751412391663, "gsm_train_21024": 0.7327864170074463, "gsm_rft_2034": 0.732789933681488, "gsm_rft_3538": 0.732789933681488, "gsm_rft_15416": 0.7329328656196594, "gsm_rft_6386": 0.7332746386528015, "gsm_rft_14979": 0.7333664298057556, "gsm_train_21052": 0.7334389090538025, "gsm_rft_8748": 0.7335731387138367, "aqua_rat_34975": 0.7335970401763916, "camel_7451": 0.733680784702301, "camel_7461": 0.7337102293968201, "gsm_train_2068": 0.7341615557670593, "gsm_rft_4583": 0.7341615557670593, "gsm_rft_35619": 0.7342715263366699, "TheoremQA_panlu/uniform_circular_motion1.json": 0.7343751788139343, "camel_39504": 0.7346585988998413, "aqua_rat_36939": 0.7347869277000427, "aqua_rat_33030": 0.7349036335945129, "gsm_rft_34630": 0.7350311279296875, "camel_7982": 0.7351406812667847, "gsm_rft_5789": 0.735176146030426, "camel_7964": 0.7352325320243835, "camel_7949": 0.7354556322097778, "camel_7476": 0.73548823595047, "math_test_algebra_518": 0.7356833219528198, "aqua_rat_58700": 0.7356960773468018, "camel_28846": 0.7358614802360535, "camel_7968": 0.7362236976623535, "camel_7923": 0.7364329695701599, "gsm_rft_29129": 0.7364419102668762, "camel_39508": 0.7365411520004272, "gsm_rft_7695": 0.736806333065033, "camel_39500": 0.7368417382240295, "gsm_rft_24978": 0.736850380897522, "camel_28868": 0.7369323968887329, "gsm_rft_22533": 0.7370141744613647, "camel_7954": 0.737094521522522, "aqua_rat_57191": 0.7371439933776855, "gsm_rft_14306": 0.7375741600990295, "gsm_rft_5266": 0.7376295328140259, "gsm_train_3790": 0.7376295328140259, "gsm_rft_16695": 0.73775714635849, "camel_7925": 0.7377983927726746, "gsm_rft_12701": 0.7378723621368408, "gsm_rft_22295": 0.7380131483078003, "camel_7988": 0.7384944558143616, "gsm_rft_24796": 0.7389093041419983, "camel_7519": 0.7389478087425232, "gsm_rft_19699": 0.739111065864563, "gsm_train_2173": 0.739111065864563, "camel_7966": 0.7391928434371948, "camel_7936": 0.7392208576202393, "camel_7995": 0.7392598986625671, "gsm_rft_32618": 0.7393331527709961, "gsm_rft_24421": 0.7394691705703735, "camel_28137": 0.7395414113998413, "gsm_rft_10505": 0.7395946979522705, "camel_43563": 0.7396448254585266, "camel_7610": 0.7404958009719849, "aqua_rat_42126": 0.7405993938446045, "camel_7947": 0.7407669425010681, "aqua_rat_67610": 0.741009533405304, "camel_7998": 0.7414504289627075, "gsm_rft_20767": 0.7418555617332458, "gsm_train_2385": 0.7424408197402954, "aqua_rat_19334": 0.7424559593200684, "camel_28909": 0.7424702048301697, "gsm_rft_14868": 0.7425187826156616, "aqua_rat_58858": 0.7428496479988098, "camel_5311": 0.7428788542747498, "camel_7962": 0.7429548501968384, "gsm_rft_21861": 0.7432984709739685, "gsm_rft_14753": 0.7432984709739685, "gsm_train_25944": 0.7432984709739685, "camel_39446": 0.7433586716651917, "gsm_rft_57": 0.7434852123260498, "camel_7993": 0.7437081933021545, "gsm_rft_10474": 0.7438204884529114, "camel_39462": 0.7441514134407043, "camel_28096": 0.7447134852409363, "camel_28847": 0.7452126145362854, "camel_7508": 0.745651364326477, "gsm_rft_9980": 0.7458609938621521, "camel_7480": 0.746284008026123, "gsm_rft_22397": 0.7466181516647339, "camel_5857": 0.7468628287315369, "camel_7498": 0.7469401955604553, "camel_17559": 0.7471945881843567, "camel_4731": 0.7477629780769348, "camel_7938": 0.7480125427246094, "camel_17406": 0.7480511665344238, "camel_7940": 0.7481175661087036, "camel_28068": 0.7481822371482849, "camel_7990": 0.7483848929405212, "camel_39479": 0.7489452958106995, "gsm_rft_17764": 0.7489726543426514, "gsm_train_29099": 0.7489726543426514, "gsm_rft_3828": 0.7493564486503601, "aqua_rat_11867": 0.7500971555709839, "camel_7920": 0.7502800822257996, "camel_7974": 0.7504826188087463, "TheoremQA_wenhuchen/Fluid_mechanics2.json": 0.7505040168762207, "camel_7491": 0.7505538463592529, "camel_7927": 0.750560998916626, "camel_7931": 0.7509837746620178, "aqua_rat_53936": 0.7513730525970459, "gsm_rft_35145": 0.7513829469680786, "camel_7980": 0.7514693737030029, "TheoremQA_panlu/uniform_circular_motion2.json": 0.7519270777702332, "camel_39485": 0.7522338032722473, "camel_7967": 0.7524080872535706, "camel_7977": 0.7524914741516113, "aqua_rat_79015": 0.7525354027748108, "camel_7478": 0.7529362440109253, "camel_7959": 0.7535175681114197, "camel_7935": 0.753786563873291, "camel_7946": 0.7540087699890137, "camel_7984": 0.754217267036438, "camel_7991": 0.7548788785934448, "camel_7934": 0.7552898526191711, "camel_4979": 0.755346953868866, "camel_7552": 0.755466103553772, "camel_7945": 0.7569429278373718, "camel_7987": 0.7571144700050354, "TheoremQA_wenhuchen/kepler's_law1.json": 0.7586245536804199, "camel_7484": 0.7617508172988892, "camel_39484": 0.761803150177002, "camel_7922": 0.7627777457237244, "camel_39469": 0.7628477811813354, "aqua_rat_86642": 0.7637201547622681, "camel_39511": 0.7653830051422119, "aqua_rat_88155": 0.7661683559417725, "aqua_rat_75922": 0.7663957476615906, "aqua_rat_4869": 0.7671059966087341, "aqua_rat_2612": 0.7685698866844177, "camel_5001": 0.7685737013816833, "camel_29979": 0.7685848474502563, "aqua_rat_26489": 0.7692162394523621, "camel_39467": 0.769668459892273, "camel_39452": 0.7722365260124207, "aqua_rat_67038": 0.7726592421531677, "camel_7463": 0.7728714346885681, "aqua_rat_63716": 0.7733877301216125, "camel_7928": 0.7745242714881897, "camel_39447": 0.7747986316680908, "aqua_rat_18184": 0.7751104235649109, "camel_7944": 0.7757988572120667, "camel_39471": 0.7765463590621948, "aqua_rat_43112": 0.7803331017494202, "aqua_rat_70741": 0.7806791067123413, "camel_39461": 0.780757486820221, "camel_39455": 0.785544216632843, "camel_39488": 0.7867130637168884, "camel_6246": 0.7910649180412292, "aqua_rat_6249": 0.7925013303756714, "aqua_rat_36823": 0.7937555313110352, "aqua_rat_18805": 0.795218825340271, "camel_39515": 0.797563374042511, "camel_39449": 0.8092091083526611, "TheoremQA_panlu/black_hole1.json": 0.815264880657196, "camel_39513": 0.8189176321029663, "TheoremQA_wenhuchen/kepler's_law3.json": 0.8232274651527405, "math_train_algebra_2156": 0.825249433517456, "TheoremQA_panlu/gravitational_force1.json": 0.8384434580802917, "TheoremQA_panlu/energy_conservation1.json": 0.8705717921257019, "TheoremQA_wenhuchen/kepler's_law2.json": 0.8813508749008179}, "TheoremQA_wenhuchen/Liouville\u2019s_theorem2.json": {"camel_42623": 0, "camel_42596": 0, "camel_42559": 0, "camel_43082": 0, "camel_42429": 0, "camel_42478": 0, "camel_42005": 0, "camel_42972": 0, "camel_42548": 0, "camel_42539": 0, "camel_43721": 0, "camel_42996": 0, "camel_42525": 0, "camel_42551": 0, "camel_43197": 0, "camel_43911": 0, "camel_43110": 0, "TheoremQA_wenhuchen/Liouville\u2019s_theorem2.json": 0, "camel_42431": 0, "camel_42636": 0, "camel_42839": 0, "camel_42553": 0, "camel_42615": 0, "camel_42614": 0, "camel_42480": 0, "camel_42530": 0, "camel_42410": 0, "camel_43263": 0, "camel_42497": 0, "camel_42485": 0, "camel_43697": 0, "camel_43152": 0, "camel_42975": 0, "camel_42603": 0, "camel_42552": 0, "camel_42021": 0, "camel_42531": 0, "camel_43171": 0, "camel_42529": 0, "camel_42435": 0, "camel_42456": 0, "camel_42558": 0, "camel_42512": 0, "camel_43131": 0, "camel_42500": 0, "camel_42507": 0, "camel_42538": 0, "camel_43036": 0, "camel_43006": 0, "camel_42985": 0, "camel_43133": 0, "camel_43010": 0, "camel_43035": 0, "camel_42492": 0, "camel_43020": 0, "camel_42556": 0, "camel_42564": 0, "camel_45809": 0.6824512481689453, "camel_44791": 0.6826227903366089, "camel_44528": 0.6826809048652649, "camel_45698": 0.6835181713104248, "camel_45998": 0.6836293339729309, "camel_44839": 0.6846198439598083, "camel_45162": 0.6846990585327148, "camel_45939": 0.6851487159729004, "camel_44621": 0.6853457093238831, "camel_45722": 0.6857293248176575, "camel_44807": 0.6859180927276611, "camel_45969": 0.6861869096755981, "camel_44758": 0.6862479448318481, "camel_44411": 0.6862713694572449, "camel_30269": 0.6866618394851685, "camel_45718": 0.6869716048240662, "camel_45681": 0.6874510049819946, "camel_44764": 0.6875131130218506, "camel_44467": 0.6875193119049072, "camel_45721": 0.6877530813217163, "camel_45924": 0.6878540515899658, "camel_44872": 0.6878694295883179, "camel_45797": 0.6879621148109436, "camel_44755": 0.688018262386322, "camel_45819": 0.6883612275123596, "camel_45152": 0.6887264251708984, "camel_45176": 0.6888852119445801, "camel_30284": 0.6890464425086975, "camel_44779": 0.6894174218177795, "camel_30223": 0.6900194883346558, "camel_45504": 0.6907026171684265, "camel_45198": 0.6907027959823608, "camel_45184": 0.6910470724105835, "camel_30316": 0.6913750767707825, "camel_45299": 0.6914159655570984, "camel_44748": 0.6916093826293945, "camel_45512": 0.691983163356781, "camel_28295": 0.6922098994255066, "camel_44725": 0.6932908296585083, "camel_30245": 0.6934122443199158, "camel_45772": 0.6937777996063232, "camel_45765": 0.6941318511962891, "camel_45689": 0.6953635811805725, "camel_45834": 0.6953868865966797, "camel_44820": 0.6954002976417542, "camel_30278": 0.6963297724723816, "camel_45170": 0.696542501449585, "camel_45745": 0.6969719529151917, "camel_44491": 0.6975066065788269, "camel_44797": 0.6977315545082092, "camel_45688": 0.6982012391090393, "camel_45952": 0.6984291672706604, "camel_44544": 0.6987840533256531, "camel_44784": 0.6993274688720703, "camel_45518": 0.699554979801178, "camel_44543": 0.6996025443077087, "camel_44732": 0.6996179223060608, "camel_45342": 0.6996482610702515, "camel_44547": 0.6999303698539734, "camel_44487": 0.7002133727073669, "camel_30254": 0.7004058957099915, "camel_45931": 0.7009795904159546, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.7011895775794983, "camel_45741": 0.7030757665634155, "camel_44721": 0.7034776210784912, "camel_45988": 0.7038296461105347, "camel_45693": 0.7041128873825073, "camel_44742": 0.7044046521186829, "camel_45727": 0.7050079703330994, "camel_45600": 0.7050679922103882, "camel_44781": 0.7051259279251099, "camel_44793": 0.7052825093269348, "camel_44743": 0.7053343057632446, "camel_44768": 0.7056881189346313, "camel_45003": 0.7060920000076294, "camel_45690": 0.7063440680503845, "camel_44722": 0.7077264785766602, "camel_44492": 0.7080253958702087, "camel_44723": 0.7081947922706604, "camel_44744": 0.7093396782875061, "camel_45676": 0.7107840180397034, "camel_45682": 0.7110639810562134, "camel_44788": 0.7114579677581787, "camel_45928": 0.7116118669509888, "camel_45379": 0.7120479941368103, "camel_45803": 0.7123007774353027, "camel_44759": 0.7123838067054749, "camel_45744": 0.7131175398826599, "camel_44776": 0.7133042812347412, "camel_44778": 0.7141600251197815, "camel_44747": 0.7141746282577515, "camel_44774": 0.7141827940940857, "TheoremQA_mingyin/liouville-theorem1.json": 0.7146904468536377, "camel_44799": 0.7148580551147461, "camel_45713": 0.7150707244873047, "camel_45754": 0.7158010601997375, "camel_45314": 0.7158870100975037, "camel_44767": 0.7163020372390747, "camel_44424": 0.7165431976318359, "camel_45706": 0.7166316509246826, "camel_44795": 0.7174158692359924, "camel_44777": 0.717499852180481, "camel_44761": 0.717637300491333, "camel_44537": 0.7180044651031494, "camel_44720": 0.7185986638069153, "camel_45492": 0.7191901206970215, "camel_45725": 0.7192692160606384, "camel_45684": 0.720492422580719, "camel_45710": 0.7205325365066528, "camel_44746": 0.7219110727310181, "camel_45171": 0.7223600149154663, "camel_45709": 0.7227510809898376, "camel_44794": 0.722797155380249, "TheoremQA_wenhuchen/Liouville\u2019s_theorem1.json": 0.7231485843658447, "camel_45936": 0.7233527302742004, "camel_44538": 0.7241581678390503, "camel_44752": 0.7246039509773254, "TheoremQA_maxku/cv-imageprocessing8-fourier3.json": 0.725213348865509, "camel_44806": 0.7253363728523254, "camel_44773": 0.7260245084762573, "camel_44729": 0.7269467115402222, "camel_44766": 0.7274699211120605, "camel_44848": 0.7275725603103638, "camel_45146": 0.7298977375030518, "camel_44838": 0.7304077744483948, "camel_44760": 0.730618953704834, "camel_44786": 0.7310189604759216, "camel_44798": 0.7329792976379395, "camel_44783": 0.7336174249649048, "camel_44775": 0.7364566922187805, "camel_44735": 0.7366620302200317, "camel_44787": 0.7370875477790833, "camel_45680": 0.7411996126174927, "camel_44782": 0.7418608665466309, "camel_44749": 0.7430179715156555, "camel_44757": 0.7453463077545166, "camel_44727": 0.7454752326011658, "camel_44785": 0.7521082758903503, "camel_44750": 0.7531561851501465, "camel_44728": 0.7569676041603088, "camel_44790": 0.761162519454956, "camel_44772": 0.7618314623832703, "camel_44762": 0.7781685590744019}, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus3.json": {"camel_7333": 0, "camel_6250": 0, "camel_7770": 0, "camel_7768": 0, "camel_7288": 0, "camel_7357": 0, "camel_7775": 0, "camel_7063": 0, "camel_7817": 0, "camel_7348": 0, "camel_7355": 0, "camel_7819": 0, "camel_7826": 0, "camel_6243": 0, "camel_7324": 0, "camel_7825": 0, "camel_7303": 0, "camel_7287": 0, "camel_7834": 0, "camel_7325": 0, "camel_7783": 0, "camel_7284": 0, "camel_7800": 0, "camel_7798": 0, "camel_7293": 0, "camel_6269": 0, "camel_7779": 0, "camel_7302": 0, "camel_6317": 0, "camel_7802": 0, "camel_7290": 0, "camel_6266": 0, "camel_7837": 0, "camel_7314": 0, "camel_7811": 0, "camel_6278": 0, "camel_7832": 0, "camel_6294": 0, "camel_7831": 0, "camel_7764": 0, "camel_6315": 0, "camel_7772": 0, "camel_7785": 0, "camel_7316": 0, "camel_7769": 0, "camel_6288": 0, "camel_7804": 0, "camel_6314": 0, "camel_6264": 0, "camel_7294": 0, "camel_6276": 0, "camel_6284": 0, "camel_7343": 0, "camel_6255": 0, "camel_6253": 0, "camel_6265": 0, "camel_6271": 0, "camel_6302": 0, "camel_6245": 0, "camel_6275": 0, "camel_6241": 0, "camel_7305": 0, "camel_7304": 0, "camel_7326": 0, "camel_7281": 0, "camel_7345": 0, "camel_7043": 0, "camel_7320": 0, "camel_7838": 0, "camel_6312": 0, "camel_7283": 0, "camel_7336": 0, "camel_7323": 0, "camel_7285": 0, "camel_7349": 0, "camel_7311": 0, "camel_7784": 0, "camel_7347": 0, "camel_6286": 0, "camel_7338": 0, "camel_6285": 0, "camel_7295": 0, "camel_7315": 0, "camel_7359": 0, "camel_7334": 0, "camel_7350": 0, "camel_7351": 0, "camel_7330": 0, "camel_7816": 0, "camel_7344": 0, "camel_7830": 0, "camel_7352": 0, "camel_7354": 0, "camel_7297": 0, "camel_7731": 0, "camel_7313": 0, "camel_7328": 0, "camel_7340": 0, "camel_7335": 0, "camel_7299": 0, "camel_7815": 0, "camel_6298": 0, "camel_7292": 0, "camel_7329": 0, "camel_7317": 0, "camel_7337": 0, "camel_6252": 0, "camel_6316": 0, "camel_7346": 0, "camel_7356": 0, "camel_6318": 0, "camel_7300": 0, "camel_7296": 0, "camel_7310": 0, "camel_6272": 0, "camel_7318": 0, "camel_7327": 0, "camel_6311": 0, "camel_7312": 0, "camel_6242": 0, "camel_6305": 0, "camel_6263": 0, "camel_7289": 0, "camel_7306": 0, "camel_6301": 0, "camel_7331": 0, "camel_7319": 0, "camel_7309": 0, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus3.json": 0, "camel_43457": 0.7177278399467468, "camel_5349": 0.7183478474617004, "camel_5493": 0.7191705107688904, "camel_5304": 0.7193092703819275, "camel_5283": 0.720072329044342, "camel_5326": 0.7203678488731384, "camel_5290": 0.7203831672668457, "camel_5330": 0.7211757302284241, "camel_5502": 0.7211920619010925, "camel_37096": 0.7225037217140198, "camel_5281": 0.7228378653526306, "camel_5332": 0.7230143547058105, "camel_5315": 0.7243655920028687, "camel_5323": 0.7246277332305908, "camel_5302": 0.7246628403663635, "camel_5335": 0.7249665856361389, "camel_5359": 0.7253230810165405, "camel_5346": 0.7254458069801331, "camel_5307": 0.7263193130493164, "camel_5329": 0.7263784408569336, "camel_5289": 0.727730393409729, "camel_5280": 0.7278814315795898, "camel_5339": 0.7279611825942993, "camel_5341": 0.7280548810958862, "camel_5340": 0.7284215688705444, "camel_5503": 0.7290095090866089, "camel_5343": 0.7290143370628357, "camel_5308": 0.7295552492141724, "camel_5310": 0.7296291589736938, "camel_5337": 0.7308321595191956, "camel_5317": 0.7310162782669067, "camel_5328": 0.7310364246368408, "camel_5324": 0.7314054369926453, "camel_5292": 0.7314340472221375, "camel_5299": 0.7317110300064087, "camel_43466": 0.7317347526550293, "camel_5336": 0.7318069338798523, "camel_5288": 0.7321330308914185, "camel_5350": 0.7321847081184387, "camel_5352": 0.7327414155006409, "camel_5306": 0.7333933711051941, "camel_5312": 0.7337023019790649, "camel_5293": 0.7337958812713623, "camel_5447": 0.7343025803565979, "camel_5300": 0.7348363399505615, "camel_5347": 0.7349128127098083, "camel_5309": 0.7350378036499023, "camel_5355": 0.7368089556694031, "camel_5321": 0.7376822829246521, "camel_43445": 0.73822420835495, "camel_45941": 0.7389706373214722, "camel_5353": 0.7392132878303528, "camel_5320": 0.739253044128418, "camel_5296": 0.7396491765975952, "camel_5294": 0.7399426102638245, "camel_5286": 0.7402791380882263, "camel_5316": 0.7412930130958557, "camel_5297": 0.741679847240448, "camel_5351": 0.7433940768241882, "camel_5282": 0.7438076734542847, "camel_5480": 0.7462717294692993, "camel_5313": 0.7470567226409912, "camel_5342": 0.7477892637252808, "camel_19568": 0.7503241300582886, "TheoremQA_wenhuchen/morera's_theorem1.json": 0.7511154413223267, "camel_43488": 0.7556545734405518, "camel_19895": 0.7570672035217285, "camel_5327": 0.7587903141975403, "camel_43463": 0.7700995206832886, "camel_19725": 0.7819530963897705, "camel_44347": 0.7829012870788574}, "TheoremQA_mingyin/convexity1.json": {"camel_38314": 0, "camel_38481": 0, "camel_38313": 0, "camel_38243": 0, "camel_39458": 0, "camel_38279": 0, "camel_38195": 0, "camel_38201": 0, "camel_38437": 0, "camel_38146": 0, "camel_38272": 0, "camel_39251": 0, "camel_39162": 0, "camel_38193": 0, "camel_38227": 0, "camel_38961": 0, "camel_39207": 0, "camel_38206": 0, "camel_38115": 0, "camel_38540": 0, "camel_38202": 0, "camel_38319": 0, "camel_39001": 0, "camel_38175": 0, "camel_39068": 0, "camel_38173": 0, "camel_38190": 0, "camel_39223": 0, "camel_39010": 0, "camel_38311": 0, "camel_38273": 0, "camel_38318": 0, "camel_38191": 0, "camel_39266": 0, "camel_38165": 0, "camel_39198": 0, "camel_39060": 0, "camel_39143": 0, "aqua_rat_65230": 0.7111049890518188, "camel_40745": 0.7111441493034363, "camel_15186": 0.711225688457489, "camel_18711": 0.7112289667129517, "camel_41422": 0.7112436890602112, "aqua_rat_64857": 0.71148282289505, "aqua_rat_39210": 0.7115143537521362, "gsm_rft_26882": 0.711804986000061, "aqua_rat_37262": 0.7119765281677246, "aqua_rat_24416": 0.7120608687400818, "camel_19742": 0.7121173143386841, "gsm_rft_24412": 0.7121601700782776, "camel_18707": 0.7122272849082947, "camel_41403": 0.7122282385826111, "gsm_rft_19280": 0.7123856544494629, "gsm_rft_3885": 0.7123856544494629, "gsm_train_18364": 0.7123856544494629, "camel_7714": 0.712429940700531, "gsm_rft_29652": 0.7124930024147034, "gsm_train_12841": 0.7124930024147034, "gsm_rft_19111": 0.71269690990448, "aqua_rat_41724": 0.7127282619476318, "aqua_rat_14285": 0.7127529382705688, "camel_18684": 0.7128585577011108, "aqua_rat_64556": 0.7129009962081909, "camel_40955": 0.7129817008972168, "camel_40833": 0.713019847869873, "camel_30219": 0.7131690382957458, "aqua_rat_9572": 0.7133064866065979, "camel_19716": 0.7133391499519348, "camel_619": 0.713376522064209, "gsm_rft_35475": 0.713483452796936, "camel_18718": 0.7135133147239685, "aqua_rat_88643": 0.7137101888656616, "gsm_rft_4482": 0.7137870192527771, "camel_41404": 0.7138068675994873, "gsm_rft_23214": 0.713814914226532, "aqua_rat_55595": 0.7140536308288574, "camel_40804": 0.7141281962394714, "gsm_rft_31264": 0.7141568660736084, "camel_18706": 0.714203953742981, "aqua_rat_47009": 0.7143089771270752, "aqua_rat_11611": 0.7144911885261536, "gsm_rft_24756": 0.7147477269172668, "camel_40841": 0.7147969603538513, "gsm_train_9463": 0.7150553464889526, "gsm_rft_1995": 0.7150553464889526, "gsm_rft_22763": 0.7151466012001038, "camel_41769": 0.715157151222229, "gsm_rft_33333": 0.7153922915458679, "gsm_train_29935": 0.7153922915458679, "aqua_rat_55675": 0.7155023217201233, "gsm_rft_14259": 0.715508759021759, "aqua_rat_6164": 0.7155745029449463, "camel_40810": 0.7155950665473938, "gsm_rft_26003": 0.7156533002853394, "gsm_train_3180": 0.7156533002853394, "aqua_rat_41830": 0.7156575918197632, "camel_40809": 0.7157923579216003, "aqua_rat_6451": 0.7158992290496826, "gsm_rft_20502": 0.715996265411377, "camel_18705": 0.7160453796386719, "gsm_train_11033": 0.7161401510238647, "camel_41615": 0.7162612676620483, "gsm_rft_16142": 0.7163416147232056, "gsm_rft_6666": 0.7164658904075623, "gsm_rft_11906": 0.7164658904075623, "camel_30292": 0.7165740728378296, "gsm_rft_13368": 0.7168456315994263, "aqua_rat_65765": 0.7169182896614075, "camel_41821": 0.7170183658599854, "aqua_rat_36780": 0.7171650528907776, "gsm_rft_2358": 0.7172331809997559, "gsm_train_1555": 0.7172331809997559, "aqua_rat_9217": 0.7174757122993469, "camel_621": 0.7175841331481934, "aqua_rat_84154": 0.7176476716995239, "camel_590": 0.7176964282989502, "TheoremQA_elainewan/math_algebra_3.json": 0.7177956104278564, "camel_30259": 0.7180991172790527, "camel_19727": 0.7181721329689026, "camel_40930": 0.7182192206382751, "camel_30216": 0.7185880541801453, "camel_40813": 0.7187089920043945, "camel_41686": 0.7187939286231995, "aqua_rat_24062": 0.7188419103622437, "aqua_rat_77712": 0.7190580368041992, "camel_18704": 0.7191300392150879, "aqua_rat_11436": 0.7193574905395508, "gsm_rft_19697": 0.719437837600708, "gsm_train_30034": 0.7195194363594055, "camel_18703": 0.7196651101112366, "math_train_prealgebra_274": 0.719688355922699, "aqua_rat_32807": 0.7197911739349365, "gsm_train_23828": 0.7201800346374512, "gsm_rft_14382": 0.7204781770706177, "gsm_rft_190": 0.7204781770706177, "gsm_rft_1017": 0.7205551862716675, "gsm_train_23437": 0.7205551862716675, "gsm_rft_9234": 0.7205551862716675, "gsm_rft_17616": 0.7205660939216614, "gsm_rft_575": 0.7205995917320251, "math_train_prealgebra_208": 0.7206448316574097, "aqua_rat_44312": 0.7207145094871521, "gsm_rft_33581": 0.7208490371704102, "gsm_train_30509": 0.7208490371704102, "aqua_rat_11796": 0.7208526730537415, "camel_579": 0.7209321856498718, "gsm_rft_27714": 0.7211037874221802, "gsm_rft_16127": 0.7217522263526917, "aqua_rat_16864": 0.7217867374420166, "camel_14621": 0.7218120694160461, "camel_608": 0.7221439480781555, "gsm_train_10108": 0.7222092151641846, "gsm_rft_12381": 0.7222092151641846, "aqua_rat_52932": 0.7222245335578918, "gsm_rft_11802": 0.7222777605056763, "aqua_rat_66786": 0.7223854660987854, "camel_615": 0.7228458523750305, "camel_18687": 0.7239359617233276, "camel_41566": 0.7239488959312439, "camel_30888": 0.7240853905677795, "gsm_rft_11803": 0.7243257164955139, "camel_618": 0.7246469855308533, "gsm_rft_23829": 0.7246662378311157, "aqua_rat_53929": 0.7247188091278076, "camel_40830": 0.7248510122299194, "math_test_prealgebra_2073": 0.7249290347099304, "gsm_rft_2620": 0.725078284740448, "gsm_train_722": 0.725078284740448, "gsm_rft_23189": 0.725125253200531, "TheoremQA_xinyi/convex_hull.json": 0.7252201437950134, "aqua_rat_60553": 0.7252386808395386, "camel_18274": 0.7262323498725891, "math_test_prealgebra_994": 0.7265902757644653, "aqua_rat_43043": 0.7270833253860474, "gsm_rft_19548": 0.7283925414085388, "gsm_rft_23764": 0.7283925414085388, "gsm_rft_28768": 0.7283925414085388, "gsm_train_16350": 0.7283925414085388, "gsm_rft_28586": 0.7283925414085388, "camel_18678": 0.7285618782043457, "camel_18362": 0.7294238209724426, "gsm_rft_20478": 0.7309037446975708, "camel_19685": 0.7318088412284851, "gsm_rft_27052": 0.7320199608802795, "gsm_rft_13006": 0.7325392961502075, "camel_40831": 0.7326482534408569, "math_test_prealgebra_969": 0.7331645488739014, "camel_18690": 0.734663724899292, "camel_30304": 0.7354254126548767, "camel_8875": 0.7361693382263184, "camel_28290": 0.7377403378486633, "camel_40940": 0.7387062311172485, "camel_18366": 0.7387884259223938, "camel_18355": 0.7393117547035217, "camel_18360": 0.7450987696647644, "camel_18377": 0.7486846446990967, "camel_18680": 0.7489537000656128, "camel_18399": 0.7545776963233948, "camel_18383": 0.7585902214050293, "camel_18380": 0.761971116065979}, "TheoremQA_tonyxia/maxplanar3.json": {"camel_23386": 0, "camel_23187": 0, "camel_22456": 0, "camel_22478": 0, "camel_22373": 0, "camel_22179": 0, "camel_22458": 0, "camel_22437": 0, "camel_23183": 0, "camel_23173": 0, "camel_21084": 0, "camel_22424": 0, "camel_22946": 0, "camel_23404": 0, "camel_21800": 0, "camel_22433": 0, "camel_22417": 0, "camel_23123": 0, "camel_23122": 0, "camel_22328": 0, "camel_23146": 0, "camel_21123": 0, "camel_22379": 0, "camel_23363": 0, "camel_22360": 0, "camel_22870": 0, "camel_21792": 0, "camel_22430": 0, "camel_21831": 0, "camel_22333": 0, "camel_22334": 0, "camel_21065": 0, "camel_22398": 0, "camel_22375": 0, "camel_22887": 0, "camel_22364": 0, "camel_22453": 0, "camel_22185": 0, "camel_22628": 0, "camel_23168": 0, "camel_23145": 0, "camel_22329": 0, "camel_22866": 0, "camel_22387": 0, "camel_23432": 0, "camel_23403": 0, "camel_22890": 0, "camel_22391": 0, "camel_23423": 0, "camel_23182": 0, "camel_22413": 0, "camel_21784": 0, "camel_23943": 0, "camel_22384": 0, "camel_22397": 0, "camel_23198": 0, "camel_21152": 0, "camel_23307": 0, "camel_22322": 0, "camel_23134": 0, "camel_22421": 0, "camel_21129": 0, "camel_23180": 0, "camel_23418": 0, "camel_23374": 0, "camel_22345": 0, "camel_23995": 0, "camel_22381": 0, "camel_23154": 0, "camel_22910": 0, "camel_22849": 0, "camel_21767": 0, "camel_22335": 0, "camel_23157": 0, "camel_21044": 0, "camel_22418": 0, "camel_23427": 0, "camel_23175": 0, "camel_23382": 0, "camel_23934": 0, "camel_23147": 0, "camel_23391": 0, "camel_23176": 0, "camel_23193": 0, "camel_23162": 0, "camel_22600": 0, "camel_21830": 0, "camel_23166": 0, "camel_21176": 0, "camel_23124": 0, "camel_23174": 0, "camel_22862": 0, "camel_23196": 0, "camel_23430": 0, "camel_22808": 0, "camel_22352": 0, "camel_21179": 0, "camel_22823": 0, "camel_23188": 0, "camel_22396": 0, "camel_22597": 0, "camel_23165": 0, "camel_23395": 0, "camel_23141": 0, "camel_23393": 0, "camel_23159": 0, "camel_23181": 0, "camel_23306": 0, "camel_22393": 0, "camel_23177": 0, "camel_21083": 0, "camel_21794": 0, "camel_21768": 0, "camel_22327": 0, "camel_22575": 0, "camel_22445": 0, "camel_23158": 0, "camel_23150": 0, "camel_23425": 0, "camel_21116": 0, "camel_22580": 0, "camel_23144": 0, "camel_23402": 0, "camel_23190": 0, "camel_21113": 0, "camel_22574": 0, "camel_22939": 0, "camel_22912": 0, "camel_22422": 0, "camel_22949": 0, "camel_22378": 0, "camel_23189": 0, "camel_22599": 0, "camel_21100": 0, "camel_23392": 0, "camel_22157": 0, "camel_23155": 0, "camel_22356": 0, "camel_22369": 0, "camel_23328": 0, "camel_23285": 0, "camel_22573": 0, "camel_22905": 0, "camel_23172": 0, "camel_22805": 0, "camel_22927": 0, "camel_23358": 0, "camel_22867": 0, "camel_22853": 0, "camel_23135": 0, "camel_22579": 0, "camel_23424": 0, "camel_21107": 0, "camel_23944": 0, "camel_22838": 0, "camel_23971": 0, "camel_23372": 0, "camel_23951": 0, "camel_22362": 0, "camel_23994": 0, "camel_21780": 0, "camel_21818": 0, "camel_23977": 0, "camel_22443": 0, "camel_23369": 0, "camel_22863": 0, "camel_23163": 0, "camel_23195": 0, "camel_21098": 0, "camel_23156": 0, "camel_23128": 0, "camel_23191": 0, "camel_22383": 0, "camel_22585": 0, "camel_23151": 0, "camel_21133": 0, "camel_22338": 0, "camel_23400": 0, "camel_23126": 0, "camel_23161": 0, "camel_23179": 0, "camel_23164": 0, "camel_23364": 0, "camel_22170": 0, "camel_19249": 0.7557463049888611, "aqua_rat_23372": 0.7558154463768005, "aqua_rat_26025": 0.7559282779693604, "camel_18571": 0.757617712020874, "aqua_rat_76358": 0.758094310760498, "camel_18621": 0.7594506740570068, "camel_18678": 0.7601312398910522, "camel_18680": 0.7605559825897217, "aqua_rat_76009": 0.7630146741867065, "aqua_rat_54929": 0.7645492553710938, "aqua_rat_44831": 0.7685739398002625, "camel_19957": 0.7697429060935974, "aqua_rat_70645": 0.7708162665367126, "camel_18365": 0.7782155275344849, "aqua_rat_40504": 0.781818151473999, "aqua_rat_25794": 0.78636634349823}, "TheoremQA_wenhuchen/series_convergen3.json": {"TheoremQA_wenhuchen/series_convergen3.json": 0, "camel_42716": 0.6480993032455444, "camel_42747": 0.6481072306632996, "camel_30927": 0.6483147144317627, "camel_42614": 0.6483604311943054, "camel_42688": 0.6483679413795471, "camel_42713": 0.6484267115592957, "camel_42279": 0.6484329700469971, "camel_30136": 0.648571789264679, "camel_42816": 0.6486631035804749, "camel_31248": 0.6489282846450806, "camel_42711": 0.6490469574928284, "camel_42375": 0.6491892337799072, "aqua_rat_50530": 0.6491962671279907, "camel_42261": 0.6492841243743896, "camel_42267": 0.6493437886238098, "aqua_rat_37159": 0.6494652032852173, "camel_30942": 0.6495157480239868, "camel_42486": 0.6496179103851318, "aqua_rat_64676": 0.6496907472610474, "aqua_rat_73910": 0.6499241590499878, "camel_42271": 0.6500231623649597, "camel_42787": 0.650494396686554, "camel_30926": 0.6505866646766663, "camel_31163": 0.6509241461753845, "camel_31158": 0.6510380506515503, "camel_30396": 0.651062548160553, "camel_31154": 0.6511633992195129, "aqua_rat_78757": 0.6512219905853271, "camel_42547": 0.6513956189155579, "TheoremQA_wenhuchen/taylor_expansion2.json": 0.651576817035675, "camel_42051": 0.6516213417053223, "camel_44110": 0.6516377329826355, "camel_42258": 0.6516677737236023, "camel_31185": 0.6518920063972473, "camel_42669": 0.651950478553772, "camel_42605": 0.6519557237625122, "camel_42625": 0.6519855260848999, "camel_42882": 0.6521632671356201, "camel_31323": 0.6522374749183655, "camel_28309": 0.6522650718688965, "camel_42712": 0.6524624824523926, "camel_31098": 0.6524922847747803, "camel_42755": 0.6525008678436279, "camel_42695": 0.6526221036911011, "camel_42888": 0.6526843905448914, "camel_30892": 0.6530510783195496, "camel_30936": 0.653099536895752, "camel_42670": 0.6535809636116028, "aqua_rat_53870": 0.6536319851875305, "camel_30897": 0.6537439227104187, "camel_30916": 0.6538147330284119, "camel_42683": 0.653816282749176, "aqua_rat_82861": 0.6539319157600403, "camel_42289": 0.6541445851325989, "camel_42613": 0.6545600891113281, "camel_30440": 0.6546617746353149, "camel_31444": 0.6547179222106934, "camel_42693": 0.6548158526420593, "aqua_rat_61662": 0.6548644304275513, "camel_42749": 0.6549785733222961, "camel_30759": 0.6549913883209229, "camel_42315": 0.6550134420394897, "camel_42306": 0.6550542712211609, "camel_30899": 0.6552644968032837, "camel_42707": 0.6555159687995911, "aqua_rat_46276": 0.6556578874588013, "camel_42478": 0.655929446220398, "camel_42703": 0.6560255885124207, "camel_43381": 0.6560426354408264, "aqua_rat_69628": 0.6560637950897217, "aqua_rat_55051": 0.6561962366104126, "aqua_rat_56288": 0.6562262773513794, "aqua_rat_3767": 0.656284749507904, "camel_42045": 0.656308650970459, "camel_42005": 0.6564433574676514, "aqua_rat_54656": 0.656486988067627, "camel_42575": 0.6573536396026611, "aqua_rat_36268": 0.6574008464813232, "camel_30932": 0.6575912237167358, "camel_31241": 0.6577176451683044, "TheoremQA_mingyin/liouville-theorem1.json": 0.6578055620193481, "camel_42623": 0.6579087972640991, "aqua_rat_20385": 0.6579626798629761, "aqua_rat_50511": 0.6581143140792847, "aqua_rat_31892": 0.6581471562385559, "camel_42674": 0.6582944393157959, "camel_31166": 0.6583995819091797, "aqua_rat_19560": 0.6584925651550293, "camel_43001": 0.6585170030593872, "camel_42792": 0.658714771270752, "camel_30325": 0.6587868928909302, "aqua_rat_11117": 0.6589369773864746, "camel_42668": 0.659064531326294, "camel_42063": 0.6591023802757263, "camel_42887": 0.6593315005302429, "aqua_rat_52544": 0.6594592332839966, "camel_31702": 0.6596366763114929, "aqua_rat_35341": 0.6597509384155273, "camel_42021": 0.6598401665687561, "camel_42249": 0.6599046587944031, "camel_42658": 0.659987211227417, "camel_42779": 0.6601619124412537, "camel_42616": 0.6605079174041748, "camel_42778": 0.6606748700141907, "camel_42732": 0.6608517169952393, "camel_42663": 0.6609869599342346, "camel_42762": 0.6611537933349609, "aqua_rat_50166": 0.6613696217536926, "aqua_rat_67612": 0.6619357466697693, "camel_30688": 0.6620255708694458, "camel_42277": 0.6625893115997314, "camel_30797": 0.662699818611145, "camel_30921": 0.6635425686836243, "camel_42282": 0.6640858054161072, "camel_42666": 0.6642767190933228, "camel_42643": 0.6643283367156982, "camel_42677": 0.6651279330253601, "camel_44106": 0.6651853322982788, "camel_30948": 0.6651908755302429, "aqua_rat_53748": 0.6652557849884033, "camel_49079": 0.6652589440345764, "camel_30887": 0.6658912301063538, "camel_30952": 0.6663862466812134, "camel_31089": 0.6668485999107361, "aqua_rat_4332": 0.6669774055480957, "camel_37619": 0.6676897406578064, "camel_42591": 0.6681150197982788, "camel_42756": 0.6682190299034119, "camel_30898": 0.6682263612747192, "camel_42704": 0.6683982610702515, "camel_42676": 0.6684066653251648, "camel_30330": 0.6688153147697449, "camel_42760": 0.6689473390579224, "camel_42564": 0.6690098643302917, "camel_30889": 0.6690674424171448, "aqua_rat_8747": 0.6692697405815125, "camel_42776": 0.6697061657905579, "camel_31452": 0.6705693006515503, "camel_44100": 0.6706048846244812, "camel_30327": 0.6706891655921936, "camel_31842": 0.6709619164466858, "camel_30385": 0.6711838245391846, "camel_42672": 0.6711950898170471, "camel_30886": 0.6716840267181396, "camel_30923": 0.6718077659606934, "camel_42990": 0.6721116304397583, "camel_42645": 0.6727344989776611, "camel_42530": 0.6727468967437744, "aqua_rat_59396": 0.6733590960502625, "camel_31505": 0.6733659505844116, "camel_30341": 0.6735457181930542, "camel_44141": 0.6736115217208862, "camel_30093": 0.6745651960372925, "camel_42497": 0.6748710870742798, "aqua_rat_48885": 0.6750802397727966, "camel_42070": 0.6751850247383118, "camel_31915": 0.6755124926567078, "TheoremQA_wenhuchen/series_convergen2.json": 0.6759591102600098, "camel_18301": 0.6763126850128174, "aqua_rat_35123": 0.6767948865890503, "aqua_rat_69318": 0.6784963011741638, "camel_42618": 0.679160475730896, "camel_31984": 0.6794850826263428, "TheoremQA_wenhuchen/infinite_series_sum2.json": 0.6797885298728943, "camel_30353": 0.6804724335670471, "camel_42678": 0.6813295483589172, "camel_42615": 0.6820197105407715, "TheoremQA_wenhuchen/series_convergen1.json": 0.6824806928634644, "camel_30357": 0.683644711971283, "math_test_algebra_2477": 0.6858627200126648, "camel_30346": 0.6861009001731873, "aqua_rat_44150": 0.6864489316940308, "camel_30371": 0.6869323253631592, "camel_49109": 0.6880012154579163, "camel_30345": 0.6887496113777161, "camel_31880": 0.689678430557251, "camel_30383": 0.6899839043617249, "camel_42777": 0.6907864809036255, "camel_31869": 0.6953924298286438, "camel_30685": 0.6961228847503662, "TheoremQA_mingyin/Lebesgue-measure1.json": 0.6973364949226379, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus2.json": 0.6975388526916504, "camel_30680": 0.6981894373893738, "camel_30202": 0.7011141777038574, "camel_30392": 0.7012028694152832, "camel_30342": 0.7017163038253784, "camel_30372": 0.7024319171905518, "camel_31056": 0.7039592862129211, "camel_30338": 0.7092453241348267, "camel_30374": 0.7098255753517151, "camel_44121": 0.7102963924407959, "camel_31759": 0.7115161418914795, "camel_30339": 0.7127144932746887, "camel_31061": 0.7154943346977234, "camel_31084": 0.7162182927131653, "camel_49051": 0.7193648219108582, "camel_30354": 0.7200796604156494, "camel_31057": 0.7203171253204346, "camel_42013": 0.7338075041770935}, "TheoremQA_jianyu_xu/Binomial_1.json": {"camel_20656": 0, "camel_21050": 0, "camel_20874": 0, "camel_20948": 0, "camel_20512": 0, "camel_20256": 0, "camel_21530": 0, "camel_20293": 0, "camel_20598": 0, "camel_21255": 0, "camel_20802": 0, "camel_21808": 0, "camel_20269": 0, "camel_20272": 0, "camel_20246": 0, "camel_20302": 0, "camel_21056": 0, "camel_20312": 0, "camel_20336": 0, "camel_21386": 0, "camel_20930": 0, "camel_20022": 0, "camel_20287": 0, "aqua_rat_79238": 0.8205106258392334, "aqua_rat_37301": 0.8206126093864441, "aqua_rat_19517": 0.8206188082695007, "aqua_rat_49782": 0.8207658529281616, "aqua_rat_8260": 0.8209094405174255, "aqua_rat_7086": 0.8209272027015686, "aqua_rat_58757": 0.8210422396659851, "aqua_rat_30884": 0.8210638165473938, "aqua_rat_29513": 0.8210739493370056, "aqua_rat_2112": 0.8211120367050171, "aqua_rat_34245": 0.8211671710014343, "aqua_rat_50290": 0.8212629556655884, "math_train_counting_and_probability_531": 0.8212835788726807, "aqua_rat_24686": 0.8214300870895386, "aqua_rat_2658": 0.8215494751930237, "aqua_rat_88698": 0.8215780854225159, "aqua_rat_5150": 0.8216015100479126, "aqua_rat_8468": 0.821712076663971, "aqua_rat_22809": 0.8218243718147278, "aqua_rat_25181": 0.821837842464447, "aqua_rat_80242": 0.8220111131668091, "aqua_rat_13609": 0.8220569491386414, "aqua_rat_45667": 0.8225294351577759, "aqua_rat_70803": 0.8225319981575012, "aqua_rat_41153": 0.8226310610771179, "aqua_rat_29035": 0.822666347026825, "aqua_rat_76271": 0.8227779865264893, "aqua_rat_48666": 0.8232393264770508, "aqua_rat_75767": 0.8233778476715088, "aqua_rat_30122": 0.8234342932701111, "aqua_rat_77361": 0.8236076831817627, "aqua_rat_8021": 0.8236249685287476, "aqua_rat_20142": 0.8237019181251526, "aqua_rat_79094": 0.8237042427062988, "aqua_rat_15615": 0.8238142728805542, "aqua_rat_29306": 0.8240302801132202, "aqua_rat_76349": 0.8240627646446228, "aqua_rat_69481": 0.824359118938446, "aqua_rat_51559": 0.8244969248771667, "aqua_rat_78835": 0.8245176672935486, "aqua_rat_41775": 0.8249503374099731, "aqua_rat_2630": 0.8250747919082642, "aqua_rat_38820": 0.82508784532547, "aqua_rat_45416": 0.8251186013221741, "aqua_rat_26380": 0.8252689838409424, "aqua_rat_64131": 0.8256046175956726, "aqua_rat_43064": 0.8257381916046143, "aqua_rat_23820": 0.8258086442947388, "aqua_rat_38845": 0.8260271549224854, "aqua_rat_27717": 0.8261383175849915, "aqua_rat_37185": 0.8264127373695374, "aqua_rat_22214": 0.8265751004219055, "aqua_rat_19040": 0.8267996907234192, "aqua_rat_78732": 0.8268539309501648, "aqua_rat_13853": 0.8269550204277039, "aqua_rat_31957": 0.8269657492637634, "aqua_rat_70526": 0.8271476030349731, "aqua_rat_59675": 0.8273599743843079, "aqua_rat_2147": 0.8275511264801025, "aqua_rat_54446": 0.8281233906745911, "aqua_rat_57095": 0.8284139633178711, "aqua_rat_74248": 0.8284637331962585, "aqua_rat_72437": 0.82846999168396, "aqua_rat_72210": 0.8285551071166992, "aqua_rat_73365": 0.8287041783332825, "aqua_rat_44130": 0.8288348317146301, "aqua_rat_42445": 0.828835129737854, "aqua_rat_47513": 0.8290500640869141, "aqua_rat_50942": 0.8290823698043823, "aqua_rat_72660": 0.8292160034179688, "aqua_rat_52756": 0.8296923041343689, "aqua_rat_73181": 0.829838216304779, "aqua_rat_58309": 0.8299160599708557, "aqua_rat_56715": 0.8301490545272827, "aqua_rat_7409": 0.8301908373832703, "aqua_rat_66465": 0.8302322626113892, "aqua_rat_88418": 0.8304731845855713, "aqua_rat_86468": 0.8307369351387024, "math_train_counting_and_probability_918": 0.8308359384536743, "aqua_rat_24963": 0.8311350345611572, "aqua_rat_64894": 0.8312889933586121, "aqua_rat_24776": 0.8316697478294373, "aqua_rat_12398": 0.8317359685897827, "aqua_rat_65642": 0.8319607377052307, "aqua_rat_45168": 0.8322029113769531, "aqua_rat_10102": 0.8322312235832214, "aqua_rat_34242": 0.8322745561599731, "aqua_rat_35015": 0.8323083519935608, "aqua_rat_58044": 0.8323919177055359, "aqua_rat_42177": 0.8325191140174866, "aqua_rat_779": 0.8325561285018921, "aqua_rat_53852": 0.8326780796051025, "aqua_rat_59747": 0.8327306509017944, "aqua_rat_71649": 0.8328418135643005, "aqua_rat_22507": 0.8333083391189575, "aqua_rat_80017": 0.8333933353424072, "aqua_rat_84398": 0.8339622020721436, "aqua_rat_49386": 0.8342134356498718, "aqua_rat_41506": 0.834949791431427, "aqua_rat_15548": 0.8353339433670044, "aqua_rat_16762": 0.8356637954711914, "aqua_rat_67179": 0.8357093334197998, "aqua_rat_7156": 0.8358001708984375, "aqua_rat_23582": 0.8359864354133606, "aqua_rat_42881": 0.8363660573959351, "aqua_rat_83206": 0.8363949060440063, "aqua_rat_49270": 0.8366689085960388, "aqua_rat_40137": 0.8368320465087891, "aqua_rat_55590": 0.8368408679962158, "aqua_rat_81997": 0.8369646072387695, "aqua_rat_31360": 0.8369773626327515, "aqua_rat_63254": 0.8369821906089783, "aqua_rat_48676": 0.837026059627533, "aqua_rat_78895": 0.8373681902885437, "aqua_rat_71578": 0.8373726606369019, "aqua_rat_62903": 0.8374170064926147, "aqua_rat_84957": 0.8375812768936157, "aqua_rat_31467": 0.8376171588897705, "aqua_rat_46850": 0.8377647399902344, "aqua_rat_66841": 0.8383352160453796, "aqua_rat_9713": 0.8384512662887573, "aqua_rat_25421": 0.8385233283042908, "aqua_rat_81548": 0.8386526107788086, "aqua_rat_63012": 0.838904857635498, "aqua_rat_32732": 0.8390266299247742, "aqua_rat_75780": 0.8391594886779785, "aqua_rat_13243": 0.8395812511444092, "aqua_rat_47506": 0.8398829698562622, "aqua_rat_50541": 0.8401948809623718, "aqua_rat_74695": 0.8405357599258423, "aqua_rat_78074": 0.8408654928207397, "aqua_rat_28183": 0.8411247134208679, "aqua_rat_18452": 0.8415606021881104, "aqua_rat_8673": 0.8416678309440613, "aqua_rat_72310": 0.8417210578918457, "aqua_rat_39411": 0.8419824242591858, "aqua_rat_53149": 0.842018187046051, "aqua_rat_4954": 0.842705249786377, "aqua_rat_84736": 0.8428159356117249, "aqua_rat_89302": 0.8432120084762573, "aqua_rat_37223": 0.8439009785652161, "math_test_counting_and_probability_216": 0.8441132307052612, "math_test_counting_and_probability_776": 0.8451027870178223, "aqua_rat_35292": 0.84510737657547, "aqua_rat_57693": 0.8455752730369568, "aqua_rat_28538": 0.846070408821106, "aqua_rat_11347": 0.8472515344619751, "aqua_rat_60755": 0.8474611043930054, "aqua_rat_3934": 0.8477984666824341, "aqua_rat_70861": 0.847993016242981, "aqua_rat_27914": 0.8498124480247498, "aqua_rat_79193": 0.85075843334198, "aqua_rat_73601": 0.8509311079978943, "aqua_rat_64653": 0.8514970541000366, "aqua_rat_42333": 0.8520193696022034, "aqua_rat_74651": 0.8522468209266663, "aqua_rat_81265": 0.85259610414505, "aqua_rat_30109": 0.8526206016540527, "aqua_rat_42155": 0.8536490797996521, "aqua_rat_51384": 0.8541678786277771, "aqua_rat_62645": 0.8548505306243896, "aqua_rat_87992": 0.8550669550895691, "aqua_rat_58323": 0.8562033176422119, "camel_38541": 0.8573898673057556, "aqua_rat_72708": 0.8585458993911743, "aqua_rat_13918": 0.8585613965988159, "aqua_rat_89036": 0.8597485423088074, "aqua_rat_43584": 0.8600724935531616, "aqua_rat_57246": 0.8609809875488281, "aqua_rat_35395": 0.8612203001976013, "aqua_rat_33533": 0.8621271848678589, "aqua_rat_84364": 0.8623302578926086, "aqua_rat_68198": 0.8656631708145142, "aqua_rat_35517": 0.8683751225471497, "aqua_rat_15917": 0.8686585426330566, "aqua_rat_51723": 0.869249165058136, "aqua_rat_23041": 0.8754494190216064}, "TheoremQA_xueguangma/forward_rate_1.json": {"TheoremQA_xueguangma/forward_rate_1.json": 0, "aqua_rat_67841": 0.7441951632499695, "aqua_rat_52978": 0.7443573474884033, "gsm_rft_9932": 0.7444718480110168, "aqua_rat_59668": 0.744484007358551, "aqua_rat_11824": 0.744621992111206, "aqua_rat_49908": 0.7446361184120178, "aqua_rat_255": 0.7448719143867493, "aqua_rat_19480": 0.7449487447738647, "math_test_algebra_1862": 0.744982898235321, "aqua_rat_26339": 0.7451595067977905, "aqua_rat_79904": 0.7453467845916748, "aqua_rat_28282": 0.7453793883323669, "aqua_rat_7826": 0.7454961538314819, "aqua_rat_79715": 0.745663046836853, "aqua_rat_59403": 0.7456998229026794, "aqua_rat_71142": 0.7460306286811829, "aqua_rat_15743": 0.7462024092674255, "aqua_rat_88504": 0.7462556958198547, "aqua_rat_48358": 0.7463397979736328, "gsm_rft_7180": 0.7463983297348022, "gsm_train_5941": 0.7463983297348022, "aqua_rat_28662": 0.7464725971221924, "aqua_rat_48494": 0.7464858889579773, "aqua_rat_60493": 0.7465139627456665, "math_test_algebra_2626": 0.7465320229530334, "aqua_rat_34775": 0.7467795014381409, "aqua_rat_88960": 0.7469075918197632, "aqua_rat_59": 0.7469491362571716, "aqua_rat_17404": 0.7472368478775024, "math_train_algebra_767": 0.7473808526992798, "aqua_rat_56129": 0.7474709153175354, "aqua_rat_77602": 0.7475351691246033, "aqua_rat_64914": 0.7475928068161011, "aqua_rat_49963": 0.7475937604904175, "aqua_rat_58694": 0.7476592659950256, "aqua_rat_44615": 0.7476673722267151, "aqua_rat_84357": 0.7479012608528137, "aqua_rat_87884": 0.7479792237281799, "aqua_rat_47882": 0.7480267882347107, "aqua_rat_3773": 0.7480432987213135, "aqua_rat_64976": 0.7480623722076416, "aqua_rat_53431": 0.7482720017433167, "aqua_rat_54481": 0.7483664751052856, "aqua_rat_3402": 0.7489370703697205, "aqua_rat_34698": 0.7490949630737305, "aqua_rat_87904": 0.7491635084152222, "aqua_rat_6566": 0.7492122650146484, "aqua_rat_50447": 0.7494279742240906, "aqua_rat_6679": 0.7495773434638977, "aqua_rat_44549": 0.7498704195022583, "aqua_rat_69905": 0.7499344348907471, "aqua_rat_86234": 0.7500385642051697, "aqua_rat_62528": 0.7500476837158203, "aqua_rat_13797": 0.7502694129943848, "aqua_rat_21250": 0.7507723569869995, "aqua_rat_83839": 0.7515662312507629, "aqua_rat_43060": 0.7522351145744324, "math_test_algebra_594": 0.7522894740104675, "aqua_rat_8658": 0.752600371837616, "aqua_rat_29976": 0.7527399659156799, "aqua_rat_39049": 0.7536664009094238, "aqua_rat_56852": 0.7539345026016235, "aqua_rat_46898": 0.7539375424385071, "aqua_rat_87246": 0.7539636492729187, "aqua_rat_69547": 0.7540222406387329, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7540972232818604, "aqua_rat_28883": 0.754258394241333, "aqua_rat_36598": 0.7545413970947266, "math_test_algebra_337": 0.7548675537109375, "aqua_rat_32851": 0.7551571130752563, "aqua_rat_9965": 0.7553638219833374, "aqua_rat_12533": 0.7554516792297363, "aqua_rat_16448": 0.7557532787322998, "aqua_rat_66298": 0.7559188008308411, "math_train_algebra_2306": 0.7559937834739685, "aqua_rat_735": 0.7559996843338013, "aqua_rat_64215": 0.7561209797859192, "aqua_rat_30386": 0.7562041878700256, "aqua_rat_70690": 0.7563517093658447, "aqua_rat_33006": 0.7564415335655212, "aqua_rat_68636": 0.7565113306045532, "aqua_rat_29154": 0.7570482492446899, "aqua_rat_29321": 0.7570871710777283, "aqua_rat_31334": 0.7571852207183838, "aqua_rat_42733": 0.7573725581169128, "aqua_rat_68": 0.7574763298034668, "aqua_rat_85902": 0.7575626969337463, "aqua_rat_78121": 0.7578526735305786, "aqua_rat_59098": 0.7583551406860352, "aqua_rat_20488": 0.758446216583252, "aqua_rat_37916": 0.7587780952453613, "aqua_rat_25162": 0.7588883638381958, "aqua_rat_34082": 0.7589063048362732, "aqua_rat_84309": 0.7594088912010193, "aqua_rat_869": 0.7596017718315125, "aqua_rat_15471": 0.7596504092216492, "aqua_rat_82669": 0.7598711252212524, "aqua_rat_86835": 0.7598901987075806, "aqua_rat_83656": 0.760644257068634, "aqua_rat_67076": 0.7611989378929138, "aqua_rat_38068": 0.7612525224685669, "aqua_rat_12597": 0.761528491973877, "aqua_rat_4137": 0.7615670561790466, "aqua_rat_83740": 0.7617654800415039, "math_train_algebra_369": 0.7622422575950623, "aqua_rat_57943": 0.762448787689209, "aqua_rat_75833": 0.7625381350517273, "aqua_rat_25723": 0.7627339959144592, "aqua_rat_10990": 0.763303816318512, "aqua_rat_21326": 0.7636222839355469, "TheoremQA_xueguangma/forward_price_3.json": 0.7636509537696838, "aqua_rat_33923": 0.7637298703193665, "aqua_rat_21814": 0.7641021609306335, "aqua_rat_11679": 0.7643235325813293, "aqua_rat_63322": 0.7647408843040466, "aqua_rat_59829": 0.7652281522750854, "aqua_rat_42515": 0.7653802633285522, "aqua_rat_46158": 0.7656925916671753, "aqua_rat_88758": 0.765749454498291, "aqua_rat_87589": 0.7658741474151611, "gsm_train_25622": 0.7659627199172974, "aqua_rat_47773": 0.7661687135696411, "aqua_rat_10582": 0.766279935836792, "aqua_rat_20423": 0.7663761377334595, "gsm_rft_11620": 0.7664618492126465, "aqua_rat_54664": 0.7669584155082703, "aqua_rat_51332": 0.7669999599456787, "math_test_algebra_311": 0.7672735452651978, "aqua_rat_37258": 0.7679126858711243, "math_train_algebra_957": 0.7679626941680908, "aqua_rat_68014": 0.7681925892829895, "aqua_rat_86517": 0.768294632434845, "aqua_rat_19784": 0.7683588266372681, "TheoremQA_xueguangma/forward_price_1.json": 0.7684220671653748, "aqua_rat_38900": 0.7685835361480713, "aqua_rat_88003": 0.7687314748764038, "aqua_rat_18368": 0.7688732147216797, "gsm_rft_6559": 0.7691068649291992, "aqua_rat_65964": 0.7694146633148193, "gsm_rft_5849": 0.7696138024330139, "aqua_rat_66371": 0.7696294188499451, "aqua_rat_3687": 0.7696389555931091, "aqua_rat_24052": 0.7699711918830872, "aqua_rat_61400": 0.770074725151062, "aqua_rat_64105": 0.7705841660499573, "aqua_rat_88415": 0.7710009813308716, "aqua_rat_17751": 0.7712695598602295, "aqua_rat_54028": 0.7721148133277893, "aqua_rat_62727": 0.7722355723381042, "aqua_rat_71239": 0.7736889719963074, "aqua_rat_73390": 0.7749038338661194, "aqua_rat_2257": 0.776220977306366, "aqua_rat_72794": 0.7764155268669128, "aqua_rat_28984": 0.7776673436164856, "aqua_rat_51796": 0.7776990532875061, "aqua_rat_69447": 0.7778318524360657, "aqua_rat_65963": 0.777985155582428, "aqua_rat_51100": 0.7782567143440247, "aqua_rat_15079": 0.7783637046813965, "aqua_rat_72687": 0.7785365581512451, "aqua_rat_17663": 0.7794343829154968, "aqua_rat_53336": 0.7795435786247253, "aqua_rat_78533": 0.7798333764076233, "aqua_rat_6415": 0.780027449131012, "aqua_rat_42017": 0.780148983001709, "math_train_algebra_667": 0.7803165316581726, "aqua_rat_14876": 0.7805655598640442, "aqua_rat_88174": 0.7808420062065125, "aqua_rat_33430": 0.7808465957641602, "aqua_rat_7674": 0.7823955416679382, "aqua_rat_79047": 0.7827494740486145, "aqua_rat_53568": 0.7832866907119751, "aqua_rat_40411": 0.7834786176681519, "aqua_rat_58298": 0.783750057220459, "aqua_rat_60181": 0.7839815020561218, "aqua_rat_75046": 0.784295916557312, "aqua_rat_26976": 0.7861937880516052, "aqua_rat_5641": 0.786738395690918, "aqua_rat_50660": 0.7886167764663696, "aqua_rat_63070": 0.7890633344650269, "aqua_rat_32852": 0.7910814881324768, "aqua_rat_26425": 0.7914871573448181, "aqua_rat_21626": 0.8030152916908264, "aqua_rat_46552": 0.8072370886802673, "aqua_rat_42949": 0.8082730174064636, "aqua_rat_29356": 0.808486819267273, "aqua_rat_70031": 0.811651885509491, "aqua_rat_73739": 0.8160189986228943, "aqua_rat_41963": 0.8168491125106812, "aqua_rat_1115": 0.8176076412200928, "aqua_rat_32321": 0.8188056349754333, "aqua_rat_56718": 0.8222112655639648, "aqua_rat_36461": 0.8337436318397522, "aqua_rat_75047": 0.8339234590530396, "aqua_rat_3885": 0.8415347933769226, "aqua_rat_20758": 0.8459274768829346, "aqua_rat_72737": 0.8463460206985474, "aqua_rat_46315": 0.8485124111175537, "aqua_rat_45867": 0.8546727895736694}, "TheoremQA_jianyu_xu/Binomial_6.json": {"camel_20448": 0, "camel_20619": 0, "camel_21216": 0, "camel_20407": 0, "camel_21021": 0, "camel_21227": 0, "camel_20715": 0, "camel_20336": 0, "camel_21267": 0, "camel_20266": 0, "camel_21388": 0, "camel_20930": 0, "camel_20293": 0, "camel_21528": 0, "camel_20708": 0, "camel_21530": 0, "camel_20716": 0, "camel_21034": 0, "camel_20283": 0, "camel_20903": 0, "camel_20477": 0, "camel_20397": 0, "camel_21413": 0, "camel_21567": 0, "camel_21002": 0, "camel_21553": 0, "aqua_rat_78074": 0.8005808591842651, "aqua_rat_10378": 0.8005886077880859, "aqua_rat_71578": 0.8006191253662109, "aqua_rat_40523": 0.8006270527839661, "aqua_rat_40108": 0.800675094127655, "aqua_rat_39411": 0.8008514642715454, "aqua_rat_41775": 0.800873339176178, "aqua_rat_84736": 0.8009715676307678, "aqua_rat_30648": 0.8009933829307556, "aqua_rat_8279": 0.8011156916618347, "math_train_counting_and_probability_657": 0.8011544942855835, "aqua_rat_4334": 0.8011773228645325, "aqua_rat_46137": 0.8011839389801025, "aqua_rat_53149": 0.8013916015625, "aqua_rat_15615": 0.8014415502548218, "aqua_rat_76795": 0.801474392414093, "aqua_rat_8673": 0.8015891909599304, "aqua_rat_50290": 0.8017022013664246, "aqua_rat_25421": 0.8017137050628662, "camel_38539": 0.8017280101776123, "aqua_rat_73601": 0.8018473386764526, "aqua_rat_83206": 0.801895022392273, "aqua_rat_55099": 0.8019168376922607, "math_train_counting_and_probability_444": 0.8019863963127136, "aqua_rat_22214": 0.8020177483558655, "aqua_rat_87868": 0.8020869493484497, "aqua_rat_42155": 0.8022133111953735, "aqua_rat_42333": 0.8022512793540955, "aqua_rat_62575": 0.8022909760475159, "aqua_rat_42177": 0.802348256111145, "aqua_rat_66465": 0.8028697371482849, "aqua_rat_78732": 0.8028862476348877, "aqua_rat_64131": 0.8028870224952698, "aqua_rat_78895": 0.8028891682624817, "aqua_rat_22121": 0.8030025362968445, "math_test_prealgebra_1142": 0.8030681610107422, "aqua_rat_43537": 0.8030968308448792, "math_test_counting_and_probability_86": 0.8031786680221558, "aqua_rat_88698": 0.8035793304443359, "aqua_rat_59556": 0.8036660552024841, "aqua_rat_59203": 0.8037124872207642, "aqua_rat_16920": 0.8037951588630676, "aqua_rat_77276": 0.8039180040359497, "aqua_rat_72868": 0.8041505813598633, "aqua_rat_3934": 0.804259717464447, "aqua_rat_41430": 0.8042802810668945, "camel_38493": 0.8045017123222351, "aqua_rat_17370": 0.8045594692230225, "aqua_rat_37642": 0.8045621514320374, "aqua_rat_23582": 0.8047603964805603, "aqua_rat_42445": 0.8048925399780273, "aqua_rat_77730": 0.8053357005119324, "math_train_prealgebra_1590": 0.8054319620132446, "aqua_rat_71649": 0.8055934906005859, "aqua_rat_30697": 0.8057012557983398, "aqua_rat_16166": 0.8058413863182068, "aqua_rat_63777": 0.8061621785163879, "aqua_rat_13243": 0.8062845468521118, "aqua_rat_34245": 0.8067021369934082, "aqua_rat_30109": 0.8067294359207153, "aqua_rat_69384": 0.8070709109306335, "aqua_rat_83208": 0.8071355819702148, "aqua_rat_74792": 0.8071639537811279, "aqua_rat_35395": 0.8073524832725525, "aqua_rat_35292": 0.807383120059967, "aqua_rat_5288": 0.8074185252189636, "aqua_rat_1941": 0.8076891303062439, "aqua_rat_22507": 0.80797278881073, "math_test_counting_and_probability_68": 0.8080121278762817, "aqua_rat_78224": 0.8081437945365906, "aqua_rat_60238": 0.8081981539726257, "aqua_rat_50689": 0.8082544803619385, "math_train_counting_and_probability_234": 0.8082988858222961, "aqua_rat_74995": 0.8083964586257935, "aqua_rat_44353": 0.808434784412384, "aqua_rat_85599": 0.8084631562232971, "aqua_rat_54461": 0.808531641960144, "aqua_rat_5455": 0.8091287612915039, "aqua_rat_1152": 0.80927574634552, "aqua_rat_65642": 0.8092907071113586, "aqua_rat_7035": 0.8093568682670593, "aqua_rat_27914": 0.8093642592430115, "aqua_rat_57246": 0.8097137212753296, "aqua_rat_42412": 0.8097339868545532, "aqua_rat_10102": 0.8097578287124634, "aqua_rat_35078": 0.8099420666694641, "aqua_rat_63963": 0.8100458979606628, "aqua_rat_87252": 0.8110193610191345, "aqua_rat_32732": 0.8111492991447449, "aqua_rat_18082": 0.8111695051193237, "aqua_rat_7495": 0.811351478099823, "aqua_rat_79204": 0.811413049697876, "aqua_rat_9182": 0.8115858435630798, "aqua_rat_89036": 0.8116644024848938, "aqua_rat_87992": 0.8116846084594727, "aqua_rat_67213": 0.8117195963859558, "aqua_rat_47128": 0.8117988705635071, "aqua_rat_67179": 0.8121612668037415, "aqua_rat_8436": 0.812312662601471, "aqua_rat_62903": 0.8125075101852417, "aqua_rat_13991": 0.8125950694084167, "math_train_prealgebra_133": 0.8128751516342163, "aqua_rat_32212": 0.8129327893257141, "aqua_rat_1884": 0.8129623532295227, "aqua_rat_23041": 0.8130561113357544, "aqua_rat_15917": 0.8132305145263672, "aqua_rat_35517": 0.8133015632629395, "aqua_rat_29054": 0.8135122060775757, "aqua_rat_51723": 0.8135678768157959, "aqua_rat_57253": 0.8137950897216797, "aqua_rat_36005": 0.8140503168106079, "aqua_rat_7086": 0.814052402973175, "math_train_counting_and_probability_707": 0.8143426775932312, "aqua_rat_59169": 0.8150705695152283, "aqua_rat_39790": 0.8151583671569824, "aqua_rat_52966": 0.8153904676437378, "aqua_rat_49927": 0.8155289888381958, "aqua_rat_66841": 0.8158199787139893, "aqua_rat_15090": 0.8163533806800842, "aqua_rat_42746": 0.8164833784103394, "math_train_counting_and_probability_918": 0.8168278336524963, "aqua_rat_85220": 0.8168938159942627, "aqua_rat_82038": 0.817145586013794, "aqua_rat_8404": 0.8171488046646118, "aqua_rat_43584": 0.8173341155052185, "aqua_rat_3235": 0.8175272345542908, "math_train_counting_and_probability_363": 0.8179792165756226, "aqua_rat_4626": 0.8181690573692322, "aqua_rat_60103": 0.8185372352600098, "aqua_rat_58323": 0.8188416361808777, "aqua_rat_78643": 0.8196168541908264, "aqua_rat_32683": 0.8197839856147766, "aqua_rat_52714": 0.8198020458221436, "aqua_rat_84364": 0.8199489116668701, "math_train_counting_and_probability_167": 0.8204628229141235, "aqua_rat_72537": 0.8205960988998413, "aqua_rat_33038": 0.8206554651260376, "aqua_rat_55001": 0.8206862211227417, "aqua_rat_61876": 0.8209657669067383, "aqua_rat_49784": 0.8210945129394531, "aqua_rat_74901": 0.8228508830070496, "aqua_rat_16474": 0.8231984972953796, "aqua_rat_47613": 0.8237310647964478, "aqua_rat_55602": 0.8261346220970154, "aqua_rat_29035": 0.826364278793335, "aqua_rat_56064": 0.827523410320282, "aqua_rat_87465": 0.8282532691955566, "aqua_rat_78834": 0.828276515007019, "aqua_rat_38273": 0.8284989595413208, "aqua_rat_56247": 0.8290005922317505, "aqua_rat_51352": 0.829001784324646, "aqua_rat_44093": 0.8293051719665527, "aqua_rat_15097": 0.830191433429718, "aqua_rat_1550": 0.8310539722442627, "aqua_rat_61781": 0.8314663767814636, "math_train_counting_and_probability_87": 0.8321529626846313, "aqua_rat_51656": 0.8322952389717102, "aqua_rat_76251": 0.832624077796936, "aqua_rat_67694": 0.8338949680328369, "math_test_counting_and_probability_303": 0.8343349099159241, "aqua_rat_55663": 0.8347565531730652, "aqua_rat_76030": 0.8355200290679932, "aqua_rat_48812": 0.8359413743019104, "aqua_rat_9476": 0.8381217122077942, "aqua_rat_87690": 0.8386030793190002, "math_test_counting_and_probability_389": 0.8397626280784607, "aqua_rat_70434": 0.8404210209846497, "math_train_counting_and_probability_429": 0.8433341383934021, "aqua_rat_88095": 0.8436173796653748, "aqua_rat_37852": 0.8464171886444092, "aqua_rat_71423": 0.8485671877861023, "aqua_rat_10346": 0.8536498546600342, "math_test_counting_and_probability_595": 0.856947124004364, "math_train_counting_and_probability_246": 0.8618946075439453}, "TheoremQA_elainewan/math_algebra_4_3.json": {"camel_33003": 0, "camel_33108": 0, "camel_32727": 0, "camel_32544": 0, "camel_32006": 0, "camel_32880": 0, "TheoremQA_elainewan/math_algebra_4_3.json": 0, "camel_32077": 0, "camel_26715": 0.6816259026527405, "camel_27658": 0.6816399097442627, "camel_27416": 0.6819565296173096, "camel_21282": 0.6820210814476013, "camel_27675": 0.6820394396781921, "camel_21353": 0.6820877194404602, "camel_23539": 0.6821358799934387, "camel_26802": 0.6825770139694214, "camel_27672": 0.6826076507568359, "camel_27676": 0.6826200485229492, "camel_27440": 0.6826490163803101, "camel_26860": 0.6826648712158203, "camel_27656": 0.682670533657074, "camel_27638": 0.682799220085144, "camel_26641": 0.6828550696372986, "camel_23522": 0.6829038858413696, "camel_23594": 0.68292236328125, "camel_21293": 0.6830078959465027, "camel_23530": 0.6831578016281128, "camel_26809": 0.6831940412521362, "camel_26745": 0.6832264065742493, "camel_15624": 0.6833674311637878, "camel_23585": 0.6837508678436279, "camel_26808": 0.6839526295661926, "camel_26877": 0.6839624643325806, "camel_27712": 0.683998167514801, "camel_27510": 0.6841381788253784, "camel_26714": 0.6842873692512512, "camel_23527": 0.6843630075454712, "camel_23540": 0.6843833327293396, "camel_27465": 0.6845569610595703, "camel_21313": 0.6845752000808716, "camel_23554": 0.6846635341644287, "camel_27688": 0.6847718358039856, "camel_27463": 0.685125470161438, "camel_26871": 0.6851761937141418, "camel_23598": 0.6851851344108582, "camel_27516": 0.6852219104766846, "camel_26694": 0.6854580044746399, "camel_23597": 0.6855399012565613, "camel_15676": 0.6856191754341125, "camel_26805": 0.6857280135154724, "camel_21292": 0.685760498046875, "TheoremQA_elainewan/math_algebra_2.json": 0.6858677268028259, "camel_23578": 0.6858891248703003, "camel_26834": 0.6863129734992981, "camel_47707": 0.6863757371902466, "camel_26868": 0.6867521405220032, "camel_21285": 0.6868376731872559, "camel_21280": 0.6869394183158875, "TheoremQA_elainewan/math_algebra_6.json": 0.6871572136878967, "camel_27444": 0.6872050762176514, "camel_26820": 0.6876099705696106, "camel_21330": 0.6876177191734314, "aqua_rat_33509": 0.6876310110092163, "camel_26858": 0.6878513097763062, "camel_27639": 0.6880488395690918, "camel_21339": 0.6881546974182129, "camel_21356": 0.6884006261825562, "camel_27607": 0.6884587407112122, "camel_27481": 0.6885722279548645, "camel_27410": 0.6886085867881775, "camel_23586": 0.6888535022735596, "camel_23537": 0.6888910531997681, "camel_23566": 0.6890507936477661, "camel_26875": 0.6891155242919922, "camel_27473": 0.6893815994262695, "camel_21300": 0.6897100210189819, "camel_27472": 0.6897382736206055, "camel_21306": 0.6901453733444214, "camel_23543": 0.6904056072235107, "camel_21296": 0.6904385089874268, "camel_26849": 0.690446138381958, "camel_26810": 0.6904706358909607, "camel_27477": 0.6906736493110657, "camel_27652": 0.6908156871795654, "camel_21324": 0.691580057144165, "camel_23552": 0.6918327212333679, "camel_21286": 0.6920226216316223, "camel_21333": 0.6920608878135681, "camel_21315": 0.692080557346344, "camel_23593": 0.6923906207084656, "camel_27479": 0.692410409450531, "camel_26647": 0.6925240755081177, "camel_27621": 0.6926416754722595, "camel_21287": 0.6927976608276367, "camel_26872": 0.6928171515464783, "camel_21329": 0.693070650100708, "camel_23558": 0.6933984160423279, "camel_23526": 0.6934385895729065, "camel_21351": 0.6935505867004395, "camel_26663": 0.6938319802284241, "camel_21323": 0.6942417621612549, "camel_26975": 0.6943597793579102, "camel_18943": 0.6945165991783142, "camel_21312": 0.6945732831954956, "camel_21290": 0.6949407458305359, "camel_26567": 0.6949847936630249, "camel_23546": 0.6951030492782593, "camel_27454": 0.6952940821647644, "camel_23575": 0.6954185366630554, "camel_27446": 0.6955064535140991, "camel_21355": 0.6958151459693909, "camel_27371": 0.6959444880485535, "camel_26837": 0.6959851980209351, "camel_21331": 0.6960058808326721, "camel_26733": 0.6960114240646362, "camel_26816": 0.6962407231330872, "camel_26840": 0.6963623762130737, "camel_27492": 0.6965318918228149, "camel_21307": 0.6967747807502747, "camel_21326": 0.6968523859977722, "camel_27657": 0.6969667077064514, "camel_26686": 0.6970705986022949, "camel_27629": 0.6973642706871033, "camel_21309": 0.6976394653320312, "camel_23564": 0.6979324817657471, "camel_26784": 0.6980116963386536, "camel_23569": 0.6980128884315491, "camel_21319": 0.698199987411499, "camel_23591": 0.6982946395874023, "camel_15728": 0.6983140110969543, "camel_27489": 0.6987023949623108, "camel_21305": 0.6991977095603943, "camel_21328": 0.6992229223251343, "camel_26734": 0.699813723564148, "camel_27490": 0.6998371481895447, "camel_27651": 0.6999658942222595, "camel_21295": 0.7002421021461487, "camel_21297": 0.7003189921379089, "camel_26766": 0.7004907727241516, "camel_26847": 0.7008069157600403, "camel_21284": 0.7011856436729431, "camel_27619": 0.701343297958374, "camel_27448": 0.7013872861862183, "camel_27501": 0.7015848755836487, "camel_26827": 0.701653003692627, "camel_27399": 0.7017050385475159, "camel_26828": 0.7017532587051392, "camel_27480": 0.702553927898407, "camel_21310": 0.7026259899139404, "camel_21327": 0.7026636004447937, "camel_21281": 0.7027848958969116, "camel_21344": 0.7034584879875183, "camel_21322": 0.7034990787506104, "camel_26728": 0.7035088539123535, "camel_21354": 0.7036951780319214, "camel_21325": 0.7039202451705933, "camel_27506": 0.7039887309074402, "camel_27513": 0.7043933868408203, "camel_21335": 0.7044994831085205, "camel_27487": 0.7049906849861145, "camel_27456": 0.7053557634353638, "camel_27457": 0.7054637670516968, "camel_23556": 0.7055503129959106, "camel_21340": 0.7056939005851746, "camel_27458": 0.706243634223938, "camel_21316": 0.7068127393722534, "camel_27636": 0.7069224119186401, "camel_21294": 0.7071472406387329, "camel_21311": 0.707733154296875, "camel_23549": 0.7079681158065796, "camel_21318": 0.7080889940261841, "camel_23571": 0.7084074020385742, "camel_23542": 0.7101981043815613, "camel_27670": 0.7116918563842773, "camel_21359": 0.711941659450531, "camel_21298": 0.712096095085144, "camel_27398": 0.7125039100646973, "camel_26864": 0.7153933048248291, "camel_27471": 0.7157730460166931, "camel_27469": 0.7166135907173157, "camel_21334": 0.7193138599395752, "camel_27486": 0.7194345593452454, "camel_27441": 0.7194711565971375, "camel_23525": 0.7196667194366455, "camel_27449": 0.7206956148147583, "camel_23536": 0.7207537293434143, "camel_26841": 0.720758855342865, "camel_27648": 0.7212944030761719, "camel_23523": 0.722497284412384, "camel_27627": 0.7225788831710815, "camel_27475": 0.7239864468574524, "camel_21347": 0.724191427230835, "camel_26823": 0.724835991859436, "camel_27464": 0.7261490225791931, "camel_21320": 0.7261701822280884, "camel_27634": 0.729744017124176, "camel_27667": 0.7310404777526855, "camel_27500": 0.731650173664093, "camel_21321": 0.7324750423431396, "camel_27504": 0.7372164726257324}, "TheoremQA_maxku/fourier1-FS.json": {"camel_45143": 0, "camel_44413": 0, "camel_44512": 0, "camel_45708": 0, "camel_44453": 0, "camel_44824": 0, "camel_44326": 0, "camel_44338": 0, "camel_44157": 0, "camel_44208": 0, "camel_44596": 0, "camel_45527": 0, "camel_45720": 0, "camel_44388": 0, "camel_44140": 0, "camel_44379": 0, "camel_45587": 0, "camel_44604": 0, "camel_44665": 0, "camel_44862": 0, "camel_44002": 0, "camel_45872": 0, "camel_44533": 0, "camel_44465": 0, "camel_45945": 0, "camel_44119": 0, "camel_44691": 0, "camel_44342": 0, "camel_45232": 0, "camel_44584": 0, "camel_45356": 0, "camel_45571": 0, "camel_44484": 0, "camel_44702": 0, "camel_45903": 0, "camel_44884": 0, "camel_44473": 0, "camel_44406": 0, "camel_45792": 0, "camel_44595": 0, "camel_44169": 0, "camel_44335": 0, "camel_44385": 0, "camel_44457": 0, "camel_44324": 0, "camel_44093": 0, "camel_44468": 0, "camel_44858": 0, "camel_45855": 0, "camel_44551": 0, "camel_44933": 0, "camel_44520": 0, "camel_44151": 0, "camel_44367": 0, "camel_45707": 0, "camel_45998": 0, "camel_44566": 0, "camel_44136": 0, "camel_44674": 0, "camel_44482": 0, "camel_44195": 0, "camel_45564": 0, "camel_44874": 0, "camel_44579": 0, "camel_44420": 0, "camel_45215": 0, "camel_45610": 0, "camel_44040": 0, "camel_44651": 0, "camel_44866": 0, "camel_44398": 0, "camel_44499": 0, "camel_44564": 0, "camel_44676": 0, "camel_44574": 0, "camel_45529": 0, "camel_45852": 0, "camel_44322": 0, "camel_45724": 0, "camel_45523": 0, "camel_44476": 0, "camel_45275": 0, "camel_44135": 0, "camel_45528": 0, "camel_45568": 0, "camel_45531": 0, "camel_44130": 0, "camel_45260": 0, "camel_44449": 0, "camel_44621": 0, "camel_44667": 0, "camel_44155": 0, "camel_44402": 0, "camel_44021": 0, "camel_45892": 0, "camel_45165": 0, "camel_45853": 0, "camel_45261": 0, "camel_45134": 0, "camel_45303": 0, "camel_44927": 0, "camel_44924": 0, "camel_45308": 0, "camel_45271": 0, "camel_44943": 0, "camel_44022": 0, "camel_44931": 0, "camel_44128": 0, "camel_44514": 0, "camel_45300": 0, "camel_44399": 0, "camel_45869": 0, "camel_44117": 0, "camel_44118": 0, "camel_44264": 0, "camel_45914": 0, "camel_44601": 0, "TheoremQA_maxku/fourier1-FS.json": 0, "camel_44109": 0, "camel_44103": 0, "camel_44125": 0, "camel_45236": 0, "camel_44089": 0, "camel_44909": 0, "camel_44160": 0, "camel_44104": 0, "camel_44955": 0, "camel_44429": 0, "camel_44176": 0, "camel_45585": 0, "camel_45227": 0, "camel_45911": 0, "camel_45553": 0, "camel_45910": 0, "camel_44681": 0, "camel_44097": 0, "camel_44560": 0, "camel_44923": 0, "camel_45524": 0, "camel_44914": 0, "camel_44427": 0, "camel_44925": 0, "camel_45270": 0, "camel_44137": 0, "camel_44232": 0, "camel_44099": 0, "camel_44883": 0, "camel_45526": 0, "camel_45121": 0, "camel_45238": 0, "camel_44433": 0, "camel_44127": 0, "camel_44352": 0, "camel_45575": 0, "camel_44903": 0, "camel_44015": 0, "camel_45133": 0, "camel_44088": 0, "camel_45203": 0, "camel_44204": 0, "camel_45220": 0, "camel_44325": 0, "camel_45224": 0, "camel_45079": 0, "camel_44881": 0, "camel_45919": 0, "camel_44928": 0, "camel_44442": 0, "camel_44124": 0, "camel_45644": 0, "camel_44803": 0, "camel_44605": 0, "camel_44900": 0, "camel_44802": 0, "camel_44092": 0, "camel_45207": 0, "camel_44495": 0, "camel_44526": 0, "camel_45145": 0, "camel_45561": 0, "camel_45533": 0, "camel_44918": 0, "camel_44143": 0, "camel_44082": 0, "camel_45822": 0, "camel_45281": 0, "camel_29842": 0.8349263668060303, "camel_43695": 0.8359307646751404, "camel_43469": 0.8361877799034119, "camel_43506": 0.845973789691925, "camel_43884": 0.8507925868034363, "camel_43682": 0.8514778017997742, "camel_43681": 0.8565079569816589, "camel_43729": 0.8608071208000183, "camel_43708": 0.8618473410606384, "camel_17830": 0.8622366786003113, "camel_43701": 0.8650233149528503, "camel_43705": 0.8725602030754089, "TheoremQA_maxku/fourier3-FT.json": 0.8749867677688599, "camel_43720": 0.8916516900062561}, "TheoremQA_xueguangma/forward_price_3.json": {"TheoremQA_xueguangma/forward_price_3.json": 0, "aqua_rat_42515": 0.7574965953826904, "gsm_rft_23260": 0.75771564245224, "aqua_rat_32864": 0.7580569386482239, "aqua_rat_24182": 0.7583030462265015, "gsm_rft_30907": 0.7583688497543335, "aqua_rat_23277": 0.7584255337715149, "math_test_algebra_1611": 0.7584686279296875, "gsm_rft_8605": 0.758481502532959, "aqua_rat_78719": 0.7586615085601807, "aqua_rat_29170": 0.7587277889251709, "aqua_rat_81805": 0.7588134407997131, "gsm_rft_12517": 0.7588319182395935, "aqua_rat_88415": 0.7588589787483215, "aqua_rat_73183": 0.7589228749275208, "gsm_rft_16062": 0.7590985298156738, "gsm_rft_6559": 0.7591113448143005, "camel_45738": 0.7591134905815125, "aqua_rat_27039": 0.7592312693595886, "gsm_rft_25231": 0.7592495083808899, "gsm_train_19719": 0.7592495083808899, "gsm_rft_6422": 0.7592781186103821, "aqua_rat_38068": 0.7593421339988708, "aqua_rat_14495": 0.7594268321990967, "aqua_rat_88960": 0.7597773671150208, "gsm_train_18514": 0.7597793936729431, "aqua_rat_53504": 0.7598690390586853, "aqua_rat_32958": 0.7598905563354492, "gsm_rft_11620": 0.7599115371704102, "gsm_rft_24497": 0.759952962398529, "aqua_rat_79856": 0.7600353956222534, "aqua_rat_70160": 0.7601389288902283, "aqua_rat_88003": 0.7601751089096069, "TheoremQA_xueguangma/put_call_parity_1.json": 0.7602031230926514, "gsm_rft_1672": 0.7603931427001953, "gsm_train_25622": 0.7604612112045288, "aqua_rat_65964": 0.7605499029159546, "aqua_rat_67076": 0.7605950236320496, "gsm_rft_26205": 0.7606264352798462, "gsm_rft_27542": 0.7607134580612183, "gsm_rft_28287": 0.7609133720397949, "aqua_rat_34081": 0.7610006928443909, "gsm_rft_33831": 0.7611724138259888, "aqua_rat_28984": 0.7611780166625977, "gsm_train_3010": 0.761355996131897, "aqua_rat_13797": 0.7614047527313232, "gsm_rft_10656": 0.7614912390708923, "aqua_rat_68287": 0.7615213394165039, "aqua_rat_3687": 0.761557400226593, "aqua_rat_80962": 0.7615730166435242, "aqua_rat_5907": 0.7615915536880493, "aqua_rat_17663": 0.7616329193115234, "math_test_algebra_155": 0.7616755962371826, "aqua_rat_86234": 0.7616812586784363, "aqua_rat_67841": 0.7623060941696167, "aqua_rat_33430": 0.7623674869537354, "aqua_rat_86309": 0.7624596357345581, "aqua_rat_52197": 0.7626906037330627, "gsm_rft_17795": 0.7629197835922241, "aqua_rat_38204": 0.7629836797714233, "gsm_train_12933": 0.7631299495697021, "gsm_rft_19903": 0.7631299495697021, "gsm_rft_21130": 0.7631299495697021, "gsm_rft_5849": 0.7631375193595886, "aqua_rat_30386": 0.7632570862770081, "aqua_rat_28662": 0.7634148001670837, "aqua_rat_66298": 0.7635216116905212, "math_test_algebra_990": 0.7638258934020996, "aqua_rat_62727": 0.7640737295150757, "gsm_rft_12217": 0.7646243572235107, "aqua_rat_48160": 0.7646821141242981, "aqua_rat_86835": 0.7646943926811218, "gsm_rft_7180": 0.7647396326065063, "gsm_train_5941": 0.7647396326065063, "aqua_rat_59403": 0.7648054361343384, "aqua_rat_54028": 0.764843761920929, "gsm_rft_32019": 0.7649053335189819, "gsm_rft_5946": 0.7652918100357056, "TheoremQA_xueguangma/spot_rate.json": 0.7656060457229614, "math_test_algebra_2626": 0.7656702995300293, "aqua_rat_255": 0.7658217549324036, "aqua_rat_46253": 0.7658296227455139, "math_train_algebra_667": 0.7662028074264526, "aqua_rat_66927": 0.7663713097572327, "aqua_rat_42017": 0.7665091753005981, "gsm_rft_27047": 0.7667444944381714, "math_test_algebra_594": 0.7667556405067444, "aqua_rat_47761": 0.7669031620025635, "aqua_rat_869": 0.7674152851104736, "math_train_algebra_940": 0.7674725651741028, "aqua_rat_7674": 0.767583429813385, "aqua_rat_63070": 0.7676116824150085, "aqua_rat_78121": 0.7682079672813416, "aqua_rat_31553": 0.7683290839195251, "aqua_rat_30717": 0.768603503704071, "gsm_rft_26458": 0.7686657905578613, "aqua_rat_75047": 0.7689322233200073, "aqua_rat_6679": 0.7690102458000183, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7691541314125061, "aqua_rat_69905": 0.7692897915840149, "math_train_algebra_369": 0.7695884704589844, "gsm_rft_16633": 0.7696372866630554, "aqua_rat_65963": 0.769774854183197, "aqua_rat_72794": 0.7701163291931152, "aqua_rat_60181": 0.7702143788337708, "aqua_rat_33006": 0.7703893184661865, "aqua_rat_59829": 0.7704951167106628, "aqua_rat_56852": 0.7706518173217773, "aqua_rat_28151": 0.7708699107170105, "aqua_rat_87246": 0.7712099552154541, "aqua_rat_32852": 0.7713118195533752, "aqua_rat_735": 0.7714024186134338, "aqua_rat_36240": 0.7714645862579346, "aqua_rat_36461": 0.7715842723846436, "aqua_rat_87884": 0.7720399498939514, "aqua_rat_70690": 0.7721073627471924, "aqua_rat_18368": 0.7721539735794067, "gsm_rft_33617": 0.7722740769386292, "aqua_rat_48494": 0.7726047039031982, "aqua_rat_9965": 0.7727235555648804, "math_test_algebra_337": 0.7728655934333801, "aqua_rat_41963": 0.7728797197341919, "aqua_rat_49908": 0.7729609608650208, "aqua_rat_84309": 0.7740048766136169, "aqua_rat_45867": 0.7740578651428223, "aqua_rat_68014": 0.774414598941803, "aqua_rat_37258": 0.77446448802948, "aqua_rat_8717": 0.774590015411377, "aqua_rat_10200": 0.7745901942253113, "aqua_rat_45508": 0.7747452855110168, "aqua_rat_15743": 0.7749348282814026, "aqua_rat_82278": 0.7750676870346069, "aqua_rat_10855": 0.7750999331474304, "math_test_algebra_1862": 0.7751589417457581, "aqua_rat_59199": 0.7751909494400024, "aqua_rat_46315": 0.77523273229599, "aqua_rat_29321": 0.775287389755249, "aqua_rat_3885": 0.7753743529319763, "aqua_rat_5641": 0.7759432196617126, "aqua_rat_15079": 0.7761306166648865, "aqua_rat_72737": 0.7763184905052185, "aqua_rat_87589": 0.7764372825622559, "aqua_rat_10582": 0.776785671710968, "aqua_rat_57943": 0.7770196795463562, "aqua_rat_73390": 0.7773370146751404, "aqua_rat_51100": 0.7773835062980652, "gsm_rft_287": 0.7780560851097107, "gsm_train_17061": 0.7780560851097107, "gsm_rft_3173": 0.7780560851097107, "aqua_rat_66371": 0.778272807598114, "gsm_rft_9014": 0.7783276438713074, "math_test_algebra_311": 0.7785617113113403, "aqua_rat_29356": 0.7786807417869568, "aqua_rat_28883": 0.778746485710144, "aqua_rat_83740": 0.7787923812866211, "aqua_rat_16448": 0.7788264751434326, "aqua_rat_63322": 0.7790384888648987, "aqua_rat_26022": 0.7791060209274292, "gsm_rft_11804": 0.7791256308555603, "aqua_rat_75833": 0.7792271971702576, "aqua_rat_64914": 0.7792845368385315, "gsm_rft_15334": 0.77961266040802, "gsm_train_6037": 0.77961266040802, "gsm_rft_33659": 0.7800427675247192, "aqua_rat_74243": 0.7804809212684631, "aqua_rat_47773": 0.7806670665740967, "aqua_rat_15556": 0.7808241248130798, "aqua_rat_10990": 0.7811166644096375, "aqua_rat_33923": 0.781585156917572, "aqua_rat_6634": 0.7826060056686401, "aqua_rat_70031": 0.7827669978141785, "aqua_rat_46898": 0.7827891707420349, "gsm_rft_19766": 0.7832133173942566, "aqua_rat_20758": 0.7832995653152466, "gsm_train_34036": 0.7835569381713867, "gsm_rft_30946": 0.7835569381713867, "aqua_rat_85902": 0.7840256094932556, "aqua_rat_71239": 0.7841408848762512, "gsm_rft_20212": 0.7845855951309204, "aqua_rat_29154": 0.7848417162895203, "aqua_rat_73739": 0.7849953174591064, "aqua_rat_32321": 0.7850181460380554, "aqua_rat_46552": 0.7859115600585938, "gsm_rft_7096": 0.7860572338104248, "aqua_rat_11679": 0.7878713607788086, "gsm_rft_6203": 0.7894806861877441, "aqua_rat_79047": 0.7899124622344971, "gsm_train_30707": 0.7905165553092957, "gsm_rft_22572": 0.7906410694122314, "aqua_rat_78533": 0.7908740043640137, "gsm_rft_20456": 0.7911825776100159, "aqua_rat_56718": 0.7921665906906128, "camel_37735": 0.7929140329360962, "aqua_rat_84306": 0.7930594682693481, "aqua_rat_50660": 0.7930657863616943, "aqua_rat_40411": 0.7942379713058472, "aqua_rat_1115": 0.7959875464439392, "aqua_rat_26425": 0.7986606955528259, "TheoremQA_xueguangma/forward_price_2.json": 0.8097030520439148, "TheoremQA_xueguangma/forward_price_1.json": 0.8100654482841492}, "TheoremQA_xueguangma/intermediate_value_theorem.json": {"camel_7254": 0, "camel_7020": 0, "camel_7276": 0, "camel_6440": 0, "camel_7128": 0, "camel_6999": 0, "camel_6993": 0, "camel_6971": 0, "camel_7216": 0, "camel_7270": 0, "camel_7234": 0, "camel_6309": 0, "camel_7159": 0, "camel_6166": 0, "camel_7028": 0, "camel_6966": 0, "camel_7161": 0, "camel_7260": 0, "camel_7024": 0, "camel_7018": 0, "camel_7211": 0, "camel_7202": 0, "camel_6975": 0, "camel_7208": 0, "camel_7014": 0, "camel_6962": 0, "camel_6437": 0, "camel_6978": 0, "camel_7261": 0, "camel_7224": 0, "camel_7033": 0, "camel_6964": 0, "camel_7005": 0, "camel_7227": 0, "camel_6992": 0, "camel_7012": 0, "camel_7029": 0, "camel_7267": 0, "camel_6988": 0, "camel_7210": 0, "camel_7266": 0, "camel_6969": 0, "camel_7206": 0, "camel_7031": 0, "camel_7003": 0, "camel_7023": 0, "camel_7247": 0, "camel_6985": 0, "camel_7221": 0, "camel_7138": 0, "camel_7272": 0, "camel_7215": 0, "camel_7257": 0, "camel_7015": 0, "camel_7025": 0, "camel_7232": 0, "camel_7019": 0, "camel_7250": 0, "camel_7124": 0, "camel_7233": 0, "camel_7231": 0, "camel_7016": 0, "camel_7262": 0, "camel_6984": 0, "camel_7229": 0, "camel_7244": 0, "camel_7204": 0, "camel_7035": 0, "camel_7007": 0, "camel_7214": 0, "camel_6981": 0, "camel_7259": 0, "camel_7205": 0, "camel_6972": 0, "camel_7273": 0, "camel_7256": 0, "camel_6990": 0, "camel_7248": 0, "camel_6976": 0, "camel_7226": 0, "camel_7223": 0, "camel_7032": 0, "camel_6417": 0, "camel_7149": 0, "camel_7238": 0, "camel_6466": 0, "camel_7160": 0, "camel_6986": 0, "camel_7277": 0, "camel_7251": 0, "camel_7030": 0, "camel_7236": 0, "camel_7011": 0, "camel_6987": 0, "camel_7278": 0, "camel_7268": 0, "camel_6974": 0, "camel_7263": 0, "camel_7209": 0, "camel_6193": 0, "camel_6994": 0, "camel_7230": 0, "camel_7237": 0, "camel_7275": 0, "camel_6979": 0, "camel_6449": 0, "camel_7013": 0, "camel_7212": 0, "camel_7218": 0, "camel_7269": 0, "camel_7252": 0, "camel_7235": 0, "aqua_rat_76637": 0.7458991408348083, "aqua_rat_5634": 0.746090292930603, "gsm_train_31894": 0.7461113333702087, "camel_41935": 0.746216893196106, "camel_41821": 0.7463224530220032, "camel_18784": 0.7464158535003662, "camel_39908": 0.7464602589607239, "camel_38162": 0.7465433478355408, "aqua_rat_23895": 0.7466423511505127, "aqua_rat_61898": 0.7467363476753235, "camel_38109": 0.7473412156105042, "camel_38894": 0.748291552066803, "camel_38187": 0.7484074234962463, "camel_39050": 0.7485530972480774, "camel_39058": 0.7485554218292236, "camel_41950": 0.7492151260375977, "camel_38950": 0.7492677569389343, "camel_39076": 0.7497824430465698, "camel_40882": 0.7503237128257751, "camel_40788": 0.7507501244544983, "camel_5016": 0.7507913112640381, "camel_41170": 0.7508703470230103, "aqua_rat_72162": 0.751510739326477, "aqua_rat_40752": 0.7522370219230652, "camel_39861": 0.7523273229598999, "aqua_rat_31829": 0.7523696422576904, "camel_39085": 0.7525652050971985, "camel_38909": 0.7532110214233398, "camel_38892": 0.7532463073730469, "camel_38237": 0.7535561323165894, "camel_38193": 0.7540849447250366, "math_test_prealgebra_1108": 0.7545962929725647, "aqua_rat_8453": 0.7546083331108093, "camel_39106": 0.7552686333656311, "camel_38169": 0.7553765773773193, "camel_38088": 0.7557641863822937, "aqua_rat_27725": 0.7558422088623047, "aqua_rat_47425": 0.7559031844139099, "aqua_rat_33621": 0.75643390417099, "camel_39301": 0.7566998600959778, "camel_41954": 0.7570022940635681, "camel_40945": 0.7576608061790466, "camel_38221": 0.7576693892478943, "camel_39319": 0.7577762007713318, "aqua_rat_48488": 0.7580548524856567, "camel_1708": 0.758179783821106, "aqua_rat_45182": 0.7582030296325684, "camel_39486": 0.758530855178833, "aqua_rat_3551": 0.7586543560028076, "camel_39483": 0.7599029541015625, "aqua_rat_11436": 0.7599402070045471, "aqua_rat_2333": 0.7605235576629639, "aqua_rat_53929": 0.760689377784729, "aqua_rat_57946": 0.7611860632896423, "camel_41712": 0.7614942789077759, "camel_41997": 0.7626104950904846, "camel_39457": 0.7632184028625488, "camel_18923": 0.7636325359344482, "aqua_rat_42779": 0.7646083831787109, "camel_1757": 0.7648960947990417, "camel_39343": 0.765598475933075, "camel_1733": 0.7657697796821594, "camel_39314": 0.7657877802848816, "aqua_rat_44312": 0.7659803628921509, "camel_38938": 0.7661271095275879, "camel_39296": 0.7661811113357544, "camel_1702": 0.7665828466415405, "camel_28147": 0.76752108335495, "camel_1565": 0.7675772309303284, "aqua_rat_52932": 0.7676114439964294, "aqua_rat_66786": 0.7677221298217773, "camel_39108": 0.7687268853187561, "camel_39355": 0.7691764831542969, "camel_39104": 0.7698380947113037, "camel_38197": 0.7698835134506226, "camel_41853": 0.7706098556518555, "camel_40760": 0.7720535397529602, "camel_41417": 0.7732619047164917, "camel_39323": 0.7736307382583618, "camel_39359": 0.77532559633255, "camel_41967": 0.7768368721008301, "TheoremQA_xueguangma/rolle_theorem.json": 0.778547465801239, "camel_39357": 0.778685986995697, "camel_39448": 0.7840766906738281, "aqua_rat_16683": 0.7842239141464233, "aqua_rat_11769": 0.7846475839614868, "camel_18139": 0.7865650653839111, "camel_39466": 0.7909334301948547}, "TheoremQA_mingyin/Limit-of-sequence2.json": {"TheoremQA_mingyin/Limit-of-sequence2.json": 0, "camel_20252": 0.6522834300994873, "aqua_rat_16733": 0.652363657951355, "aqua_rat_49275": 0.6524437069892883, "camel_30685": 0.6524571776390076, "camel_30927": 0.6525407433509827, "aqua_rat_4387": 0.6525664925575256, "camel_10726": 0.652685284614563, "camel_10941": 0.6527503728866577, "aqua_rat_5650": 0.6527519822120667, "camel_21383": 0.6527866125106812, "camel_10321": 0.652812659740448, "aqua_rat_13439": 0.6528748273849487, "camel_11002": 0.6530046463012695, "camel_10911": 0.6530663371086121, "camel_37545": 0.6530957221984863, "camel_10929": 0.6532652974128723, "aqua_rat_65264": 0.65329509973526, "aqua_rat_53659": 0.6533229351043701, "camel_10351": 0.6533849835395813, "camel_31323": 0.6535052061080933, "camel_8369": 0.6536250114440918, "camel_31702": 0.6536306142807007, "camel_10380": 0.6536614298820496, "camel_30948": 0.6537903547286987, "aqua_rat_4332": 0.6538189649581909, "camel_11312": 0.6538295745849609, "aqua_rat_9157": 0.6539801955223083, "math_test_prealgebra_1135": 0.6539903879165649, "camel_10950": 0.6542215347290039, "camel_11161": 0.6542510986328125, "camel_10784": 0.654276430606842, "camel_10673": 0.6543177366256714, "aqua_rat_2286": 0.6545333862304688, "aqua_rat_80797": 0.6547208428382874, "camel_13773": 0.6549174189567566, "aqua_rat_54033": 0.6549602746963501, "camel_10730": 0.6549778580665588, "aqua_rat_62871": 0.6549986004829407, "aqua_rat_68160": 0.6550447344779968, "aqua_rat_50924": 0.6550531983375549, "aqua_rat_60681": 0.6550580263137817, "camel_10734": 0.6551908254623413, "camel_11318": 0.655221700668335, "camel_28502": 0.6554632186889648, "aqua_rat_11117": 0.6554878354072571, "camel_11722": 0.6554985046386719, "camel_37502": 0.6555056571960449, "camel_9582": 0.6555529236793518, "aqua_rat_37996": 0.6557292342185974, "aqua_rat_6261": 0.6558085680007935, "aqua_rat_30276": 0.6559221148490906, "camel_10393": 0.6560835242271423, "camel_10854": 0.6560991406440735, "camel_31842": 0.6562047600746155, "camel_11989": 0.6562265157699585, "aqua_rat_23642": 0.6563258171081543, "camel_16044": 0.656385064125061, "aqua_rat_18530": 0.656502366065979, "camel_30886": 0.6565291285514832, "camel_10323": 0.6565800905227661, "camel_11737": 0.6566385626792908, "camel_8355": 0.6566534638404846, "aqua_rat_73666": 0.6566910147666931, "camel_11765": 0.6566999554634094, "camel_11230": 0.6568160057067871, "camel_10800": 0.6568226218223572, "camel_11760": 0.6568403244018555, "aqua_rat_73092": 0.6568765044212341, "aqua_rat_47013": 0.6570507287979126, "aqua_rat_2274": 0.6570627093315125, "camel_11227": 0.6571586728096008, "aqua_rat_5000": 0.6572356820106506, "camel_10813": 0.6573976874351501, "camel_42013": 0.6574944853782654, "camel_31915": 0.6577333807945251, "aqua_rat_52143": 0.6577863693237305, "camel_10839": 0.6578184366226196, "aqua_rat_26864": 0.6578701734542847, "camel_8351": 0.6579048037528992, "aqua_rat_13223": 0.6580803990364075, "aqua_rat_60978": 0.658176839351654, "camel_11211": 0.6582154035568237, "camel_30342": 0.6583099961280823, "camel_10334": 0.6583468317985535, "aqua_rat_67564": 0.6586054563522339, "camel_27951": 0.6587475538253784, "camel_11173": 0.6588564515113831, "aqua_rat_80404": 0.6589311361312866, "camel_11574": 0.6590991020202637, "camel_30093": 0.6592198610305786, "camel_11691": 0.6592423915863037, "aqua_rat_65549": 0.659321129322052, "aqua_rat_1671": 0.6594936847686768, "camel_11607": 0.6595607399940491, "camel_11853": 0.6596118807792664, "camel_30338": 0.6597406268119812, "camel_30887": 0.6597433686256409, "aqua_rat_69735": 0.6597521305084229, "camel_8398": 0.6598543524742126, "camel_31057": 0.6602241396903992, "aqua_rat_61431": 0.6605005264282227, "camel_10375": 0.6610223054885864, "camel_30339": 0.6611965894699097, "aqua_rat_68585": 0.6614077091217041, "camel_11464": 0.6615918874740601, "camel_37414": 0.6616702079772949, "camel_9540": 0.6619748473167419, "aqua_rat_79822": 0.6621893644332886, "camel_10320": 0.6622090935707092, "camel_11113": 0.6622395515441895, "camel_11074": 0.6622936725616455, "camel_11250": 0.6628262996673584, "camel_11240": 0.6628332734107971, "camel_8361": 0.6629403829574585, "aqua_rat_36422": 0.6629530787467957, "camel_8743": 0.6632988452911377, "camel_10395": 0.663308322429657, "aqua_rat_80474": 0.6633898019790649, "camel_31061": 0.6635064482688904, "camel_31984": 0.6635847091674805, "camel_38527": 0.6635943055152893, "camel_11202": 0.6636973023414612, "camel_20501": 0.6638960838317871, "camel_11748": 0.6639766097068787, "camel_11526": 0.6640132665634155, "camel_11206": 0.6641953587532043, "camel_10743": 0.6642009615898132, "aqua_rat_31892": 0.6643654704093933, "camel_10047": 0.6645848155021667, "camel_11716": 0.6646578907966614, "camel_10378": 0.6648243069648743, "camel_11459": 0.6650497913360596, "aqua_rat_19055": 0.6653575897216797, "camel_20433": 0.66583651304245, "camel_11174": 0.6659132242202759, "camel_30889": 0.6660194396972656, "camel_10005": 0.6660485863685608, "aqua_rat_69403": 0.6662565469741821, "aqua_rat_73910": 0.6663315892219543, "camel_30354": 0.6666474342346191, "camel_10855": 0.6667815446853638, "camel_11570": 0.6669121980667114, "aqua_rat_82861": 0.66730797290802, "camel_11707": 0.6674054265022278, "camel_11452": 0.6674222350120544, "aqua_rat_29787": 0.6678251624107361, "aqua_rat_12020": 0.6678783893585205, "camel_10046": 0.6679895520210266, "camel_28521": 0.6682229042053223, "camel_11529": 0.6683720946311951, "camel_11751": 0.6685751676559448, "aqua_rat_88648": 0.6697112321853638, "aqua_rat_22137": 0.6705144643783569, "camel_11220": 0.6707826852798462, "camel_11226": 0.6708918809890747, "aqua_rat_50724": 0.6716042160987854, "aqua_rat_47209": 0.6716304421424866, "camel_10756": 0.6719915866851807, "camel_11273": 0.6727821826934814, "aqua_rat_44801": 0.6729925274848938, "camel_10027": 0.6730347275733948, "camel_30374": 0.6734956502914429, "camel_31084": 0.6736565232276917, "camel_31880": 0.6738908290863037, "aqua_rat_16186": 0.6739397048950195, "camel_10346": 0.6740779280662537, "camel_37514": 0.6744345426559448, "camel_11328": 0.6751203536987305, "camel_11841": 0.675281822681427, "aqua_rat_57169": 0.6759601831436157, "aqua_rat_66546": 0.6760756373405457, "camel_11579": 0.6766363978385925, "camel_37705": 0.6769465208053589, "aqua_rat_68877": 0.6769919395446777, "aqua_rat_62672": 0.6770683526992798, "camel_11552": 0.6772798299789429, "aqua_rat_61618": 0.677578866481781, "camel_18301": 0.677778959274292, "aqua_rat_59407": 0.6778231263160706, "camel_11781": 0.6782203316688538, "aqua_rat_69628": 0.6785171031951904, "aqua_rat_47520": 0.6785314083099365, "camel_11276": 0.6787698268890381, "camel_30372": 0.6789095401763916, "aqua_rat_260": 0.6791173219680786, "camel_11628": 0.6792630553245544, "camel_49051": 0.6796726584434509, "camel_30952": 0.6808773279190063, "camel_31759": 0.6811780333518982, "camel_11562": 0.6815564632415771, "math_test_prealgebra_754": 0.6837586164474487, "camel_11223": 0.6839334964752197, "camel_8368": 0.6908801198005676, "camel_10771": 0.6918474435806274, "camel_11271": 0.7028490304946899, "camel_11523": 0.7061358690261841, "camel_20653": 0.708209753036499, "aqua_rat_59305": 0.7121871113777161, "TheoremQA_mingyin/Fundamental-Theorem-of-Calculus2.json": 0.7376102209091187}, "TheoremQA_elainewan/math_abstact_algebra_7_3.json": {"camel_32977": 0, "camel_32855": 0, "camel_33376": 0, "camel_32077": 0, "camel_32286": 0, "camel_33137": 0, "camel_32789": 0, "camel_32796": 0, "camel_33051": 0, "camel_32255": 0, "camel_33509": 0, "camel_32485": 0, "camel_32578": 0, "camel_32942": 0, "camel_32508": 0, "camel_33834": 0, "camel_32999": 0, "camel_32927": 0, "camel_32979": 0, "camel_33943": 0, "camel_32852": 0, "camel_33312": 0, "camel_32777": 0, "camel_32526": 0, "camel_33595": 0, "camel_32994": 0, "camel_33315": 0, "camel_33154": 0, "camel_33593": 0, "camel_33538": 0, "camel_32912": 0, "camel_33657": 0, "camel_33071": 0, "camel_32544": 0, "camel_33511": 0, "camel_33316": 0, "camel_32797": 0, "camel_32072": 0, "camel_33159": 0, "camel_32857": 0, "camel_33733": 0, "camel_33739": 0, "camel_32582": 0, "camel_33512": 0, "camel_33382": 0, "camel_32787": 0, "camel_32900": 0, "camel_32869": 0, "camel_33448": 0, "camel_32909": 0, "camel_33113": 0, "camel_32729": 0, "camel_33140": 0, "camel_32992": 0, "camel_33019": 0, "camel_32904": 0, "camel_33069": 0, "camel_32860": 0, "camel_33170": 0, "camel_33411": 0, "camel_33175": 0, "camel_32791": 0, "camel_33191": 0, "camel_33141": 0, "camel_33417": 0, "camel_32515": 0, "camel_32600": 0, "camel_33452": 0, "camel_32531": 0, "camel_33580": 0, "camel_32052": 0, "camel_32747": 0, "camel_33160": 0, "camel_33480": 0, "camel_32487": 0, "camel_33449": 0, "camel_33156": 0, "camel_33713": 0, "camel_33073": 0, "camel_32761": 0, "camel_33475": 0, "camel_33463": 0, "camel_32488": 0, "camel_33481": 0, "camel_33397": 0, "camel_33625": 0, "camel_32858": 0, "camel_32680": 0, "camel_33047": 0, "camel_32605": 0, "camel_32945": 0, "camel_33854": 0, "camel_33224": 0, "camel_33818": 0, "camel_32598": 0, "camel_33730": 0, "camel_32608": 0, "camel_33344": 0, "camel_33705": 0, "camel_33192": 0, "camel_32955": 0, "camel_33710": 0, "camel_32953": 0, "camel_33446": 0, "camel_33747": 0, "camel_33457": 0, "camel_33027": 0, "camel_32995": 0, "camel_32623": 0, "camel_33050": 0, "camel_33138": 0, "camel_33082": 0, "camel_32944": 0, "camel_33501": 0, "camel_33013": 0, "camel_33171": 0, "camel_32906": 0, "camel_33435": 0, "camel_33970": 0, "camel_32750": 0, "camel_32769": 0, "camel_33091": 0, "camel_32824": 0, "camel_32026": 0, "camel_32851": 0, "camel_33150": 0, "camel_32804": 0, "camel_33941": 0, "camel_32541": 0, "camel_33070": 0, "camel_32786": 0, "camel_33325": 0, "camel_33838": 0, "camel_33497": 0, "camel_33284": 0, "camel_33453": 0, "camel_33930": 0, "camel_32751": 0, "camel_32529": 0, "camel_32835": 0, "camel_32781": 0, "camel_33467": 0, "camel_33387": 0, "camel_33727": 0, "camel_32928": 0, "camel_32886": 0, "camel_32802": 0, "camel_32766": 0, "camel_33824": 0, "camel_32827": 0, "camel_33003": 0, "camel_33148": 0, "camel_32967": 0, "camel_33129": 0, "camel_32973": 0, "camel_33748": 0, "camel_33618": 0, "camel_32634": 0, "camel_32643": 0, "camel_33755": 0, "camel_32885": 0, "camel_33968": 0, "camel_33848": 0, "camel_33598": 0, "camel_33694": 0, "camel_32741": 0, "camel_33736": 0, "camel_33529": 0, "camel_33701": 0, "camel_33981": 0, "TheoremQA_elainewan/math_abstact_algebra_7_3.json": 0, "camel_32533": 0, "camel_32612": 0, "camel_33025": 0, "camel_33513": 0, "camel_33351": 0, "camel_32775": 0, "camel_33470": 0, "camel_33832": 0, "camel_33936": 0, "camel_33462": 0, "camel_33517": 0, "camel_33596": 0, "camel_32493": 0, "camel_33495": 0, "camel_33749": 0, "camel_33456": 0, "camel_33757": 0, "camel_33533": 0, "camel_32580": 0, "camel_33947": 0, "camel_32849": 0, "camel_33090": 0, "camel_32792": 0, "camel_33530": 0, "camel_32864": 0, "camel_33944": 0, "camel_33704": 0, "camel_33750": 0, "TheoremQA_elainewan/math_abstact_algebra_7_8.json": 0.837053120136261}, "TheoremQA_tonyxia/maxplanar1.json": {"camel_21129": 0, "camel_23367": 0, "camel_22575": 0, "camel_22943": 0, "camel_23383": 0, "camel_23130": 0, "camel_23392": 0, "camel_22902": 0, "camel_22824": 0, "camel_23794": 0, "camel_23160": 0, "camel_23140": 0, "camel_22157": 0, "camel_21794": 0, "camel_22381": 0, "camel_22937": 0, "camel_22359": 0, "camel_21780": 0, "camel_23414": 0, "camel_23167": 0, "camel_22356": 0, "camel_22322": 0, "camel_22443": 0, "camel_22801": 0, "camel_22387": 0, "camel_21784": 0, "camel_23431": 0, "camel_21100": 0, "camel_23131": 0, "camel_22328": 0, "camel_22378": 0, "camel_21179": 0, "camel_22386": 0, "camel_22946": 0, "camel_22375": 0, "camel_23386": 0, "camel_21123": 0, "camel_22574": 0, "camel_21057": 0, "camel_23376": 0, "camel_23122": 0, "camel_22879": 0, "camel_23170": 0, "camel_23306": 0, "camel_22373": 0, "camel_23149": 0, "camel_22887": 0, "camel_22422": 0, "camel_22823": 0, "camel_23153": 0, "camel_22805": 0, "camel_21084": 0, "camel_21113": 0, "camel_22379": 0, "camel_21065": 0, "camel_23418": 0, "camel_23157": 0, "camel_22364": 0, "camel_22413": 0, "camel_23389": 0, "camel_23328": 0, "camel_22949": 0, "camel_22371": 0, "camel_22580": 0, "camel_23182": 0, "camel_22398": 0, "camel_23408": 0, "camel_22335": 0, "camel_23146": 0, "camel_21831": 0, "camel_22392": 0, "camel_23994": 0, "camel_23402": 0, "camel_21800": 0, "camel_22320": 0, "camel_22939": 0, "camel_23363": 0, "camel_23374": 0, "camel_22331": 0, "camel_23154": 0, "camel_23378": 0, "camel_22812": 0, "camel_23137": 0, "camel_23187": 0, "camel_23364": 0, "camel_21072": 0, "camel_23156": 0, "camel_22352": 0, "camel_22327": 0, "camel_22573": 0, "camel_23151": 0, "camel_23423": 0, "camel_23180": 0, "camel_22362": 0, "camel_23400": 0, "camel_21116": 0, "camel_23425": 0, "camel_22910": 0, "camel_23135": 0, "camel_23141": 0, "camel_23372": 0, "camel_23995": 0, "camel_21083": 0, "camel_21768": 0, "camel_23134": 0, "camel_23934": 0, "camel_22867": 0, "camel_23403": 0, "camel_22338": 0, "camel_23190": 0, "camel_23199": 0, "camel_21098": 0, "camel_23394": 0, "camel_23196": 0, "camel_23148": 0, "camel_23198": 0, "camel_22360": 0, "camel_23174": 0, "camel_22396": 0, "camel_22849": 0, "camel_22927": 0, "camel_23189": 0, "camel_23155": 0, "camel_23144": 0, "camel_22866": 0, "camel_22393": 0, "camel_23181": 0, "camel_22369": 0, "camel_22808": 0, "camel_22333": 0, "camel_23188": 0, "camel_22916": 0, "camel_23172": 0, "camel_22383": 0, "camel_23427": 0, "camel_22599": 0, "camel_23161": 0, "camel_22418": 0, "camel_23424": 0, "camel_22391": 0, "camel_22838": 0, "camel_23404": 0, "camel_21044": 0, "camel_22347": 0, "camel_21133": 0, "camel_23395": 0, "camel_22912": 0, "camel_22345": 0, "camel_23391": 0, "camel_23132": 0, "camel_23138": 0, "camel_23422": 0, "camel_23165": 0, "camel_23430": 0, "camel_23128": 0, "camel_23977": 0, "camel_23177": 0, "camel_21818": 0, "camel_23393": 0, "camel_22329": 0, "camel_23124": 0, "camel_22853": 0, "camel_23193": 0, "camel_21176": 0, "camel_23369": 0, "camel_22863": 0, "camel_21107": 0, "camel_22862": 0, "camel_23183": 0, "camel_23159": 0, "camel_23175": 0, "camel_23382": 0, "camel_23147": 0, "camel_23150": 0, "camel_23168": 0, "camel_23123": 0, "camel_23432": 0, "camel_23173": 0, "camel_23191": 0, "camel_23145": 0, "camel_23176": 0, "camel_23158": 0, "camel_23195": 0, "camel_23163": 0, "camel_23166": 0, "camel_23179": 0, "camel_23162": 0, "camel_23126": 0, "camel_23164": 0, "camel_22170": 0, "camel_18365": 0.7835761308670044, "aqua_rat_36545": 0.785230278968811, "math_train_prealgebra_350": 0.7896952033042908, "aqua_rat_54929": 0.7917565107345581, "aqua_rat_76009": 0.7952167987823486, "aqua_rat_44831": 0.798097550868988, "aqua_rat_70645": 0.8024446368217468, "camel_19957": 0.8086656332015991, "aqua_rat_40504": 0.8149341344833374, "aqua_rat_25794": 0.8194239139556885}, "TheoremQA_jianyu_xu/Multinomial_6.json": {"camel_21418": 0, "camel_21534": 0, "camel_20860": 0, "camel_21219": 0, "camel_20317": 0, "camel_21530": 0, "camel_20246": 0, "camel_21022": 0, "camel_20818": 0, "camel_21002": 0, "camel_20549": 0, "camel_21253": 0, "camel_20848": 0, "camel_20410": 0, "camel_20856": 0, "camel_20578": 0, "camel_20614": 0, "camel_21267": 0, "camel_21117": 0, "camel_20487": 0, "camel_20903": 0, "camel_20863": 0, "camel_20397": 0, "camel_20272": 0, "camel_20269": 0, "camel_20998": 0, "camel_21528": 0, "camel_21379": 0, "camel_20466": 0, "camel_20244": 0, "camel_20287": 0, "camel_21261": 0, "camel_20336": 0, "camel_20598": 0, "camel_20802": 0, "camel_20414": 0, "camel_20257": 0, "camel_20302": 0, "camel_20623": 0, "camel_20973": 0, "camel_20813": 0, "camel_20844": 0, "camel_20611": 0, "camel_21386": 0, "camel_21039": 0, "camel_20514": 0, "camel_20867": 0, "camel_20022": 0, "camel_20849": 0, "camel_20946": 0, "camel_20309": 0, "camel_20312": 0, "camel_21034": 0, "camel_20447": 0, "camel_20462": 0, "camel_20656": 0, "camel_20297": 0, "camel_20996": 0, "camel_21400": 0, "camel_21567": 0, "camel_20310": 0, "camel_20248": 0, "camel_20499": 0, "camel_20477": 0, "camel_21021": 0, "camel_21050": 0, "camel_20930": 0, "camel_21028": 0, "camel_21808": 0, "camel_20619": 0, "aqua_rat_61326": 0.8214255571365356, "math_test_counting_and_probability_86": 0.8214361667633057, "aqua_rat_15615": 0.8214818239212036, "aqua_rat_13243": 0.821566104888916, "aqua_rat_39638": 0.8215665817260742, "aqua_rat_80161": 0.8216281533241272, "aqua_rat_30109": 0.8217257261276245, "aqua_rat_89036": 0.8219099640846252, "aqua_rat_67749": 0.8220070600509644, "aqua_rat_78224": 0.8225076198577881, "aqua_rat_52714": 0.8225327730178833, "aqua_rat_86063": 0.8226384520530701, "math_train_counting_and_probability_657": 0.8226763010025024, "aqua_rat_50641": 0.8228343725204468, "aqua_rat_87327": 0.822935938835144, "math_test_counting_and_probability_216": 0.8229566812515259, "math_train_counting_and_probability_707": 0.8229924440383911, "aqua_rat_68198": 0.8230080604553223, "aqua_rat_39610": 0.8232554793357849, "aqua_rat_21240": 0.8233615756034851, "aqua_rat_87992": 0.82341068983078, "aqua_rat_43584": 0.8235180377960205, "aqua_rat_58044": 0.8235293626785278, "aqua_rat_18901": 0.823734700679779, "aqua_rat_210": 0.8238564133644104, "aqua_rat_88325": 0.8241738677024841, "aqua_rat_9762": 0.8243151903152466, "aqua_rat_64653": 0.8243549466133118, "aqua_rat_63836": 0.8243932127952576, "aqua_rat_58323": 0.8247194886207581, "math_train_counting_and_probability_375": 0.8247613310813904, "aqua_rat_8627": 0.8248831629753113, "math_test_counting_and_probability_1005": 0.8252622485160828, "aqua_rat_5455": 0.8255997896194458, "aqua_rat_575": 0.8256095051765442, "aqua_rat_4334": 0.8257914781570435, "aqua_rat_15927": 0.8257948160171509, "aqua_rat_35292": 0.8259158730506897, "aqua_rat_62261": 0.8264297842979431, "aqua_rat_10378": 0.8264678120613098, "aqua_rat_85599": 0.8264891505241394, "aqua_rat_87252": 0.8264978528022766, "aqua_rat_30172": 0.8265334963798523, "aqua_rat_72582": 0.8265404105186462, "aqua_rat_43512": 0.826568067073822, "aqua_rat_5288": 0.8267021179199219, "aqua_rat_1152": 0.8268144726753235, "aqua_rat_42061": 0.8268263936042786, "aqua_rat_41861": 0.8272005915641785, "aqua_rat_13369": 0.8275554180145264, "aqua_rat_74901": 0.8275664448738098, "aqua_rat_77698": 0.8279082775115967, "aqua_rat_42412": 0.8279131650924683, "aqua_rat_89175": 0.8280603885650635, "aqua_rat_4294": 0.8280760049819946, "math_train_counting_and_probability_167": 0.8281950950622559, "aqua_rat_3934": 0.8282119035720825, "aqua_rat_57767": 0.8284828066825867, "aqua_rat_51656": 0.828670859336853, "aqua_rat_76251": 0.8287251591682434, "aqua_rat_34205": 0.8293820023536682, "aqua_rat_69384": 0.8295086622238159, "aqua_rat_7495": 0.8296204805374146, "aqua_rat_18404": 0.8296977281570435, "aqua_rat_70803": 0.8299229741096497, "aqua_rat_84364": 0.8299258947372437, "aqua_rat_32162": 0.8300775289535522, "aqua_rat_52067": 0.8302274346351624, "aqua_rat_57985": 0.8308216333389282, "aqua_rat_9182": 0.8309617042541504, "aqua_rat_70446": 0.8309735655784607, "aqua_rat_79755": 0.8310363292694092, "aqua_rat_83547": 0.8310481905937195, "aqua_rat_7248": 0.8313345313072205, "aqua_rat_27914": 0.8314135074615479, "aqua_rat_22507": 0.8315398693084717, "aqua_rat_57246": 0.8317689299583435, "aqua_rat_65667": 0.8319437503814697, "aqua_rat_76714": 0.8320513367652893, "aqua_rat_1184": 0.8323159217834473, "aqua_rat_55266": 0.8325319886207581, "aqua_rat_35395": 0.8325937986373901, "math_train_counting_and_probability_698": 0.8327869772911072, "math_test_counting_and_probability_416": 0.833189070224762, "aqua_rat_19436": 0.8332371115684509, "aqua_rat_2658": 0.833259642124176, "aqua_rat_25369": 0.8335348963737488, "aqua_rat_74550": 0.8335429430007935, "aqua_rat_58757": 0.8335751295089722, "aqua_rat_10102": 0.8338243365287781, "aqua_rat_78835": 0.834308385848999, "aqua_rat_15548": 0.8343330025672913, "aqua_rat_64131": 0.8344630002975464, "aqua_rat_73402": 0.8346458673477173, "aqua_rat_61965": 0.8353684544563293, "aqua_rat_35517": 0.8354775905609131, "aqua_rat_7086": 0.835519015789032, "aqua_rat_36385": 0.8357403874397278, "aqua_rat_66841": 0.8359586000442505, "aqua_rat_29035": 0.8361800312995911, "aqua_rat_13585": 0.8366063833236694, "aqua_rat_15917": 0.8366687893867493, "aqua_rat_51384": 0.8367429375648499, "aqua_rat_32732": 0.8375265002250671, "aqua_rat_62903": 0.8379799723625183, "aqua_rat_3235": 0.8384113311767578, "aqua_rat_22458": 0.8385563492774963, "aqua_rat_10096": 0.8391302824020386, "aqua_rat_89113": 0.8399608135223389, "aqua_rat_60238": 0.8400681018829346, "aqua_rat_51723": 0.8405896425247192, "math_train_counting_and_probability_918": 0.8407465219497681, "aqua_rat_2480": 0.8411728739738464, "aqua_rat_84159": 0.8417673707008362, "aqua_rat_34600": 0.8420506119728088, "aqua_rat_37185": 0.8426427245140076, "aqua_rat_54461": 0.8426963686943054, "aqua_rat_61885": 0.8433473110198975, "aqua_rat_73122": 0.8435519933700562, "aqua_rat_7911": 0.8439823389053345, "aqua_rat_77478": 0.8441133499145508, "aqua_rat_49410": 0.8446983695030212, "aqua_rat_12795": 0.8449516296386719, "aqua_rat_16877": 0.8450526595115662, "aqua_rat_23041": 0.8453611731529236, "aqua_rat_34678": 0.8459344506263733, "aqua_rat_40108": 0.8462761640548706, "aqua_rat_29651": 0.8474581241607666, "aqua_rat_11164": 0.8487201929092407, "aqua_rat_60936": 0.8523276448249817}, "TheoremQA_wenhuchen/optics3.json": {"TheoremQA_wenhuchen/optics3.json": 0, "aqua_rat_55747": 0.7006728053092957, "aqua_rat_6220": 0.7008658051490784, "camel_4802": 0.7008731365203857, "gsm_rft_7089": 0.7008984684944153, "camel_4755": 0.7009493708610535, "gsm_rft_33234": 0.7009850740432739, "aqua_rat_85100": 0.7010104060173035, "aqua_rat_25668": 0.7011380791664124, "aqua_rat_61971": 0.7011496424674988, "aqua_rat_23369": 0.7011564373970032, "camel_4867": 0.7014148831367493, "gsm_rft_29693": 0.7014200687408447, "gsm_rft_15228": 0.7014232277870178, "aqua_rat_76667": 0.7020235657691956, "aqua_rat_28523": 0.7021149396896362, "aqua_rat_60403": 0.7021517157554626, "aqua_rat_80763": 0.7022867202758789, "gsm_train_21024": 0.7023012638092041, "gsm_rft_2034": 0.7023470997810364, "gsm_rft_3538": 0.7023470997810364, "camel_4928": 0.7024287581443787, "camel_5561": 0.7026049494743347, "aqua_rat_18562": 0.7026200890541077, "gsm_rft_21096": 0.7027835845947266, "gsm_rft_27782": 0.7027924060821533, "gsm_rft_28321": 0.702800989151001, "camel_4800": 0.7029104828834534, "aqua_rat_37409": 0.7029526829719543, "aqua_rat_72645": 0.7029697299003601, "aqua_rat_36249": 0.7030834555625916, "aqua_rat_45630": 0.7031959295272827, "camel_4728": 0.7032225131988525, "aqua_rat_86056": 0.7033822536468506, "gsm_train_31894": 0.7034046649932861, "aqua_rat_8162": 0.7034090757369995, "math_test_prealgebra_1108": 0.7034655213356018, "camel_4935": 0.7035430073738098, "aqua_rat_37980": 0.7035818696022034, "camel_4875": 0.703646719455719, "aqua_rat_51212": 0.7038155198097229, "aqua_rat_57888": 0.703819215297699, "gsm_rft_26992": 0.7040824294090271, "gsm_rft_15709": 0.7040830254554749, "camel_4848": 0.7041367888450623, "gsm_rft_15250": 0.7041608691215515, "camel_4767": 0.704258918762207, "camel_4804": 0.7043462991714478, "camel_4961": 0.7044803500175476, "camel_5012": 0.7044841647148132, "math_train_geometry_649": 0.7045555114746094, "aqua_rat_33103": 0.7046957612037659, "camel_4988": 0.7047733068466187, "aqua_rat_31980": 0.7047951817512512, "camel_4781": 0.7048893570899963, "camel_5033": 0.7050204873085022, "camel_36254": 0.7050591707229614, "camel_4913": 0.7050809264183044, "aqua_rat_30572": 0.7050992846488953, "camel_4794": 0.7054247856140137, "aqua_rat_24901": 0.7056314945220947, "camel_4773": 0.7058630585670471, "gsm_rft_12209": 0.7060103416442871, "camel_4946": 0.7060537338256836, "camel_4803": 0.7063260078430176, "gsm_rft_3570": 0.7063319683074951, "camel_4760": 0.706400454044342, "aqua_rat_88321": 0.7064124345779419, "aqua_rat_33439": 0.7064836621284485, "camel_4798": 0.7065088152885437, "aqua_rat_56182": 0.7067381739616394, "camel_4932": 0.7071332931518555, "camel_5000": 0.7071851491928101, "gsm_rft_14765": 0.7073409557342529, "gsm_train_24865": 0.7074375152587891, "camel_4801": 0.7075372934341431, "gsm_rft_15409": 0.7077949643135071, "camel_4916": 0.7078752517700195, "gsm_rft_35481": 0.708146333694458, "gsm_train_5301": 0.7082902193069458, "camel_5105": 0.7083272933959961, "gsm_rft_34396": 0.7085131406784058, "gsm_train_2639": 0.7085131406784058, "aqua_rat_25154": 0.7085863351821899, "gsm_rft_11101": 0.7086547613143921, "gsm_rft_2601": 0.7086547613143921, "camel_4891": 0.7087252736091614, "camel_4955": 0.7088900208473206, "camel_4857": 0.7089299559593201, "aqua_rat_46971": 0.7089460492134094, "aqua_rat_15159": 0.7089709639549255, "aqua_rat_32781": 0.7090200185775757, "camel_4816": 0.7090768218040466, "gsm_rft_20209": 0.7092161178588867, "gsm_rft_3001": 0.7092161178588867, "gsm_train_22328": 0.7092161178588867, "gsm_rft_26574": 0.7094451189041138, "camel_4924": 0.7096624374389648, "gsm_train_33444": 0.7097902894020081, "gsm_rft_13589": 0.7099065780639648, "gsm_rft_27197": 0.709988534450531, "camel_4920": 0.7099981307983398, "aqua_rat_13703": 0.7100358009338379, "aqua_rat_21504": 0.7100699543952942, "aqua_rat_3234": 0.7101786732673645, "aqua_rat_66162": 0.7102406620979309, "gsm_rft_14244": 0.7104448080062866, "gsm_train_34815": 0.7104448080062866, "gsm_train_31158": 0.7106510996818542, "gsm_rft_1939": 0.7106510996818542, "aqua_rat_53630": 0.7106727957725525, "camel_5563": 0.7106989622116089, "aqua_rat_8610": 0.7109530568122864, "gsm_rft_28133": 0.7110322713851929, "gsm_rft_8463": 0.7110984921455383, "camel_4552": 0.7115688920021057, "aqua_rat_29281": 0.7115734219551086, "camel_5543": 0.7117038369178772, "camel_4866": 0.7125368714332581, "gsm_rft_33471": 0.7127413153648376, "aqua_rat_83787": 0.7127680778503418, "camel_5032": 0.7130748629570007, "aqua_rat_23105": 0.71309894323349, "camel_4828": 0.7133820056915283, "camel_4807": 0.7135409116744995, "aqua_rat_20932": 0.7140480279922485, "camel_4841": 0.7145843505859375, "camel_4106": 0.7145864367485046, "aqua_rat_44457": 0.7147689461708069, "camel_4724": 0.7165111303329468, "camel_5583": 0.7167177200317383, "camel_4721": 0.7168195247650146, "aqua_rat_61332": 0.7168725728988647, "aqua_rat_12010": 0.7171854376792908, "aqua_rat_71816": 0.7172806859016418, "aqua_rat_43435": 0.7187132239341736, "camel_6840": 0.7188129425048828, "camel_4820": 0.7189698219299316, "gsm_rft_11389": 0.7190665006637573, "camel_4780": 0.7193808555603027, "camel_4991": 0.7194820642471313, "camel_4904": 0.7198659777641296, "aqua_rat_14967": 0.7200313210487366, "camel_4837": 0.7203342914581299, "math_test_geometry_151": 0.7212828993797302, "gsm_rft_2430": 0.7213460803031921, "camel_4865": 0.7216273546218872, "camel_4893": 0.7239285111427307, "math_test_prealgebra_583": 0.7242230176925659, "camel_4981": 0.7242347002029419, "camel_4853": 0.7247923612594604, "aqua_rat_30115": 0.7249326705932617, "camel_4831": 0.7253957986831665, "aqua_rat_63015": 0.725420355796814, "math_test_algebra_2160": 0.7263352274894714, "camel_4827": 0.7275484204292297, "camel_4874": 0.7284040451049805, "math_test_prealgebra_1904": 0.7285073399543762, "aqua_rat_27170": 0.7288524508476257, "aqua_rat_59988": 0.729583203792572, "camel_4846": 0.7298542857170105, "aqua_rat_30186": 0.730039656162262, "aqua_rat_74461": 0.7310917973518372, "camel_4813": 0.7329764366149902, "aqua_rat_2228": 0.7336827516555786, "camel_49646": 0.7345961928367615, "camel_5587": 0.7346495389938354, "aqua_rat_10339": 0.7349206209182739, "aqua_rat_22739": 0.735266923904419, "camel_4737": 0.7356980443000793, "camel_4980": 0.7359068393707275, "camel_5017": 0.7374914884567261, "aqua_rat_18718": 0.7384576201438904, "camel_5287": 0.7385019063949585, "aqua_rat_86356": 0.7391910552978516, "aqua_rat_12240": 0.7393242716789246, "aqua_rat_83857": 0.7394087314605713, "aqua_rat_22618": 0.7398092150688171, "aqua_rat_70142": 0.7399449944496155, "aqua_rat_18543": 0.7414519786834717, "aqua_rat_60805": 0.7415869235992432, "gsm_rft_5305": 0.7419873476028442, "gsm_train_22045": 0.7419873476028442, "aqua_rat_69962": 0.7430751323699951, "camel_5527": 0.7433459162712097, "aqua_rat_25937": 0.7439777255058289, "aqua_rat_37605": 0.7440776824951172, "aqua_rat_55057": 0.7443522214889526, "camel_4983": 0.7481939196586609, "math_train_prealgebra_1701": 0.7487934231758118, "aqua_rat_14896": 0.7518476843833923, "aqua_rat_8530": 0.7528617978096008, "aqua_rat_35477": 0.7563205361366272, "camel_4771": 0.7601975202560425, "gsm_rft_7733": 0.7667612433433533, "gsm_train_19077": 0.767095148563385, "gsm_rft_17748": 0.767095148563385, "camel_4808": 0.7729505300521851, "TheoremQA_wenhuchen/optics7.json": 0.7846404910087585, "TheoremQA_wenhuchen/optics2.json": 0.8075003623962402}, "TheoremQA_elainewan/math_algebra_7_2.json": {"camel_14551": 0, "camel_14509": 0, "camel_14250": 0, "camel_14467": 0, "camel_14534": 0, "camel_14542": 0, "camel_14550": 0, "camel_14442": 0, "camel_14556": 0, "camel_15728": 0, "camel_14487": 0, "camel_14507": 0, "camel_14521": 0, "camel_14459": 0, "camel_14536": 0, "camel_14545": 0, "camel_14523": 0, "camel_14506": 0, "TheoremQA_elainewan/math_algebra_7_2.json": 0, "camel_23067": 0.6336809992790222, "camel_28462": 0.6338185667991638, "camel_40101": 0.6338703036308289, "camel_29799": 0.6340422630310059, "camel_9312": 0.6340503692626953, "camel_28385": 0.6341271996498108, "camel_23549": 0.6343045830726624, "camel_23553": 0.6343830823898315, "camel_28347": 0.6344606280326843, "camel_28877": 0.6346195936203003, "camel_28361": 0.6346219778060913, "camel_49914": 0.6347237825393677, "camel_28386": 0.6347752809524536, "camel_29918": 0.6348568201065063, "camel_23573": 0.6348966956138611, "camel_29321": 0.6349830031394958, "camel_9343": 0.6352645754814148, "camel_29613": 0.6352918148040771, "camel_9295": 0.6353678107261658, "camel_29540": 0.6354960799217224, "camel_23523": 0.635556697845459, "camel_29910": 0.635576605796814, "camel_29554": 0.6357749104499817, "camel_29120": 0.6359878182411194, "camel_29110": 0.6360524892807007, "TheoremQA_mingyin/compact-operator-theorem1.json": 0.6363928318023682, "camel_27500": 0.6365999579429626, "camel_9305": 0.6367549300193787, "camel_28327": 0.636868953704834, "camel_29888": 0.636880099773407, "camel_49850": 0.6369770765304565, "camel_29196": 0.6370778679847717, "TheoremQA_elainewan/math_algebra_2.json": 0.637111485004425, "camel_29525": 0.6371994614601135, "camel_36766": 0.6372532844543457, "camel_28328": 0.6374133825302124, "camel_47784": 0.6374297142028809, "camel_9325": 0.6374408602714539, "camel_29679": 0.6375918388366699, "camel_29097": 0.6377636790275574, "camel_49856": 0.6379381418228149, "camel_23114": 0.6381387114524841, "camel_28759": 0.638180136680603, "camel_29867": 0.6382428407669067, "camel_29103": 0.6384327411651611, "camel_29126": 0.6386090517044067, "camel_23556": 0.6386324167251587, "camel_29855": 0.6389465928077698, "camel_47790": 0.6389647126197815, "camel_9313": 0.6389703154563904, "camel_29596": 0.6393141746520996, "camel_29556": 0.6393277645111084, "camel_47834": 0.6393939256668091, "camel_47826": 0.6394544243812561, "camel_29607": 0.6396312713623047, "camel_49861": 0.6398019790649414, "camel_47783": 0.6398971080780029, "camel_29117": 0.6399089694023132, "camel_47787": 0.639997661113739, "TheoremQA_wenhuchen/definite_matrix2.json": 0.6402289271354675, "camel_28747": 0.6403338313102722, "camel_29565": 0.6404980421066284, "TheoremQA_elainewan/math_algebra_3.json": 0.640516996383667, "camel_29566": 0.6407095193862915, "camel_28657": 0.6408059000968933, "camel_9280": 0.6410115957260132, "camel_29619": 0.6415609121322632, "camel_47835": 0.6417652368545532, "camel_29672": 0.6418514847755432, "camel_29653": 0.6424988508224487, "camel_49883": 0.6428934335708618, "camel_29879": 0.642987847328186, "camel_47760": 0.6431724429130554, "camel_49842": 0.6433048248291016, "camel_9335": 0.6437704563140869, "camel_47756": 0.6437987685203552, "camel_29078": 0.6439262628555298, "camel_29878": 0.6440194249153137, "camel_29876": 0.6442273259162903, "camel_29549": 0.6443158388137817, "camel_29534": 0.6443613767623901, "camel_47799": 0.6444286108016968, "camel_29605": 0.6446030735969543, "camel_47788": 0.6448338627815247, "camel_49884": 0.6450778245925903, "camel_9356": 0.6451447606086731, "camel_47730": 0.645148754119873, "camel_9331": 0.6451608538627625, "camel_28948": 0.6455115675926208, "camel_17569": 0.6457390189170837, "camel_29670": 0.6465340256690979, "camel_29606": 0.6471137404441833, "TheoremQA_elainewan/math_algebra_4.json": 0.647575318813324, "camel_29636": 0.647580623626709, "camel_9296": 0.6477208137512207, "camel_29665": 0.6477741003036499, "camel_29616": 0.6484516263008118, "camel_9300": 0.6486166715621948, "camel_29663": 0.6487299203872681, "camel_29130": 0.6489787101745605, "camel_23558": 0.6490702033042908, "camel_29869": 0.6492347121238708, "camel_29559": 0.6494223475456238, "camel_29158": 0.6495269536972046, "camel_47755": 0.6496601104736328, "camel_29068": 0.6499512791633606, "camel_29650": 0.6503380537033081, "camel_47813": 0.6515403389930725, "camel_9321": 0.6515517830848694, "camel_29570": 0.6519386768341064, "camel_49935": 0.6519487500190735, "camel_28412": 0.6521401405334473, "camel_49852": 0.6525800228118896, "camel_29523": 0.6527760028839111, "camel_29629": 0.6530619263648987, "camel_9346": 0.6536045670509338, "camel_47793": 0.6537480354309082, "camel_47807": 0.6540870666503906, "camel_29624": 0.6541391611099243, "camel_47801": 0.6546581983566284, "camel_29675": 0.6547020673751831, "camel_47838": 0.6548306941986084, "camel_29673": 0.6550461649894714, "TheoremQA_elainewan/math_algebra_6.json": 0.6554443836212158, "camel_9327": 0.655491292476654, "camel_49882": 0.6555310487747192, "camel_9294": 0.6557020545005798, "camel_29651": 0.6563685536384583, "camel_29563": 0.6573950052261353, "camel_9339": 0.658017635345459, "camel_29612": 0.6580579876899719, "camel_29568": 0.6592952609062195, "camel_9358": 0.6593445539474487, "camel_29186": 0.6594669222831726, "camel_47777": 0.6596247553825378, "camel_47713": 0.6599182486534119, "camel_40112": 0.66022127866745, "camel_29609": 0.6608263850212097, "camel_49906": 0.6608644723892212, "camel_47805": 0.6612690091133118, "camel_49865": 0.6612873673439026, "camel_29669": 0.6613374948501587, "camel_40126": 0.6613474488258362, "camel_23542": 0.6617078185081482, "camel_29642": 0.6617682576179504, "camel_47780": 0.6626065373420715, "camel_29900": 0.662909746170044, "camel_29532": 0.6635282039642334, "camel_29622": 0.6639501452445984, "camel_29641": 0.6642197966575623, "camel_29615": 0.6648007035255432, "camel_29635": 0.6651569604873657, "camel_9359": 0.6658177375793457, "camel_9299": 0.6665918231010437, "camel_49866": 0.6667820811271667, "camel_29617": 0.666853129863739, "camel_49891": 0.6681878566741943, "camel_47827": 0.6683117747306824, "camel_49887": 0.6683887243270874, "camel_29676": 0.6689732670783997, "camel_47817": 0.6696838140487671, "camel_29655": 0.6698586940765381, "camel_47830": 0.6701697707176208, "camel_29649": 0.6719158887863159, "camel_29630": 0.6729312539100647, "camel_49909": 0.6731887459754944, "camel_29602": 0.6750412583351135, "camel_47761": 0.6764708161354065, "camel_47828": 0.6767702102661133, "camel_29628": 0.6768205761909485, "camel_40117": 0.6788106560707092, "camel_29661": 0.6791933178901672, "camel_40110": 0.6890873908996582, "camel_40139": 0.6891986727714539, "camel_47814": 0.690180778503418, "camel_49900": 0.690666139125824, "camel_29658": 0.6925356984138489, "TheoremQA_elainewan/math_algebra_7.json": 0.6961774826049805, "camel_49871": 0.7024905681610107, "camel_40119": 0.7030012011528015, "camel_40155": 0.7092185616493225}, "TheoremQA_mingyin/Limit-of-sequence3.json": {"camel_11539": 0.6756881475448608, "gsm_rft_23543": 0.6757006049156189, "aqua_rat_18809": 0.6757063865661621, "aqua_rat_50530": 0.6757128238677979, "camel_10910": 0.6757474541664124, "aqua_rat_30582": 0.6758608818054199, "camel_11105": 0.675881028175354, "aqua_rat_6441": 0.6758835315704346, "math_train_algebra_1612": 0.6758851408958435, "camel_9555": 0.6760467290878296, "camel_25573": 0.6761236786842346, "camel_10698": 0.6761294603347778, "gsm_rft_7403": 0.6761333346366882, "gsm_rft_3034": 0.6761779189109802, "gsm_rft_15224": 0.6762383580207825, "aqua_rat_81423": 0.6762709617614746, "aqua_rat_21292": 0.6763014793395996, "aqua_rat_28227": 0.6764085292816162, "gsm_rft_28362": 0.6764200925827026, "camel_10543": 0.6765697598457336, "gsm_rft_18763": 0.6766027212142944, "aqua_rat_77717": 0.6767974495887756, "camel_10999": 0.6768302917480469, "aqua_rat_68259": 0.676873505115509, "aqua_rat_67480": 0.6769243478775024, "aqua_rat_72999": 0.6769880652427673, "camel_11316": 0.6770696043968201, "camel_30372": 0.6770706176757812, "aqua_rat_255": 0.6770724058151245, "aqua_rat_83725": 0.6771167516708374, "camel_10997": 0.6771397590637207, "gsm_rft_13191": 0.6771932244300842, "gsm_rft_17965": 0.6773294806480408, "gsm_train_18502": 0.6773294806480408, "aqua_rat_3965": 0.6774859428405762, "camel_10880": 0.6774864196777344, "aqua_rat_45141": 0.6775919795036316, "camel_10922": 0.677675187587738, "aqua_rat_30397": 0.6777396202087402, "gsm_train_5213": 0.6777698993682861, "gsm_rft_24395": 0.6777698993682861, "camel_8573": 0.677828311920166, "aqua_rat_56798": 0.6779665350914001, "math_test_prealgebra_840": 0.677979052066803, "gsm_rft_21208": 0.6779941916465759, "camel_10905": 0.6781467199325562, "aqua_rat_2126": 0.6782621145248413, "gsm_rft_21743": 0.6783310770988464, "aqua_rat_75339": 0.6783570647239685, "aqua_rat_8054": 0.6785025596618652, "aqua_rat_31548": 0.678564190864563, "aqua_rat_87381": 0.678730309009552, "gsm_rft_9090": 0.678754448890686, "aqua_rat_48756": 0.6788061857223511, "aqua_rat_19860": 0.6788138747215271, "aqua_rat_47971": 0.678816020488739, "aqua_rat_32960": 0.6788850426673889, "aqua_rat_35494": 0.6790904402732849, "camel_10812": 0.6790913939476013, "gsm_rft_14385": 0.679146409034729, "aqua_rat_56490": 0.6791515946388245, "gsm_rft_12794": 0.6792169213294983, "camel_10482": 0.6792514324188232, "aqua_rat_87246": 0.6793330311775208, "camel_10965": 0.6793850064277649, "camel_11163": 0.6793951988220215, "aqua_rat_6957": 0.6794230341911316, "aqua_rat_35341": 0.6794469356536865, "camel_8817": 0.6795167922973633, "aqua_rat_39808": 0.6795462965965271, "camel_9872": 0.6796059012413025, "gsm_train_8946": 0.6796168088912964, "aqua_rat_86773": 0.6796584129333496, "camel_11112": 0.6796611547470093, "camel_9579": 0.6797125339508057, "camel_37652": 0.6797196865081787, "aqua_rat_14187": 0.6797755360603333, "gsm_rft_21089": 0.6798149347305298, "camel_10656": 0.6798658967018127, "aqua_rat_29639": 0.6799610257148743, "aqua_rat_33501": 0.6800392270088196, "gsm_train_5496": 0.6801295280456543, "gsm_rft_4931": 0.6801295280456543, "math_train_algebra_627": 0.6802139282226562, "gsm_rft_25879": 0.6802862882614136, "aqua_rat_6030": 0.680322527885437, "gsm_rft_32543": 0.6803253293037415, "aqua_rat_66726": 0.6803990006446838, "aqua_rat_42434": 0.680431604385376, "gsm_rft_30725": 0.6805045008659363, "aqua_rat_53870": 0.6805071234703064, "camel_11758": 0.6806610822677612, "camel_11558": 0.6807089447975159, "aqua_rat_59808": 0.6807141304016113, "aqua_rat_62600": 0.6807149052619934, "gsm_rft_9427": 0.6807613968849182, "gsm_train_29573": 0.6807613968849182, "camel_10955": 0.6807762980461121, "camel_11810": 0.6807845234870911, "aqua_rat_59651": 0.6808598041534424, "camel_10488": 0.6810056567192078, "gsm_rft_7431": 0.6811226010322571, "gsm_rft_31676": 0.6811325550079346, "camel_25589": 0.6811529994010925, "aqua_rat_62048": 0.6811712980270386, "aqua_rat_51875": 0.6812471151351929, "camel_11286": 0.6813720464706421, "aqua_rat_67347": 0.6813897490501404, "camel_8429": 0.6814727187156677, "aqua_rat_15506": 0.6815305352210999, "camel_11536": 0.6816500425338745, "camel_11292": 0.681675374507904, "aqua_rat_54690": 0.681733250617981, "aqua_rat_5046": 0.6817940473556519, "camel_11356": 0.6822899580001831, "gsm_rft_1786": 0.6823227405548096, "gsm_train_29305": 0.6823227405548096, "aqua_rat_64015": 0.6825148463249207, "gsm_rft_28257": 0.6825916767120361, "aqua_rat_13038": 0.6826474666595459, "camel_11302": 0.6827669143676758, "gsm_rft_15321": 0.6828100085258484, "aqua_rat_64676": 0.6828358769416809, "aqua_rat_84419": 0.682863712310791, "aqua_rat_38021": 0.6831087470054626, "camel_10367": 0.6834739446640015, "gsm_rft_18655": 0.6837325692176819, "camel_11624": 0.6838711500167847, "math_train_prealgebra_729": 0.6838851571083069, "gsm_rft_24203": 0.6840192079544067, "aqua_rat_61662": 0.6840509176254272, "camel_11346": 0.6846978664398193, "camel_11357": 0.6847264766693115, "aqua_rat_43878": 0.6849203705787659, "camel_11179": 0.6850927472114563, "gsm_train_28964": 0.6851277947425842, "camel_11671": 0.6851562857627869, "gsm_rft_24677": 0.6852563619613647, "gsm_rft_17239": 0.6852563619613647, "gsm_rft_31508": 0.6852649450302124, "camel_11884": 0.68553227186203, "math_test_counting_and_probability_878": 0.6859973073005676, "camel_10943": 0.6862642765045166, "math_test_algebra_248": 0.6865748763084412, "camel_11317": 0.6867575645446777, "gsm_rft_34175": 0.6867826581001282, "aqua_rat_75743": 0.6870482563972473, "camel_10369": 0.6875232458114624, "camel_11321": 0.6876490712165833, "camel_9532": 0.6877164244651794, "camel_10822": 0.6883782744407654, "math_test_algebra_749": 0.688412070274353, "camel_10839": 0.6884422302246094, "camel_11358": 0.6886671781539917, "math_test_algebra_2664": 0.6886999607086182, "camel_37619": 0.6887692213058472, "aqua_rat_34788": 0.6887775659561157, "aqua_rat_8490": 0.6888576745986938, "camel_11318": 0.6891273260116577, "camel_9540": 0.6896836757659912, "camel_11386": 0.689967155456543, "aqua_rat_43863": 0.6900859475135803, "aqua_rat_61622": 0.6902364492416382, "camel_11312": 0.69040447473526, "aqua_rat_18321": 0.6906372904777527, "camel_11563": 0.6918529868125916, "aqua_rat_16117": 0.6920265555381775, "gsm_rft_3078": 0.6922817826271057, "aqua_rat_46553": 0.6923778057098389, "aqua_rat_9211": 0.6942083835601807, "camel_10855": 0.6942237019538879, "aqua_rat_5634": 0.6943026185035706, "aqua_rat_29953": 0.6947375535964966, "math_test_algebra_981": 0.6949192881584167, "camel_11344": 0.6952411532402039, "camel_9582": 0.6963018178939819, "aqua_rat_88394": 0.6969016790390015, "aqua_rat_3097": 0.6970694661140442, "camel_37789": 0.6972276568412781, "math_test_counting_and_probability_359": 0.6986980438232422, "camel_11983": 0.6994948983192444, "math_train_algebra_2250": 0.7004629969596863, "gsm_train_5852": 0.7011304497718811, "camel_10242": 0.7016006708145142, "gsm_rft_17172": 0.7024152874946594, "gsm_rft_8043": 0.7030448913574219, "aqua_rat_33076": 0.7047311067581177, "aqua_rat_31829": 0.7079905271530151, "aqua_rat_85856": 0.7081880569458008, "aqua_rat_6364": 0.708467423915863, "camel_9562": 0.7085708975791931, "camel_37705": 0.7089935541152954, "aqua_rat_65902": 0.7095817923545837, "aqua_rat_7395": 0.7114406228065491, "aqua_rat_39753": 0.7152237296104431, "aqua_rat_31646": 0.7153733372688293, "aqua_rat_32273": 0.7157078385353088, "aqua_rat_9157": 0.7158060073852539, "aqua_rat_10334": 0.7179877758026123, "aqua_rat_68972": 0.7199401259422302}, "TheoremQA_maxku/graphtheory6-shortestpath.json": {"camel_22277": 0, "camel_21661": 0, "camel_39987": 0, "camel_23409": 0, "camel_38627": 0, "camel_23964": 0, "camel_22026": 0, "camel_22072": 0, "camel_22384": 0, "camel_22859": 0, "camel_23996": 0, "camel_23921": 0, "camel_23924": 0, "camel_22818": 0, "camel_22054": 0, "camel_22052": 0, "camel_22873": 0, "camel_21630": 0, "camel_39947": 0, "camel_39998": 0, "camel_22058": 0, "camel_23942": 0, "camel_22047": 0, "camel_21610": 0, "camel_21627": 0, "camel_38615": 0, "camel_38491": 0, "camel_22847": 0, "camel_22074": 0, "camel_22377": 0, "camel_22252": 0, "camel_22294": 0, "camel_38611": 0, "camel_22033": 0, "camel_39968": 0, "camel_22002": 0, "camel_38608": 0, "camel_23967": 0, "camel_22039": 0, "camel_38561": 0, "camel_22007": 0, "camel_22004": 0, "camel_23970": 0, "camel_22467": 0, "camel_23923": 0, "camel_39999": 0, "camel_21658": 0, "camel_23991": 0, "camel_23961": 0, "camel_39959": 0, "camel_22028": 0, "camel_22079": 0, "camel_22875": 0, "camel_22345": 0, "camel_39957": 0, "camel_22398": 0, "camel_22044": 0, "camel_23977": 0, "camel_22326": 0, "camel_39972": 0, "camel_22387": 0, "camel_22027": 0, "camel_22070": 0, "camel_23957": 0, "camel_22279": 0, "camel_23192": 0, "camel_39977": 0, "camel_38564": 0, "camel_21601": 0, "camel_21654": 0, "camel_38621": 0, "camel_21639": 0, "camel_22030": 0, "camel_22417": 0, "camel_22340": 0, "camel_39964": 0, "camel_39932": 0, "camel_22036": 0, "camel_22062": 0, "camel_22014": 0, "camel_22806": 0, "camel_22366": 0, "camel_22010": 0, "camel_38630": 0, "camel_22367": 0, "camel_39931": 0, "camel_23982": 0, "camel_23952": 0, "camel_23938": 0, "camel_23951": 0, "camel_23193": 0, "camel_23127": 0, "camel_23997": 0, "camel_23981": 0, "camel_23983": 0, "camel_39975": 0, "camel_22001": 0, "camel_23973": 0, "camel_22043": 0, "camel_22025": 0, "camel_22073": 0, "camel_39926": 0, "camel_22011": 0, "camel_22003": 0, "camel_38560": 0, "camel_22335": 0, "camel_22397": 0, "camel_22005": 0, "camel_23947": 0, "camel_21667": 0, "camel_22057": 0, "camel_22017": 0, "camel_22038": 0, "camel_22056": 0, "camel_22000": 0, "camel_38581": 0, "camel_22449": 0, "camel_21675": 0, "camel_39997": 0, "camel_23971": 0, "camel_22075": 0, "camel_22868": 0, "camel_39960": 0, "camel_21628": 0, "camel_22042": 0, "camel_22009": 0, "camel_22076": 0, "camel_38569": 0, "camel_21664": 0, "camel_22024": 0, "camel_22055": 0, "camel_22008": 0, "camel_21607": 0, "camel_22023": 0, "camel_22035": 0, "camel_22077": 0, "camel_22354": 0, "camel_23980": 0, "camel_22032": 0, "camel_38501": 0, "camel_23926": 0, "camel_22016": 0, "camel_22021": 0, "camel_22330": 0, "camel_22300": 0, "camel_22361": 0, "camel_39920": 0, "camel_21646": 0, "camel_23928": 0, "camel_39996": 0, "camel_21648": 0, "camel_21663": 0, "camel_38585": 0, "camel_21641": 0, "camel_22006": 0, "camel_38572": 0, "camel_22064": 0, "camel_22040": 0, "camel_23184": 0, "camel_21678": 0, "camel_22029": 0, "camel_39938": 0, "camel_22067": 0, "camel_38609": 0, "camel_22059": 0, "camel_22051": 0, "camel_22061": 0, "camel_22053": 0, "camel_22022": 0, "camel_22049": 0, "camel_22068": 0, "camel_38489": 0, "camel_22344": 0, "camel_22363": 0, "camel_21634": 0, "camel_38576": 0, "camel_22037": 0, "camel_22324": 0, "camel_23945": 0, "camel_38906": 0, "camel_22041": 0, "camel_23143": 0, "camel_22065": 0, "camel_22031": 0, "camel_22170": 0, "camel_22368": 0, "camel_22046": 0, "camel_39928": 0, "camel_22069": 0, "camel_22332": 0, "camel_22060": 0, "camel_39974": 0, "camel_22015": 0, "camel_22071": 0, "TheoremQA_maxku/graphtheory6-shortestpath.json": 0, "camel_41246": 0.7974611520767212, "camel_36503": 0.8111826181411743, "TheoremQA_maxku/graphtheory11-shortestpath-hard.json": 0.8305811285972595, "TheoremQA_maxku/graphtheory7-shortestpath.json": 0.8603624701499939, "TheoremQA_maxku/graphtheory10-shortestpath.json": 0.8716230392456055}, "TheoremQA_elainewan/math_calculus_2_7.json": {"camel_6166": 0, "camel_7201": 0, "camel_7246": 0, "camel_7218": 0, "camel_6174": 0, "camel_7242": 0, "camel_7247": 0, "camel_7200": 0, "camel_7229": 0, "camel_7279": 0, "camel_7124": 0, "camel_7261": 0, "camel_7272": 0, "camel_7254": 0, "camel_7149": 0, "camel_7224": 0, "camel_7255": 0, "camel_7202": 0, "camel_7266": 0, "camel_7237": 0, "camel_7236": 0, "camel_7269": 0, "camel_7216": 0, "camel_7270": 0, "camel_7234": 0, "camel_7209": 0, "camel_7250": 0, "camel_7262": 0, "camel_7232": 0, "camel_7212": 0, "camel_7259": 0, "camel_7227": 0, "camel_7207": 0, "camel_7214": 0, "camel_7276": 0, "camel_7205": 0, "camel_7221": 0, "camel_7204": 0, "camel_7256": 0, "camel_7225": 0, "camel_7275": 0, "camel_7208": 0, "camel_7206": 0, "camel_7238": 0, "camel_7251": 0, "camel_7233": 0, "camel_7257": 0, "camel_7226": 0, "camel_7210": 0, "camel_7263": 0, "camel_7268": 0, "camel_7277": 0, "camel_7267": 0, "camel_7215": 0, "camel_7213": 0, "camel_7252": 0, "camel_7731": 0, "camel_7260": 0, "camel_7278": 0, "camel_7223": 0, "camel_7273": 0, "camel_7244": 0, "TheoremQA_elainewan/math_calculus_2_7.json": 0, "camel_7230": 0, "camel_7245": 0, "camel_7203": 0, "camel_7231": 0, "camel_7211": 0, "camel_6107": 0, "camel_7248": 0, "camel_7235": 0, "aqua_rat_3097": 0.6667932868003845, "aqua_rat_29953": 0.6668500900268555, "camel_18272": 0.667024552822113, "camel_41170": 0.6672203540802002, "camel_41882": 0.6673141717910767, "camel_38938": 0.6673197150230408, "camel_29240": 0.6675563454627991, "camel_28835": 0.6676170229911804, "aqua_rat_42657": 0.667648196220398, "camel_18260": 0.6677021980285645, "camel_18105": 0.6677499413490295, "camel_18267": 0.667758047580719, "camel_29435": 0.6677712202072144, "aqua_rat_66420": 0.6677972078323364, "camel_30327": 0.6678772568702698, "math_train_number_theory_7070": 0.6681841015815735, "camel_18891": 0.6682261228561401, "camel_29987": 0.6682475209236145, "camel_39458": 0.6682575345039368, "camel_17811": 0.6683200597763062, "camel_37507": 0.6683339476585388, "aqua_rat_23895": 0.6683631539344788, "camel_29964": 0.668455958366394, "camel_40647": 0.6685940027236938, "camel_45301": 0.6687319874763489, "camel_29184": 0.668799877166748, "camel_41712": 0.6688097715377808, "camel_18940": 0.6690226793289185, "aqua_rat_8453": 0.6690295934677124, "camel_40882": 0.6693387627601624, "aqua_rat_41872": 0.6693764328956604, "aqua_rat_12010": 0.6694062948226929, "camel_30919": 0.6696105599403381, "aqua_rat_16683": 0.6696734428405762, "camel_29279": 0.669690728187561, "camel_18300": 0.6697345972061157, "camel_28100": 0.670171856880188, "aqua_rat_11272": 0.6702534556388855, "aqua_rat_65996": 0.6703094244003296, "math_test_algebra_2628": 0.6703740358352661, "camel_39482": 0.6705571413040161, "aqua_rat_31829": 0.670725405216217, "camel_39104": 0.6708279252052307, "camel_30907": 0.6709017157554626, "gsm_rft_21213": 0.6709795594215393, "aqua_rat_77759": 0.6710759401321411, "gsm_rft_35104": 0.6710890531539917, "gsm_train_10153": 0.6710941195487976, "camel_28122": 0.671212375164032, "camel_40704": 0.6712210774421692, "aqua_rat_43435": 0.6714076399803162, "camel_30903": 0.6714900135993958, "camel_28532": 0.6715009808540344, "camel_30346": 0.6715494394302368, "aqua_rat_80489": 0.6716883778572083, "aqua_rat_72162": 0.6717749238014221, "camel_29407": 0.6718336939811707, "camel_30882": 0.6718849539756775, "camel_41758": 0.671907901763916, "camel_18919": 0.6719630360603333, "camel_41950": 0.6720309853553772, "camel_41997": 0.6720523834228516, "aqua_rat_19118": 0.672470211982727, "camel_39598": 0.6724809408187866, "gsm_rft_11031": 0.6727330684661865, "camel_42282": 0.6729764938354492, "camel_38892": 0.673029363155365, "gsm_rft_2452": 0.6730467081069946, "camel_28825": 0.6734427809715271, "camel_39465": 0.6738148331642151, "camel_41821": 0.6739562153816223, "camel_45318": 0.6740105152130127, "TheoremQA_xueguangma/extreme_value_theorem.json": 0.674066960811615, "gsm_rft_17551": 0.6740933060646057, "gsm_rft_9344": 0.6740933060646057, "gsm_train_17819": 0.6740933060646057, "camel_18936": 0.6742634773254395, "camel_29097": 0.6747005581855774, "aqua_rat_76642": 0.6748695969581604, "camel_40761": 0.6749013662338257, "camel_42301": 0.6753193736076355, "aqua_rat_47425": 0.6764439344406128, "camel_30926": 0.6770734786987305, "camel_29060": 0.677169144153595, "camel_29969": 0.6780221462249756, "aqua_rat_9493": 0.6781467795372009, "camel_30887": 0.6782528758049011, "camel_18917": 0.678325891494751, "camel_30916": 0.6784569025039673, "camel_39457": 0.6786537766456604, "camel_30945": 0.6797559857368469, "aqua_rat_48488": 0.6798189878463745, "aqua_rat_57946": 0.6801629066467285, "camel_42911": 0.6805713176727295, "camel_40945": 0.6816740036010742, "camel_28715": 0.6819010972976685, "camel_40781": 0.6833779811859131, "camel_30880": 0.6838915944099426, "camel_39486": 0.6839736104011536, "aqua_rat_30425": 0.6844024062156677, "camel_18139": 0.684553861618042, "camel_18883": 0.6850547790527344, "camel_39466": 0.6853185892105103, "camel_18893": 0.6855510473251343, "camel_36444": 0.6861697435379028, "camel_28147": 0.6861915588378906, "aqua_rat_11769": 0.686618447303772, "camel_17545": 0.6871568560600281, "TheoremQA_elainewan/math_real_analysis_additional_2.json": 0.6877744793891907, "TheoremQA_elainewan/math_calculus_2_10.json": 0.6880097389221191, "camel_41853": 0.6884164214134216, "camel_41967": 0.6892670392990112, "aqua_rat_42779": 0.6901936531066895, "camel_28821": 0.6923885345458984, "camel_40760": 0.6924193501472473, "TheoremQA_xueguangma/rolle_theorem.json": 0.6928070187568665, "camel_36477": 0.6934723854064941, "camel_28080": 0.69371098279953, "camel_1528": 0.6949498653411865, "camel_18083": 0.7014240622520447, "camel_28086": 0.7036558985710144, "aqua_rat_49646": 0.7041017413139343, "TheoremQA_wenhuchen/L'H\u00f4pital_rule2.json": 0.7047910690307617, "camel_18122": 0.7067981362342834, "camel_39357": 0.7077744007110596, "camel_18047": 0.7079521417617798, "camel_18957": 0.7105977535247803, "camel_18909": 0.7175877690315247, "camel_18130": 0.7226315140724182}, "TheoremQA_panlu/wave_length1.json": {"camel_16565": 0, "camel_16583": 0, "camel_16636": 0, "camel_16606": 0, "camel_16603": 0, "camel_16622": 0, "camel_16619": 0, "camel_16621": 0, "camel_16579": 0, "camel_16283": 0, "camel_16560": 0, "camel_16616": 0, "camel_17811": 0, "camel_16572": 0, "camel_16634": 0, "camel_16590": 0, "camel_16602": 0, "camel_16608": 0, "camel_16581": 0, "camel_16592": 0, "camel_16618": 0, "camel_16624": 0, "camel_16628": 0, "camel_16588": 0, "TheoremQA_panlu/wave_length1.json": 0, "camel_16573": 0, "camel_16605": 0, "camel_16571": 0, "camel_16567": 0, "camel_16577": 0, "camel_16615": 0, "camel_16626": 0, "camel_16632": 0, "camel_16613": 0, "camel_16637": 0, "camel_16598": 0, "camel_16564": 0, "camel_16623": 0, "camel_16586": 0, "camel_16596": 0, "camel_16575": 0, "camel_45148": 0.7159224152565002, "camel_5092": 0.7159674763679504, "camel_45299": 0.716356635093689, "aqua_rat_69910": 0.7164527177810669, "aqua_rat_77586": 0.7165757417678833, "aqua_rat_3331": 0.7165780067443848, "aqua_rat_35903": 0.7166623473167419, "aqua_rat_28523": 0.7166725397109985, "aqua_rat_18320": 0.7167057991027832, "camel_36254": 0.716724693775177, "aqua_rat_6210": 0.7167683243751526, "gsm_rft_7166": 0.7167999148368835, "gsm_train_228": 0.7167999148368835, "aqua_rat_34545": 0.7169288396835327, "aqua_rat_33439": 0.7169873118400574, "aqua_rat_52829": 0.7169895172119141, "aqua_rat_42126": 0.7170214056968689, "gsm_rft_15666": 0.71706223487854, "gsm_rft_3828": 0.7171860933303833, "camel_4965": 0.7172964811325073, "aqua_rat_51212": 0.7173179984092712, "aqua_rat_62580": 0.7175307869911194, "aqua_rat_64647": 0.7176765203475952, "aqua_rat_72100": 0.7176942229270935, "aqua_rat_19213": 0.7178871631622314, "aqua_rat_42233": 0.7180247902870178, "camel_45129": 0.7181028127670288, "aqua_rat_78234": 0.7181366682052612, "aqua_rat_6655": 0.7181460857391357, "gsm_rft_57": 0.7181631326675415, "camel_24382": 0.718237042427063, "camel_5197": 0.7183424234390259, "gsm_rft_14753": 0.7183443307876587, "gsm_train_25944": 0.7183443307876587, "gsm_rft_21861": 0.7183443307876587, "aqua_rat_3900": 0.7183792591094971, "aqua_rat_15159": 0.7185805439949036, "camel_5070": 0.7188161611557007, "aqua_rat_19602": 0.7189063429832458, "gsm_rft_20677": 0.7190579771995544, "gsm_rft_10474": 0.7191285490989685, "gsm_rft_18492": 0.7191520929336548, "aqua_rat_81870": 0.7193662524223328, "gsm_rft_22448": 0.7193676829338074, "aqua_rat_50921": 0.7194957137107849, "aqua_rat_76776": 0.7197644114494324, "aqua_rat_70812": 0.7199239134788513, "aqua_rat_48132": 0.7201096415519714, "aqua_rat_20582": 0.7201783657073975, "aqua_rat_25154": 0.720253050327301, "aqua_rat_75856": 0.7208669781684875, "aqua_rat_9493": 0.7208724617958069, "camel_45340": 0.7210353016853333, "gsm_rft_29698": 0.721139669418335, "gsm_train_13418": 0.721139669418335, "aqua_rat_80966": 0.7212717533111572, "gsm_rft_21678": 0.7219929695129395, "aqua_rat_12423": 0.7220034003257751, "camel_45967": 0.7227246165275574, "gsm_rft_9980": 0.7227278351783752, "aqua_rat_83482": 0.7227665781974792, "aqua_rat_38059": 0.7229123115539551, "camel_45178": 0.723136842250824, "gsm_rft_23018": 0.7231868505477905, "gsm_rft_12596": 0.7233851552009583, "camel_45931": 0.7235608100891113, "gsm_train_14053": 0.7237427234649658, "gsm_rft_11828": 0.7237427234649658, "gsm_rft_8806": 0.7237427234649658, "aqua_rat_25765": 0.7238509058952332, "gsm_rft_8656": 0.7244659066200256, "camel_5227": 0.7248772382736206, "gsm_rft_7428": 0.7249251008033752, "gsm_train_21024": 0.7253613471984863, "camel_5165": 0.7255695462226868, "gsm_rft_2034": 0.7259299755096436, "gsm_rft_3538": 0.7259299755096436, "camel_5008": 0.7261444330215454, "aqua_rat_53891": 0.7266595363616943, "camel_45136": 0.7269273996353149, "aqua_rat_13703": 0.7270978689193726, "aqua_rat_56182": 0.7272578477859497, "aqua_rat_45302": 0.7276606559753418, "aqua_rat_72645": 0.7276871204376221, "camel_37936": 0.7280184626579285, "aqua_rat_61619": 0.7280799150466919, "gsm_rft_24978": 0.7282353043556213, "gsm_rft_8537": 0.7287354469299316, "gsm_rft_24420": 0.7287742495536804, "gsm_train_29686": 0.7287742495536804, "gsm_rft_2576": 0.7287939786911011, "gsm_rft_8266": 0.7287939786911011, "aqua_rat_36249": 0.7288604974746704, "aqua_rat_67777": 0.7289572954177856, "gsm_train_18003": 0.7289735078811646, "gsm_rft_24790": 0.7289735078811646, "gsm_rft_25136": 0.7289735078811646, "aqua_rat_30930": 0.7292758226394653, "aqua_rat_84711": 0.7293305397033691, "camel_44806": 0.7297140955924988, "gsm_train_21544": 0.7297986745834351, "gsm_rft_7812": 0.7299112677574158, "aqua_rat_23842": 0.730051577091217, "gsm_rft_18251": 0.730139434337616, "gsm_rft_2271": 0.7303484082221985, "camel_45141": 0.7303674221038818, "gsm_rft_34630": 0.7304311990737915, "aqua_rat_68249": 0.7304829359054565, "aqua_rat_20932": 0.7306619882583618, "aqua_rat_61332": 0.7307496070861816, "gsm_rft_6897": 0.7307615280151367, "aqua_rat_54840": 0.7309455871582031, "gsm_rft_2452": 0.7312949895858765, "aqua_rat_12260": 0.7315208315849304, "aqua_rat_69487": 0.7323040962219238, "aqua_rat_12658": 0.7323300838470459, "aqua_rat_88332": 0.7328225374221802, "gsm_rft_11031": 0.7331218123435974, "gsm_rft_9344": 0.7333996295928955, "gsm_rft_17551": 0.7333996295928955, "gsm_train_17819": 0.7333996295928955, "aqua_rat_71816": 0.7341843247413635, "aqua_rat_12925": 0.7342287302017212, "camel_45149": 0.735258936882019, "camel_29166": 0.7353675961494446, "camel_5189": 0.7353760600090027, "aqua_rat_48959": 0.7354021668434143, "aqua_rat_5108": 0.73578280210495, "aqua_rat_12010": 0.7365416884422302, "camel_45195": 0.7373722791671753, "camel_29154": 0.7388842701911926, "aqua_rat_43435": 0.7408300638198853, "camel_43803": 0.7472957372665405, "aqua_rat_16469": 0.7484862804412842, "camel_28143": 0.7537781596183777, "camel_45190": 0.757274329662323, "camel_45169": 0.7598465085029602, "aqua_rat_67486": 0.7604597210884094, "camel_43782": 0.7606553435325623, "camel_45323": 0.7629920840263367, "camel_45295": 0.7630636096000671, "TheoremQA_panlu/wave_speed1.json": 0.7642419338226318, "aqua_rat_75111": 0.764346182346344, "aqua_rat_63167": 0.765640377998352, "aqua_rat_60081": 0.7657874226570129, "aqua_rat_81926": 0.7670286893844604, "aqua_rat_23035": 0.7694340348243713, "aqua_rat_23105": 0.7711483240127563, "aqua_rat_8610": 0.7725585103034973, "aqua_rat_3234": 0.7733034491539001, "aqua_rat_66162": 0.7735620737075806, "camel_45159": 0.7746737599372864, "aqua_rat_44457": 0.775005578994751, "camel_45174": 0.777073323726654, "camel_45935": 0.7785749435424805, "camel_45155": 0.7797810435295105, "camel_45199": 0.7989225387573242, "camel_45140": 0.8011977076530457, "camel_45163": 0.8041613698005676}, "TheoremQA_wenhuchen/Poisson_process3.json": {"camel_11050": 0, "camel_11172": 0, "camel_10365": 0, "camel_11033": 0, "camel_11282": 0, "camel_10919": 0, "camel_10948": 0, "camel_10938": 0, "camel_10882": 0, "camel_11025": 0, "camel_11332": 0, "camel_11189": 0, "camel_11164": 0, "camel_11860": 0, "camel_11046": 0, "camel_10890": 0, "camel_11364": 0, "camel_11758": 0, "camel_11293": 0, "camel_10397": 0, "camel_11625": 0, "camel_11014": 0, "camel_11357": 0, "camel_11003": 0, "camel_11601": 0, "camel_10889": 0, "camel_10915": 0, "camel_10910": 0, "camel_11644": 0, "camel_11186": 0, "camel_10806": 0, "camel_11693": 0, "camel_11629": 0, "camel_11019": 0, "camel_11197": 0, "camel_9464": 0, "camel_11055": 0, "camel_11007": 0, "camel_11201": 0, "camel_10996": 0, "camel_10327": 0, "camel_11289": 0, "camel_11884": 0, "camel_11624": 0, "camel_10813": 0, "camel_11386": 0, "camel_11192": 0, "camel_11092": 0, "camel_11875": 0, "camel_11316": 0, "camel_11127": 0, "camel_11238": 0, "camel_11853": 0, "camel_11029": 0, "camel_11323": 0, "camel_11630": 0, "camel_11130": 0, "camel_10351": 0, "camel_11328": 0, "camel_11135": 0, "camel_10822": 0, "camel_11649": 0, "camel_11422": 0, "camel_10974": 0, "camel_9522": 0, "camel_11346": 0, "camel_11857": 0, "camel_10367": 0, "camel_10887": 0, "camel_11335": 0, "camel_11105": 0, "camel_10242": 0, "camel_10816": 0, "camel_11355": 0, "camel_11256": 0, "camel_11347": 0, "camel_11804": 0, "camel_10905": 0, "camel_11658": 0, "camel_11228": 0, "camel_11239": 0, "camel_11162": 0, "camel_10364": 0, "camel_11539": 0, "camel_11325": 0, "camel_10354": 0, "camel_11286": 0, "camel_11010": 0, "camel_11633": 0, "camel_11140": 0, "camel_10606": 0, "camel_11143": 0, "camel_10980": 0, "camel_10335": 0, "camel_10976": 0, "camel_11864": 0, "camel_11322": 0, "camel_10998": 0, "camel_11671": 0, "camel_11558": 0, "camel_11605": 0, "camel_11112": 0, "camel_9398": 0, "camel_11307": 0, "camel_11026": 0, "camel_11179": 0, "camel_9455": 0, "camel_11281": 0, "camel_11883": 0, "camel_11397": 0, "camel_11036": 0, "camel_11188": 0, "camel_8383": 0, "camel_11094": 0, "camel_11604": 0, "camel_10983": 0, "camel_10929": 0, "camel_11067": 0, "camel_11153": 0, "camel_10839": 0, "camel_11182": 0, "camel_9484": 0, "camel_11660": 0, "camel_11072": 0, "camel_11071": 0, "camel_10936": 0, "camel_11001": 0, "camel_11032": 0, "camel_10897": 0, "camel_11081": 0, "camel_10943": 0, "camel_11185": 0, "camel_10930": 0, "camel_11066": 0, "camel_9570": 0, "camel_10833": 0, "camel_10951": 0, "camel_10966": 0, "camel_11655": 0, "camel_11650": 0, "camel_10369": 0, "camel_11023": 0, "camel_11208": 0, "camel_10385": 0, "camel_11161": 0, "camel_11122": 0, "camel_10955": 0, "camel_10350": 0, "camel_11000": 0, "camel_11183": 0, "camel_10977": 0, "camel_11310": 0, "camel_11394": 0, "camel_10950": 0, "camel_10896": 0, "camel_10361": 0, "camel_10999": 0, "camel_11181": 0, "camel_10568": 0, "camel_10920": 0, "camel_11234": 0, "camel_10922": 0, "camel_10923": 0, "camel_9383": 0, "camel_10939": 0, "camel_10979": 0, "camel_11218": 0, "camel_10969": 0, "camel_11308": 0, "camel_11168": 0, "camel_11866": 0, "camel_11008": 0, "camel_11356": 0, "camel_11321": 0, "camel_11255": 0, "camel_10926": 0, "camel_11302": 0, "camel_11121": 0, "camel_10352": 0, "camel_11983": 0, "camel_11344": 0, "camel_11317": 0, "camel_11926": 0, "camel_11358": 0, "camel_10908": 0, "camel_11563": 0, "camel_10828": 0, "aqua_rat_9422": 0.7783714532852173, "aqua_rat_23464": 0.7784138917922974, "aqua_rat_20677": 0.7788582444190979, "aqua_rat_22368": 0.7791890501976013, "aqua_rat_85797": 0.7823147177696228, "aqua_rat_23262": 0.7828271985054016, "aqua_rat_77065": 0.7837610244750977, "aqua_rat_4849": 0.7841008305549622, "aqua_rat_37149": 0.7848066091537476, "aqua_rat_35997": 0.7891892194747925, "aqua_rat_89088": 0.7923734784126282, "aqua_rat_48773": 0.7947463393211365, "aqua_rat_26702": 0.7956699728965759}, "TheoremQA_xinyi/dag_1.json": {"camel_23151": 0, "camel_23166": 0, "camel_23292": 0, "camel_23364": 0, "camel_23442": 0, "camel_23980": 0, "camel_22573": 0, "camel_22381": 0, "camel_23432": 0, "camel_23144": 0, "camel_22949": 0, "camel_23308": 0, "camel_23172": 0, "camel_23962": 0, "camel_23391": 0, "camel_23165": 0, "camel_22476": 0, "camel_23931": 0, "camel_22467": 0, "camel_23131": 0, "camel_22808": 0, "camel_21059": 0, "camel_23196": 0, "camel_23423": 0, "camel_23342": 0, "camel_22449": 0, "camel_23154": 0, "camel_22352": 0, "camel_23985": 0, "camel_22407": 0, "camel_23999": 0, "camel_22446": 0, "camel_23921": 0, "camel_20734": 0, "camel_22068": 0, "camel_23179": 0, "camel_22170": 0, "camel_23963": 0, "camel_23358": 0, "camel_23189": 0, "camel_23198": 0, "camel_22426": 0, "camel_22414": 0, "camel_22940": 0, "camel_22157": 0, "camel_22473": 0, "camel_23992": 0, "camel_22406": 0, "camel_22912": 0, "camel_22409": 0, "camel_22418": 0, "camel_22338": 0, "camel_22823": 0, "camel_23158": 0, "camel_22334": 0, "camel_23424": 0, "camel_23926": 0, "camel_22455": 0, "camel_22807": 0, "camel_22463": 0, "camel_23972": 0, "camel_22403": 0, "camel_23984": 0, "camel_22442": 0, "camel_22453": 0, "camel_23966": 0, "camel_23941": 0, "camel_22440": 0, "camel_22404": 0, "camel_21064": 0, "camel_23174": 0, "camel_23949": 0, "camel_23933": 0, "camel_23987": 0, "camel_23287": 0, "camel_23960": 0, "camel_23952": 0, "camel_23943": 0, "camel_22465": 0, "camel_23922": 0, "camel_22475": 0, "camel_23959": 0, "camel_22421": 0, "camel_22405": 0, "camel_23954": 0, "camel_23939": 0, "camel_23955": 0, "camel_23946": 0, "camel_22460": 0, "camel_22412": 0, "camel_23400": 0, "camel_22441": 0, "camel_22664": 0, "camel_22416": 0, "camel_22400": 0, "camel_22422": 0, "camel_22436": 0, "camel_22401": 0, "camel_23299": 0, "camel_22458": 0, "camel_22464": 0, "camel_22415": 0, "camel_23161": 0, "camel_22471": 0, "camel_22434": 0, "camel_22444": 0, "camel_22863": 0, "camel_22456": 0, "camel_23990": 0, "camel_22430": 0, "camel_22468": 0, "camel_22424": 0, "camel_22410": 0, "camel_23994": 0, "camel_23180": 0, "camel_22466": 0, "camel_22408": 0, "camel_22438": 0, "camel_23988": 0, "camel_22427": 0, "camel_22474": 0, "camel_22413": 0, "camel_23920": 0, "camel_23971": 0, "camel_22443": 0, "camel_22448": 0, "camel_23940": 0, "camel_22417": 0, "camel_22061": 0, "camel_22435": 0, "camel_23944": 0, "camel_23928": 0, "camel_23989": 0, "camel_22432": 0, "camel_22462": 0, "camel_22450": 0, "camel_22461": 0, "camel_23975": 0, "camel_23969": 0, "camel_23995": 0, "camel_22459": 0, "camel_22437": 0, "camel_23976": 0, "camel_22477": 0, "camel_23927": 0, "camel_22470": 0, "camel_23935": 0, "camel_22439": 0, "camel_22431": 0, "camel_23977": 0, "camel_23930": 0, "camel_22411": 0, "camel_23177": 0, "camel_22472": 0, "camel_23164": 0, "camel_23934": 0, "camel_22433": 0, "camel_22478": 0, "camel_23925": 0, "camel_22452": 0, "camel_22454": 0, "camel_23193": 0, "camel_22428": 0, "camel_22402": 0, "camel_23181": 0, "camel_23993": 0, "camel_23997": 0, "camel_22420": 0, "camel_22447": 0, "camel_22469": 0, "camel_22425": 0, "camel_23983": 0, "camel_22429": 0, "camel_23942": 0, "camel_23998": 0, "camel_22451": 0, "camel_22445": 0, "camel_22419": 0, "camel_22423": 0, "camel_23978": 0, "camel_23996": 0, "camel_23938": 0, "camel_23948": 0, "camel_22457": 0, "camel_21098": 0, "camel_23986": 0, "camel_23968": 0, "camel_23958": 0, "camel_23951": 0, "camel_23932": 0, "camel_23945": 0, "TheoremQA_xinyi/dag_1.json": 0, "camel_23923": 0, "camel_19979": 0.7413122057914734, "camel_36749": 0.7453500032424927, "TheoremQA_xinyi/dag_3.json": 0.7635327577590942, "aqua_rat_34441": 0.7639366388320923, "aqua_rat_41715": 0.7665359377861023, "aqua_rat_44391": 0.7665859460830688, "aqua_rat_67605": 0.7697687745094299}, "TheoremQA_xueguangma/geometric_brownian_motion.json": {"TheoremQA_xueguangma/geometric_brownian_motion.json": 0, "aqua_rat_46842": 0.7071127891540527, "TheoremQA_xueguangma/options_theory.json": 0.7071317434310913, "camel_16739": 0.7072350978851318, "camel_16781": 0.7075127959251404, "camel_17928": 0.7078572511672974, "camel_10545": 0.7079748511314392, "camel_16773": 0.7079824805259705, "camel_16730": 0.708161473274231, "camel_16749": 0.7082529664039612, "camel_16761": 0.7084400653839111, "camel_10495": 0.7088412046432495, "camel_9557": 0.7088673114776611, "camel_16732": 0.7089686989784241, "camel_10544": 0.7093995809555054, "camel_45742": 0.7094640731811523, "camel_37752": 0.7096630334854126, "camel_16728": 0.709703803062439, "TheoremQA_xueguangma/fair_market_value_of_a_bond.json": 0.7101336121559143, "camel_16746": 0.7103931903839111, "camel_38645": 0.7112801671028137, "camel_16736": 0.711549699306488, "camel_16797": 0.7116143107414246, "camel_37742": 0.7121003866195679, "camel_10546": 0.71220463514328, "camel_16760": 0.7122091054916382, "camel_16774": 0.712364912033081, "TheoremQA_xueguangma/capital_asset_pricing_model.json": 0.7123791575431824, "camel_17942": 0.7125031352043152, "camel_16758": 0.7126104831695557, "camel_10526": 0.7130157947540283, "camel_38649": 0.7130829095840454, "camel_45738": 0.7133424878120422, "camel_38643": 0.7136435508728027, "camel_25251": 0.7139409780502319, "camel_16796": 0.7140305638313293, "camel_16726": 0.7143969535827637, "camel_16750": 0.7144705653190613, "camel_10553": 0.7146397233009338, "camel_38714": 0.7147208452224731, "camel_16769": 0.714776337146759, "camel_10511": 0.7151025533676147, "camel_17969": 0.7157752513885498, "camel_16735": 0.7157928943634033, "camel_25244": 0.7163166999816895, "camel_16784": 0.7163261771202087, "camel_16772": 0.7173770070075989, "camel_16793": 0.717530369758606, "camel_17959": 0.7175436615943909, "camel_16756": 0.7176599502563477, "camel_17515": 0.7179217338562012, "camel_16745": 0.7186521887779236, "camel_16744": 0.7188172936439514, "TheoremQA_xueguangma/spot_rate.json": 0.7191024422645569, "camel_16788": 0.7195929288864136, "camel_17985": 0.7197657823562622, "camel_17446": 0.7201814651489258, "camel_10530": 0.7204986810684204, "camel_17996": 0.720579206943512, "camel_16751": 0.7205831408500671, "camel_10540": 0.7206158638000488, "camel_17972": 0.7211624383926392, "camel_17930": 0.721224308013916, "camel_17932": 0.7214300036430359, "camel_16734": 0.7215316891670227, "camel_17958": 0.7218589186668396, "camel_10482": 0.7218972444534302, "camel_16792": 0.721918523311615, "camel_38662": 0.7220686078071594, "camel_16779": 0.7226176261901855, "camel_17982": 0.7227581739425659, "camel_17440": 0.7230263352394104, "camel_10504": 0.7234401106834412, "camel_16753": 0.7237727046012878, "camel_17993": 0.7240287065505981, "camel_10551": 0.7243314385414124, "camel_10543": 0.7246137857437134, "camel_38693": 0.7251457571983337, "camel_16720": 0.7251836061477661, "camel_10498": 0.725644588470459, "camel_17978": 0.7256765961647034, "camel_10531": 0.7257537841796875, "camel_17948": 0.7257829904556274, "camel_16776": 0.7262170314788818, "camel_17944": 0.7265285849571228, "camel_16752": 0.7267622351646423, "camel_16770": 0.7268134355545044, "camel_17995": 0.7270215749740601, "camel_17977": 0.7271392941474915, "camel_17931": 0.7271984219551086, "camel_16727": 0.7275877594947815, "camel_17980": 0.7276380658149719, "camel_17973": 0.728056013584137, "camel_16741": 0.7281450629234314, "camel_16786": 0.7294222712516785, "camel_10497": 0.7310433387756348, "camel_10502": 0.7315956354141235, "camel_17934": 0.7322993874549866, "camel_16777": 0.7325613498687744, "camel_16799": 0.733700692653656, "camel_10523": 0.7342332601547241, "camel_17962": 0.7344854474067688, "camel_16759": 0.7345901131629944, "camel_16762": 0.7348070740699768, "camel_10507": 0.735596239566803, "camel_37729": 0.7358154654502869, "camel_16787": 0.7359486222267151, "camel_16778": 0.7361758947372437, "camel_16794": 0.736325740814209, "camel_10486": 0.7382465600967407, "camel_16733": 0.7384232878684998, "camel_17981": 0.7393212914466858, "camel_10557": 0.7395784258842468, "camel_10555": 0.7401140332221985, "camel_10491": 0.7401609420776367, "camel_38648": 0.740422248840332, "camel_16782": 0.7405008673667908, "camel_10539": 0.7406407594680786, "camel_10493": 0.7407211661338806, "camel_17938": 0.7415789365768433, "camel_10529": 0.742260754108429, "camel_10537": 0.742322564125061, "camel_17479": 0.7434520721435547, "camel_10515": 0.7442213296890259, "camel_17513": 0.7445802092552185, "camel_17518": 0.74566251039505, "camel_10480": 0.7462912201881409, "camel_16755": 0.7462915182113647, "camel_17945": 0.7465146780014038, "camel_17947": 0.7465547919273376, "camel_17988": 0.7472103238105774, "camel_17922": 0.7472784519195557, "camel_17946": 0.7474504709243774, "camel_16748": 0.7475506663322449, "camel_10506": 0.7477940917015076, "camel_17974": 0.7479676008224487, "camel_10542": 0.747992217540741, "camel_17933": 0.7483654618263245, "TheoremQA_xueguangma/forward_price_2.json": 0.7485796213150024, "camel_17999": 0.7496735453605652, "camel_17475": 0.7499175667762756, "camel_17952": 0.7505413889884949, "camel_10558": 0.7506865859031677, "camel_17976": 0.7513384222984314, "camel_10532": 0.752068042755127, "camel_16783": 0.7530300617218018, "camel_10492": 0.7533954977989197, "camel_17957": 0.7536807060241699, "camel_17987": 0.7541861534118652, "camel_10488": 0.7542605996131897, "camel_17967": 0.7570449113845825, "camel_17960": 0.7584606409072876, "camel_17955": 0.7588735818862915, "camel_17937": 0.7592134475708008, "camel_17994": 0.75951087474823, "camel_17979": 0.7601078748703003, "camel_16738": 0.7602388858795166, "camel_17968": 0.7640106081962585, "camel_17990": 0.7656087875366211, "camel_17983": 0.7669541239738464, "camel_17950": 0.7677212953567505, "camel_45695": 0.7726691961288452, "camel_17936": 0.7757549285888672, "camel_17927": 0.7758762240409851, "camel_16785": 0.7780898213386536, "camel_17943": 0.7800605893135071, "camel_10514": 0.7801536321640015, "TheoremQA_xueguangma/binomial_model_1.json": 0.7818527817726135, "camel_17935": 0.7827599048614502, "camel_16780": 0.7839610576629639, "camel_45730": 0.7841482162475586, "camel_17998": 0.7856768369674683, "camel_17941": 0.7868565320968628, "camel_17469": 0.7871749997138977, "camel_16763": 0.7880547046661377, "camel_17926": 0.7893900871276855, "camel_17964": 0.7927337884902954, "TheoremQA_xueguangma/binomial_model_2.json": 0.7938101887702942, "camel_16795": 0.7939270734786987, "camel_17954": 0.7940382957458496, "camel_16791": 0.7947717308998108, "camel_17939": 0.7948694825172424, "camel_17924": 0.7951605319976807, "camel_17929": 0.7981123924255371, "camel_16740": 0.798213541507721, "TheoremQA_xueguangma/put_call_parity_1.json": 0.7982320785522461, "camel_17991": 0.7990178465843201, "TheoremQA_xueguangma/forward_price_1.json": 0.800791323184967, "camel_16754": 0.801815390586853, "camel_17975": 0.8047937750816345, "camel_17984": 0.8074995875358582, "camel_16789": 0.8098586201667786, "camel_17921": 0.8100622296333313, "camel_17940": 0.8111457824707031, "camel_16747": 0.8123705387115479, "camel_17989": 0.8144365549087524, "camel_17965": 0.8144665360450745, "camel_17961": 0.8158907890319824, "camel_17963": 0.8172017931938171, "camel_17923": 0.8349059224128723}, "TheoremQA_xinyi/rate_distortion_function_1.json": {"TheoremQA_xinyi/rate_distortion_function_1.json": 0, "aqua_rat_19750": 0.6335628032684326, "aqua_rat_62074": 0.6335790157318115, "camel_44543": 0.6335800290107727, "camel_38707": 0.6336883902549744, "aqua_rat_83552": 0.6337162256240845, "aqua_rat_46866": 0.6338165998458862, "aqua_rat_6164": 0.6338189840316772, "camel_15793": 0.633863091468811, "camel_38645": 0.6338967680931091, "aqua_rat_81382": 0.633922815322876, "camel_28007": 0.6339601278305054, "camel_28361": 0.6339777112007141, "camel_25533": 0.6340672969818115, "camel_25395": 0.6341217160224915, "camel_25266": 0.6342591643333435, "aqua_rat_73720": 0.6342605352401733, "aqua_rat_60384": 0.6343477368354797, "aqua_rat_75858": 0.6343667507171631, "aqua_rat_31571": 0.634397029876709, "aqua_rat_33903": 0.6344075202941895, "camel_36334": 0.6344516277313232, "aqua_rat_59216": 0.6344652771949768, "camel_38787": 0.6346503496170044, "aqua_rat_42720": 0.6347277760505676, "aqua_rat_56027": 0.6347511410713196, "aqua_rat_86877": 0.6348425149917603, "camel_24997": 0.6348491311073303, "camel_38740": 0.6349731683731079, "TheoremQA_maxku/cv-imageprocessing5-histogram.json": 0.6349826455116272, "camel_38675": 0.6351152062416077, "camel_45836": 0.6351544857025146, "aqua_rat_65589": 0.6351641416549683, "camel_25598": 0.635236382484436, "aqua_rat_34251": 0.6355047821998596, "camel_45805": 0.635564923286438, "camel_27541": 0.635628879070282, "camel_28640": 0.6356290578842163, "aqua_rat_52107": 0.6357752680778503, "aqua_rat_8518": 0.6359221339225769, "camel_25585": 0.6359259486198425, "aqua_rat_81157": 0.6359634399414062, "camel_28888": 0.6359848976135254, "aqua_rat_60553": 0.636002242565155, "aqua_rat_30381": 0.6360108256340027, "aqua_rat_39605": 0.636115550994873, "aqua_rat_4946": 0.6361580491065979, "aqua_rat_11574": 0.6361626982688904, "aqua_rat_74788": 0.6362760066986084, "camel_9911": 0.6362899541854858, "aqua_rat_66494": 0.636336624622345, "aqua_rat_50486": 0.6365366578102112, "aqua_rat_31598": 0.6365520358085632, "camel_37553": 0.6366657018661499, "camel_28642": 0.6367706656455994, "aqua_rat_72155": 0.6368851661682129, "camel_38743": 0.6369055509567261, "aqua_rat_5583": 0.6369782090187073, "aqua_rat_68579": 0.6370670795440674, "camel_27418": 0.6371639966964722, "aqua_rat_40285": 0.6371641159057617, "camel_41005": 0.6373116374015808, "aqua_rat_49332": 0.6373494863510132, "aqua_rat_56477": 0.6373813152313232, "camel_41325": 0.6374381184577942, "aqua_rat_60134": 0.6375980973243713, "camel_26518": 0.6378096342086792, "aqua_rat_82257": 0.6378710269927979, "camel_38715": 0.6378892064094543, "camel_38758": 0.6379435658454895, "camel_38718": 0.6380107998847961, "camel_38717": 0.6381202936172485, "camel_38692": 0.6381382346153259, "aqua_rat_17977": 0.6381672620773315, "aqua_rat_22601": 0.6381888389587402, "aqua_rat_43043": 0.6381978392601013, "aqua_rat_79659": 0.6382207870483398, "aqua_rat_41800": 0.6382548213005066, "camel_28433": 0.6383346319198608, "aqua_rat_58646": 0.6383516788482666, "aqua_rat_55600": 0.638375461101532, "aqua_rat_82931": 0.6385343074798584, "camel_25524": 0.6386246085166931, "camel_13809": 0.6387780904769897, "camel_37507": 0.6387780904769897, "aqua_rat_30472": 0.6389163732528687, "aqua_rat_85136": 0.6389999389648438, "aqua_rat_43429": 0.6391172409057617, "aqua_rat_5881": 0.6391255855560303, "aqua_rat_50580": 0.6392154693603516, "camel_38773": 0.6393774151802063, "aqua_rat_55231": 0.6394193768501282, "aqua_rat_24981": 0.6399667263031006, "camel_38697": 0.6400114297866821, "aqua_rat_74819": 0.6403207182884216, "camel_38699": 0.6403664946556091, "camel_26535": 0.6403682827949524, "camel_25573": 0.640506386756897, "camel_25046": 0.6405712962150574, "aqua_rat_41697": 0.6408110857009888, "camel_38700": 0.6408217549324036, "aqua_rat_84154": 0.6408830881118774, "aqua_rat_53165": 0.6409450769424438, "aqua_rat_72954": 0.6409929394721985, "aqua_rat_34577": 0.6410434246063232, "aqua_rat_88917": 0.6410862803459167, "camel_25555": 0.6411577463150024, "camel_25597": 0.6413040161132812, "camel_39482": 0.6414456963539124, "camel_25548": 0.6414697170257568, "aqua_rat_74996": 0.6415334939956665, "aqua_rat_39252": 0.6417205333709717, "aqua_rat_10733": 0.641836941242218, "aqua_rat_11117": 0.6419045925140381, "camel_36502": 0.6422592997550964, "aqua_rat_10089": 0.6423470377922058, "camel_25584": 0.6423935890197754, "camel_37666": 0.6424434781074524, "aqua_rat_25135": 0.642558217048645, "camel_27920": 0.6426905989646912, "camel_25528": 0.642796516418457, "camel_38660": 0.642891526222229, "camel_25589": 0.6429359912872314, "aqua_rat_41618": 0.6429398655891418, "camel_25541": 0.643132209777832, "camel_38714": 0.6436964869499207, "aqua_rat_29824": 0.6436980962753296, "aqua_rat_3031": 0.6437694430351257, "camel_25559": 0.6438427567481995, "camel_41923": 0.6439551711082458, "camel_38748": 0.6440860033035278, "camel_40964": 0.6441890001296997, "camel_13802": 0.6442049145698547, "camel_37705": 0.6444735527038574, "camel_38762": 0.644771933555603, "camel_25568": 0.6448982357978821, "camel_25542": 0.6449322700500488, "camel_25577": 0.6449379324913025, "camel_27981": 0.6451142430305481, "aqua_rat_84046": 0.6452440619468689, "camel_25547": 0.6452930569648743, "camel_38665": 0.645469069480896, "camel_38730": 0.6460229754447937, "camel_25540": 0.6464105844497681, "camel_25543": 0.6465340852737427, "aqua_rat_72603": 0.6466563940048218, "aqua_rat_9175": 0.6467016935348511, "aqua_rat_43966": 0.6468849778175354, "camel_38685": 0.6469308733940125, "camel_25572": 0.6472353935241699, "aqua_rat_80404": 0.6481138467788696, "aqua_rat_44665": 0.6481661200523376, "aqua_rat_36210": 0.6483526825904846, "camel_29099": 0.6485983729362488, "aqua_rat_51852": 0.648646891117096, "camel_25452": 0.6487622857093811, "camel_25107": 0.6487818360328674, "TheoremQA_xinyi/huffman_code_2.json": 0.6488434672355652, "camel_38760": 0.6490444540977478, "aqua_rat_58120": 0.6494032144546509, "aqua_rat_58031": 0.6498426795005798, "camel_38649": 0.6498947739601135, "camel_38796": 0.6515178680419922, "aqua_rat_19675": 0.6535841822624207, "camel_38642": 0.6546487212181091, "camel_38643": 0.6547859907150269, "aqua_rat_84213": 0.6551104187965393, "camel_13773": 0.6557639837265015, "camel_27356": 0.6568482518196106, "camel_13770": 0.6568741202354431, "camel_26547": 0.6569466590881348, "aqua_rat_42217": 0.6571557521820068, "camel_25581": 0.6573348045349121, "aqua_rat_49646": 0.6583819389343262, "camel_44798": 0.6587502360343933, "camel_25115": 0.6605790853500366, "TheoremQA_xinyi/data_processing.json": 0.6608443260192871, "TheoremQA_xinyi/distortion_rate_function_2.json": 0.6625043153762817, "aqua_rat_27125": 0.6632342338562012, "TheoremQA_xinyi/huffman_code_3.json": 0.6632476449012756, "camel_25447": 0.6637412905693054, "aqua_rat_70783": 0.6644614338874817, "aqua_rat_9603": 0.6645944118499756, "TheoremQA_xinyi/huffman_code_1.json": 0.6654684543609619, "aqua_rat_42161": 0.6658902764320374, "aqua_rat_23428": 0.6673868894577026, "camel_44741": 0.6771433353424072, "TheoremQA_xinyi/expected_distortion.json": 0.6837332248687744, "camel_38527": 0.6902039647102356, "TheoremQA_xinyi/markov_inequality.json": 0.6921734809875488, "TheoremQA_xinyi/maximum_entropy_1.json": 0.7034922242164612, "TheoremQA_xinyi/channel_capacity_1.json": 0.7159263491630554, "TheoremQA_xinyi/kraft_inequality.json": 0.7201346755027771, "TheoremQA_xinyi/distortion_rate_function_1.json": 0.7227216958999634, "TheoremQA_xinyi/binary_symmetric_channel_1.json": 0.7229107022285461, "TheoremQA_xinyi/concavity.json": 0.7336527705192566, "TheoremQA_xinyi/fano_inequality.json": 0.7718321681022644, "TheoremQA_xinyi/rate_distortion_function_2.json": 0.7985599040985107, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.8037732243537903, "TheoremQA_xinyi/shannon_lower_bound.json": 0.820603609085083}, "TheoremQA_xinyi/distortion_rate_function_2.json": {"TheoremQA_xinyi/distortion_rate_function_2.json": 0, "math_train_counting_and_probability_629": 0.5756045579910278, "math_test_intermediate_algebra_1593": 0.5756464004516602, "math_train_intermediate_algebra_1530": 0.5756511092185974, "math_test_intermediate_algebra_1580": 0.5757125020027161, "math_train_intermediate_algebra_518": 0.5758957862854004, "math_train_intermediate_algebra_1936": 0.5759009718894958, "math_train_intermediate_algebra_529": 0.5760218501091003, "math_train_intermediate_algebra_1652": 0.5760905146598816, "camel_18740": 0.5761584043502808, "math_train_intermediate_algebra_825": 0.5762261152267456, "camel_18752": 0.5762419104576111, "math_train_intermediate_algebra_1712": 0.5765620470046997, "math_train_intermediate_algebra_282": 0.5766578912734985, "camel_43057": 0.5766631364822388, "camel_18771": 0.5766993761062622, "math_test_intermediate_algebra_673": 0.5767061710357666, "math_train_intermediate_algebra_54": 0.5767136812210083, "math_train_algebra_169": 0.5767726302146912, "math_train_algebra_739": 0.5768083333969116, "math_test_intermediate_algebra_1805": 0.5769284963607788, "math_train_algebra_2632": 0.577022910118103, "math_test_intermediate_algebra_437": 0.5771172642707825, "math_test_intermediate_algebra_1855": 0.5773699879646301, "camel_42465": 0.57740318775177, "math_test_intermediate_algebra_891": 0.577573299407959, "math_test_intermediate_algebra_898": 0.5775822997093201, "camel_19499": 0.5775842666625977, "camel_18795": 0.5776499509811401, "camel_18792": 0.5777246356010437, "math_test_intermediate_algebra_2111": 0.577772855758667, "math_train_precalculus_816": 0.5778378844261169, "math_test_intermediate_algebra_1542": 0.5782825350761414, "math_train_algebra_2020": 0.5783108472824097, "math_train_algebra_85": 0.5783655047416687, "math_test_algebra_282": 0.5783742070198059, "math_test_algebra_1912": 0.5783987641334534, "math_test_intermediate_algebra_1640": 0.5784749388694763, "math_train_intermediate_algebra_1285": 0.5785348415374756, "camel_45105": 0.57868891954422, "math_test_precalculus_499": 0.5786942839622498, "math_train_intermediate_algebra_1989": 0.5786957740783691, "math_train_intermediate_algebra_1110": 0.5788689851760864, "math_test_intermediate_algebra_955": 0.5789104700088501, "math_train_intermediate_algebra_171": 0.5792314410209656, "camel_18739": 0.5792389512062073, "math_train_precalculus_932": 0.5793024897575378, "math_test_algebra_1810": 0.5793101787567139, "math_train_intermediate_algebra_669": 0.5793259143829346, "math_train_intermediate_algebra_335": 0.579386830329895, "math_train_intermediate_algebra_271": 0.5794174671173096, "math_test_intermediate_algebra_987": 0.5794854164123535, "TheoremQA_xinyi/change_of_variable_linear.json": 0.5795537829399109, "math_train_algebra_268": 0.5800619721412659, "camel_18133": 0.5801490545272827, "math_test_intermediate_algebra_1454": 0.5801637172698975, "camel_19638": 0.5802223086357117, "TheoremQA_xinyi/expected_length_of_instatntaneous_code.json": 0.58031165599823, "math_train_intermediate_algebra_616": 0.5803620219230652, "math_test_intermediate_algebra_2164": 0.5803820490837097, "camel_18779": 0.5806010365486145, "math_test_intermediate_algebra_420": 0.5806631445884705, "camel_18933": 0.5806767344474792, "math_test_intermediate_algebra_1571": 0.5807151794433594, "math_train_intermediate_algebra_592": 0.5807854533195496, "math_test_intermediate_algebra_986": 0.5808054804801941, "TheoremQA_xinyi/expected_waiting_time.json": 0.5809288024902344, "math_test_intermediate_algebra_379": 0.5809780955314636, "math_test_intermediate_algebra_495": 0.5810695886611938, "math_test_intermediate_algebra_527": 0.5811821222305298, "math_test_algebra_2438": 0.5814032554626465, "math_train_intermediate_algebra_372": 0.5814290046691895, "math_test_intermediate_algebra_1512": 0.5814626812934875, "math_test_intermediate_algebra_1773": 0.5815861225128174, "camel_18929": 0.581598699092865, "math_test_intermediate_algebra_1948": 0.5816252827644348, "math_test_intermediate_algebra_692": 0.5820489525794983, "math_train_algebra_2678": 0.5821076035499573, "camel_18763": 0.5823460817337036, "math_test_algebra_1031": 0.5824750065803528, "math_train_intermediate_algebra_1019": 0.5825415849685669, "math_train_intermediate_algebra_1647": 0.582616925239563, "math_train_intermediate_algebra_1531": 0.58262038230896, "TheoremQA_wenhuchen/double_integral2.json": 0.5826696157455444, "TheoremQA_mingyin/complete-metric-space1.json": 0.5827365517616272, "math_train_algebra_16": 0.5832310318946838, "math_train_intermediate_algebra_809": 0.5834141969680786, "math_train_intermediate_algebra_639": 0.5834761261940002, "camel_18781": 0.5835205912590027, "math_test_algebra_1362": 0.5836620330810547, "math_train_precalculus_1011": 0.583734393119812, "math_train_algebra_379": 0.5838509202003479, "math_train_precalculus_314": 0.5840922594070435, "math_train_intermediate_algebra_2136": 0.584145724773407, "math_train_algebra_823": 0.5842459201812744, "math_test_intermediate_algebra_677": 0.5843502879142761, "math_test_intermediate_algebra_1791": 0.584385871887207, "math_train_intermediate_algebra_2069": 0.584606945514679, "math_test_algebra_2192": 0.5847643613815308, "math_train_intermediate_algebra_1545": 0.584930956363678, "math_train_intermediate_algebra_1012": 0.5850525498390198, "camel_38985": 0.5852153301239014, "camel_18330": 0.5858256220817566, "math_train_intermediate_algebra_557": 0.5858572721481323, "math_test_intermediate_algebra_763": 0.5862225890159607, "math_test_algebra_945": 0.586845338344574, "camel_42126": 0.5870397686958313, "math_train_intermediate_algebra_103": 0.5870453119277954, "math_train_intermediate_algebra_681": 0.5873015522956848, "math_test_algebra_2641": 0.5873296856880188, "math_train_intermediate_algebra_961": 0.5873995423316956, "TheoremQA_wenhuchen/Poisson_process2.json": 0.5875269174575806, "math_train_intermediate_algebra_1713": 0.5875535011291504, "math_test_intermediate_algebra_1511": 0.5875812768936157, "math_train_algebra_394": 0.5876004099845886, "math_test_intermediate_algebra_493": 0.5878579616546631, "math_train_intermediate_algebra_1172": 0.5880190134048462, "math_test_intermediate_algebra_163": 0.5882580876350403, "camel_18935": 0.5882906913757324, "math_test_intermediate_algebra_17": 0.5882911086082458, "math_test_algebra_2022": 0.5883423686027527, "math_train_intermediate_algebra_1313": 0.5884990096092224, "math_train_algebra_1681": 0.5885475873947144, "camel_39029": 0.5885491371154785, "math_train_intermediate_algebra_1604": 0.588984489440918, "math_test_intermediate_algebra_74": 0.5891702771186829, "math_test_intermediate_algebra_1448": 0.5896043181419373, "math_train_intermediate_algebra_1205": 0.5897130966186523, "math_test_intermediate_algebra_922": 0.5897234678268433, "camel_18107": 0.5897729992866516, "math_test_intermediate_algebra_1187": 0.5898861289024353, "math_train_intermediate_algebra_919": 0.5898865461349487, "math_train_intermediate_algebra_1196": 0.5898979306221008, "TheoremQA_mingyin/martingale2.json": 0.5905287265777588, "math_train_algebra_980": 0.5905658006668091, "camel_18772": 0.5905946493148804, "math_test_intermediate_algebra_1151": 0.5907471179962158, "math_test_intermediate_algebra_1171": 0.5910918116569519, "math_train_intermediate_algebra_245": 0.5918582081794739, "math_train_intermediate_algebra_672": 0.5918946266174316, "math_test_algebra_487": 0.5920932292938232, "math_train_intermediate_algebra_2110": 0.5922237634658813, "math_train_intermediate_algebra_699": 0.5925406217575073, "math_train_intermediate_algebra_203": 0.5928647518157959, "math_train_intermediate_algebra_1383": 0.5929141044616699, "math_test_intermediate_algebra_121": 0.5935866832733154, "camel_18914": 0.5936921834945679, "math_train_precalculus_210": 0.5939467549324036, "math_test_intermediate_algebra_1975": 0.5945302844047546, "math_test_algebra_480": 0.5946007966995239, "math_train_intermediate_algebra_1432": 0.5952000617980957, "math_train_intermediate_algebra_241": 0.5952325463294983, "math_test_intermediate_algebra_1390": 0.5957300066947937, "camel_18755": 0.5960529446601868, "math_test_algebra_35": 0.5964338183403015, "camel_18388": 0.5964341163635254, "camel_18348": 0.5965707302093506, "math_train_intermediate_algebra_1672": 0.5968182682991028, "math_train_intermediate_algebra_360": 0.5971406698226929, "math_train_intermediate_algebra_1027": 0.5973123908042908, "math_test_intermediate_algebra_2013": 0.5986747145652771, "math_train_algebra_681": 0.5987942814826965, "math_test_intermediate_algebra_967": 0.5989224910736084, "math_train_algebra_2281": 0.599260687828064, "math_test_intermediate_algebra_1365": 0.5999956130981445, "math_test_intermediate_algebra_1503": 0.6007740497589111, "math_train_intermediate_algebra_419": 0.6009262204170227, "math_train_intermediate_algebra_2071": 0.6038550734519958, "math_train_intermediate_algebra_1513": 0.6043898463249207, "math_test_intermediate_algebra_1323": 0.604505181312561, "math_test_algebra_1375": 0.6049121618270874, "math_test_intermediate_algebra_145": 0.6051139235496521, "math_test_intermediate_algebra_2002": 0.6053216457366943, "math_test_algebra_628": 0.6053510308265686, "math_train_intermediate_algebra_1465": 0.6088816523551941, "math_test_precalculus_1056": 0.6098617911338806, "math_train_intermediate_algebra_750": 0.6113743185997009, "camel_45101": 0.6113967299461365, "TheoremQA_mingyin/log-concave1.json": 0.6127781867980957, "math_train_intermediate_algebra_821": 0.6190943121910095, "math_train_intermediate_algebra_1190": 0.6198603510856628, "TheoremQA_xinyi/cramer_rao_lower_bound_1.json": 0.6305001378059387, "TheoremQA_xinyi/markov_inequality.json": 0.6310506463050842, "TheoremQA_xinyi/cramer_rao_lower_bound_2.json": 0.6392644643783569, "TheoremQA_mingyin/convexity1.json": 0.6445223093032837, "TheoremQA_xinyi/maximum_entropy_1.json": 0.6479719281196594, "TheoremQA_xinyi/fisher_information_4.json": 0.6526252627372742, "TheoremQA_xinyi/fisher_information_3.json": 0.6526274681091309, "TheoremQA_xinyi/maximum_entropy_2.json": 0.6619299650192261, "TheoremQA_xinyi/chi_square_test.json": 0.6778982877731323, "TheoremQA_xinyi/expected_distortion.json": 0.6946640014648438, "TheoremQA_xinyi/Concavity_of_second_law_of_thermodynamics.json": 0.7084596157073975, "TheoremQA_xinyi/data_processing.json": 0.7159852385520935, "TheoremQA_xinyi/fano_inequality.json": 0.7369142174720764, "TheoremQA_xinyi/shannon_lower_bound.json": 0.7548378705978394, "TheoremQA_xinyi/channel_capacity_1.json": 0.7743324041366577, "TheoremQA_xinyi/rate_distortion_function_2.json": 0.7856943011283875, "TheoremQA_xinyi/rate_distortion_function_1.json": 0.7947826385498047, "TheoremQA_xinyi/concavity.json": 0.8233757019042969, "TheoremQA_xinyi/distortion_rate_function_1.json": 0.9329856038093567}, "TheoremQA_maxku/graphtheory2-vertexcover.json": {"camel_23826": 0, "camel_22673": 0, "camel_22852": 0, "camel_22773": 0, "camel_22106": 0, "camel_23817": 0, "camel_22347": 0, "camel_23400": 0, "camel_23432": 0, "camel_22814": 0, "camel_22756": 0, "camel_23134": 0, "camel_23393": 0, "camel_22258": 0, "camel_23389": 0, "camel_23157": 0, "camel_21918": 0, "camel_22783": 0, "camel_22795": 0, "camel_23397": 0, "camel_21186": 0, "camel_23767": 0, "camel_22264": 0, "camel_22108": 0, "camel_22384": 0, "camel_23158": 0, "camel_21179": 0, "camel_22324": 0, "camel_22753": 0, "camel_22749": 0, "camel_22653": 0, "camel_22191": 0, "camel_23807": 0, "camel_22300": 0, "camel_23762": 0, "camel_22868": 0, "camel_23404": 0, "camel_21170": 0, "camel_22874": 0, "camel_22920": 0, "camel_22361": 0, "camel_23825": 0, "camel_21193": 0, "camel_23192": 0, "camel_22738": 0, "camel_22252": 0, "camel_23141": 0, "camel_22744": 0, "camel_23977": 0, "camel_22192": 0, "camel_23367": 0, "camel_21130": 0, "camel_23833": 0, "camel_21198": 0, "camel_22396": 0, "camel_22294": 0, "camel_22315": 0, "camel_22644": 0, "camel_22692": 0, "camel_22279": 0, "camel_22760": 0, "camel_23363": 0, "camel_22368": 0, "camel_22871": 0, "camel_22367": 0, "camel_23379": 0, "camel_22777": 0, "camel_22785": 0, "camel_22872": 0, "camel_22218": 0, "camel_22745": 0, "camel_22009": 0, "camel_23143": 0, "camel_22721": 0, "camel_22737": 0, "camel_21180": 0, "camel_22757": 0, "camel_22857": 0, "camel_23435": 0, "camel_22223": 0, "camel_22859": 0, "camel_22179": 0, "camel_22768": 0, "camel_21678": 0, "camel_23362": 0, "camel_21129": 0, "camel_22809": 0, "camel_22377": 0, "camel_22182": 0, "camel_22858": 0, "camel_22397": 0, "camel_21145": 0, "camel_22363": 0, "camel_22168": 0, "camel_22800": 0, "camel_22763": 0, "camel_21083": 0, "camel_21133": 0, "camel_22040": 0, "camel_22860": 0, "camel_22089": 0, "camel_22778": 0, "camel_21197": 0, "camel_21116": 0, "camel_23172": 0, "camel_23409": 0, "camel_21152": 0, "camel_22204": 0, "camel_22793": 0, "camel_22224": 0, "camel_22116": 0, "camel_23381": 0, "camel_22728": 0, "camel_22117": 0, "camel_22850": 0, "camel_22870": 0, "camel_22398": 0, "camel_22808": 0, "camel_22193": 0, "camel_22873": 0, "camel_22802": 0, "camel_22210": 0, "camel_22835": 0, "camel_22330": 0, "TheoremQA_maxku/graphtheory2-vertexcover.json": 0, "camel_22724": 0, "camel_22806": 0, "camel_22792": 0, "camel_23770": 0, "camel_22742": 0, "camel_22875": 0, "camel_22847": 0, "camel_22746": 0, "camel_22830": 0, "camel_22829": 0, "camel_22735": 0, "camel_22729": 0, "camel_22720": 0, "camel_22734": 0, "camel_22356": 0, "camel_22176": 0, "camel_22764": 0, "camel_23427": 0, "camel_21589": 0, "camel_22820": 0, "camel_22761": 0, "camel_22817": 0, "camel_22842": 0, "camel_22332": 0, "camel_22856": 0, "camel_22215": 0, "camel_22789": 0, "camel_22767": 0, "camel_22821": 0, "camel_22185": 0, "camel_22831": 0, "camel_22743": 0, "camel_22727": 0, "camel_23438": 0, "camel_23360": 0, "camel_22818": 0, "camel_21176": 0, "camel_22810": 0, "camel_22861": 0, "camel_23364": 0, "camel_23410": 0, "camel_22799": 0, "camel_22170": 0, "aqua_rat_43370": 0.7795291543006897, "aqua_rat_63046": 0.7799097895622253, "camel_38569": 0.7813745737075806, "aqua_rat_20425": 0.7815104722976685, "aqua_rat_56385": 0.782632052898407, "camel_38615": 0.7827529311180115, "aqua_rat_25794": 0.7834184169769287, "camel_38608": 0.7836312651634216, "camel_39997": 0.7841387987136841, "camel_38621": 0.7847945690155029, "aqua_rat_76009": 0.7854979038238525, "camel_38617": 0.7861846685409546, "aqua_rat_70645": 0.7864850759506226, "aqua_rat_54929": 0.7873824834823608, "camel_38561": 0.7898550033569336, "camel_38585": 0.79033362865448, "aqua_rat_44831": 0.7907045483589172, "aqua_rat_44895": 0.7909510731697083, "camel_38906": 0.7916404008865356, "TheoremQA_maxku/graphtheory5-vertexcover.json": 0.7925789952278137, "camel_38526": 0.7927294969558716, "TheoremQA_maxku/graphtheory3-vertexcover.json": 0.7948601245880127, "camel_39941": 0.7950778603553772, "camel_38572": 0.796932578086853, "camel_38609": 0.7975821495056152, "aqua_rat_64683": 0.7982421517372131, "aqua_rat_77006": 0.8000455498695374, "camel_38564": 0.8011856079101562, "aqua_rat_7562": 0.8012198805809021, "aqua_rat_10797": 0.8017328381538391, "aqua_rat_83797": 0.8040817379951477, "aqua_rat_76903": 0.8041899800300598}, "TheoremQA_maxku/cv-imageprocessing2-morphology.json": {"TheoremQA_maxku/cv-imageprocessing2-morphology.json": 0, "camel_36957": 0.5025947093963623, "camel_18680": 0.5026795864105225, "camel_31554": 0.5026878714561462, "camel_18071": 0.502702534198761, "camel_30513": 0.5027362108230591, "camel_36412": 0.502834141254425, "camel_18895": 0.5029140710830688, "camel_36444": 0.502915620803833, "camel_18336": 0.5029534697532654, "camel_22009": 0.5029907822608948, "camel_22394": 0.5031142234802246, "camel_18365": 0.5031366348266602, "camel_39258": 0.5032095313072205, "camel_37374": 0.5033628344535828, "camel_18072": 0.5033807158470154, "camel_39001": 0.5034504532814026, "camel_18370": 0.503466784954071, "camel_18193": 0.5037041902542114, "camel_36912": 0.5037410259246826, "aqua_rat_69333": 0.5038581490516663, "camel_40982": 0.5039394497871399, "camel_36173": 0.5042710304260254, "camel_37917": 0.5043085813522339, "camel_36581": 0.5044201612472534, "camel_19504": 0.504427433013916, "camel_38481": 0.5044823884963989, "camel_36521": 0.5044845342636108, "camel_36469": 0.5045056343078613, "camel_36884": 0.5045372843742371, "camel_30538": 0.5045530796051025, "camel_36425": 0.5046007633209229, "camel_36896": 0.5046248435974121, "camel_36524": 0.5046979188919067, "camel_22391": 0.5048401355743408, "camel_22867": 0.5051010251045227, "camel_36439": 0.5053870677947998, "camel_36549": 0.5053936839103699, "camel_41431": 0.5054300427436829, "camel_22071": 0.5055772662162781, "camel_22383": 0.5056641101837158, "camel_23193": 0.5057053565979004, "camel_36470": 0.5057411193847656, "camel_36520": 0.5058057308197021, "camel_18194": 0.5058571696281433, "camel_18177": 0.5059038996696472, "camel_22360": 0.5059425234794617, "camel_35990": 0.5059463977813721, "camel_36477": 0.5059497952461243, "camel_36179": 0.5059791207313538, "camel_22233": 0.5061115622520447, "camel_36465": 0.50618976354599, "camel_19412": 0.5064624547958374, "camel_30298": 0.5064644813537598, "camel_22377": 0.5065056681632996, "camel_36713": 0.5067126750946045, "camel_36875": 0.506813108921051, "camel_36452": 0.5068906545639038, "camel_36410": 0.5069944262504578, "camel_36752": 0.5070089101791382, "camel_40840": 0.5070308446884155, "camel_36518": 0.5071092844009399, "camel_30245": 0.507135272026062, "camel_30223": 0.50736004114151, "camel_36835": 0.5074576735496521, "camel_36848": 0.5075695514678955, "camel_37916": 0.5076199769973755, "camel_36498": 0.5077095031738281, "camel_19387": 0.5077916979789734, "camel_36891": 0.5078040361404419, "camel_22068": 0.5078370571136475, "camel_22397": 0.5078625679016113, "camel_30499": 0.5078635811805725, "camel_36926": 0.5080026388168335, "camel_22345": 0.5080944895744324, "camel_30407": 0.5082390308380127, "camel_36453": 0.5082830786705017, "camel_41769": 0.5083287358283997, "camel_22387": 0.5084171295166016, "camel_19519": 0.5086080431938171, "camel_18207": 0.5086265802383423, "camel_36544": 0.5086842179298401, "camel_30509": 0.5087273120880127, "camel_36321": 0.5087781548500061, "camel_36907": 0.5088126063346863, "camel_36917": 0.5088396668434143, "camel_18567": 0.5088992714881897, "camel_36404": 0.5092145204544067, "camel_19952": 0.5093059539794922, "camel_35881": 0.509525716304779, "camel_36937": 0.5096005797386169, "camel_36671": 0.5096734762191772, "camel_36813": 0.5097649097442627, "camel_36447": 0.5100240707397461, "camel_36463": 0.510040819644928, "camel_37900": 0.5100892782211304, "camel_36437": 0.5101231932640076, "camel_30515": 0.5102952718734741, "camel_36323": 0.5104026794433594, "camel_36406": 0.5105741024017334, "camel_36775": 0.5106436610221863, "camel_39226": 0.5109261274337769, "camel_36432": 0.5110008120536804, "camel_18595": 0.5110604166984558, "camel_36413": 0.5112912654876709, "camel_36440": 0.5114085674285889, "camel_36187": 0.5115429162979126, "camel_39278": 0.511644184589386, "camel_36424": 0.5117709636688232, "camel_36446": 0.5118008852005005, "camel_36396": 0.5118537545204163, "camel_37046": 0.5118672251701355, "camel_36195": 0.5119317173957825, "camel_36485": 0.5119471549987793, "camel_19389": 0.5120066404342651, "camel_36355": 0.5120981931686401, "camel_36683": 0.5122514367103577, "camel_19416": 0.5125377774238586, "camel_22364": 0.5125592350959778, "camel_36476": 0.5126075744628906, "camel_36512": 0.5126844644546509, "camel_18079": 0.5127400159835815, "camel_18362": 0.5127726197242737, "camel_18357": 0.5128829479217529, "camel_22378": 0.5130590796470642, "camel_19531": 0.5130776762962341, "camel_36170": 0.513106644153595, "camel_22336": 0.5132433176040649, "camel_18339": 0.5133354663848877, "camel_22366": 0.5133822560310364, "camel_19374": 0.5134075880050659, "camel_36481": 0.5140705704689026, "camel_36423": 0.5140957832336426, "camel_39234": 0.5141510367393494, "camel_18355": 0.514668345451355, "camel_18399": 0.5149654150009155, "camel_36893": 0.5153005123138428, "camel_18705": 0.515413224697113, "camel_19567": 0.5156880021095276, "camel_36454": 0.5166722536087036, "camel_36533": 0.516703188419342, "camel_36929": 0.5170042514801025, "camel_37909": 0.517087996006012, "camel_36428": 0.5171881914138794, "camel_36419": 0.5172809958457947, "camel_36429": 0.5176056623458862, "camel_36415": 0.5178645253181458, "camel_36457": 0.5179650783538818, "camel_36486": 0.5180602073669434, "camel_36400": 0.5184237360954285, "camel_18366": 0.5185251832008362, "camel_22331": 0.5186562538146973, "camel_36422": 0.5186575055122375, "camel_22399": 0.5199529528617859, "camel_36472": 0.5200636386871338, "camel_30474": 0.5201668739318848, "camel_36435": 0.5201991200447083, "camel_41413": 0.520293653011322, "camel_39209": 0.5205764770507812, "camel_22061": 0.5209869146347046, "camel_36456": 0.5210670828819275, "camel_30212": 0.5211417078971863, "camel_39270": 0.5214564204216003, "camel_36557": 0.5215238928794861, "TheoremQA_maxku/cv-imageprocessing8-fourier2.json": 0.5216515064239502, "camel_36858": 0.5222635269165039, "camel_39225": 0.5224364995956421, "camel_36460": 0.5226008296012878, "camel_36169": 0.5231247544288635, "camel_39260": 0.5233439803123474, "camel_36830": 0.5238222479820251, "camel_17674": 0.5243726372718811, "camel_30284": 0.5245311856269836, "camel_36421": 0.5253020524978638, "camel_18342": 0.5254119634628296, "camel_36458": 0.5257378220558167, "camel_18377": 0.5260993242263794, "camel_36451": 0.5264472961425781, "camel_18380": 0.526521623134613, "camel_18360": 0.5275155901908875, "camel_36923": 0.527923047542572, "camel_36352": 0.5279362201690674, "camel_36335": 0.5287197232246399, "camel_36936": 0.5299727320671082, "camel_36478": 0.5300164222717285, "camel_41414": 0.5302742719650269, "camel_36490": 0.5307356715202332, "camel_19436": 0.5315674543380737, "camel_36502": 0.5317384600639343, "camel_18383": 0.5329551100730896, "camel_36497": 0.5331979393959045, "camel_36418": 0.5335305333137512, "camel_36441": 0.5361101627349854, "camel_36938": 0.5393608808517456, "camel_36417": 0.539430558681488, "camel_18345": 0.5407211184501648, "camel_17639": 0.5415619015693665, "camel_36201": 0.5440718531608582, "camel_18943": 0.5456023216247559, "TheoremQA_maxku/cv-imageprocessing1-morphology.json": 0.861812949180603}, "TheoremQA_jianyu_xu/Ramsey_5.json": {"camel_23717": 0, "camel_23715": 0, "camel_23688": 0, "camel_23754": 0, "TheoremQA_jianyu_xu/Ramsey_5.json": 0, "camel_23683": 0, "camel_23751": 0, "camel_23707": 0, "camel_23442": 0, "camel_21428": 0, "camel_21767": 0, "camel_23816": 0, "camel_20540": 0, "camel_23734": 0, "camel_21040": 0, "camel_21792": 0, "camel_21197": 0, "camel_21568": 0, "camel_22135": 0, "camel_22133": 0, "camel_21100": 0, "camel_21116": 0, "camel_23748": 0, "camel_23739": 0, "camel_23732": 0, "camel_23745": 0, "camel_23794": 0, "camel_23685": 0, "camel_21148": 0, "camel_23744": 0, "camel_21136": 0, "camel_22120": 0, "camel_23689": 0, "camel_21768": 0, "camel_23755": 0, "camel_21376": 0, "camel_23753": 0, "camel_21151": 0, "camel_22792": 0, "camel_21133": 0, "camel_23735": 0, "camel_21154": 0, "camel_21174": 0, "camel_23750": 0, "camel_21158": 0, "camel_21128": 0, "camel_21177": 0, "camel_23759": 0, "camel_23737": 0, "camel_23723": 0, "camel_22170": 0, "camel_21199": 0, "camel_23703": 0, "camel_22161": 0, "camel_23720": 0, "camel_22117": 0, "camel_23699": 0, "camel_21835": 0, "camel_21144": 0, "camel_21196": 0, "camel_21198": 0, "camel_21149": 0, "camel_21135": 0, "camel_21190": 0, "camel_21160": 0, "camel_21155": 0, "camel_23696": 0, "camel_21173": 0, "camel_21142": 0, "camel_21180": 0, "camel_21152": 0, "camel_21153": 0, "camel_21182": 0, "camel_21131": 0, "camel_21145": 0, "camel_21159": 0, "camel_21192": 0, "camel_21833": 0, "camel_21157": 0, "camel_21129": 0, "camel_21137": 0, "camel_21161": 0, "camel_21120": 0, "camel_21181": 0, "camel_23722": 0, "camel_21178": 0, "camel_21123": 0, "camel_21193": 0, "camel_21068": 0, "camel_21156": 0, "camel_21122": 0, "camel_23711": 0, "camel_21215": 0, "camel_21185": 0, "camel_23729": 0, "camel_21121": 0, "camel_21141": 0, "camel_21191": 0, "camel_23695": 0, "camel_23682": 0, "camel_21175": 0, "camel_21170": 0, "camel_21163": 0, "camel_23693": 0, "camel_21132": 0, "camel_23714": 0, "camel_21188": 0, "camel_21195": 0, "camel_21169": 0, "camel_23686": 0, "camel_21146": 0, "camel_21184": 0, "camel_21168": 0, "camel_21194": 0, "camel_21822": 0, "camel_21127": 0, "camel_21187": 0, "camel_23731": 0, "camel_21164": 0, "camel_23713": 0, "camel_21130": 0, "camel_21147": 0, "camel_21784": 0, "camel_23758": 0, "camel_21139": 0, "camel_21186": 0, "camel_21179": 0, "camel_21166": 0, "camel_21126": 0, "camel_23697": 0, "camel_21172": 0, "camel_21782": 0, "camel_21125": 0, "camel_21167": 0, "camel_21134": 0, "camel_21162": 0, "camel_21143": 0, "camel_21171": 0, "camel_21124": 0, "camel_23752": 0, "camel_23690": 0, "camel_21183": 0, "camel_21176": 0, "aqua_rat_8519": 0.7691725492477417, "aqua_rat_36721": 0.7694264650344849, "math_test_prealgebra_1727": 0.7696802020072937, "aqua_rat_69238": 0.7699799537658691, "aqua_rat_34677": 0.7700779438018799, "math_test_prealgebra_1764": 0.7704337239265442, "aqua_rat_13835": 0.7707076072692871, "aqua_rat_15480": 0.7710278630256653, "aqua_rat_14782": 0.7712087035179138, "aqua_rat_46132": 0.7716958522796631, "aqua_rat_78389": 0.7718448638916016, "math_test_counting_and_probability_763": 0.7719607949256897, "aqua_rat_69290": 0.7721731662750244, "aqua_rat_73560": 0.7723285555839539, "math_test_counting_and_probability_513": 0.7726563811302185, "aqua_rat_53805": 0.7739814519882202, "aqua_rat_75954": 0.7752341032028198, "aqua_rat_48816": 0.7752968668937683, "math_test_prealgebra_1306": 0.7753764986991882, "aqua_rat_20969": 0.7754138708114624, "aqua_rat_10136": 0.7763888239860535, "aqua_rat_25103": 0.7768563032150269, "aqua_rat_41911": 0.7770015597343445, "camel_36368": 0.7770673632621765, "aqua_rat_53479": 0.7771497368812561, "math_train_counting_and_probability_1110": 0.7773511409759521, "aqua_rat_17402": 0.7782859206199646, "aqua_rat_12645": 0.7788528203964233, "aqua_rat_18439": 0.7800350785255432, "aqua_rat_57520": 0.7801214456558228, "aqua_rat_75970": 0.7811579704284668, "aqua_rat_58707": 0.7814792394638062, "aqua_rat_76846": 0.7819394469261169, "TheoremQA_jianyu_xu/pigeonhole_1.json": 0.7829168438911438, "aqua_rat_84086": 0.7848367691040039, "aqua_rat_37692": 0.7850752472877502, "aqua_rat_63918": 0.7857897877693176, "aqua_rat_15706": 0.7872706651687622, "aqua_rat_19096": 0.7888669967651367, "aqua_rat_85357": 0.7892146706581116, "aqua_rat_47964": 0.7897406816482544, "aqua_rat_5877": 0.7903828024864197, "aqua_rat_84407": 0.7924511432647705, "aqua_rat_39765": 0.7945871353149414, "aqua_rat_60481": 0.7960759997367859, "aqua_rat_53788": 0.7979081869125366, "aqua_rat_46637": 0.7981239557266235, "aqua_rat_76154": 0.8004064559936523, "aqua_rat_83797": 0.8013565540313721, "aqua_rat_44859": 0.8045838475227356, "TheoremQA_jianyu_xu/Ramsey_3.json": 0.8048986792564392, "aqua_rat_46632": 0.8072207570075989, "TheoremQA_jianyu_xu/Ramsey_2.json": 0.8129939436912537, "aqua_rat_78805": 0.8135150671005249, "aqua_rat_31932": 0.81374192237854, "aqua_rat_50073": 0.820708155632019, "aqua_rat_58088": 0.8246586918830872}, "TheoremQA_tonyxia/particle4.json": {"TheoremQA_tonyxia/particle4.json": 0, "aqua_rat_18744": 0.6503382325172424, "camel_28715": 0.650354266166687, "aqua_rat_64606": 0.6504119634628296, "aqua_rat_71204": 0.6504650712013245, "aqua_rat_55232": 0.6504936814308167, "aqua_rat_6964": 0.6504944562911987, "gsm_rft_4453": 0.6505310535430908, "gsm_rft_57": 0.6506856083869934, "aqua_rat_6768": 0.650892436504364, "aqua_rat_24071": 0.6510000228881836, "aqua_rat_19425": 0.6511059403419495, "aqua_rat_78209": 0.6511508226394653, "gsm_rft_18266": 0.6511614918708801, "aqua_rat_34706": 0.6511682868003845, "aqua_rat_42716": 0.6512426733970642, "gsm_rft_23547": 0.6512762904167175, "gsm_train_13099": 0.6512762904167175, "aqua_rat_42126": 0.6513333320617676, "gsm_rft_32849": 0.6513416171073914, "gsm_train_26360": 0.6513416171073914, "gsm_rft_14979": 0.6513615250587463, "gsm_train_553": 0.6513778567314148, "gsm_rft_31880": 0.6517375707626343, "gsm_rft_30083": 0.6517606377601624, "gsm_train_33416": 0.6517606377601624, "gsm_rft_26897": 0.6517630219459534, "gsm_rft_29554": 0.651861310005188, "aqua_rat_82501": 0.6519765853881836, "gsm_rft_2421": 0.6519920229911804, "aqua_rat_72645": 0.6521166563034058, "gsm_rft_12732": 0.6521413922309875, "aqua_rat_82624": 0.6521735191345215, "aqua_rat_88921": 0.6523221135139465, "gsm_rft_1734": 0.6523544788360596, "gsm_train_9298": 0.6523544788360596, "gsm_train_18501": 0.6524606943130493, "gsm_rft_15576": 0.6525835990905762, "aqua_rat_37341": 0.6525892019271851, "camel_7984": 0.6526658535003662, "gsm_rft_34703": 0.6527476906776428, "aqua_rat_79832": 0.6528003215789795, "gsm_rft_2575": 0.6528240442276001, "gsm_rft_870": 0.6528240442276001, "aqua_rat_67115": 0.6530238389968872, "camel_28811": 0.6535196304321289, "gsm_rft_28645": 0.6535404324531555, "gsm_rft_28878": 0.6535404324531555, "gsm_rft_30836": 0.6535404324531555, "gsm_train_31124": 0.6535404324531555, "aqua_rat_21246": 0.6536425352096558, "aqua_rat_4346": 0.653700053691864, "camel_7995": 0.653997004032135, "gsm_rft_26630": 0.6540327668190002, "aqua_rat_35905": 0.6541159152984619, "aqua_rat_59271": 0.654228687286377, "gsm_rft_14306": 0.6544779539108276, "aqua_rat_80680": 0.6548202037811279, "aqua_rat_64399": 0.6549387574195862, "aqua_rat_25846": 0.6551643013954163, "aqua_rat_73742": 0.6551676392555237, "gsm_rft_31297": 0.6553804278373718, "aqua_rat_7671": 0.6554064154624939, "aqua_rat_63443": 0.6556054949760437, "aqua_rat_20870": 0.6556808352470398, "camel_39462": 0.6557280421257019, "camel_39446": 0.6557839512825012, "aqua_rat_36249": 0.6559340357780457, "gsm_rft_13505": 0.6559828519821167, "gsm_train_18003": 0.6561497449874878, "gsm_rft_24790": 0.6561497449874878, "gsm_rft_25136": 0.6561497449874878, "gsm_rft_34630": 0.6562616229057312, "aqua_rat_83605": 0.656354546546936, "aqua_rat_28523": 0.6565724015235901, "aqua_rat_30607": 0.6566815376281738, "aqua_rat_37623": 0.6570931077003479, "gsm_rft_23284": 0.6571866273880005, "aqua_rat_8080": 0.6572898626327515, "camel_39452": 0.6572914123535156, "aqua_rat_12658": 0.6572984457015991, "aqua_rat_85851": 0.6574322581291199, "gsm_rft_24978": 0.6574863195419312, "aqua_rat_25154": 0.6574956774711609, "aqua_rat_33317": 0.6576191782951355, "gsm_rft_2271": 0.6577340960502625, "aqua_rat_86305": 0.6579630970954895, "aqua_rat_72791": 0.6579772233963013, "aqua_rat_48679": 0.6580882668495178, "aqua_rat_56182": 0.658211350440979, "gsm_train_31725": 0.6582117080688477, "gsm_rft_6656": 0.6582117080688477, "aqua_rat_30868": 0.6585639119148254, "aqua_rat_53685": 0.6588987112045288, "gsm_rft_31346": 0.6589763164520264, "aqua_rat_55904": 0.6592472195625305, "aqua_rat_7651": 0.6593111753463745, "aqua_rat_81900": 0.6593498587608337, "aqua_rat_69977": 0.6593564748764038, "gsm_rft_7211": 0.659399688243866, "aqua_rat_3859": 0.6594519019126892, "gsm_train_34664": 0.6595184206962585, "gsm_rft_24393": 0.6595184206962585, "aqua_rat_34975": 0.6595737934112549, "gsm_rft_25773": 0.6596121788024902, "camel_24344": 0.6598364114761353, "aqua_rat_5161": 0.6598639488220215, "aqua_rat_62486": 0.6598750352859497, "gsm_rft_30773": 0.6599941253662109, "aqua_rat_30731": 0.6601370573043823, "gsm_rft_11389": 0.6602452397346497, "aqua_rat_3796": 0.6603214144706726, "aqua_rat_15984": 0.660475492477417, "gsm_rft_22887": 0.6606631278991699, "aqua_rat_48959": 0.660876452922821, "aqua_rat_62767": 0.6611337661743164, "aqua_rat_20452": 0.6611480116844177, "aqua_rat_12925": 0.6611504554748535, "gsm_rft_22305": 0.6612709760665894, "aqua_rat_72145": 0.6613887548446655, "aqua_rat_81927": 0.6614537835121155, "aqua_rat_197": 0.661458432674408, "aqua_rat_22263": 0.6615968942642212, "gsm_rft_12524": 0.6616705656051636, "aqua_rat_74682": 0.6616712808609009, "gsm_rft_10767": 0.6617324352264404, "aqua_rat_26179": 0.6618350148200989, "gsm_rft_31299": 0.6618750691413879, "gsm_rft_32171": 0.6618750691413879, "gsm_train_30351": 0.6618750691413879, "gsm_rft_25020": 0.6618750691413879, "aqua_rat_50655": 0.6619664430618286, "aqua_rat_51819": 0.6620309948921204, "aqua_rat_8426": 0.6623030304908752, "aqua_rat_32616": 0.6624450087547302, "aqua_rat_6188": 0.6624894738197327, "aqua_rat_47058": 0.6626530289649963, "gsm_rft_7812": 0.6626841425895691, "gsm_rft_6897": 0.6628146171569824, "gsm_rft_8990": 0.6629967093467712, "gsm_train_7372": 0.6629967093467712, "gsm_train_21544": 0.6630628705024719, "aqua_rat_15732": 0.6632605195045471, "aqua_rat_11683": 0.663436233997345, "aqua_rat_54005": 0.6635019183158875, "aqua_rat_56051": 0.6637214422225952, "aqua_rat_83526": 0.6637519598007202, "aqua_rat_16681": 0.6641799211502075, "aqua_rat_63465": 0.6643213629722595, "gsm_rft_15416": 0.6650013327598572, "aqua_rat_75129": 0.6650136113166809, "aqua_rat_47750": 0.6651020646095276, "aqua_rat_3432": 0.6654006838798523, "aqua_rat_67295": 0.6654394268989563, "gsm_rft_24421": 0.6654660701751709, "aqua_rat_61971": 0.6654719114303589, "aqua_rat_82115": 0.6656541228294373, "gsm_train_2068": 0.6657525897026062, "gsm_rft_4583": 0.6657525897026062, "gsm_rft_16695": 0.6657539010047913, "gsm_rft_35619": 0.6659442782402039, "gsm_rft_29129": 0.6664608120918274, "TheoremQA_tonyxia/wave2.json": 0.6666017174720764, "aqua_rat_16975": 0.666628360748291, "aqua_rat_58051": 0.666942298412323, "aqua_rat_65198": 0.6670758724212646, "aqua_rat_9493": 0.6674453616142273, "aqua_rat_70812": 0.6674786806106567, "aqua_rat_85422": 0.6681178212165833, "camel_28847": 0.6690973043441772, "aqua_rat_20932": 0.6694172620773315, "aqua_rat_11192": 0.6695488095283508, "aqua_rat_56584": 0.6702858805656433, "aqua_rat_61332": 0.6708864569664001, "gsm_rft_24796": 0.6710888147354126, "aqua_rat_10204": 0.6715632677078247, "aqua_rat_71816": 0.6736698150634766, "aqua_rat_43435": 0.673766016960144, "TheoremQA_xinyi/work_energy_theorem.json": 0.6747039556503296, "camel_39513": 0.6762735247612, "aqua_rat_12010": 0.6780958771705627, "aqua_rat_36957": 0.6790835857391357, "aqua_rat_41482": 0.6803953647613525, "aqua_rat_54375": 0.6828244924545288, "aqua_rat_57727": 0.683525025844574, "aqua_rat_73760": 0.6856133937835693, "camel_17811": 0.68580561876297, "gsm_rft_22533": 0.6870409846305847, "aqua_rat_11549": 0.6882048845291138, "gsm_rft_22397": 0.6884505152702332, "camel_28846": 0.690919816493988, "gsm_rft_10505": 0.6944400668144226, "gsm_rft_17764": 0.6951296925544739, "gsm_train_29099": 0.6951296925544739, "gsm_rft_35145": 0.6975725293159485, "TheoremQA_xinyi/momentum.json": 0.7041029930114746, "TheoremQA_tonyxia/relativity3.json": 0.728630006313324, "TheoremQA_tonyxia/particle5.json": 0.733391523361206, "TheoremQA_tonyxia/nuclear3.json": 0.7434859871864319, "TheoremQA_tonyxia/particle6.json": 0.8544159531593323}, "TheoremQA_jianyu_xu/Binomial_2.json": {"camel_20545": 0, "camel_20283": 0, "camel_20038": 0, "camel_20175": 0, "camel_20519": 0, "aqua_rat_65682": 0.7807556986808777, "aqua_rat_14810": 0.7808913588523865, "aqua_rat_41645": 0.7809731960296631, "math_train_counting_and_probability_874": 0.7810177803039551, "aqua_rat_70014": 0.7811303734779358, "aqua_rat_35795": 0.7813145518302917, "aqua_rat_18686": 0.7813935279846191, "aqua_rat_34268": 0.7814111709594727, "aqua_rat_19073": 0.7814616560935974, "aqua_rat_14535": 0.7815269231796265, "aqua_rat_57663": 0.7816133499145508, "aqua_rat_64752": 0.78179532289505, "aqua_rat_75231": 0.7818095088005066, "aqua_rat_56651": 0.7819346189498901, "aqua_rat_88653": 0.7819676995277405, "aqua_rat_80293": 0.7820308804512024, "aqua_rat_65878": 0.7820960283279419, "aqua_rat_9102": 0.7821714282035828, "aqua_rat_85085": 0.7822410464286804, "math_train_counting_and_probability_1099": 0.78229820728302, "aqua_rat_2635": 0.782308042049408, "aqua_rat_9727": 0.7823243141174316, "aqua_rat_54141": 0.7824863791465759, "aqua_rat_68780": 0.7826446294784546, "aqua_rat_37766": 0.782655656337738, "aqua_rat_64936": 0.7830215692520142, "aqua_rat_43597": 0.7833393812179565, "aqua_rat_69551": 0.7834590077400208, "aqua_rat_62255": 0.7835075259208679, "aqua_rat_83094": 0.7836788892745972, "aqua_rat_54809": 0.78386390209198, "aqua_rat_8879": 0.7841426134109497, "aqua_rat_27444": 0.784276008605957, "aqua_rat_17716": 0.7843239307403564, "aqua_rat_1826": 0.7844499349594116, "aqua_rat_46658": 0.7844865322113037, "aqua_rat_39861": 0.7846323847770691, "aqua_rat_60948": 0.7846391201019287, "aqua_rat_62860": 0.7847499847412109, "aqua_rat_44485": 0.7849101424217224, "aqua_rat_24240": 0.785128653049469, "math_train_prealgebra_1740": 0.7851465344429016, "aqua_rat_60662": 0.7852009534835815, "aqua_rat_86991": 0.7853663563728333, "aqua_rat_48451": 0.7853723764419556, "aqua_rat_55663": 0.7855615019798279, "aqua_rat_28682": 0.7858116626739502, "aqua_rat_36722": 0.7858915328979492, "aqua_rat_8833": 0.7860606908798218, "aqua_rat_65830": 0.7862357497215271, "aqua_rat_67694": 0.7864134311676025, "aqua_rat_88132": 0.7865039706230164, "aqua_rat_51352": 0.7866460680961609, "aqua_rat_24455": 0.7866739630699158, "aqua_rat_80773": 0.7866833806037903, "aqua_rat_45147": 0.786788284778595, "aqua_rat_43721": 0.7868832945823669, "aqua_rat_47339": 0.7869025468826294, "aqua_rat_62241": 0.7875233292579651, "aqua_rat_68557": 0.7877659201622009, "aqua_rat_2284": 0.7878835201263428, "aqua_rat_16873": 0.7879915833473206, "aqua_rat_31049": 0.7884407043457031, "aqua_rat_21916": 0.7891089916229248, "aqua_rat_56247": 0.7891677618026733, "aqua_rat_14844": 0.7891702055931091, "aqua_rat_8636": 0.7891720533370972, "aqua_rat_9063": 0.7895337343215942, "aqua_rat_46501": 0.7895970344543457, "aqua_rat_7455": 0.7896860837936401, "aqua_rat_33999": 0.7897211909294128, "aqua_rat_35991": 0.7902830839157104, "aqua_rat_24239": 0.7903398275375366, "aqua_rat_2328": 0.7906085848808289, "aqua_rat_29935": 0.790732204914093, "aqua_rat_88317": 0.7907529473304749, "math_test_counting_and_probability_1007": 0.7907684445381165, "aqua_rat_48428": 0.7908020615577698, "aqua_rat_3068": 0.7908673286437988, "aqua_rat_62723": 0.790907621383667, "aqua_rat_4340": 0.7909536361694336, "aqua_rat_1550": 0.7911313772201538, "aqua_rat_3309": 0.791255533695221, "aqua_rat_18810": 0.7913553714752197, "aqua_rat_25285": 0.7915865182876587, "aqua_rat_87194": 0.7916431427001953, "aqua_rat_14966": 0.7917314171791077, "aqua_rat_69596": 0.7918541431427002, "aqua_rat_15466": 0.7924147844314575, "aqua_rat_4355": 0.7927838563919067, "aqua_rat_72902": 0.7929016947746277, "aqua_rat_41995": 0.7932432889938354, "aqua_rat_21632": 0.7934527397155762, "aqua_rat_56289": 0.7936452627182007, "aqua_rat_77566": 0.7936528921127319, "math_train_counting_and_probability_441": 0.793693482875824, "aqua_rat_37792": 0.7937933206558228, "aqua_rat_27207": 0.7940282821655273, "aqua_rat_65536": 0.7945737838745117, "aqua_rat_43964": 0.7946934700012207, "aqua_rat_77579": 0.7947125434875488, "aqua_rat_55986": 0.7948485612869263, "aqua_rat_66552": 0.7948676347732544, "aqua_rat_45278": 0.7948974370956421, "aqua_rat_1998": 0.7949944734573364, "aqua_rat_10159": 0.7950241565704346, "aqua_rat_12345": 0.7950776815414429, "aqua_rat_15303": 0.7951827049255371, "aqua_rat_52853": 0.7952309250831604, "aqua_rat_36022": 0.7954305410385132, "aqua_rat_2072": 0.7954671382904053, "aqua_rat_33285": 0.7956025004386902, "aqua_rat_38587": 0.795635461807251, "aqua_rat_86975": 0.7959063053131104, "aqua_rat_58499": 0.79592365026474, "aqua_rat_29222": 0.7963870763778687, "aqua_rat_3845": 0.796427309513092, "aqua_rat_11382": 0.7969603538513184, "aqua_rat_33635": 0.7970021963119507, "aqua_rat_47160": 0.7970160841941833, "aqua_rat_6238": 0.7971392273902893, "aqua_rat_24634": 0.7971686720848083, "aqua_rat_44161": 0.7972143292427063, "math_test_counting_and_probability_737": 0.7973750829696655, "aqua_rat_19714": 0.7975003123283386, "aqua_rat_41993": 0.7975971102714539, "aqua_rat_46448": 0.7976417541503906, "aqua_rat_73109": 0.7978646755218506, "aqua_rat_12027": 0.7978830933570862, "aqua_rat_14573": 0.7979991436004639, "aqua_rat_77088": 0.7986054420471191, "aqua_rat_16429": 0.7986295819282532, "aqua_rat_7334": 0.7986457347869873, "aqua_rat_3300": 0.7987117767333984, "aqua_rat_9747": 0.7989562749862671, "aqua_rat_80880": 0.7993959784507751, "aqua_rat_63250": 0.7995176315307617, "aqua_rat_89049": 0.7997705936431885, "aqua_rat_27137": 0.7998437285423279, "aqua_rat_9439": 0.8002152442932129, "aqua_rat_17322": 0.8010078072547913, "aqua_rat_38330": 0.8012027144432068, "aqua_rat_32332": 0.8019822835922241, "aqua_rat_14470": 0.8028581142425537, "aqua_rat_73969": 0.8028741478919983, "aqua_rat_37487": 0.8028929829597473, "aqua_rat_12250": 0.8031250238418579, "aqua_rat_22365": 0.8031415939331055, "aqua_rat_19798": 0.8031719923019409, "aqua_rat_80829": 0.803267776966095, "aqua_rat_35669": 0.8034949898719788, "aqua_rat_17726": 0.8037739396095276, "aqua_rat_5740": 0.8051695227622986, "aqua_rat_57419": 0.8052080273628235, "aqua_rat_17215": 0.8055262565612793, "aqua_rat_31137": 0.8055912256240845, "aqua_rat_50221": 0.8057563900947571, "aqua_rat_36098": 0.8058432340621948, "aqua_rat_14704": 0.8058778047561646, "aqua_rat_69444": 0.805988073348999, "aqua_rat_41332": 0.8063547015190125, "aqua_rat_8913": 0.8063628077507019, "aqua_rat_23851": 0.8067445158958435, "aqua_rat_69806": 0.806799054145813, "aqua_rat_45246": 0.8068783283233643, "aqua_rat_61853": 0.8069114089012146, "aqua_rat_80157": 0.8072277307510376, "aqua_rat_30088": 0.8073146939277649, "aqua_rat_593": 0.8077329993247986, "aqua_rat_40903": 0.8077577352523804, "aqua_rat_65303": 0.8080371618270874, "aqua_rat_35796": 0.8080701231956482, "aqua_rat_26931": 0.8083778023719788, "aqua_rat_75975": 0.8087285161018372, "aqua_rat_86061": 0.8089256286621094, "aqua_rat_79348": 0.8090060353279114, "aqua_rat_22118": 0.8093639612197876, "aqua_rat_28709": 0.8094735741615295, "aqua_rat_82385": 0.8094988465309143, "aqua_rat_16417": 0.8098975419998169, "aqua_rat_62457": 0.8106223940849304, "aqua_rat_42248": 0.811501145362854, "aqua_rat_75690": 0.8117803931236267, "aqua_rat_78850": 0.8119702935218811, "aqua_rat_20032": 0.8122588396072388, "aqua_rat_76698": 0.8122987747192383, "math_train_counting_and_probability_29": 0.8129676580429077, "aqua_rat_37506": 0.8154587149620056, "aqua_rat_67588": 0.8186389803886414, "aqua_rat_53069": 0.824065625667572, "aqua_rat_32954": 0.8248583674430847, "aqua_rat_79806": 0.8250651359558105, "aqua_rat_19231": 0.8289302587509155, "aqua_rat_32025": 0.8317747116088867, "aqua_rat_59175": 0.8329174518585205}, "TheoremQA_jianyu_xu/Ramsey_6.json": {"camel_22937": 0, "camel_21143": 0, "camel_21198": 0, "camel_21828": 0, "camel_23369": 0, "camel_21188": 0, "camel_21765": 0, "camel_23712": 0, "camel_23726": 0, "camel_21770": 0, "camel_22959": 0, "camel_21193": 0, "camel_22912": 0, "camel_23704": 0, "camel_21839": 0, "camel_23725": 0, "camel_21116": 0, "camel_23727": 0, "camel_23482": 0, "camel_22161": 0, "camel_21774": 0, "camel_21824": 0, "camel_21171": 0, "camel_23307": 0, "camel_22120": 0, "camel_22943": 0, "camel_21834": 0, "camel_22887": 0, "camel_23689": 0, "camel_21129": 0, "camel_22917": 0, "camel_21180": 0, "camel_23698": 0, "camel_23702": 0, "camel_22203": 0, "camel_22905": 0, "camel_21806": 0, "camel_22142": 0, "camel_23734": 0, "camel_21818": 0, "camel_21812": 0, "camel_21838": 0, "camel_23684": 0, "camel_21773": 0, "camel_22948": 0, "camel_22138": 0, "camel_21124": 0, "camel_22939": 0, "camel_21100": 0, "camel_21800": 0, "camel_23755": 0, "camel_23943": 0, "camel_22128": 0, "camel_23696": 0, "camel_23737": 0, "camel_21829": 0, "camel_21832": 0, "camel_21170": 0, "camel_21781": 0, "camel_22928": 0, "camel_23715": 0, "camel_22393": 0, "camel_21185": 0, "camel_23722": 0, "camel_21785": 0, "camel_21792": 0, "camel_21782": 0, "camel_23694": 0, "camel_23708": 0, "camel_23733": 0, "camel_23756": 0, "camel_23740": 0, "camel_23724": 0, "camel_21794": 0, "camel_23788": 0, "camel_21190": 0, "camel_21103": 0, "camel_23743": 0, "camel_23744": 0, "camel_21769": 0, "camel_21793": 0, "camel_23687": 0, "camel_23718": 0, "camel_21826": 0, "camel_23706": 0, "camel_21168": 0, "camel_23713": 0, "camel_23692": 0, "camel_23680": 0, "camel_21811": 0, "camel_21189": 0, "camel_21157": 0, "camel_21186": 0, "camel_21771": 0, "camel_23697": 0, "camel_23749": 0, "camel_23720": 0, "camel_21121": 0, "camel_21179": 0, "camel_21768": 0, "camel_21145": 0, "camel_23775": 0, "camel_21175": 0, "camel_21133": 0, "camel_21135": 0, "camel_22934": 0, "camel_21187": 0, "camel_23790": 0, "camel_21065": 0, "camel_21777": 0, "camel_21181": 0, "camel_21194": 0, "camel_21173": 0, "camel_22947": 0, "camel_23682": 0, "camel_21153": 0, "camel_23707": 0, "camel_22909": 0, "camel_23748": 0, "camel_21182": 0, "camel_21784": 0, "camel_22094": 0, "camel_21162": 0, "camel_21163": 0, "camel_21156": 0, "camel_21132": 0, "camel_21134": 0, "camel_21780": 0, "camel_23750": 0, "camel_23731": 0, "camel_23686": 0, "camel_22207": 0, "camel_21142": 0, "camel_21120": 0, "camel_21137": 0, "camel_23738": 0, "camel_23699": 0, "camel_21130": 0, "camel_21152": 0, "camel_23730": 0, "camel_21127": 0, "camel_21149": 0, "camel_21148": 0, "camel_21178": 0, "camel_23700": 0, "camel_23735": 0, "camel_21191": 0, "camel_23742": 0, "camel_23710": 0, "camel_23693": 0, "camel_22927": 0, "camel_21803": 0, "camel_21125": 0, "camel_23728": 0, "camel_21164": 0, "camel_23719": 0, "camel_21161": 0, "camel_22955": 0, "camel_21151": 0, "camel_21106": 0, "camel_23714": 0, "camel_23736": 0, "camel_21155": 0, "camel_21139": 0, "camel_23732": 0, "camel_23685": 0, "camel_23751": 0, "TheoremQA_jianyu_xu/Ramsey_6.json": 0, "camel_23747": 0, "camel_21136": 0, "camel_21172": 0, "camel_21166": 0, "camel_23741": 0, "camel_23753": 0, "camel_23758": 0, "camel_23739": 0, "camel_23717": 0, "camel_23729": 0, "camel_23723": 0, "camel_23683": 0, "camel_23681": 0, "camel_23705": 0, "camel_23759": 0, "camel_23703": 0, "camel_23709": 0, "camel_21123": 0, "camel_23688": 0, "camel_21146": 0, "camel_23745": 0, "camel_23711": 0, "camel_23752": 0, "camel_21176": 0, "camel_23690": 0, "camel_23794": 0, "aqua_rat_40504": 0.8154795169830322, "aqua_rat_25794": 0.8164724111557007, "TheoremQA_jianyu_xu/Ramsey_4.json": 0.832755982875824, "TheoremQA_jianyu_xu/Ramsey_5.json": 0.8370004892349243, "TheoremQA_jianyu_xu/Ramsey_2.json": 0.8731426000595093, "TheoremQA_jianyu_xu/Ramsey_3.json": 0.8764493465423584}, "TheoremQA_wenhuchen/series_convergen2.json": {"camel_31884": 0.7389206290245056, "camel_31631": 0.7389712929725647, "camel_31607": 0.7390421032905579, "camel_31646": 0.7390532493591309, "math_train_algebra_2272": 0.7391034960746765, "camel_31637": 0.7393593192100525, "camel_31456": 0.739386796951294, "aqua_rat_70269": 0.7394317388534546, "camel_31179": 0.7394387722015381, "aqua_rat_81324": 0.7395200133323669, "camel_31180": 0.739550769329071, "camel_30934": 0.7396494746208191, "aqua_rat_54426": 0.7397175431251526, "camel_30136": 0.7399029731750488, "aqua_rat_61662": 0.7400732040405273, "camel_31601": 0.740090548992157, "aqua_rat_81904": 0.7404847145080566, "aqua_rat_76921": 0.7405962347984314, "aqua_rat_12153": 0.7406173348426819, "aqua_rat_68811": 0.7408018708229065, "aqua_rat_64676": 0.740900993347168, "camel_30351": 0.7409366965293884, "camel_30883": 0.7410092353820801, "camel_30917": 0.7415724992752075, "aqua_rat_30435": 0.7417879700660706, "aqua_rat_4917": 0.7418053150177002, "camel_30912": 0.7418138384819031, "aqua_rat_15035": 0.7418189644813538, "math_train_algebra_881": 0.7421808242797852, "aqua_rat_10308": 0.7423028945922852, "camel_30335": 0.7425859570503235, "camel_30388": 0.742641806602478, "aqua_rat_66140": 0.7426733374595642, "camel_31517": 0.7431186437606812, "camel_31881": 0.7436119914054871, "aqua_rat_23758": 0.7438507080078125, "camel_30888": 0.7439498901367188, "camel_30321": 0.7440784573554993, "aqua_rat_27220": 0.7445327043533325, "camel_30955": 0.7445434927940369, "camel_30377": 0.7449192404747009, "camel_31643": 0.7450188398361206, "camel_30125": 0.7451213598251343, "aqua_rat_33897": 0.7451923489570618, "aqua_rat_8695": 0.7458014488220215, "camel_31309": 0.74592524766922, "camel_31552": 0.7462918162345886, "camel_31147": 0.746316134929657, "camel_30922": 0.7466144561767578, "camel_31516": 0.7467116117477417, "aqua_rat_69735": 0.7467410564422607, "camel_30904": 0.7467989921569824, "aqua_rat_25538": 0.7468136548995972, "camel_30959": 0.7470449805259705, "aqua_rat_49474": 0.7471976280212402, "camel_30916": 0.7473904490470886, "camel_31316": 0.7475659251213074, "camel_31241": 0.7476649284362793, "camel_31304": 0.747759997844696, "camel_30927": 0.7478364706039429, "camel_30949": 0.7480418086051941, "camel_30899": 0.7486192584037781, "camel_30907": 0.7486217021942139, "camel_30348": 0.7486541271209717, "aqua_rat_317": 0.7487174868583679, "camel_31202": 0.7488152384757996, "camel_30320": 0.7489574551582336, "camel_31452": 0.7489683628082275, "camel_31444": 0.7491068243980408, "aqua_rat_10112": 0.7492654323577881, "camel_31633": 0.749288022518158, "camel_30898": 0.7497296929359436, "camel_31869": 0.7500271201133728, "camel_31645": 0.7501863241195679, "aqua_rat_50336": 0.7505234479904175, "aqua_rat_22908": 0.7506060004234314, "aqua_rat_53783": 0.7506691217422485, "aqua_rat_74557": 0.7507486343383789, "camel_31339": 0.751049816608429, "camel_37027": 0.7510785460472107, "camel_30387": 0.7512413263320923, "aqua_rat_14125": 0.7514064311981201, "aqua_rat_17944": 0.7516350150108337, "aqua_rat_9255": 0.7517432570457458, "aqua_rat_442": 0.7518846392631531, "aqua_rat_7480": 0.752030074596405, "camel_30910": 0.7521375417709351, "camel_30366": 0.7526041865348816, "aqua_rat_9135": 0.7526481747627258, "aqua_rat_9734": 0.7527902722358704, "camel_30895": 0.7528417110443115, "camel_31915": 0.7530179619789124, "camel_31505": 0.7536540627479553, "camel_30954": 0.7538089752197266, "aqua_rat_40701": 0.7539111971855164, "aqua_rat_31892": 0.7541393041610718, "camel_18671": 0.7541643977165222, "camel_30685": 0.7544833421707153, "aqua_rat_19250": 0.7549774050712585, "camel_30946": 0.7552446126937866, "camel_31056": 0.7552791833877563, "camel_31047": 0.7562022805213928, "aqua_rat_63913": 0.7563188672065735, "camel_30389": 0.7566540241241455, "camel_30915": 0.7567520141601562, "aqua_rat_38873": 0.7567578554153442, "camel_30953": 0.7567715048789978, "camel_31057": 0.7571917176246643, "camel_30680": 0.7574260234832764, "camel_31676": 0.7575755715370178, "camel_31880": 0.757835328578949, "camel_31635": 0.7579301595687866, "aqua_rat_8940": 0.7582058906555176, "aqua_rat_11729": 0.7590546607971191, "camel_30923": 0.7597888112068176, "camel_30937": 0.7599805593490601, "aqua_rat_58691": 0.7601533532142639, "camel_30360": 0.7604367136955261, "camel_31061": 0.7605839371681213, "camel_30951": 0.761290431022644, "aqua_rat_53487": 0.7614722847938538, "aqua_rat_4875": 0.7615827322006226, "aqua_rat_51974": 0.7618893980979919, "aqua_rat_51216": 0.7620812654495239, "aqua_rat_65996": 0.7621482014656067, "aqua_rat_38959": 0.7626325488090515, "camel_30952": 0.7633689045906067, "aqua_rat_73706": 0.7635424733161926, "aqua_rat_73502": 0.7638083696365356, "camel_31190": 0.7639753222465515, "aqua_rat_4332": 0.7655783295631409, "aqua_rat_73142": 0.7656951546669006, "camel_30343": 0.7662128210067749, "aqua_rat_26892": 0.766251802444458, "camel_31098": 0.766600489616394, "camel_31984": 0.7671504616737366, "camel_30881": 0.7674480080604553, "camel_30368": 0.767702043056488, "camel_30947": 0.7679726481437683, "aqua_rat_31598": 0.7680966854095459, "camel_30932": 0.7687939405441284, "aqua_rat_63400": 0.769529402256012, "aqua_rat_54656": 0.7697288990020752, "aqua_rat_22760": 0.7702584266662598, "camel_30926": 0.7704632878303528, "camel_30885": 0.7707919478416443, "TheoremQA_mingyin/Lebesgue-measure1.json": 0.7713367342948914, "aqua_rat_45": 0.7718448638916016, "camel_30328": 0.7725885510444641, "aqua_rat_50530": 0.773389458656311, "aqua_rat_36268": 0.774320662021637, "aqua_rat_67612": 0.774530291557312, "camel_30942": 0.7761085033416748, "camel_31842": 0.776178777217865, "aqua_rat_53748": 0.7767525315284729, "aqua_rat_12993": 0.7768391370773315, "aqua_rat_72563": 0.7775710821151733, "camel_30374": 0.7776767611503601, "aqua_rat_69318": 0.7781524658203125, "aqua_rat_56288": 0.7789269685745239, "aqua_rat_46276": 0.7790358066558838, "camel_30327": 0.7791328430175781, "aqua_rat_35123": 0.7797033190727234, "aqua_rat_8747": 0.7800399661064148, "camel_30385": 0.7802848815917969, "aqua_rat_3767": 0.7804955840110779, "aqua_rat_31297": 0.7807328701019287, "camel_30330": 0.7813256978988647, "aqua_rat_50511": 0.7814807295799255, "camel_30371": 0.7820966839790344, "camel_30921": 0.782149612903595, "camel_30341": 0.7823401689529419, "aqua_rat_20385": 0.7825214266777039, "aqua_rat_48885": 0.7825374603271484, "aqua_rat_25391": 0.7831964492797852, "camel_30339": 0.7834305167198181, "camel_30887": 0.7841322422027588, "camel_30396": 0.7842465043067932, "camel_30948": 0.7844167351722717, "aqua_rat_19560": 0.7847542762756348, "aqua_rat_50166": 0.7849249839782715, "camel_30325": 0.7856045961380005, "camel_30342": 0.7857673764228821, "camel_30383": 0.7861645221710205, "camel_30353": 0.7899030447006226, "camel_30886": 0.7909500598907471, "camel_30345": 0.7912153005599976, "camel_30357": 0.7933554649353027, "camel_30346": 0.7959621548652649, "camel_31084": 0.7962729334831238, "camel_31759": 0.7989173531532288, "camel_30372": 0.7993549108505249, "aqua_rat_16186": 0.7994990944862366, "aqua_rat_73910": 0.7997961640357971, "aqua_rat_13223": 0.8021038770675659, "camel_30392": 0.8029741644859314, "aqua_rat_69628": 0.8032165765762329, "camel_30338": 0.8078189492225647, "aqua_rat_82861": 0.8083866238594055, "camel_30354": 0.8147217631340027}, "TheoremQA_xinyi/channel_capacity_3.json": {"TheoremQA_xinyi/channel_capacity_3.json": 0, "camel_21864": 0.6440280675888062, "camel_36509": 0.6441378593444824, "camel_41204": 0.6441552639007568, "camel_11135": 0.644195020198822, "camel_41117": 0.6443423628807068, "camel_38626": 0.6445479393005371, "camel_30474": 0.6445558667182922, "camel_25410": 0.6449753642082214, "gsm_rft_11818": 0.6449998021125793, "gsm_rft_4313": 0.6451869010925293, "aqua_rat_37057": 0.6451942324638367, "camel_41098": 0.6452176570892334, "camel_21867": 0.6452744603157043, "camel_11558": 0.6453213095664978, "camel_25447": 0.6454516053199768, "gsm_rft_28347": 0.6454520225524902, "camel_41202": 0.6455675363540649, "camel_11126": 0.6456724405288696, "gsm_rft_32782": 0.6457818150520325, "camel_41222": 0.645824670791626, "camel_30444": 0.6458295583724976, "camel_9465": 0.6459919214248657, "aqua_rat_25750": 0.6461557745933533, "camel_22557": 0.6461968421936035, "camel_36503": 0.646354615688324, "aqua_rat_14333": 0.646615207195282, "camel_38665": 0.6466752290725708, "camel_21918": 0.646696925163269, "camel_9447": 0.6467524170875549, "camel_21855": 0.6467662453651428, "camel_9511": 0.6473016738891602, "camel_37945": 0.6473918557167053, "camel_38540": 0.6474472284317017, "camel_20734": 0.6474528312683105, "gsm_rft_25368": 0.6474645137786865, "camel_9468": 0.6475738286972046, "camel_38645": 0.6475821137428284, "camel_38694": 0.6476184129714966, "camel_9477": 0.6476808190345764, "camel_38787": 0.6478396058082581, "camel_36502": 0.6480551362037659, "gsm_train_31599": 0.64812833070755, "camel_11903": 0.6483246684074402, "camel_11898": 0.6483314633369446, "camel_39930": 0.648398756980896, "camel_9506": 0.64850252866745, "camel_41200": 0.6486070156097412, "camel_38711": 0.6486079096794128, "camel_22397": 0.6487519145011902, "camel_11308": 0.6489957571029663, "camel_39285": 0.64923095703125, "camel_38565": 0.6492354869842529, "camel_41640": 0.6493389010429382, "gsm_rft_12713": 0.6494026184082031, "gsm_rft_24984": 0.6495019197463989, "camel_41255": 0.6495979428291321, "camel_41279": 0.6498061418533325, "camel_11874": 0.6498767137527466, "gsm_rft_19302": 0.6499149203300476, "camel_11876": 0.6501966714859009, "camel_36523": 0.6502147912979126, "camel_39659": 0.6507360339164734, "camel_9464": 0.6509979963302612, "camel_9495": 0.651147723197937, "camel_41212": 0.6515399217605591, "camel_28142": 0.6515618562698364, "gsm_rft_14307": 0.6515681147575378, "aqua_rat_73185": 0.651616632938385, "camel_39482": 0.6517361402511597, "camel_39958": 0.651984453201294, "camel_21570": 0.6522007584571838, "gsm_rft_16361": 0.6522587537765503, "camel_38560": 0.652279794216156, "camel_21846": 0.652309238910675, "camel_25919": 0.6524073481559753, "aqua_rat_53867": 0.6531127691268921, "camel_41248": 0.6533296704292297, "gsm_rft_14862": 0.653357982635498, "gsm_train_9826": 0.653357982635498, "camel_38700": 0.6534659266471863, "camel_41396": 0.6536586880683899, "camel_24831": 0.6537208557128906, "camel_21895": 0.6538206934928894, "camel_38521": 0.6538761258125305, "gsm_rft_11985": 0.6539111733436584, "gsm_rft_27803": 0.6539160013198853, "camel_41753": 0.6541446447372437, "gsm_rft_2474": 0.6542109847068787, "gsm_rft_13965": 0.6542801856994629, "gsm_train_30685": 0.6542801856994629, "camel_39060": 0.6543598771095276, "camel_21841": 0.6546831727027893, "camel_21861": 0.6548188924789429, "camel_38730": 0.6551101803779602, "camel_41252": 0.6554701924324036, "gsm_rft_6860": 0.6556382179260254, "camel_21053": 0.6558486819267273, "camel_41254": 0.6558587551116943, "camel_41223": 0.6558765769004822, "camel_37713": 0.6558890342712402, "camel_21873": 0.6559010744094849, "aqua_rat_10496": 0.6560282111167908, "TheoremQA_maxku/ipnetwork7-lan.json": 0.6563073992729187, "aqua_rat_52087": 0.6563395261764526, "camel_21881": 0.6563771367073059, "camel_9471": 0.6564340591430664, "camel_38659": 0.6566547155380249, "TheoremQA_maxku/ipnetwork4-mac.json": 0.657265305519104, "camel_36749": 0.6573335528373718, "camel_9485": 0.6577290296554565, "gsm_rft_229": 0.6579182147979736, "gsm_rft_9272": 0.6579182147979736, "gsm_train_4199": 0.6579182147979736, "camel_9449": 0.6588872671127319, "camel_38567": 0.6589259505271912, "aqua_rat_6577": 0.6592314839363098, "aqua_rat_2322": 0.659670889377594, "camel_41270": 0.6598352789878845, "camel_21909": 0.6598554849624634, "camel_25498": 0.6598836779594421, "camel_21850": 0.6600374579429626, "aqua_rat_81119": 0.6601967811584473, "aqua_rat_8926": 0.6606101393699646, "aqua_rat_60195": 0.6606936454772949, "camel_9489": 0.6607471704483032, "camel_9454": 0.6610446572303772, "aqua_rat_87402": 0.6614413857460022, "aqua_rat_38416": 0.6619912981987, "camel_39973": 0.6622152924537659, "aqua_rat_37698": 0.6626346707344055, "camel_41247": 0.6626613736152649, "camel_29102": 0.6627042293548584, "camel_38587": 0.6627891063690186, "aqua_rat_66093": 0.6631196737289429, "aqua_rat_47751": 0.6635591387748718, "camel_41242": 0.663788378238678, "camel_41221": 0.6638230085372925, "camel_21893": 0.6639275550842285, "aqua_rat_69941": 0.6639922857284546, "camel_21885": 0.6640451550483704, "aqua_rat_78286": 0.6645671129226685, "camel_40967": 0.6646677851676941, "camel_41208": 0.6650851964950562, "aqua_rat_72089": 0.6652483344078064, "camel_9505": 0.6652615666389465, "camel_41237": 0.6653519868850708, "camel_21889": 0.6653761863708496, "camel_9474": 0.665418803691864, "camel_22521": 0.6661058664321899, "aqua_rat_21944": 0.6661806702613831, "camel_11866": 0.6662876605987549, "aqua_rat_50510": 0.6664845943450928, "aqua_rat_85903": 0.6665782928466797, "aqua_rat_80730": 0.6666052937507629, "aqua_rat_40444": 0.666742205619812, "camel_9457": 0.6667641997337341, "camel_38734": 0.6668150424957275, "aqua_rat_60327": 0.6670107245445251, "camel_22524": 0.6670306324958801, "camel_9508": 0.6672539114952087, "aqua_rat_36286": 0.6675912737846375, "aqua_rat_87308": 0.6679825186729431, "camel_21903": 0.6680591106414795, "aqua_rat_9712": 0.668079137802124, "camel_36244": 0.6680843830108643, "camel_41207": 0.6682154536247253, "camel_38775": 0.6685115694999695, "camel_9453": 0.6692233085632324, "camel_21913": 0.6695194840431213, "camel_9476": 0.6697565317153931, "aqua_rat_27910": 0.6700834631919861, "camel_21911": 0.6701538562774658, "camel_40840": 0.6708524227142334, "camel_22536": 0.671044647693634, "camel_22486": 0.6715328693389893, "camel_22490": 0.6716822981834412, "camel_40982": 0.6725513339042664, "camel_38586": 0.674041748046875, "camel_9500": 0.6752666234970093, "camel_22547": 0.6767442226409912, "camel_36276": 0.6771348118782043, "camel_38692": 0.6777997016906738, "camel_9446": 0.6788586974143982, "camel_22520": 0.6795916557312012, "camel_21912": 0.6807751655578613, "TheoremQA_xinyi/binary_symmetric_channel_1.json": 0.6820786595344543, "camel_9487": 0.6825721859931946, "camel_22548": 0.6830354332923889, "camel_36493": 0.6859865188598633, "camel_22539": 0.6876674890518188, "camel_9448": 0.6902065873146057, "camel_22484": 0.6908831000328064, "camel_9462": 0.6908928751945496, "camel_39395": 0.6968490481376648, "camel_9514": 0.6996198296546936, "camel_9501": 0.7000954747200012, "camel_9503": 0.7074507474899292, "camel_9466": 0.7078449130058289, "TheoremQA_maxku/ipnetwork10-datatransmission.json": 0.7321845293045044}, "TheoremQA_xinyi/huffman_code_3.json": {"TheoremQA_xinyi/huffman_code_3.json": 0, "gsm_rft_22246": 0.726405143737793, "gsm_train_28498": 0.726405143737793, "aqua_rat_44904": 0.7264257669448853, "gsm_rft_787": 0.7265156507492065, "aqua_rat_81690": 0.7265748381614685, "aqua_rat_69430": 0.7266098856925964, "aqua_rat_51437": 0.72662353515625, "aqua_rat_80844": 0.7268815040588379, "camel_25951": 0.7269374132156372, "gsm_rft_21725": 0.7272472381591797, "math_test_counting_and_probability_430": 0.727672278881073, "gsm_train_26662": 0.7277083992958069, "gsm_rft_5816": 0.7277083992958069, "gsm_rft_989": 0.7277083992958069, "aqua_rat_51371": 0.7278494238853455, "aqua_rat_7317": 0.7279424071311951, "aqua_rat_30627": 0.7280328273773193, "aqua_rat_41006": 0.7282277345657349, "aqua_rat_15480": 0.7282686233520508, "camel_37851": 0.7286173105239868, "aqua_rat_75713": 0.7286425828933716, "aqua_rat_38285": 0.7286465167999268, "aqua_rat_6737": 0.7291082143783569, "aqua_rat_79653": 0.729147732257843, "gsm_rft_21502": 0.7293198108673096, "aqua_rat_47432": 0.7293952107429504, "aqua_rat_69333": 0.7296189665794373, "gsm_train_9727": 0.7297658920288086, "gsm_rft_25109": 0.7299498915672302, "aqua_rat_80404": 0.7301568388938904, "gsm_rft_9202": 0.7301958799362183, "camel_25568": 0.7304566502571106, "aqua_rat_52332": 0.7304947972297668, "aqua_rat_51353": 0.730539083480835, "gsm_rft_11773": 0.7305692434310913, "aqua_rat_14782": 0.7308042049407959, "camel_36334": 0.7309746742248535, "camel_25563": 0.7311513423919678, "gsm_rft_23632": 0.7311813235282898, "aqua_rat_8487": 0.7313142418861389, "aqua_rat_44526": 0.7316075563430786, "aqua_rat_53200": 0.7318094968795776, "aqua_rat_39917": 0.7319374680519104, "aqua_rat_24803": 0.7320706844329834, "aqua_rat_31828": 0.7320852875709534, "camel_25572": 0.7321073412895203, "gsm_train_30442": 0.7321770787239075, "gsm_rft_32974": 0.7321770787239075, "gsm_rft_20550": 0.7321829199790955, "camel_8697": 0.7322478294372559, "aqua_rat_75531": 0.7322757840156555, "aqua_rat_64699": 0.7325400710105896, "aqua_rat_12910": 0.7329782247543335, "camel_20512": 0.7330580353736877, "aqua_rat_56269": 0.7330977320671082, "aqua_rat_7483": 0.7334578633308411, "camel_9724": 0.7334882020950317, "aqua_rat_51541": 0.7335252165794373, "aqua_rat_17359": 0.7337148189544678, "aqua_rat_79546": 0.7338546514511108, "aqua_rat_15511": 0.7339600920677185, "aqua_rat_149": 0.7339803576469421, "aqua_rat_34864": 0.7341413497924805, "aqua_rat_66892": 0.734214186668396, "aqua_rat_71213": 0.7343710064888, "camel_36361": 0.7345130443572998, "gsm_rft_4841": 0.7347294092178345, "aqua_rat_17980": 0.7348214387893677, "aqua_rat_72312": 0.7348233461380005, "aqua_rat_50929": 0.7352068424224854, "aqua_rat_23524": 0.7353144288063049, "aqua_rat_37569": 0.7354145646095276, "aqua_rat_7521": 0.7355968356132507, "aqua_rat_36389": 0.7356414794921875, "aqua_rat_76567": 0.7357746362686157, "math_train_prealgebra_1223": 0.7358503341674805, "aqua_rat_85665": 0.7365939617156982, "aqua_rat_44802": 0.7367797493934631, "aqua_rat_42479": 0.7368162870407104, "aqua_rat_70890": 0.7369336485862732, "aqua_rat_47084": 0.737104594707489, "camel_36357": 0.7371717095375061, "aqua_rat_61568": 0.7372038960456848, "gsm_train_31076": 0.7374372482299805, "aqua_rat_59401": 0.7376023530960083, "aqua_rat_76356": 0.7378119230270386, "aqua_rat_36951": 0.7380260229110718, "gsm_rft_16567": 0.7382152676582336, "aqua_rat_41017": 0.7383204698562622, "aqua_rat_15086": 0.738378643989563, "aqua_rat_80351": 0.7387716174125671, "gsm_rft_8211": 0.738791823387146, "gsm_train_1905": 0.738791823387146, "aqua_rat_32157": 0.7390056848526001, "gsm_rft_25388": 0.7390608191490173, "aqua_rat_76140": 0.7390759587287903, "gsm_rft_2237": 0.7391474843025208, "aqua_rat_77548": 0.739428699016571, "aqua_rat_29842": 0.7394503951072693, "aqua_rat_36983": 0.7396194338798523, "gsm_rft_14881": 0.7396878004074097, "gsm_rft_20363": 0.7397496700286865, "aqua_rat_2861": 0.7399950623512268, "gsm_rft_30314": 0.7405471205711365, "camel_37615": 0.7406145930290222, "aqua_rat_34164": 0.7407886385917664, "aqua_rat_20344": 0.7408919334411621, "aqua_rat_80759": 0.7409958243370056, "camel_36391": 0.7410880923271179, "aqua_rat_62327": 0.7413136959075928, "aqua_rat_80459": 0.7415981888771057, "aqua_rat_88939": 0.741682231426239, "aqua_rat_70073": 0.7416847348213196, "aqua_rat_66732": 0.7418258786201477, "gsm_rft_2111": 0.7421166300773621, "aqua_rat_39271": 0.7424765825271606, "aqua_rat_65028": 0.7425613403320312, "aqua_rat_3175": 0.7427680492401123, "aqua_rat_15442": 0.7430794835090637, "aqua_rat_73303": 0.7431389093399048, "aqua_rat_59053": 0.743220329284668, "camel_37553": 0.7434344291687012, "aqua_rat_36836": 0.7435885071754456, "aqua_rat_67387": 0.7439687848091125, "camel_37914": 0.7439814805984497, "aqua_rat_20004": 0.7441104054450989, "camel_36340": 0.7441605925559998, "aqua_rat_53649": 0.7442848086357117, "aqua_rat_78880": 0.7442870140075684, "aqua_rat_31650": 0.7443510293960571, "aqua_rat_24238": 0.7445418834686279, "gsm_rft_10444": 0.7456121444702148, "aqua_rat_67308": 0.7464599013328552, "camel_37554": 0.7469664812088013, "aqua_rat_40065": 0.7470287084579468, "aqua_rat_48010": 0.7472203969955444, "aqua_rat_64824": 0.7472742199897766, "aqua_rat_29990": 0.7473215460777283, "aqua_rat_84418": 0.748181939125061, "aqua_rat_78018": 0.74824059009552, "aqua_rat_23531": 0.7486396431922913, "aqua_rat_83796": 0.7491233348846436, "aqua_rat_87746": 0.7491275668144226, "aqua_rat_41713": 0.7492949962615967, "aqua_rat_74390": 0.7497889399528503, "camel_36341": 0.7500861883163452, "aqua_rat_17862": 0.7506469488143921, "aqua_rat_70004": 0.7507554888725281, "aqua_rat_26254": 0.7507578134536743, "aqua_rat_34677": 0.7519713640213013, "aqua_rat_6686": 0.7522830963134766, "aqua_rat_80435": 0.7525248527526855, "aqua_rat_52525": 0.7534091472625732, "aqua_rat_20302": 0.7544609308242798, "aqua_rat_78942": 0.7547394037246704, "aqua_rat_81027": 0.7555733323097229, "camel_36377": 0.75572669506073, "aqua_rat_73560": 0.7561562657356262, "aqua_rat_15776": 0.7561965584754944, "aqua_rat_23636": 0.7563617825508118, "aqua_rat_12157": 0.7569872140884399, "aqua_rat_77208": 0.7573708295822144, "aqua_rat_78708": 0.7574531435966492, "camel_36326": 0.7581580281257629, "aqua_rat_78747": 0.7582026124000549, "aqua_rat_80797": 0.7586329579353333, "aqua_rat_48028": 0.7595821619033813, "aqua_rat_43433": 0.7596193552017212, "aqua_rat_73092": 0.7598737478256226, "aqua_rat_21385": 0.7599907517433167, "aqua_rat_38718": 0.7642598152160645, "aqua_rat_4547": 0.7653570175170898, "aqua_rat_28724": 0.7677667140960693, "aqua_rat_60978": 0.7678101658821106, "aqua_rat_69403": 0.7689865231513977, "camel_37570": 0.7690017223358154, "aqua_rat_48356": 0.7704451680183411, "aqua_rat_28998": 0.7708345651626587, "aqua_rat_33643": 0.7712787389755249, "aqua_rat_79822": 0.7718275785446167, "camel_36395": 0.7723954319953918, "aqua_rat_53187": 0.7777538895606995, "gsm_rft_6826": 0.7801216840744019, "aqua_rat_58347": 0.7826210856437683, "camel_36360": 0.7837998270988464, "gsm_rft_32883": 0.7864693999290466, "aqua_rat_52378": 0.7877227663993835, "gsm_rft_15553": 0.7893959879875183, "gsm_rft_34828": 0.7900977730751038, "camel_36343": 0.7920499444007874, "gsm_rft_15172": 0.7952190041542053, "gsm_rft_19047": 0.796764075756073, "gsm_train_29804": 0.796764075756073, "gsm_rft_12684": 0.7983934283256531, "aqua_rat_20543": 0.8118147850036621, "aqua_rat_10491": 0.8310766220092773, "camel_37112": 0.8505693674087524, "aqua_rat_623": 0.8521084189414978, "aqua_rat_74410": 0.8565517663955688}}